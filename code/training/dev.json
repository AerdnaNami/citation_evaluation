[
  {
    "span": "(Kim et al.), 2022",
    "document": "Related Work\n\nTemporal graph learning extends static GNNs by modeling time-evolving edges and node states (Rossi et al., 2020; Kazemi et al., 2020). Continuous-time methods use temporal point processes to capture fine-grained dynamics, while discrete-time approaches aggregate snapshots over intervals (Trivedi et al., 2019; Xu et al., 2020). For inductive generalization, memory modules and recurrent state updates preserve historical context (Jiang et al., 2016; Kumar et al., 2018). Recent advances incorporate contrastive objectives to disentangle structure from time-varying noise (Sankar et al., 2020). A probabilistic treatment of event uncertainty was explored by (Kim et al.), 2022, who proposed variance-aware attention to modulate updates under sparse supervision. Our framework complements these by introducing counterfactual interventions on edge events to probe causal influences while retaining scalability on large dynamic graphs.\n",
    "reason": "Year placed outside the parenthetical author–year citation; should be '(Kim et al., 2022)' or narrative 'Kim et al. (2022)'.",
    "start": 672,
    "end": 690,
    "label": "Format"
  },
  {
    "span": "(Chen et al., 2018;,",
    "document": "Introduction\n\nNeural retrievers have transformed open-domain question answering by replacing sparse term matching with dense vector similarity (Karpukhin et al., 2020). Despite strong performance, dense retrievers degrade under domain shift. Prior work explores synthetic queries to diversify training (Bonifacio et al., 2022), iterative hard negative mining (Xiong et al., 2021), and hybrid sparse-dense fusion (Gao et al., 2021). We extend negative sampling by aligning negatives under a curriculum shaped by answer type distributions (Chen et al., 2018;, leading to improved calibration and recall on out-of-domain benchmarks.\n\nRelated Work\n\nRe-ranking with cross-encoders (Nogueira and Cho, 2019) remains competitive, but at high latency. Our approach provides cross-encoder gains with retrieval-time efficiency.",
    "reason": "Punctuation/bracket formatting error within the citation: extraneous semicolon and comma before the closing parenthesis. It should be “(Chen et al., 2018)” without the extra characters.",
    "start": 537,
    "end": 557,
    "label": "Format"
  },
  {
    "span": "There are many recent works that explore cross-lingual summarization in low-resource settings.",
    "document": "Related Work\n\nWe review prior research on monolingual and cross-lingual summarization. Early abstractive summarization systems relied on sequence-to-sequence models with attention and later benefited from large transformer-based encoders and decoders. Cross-lingual summarization (CLS) aims to generate a summary in a target language given a source document in a different language. Initial CLS approaches used pipeline systems that translate the source into the target language before applying a monolingual summarizer, while more recent methods train end-to-end models that jointly learn translation and summarization. There are many recent works that explore cross-lingual summarization in low-resource settings. Evaluation has typically used ROUGE and BLEU, with some works proposing semantic metrics to account for cross-lingual paraphrase. However, the scarcity of aligned document–summary pairs and the domain mismatch between available parallel corpora and summarization data remain persistent challenges.\n",
    "reason": "Mentions 'recent works' without providing any citations to support the claim (violates rule d).",
    "start": 621,
    "end": 715,
    "label": "Unsupported_claim"
  },
  {
    "span": "Zhou et al.",
    "document": "Related Work\n\nGraph neural networks (GNNs) have become the de facto approach for learning over relational data (Kipf and Welling, 2017; Hamilton et al., 2017). Attention-based architectures further improved message passing by adaptively weighting neighbors, as shown by Velickovic et al. (2018). Although early methods assumed homophily, recent studies explore heterophilous graphs and long-range dependencies (Pei et al., 2020; Chien et al., 2021).\n\nZhou et al. propose a taxonomy of training strategies for deep GNNs, including residual connections and normalization, complementing stability analyses (Oono and Suzuki, 2020). Concurrently, scalable sampling and partitioning techniques have enabled GNNs on billion-edge graphs (Chiang et al., 2019; Zeng et al., 2020). Our work builds on these insights and focuses on efficient pretraining for sparse supervision, similar in spirit to Hu et al. (2020) but adapted to dynamic graphs.\n",
    "reason": "Narrative citation is missing the publication year; should be formatted as \"Zhou et al. (YEAR)\".",
    "start": 451,
    "end": 462,
    "label": "Format"
  },
  {
    "span": "there has been a surge of interest recently in graph contrastive learning",
    "document": "Introduction\n\nSelf-supervised learning on graphs seeks to learn useful node and graph representations without manual labels by creating pretext tasks that capture structural and semantic regularities. Contrastive objectives are particularly appealing because they encourage invariance under well-chosen augmentations.\n\nBeyond methodological innovations, there has been a surge of interest recently in graph contrastive learning, motivating comprehensive evaluations across datasets, augmentations, and encoders.\n\nIn this work, we present a principled augmentation taxonomy, propose a calibration strategy for view difficulty, and report a thorough study of transfer performance under distribution shift.",
    "reason": "Uses 'recently' to claim a body of work without any citations per rule (d).",
    "start": 354,
    "end": 427,
    "label": "Unsupported_claim"
  },
  {
    "span": "In (Kipf and Welling, 2017)",
    "document": "Related Work\n\nGraph neural networks (GNNs) extend deep learning to relational structures by iteratively aggregating neighborhood information (Gilmer et al., 2017; Hamilton et al., 2017). Spectral approaches define convolutions via the graph Laplacian (Bruna et al., 2014; Defferrard et al., 2016), while spatial methods operate directly on node neighborhoods (Velickovic et al., 2018; Xu et al., 2019).\n\nIn (Kipf and Welling, 2017), the graph convolutional network (GCN) popularized a simplified first-order approximation that has become a standard baseline for node classification. Subsequent work explored depth and over-smoothing (Li et al., 2018; Oono and Suzuki, 2020), normalization (Zhao and Akoglu, 2020), and scalability to large graphs (Chiang et al., 2019; Rossi et al., 2020).\n\nBeyond transductive settings, inductive learning with mini-batch sampling has been widely studied (Hamilton et al., 2017; Zou et al., 2019), and pretraining strategies for graphs have emerged, inspired by self-supervised learning (Hu et al., 2020; You et al., 2020). For molecular property prediction, equivariant and message-passing architectures capture chemical structure (Schütt et al., 2018; Klicpera et al., 2020).\n\nOur work focuses on calibration for GNNs under distribution shift, complementing advances in robust training (Zugner and Gunnemann, 2019) and uncertainty estimation (Kendall and Gal, 2017).",
    "reason": "Wrong citation style; the preposition \"In\" should introduce a narrative citation like \"Kipf and Welling (2017)\", not a parenthetical form \"(Kipf and Welling, 2017)\".",
    "start": 404,
    "end": 431,
    "label": "Format"
  },
  {
    "span": "Li and Sun, 2020",
    "document": "Introduction\n\nAutomatic detection of misinformation on social media has leveraged linguistic cues, propagation patterns, and user profiling (Shu et al., 2017; Zhou and Zafarani, 2020). According to Li and Sun, 2020, stance-aware features are crucial for early detection, yet most models do not exploit fine-grained discourse roles (Qazvinian et al., 2011; Dungs et al., 2018). We propose a dual-view encoder that aligns claim-centric and user-centric signals to improve robustness under topic shift.",
    "reason": "Narrative citation incorrectly uses a comma before the year; should be 'Li and Sun (2020)'.",
    "start": 198,
    "end": 214,
    "label": "Format"
  },
  {
    "span": "It is well known that toxicity classifiers exhibit higher false positive rates on dialectal English, including African American English.",
    "document": "Introduction\n\nContent moderation systems increasingly rely on supervised classifiers to detect hate speech and toxicity at scale (Schmidt and Wiegand, 2017; Fortuna and Nunes, 2018). Despite high aggregate accuracy, these systems can propagate social biases that disproportionately impact marginalized communities (Buolamwini and Gebru, 2018; Blodgett et al., 2020). It is well known that toxicity classifiers exhibit higher false positive rates on dialectal English, including African American English. Addressing these disparities requires careful dataset design, robust evaluation protocols, and calibration techniques that respect uncertainty under distribution shift. We propose a dialect-aware calibration strategy that reduces spurious correlations without needing dialect labels at test time.",
    "reason": "Asserts a specific, domain-sensitive empirical claim without providing citations to the studies establishing it.",
    "start": 367,
    "end": 503,
    "label": "Unsupported_claim"
  },
  {
    "span": "Rahman et al. 1",
    "document": "Related Work\n\nBenchmarking multilingual NER has historically focused on high-resource languages (Pan et al., 2017) with limited attention to transfer to truly low-resource scripts. Cross-lingual projection (Tiedemann, 2018) and multilingual pretraining (Conneau et al., 2020) have improved zero-shot transfer, but label scarcity still hampers adaptation. Previous surveys Rahman et al. 1 outline challenges in script normalization and tokenization, yet they do not quantify the impact of morphological richness on sample complexity. We complement this line by offering a controlled evaluation with budgeted annotation across typologically diverse languages (Lee et al., 2022).",
    "reason": "Incorrect footnote-like usage: includes a superscript-style number without a proper year or formal footnote formatting.",
    "start": 372,
    "end": 387,
    "label": "Format"
  },
  {
    "span": "Bordes et al. (2013) introduce TransE for learning embeddings of knowledge graphs. Sun et al. (2019) propose RotatE for relational pattern modeling. Miller et al. (2016) present Key-Value Memory Networks for question answering. Karpukhin et al. (2020) propose dense passage retrieval for open-domain QA.",
    "document": "Related Work\n\nKnowledge graph (KG) reasoning and question answering (QA) involve structured representation learning and retrieval-augmented inference. Methods differ in how they model relations, integrate text, and execute multi-hop queries.\n\nBordes et al. (2013) introduce TransE for learning embeddings of knowledge graphs. Sun et al. (2019) propose RotatE for relational pattern modeling. Miller et al. (2016) present Key-Value Memory Networks for question answering. Karpukhin et al. (2020) propose dense passage retrieval for open-domain QA.\n\nRecent approaches hybridize KG embeddings with textual encoders and use learned retrievers for evidence gathering. We propose a joint KG-text retriever with path-aware scoring to improve compositional QA.",
    "reason": "The sentences juxtapose KG embedding methods with QA architectures and open-domain retrieval without transitions or explanation of how they relate, reducing coherence.",
    "start": 243,
    "end": 546,
    "label": "Coherence"
  },
  {
    "span": "(Smith and Jones, 2020)",
    "document": "Introduction\n\nPretraining objectives. Masked language modeling remains the dominant objective for learning general-purpose representations, often combined with next-sentence prediction or span corruption (Devlin et al., 2019; Joshi et al., 2020). Several works explore replaced-token detection and permutation-based masking to enhance robustness (Clark et al., 2020; Yang et al., 2019). Related efforts propose task-aware pretraining for retrieval and QA (Smith and Jones, 2020) to reduce mismatch between pretraining and fine-tuning.\n",
    "reason": "Incorrect conjunction inside a parenthetical citation for APA-style author–date: use \"&\" instead of \"and\". Should be \"(Smith & Jones, 2020)\".",
    "start": 455,
    "end": 478,
    "label": "Format"
  },
  {
    "span": "MTL ",
    "document": "Related Works\n\nExisting task weighting strategies can be divided into two categories: weight adaptation methods and Pareto Optimization (PO)-based methods. The weight adaptation methods adaptively adjust the tasks' weights during training based on pre-defined heuristic, such as uncertainty (Kendall et al., 2018), task difficulty prioritization (Guo et al., 2018), gradient normalization (Chen et al., 2018), weight average (Liu et al., 2019) and task variance regularization (Mao et al., 2021). These methods only use training losses or their gradients to compute task weights while ignores the gap between the training loss and generalization loss.\n\nBesides, the PO-based methods formulate MTL as a multi-objective optimization problem and aim to find an arbitrary Pareto stationary solution (Sener and Koltun, 2018;Mahapatra and Rajan, 2020;Lin et al., 2020;Mao et al., 2020). However, in these methods, the learning objectives only involve training losses; thus, they can only achieve Pareto stationary points w.r.t training losses. They also ignore the gap between the training loss and generalization loss. Moreover,  proposes that the PO-based methods can be also regarded as weight adaptation methods for they optimize the weighted sum of training losses as well.\n\nOverlooking the gap between the training loss and generalization loss would degenerate the performance of MTL. This paper proposes a novel task weighting method to solve this issue.\n\n ",
    "start": 693,
    "end": 697,
    "label": "Unsupported_claim"
  },
  {
    "span": "Zhao and Lee",
    "document": "Introduction\n\nSemi-supervised text classification seeks to leverage abundant unlabeled data to improve performance when labeled examples are scarce (Chapelle et al., 2006; Oliver et al., 2018). Pseudo-labeling and consistency regularization have emerged as two dominant paradigms (Laine and Aila, 2017; Sohn et al., 2020). Following Zhao and Lee, we treat label propagation as a graph-regularized problem where representations are smoothed over a k-NN graph constructed in embedding space. This perspective complements entropy minimization and facilitates robust training under covariate shift (Grandvalet and Bengio, 2005; Shu et al., 2019). Recent advances in pre-trained encoders further amplify gains from unlabeled data by providing stronger feature priors (Devlin et al., 2019; Liu et al., 2019). We extend this line by coupling representation sharpening with neighborhood agreement to reduce confirmation bias, and we benchmark across noisy, class-imbalanced settings (Nguyen and Tran, 2021; Park et al., 2022).\n",
    "reason": "Narrative citation missing year: should be presented as \"Zhao and Lee (YEAR)\" when used narratively.",
    "start": 333,
    "end": 345,
    "label": "Format"
  },
  {
    "span": "In (Klein and Rush, 2017)",
    "document": "Related Work\n\nNeural machine translation leverages sequence-to-sequence modeling with attention (Bahdanau et al., 2015) and has been extended with efficient decoding strategies (Ott et al., 2019). In (Klein and Rush, 2017) the authors introduced a toolkit emphasizing modularity and speed, while later work standardized benchmarking protocols (Post, 2018). Recent advances incorporate pre-trained multilingual encoders to improve low-resource transfer (Conneau et al., 2020).\n",
    "reason": "Wrong citation style: preposition followed by a parenthetical citation; should be “in Klein and Rush (2017)”.",
    "start": 197,
    "end": 222,
    "label": "Format"
  },
  {
    "span": "Klein et al. 1",
    "document": "Introduction\n\nScaling Transformers requires reducing memory and compute without harming accuracy. Low-rank projections (Wang et al., 2020), kernelized attention (Choromanski et al., 2021), and sparsity (Child et al., 2019) are common strategies. A complementary line explores reversible architectures to save activations; Klein et al. 1 report substantial memory reductions on long-sequence tasks but do not address layer normalization stability. We revisit this setting with a norm-preserving reversible block that improves convergence.\n\nWe compare against strong baselines, including Performer (Choromanski et al., 2021) and Longformer (Beltagy et al., 2020), under identical training budgets.",
    "reason": "Wrong use of a footnote-style numeric marker instead of a year; should include the year (e.g., 'Klein et al. (2021)') or be formatted as a proper footnote.",
    "start": 322,
    "end": 336,
    "label": "Format"
  },
  {
    "span": "We evaluate on the widely used SciFact dataset for claim verification.",
    "document": "Introduction\n\nScientific claim verification aims to assess whether a natural-language claim is supported by evidence in the literature (Thorne et al., 2018; Augenstein et al., 2019; Guo et al., 2022). It builds on advances in fact checking and scientific information retrieval (Cohan et al., 2020). We evaluate on the widely used SciFact dataset for claim verification. To model domain-specific language, we initialize with a scientific PLM (Beltagy et al., 2019) and fine-tune with distant supervision from citation contexts (Veyseh et al., 2020).",
    "reason": "First mention of a specific dataset (SciFact) lacks a supporting citation.",
    "start": 299,
    "end": 369,
    "label": "Unsupported_claim"
  },
  {
    "span": "(Brown et. al., 2021)",
    "document": "Introduction. Domain adaptation aims to transfer knowledge from a labeled source domain to an unlabeled or sparsely labeled target (Ben-David et al., 2010). Recent text adaptation methods align feature distributions via adversarial training and contrastive objectives (Ganin et al., 2016; Cai & Wang, 2020). Pseudo-labeling with confidence filtering can further improve target performance (Zou et al., 2019). Prompt-based adaptation leverages pretrained language models to reduce task-specific supervision (Gao et al., 2021). Notably, (Brown et. al., 2021) examine instruction tuning as a means to generalize across tasks with minimal updates. Our approach combines target-aware prompts with risk minimization under shift.",
    "reason": "Typographical/format style error in citation: uses 'et. al.' instead of the correct 'et al.'; should be '(Brown et al., 2021)'.",
    "start": 535,
    "end": 556,
    "label": "Format"
  },
  {
    "span": "Adversarial alignment minimizes domain discrepancy (Ganin and Lempitsky, 2015). Strong augmentations increase robustness (Cubuk et al., 2019). Vision-language pretraining learns cross-modal features (Radford et al., 2021).",
    "document": "Introduction\n\nDomain shift degrades the performance of object detectors when training and test distributions differ. Bridging this gap requires both distribution alignment and robustness to perturbations encountered in the target environment.\n\nAdversarial alignment minimizes domain discrepancy (Ganin and Lempitsky, 2015). Strong augmentations increase robustness (Cubuk et al., 2019). Vision-language pretraining learns cross-modal features (Radford et al., 2021).\n\nWhile each direction is promising, it is uncertain how to combine them effectively for detection under severe shift. We present a pipeline that unifies alignment with augmentation-aware pretraining signals.",
    "reason": "The span moves from adversarial domain adaptation to data augmentation to vision-language pretraining with no transitions or stated relationships, leaving the connections implicit and abrupt.",
    "start": 244,
    "end": 466,
    "label": "Coherence"
  },
  {
    "span": "Smith (et al., 2021)",
    "document": "Introduction\n\nLearning from weak supervision aggregates noisy labeling sources into probabilistic labels that can train high-capacity models with few annotations. Early systems focused on rule-based labeling functions and generative modeling of source accuracies (Ratner et al., 2017), while recent work integrates learned heuristics and representation sharing across tasks (Bach et al., 2019). Smith (et al., 2021) analyze the limits of simple majority-vote aggregation under label shift, motivating calibration-aware reweighting. Our contribution unifies weak-label calibration with curriculum sampling to reduce confirmation bias during self-training.\n",
    "reason": "Incorrect placement of parentheses around “et al.” in a narrative citation; should be “Smith et al. (2021)”.",
    "start": 395,
    "end": 415,
    "label": "Format"
  },
  {
    "span": "Artetxe et al. (2018) presented methods for learning bilingual word embeddings without supervision. Conneau et al. (2020) introduced XLM-R as a strong cross-lingual pretraining baseline. Lample et al. (2018) explored unsupervised machine translation using shared latent representations. Pires et al. (2019) analyzed zero-shot transfer properties of mBERT.",
    "document": "Related Work\n\nCross-lingual transfer aims to build models that generalize across languages without requiring task-specific labels in each target language. Approaches include alignment of lexical spaces, multilingual pretraining, and unsupervised translation.\n\nArtetxe et al. (2018) presented methods for learning bilingual word embeddings without supervision. Conneau et al. (2020) introduced XLM-R as a strong cross-lingual pretraining baseline. Lample et al. (2018) explored unsupervised machine translation using shared latent representations. Pires et al. (2019) analyzed zero-shot transfer properties of mBERT.\n\nWe focus on parameter-efficient adaptation for low-resource targets by combining lightweight adapters with vocabulary alignment, targeting improved stability under domain shift.",
    "reason": "Sentences enumerate studies without signaling how they relate to each other or to the surrounding discussion; relationships are implied rather than made explicit and transitions are missing (issues a and b).",
    "start": 260,
    "end": 615,
    "label": "Coherence"
  },
  {
    "span": "Johnson (2019",
    "document": "Related Work\n\nOff-policy reinforcement learning focuses on data reuse to improve sample efficiency. Q-learning with function approximation remains a standard baseline (Watkins and Dayan, 1992), and deep variants mitigate divergence through target networks and experience replay (Mnih et al., 2015). As shown by Johnson (2019 in the context of distributional critics, constraining the Bellman operator can stabilize training, a finding later echoed by algorithms using implicit regularization (Nachum et al., 2019; Fujimoto et al., 2019).",
    "reason": "Missing closing parenthesis in a narrative citation; should be “Johnson (2019)”.",
    "start": 311,
    "end": 324,
    "label": "Format"
  },
  {
    "span": "(Patel, 2021; and Müller, 2022)",
    "document": "Related Work\n\nProgram analysis has leveraged abstract interpretation and SMT-based reasoning to scale verification to real-world codebases (Cousot and Cousot, 1977; Barrett et al., 2011). Neural program representations enable learning-based bug detection and code completion (Allamanis et al., 2018; Hellendoorn et al., 2020). Hybrid approaches combine static analysis with learned heuristics to prioritize warnings (Gulwani et al., 2018; Bielik et al., 2017). Prior work on probabilistic invariants explores learning distributional properties over program states (Wang et al., 2018). Recent efforts integrate counterexample-guided refinement (Sharma et al., 2013) and data-flow summaries (Li et al., 2020) to improve precision (Patel, 2021; and Müller, 2022).",
    "reason": "Incorrect separator inside a multi-citation: 'and' should not appear within a parenthetical list separated by semicolons. It should be '(Patel, 2021; Müller, 2022)'.",
    "start": 728,
    "end": 759,
    "label": "Format"
  },
  {
    "span": "He et al. (2020) proposed momentum contrast (MoCo) for instance discrimination. Caron et al. (2021) introduced DINO using self-distillation with no labels. Xie et al. (2021) showed masked image modeling substantially improves visual pretraining. Grid masking has also been studied for regularization (Chen et al., 2020).",
    "document": "Related Work\n\nSelf-supervised learning (SSL) in computer vision has progressed rapidly, with contrastive, clustering, and reconstruction-based objectives driving state-of-the-art representation quality. These methods differ in their reliance on negative samples, augmentation invariances, and architectural constraints.\n\nHe et al. (2020) proposed momentum contrast (MoCo) for instance discrimination. Caron et al. (2021) introduced DINO using self-distillation with no labels. Xie et al. (2021) showed masked image modeling substantially improves visual pretraining. Grid masking has also been studied for regularization (Chen et al., 2020).\n\nBeyond pretraining objectives, researchers explored multi-modal alignment, stronger augmentation pipelines, and scalable training setups that balance invariance and equivariance (Radford et al., 2021; Zbontar et al., 2021). Our work examines how pretext-task choice interacts with downstream sample efficiency under domain shift.",
    "reason": "The span abruptly enumerates four different works without clarifying how each relates to the others or to the same theme, leaving the reader to infer connections and lacking transitions.",
    "start": 321,
    "end": 641,
    "label": "Coherence"
  },
  {
    "span": "Demographic bias in word embeddings has been widely documented (Bolukbasi et al., 2016; Caliskan et al., 2017). Model calibration addresses overconfidence (Guo et al., 2017). Domain adaptation techniques reduce distribution shift (Ben-David et al., 2010). Toxicity detection datasets highlight annotation disagreements (Dixon et al., 2018).",
    "document": "Introduction\n\nMitigating bias in NLP systems requires understanding sources of harm across data, models, and evaluation. Prior work spans representation learning, training objectives, and post-hoc interventions, but integration across these threads remains limited.\n\nDemographic bias in word embeddings has been widely documented (Bolukbasi et al., 2016; Caliskan et al., 2017). Model calibration addresses overconfidence (Guo et al., 2017). Domain adaptation techniques reduce distribution shift (Ben-David et al., 2010). Toxicity detection datasets highlight annotation disagreements (Dixon et al., 2018).\n\nWe instead study counterfactual data augmentation targeting lexical and syntactic confounders, linking representational harms to metric selection under varying demographic proportions.",
    "reason": "The listed sentences jump across embedding bias, calibration, domain adaptation, and toxicity datasets without explaining their connections, and lack transitions that establish a coherent thread.",
    "start": 267,
    "end": 607,
    "label": "Coherence"
  },
  {
    "span": "Biomedical entity linking systems rely on dictionary matching, candidate generation via TF–IDF or dense retrieval, and neural reranking with cross-encoders (Zheng et al., 2020; Ji et al., 2020; Yao et al., 2021; Sung et al., 2020). Large biomedical language models such as SciBERT and BioBERT further boost linking accuracy (Beltagy et al., 2019; Lee et al., 2020).",
    "document": "Related Work\n\nDatasets and evaluation. Biomedical entity linking has been evaluated on diverse corpora spanning clinical narratives and scientific articles, with varying ontology coverage and mention ambiguity. Robustness across domains remains challenging due to terminology drift and noisy surface forms.\n\nLinking architectures. Biomedical entity linking systems rely on dictionary matching, candidate generation via TF–IDF or dense retrieval, and neural reranking with cross-encoders (Zheng et al., 2020; Ji et al., 2020; Yao et al., 2021; Sung et al., 2020). Large biomedical language models such as SciBERT and BioBERT further boost linking accuracy (Beltagy et al., 2019; Lee et al., 2020).\n\nDisambiguation signals. Beyond text, recent work integrates ontology structure, synonyms, and definition graphs to capture concept semantics and improve disambiguation, sometimes using graph neural networks or constrained inference.\n\nOur method introduces calibration-aware candidate generation with semantic priors derived from ontology neighborhoods, reducing overconfident mislinks in low-resource concepts.",
    "reason": "The span lists components and models used in prior systems without relating them to the proposed method or explicitly stating the unresolved problem the paper tackles.",
    "start": 331,
    "end": 696,
    "label": "Lacks_synthesis"
  },
  {
    "span": "(Kulshreshtha et al., 2021,",
    "document": "Related Work\n\nDomain adaptation for QA leverages data augmentation, adversarial training, and back-training (Kulshreshtha et al., 2021, with varying degrees of success. Lottery-ticket subnetworks have also been explored for low-resource regimes (Zhu et al., 2021). Our work focuses on the interaction between acquisition strategies and target-domain shift.",
    "reason": "Missing closing parenthesis in the citation.",
    "start": 108,
    "end": 135,
    "label": "Format"
  },
  {
    "span": "BERT was used in an AES task trained on essays written by high school students.",
    "document": "Related Work\n\nAutomated essay scoring (AES) has progressed from handcrafted features and linear models to neural encoders that capture syntax and discourse structure (Attali and Burstein, 2006; Taghipour and Ng, 2016). Pretrained language models have further improved cross-prompt generalization by leveraging large-scale unlabeled text.\n\nBERT was used in an AES task trained on essays written by high school students. However, few works examine whether such models rely on superficial cues like length and prompt keywords versus holistic argumentation quality.",
    "reason": "Describes a specific prior setup (model + task + population) without citation (rule a for first mention of study; rule e/iii example).",
    "start": 339,
    "end": 418,
    "label": "Unsupported_claim"
  },
  {
    "span": "(2020)",
    "document": "Related Work\n\nVisual grounding links natural language expressions to image regions by learning cross-modal alignments. As demonstrated in (2020), conditioning on object proposals improves phrase localization, while later methods refine alignment with region-language attention (Rohrbach et al., 2016; Yu et al., 2018). Cross-modal transformers further enhance performance by pretraining on captioning corpora (Li et al., 2020; Chen et al., 2020). Recent benchmarks emphasize robustness to referring expression ambiguity (Luo et al., 2021).",
    "reason": "Year-only parenthetical used as a citation without authors; should include author–year (e.g., \"As demonstrated in Zhang et al. (2020)\") or be otherwise fully specified.",
    "start": 138,
    "end": 144,
    "label": "Format"
  },
  {
    "span": "HotpotQA distractor setting",
    "document": "Related Work\n\nMulti-hop question answering requires integrating evidence from multiple passages to arrive at a final answer. Benchmarks have spurred progress in scalable retrieval, reasoning, and explanation generation. Recent models explicitly model chains of thought or latent question decompositions, while others emphasize efficient retrieval over large corpora.\n\nA popular evaluation protocol focuses on the HotpotQA distractor setting, where systems must identify supporting facts among distractors and produce both an answer and an explanation. Approaches vary in whether they interleave retrieval and reasoning or separate them into distinct stages.\n\nWe build upon retrieval-augmented architectures with a lightweight verifier that scores candidate reasoning paths, emphasizing faithfulness and robustness to spurious correlations.\n",
    "reason": "References a specific benchmark configuration without providing a citation at first mention.",
    "start": 413,
    "end": 440,
    "label": "Unsupported_claim"
  },
  {
    "span": "Furthermore, the evaluation is limited to top 10-50 predictions regardless of the actual size of the entity set.",
    "document": "Introduction\n\nEntities are integral to applications that require understanding natural language text such as semantic search (Inan et al., 2021;Lashkari et al., 2019), question answering (Chandrasekaran et al., 2020;Cheng and Erk, 2020) and knowledge base construction (Goel et al., 2021;Al-Moslmi et al., 2020). To this end, entity set expansion (ESE) is a crucial task that uses a textual corpus to enhance a set of seed entities (e.g., 'mini bar', 'tv unit') with new entities (e.g., 'coffee', 'clock') that belong to the same semantic concept (e.g., room features).\n\nSince training data in new domains is scarce, many existing ESE methods expand a small seed  set by learning to rank new entity candidates with limited supervision. Broadly speaking, there are two types of such low-resource ESE methods: (a) corpus-based methods (Shen et al., 2018;Huang et al., 2020a;Yu et al., 2019a) that bootstrap the seed set using contextual features and patterns, and (b) language model-based methods  that probe a pre-trained language model with prompts to rank the entity candidates.\n\nDespite the recent progress, reported success of ESE methods is largely limited to benchmarks focusing on named entities (e.g., countries, diseases) and well-written text such as Wikipedia. Furthermore, the evaluation is limited to top 10-50 predictions regardless of the actual size of the entity set. As a result, it is unclear whether the reported effectiveness of ESE methods is conditional to datasets, domains, and/or evaluation methods.\n\nIn this paper, we conduct a comprehensive study to investigate the generalizability of ESE methods in low-resource settings. Specifically, we focus on user-generated text such as customer reviews, which is widely used in many NLP applications (Li et al., 2019;Bhutani et al., 2020;Dai and Song, 2019). Due to lack of benchmarks on user-generated text, we create new benchmarks from three domains -hotels, restaurants and jobs.\n\nWe found that these benchmarks exhibit characteristics (illustrated in Figure 1) distinctive from existing benchmarks: (a) multifaceted entities (entities that belong to multiple concepts -e.g., 'venice beach' can belong to concepts location and nearby attractions); (b) non-named entities (entities that are typically noun phrases but not proper names (Paris and Suchanek, 2021) -e.g., 'coffee'); and (c) vague entities (human annotators have subjective disagreement on their concept labels -e.g., 'casino' for nearby attraction).\n\nWe found that user-generated text can have up to 10X more multifaceted entities and 2X more nonnamed entities compared to well-curated benchmarks. Furthermore, concepts that do not have well-defined semantics result in vague entities. We hypothesize that these characteristics may affect the performance of ESE methods and thus use these to profile ESE methods. 1 kg denotes the number of all correct entities of a concept.\n\n ",
    "start": 1271,
    "end": 1383,
    "label": "Unsupported_claim"
  },
  {
    "span": "Balog et al. (2017) explored learning to synthesize simple programs from input-output examples. Chen et al. (2021) demonstrated large language models for competitive programming tasks. Yin and Neubig (2018) investigated program generation via abstract syntax constraints. Kaliszyk et al. (2018) studied premise selection for theorem proving with learning-based methods.",
    "document": "Related Work\n\nProgram synthesis and code generation research spans neural and symbolic techniques, with constraints informed by type systems, grammars, and test feedback. Benchmarks range from domain-specific languages to general-purpose programming and formal reasoning.\n\nBalog et al. (2017) explored learning to synthesize simple programs from input-output examples. Chen et al. (2021) demonstrated large language models for competitive programming tasks. Yin and Neubig (2018) investigated program generation via abstract syntax constraints. Kaliszyk et al. (2018) studied premise selection for theorem proving with learning-based methods.\n\nRecent lines integrate execution-guided decoding and constraint solvers to improve correctness (Chen et al., 2018; Austin et al., 2021). Our framework augments decoding with dynamic unit tests and learned repair to increase pass rates under strict evaluation.",
    "reason": "The span lists works from IO-based synthesis, competitive programming, syntax-constrained generation, and theorem proving without explaining their relationship. The sequence lacks transitions and the relevance of each to the others is left implicit.",
    "start": 273,
    "end": 642,
    "label": "Coherence"
  },
  {
    "span": "Graph-based recommenders extend collaborative filtering by propagating user–item signals over interaction graphs using message passing layers (Ying et al., 2018; Wu et al., 2019; He et al., 2020). Later work incorporates higher-order neighborhoods and edge weights to capture complex dependencies (Klicpera et al., 2019; Wang et al., 2019; Sun et al., 2020). Contrastive objectives have also been introduced to regularize representations against graph augmentations (Velickovic et al., 2019; You et al., 2020; Zhou et al., 2020).",
    "document": "Related Work\n\nRecommender systems leverage historical interactions to infer user preferences at scale. Traditional collaborative filtering methods model user–item affinities either via neighborhood heuristics or low-rank factorization, and recent progress has been driven by deep learning, enabling nonlinear embeddings and context-aware signals. However, capturing high-order connectivity and alleviating sparsity remain central challenges.\n\nGraph-based recommenders extend collaborative filtering by propagating user–item signals over interaction graphs using message passing layers (Ying et al., 2018; Wu et al., 2019; He et al., 2020). Later work incorporates higher-order neighborhoods and edge weights to capture complex dependencies (Klicpera et al., 2019; Wang et al., 2019; Sun et al., 2020). Contrastive objectives have also been introduced to regularize representations against graph augmentations (Velickovic et al., 2019; You et al., 2020; Zhou et al., 2020).\n\nIn this work, we study a lightweight propagation module that decouples graph construction from representation learning and scales to billion-edge graphs. We evaluate on public and industrial datasets and analyze the trade-offs between depth, normalization, and long-tail coverage.\n",
    "reason": "The span lists prior GNN recommender approaches without explaining how they relate to the present work or what specific gap motivates the new module.",
    "start": 443,
    "end": 972,
    "label": "Lacks_synthesis"
  },
  {
    "span": "Vastwani et al. 1",
    "document": "Introduction\n\nWe study how annotation feedback can be leveraged as bandit signals for extractive QA. Prior work has explored binary feedback and simulated rewards to cut labeling costs (Kratzwald et al., 2020; Stiennon et al., 2020). As argued by Vastwani et al. 1, reducing span-level supervision can make training more robust to noise in crowd-sourced data. We build on these insights and test cross-domain adaptation baselines (Fisch et al., 2019; Khashabi et al., 2020b).",
    "reason": "Improper footnote-style marker without year; should include a year or be formatted as a proper footnote/reference.",
    "start": 247,
    "end": 264,
    "label": "Format"
  },
  {
    "span": "Chen et al. (2021) demonstrated code generation from natural language with large pretrained models. Austin et al. (2021) evaluated scaling laws for program synthesis. Le et al. (2022) incorporated unit tests to guide decoding. Zelikman et al. (2022) examined self-training signals for improving reasoning in code.",
    "document": "Related Work\n\nProgram Synthesis with Large Language Models\n\nRecent work leverages pretrained transformers for generating code from natural language, with improvements driven by data scale, decoding strategies, and feedback signals. Benchmarks differ in specification fidelity, test coverage, and execution safety, making direct comparisons challenging.\n\nChen et al. (2021) demonstrated code generation from natural language with large pretrained models. Austin et al. (2021) evaluated scaling laws for program synthesis. Le et al. (2022) incorporated unit tests to guide decoding. Zelikman et al. (2022) examined self-training signals for improving reasoning in code.\n\nOur method unifies test-guided decoding with semantic feedback from static analysis, reducing reliance on oracle test suites while preserving execution safety.",
    "reason": "Sequentially cited works are presented without explicit links or transitions; it is not clear how scaling laws, unit tests, and self-training relate to or differ from one another.",
    "start": 354,
    "end": 667,
    "label": "Coherence"
  },
  {
    "span": "There are many recent works that explore multilingual code-mixing in dialogue.",
    "document": "Related Work\n\nCode-mixing and code-switching in conversational agents present unique challenges for intent classification and slot filling across languages. There are many recent works that explore multilingual code-mixing in dialogue. Prior efforts have examined token-level mixing patterns and pragmatic triggers in chatbots and customer support logs. Despite these advances, there is still limited understanding of how pretraining objectives transfer to mixed-lingual contexts.",
    "reason": "Mentions \"recent works\" without providing any citations; per rule (d), such claims must be backed by references.",
    "start": 157,
    "end": 235,
    "label": "Unsupported_claim"
  },
  {
    "span": "Recent competitions on robotic grasping have underscored the importance of sim-to-real transfer",
    "document": "Introduction\n\nRobotic manipulation research increasingly relies on simulation for large-scale data generation, policy learning, and rapid iteration. Nevertheless, transferring policies learned in simulation to real hardware remains challenging due to visual and dynamical domain gaps.\n\nRecent competitions on robotic grasping have underscored the importance of sim-to-real transfer. Yet, most evaluation protocols emphasize success rates under constrained settings, leaving robustness to lighting, clutter, and object shift underexplored.\n\nWe present a benchmark that systematically varies visual texture, camera pose, and object distribution, enabling precise diagnosis of generalization failures in visuo-motor grasping policies.",
    "reason": "Mentions 'recent competitions' and their conclusions without citing the competitions or reports (rule d and a).",
    "start": 286,
    "end": 381,
    "label": "Unsupported_claim"
  },
  {
    "span": "In (Vatswani et al., 2019)",
    "document": "Related Work\n\nDomain adaptation for text classification often relies on self-training and auxiliary supervision to bridge distribution gaps. In (Vatswani et al., 2019) the authors examine cross-domain transfer with parameter-efficient adapters, while Gururangan et al. (2020) demonstrate that continued pretraining on in-domain corpora substantially improves downstream accuracy. Contrastive objectives have been adapted to align feature spaces across domains (Ruder and Plank, 2018), and data augmentation via back-translation helps mitigate label sparsity (Edunov et al., 2018). Our work differs in explicitly modeling acquisition shift introduced by bandit-style feedback and evaluates adaptation under limited annotation.\n",
    "reason": "Wrong citation style; the preposition should not enclose the citation in parentheses and should read “In Vatswani et al. (2019)”.",
    "start": 141,
    "end": 167,
    "label": "Format"
  },
  {
    "span": "According to industry reports, misinformation increased by 35% during the pandemic.",
    "document": "Introduction\n\nAutomated fact-checking aims to assess the veracity of claims by retrieving evidence and reasoning over it. The societal impact of misinformation has intensified with the rapid dissemination of content on social platforms. According to industry reports, misinformation increased by 35% during the pandemic. Despite advances in retrieval-augmented language models, reliability suffers in low-resource topics and emerging events, motivating strategies that fuse multiple retrieval signals and explicitly model uncertainty.",
    "reason": "This presents a specific statistic without any citation or evidence, violating rule concerning unsupported statistics (b).",
    "start": 237,
    "end": 320,
    "label": "Unsupported_claim"
  },
  {
    "span": "The LibriSpeech test-clean set contains 2620 utterances.",
    "document": "Introduction\n\nEnd-to-end automatic speech recognition (ASR) has benefited from attention-based encoder–decoder models and CTC hybrids, enabling direct mapping from acoustics to word sequences (Graves et al., 2013; Chan et al., 2016). Self-supervised pre-training further reduces labeled data requirements and improves robustness (Baevski et al., 2020; Hsu et al., 2021).\n\nThe LibriSpeech test-clean set contains 2620 utterances. Despite widespread adoption of LibriSpeech benchmarks, domain shifts to conversational and far-field speech remain challenging. We therefore study multi-domain training and test-time adaptation to close the gap between read and conversational speech, while maintaining performance on standard test sets.\n\nOur contributions include a domain-conditional adapter, an uncertainty-aware decoding scheme, and an analysis of error types across domains.",
    "reason": "A specific dataset statistic is provided without a citation or evidence supporting the number (violates rule b).",
    "start": 372,
    "end": 428,
    "label": "Unsupported_claim"
  },
  {
    "span": "Graph Attention Networks have become the standard choice for molecular property prediction",
    "document": "Introduction\n\nMolecular property prediction relies on learning from graph-structured data where atoms and bonds define the topology. Neural message passing frameworks have achieved strong results by iteratively aggregating neighborhood information.\n\nGraph Attention Networks have become the standard choice for molecular property prediction, as they can differentially weight neighbors during aggregation to capture functional group relevance and local chemical context.\n\nDespite impressive performance, most models remain brittle to distributional shift across scaffolds. We propose scaffold-aware pretraining and calibration strategies to improve out-of-distribution generalization without additional labels.\n",
    "reason": "Makes a field-level claim about a 'standard choice' without supporting citations; per rule (b), specialized assertions about common practice must be referenced.",
    "start": 250,
    "end": 340,
    "label": "Unsupported_claim"
  },
  {
    "span": "Several recent works apply ViTs to chest X-ray diagnosis with promising results.",
    "document": "Related Work\n\nMedical image classification increasingly leverages transformer architectures to model long-range dependencies beyond local convolutional receptive fields. Hybrid CNN-Transformer designs have been proposed to retain fine textures while attending to global context. Several recent works apply ViTs to chest X-ray diagnosis with promising results. Nonetheless, performance can be sensitive to resolution, patch size, and pretraining domain, and annotation scarcity limits generalization. We explore masked image pretraining with anatomy-aware tokenization to capture disease patterns across varying spatial scales while reducing reliance on exhaustive labels.",
    "reason": "Mentions 'recent works' and their outcomes without providing citations to those works (rule d).",
    "start": 279,
    "end": 359,
    "label": "Unsupported_claim"
  },
  {
    "span": "[12]",
    "document": "Introduction\n\nModel-based reinforcement learning (RL) seeks sample efficiency by learning environment dynamics to plan or improve policies (Gupta and Singh, 2019; Perez et al., 2021). While earlier methods suffered from compounding model error, recent work leverages uncertainty-aware ensembles and latent dynamics to stabilize planning (Huang and Li, 2020; Ortega and Kim, 2022). As shown in [12], policy constraints can reduce exploitation of model inaccuracies, but author–year citations remain standard in this literature (e.g., Chen and Rao, 2020; Silva and Tan, 2021).\n\nWe present a constrained latent planner that unifies trajectory regularization with risk-sensitive objectives, improving robustness under sparse rewards and stochastic transitions.",
    "reason": "Numeric bracketed citation used in a context that otherwise follows author–year style. Should be replaced with an author–year citation, e.g., \"as shown in Chen and Rao (2020)\" or a parenthetical author–year reference.",
    "start": 393,
    "end": 397,
    "label": "Format"
  },
  {
    "span": "Garcia et al. 1",
    "document": "Introduction\n\nProgram synthesis from natural language specifications has advanced with neural decoders guided by symbolic constraints (Yin and Neubig, 2017; Rabinovich et al., 2017). Despite progress, models often overfit template artifacts and fail to generalize to unseen compositions. Garcia et al. 1 report that incorporating execution-guided decoding substantially reduces spurious programs on text-to-SQL. We revisit this finding in broader semantic parsing settings, introducing a verifier that integrates partial execution signals during beam search (Shi et al., 2020).\n\nOur contributions include a unified training objective and a standardized evaluation suite for compositional generalization.",
    "reason": "Wrong use of footnotes/format: citation ends with a superscript-like numeral instead of a year or proper footnote; should be 'Garcia et al. (YEAR)' or a correctly formatted footnote.",
    "start": 288,
    "end": 303,
    "label": "Format"
  },
  {
    "span": "(Li and Zhao, 2021",
    "document": "Related Work\n\nGraph neural networks generalize convolution to irregular domains (Bronstein et al., 2017). Spectral methods laid the groundwork (Bruna et al., 2014), and localized filters improved scalability (Kipf and Welling, 2017). Inductive learning was enabled by neighborhood sampling (Hamilton et al., 2017). Recent works consider over-smoothing and expressivity (Xu et al., 2019). As shown by (Li and Zhao, 2021 we evaluate residual connections to alleviate degradation. We also assess normalization strategies (Zhao and Akoglu, 2020) and calibration techniques for uncertainty estimation.",
    "reason": "Missing closing parenthesis in the parenthetical citation.",
    "start": 400,
    "end": 418,
    "label": "Format"
  },
  {
    "span": "In previous industry deployments, end-to-end models have replaced hybrid systems in noisy conditions.",
    "document": "Introduction\n\nAutomatic speech recognition (ASR) has transitioned from hybrid HMM-DNN systems to end-to-end encoder-decoder architectures, driven by simplification and better exploitation of large datasets (Graves et al., 2014; Chan et al., 2016). Robustness to noise and far-field conditions remains a key challenge addressed through data augmentation and specialized front-ends (Ko et al., 2015; Sainath et al., 2017).\n\nIn previous industry deployments, end-to-end models have replaced hybrid systems in noisy conditions. Yet systematic evidence quantifying the break-even point between the two paradigms across SNR regimes and languages is limited. We provide a multi-domain comparison using identical lexicons and language models where applicable.\n\nRelated Work\n\nPrior analyses study domain adaptation for ASR (Shinohara, 2016) and investigate the role of external language models in end-to-end decoding (Kannan et al., 2018).",
    "reason": "Claims a trend in 'industry deployments' without citing case studies, reports, or papers to support the statement.",
    "start": 422,
    "end": 523,
    "label": "Unsupported_claim"
  },
  {
    "span": "Prompt tuning improves zero-shot performance by learning soft tokens (Lester et al., 2021). Retrieval-augmented generation reduces hallucination by consulting external documents (Lewis et al., 2020). Chain-of-thought prompting provides stepwise rationales that enhance reasoning (Wei et al., 2022). Calibration methods estimate confidence to align probabilities with accuracy (Guo et al., 2017).",
    "document": "Related Work\n\nLarge language models have rapidly advanced zero-shot and few-shot capabilities through in-context learning and parameter-efficient adaptation. A parallel literature studies reliability, including uncertainty estimation and interpretability, to make model outputs more trustworthy.\n\nPrompt tuning improves zero-shot performance by learning soft tokens (Lester et al., 2021). Retrieval-augmented generation reduces hallucination by consulting external documents (Lewis et al., 2020). Chain-of-thought prompting provides stepwise rationales that enhance reasoning (Wei et al., 2022). Calibration methods estimate confidence to align probabilities with accuracy (Guo et al., 2017).\n\nDespite covering complementary aspects of control and reliability, prior work rarely examines their interactions. Our study analyzes how prompting and retrieval jointly affect calibration in reasoning tasks.",
    "reason": "The paragraph enumerates four separate topics with citations but lacks transitions or an explicit thread connecting prompting, retrieval, chain-of-thought, and calibration, making the connection between works abrupt and unclear.",
    "start": 297,
    "end": 692,
    "label": "Coherence"
  },
  {
    "span": "[12]",
    "document": "Related Work\n\nIn knowledge-grounded dialogue, grounding sources range from encyclopedic passages to task-specific APIs. Most recent approaches cite prior work using author–date style (e.g., Dinan et al., 2019; Zhou et al., 2020), but some systems also reference toolkits for retrieval [12]. Our work adheres to author–date conventions and reports toolkit details separately in the appendix.",
    "reason": "Inconsistent citation style: numeric bracket '[12]' appears in an author–date context. It should be converted to an author–year citation or harmonized with the chosen style.",
    "start": 285,
    "end": 289,
    "label": "Format"
  },
  {
    "span": "(Kim, 2016, Park, 2019)",
    "document": "Related Work\n\nDialogue state tracking has progressed from rule-based trackers to statistical and neural models that infer slot-value distributions. Early rule-based systems relied on handcrafted update rules (Williams and Young, 2007). Neural approaches (Kim, 2016, Park, 2019) focus on end-to-end training with attention over dialogue context, while pretraining further improves sample efficiency (Zhang et al., 2020; Rastogi et al., 2020). Recent work integrates external knowledge graphs to enhance entity grounding (Chen and Lin, 2021).",
    "reason": "Multiple citations inside parentheses separated by a comma instead of a semicolon; should be \"(Kim, 2016; Park, 2019)\" per author–year style.",
    "start": 254,
    "end": 277,
    "label": "Format"
  },
  {
    "span": "Existing indoor positioning datasets rarely include multi-floor environments.",
    "document": "Related Work\n\nIndoor positioning systems leverage Wi-Fi fingerprints, Bluetooth beacons, inertial sensors, and visual cues to localize users where GPS is unreliable (Haeberlen et al., 2004; Zhang et al., 2019). Public datasets have enabled benchmarking across buildings and sensor modalities, but they vary in scale, coverage, and annotation density (Torres-Sospedra et al., 2014). Existing indoor positioning datasets rarely include multi-floor environments. This limitation restricts research on vertical disambiguation and stair/elevator transitions, which are critical for realistic deployments. We introduce a multi-floor dataset with synchronized inertial and RF measurements and propose a floor-aware particle filter with learned map priors.",
    "reason": "Makes a comparative claim about the composition of existing datasets without providing citations to support the survey.",
    "start": 382,
    "end": 459,
    "label": "Unsupported_claim"
  },
  {
    "span": "Message passing networks have been applied to molecular property prediction (Gilmer et al., 2017; Yang et al., 2019; Hu et al., 2020). Graph isomorphism networks improve expressivity (Xu et al., 2019). Attention-based GNNs weigh neighbor contributions (Velickovic et al., 2018). Pretraining on large molecular corpora has been explored (Hu et al., 2019; Rong et al., 2020).",
    "document": "Related Work\n\nMolecular representation learning has rapidly advanced with graph neural networks (GNNs) that operate on atoms and bonds as nodes and edges. These approaches typically aggregate local neighborhood information to produce graph-level embeddings useful for predicting physicochemical and biological properties.\n\nMessage passing networks have been applied to molecular property prediction (Gilmer et al., 2017; Yang et al., 2019; Hu et al., 2020). Graph isomorphism networks improve expressivity (Xu et al., 2019). Attention-based GNNs weigh neighbor contributions (Velickovic et al., 2018). Pretraining on large molecular corpora has been explored (Hu et al., 2019; Rong et al., 2020).\n\nBeyond architectures, data-centric methods address label scarcity via multi-task learning or property-aware data augmentation, while training strategies such as contrastive objectives aim to improve robustness under distribution shifts. We next detail the components of our approach and empirical setup.",
    "reason": "The span lists prior GNN methods and pretraining techniques without articulating how they relate to the authors' approach, what gap remains, or why a new method is needed.",
    "start": 323,
    "end": 696,
    "label": "Lacks_synthesis"
  },
  {
    "span": "Prior studies have explored rehearsal-based methods (Lopez-Paz and Ranzato, 2017; Chaudhry et al., 2019), regularization schemes (Kirkpatrick et al., 2017; Zenke et al., 2017), and dynamic architectures (Rusu et al., 2016; Yoon et al., 2018) for continual learning in NLP.",
    "document": "Related Work\n\nContinual Learning in NLP\nContinual learning aims to enable models to acquire new tasks without catastrophically forgetting previously learned knowledge. A variety of paradigms have been investigated across vision and language tasks as interest in lifelong systems has grown. Prior studies have explored rehearsal-based methods (Lopez-Paz and Ranzato, 2017; Chaudhry et al., 2019), regularization schemes (Kirkpatrick et al., 2017; Zenke et al., 2017), and dynamic architectures (Rusu et al., 2016; Yoon et al., 2018) for continual learning in NLP. These approaches vary in assumptions about task boundaries, memory budgets, and computational costs.\n\nTask-Order Robustness\nBeyond base algorithms, recent work considers robustness to task order permutations and domain shifts during training, proposing evaluation protocols and metrics that better reflect real-world deployment. However, unified benchmarks for NLP settings remain limited.\n\nPretrained Language Models\nWith the widespread use of large pretrained encoders, methods for parameter-efficient adaptation and modularization have become prominent, raising new questions about where and how knowledge is stored and updated during continual training.",
    "reason": "The sentence lists categories and citations without articulating how they relate to the authors' approach, what limitation they intend to address, or any perspective (criterion a and c).",
    "start": 290,
    "end": 562,
    "label": "Lacks_synthesis"
  },
  {
    "span": "Compared to other tasks, anomaly detection datasets are notoriously small and noisy.",
    "document": "Introduction\n\nTime-series anomaly detection underpins monitoring in finance, manufacturing, and cloud systems. Models must detect rare, heterogeneous events with limited delay while controlling false alarms.\n\nCompared to other tasks, anomaly detection datasets are notoriously small and noisy. This scarcity complicates supervised learning and motivates semi- and self-supervised objectives that exploit structure in normal behavior.\n\nWe introduce a temporal contrastive learner with adaptive memory that improves detection under severe label sparsity and provides calibrated anomaly scores for operations.\n",
    "reason": "The claim generalizes about dataset size and quality across the domain without providing citations to benchmarks or surveys that support it.",
    "start": 209,
    "end": 293,
    "label": "Unsupported_claim"
  },
  {
    "span": "There have been many recent works exploring unsupervised MT for Indic languages.",
    "document": "Introduction\n\nNeural machine translation (NMT) has achieved remarkable progress in high-resource settings due to large parallel corpora and advanced architectures. However, many languages remain under-resourced, particularly in the Indic family, where parallel data is scarce and often noisy. There have been many recent works exploring unsupervised MT for Indic languages. Despite this interest, robust evaluation across diverse domains and scripts is still lacking. In this paper, we present a unified benchmark and a set of strong baselines for low-resource Indic NMT, focusing on script variance, domain shift, and multilingual transfer.\n\nOur contributions are as follows. First, we curate comparable corpora across multiple Indic languages and normalize scripts to reduce orthographic variance. Second, we examine multilingual pretraining strategies and analyze their impact on unseen domains. Third, we provide a comprehensive error taxonomy to facilitate qualitative assessment of translation failures.",
    "reason": "Mentions 'many recent works' without citing any of them (definition d). The first mention of a line of work should be supported by citations (definition a).",
    "start": 293,
    "end": 373,
    "label": "Unsupported_claim"
  },
  {
    "span": "The MovieLens-25M dataset is the de facto benchmark for long-tail recommendation",
    "document": "Related Work\n\nLong-tail recommendation seeks to expose users to under-consumed items without sacrificing relevance. A broad line of work studies debiasing from exposure, reweighting loss functions, and calibrating rankings toward diverse content.\n\nThe MovieLens-25M dataset is the de facto benchmark for long-tail recommendation. Many methods report gains on tail coverage and catalog exposure when trained on implicit feedback with pairwise ranking losses.\n\nBeyond reweighting, recent approaches incorporate propensity estimation and counterfactual evaluation to correct for selection bias. Nevertheless, operationalizing long-tail gains while maintaining user satisfaction remains challenging in production systems.\n",
    "reason": "Introduces a specific dataset and asserts its benchmark status without citation; per rule (a) and (b), first mention of a dataset and domain-specific claims require references.",
    "start": 248,
    "end": 328,
    "label": "Unsupported_claim"
  },
  {
    "span": "It has been shown that sparse-reward robotic manipulation benchmarks are solved reliably with curriculum learning.",
    "document": "Related Work\n\nReinforcement learning (RL) in robotics contends with sparse rewards, safety constraints, and sim-to-real transfer gaps. Techniques such as hindsight experience replay, shaped rewards, and auxiliary objectives have been proposed to alleviate exploration challenges. It has been shown that sparse-reward robotic manipulation benchmarks are solved reliably with curriculum learning. Parallel trends include policy distillation from demonstrations and domain randomization to improve transfer. Yet, comprehensive evaluations across diverse tasks and hardware platforms remain limited.",
    "reason": "Claims a known result ('has been shown') about curriculum learning solving benchmarks without citing supporting studies.",
    "start": 280,
    "end": 394,
    "label": "Unsupported_claim"
  },
  {
    "span": "Recent contrastive recommenders pretrain with augmentations such as node or edge dropout and masking (Wu et al., 2021; Xia et al., 2022; Zhou et al., 2023).",
    "document": "Related Work\n\nContrastive learning has recently improved collaborative filtering by leveraging self-supervision over user-item graphs. Data augmentations and objective design are central to learning robust representations under sparse and noisy feedback.\n\nRecent contrastive recommenders pretrain with augmentations such as node or edge dropout and masking (Wu et al., 2021; Xia et al., 2022; Zhou et al., 2023).\n\nOur approach introduces exposure-aware contrastive signals that disentangle preference from position bias by incorporating logged propensities into the augmentation pipeline. This allows representation learning to focus on preference-consistent invariances.\n\nWe benchmark on four public datasets and a large-scale production dataset, showing gains in NDCG and recall, with improved robustness to popularity shifts.",
    "reason": "The span lists prior methods and citations without analyzing their relation to the paper's goals or identifying a gap, matching (a) and (c).",
    "start": 256,
    "end": 412,
    "label": "Lacks_synthesis"
  },
  {
    "span": "Zhang and Liu",
    "document": "Related Work\n\nVision Transformers (ViTs) have emerged as strong alternatives to convolutional architectures by leveraging self-attention for global context modeling (Dosovitskiy et al., 2021; Touvron et al., 2021). Zhang and Liu propose hierarchical token merging to reduce quadratic attention costs while preserving fine-grained details, complementing pooling-based strategies explored in concurrent work (Wu et al., 2021; Wang et al., 2021).\n\nBeyond architecture design, data-efficient training strategies such as knowledge distillation and strong augmentation have proven crucial for ViT performance at scale (Touvron et al., 2021; Steiner et al., 2022). Our approach integrates curriculum-based token sparsification with distillation to further improve efficiency without sacrificing accuracy.",
    "reason": "Narrative citation missing year: \"Zhang and Liu\" should include the publication year, e.g., \"Zhang and Liu (2022)\".",
    "start": 215,
    "end": 228,
    "label": "Format"
  },
  {
    "span": "Existing benchmarks overwhelmingly focus on English Twitter data.",
    "document": "Introduction\n\nToxic language and hate speech detection have received growing attention due to their social impact and the need for scalable moderation tools. Prior research has explored lexical, syntactic, and contextual cues, as well as user-level and conversation-level signals. Existing benchmarks overwhelmingly focus on English Twitter data. This narrow focus limits the ecological validity of models deployed across platforms and languages, and raises concerns about dataset artifacts and annotation schemas that may not transfer. In response, recent efforts have begun to consider multilingual corpora and long-form content, but consistent evaluation across platforms remains challenging. Our work contributes a cross-platform dataset with harmonized labels and length-normalized sampling.\n",
    "reason": "Asserts a statistical characterization of prior datasets without providing evidence or citations (violates rule b).",
    "start": 281,
    "end": 346,
    "label": "Unsupported_claim"
  },
  {
    "span": "Recent approaches apply spatiotemporal GNNs, attention mechanisms, and diffusion models to urban traffic forecasting (Li et al., 2018; Wu et al., 2019; Cini et al., 2022; Xu et al., 2023).",
    "document": "Related Work\n\nClassical time-series and state-space models. Early traffic forecasting relied on ARIMA variants, vector autoregression, and Kalman filtering to capture temporal trends and short-term dependencies across sensor networks (Newell, 1971; Ahmed and Cook, 1979; Okutani and Stephanedes, 1984). While effective for local stationarity and short horizons, these models often struggle with nonlinear interactions and nonstationary regimes common in urban settings.\n\nNeural sequence models. Deep learning methods introduced recurrent networks and temporal convolutional architectures that substantially improved multi-step prediction through learned feature abstractions and long-range temporal modeling (Ma et al., 2015; Yu et al., 2017; Bai et al., 2018). Hybrid designs incorporate exogenous signals, such as weather and events, to improve robustness under distribution shifts (Zhang et al., 2019; Ke et al., 2017).\n\nGraph-based and generative methods. Recent approaches apply spatiotemporal GNNs, attention mechanisms, and diffusion models to urban traffic forecasting (Li et al., 2018; Wu et al., 2019; Cini et al., 2022; Xu et al., 2023). Prior work explores dynamic adjacency learning, spectral filtering, and multi-hop message passing for capturing topological dependencies in road networks (Guo et al., 2019; Pan et al., 2020).\n\nOur perspective. We focus on medium-horizon forecasting under sparse sensor coverage, seeking methods that remain stable under missing edges and time-varying connectivity. We evaluate on four public benchmarks and two metropolitan datasets with induced sensor outages.",
    "reason": "The sentence lists categories and citations of prior methods without explaining how they relate to the present study, what limitations they have, or why they motivate the proposed approach, thus lacking synthesis.",
    "start": 960,
    "end": 1148,
    "label": "Lacks_synthesis"
  },
  {
    "span": "Rafferty et al., 2018)",
    "document": "Introduction\n\nPretrained sequence-to-sequence models have transformed text generation across summarization, translation, and data-to-text tasks (Lewis et al., 2020; Brown et al., 2020). In controllable generation, attribute conditioning enables style, sentiment, or content manipulation without extensive labeled data (Keskar et al., 2019; Dathathri et al., 2020). Several approaches align latent representations with user-specified control codes while maintaining fluency and factuality. While prior work has considered lexically constrained decoding (Hokamp and Liu, 2017; Post and Vilar, 2018), few methods jointly address semantic control and faithfulness to source inputs. Building on constrained decoding, we integrate span-level constraints with a content planning module to ensure coverage of key facts, improving upon baselines such as pointer-generators and copy-augmented transformers (See et al., 2017; Rafferty et al., 2018). We further introduce a calibration loss to reduce hallucinations in low-resource settings, demonstrating consistent gains on two benchmarks.\n",
    "reason": "Missing opening parenthesis in parenthetical citation; should be '(Rafferty et al., 2018)'.",
    "start": 915,
    "end": 937,
    "label": "Format"
  },
  {
    "span": "Neural Programmer-Interpreter learns to execute latent programs from examples (Reed and de Freitas, 2016). Semantic parsing maps natural language to logical forms over knowledge bases (Liang, 2016). Large language models have demonstrated strong code generation capabilities (Chen et al., 2021). Type systems capture program invariants statically (Pierce, 2002).",
    "document": "Introduction\n\nProgram Synthesis from Natural Language\n\nMapping natural language to executable programs promises to democratize software development and automate routine tasks. Approaches vary from supervised semantic parsing over formal languages to neural sequence models targeting general-purpose programming languages.\n\nBackground and Prior Work\n\nNeural Programmer-Interpreter learns to execute latent programs from examples (Reed and de Freitas, 2016). Semantic parsing maps natural language to logical forms over knowledge bases (Liang, 2016). Large language models have demonstrated strong code generation capabilities (Chen et al., 2021). Type systems capture program invariants statically (Pierce, 2002).\n\nOur Approach\n\nWe introduce a type-guided decoding strategy that enforces syntactic and semantic constraints during generation, coupled with counterexample-guided refinement using lightweight execution feedback.",
    "reason": "The span strings together four areas—latent program induction, semantic parsing, LLM code generation, and type systems—without clarifying how each relates to or informs the others; the transitions are absent, reducing coherence.",
    "start": 350,
    "end": 712,
    "label": "Coherence"
  },
  {
    "span": "(LeCun et al., 1998;",
    "document": "Related Work\n\nConvolutional neural networks (CNNs) have long served as the backbone for visual recognition, starting from early character recognition to modern large-scale image classification. Foundational studies established the efficacy of local receptive fields and weight sharing for translation invariance (LeCun et al., 1989; Yamashita et al., 2018). The deepening of architectures led to dramatic improvements on benchmarks such as ImageNet (Krizhevsky et al., 2012; He et al., 2016). Despite these advances, classic insights from (LeCun et al., 1998; remain relevant, particularly regarding regularization and architectural priors. Our approach integrates these priors with transformer-based vision modules (Dosovitskiy et al., 2021).",
    "reason": "Missing closing parenthesis in the parenthetical citation; the citation ends with a semicolon and lacks ')'.",
    "start": 539,
    "end": 559,
    "label": "Format"
  },
  {
    "span": "Most prior work assumes Gaussian residuals in demand forecasting for retail.",
    "document": "Introduction\n\nAccurate demand forecasting underpins inventory optimization and supply chain planning (Hyndman and Athanasopoulos, 2018). Deep learning methods have achieved strong performance by modeling temporal dependencies and cross-series effects (Salinas et al., 2019; Lim et al., 2021). Retail data frequently exhibits intermittent demand, heavy tails, and promotions, challenging common modeling assumptions.\n\nMost prior work assumes Gaussian residuals in demand forecasting for retail. This mismatch can lead to biased uncertainty estimates and suboptimal safety-stock decisions. We introduce a flexible mixture-of-experts likelihood that adapts to varying dispersion and zero-inflation across items while remaining tractable for large-scale training.\n\nWe evaluate on three multi-category retail datasets and show improved calibration and service levels over Gaussian and negative binomial baselines.",
    "reason": "Claims a common assumption across prior literature without providing citations to support the characterization of prior work.",
    "start": 417,
    "end": 493,
    "label": "Unsupported_claim"
  },
  {
    "span": "Recent datasets for fairness-aware recommendation include large-scale collections with user demographics.",
    "document": "Related Work\n\nFairness in recommender systems has drawn increasing attention, with studies examining exposure disparities, calibration, and long-term user impacts (Ekstrand et al., 2018; Diaz et al., 2020; Burke, 2017). Methodologically, approaches span reweighting, post-processing, and in-processing with constraints on group metrics. Recent datasets for fairness-aware recommendation include large-scale collections with user demographics. While such resources enable group-aware evaluation, privacy and consent considerations necessitate careful governance, and demographic proxies can introduce additional biases. Our work complements these lines by proposing privacy-preserving demographic inference calibrated for fairness metrics.\n\nWe also survey evaluation protocols and identify pitfalls in metric selection under distribution shift.",
    "reason": "It references 'recent datasets' and describes their characteristics without citing any of the datasets.",
    "start": 337,
    "end": 442,
    "label": "Unsupported_claim"
  },
  {
    "span": "according to (Tanaka, 2021)",
    "document": "Introduction\n\nKnowledge graphs (KGs) provide a structured representation of entities and relations that support reasoning and retrieval (Nickel et al., 2016; Hogan et al., 2021). However, real-world KGs are incomplete and noisy, necessitating link prediction and graph completion methods (Bordes et al., 2013; Trouillon et al., 2016). Recent surveys argue that scalability and inductive generalization remain key bottlenecks, according to (Tanaka, 2021), spurring interest in subgraph-based encoders and rule-guided learning (Teru et al., 2020; Ren et al., 2020).",
    "reason": "Wrong narrative use of a parenthetical citation; should be Tanaka (2021) or rephrase to use a parenthetical citation without the narrative cue.",
    "start": 426,
    "end": 453,
    "label": "Format"
  },
  {
    "span": "ARIMA models capture linear dependencies (Box and Jenkins, 1970). Attention improves long-horizon accuracy (Lim et al., 2021). Copula-based methods model joint uncertainty (Salinas et al., 2019). Change-point detection identifies regime shifts (Truong et al., 2020).",
    "document": "Introduction\n\nForecasting time series at scale requires balancing bias-variance trade-offs, handling nonstationarity, and producing calibrated probabilistic outputs. Classical statistical models and modern deep architectures have been combined with hierarchical reconciliation and covariate effects to improve accuracy in practice (Hyndman and Athanasopoulos, 2018; Oreshkin et al., 2019).\n\nARIMA models capture linear dependencies (Box and Jenkins, 1970). Attention improves long-horizon accuracy (Lim et al., 2021). Copula-based methods model joint uncertainty (Salinas et al., 2019). Change-point detection identifies regime shifts (Truong et al., 2020).\n\nWe propose a regime-aware transformer with prior-informed state transitions that jointly forecasts and signals structural breaks.",
    "reason": "The span lists four topics (ARIMA, attention mechanisms, copulas, change-point detection) without transitions or an explicit connective argument, making their relationships unclear.",
    "start": 391,
    "end": 657,
    "label": "Coherence"
  },
  {
    "span": "Continual learning methods include regularization-based approaches like EWC and SI (Kirkpatrick et al., 2017; Zenke et al., 2017), rehearsal via memory replay (Lopez-Paz and Ranzato, 2017; Chaudhry et al., 2019), dynamic architectures (Rusu et al., 2016; Yoon et al., 2018), and distillation-based consolidation (Li and Hoiem, 2016; Rebuffi et al., 2017). Our method builds on parameter-isolation while leveraging token-level sparsity.",
    "document": "Related Work\n\nAs vision transformers are adopted in dynamic environments, preventing catastrophic forgetting becomes crucial for practical deployment. Continual learning offers a toolbox of strategies with different compute and memory trade-offs.\n\nContinual learning methods include regularization-based approaches like EWC and SI (Kirkpatrick et al., 2017; Zenke et al., 2017), rehearsal via memory replay (Lopez-Paz and Ranzato, 2017; Chaudhry et al., 2019), dynamic architectures (Rusu et al., 2016; Yoon et al., 2018), and distillation-based consolidation (Li and Hoiem, 2016; Rebuffi et al., 2017). Our method builds on parameter-isolation while leveraging token-level sparsity.\n\nWe later compare against these baselines under compute budgets typical of on-device continual adaptation and report accuracy-stability trade-offs.\n",
    "reason": "Violates (b): after summarizing prior categories, it announces the proposed direction without clarifying the specific deficiency or gap in existing approaches that motivates the new method.",
    "start": 248,
    "end": 683,
    "label": "Lacks_synthesis"
  },
  {
    "span": "In (Doe et al., 2018)",
    "document": "Introduction\n\nTask-oriented dialog systems benefit from pretrained encoders and copy mechanisms (See et al., 2017; Devlin et al., 2019). In (Doe et al., 2018), the authors propose a hierarchical policy that coordinates intent detection with slot filling, and subsequent work extends this idea with reinforcement learning (Williams and Zweig, 2016) and uncertainty modeling (Sun et al., 2020). Despite these advances, robustness to out-of-domain inputs remains limited (Hendrycks et al., 2020).",
    "reason": "Wrong citation style with a preposition before a parenthetical; should be narrative: “Doe et al. (2018)”.",
    "start": 137,
    "end": 158,
    "label": "Format"
  },
  {
    "span": "Transformer-based forecasters model long-range dependencies through self-attention, seasonal-trend decomposition, and sparse or linear attention mechanisms (Zhou et al., 2021; Wu et al., 2021; Zeng et al., 2023; Choromanski et al., 2021; Katharopoulos et al., 2020). Benchmarks on electricity, traffic, and exchange datasets accompany these architectures (Lai et al., 2018; Zhou et al., 2021; Wu et al., 2021).",
    "document": "Introduction\n\nForecasting multivariate time series at scale requires models that capture long horizons while remaining data-efficient. Despite progress with attention-based architectures, practitioners face instability, inconsistent metrics, and heavy compute footprints. We revisit design choices to reconcile accuracy with simplicity.\n\nTransformer-based forecasters model long-range dependencies through self-attention, seasonal-trend decomposition, and sparse or linear attention mechanisms (Zhou et al., 2021; Wu et al., 2021; Zeng et al., 2023; Choromanski et al., 2021; Katharopoulos et al., 2020). Benchmarks on electricity, traffic, and exchange datasets accompany these architectures (Lai et al., 2018; Zhou et al., 2021; Wu et al., 2021).\n\nWe propose a residual linear state space forecaster that requires no decomposition or specialized attention kernels and achieves competitive performance with an order-of-magnitude lower training cost.",
    "reason": "The span enumerates prior transformer-based methods and datasets without explaining the gap (e.g., instability, compute) or how those works compare to the proposed simpler alternative (criteria a and b).",
    "start": 338,
    "end": 748,
    "label": "Lacks_synthesis"
  },
  {
    "span": "Shelmanov et al., 2021)",
    "document": "Related Work\n\nSeveral works question whether active learning helps when modern pretrained encoders are used. As noted in Shelmanov et al., 2021) the performance of successors can degrade due to acquisition-shift mismatch. Follow-up studies propose training proxies and transferring selectors (Ein-Dor et al., 2020; Lowell et al., 2019). We revisit these concerns and introduce a compute-aware protocol.",
    "reason": "Unmatched closing parenthesis and wrong narrative style; should be 'Shelmanov et al. (2021)'.",
    "start": 121,
    "end": 144,
    "label": "Format"
  },
  {
    "span": "Smith & Jones (2017)",
    "document": "Introduction\n\nEducational data mining seeks to model learning processes and predict outcomes (Baker and Yacef, 2009). Early work focused on logistic models (Beck and Woolf, 2000), while recent approaches leverage deep sequence models (Piech et al., 2015; Pandey and Karypis, 2019). As Smith & Jones (2017) demonstrate, incorporating cognitive features improves interpretability, and mixed-effect models capture student heterogeneity (Vieira et al., 2018). We propose a hierarchical model that unifies knowledge tracing with concept drift (Gonzalez et al., 2020).",
    "reason": "Ampersand used in a narrative citation; narrative form should use 'and': 'Smith and Jones (2017)'.",
    "start": 285,
    "end": 305,
    "label": "Format"
  },
  {
    "span": "Data augmentation for low-resource machine translation includes back-translation, noising schemes, and synthetic parallel generation via multilingual models (Senn rich et al., 2016; Edunov et al., 2018; Ng et al., 2019; Gu et al., 2020; Xia et al., 2021).",
    "document": "Related Work\n\nLow-resource neural machine translation suffers from overfitting and poor coverage of rare constructions. Augmentation strategies attempt to increase effective training signal.\n\nData augmentation for low-resource machine translation includes back-translation, noising schemes, and synthetic parallel generation via multilingual models (Senn rich et al., 2016; Edunov et al., 2018; Ng et al., 2019; Gu et al., 2020; Xia et al., 2021).\n\nWhile augmentation improves learning, distribution mismatches between synthetic and real text can degrade performance. Our approach targets quality-controlled augmentation guided by uncertainty estimates.",
    "reason": "The sentence enumerates techniques and citations without explaining their limitations relative to the paper’s approach or articulating a gap (criteria a and b).",
    "start": 192,
    "end": 447,
    "label": "Lacks_synthesis"
  },
  {
    "span": "Robot motion planning has diversified. Sampling-based planners explore configuration spaces efficiently (LaValle, 1998). Trajectory optimization refines smooth paths with constraints (Schulman et al., 2014). Learning-based planners approximate cost-to-go from data (Value Iteration Networks; Tamar et al., 2016). Sim-to-real transfer reduces reliance on labeled trajectories (Peng et al., 2018). Safety constraints limit risk near obstacles (Fisac et al., 2018).",
    "document": "Related Work\n\nAutonomous navigation requires generating feasible, safe motions under dynamics and environmental uncertainty. Classical planning emphasizes geometric and kinodynamic feasibility, while recent methods leverage data to accelerate search and improve generalization. Safety and robustness are cross-cutting concerns across these strands.\n\nRobot motion planning has diversified. Sampling-based planners explore configuration spaces efficiently (LaValle, 1998). Trajectory optimization refines smooth paths with constraints (Schulman et al., 2014). Learning-based planners approximate cost-to-go from data (Value Iteration Networks; Tamar et al., 2016). Sim-to-real transfer reduces reliance on labeled trajectories (Peng et al., 2018). Safety constraints limit risk near obstacles (Fisac et al., 2018).\n\nWe present a planner that couples sampling with learned risk estimates and provides probabilistic safety guarantees.",
    "reason": "The span strings together various planning paradigms and topics without transitions or clarifying how each relates to the preceding one, leaving the relationships implied and reducing coherence.",
    "start": 350,
    "end": 812,
    "label": "Coherence"
  },
  {
    "span": "Early works approached traffic prediction with spatiotemporal graphs and attention mechanisms, leveraging diffusion convolution, dynamic adjacency learning, and temporal gating (Li et al., 2018; Yu et al., 2018; Wu et al., 2019; Pan et al., 2021). More recent methods incorporate transformers, adaptive graph construction, and multi-resolution temporal modules to capture long-range dependencies (Cui et al., 2020; Xu et al., 2020; Guo et al., 2021).",
    "document": "Introduction\n\nAccurate traffic forecasting is a cornerstone for intelligent transportation systems, enabling congestion mitigation, route planning, and safety-critical control. Urban road networks exhibit complex spatiotemporal dynamics driven by human mobility, weather, and infrastructure constraints, making forecasting a challenging problem.\n\nEarly works approached traffic prediction with spatiotemporal graphs and attention mechanisms, leveraging diffusion convolution, dynamic adjacency learning, and temporal gating (Li et al., 2018; Yu et al., 2018; Wu et al., 2019; Pan et al., 2021). More recent methods incorporate transformers, adaptive graph construction, and multi-resolution temporal modules to capture long-range dependencies (Cui et al., 2020; Xu et al., 2020; Guo et al., 2021).\n\nIn this paper, we present a unified framework that models traffic as a latent controlled dynamical system with learnable operators over graph-structured states. Our approach integrates physics-inspired constraints with sequence modeling to produce stable and interpretable forecasts across horizons.",
    "reason": "The span enumerates prior methods and datasets without stating how they relate to the current work, what gap remains, or the authors' perspective; it summarizes literature without synthesis.",
    "start": 347,
    "end": 797,
    "label": "Lacks_synthesis"
  },
  {
    "span": "Contrastive learning has been adapted to collaborative filtering by maximizing agreement between augmented user–item interaction views (He et al., 2020; Xin et al., 2020; Yu et al., 2021).",
    "document": "Introduction\n\nRecommender systems must learn from sparse and noisy interaction data while resisting popularity bias and distribution shift. Self-supervised learning offers a way to exploit abundant unlabeled structure beyond explicit feedback signals.\n\nContrastive learning has been adapted to collaborative filtering by maximizing agreement between augmented user–item interaction views (He et al., 2020; Xin et al., 2020; Yu et al., 2021). Graph-based recommenders leverage message passing over bipartite graphs to capture high-order connectivity, while regularizers mitigate over-smoothing in deep stacks (Wang et al., 2019; He et al., 2020b). Negative sampling strategies, temperature tuning, and augmentation design have been shown to strongly influence performance (Chen et al., 2020; Tian et al., 2020).\n\nBeyond contrastive objectives, generative self-supervision and masked modeling aim to reconstruct withheld interactions or attributes, complementing pairwise ranking losses (Sun et al., 2019; Zhou et al., 2020). Domain adaptation and debiasing techniques attempt to improve fairness and robustness in long-tail recommendation (Zhu et al., 2020; Ge et al., 2020).\n\nThese threads highlight the promise of self-supervision for improving collaborative filtering under practical constraints.",
    "reason": "The span lists a trend and citations without explaining its relevance to the authors’ method, failing to articulate a clear gap or the paper’s perspective on these techniques.",
    "start": 253,
    "end": 441,
    "label": "Lacks_synthesis"
  },
  {
    "span": "(Ahmed et al. 2021)",
    "document": "Introduction\n\nTopic models provide interpretable structure for document collections by uncovering latent themes (Blei et al., 2003; Griffiths and Steyvers, 2004). Supervised variants incorporate labels to guide topic discovery for prediction tasks (Mcauliffe and Blei, 2008; Ramage et al., 2009). Neural topic models leverage amortized inference to scale to large corpora while maintaining coherence (Miao et al., 2017; Srivastava and Sutton, 2017).\n\nRecent advances integrate pretrained language models to improve lexical semantics and coherence (Zhao et al., 2021; Hoyle et al., 2021). However, disentangling syntax from semantics remains challenging, leading to entangled topics and syntactic drift (Card et al., 2018). We build on contextualized priors proposed in (Ahmed et al. 2021) and introduce a sparsity-inducing regularizer that enhances stability across domains.\n",
    "reason": "Missing comma between author and year in parenthetical citation; should be \"(Ahmed et al., 2021)\".",
    "start": 769,
    "end": 788,
    "label": "Format"
  },
  {
    "span": "[Smith et al., 2021)",
    "document": "Introduction\n\nGraph neural networks (GNNs) have advanced node classification and link prediction by exploiting message passing over relational structures (Kipf and Welling, 2017; Hamilton et al., 2017). Despite this success, over-smoothing and oversquashing remain central challenges, spurring architectural modifications and regularization techniques [Smith et al., 2021). Our work addresses these issues via controllable receptive fields and curvature-aware propagation.\n\nWe evaluate on benchmarks spanning citation networks and heterogeneous graphs, comparing to residual and jumping-knowledge baselines (Xu et al., 2018; Li et al., 2019).",
    "reason": "Mismatched brackets in the citation: it opens with '[' and closes with ')', which is a formatting error.",
    "start": 352,
    "end": 372,
    "label": "Format"
  },
  {
    "span": "Previous studies report that spatial attention consistently outperforms temporal attention.",
    "document": "Related Work\n\nData-driven traffic forecasting has progressed from classical statistical models to deep spatio-temporal networks. Graph-based approaches capture road network topology and temporal dynamics, including diffusion convolutional recurrent networks (Li et al., 2018), spatio-temporal graph convolutions (Yu et al., 2018), and graph-based dilated temporal models (Wu et al., 2019). Attention mechanisms have been incorporated to adaptively weight nodes or time steps for improved forecasting robustness.\n\nPrevious studies report that spatial attention consistently outperforms temporal attention. While hybrid designs that jointly learn spatial and temporal weights are promising, they often incur substantial computational overhead and may overfit on sparse sensor networks. Our work introduces a parameter-efficient decoupled attention module that addresses these shortcomings.",
    "reason": "Claims a consensus finding about comparative performance in prior studies without citing any studies; such comparative claims require evidence.",
    "start": 513,
    "end": 604,
    "label": "Unsupported_claim"
  },
  {
    "span": "Gulwani (2011) surveyed inductive program synthesis by example. Papadimitriou (1994) discussed complexity classes relevant to combinatorial search. Nye et al. (2021) demonstrated few-shot program synthesis with large language models.",
    "document": "Related Work\n\nProgram synthesis research spans deductive, inductive, and neural methods, often trading off search efficiency and generalization. Recent advances leverage pretrained language models while classic approaches rely on symbolic search.\n\nGulwani (2011) surveyed inductive program synthesis by example. Papadimitriou (1994) discussed complexity classes relevant to combinatorial search. Nye et al. (2021) demonstrated few-shot program synthesis with large language models. Neural-guided search combines learned proposals with symbolic executors (Balog et al., 2017; Ellis et al., 2018).\n\nBenchmarks such as DeepCoder, Karel, and GSM8K evaluate increasingly realistic tasks and compositional generalization (Zaremba and Sutskever, 2014; Austin et al., 2021).",
    "reason": "The span inserts a theoretical complexity reference between two synthesis-focused works without explaining the connection, leaving the relationship implied rather than explicit.",
    "start": 248,
    "end": 481,
    "label": "Coherence"
  },
  {
    "span": "(Nguyen et al., 2015]",
    "document": "Introduction\n\nNeural retrieval has rapidly advanced from sparse term matching to dense representations (Robertson and Walker, 1994; Karpukhin et al., 2020; Xiong et al., 2021). Training objectives typically rely on in-batch negatives or mined hard negatives that shape the embedding space. For open-domain QA, the design of negatives has a strong effect on generalization (Nguyen et al., 2015]. We focus on scalable negative mining that preserves diversity without sacrificing relevance.",
    "reason": "Mismatched brackets: the citation opens with a parenthesis but closes with a square bracket.",
    "start": 372,
    "end": 393,
    "label": "Format"
  },
  {
    "span": "(Miller et al., 2021; Ortega, 2020.",
    "document": "Related Work\n\nGraph neural networks (GNNs) have achieved state-of-the-art results on node classification and link prediction by propagating neighborhood information via learned message passing (Chandra and Li, 2019; Kumar et al., 2021). Despite progress, challenges remain, including over-smoothing at depth and sensitivity to topology noise (Wei and Park, 2020). Recent surveys discuss theoretical limits of expressivity and training stability (Miller et al., 2021; Ortega, 2020.\n\nMitigation strategies include residual connections and normalization schemes tailored to graphs (Rossi and Patel, 2020), as well as data-centric techniques such as subgraph sampling and augmentation (Hsu and Tang, 2022). Our work explores curriculum-based neighborhood expansion, which balances receptive field growth against feature dilution to improve performance on large, sparse graphs (Zhou and Ahmed, 2022).",
    "reason": "Missing closing parenthesis in a parenthetical multi-citation.",
    "start": 445,
    "end": 480,
    "label": "Format"
  },
  {
    "span": "Settles (2009) surveyed pool-based active learning methods. Ash et al. (2019) propose BADGE to diversify uncertain selections. Crowdsourcing frameworks address label aggregation noise (Dawid and Skene, 1979). Kulesza et al. (2015) study explanatory interactive machine learning.",
    "document": "Related Work\n\nActive learning and human-in-the-loop annotation aim to reduce labeling costs by querying informative examples. We discuss selection strategies and interfaces for effective collaboration between models and annotators.\n\nSettles (2009) surveyed pool-based active learning methods. Ash et al. (2019) propose BADGE to diversify uncertain selections. Crowdsourcing frameworks address label aggregation noise (Dawid and Skene, 1979). Kulesza et al. (2015) study explanatory interactive machine learning.\n\nOur work builds on these strands by combining batch-mode active learning with cost-aware acquisition and calibration-driven human guidance.",
    "reason": "Multiple sentences list disparate topics (query strategies, aggregation, explanations) without transitions or explanation of how they relate; the connection among the cited works is abrupt and implicit.",
    "start": 233,
    "end": 511,
    "label": "Coherence"
  },
  {
    "span": "The widely used PubMedQA dataset contains 1,000 annotated abstracts.",
    "document": "Related Work\n\nBiomedical question answering (BioQA) requires domain-specific reasoning and robust handling of technical terminology. Progress in this area has benefited from pretrained biomedical encoders and curated QA datasets that target literature-based inference and clinical decision support.\n\nThe widely used PubMedQA dataset contains 1,000 annotated abstracts.\n\nOther datasets vary in format and difficulty, with some focusing on yes/no questions and others requiring multi-sentence evidence aggregation. Methods range from extractive approaches to generative models that synthesize answers from retrieved passages.",
    "reason": "Claims a specific dataset and its statistics without providing a citation at first mention and for the numeric detail (rule a and b).",
    "start": 300,
    "end": 368,
    "label": "Unsupported_claim"
  },
  {
    "span": "Cross-lingual semantic parsing has been approached with multilingual encoders, annotation projection, and machine translation to create silver data (Jie and Lu, 2014; Susanto and Lu, 2017; Ponti et al., 2019; Artetxe and Schwenk, 2019). Prompting and adapters have been explored for transferring structures across languages (Winata et al., 2021; Pfeiffer et al., 2020).",
    "document": "Related Work\n\nSemantic parsing maps text to meaning representations that support downstream reasoning. Cross-lingual transfer aims to extend parsers to low-resource languages without extensive annotation.\n\nCross-lingual semantic parsing has been approached with multilingual encoders, annotation projection, and machine translation to create silver data (Jie and Lu, 2014; Susanto and Lu, 2017; Ponti et al., 2019; Artetxe and Schwenk, 2019). Prompting and adapters have been explored for transferring structures across languages (Winata et al., 2021; Pfeiffer et al., 2020).\n\nNevertheless, compositional generalization often degrades under zero-shot transfer, particularly when target languages diverge morphologically. Prior methods seldom disentangle syntax from semantics in a way that supports robust transfer.\n\nWe propose a syntax-invariant intermediate representation trained with cross-lingual contrastive objectives, improving zero-shot compositional generalization on diverse target languages.",
    "reason": "The span lists prior approaches and citations but fails to connect them to the authors’ perspective or highlight a specific gap at that point.",
    "start": 206,
    "end": 575,
    "label": "Lacks_synthesis"
  },
  {
    "span": "(Kaur et al., 2021)",
    "document": "Introduction\n\nEdge computing reduces latency by moving computation closer to data sources. In (Kaur et al., 2021) we benchmarked federated schedulers across heterogeneous devices, showing significant gains over centralized baselines. Complementary work explores adaptive offloading and resource-aware compression to minimize communication overhead (Zhang and Wu, 2020; Perez et al., 2022). Security concerns remain a major barrier, particularly in multi-tenant deployments with shared accelerators (Lin and Cho, 2019).\n\nWe propose a topology-aware scheduler that jointly optimizes placement and batching under strict latency SLOs. Our approach blends reinforcement learning with constraint solving to provide predictable performance in dynamic edge clusters.",
    "reason": "Wrong citation style: the preposition 'In' precedes a parenthetical citation; should be narrative style, e.g., “In Kaur et al. (2021)”.",
    "start": 94,
    "end": 113,
    "label": "Format"
  },
  {
    "span": "Most commercial task-oriented dialog systems still rely on rule-based state trackers.",
    "document": "Introduction\n\nDialog state tracking has evolved from rule-based pipelines to neural architectures that jointly model belief states and system acts (Henderson et al., 2014; Zhong et al., 2018). End-to-end training and pretrained encoders have further improved scalability (Wu et al., 2019; Lee et al., 2019). Most commercial task-oriented dialog systems still rely on rule-based state trackers. This gap between research prototypes and deployed systems motivates methods that are interpretable, robust to schema drift, and easy to maintain. We propose a constrained neural tracker with symbolic fallbacks that supports safe deployment while retaining strong accuracy.",
    "reason": "This is a field-wide claim about current practice in industry without any supporting evidence or citations.",
    "start": 308,
    "end": 393,
    "label": "Unsupported_claim"
  },
  {
    "span": "Many studies have leveraged knowledge graphs to enhance top-N recommendation without sacrificing scalability.",
    "document": "Related Work\n\nRecommendation models have increasingly incorporated auxiliary structures to capture higher-order interactions beyond user–item pairs. Many studies have leveraged knowledge graphs to enhance top-N recommendation without sacrificing scalability. Graph neural networks and embedding propagation have been particularly influential, enabling the model to diffuse signals across multi-hop relations.\n\nNevertheless, these graph-based approaches often incur heavy memory footprints and suffer from noisy relation types in large heterogeneous graphs. Recent advances in sampling strategies and relation pruning attempt to mitigate these issues by focusing computation on salient neighborhoods.\n\nOur work follows the line of incorporating structured knowledge but emphasizes sparsity-inducing objectives to reduce noise while maintaining predictive performance. We also explore an adaptive neighborhood selection mechanism to strike a balance between coverage and efficiency.",
    "reason": "Claims prior work ('many studies') and a specific outcome for top-N recommendation but cites no sources.",
    "start": 149,
    "end": 258,
    "label": "Unsupported_claim"
  },
  {
    "span": "FGSM introduces single-step gradient-based attacks (Goodfellow et al., 2015). PGD provides a strong multi-step adversary within an L∞ ball (Madry et al., 2018). TRADES balances robustness and accuracy via a surrogate loss (Zhang et al., 2019). Certified defenses bound worst-case risk using randomized smoothing (Cohen et al., 2019). Data augmentation increases diversity for robustness (Hendrycks et al., 2020).",
    "document": "Related Work\n\nAdversarial Robustness in Deep Learning\n\nBuilding models resilient to adversarial perturbations has been a major focus in vision and NLP. Approaches span from adversarial training and input transformations to certified guarantees, each offering different robustness-accuracy tradeoffs and computational costs.\n\nFGSM introduces single-step gradient-based attacks (Goodfellow et al., 2015). PGD provides a strong multi-step adversary within an L∞ ball (Madry et al., 2018). TRADES balances robustness and accuracy via a surrogate loss (Zhang et al., 2019). Certified defenses bound worst-case risk using randomized smoothing (Cohen et al., 2019). Data augmentation increases diversity for robustness (Hendrycks et al., 2020).\n\nRobust Pretraining and Transfer\n\nRecent efforts investigate robust pretraining, showing that contrastive objectives and large-scale data can improve out-of-distribution performance (Xie et al., 2020). Others explore curriculum adversarial training (Cai et al., 2018) and robust fine-tuning protocols to maintain transfer efficacy (Salman et al., 2020).\n\nOur Perspective\n\nWe unify adversarial training with distributional augmentation via a bilevel scheduler that adapts perturbation strength and sample difficulty, achieving robustness with lower compute budgets.",
    "reason": "The span lists disparate methods and claims in consecutive sentences without transitions or explicit explanation of how they relate to one another, producing abrupt, unconnected statements.",
    "start": 325,
    "end": 737,
    "label": "Coherence"
  },
  {
    "span": "Chen et al.",
    "document": "Introduction\n\nNeural machine translation (NMT) has advanced substantially with encoder–decoder architectures and attention mechanisms (Bahdanau et al., 2015; Vaswani et al., 2017). Chen et al. introduce curriculum strategies that reorder sentence pairs by difficulty to stabilize training, which complements adaptive optimizers used in large-scale setups (Sato and Iwata, 2019). Despite these advances, domain shift remains a key challenge, motivating techniques such as domain-adaptive pretraining and instance reweighting (Gururangan et al., 2020; Wang and Neubig, 2021).",
    "reason": "Narrative citation missing year. It should appear as \"Chen et al. (YEAR)\" in narrative form.",
    "start": 181,
    "end": 192,
    "label": "Format"
  },
  {
    "span": "Kim et al., (2018)",
    "document": "Introduction\n\nSequence-to-sequence models with attention have driven progress in neural machine translation (Bahdanau et al., 2015; Luong et al., 2015). Following Kim et al., (2018) we adopt a convolutional encoder to reduce inference latency, while leveraging subword units for open-vocabulary translation (Sennrich et al., 2016). Transformer architectures further improved performance via multi-head self-attention (Vaswani et al., 2017; Ott et al., 2018). We evaluate across high- and low-resource settings (Aharoni et al., 2019) and consider domain adaptation via fine-tuning (Gururangan et al., 2020).",
    "reason": "Incorrect punctuation in narrative citation: comma before the year parentheses. It should be 'Kim et al. (2018)' without the comma.",
    "start": 163,
    "end": 181,
    "label": "Format"
  },
  {
    "span": "(Brown et al. 2022)",
    "document": "Introduction\n\nSelf-supervised learning in computer vision has advanced via contrastive objectives (He et al., 2020; Chen et al., 2020) and non-contrastive methods (Grill et al., 2020). For dense prediction, pixel-level pretext tasks and masked autoencoding have shown promise. Recent work (Brown et al. 2022) investigates multi-task pretraining for detection and segmentation with a unified backbone, reporting significant gains in low-data regimes. Nevertheless, transfer under severe class imbalance remains an open challenge.\n",
    "reason": "Missing comma after 'et al.' before the year; should be '(Brown et al., 2022)'.",
    "start": 289,
    "end": 308,
    "label": "Format"
  },
  {
    "span": "Lee et al., 2021)",
    "document": "Related Work\n\nGraph neural networks (GNNs) have become a dominant framework for learning over relational data (Kipf and Welling, 2017; Hamilton et al., 2017). Despite their success, GNNs suffer from oversmoothing when stacking many layers (Li et al., 2018; Oono and Suzuki, 2020), and from oversquashing when long-range dependencies are compressed into fixed-size messages (Alon and Yahav, 2021).\n\nRecent works introduce positional encodings and global attention to alleviate these limitations (Dwivedi et al., 2021; Ying et al., 2021). Others propose subgraph-based training to improve expressivity and efficiency (Zhang and Li, 2022). A complementary line studies spectral regularization to maintain discriminative node features across layers Lee et al., 2021) while preserving stability under perturbations (Rusch et al., 2021).\n\nOur method unifies subgraph sampling with learned positional features and a stability-inducing penalty, achieving competitive performance on benchmarks with long-range interactions (Pei et al., 2020).",
    "reason": "Missing opening parenthesis for a parenthetical citation; should be '(Lee et al., 2021)'.",
    "start": 745,
    "end": 762,
    "label": "Format"
  },
  {
    "span": "(Perez et al., 2016 Wang et al., 2018)",
    "document": "Related Work\n\nData augmentation for semantic parsing ranges from rule-based templates to neural paraphrasing. Template-driven methods improve coverage with minimal supervision (Perez et al., 2016 Wang et al., 2018), whereas generative paraphrasers expand linguistic diversity (Ahmed and Long, 2020). Recent approaches synthesize programs directly from schemas (Rao and Mehta, 2021) and filter candidates using execution results (Tran et al., 2022). Our method integrates execution-guided filtering with paraphrase diversity control.",
    "reason": "Multiple citations in one parenthesis are missing a separator; should separate entries with a semicolon, e.g., \"(Perez et al., 2016; Wang et al., 2018)\".",
    "start": 176,
    "end": 214,
    "label": "Format"
  },
  {
    "span": "Projected gradient descent remains a strong first-order baseline (Madry et al., 2018). Mixup improves generalization by interpolating samples (Zhang et al., 2018). Temperature scaling calibrates probabilities on held-out sets (Guo et al., 2017).",
    "document": "Related Work\n\nAdversarial robustness in computer vision explores training and evaluation methods that withstand worst-case perturbations. Robust optimization and certified defenses have been proposed to provide guarantees under norm-bounded attacks, while data augmentation and regularization aim to reduce sensitivity to small input changes.\n\nProjected gradient descent remains a strong first-order baseline (Madry et al., 2018). Mixup improves generalization by interpolating samples (Zhang et al., 2018). Temperature scaling calibrates probabilities on held-out sets (Guo et al., 2017). Subsequent studies combined adversarial training with semi-supervised learning to leverage unlabeled data (Carmon et al., 2019), and explored frequency-domain defenses that attenuate high-frequency vulnerabilities (Yin et al., 2019).\n\nWe focus on decoupling robustness and calibration by introducing a training scheme that explicitly trades off adversarial accuracy and probability calibration, enabling reliable confidence estimates under attack.",
    "reason": "The three consecutive sentences list disparate topics (attack baseline, data augmentation, calibration) without transitions or an explicit relationship between them, making the connection between cited works unclear.",
    "start": 344,
    "end": 589,
    "label": "Coherence"
  },
  {
    "span": "Patel et al.",
    "document": "Introduction\n\nFederated learning (FL) aims to train models collaboratively without centralizing sensitive data, thereby improving privacy and compliance while maintaining utility (Alvarez et al., 2020; Mota and Singh, 2019). Communication-efficient aggregation and robustness to device heterogeneity are central challenges for practical FL systems (Rao and Meier, 2021). As shown by Patel et al., robust client sampling can mitigate stragglers and reduce bias in the global model. However, sampling alone cannot address non-iid data distributions that characterize many real-world deployments (Bose and Kramer, 2020).\n\nOur work complements compression-based protocols (Ibrahim and Zhao, 2022) by introducing an adaptive scheduler that dynamically re-weights updates based on uncertainty. Unlike prior approaches focusing solely on communication reduction (Costa et al., 2021), we target the interplay between client reliability and data drift. We evaluate our method under realistic device churn and shifting label marginals, showing consistent gains across vision and language benchmarks (Kim and Duarte, 2022).",
    "reason": "Narrative citation missing year; should be formatted as 'Patel et al. (YEAR)'.",
    "start": 383,
    "end": 395,
    "label": "Format"
  },
  {
    "span": "There are many recent works that explore this topic.",
    "document": "Introduction\n\nNamed entity recognition (NER) in the clinical domain is challenging due to distribution shifts across institutions, annotation schemes, and specialties. Prior work has explored semi-supervised learning and domain adaptation for general NER (Lample et al., 2016; Peters et al., 2018; Akbik et al., 2019) and for biomedical text (Habibi et al., 2017; Li et al., 2020). Unsupervised domain adaptation with consistency training and pseudo-labeling has shown promise in NLP tasks (Xie et al., 2019; Sohn et al., 2020).\n\nThere are many recent works that explore this topic. However, the privacy constraints and limited labeled data in clinical narratives demand methods that minimize annotation while maintaining high precision. In this paper, we propose a method that combines self-training with domain-adaptive pretraining to improve clinical NER under label scarcity.\n\nWe evaluate across multiple hospital systems and note strong gains in recall without compromising precision. We further analyze robustness to annotation shifts and present ablations on pseudo-label thresholds.",
    "reason": "This sentence refers to unspecified recent works without providing citations (rule d).",
    "start": 530,
    "end": 582,
    "label": "Unsupported_claim"
  },
  {
    "span": "Li & Sun (2019)",
    "document": "Related Work\n\nOpen-domain question answering (QA) combines retrieval with machine reading to find answers in large corpora (Chen et al., 2017; Karpukhin et al., 2020). Li & Sun (2019) introduced a dense retriever with supervised contrastive training, while later methods refine negatives using cross-encoders and iterative re-ranking (Qu et al., 2021; Xiong et al., 2021).\n\nOur approach unifies retrieval and reading under a multi-task objective that encourages shared evidence aggregation across hops.\n",
    "reason": "Incorrect conjunction in narrative citation; narrative form should use 'and' instead of '&' (i.e., 'Li and Sun (2019)').",
    "start": 168,
    "end": 183,
    "label": "Format"
  },
  {
    "span": "(Chen et al., 2021;,",
    "document": "Related Work\n\nScene graph generation aims to detect objects and predict pairwise relations to form a structured graph representation. Early methods relied on message passing with visual features (Xu et al., 2017) and later incorporated linguistic priors (Zellers et al., 2018). Transformer-based pipelines improve long-range dependencies (Herzig et al., 2020), yet rare relation prediction remains difficult. Recent calibration approaches rescore tail predicates using debiased training (Tang and Wang, 2021; Liu et al., 2022). We follow the contrastive paradigm (Chen et al., 2021;, aligning entity embeddings with relation prototypes to mitigate frequency imbalance.",
    "reason": "Malformed parenthetical citation with an extra semicolon and comma; should be (Chen et al., 2021).",
    "start": 563,
    "end": 583,
    "label": "Format"
  },
  {
    "span": "Earlier studies consistently report that inter-annotator agreement on preference labels rarely exceeds 0.5 Cohen's kappa.",
    "document": "Introduction\n\nReinforcement learning from human feedback (RLHF) aligns model behavior with human preferences by training a reward model on pairwise comparisons and optimizing policies to maximize learned rewards. Despite its practical success, the reliability of preference annotations remains a critical bottleneck.\n\nEarlier studies consistently report that inter-annotator agreement on preference labels rarely exceeds 0.5 Cohen's kappa. Low agreement can stem from ambiguous prompts, annotator expertise, or instruction drift, which in turn affects reward model calibration and downstream policy stability.\n\nWe analyze annotation protocols and propose a quality-controlled labeling pipeline with dynamic consensus thresholds to improve agreement and reduce reward hacking.",
    "reason": "Makes a quantitative claim about prior studies and statistics without citing any sources (rule b).",
    "start": 318,
    "end": 439,
    "label": "Unsupported_claim"
  },
  {
    "span": "Doe 2015",
    "document": "Introduction\n\nProgram synthesis methods vary from enumerative search to neural-guided constraint solving. Early enumerative techniques guarantee completeness but scale poorly with combinatorial explosion. Neural methods bias the search toward likely programs conditioned on input–output examples, improving efficiency in practice. Prior approaches relied on frequency-based grammars; see Doe 2015; (Roe et al., 2016) for contrasting views on bias and variance in neural-guided search. More recent pipelines integrate differentiable interpreters with symbolic pruning to combine generalization with verifiability (Devlin et al., 2017; Ellis et al., 2018).",
    "reason": "Inconsistent citation style within a coordinated list: “Doe 2015” lacks parentheses and the comma before the year. It should be “(Doe, 2015)” or narrative “Doe (2015)”, consistent with “(Roe et al., 2016)”.",
    "start": 388,
    "end": 396,
    "label": "Format"
  },
  {
    "span": "In (Klein et al., 2018)",
    "document": "Introduction\n\nNeural machine translation (NMT) has benefited from standardized toolkits and benchmarks that enable reproducible research (Ott et al., 2019; Tiedemann, 2020). In (Klein et al., 2018) we adopt a strong transformer baseline to measure the effect of lexical constraints and noise-robust training. Although large-scale pretraining narrows the gap between domains, constrained decoding remains crucial for terminology control (Hokamp and Liu, 2017; Post and Vilar, 2018). We further analyze domain drift when constraints are sparse and propose calibration strategies for practical deployment.",
    "reason": "Wrong citation style after a preposition; should be “In Klein et al. (2018) we …” rather than a parenthetical citation.",
    "start": 174,
    "end": 197,
    "label": "Format"
  },
  {
    "span": "Several datasets have been proposed to benchmark safety in open-domain chatbots.",
    "document": "Related Work\n\nSafety in open-domain dialogue includes toxicity avoidance, hallucination control, and prevention of harmful advice. Evaluation is challenging due to the open-ended nature of prompts and the contextual dependence of safety norms.\n\nSeveral datasets have been proposed to benchmark safety in open-domain chatbots. Methods range from supervised fine-tuning on safety-annotated prompts to reinforcement learning with human feedback and rule-based filtering.\n\nWe situate our approach within this landscape by introducing a scenario-driven evaluation protocol that captures multi-turn risk escalation, complemented by human adjudication.",
    "reason": "Mentions the existence of multiple datasets at first mention without citing any of them, which is required for prior work and dataset introductions.",
    "start": 245,
    "end": 325,
    "label": "Unsupported_claim"
  },
  {
    "span": "Savova et al. (2010) introduced cTAKES for clinical concept extraction. Chapman et al. (2001) developed NegEx for assertion status detection. Alsentzer et al. (2019) pretrained BERT models on clinical notes. Mullenbach et al. (2018) proposed CNNs for ICD coding. Question answering over EHRs has also been explored (Pampari et al., 2018).",
    "document": "Related Work\n\nClinical NLP and Structured Prediction in EHRs\n\nClinical text processing has advanced from rule-based systems to pretrained language models adapted to healthcare corpora. We target few-shot extraction of problem-medication relations in discharge summaries.\n\nSavova et al. (2010) introduced cTAKES for clinical concept extraction. Chapman et al. (2001) developed NegEx for assertion status detection. Alsentzer et al. (2019) pretrained BERT models on clinical notes. Mullenbach et al. (2018) proposed CNNs for ICD coding. Question answering over EHRs has also been explored (Pampari et al., 2018).\n\nOur approach combines weak supervision with domain-adapted adapters to reduce annotation cost.",
    "reason": "Papers from different tasks (assertion detection, pretraining, ICD coding, QA) are listed without transitions that explain their relevance to relation extraction; the connections are left implicit.",
    "start": 272,
    "end": 610,
    "label": "Coherence"
  },
  {
    "span": "Burke (2017) defines multi-stakeholder fairness in recommender systems. He et al. (2017) propose neural collaborative filtering for implicit feedback. Ekstrand et al. (2022) report user studies on perceived recommendation fairness.",
    "document": "Related Work\n\nFairness in recommender systems encompasses provider- and consumer-side outcomes, exposure balancing, and calibration under utility constraints. Methods range from re-ranking and regularization to counterfactual evaluation and user-centered studies.\n\nBurke (2017) defines multi-stakeholder fairness in recommender systems. He et al. (2017) propose neural collaborative filtering for implicit feedback. Ekstrand et al. (2022) report user studies on perceived recommendation fairness.\n\nRecent approaches incorporate exposure-aware objectives and causality-informed debiasing, with metrics that capture disparate impact across groups. Our work introduces an exposure-constrained objective that improves provider fairness while maintaining click utility.",
    "reason": "The span juxtaposes a fairness definition, a generic CF model, and a user study without transitions or explicit connections, leaving unclear how the CF model relates to fairness or the user study.",
    "start": 265,
    "end": 496,
    "label": "Coherence"
  },
  {
    "span": "Several prior competitions developed standardized episodes for fair few-shot evaluation.",
    "document": "Related Work\n\nFew-shot learning aims to generalize to novel classes with limited labeled examples, often by learning transferable inductive biases. Representative approaches include metric-based methods (Vinyals et al., 2016; Snell et al., 2017) and optimization-based meta-learning (Finn et al., 2017). Dataset design and evaluation protocols significantly impact reported performance and generalization.\n\nSeveral prior competitions developed standardized episodes for fair few-shot evaluation. Yet, inconsistent class hierarchies and domain heterogeneity continue to complicate cross-benchmark comparisons. We introduce a unified episode construction protocol with domain-balanced sampling and assess robustness across visual domains.",
    "reason": "References competitions and standardized setups without any citations; first mentions of such prior efforts should be supported.",
    "start": 407,
    "end": 495,
    "label": "Unsupported_claim"
  },
  {
    "span": "(Nguyen and Rao, 2016)",
    "document": "Introduction\n\nOpen-domain dialogue systems have evolved from retrieval-based to generative models that better capture context and persona (Vinyals and Le, 2015; Zhang et al., 2018; Zhang et al., 2020). Personalization improves engagement and consistency by conditioning responses on speaker attributes (Li et al., 2016). Prior work (Nguyen and Rao, 2016) examines turn-level coherence via hierarchical encoders, while subsequent models add knowledge grounding (Dinan et al., 2019). We propose a contrastive objective that disentangles style from content, enabling controllable generation without supervised attribute labels.",
    "reason": "Incorrect conjunction inside parenthetical citation for APA style; within parentheses, use '&' instead of 'and', i.e., '(Nguyen & Rao, 2016)'.",
    "start": 332,
    "end": 354,
    "label": "Format"
  },
  {
    "span": "Previous studies standardly use cosine similarity over tf-idf character trigrams for candidate ranking.",
    "document": "Related Work\n\nBiomedical entity normalization (BEN) links surface mentions in text to entries in controlled vocabularies, enabling downstream curation and retrieval. The task is commonly decomposed into candidate generation followed by candidate ranking, with methods ranging from rule-based pruning to neural embedding comparison.\n\nPrevious studies standardly use cosine similarity over tf-idf character trigrams for candidate ranking. More recent approaches learn dense encoders and integrate ontology structure, but they often require substantial in-domain supervision and careful calibration to handle synonymy and acronyms.\n\nOur work revisits candidate ranking under label scarcity and proposes a contrastive calibration layer that adapts to ontology-specific synonym distributions with minimal supervision.\n",
    "reason": "The sentence attributes a standard practice to 'previous studies' without citing any specific papers, violating the requirement to cite prior work when referencing it.",
    "start": 333,
    "end": 436,
    "label": "Unsupported_claim"
  },
  {
    "span": "Zhang et al. 2",
    "document": "Related Work\n\nAbstractive summarization models based on sequence-to-sequence learning have advanced with pointer-generator mechanisms (See et al., 2017) and pre-trained language models (Liu and Lapata, 2019). A number of works have explored content planning before decoding; for example, Zhang et al. 2 argue for separating planning and realization, while He et al. (2020) propose learning content selectors. We extend these ideas by introducing discourse-aware plans that guide evidence aggregation.",
    "reason": "Improper use of a footnote-like number in place of a proper citation. It should include the year (e.g., “Zhang et al. (2020)”) or be formatted as a proper footnote reference.",
    "start": 288,
    "end": 302,
    "label": "Format"
  },
  {
    "span": "federated pathology models outperform centralized baselines by 3–5%",
    "document": "Introduction\n\nFederated learning enables collaborative training across institutions without centralizing sensitive data, which is crucial for clinical imaging applications (Konecny et al., 2016; Li et al., 2020). Histopathology, with gigapixel whole-slide images and site-specific staining protocols, presents unique challenges for distribution shift and communication efficiency (Campanella et al., 2019; Lu et al., 2021). A previous multi-institutional study reports that federated pathology models outperform centralized baselines by 3–5% while preserving patient privacy under regulatory constraints.\n\nBuilding on this premise, we propose a stain-aware aggregation scheme and client-specific normalization layers to mitigate cross-site heterogeneity, demonstrating improved robustness on four hospitals spanning different scanners and protocols.",
    "reason": "Claims concrete performance gains from a prior study without providing a citation; such comparative statistics require supporting references.",
    "start": 474,
    "end": 541,
    "label": "Unsupported_claim"
  },
  {
    "span": "Clinical concept extraction identifies spans of problems, tests, and treatments (Uzuner et al., 2011). Negation detection distinguishes affirmed from negated findings (Chapman et al., 2001). Temporal relation extraction orders events and time expressions (Bethard et al., 2016). De-identification removes protected health information from clinical narratives (Stubbs and Uzuner, 2015).",
    "document": "Related Work\n\nClinical NLP covers a variety of information extraction problems that enable secondary use of electronic health records. Systems often require domain adaptation and careful handling of data privacy constraints.\n\nClinical concept extraction identifies spans of problems, tests, and treatments (Uzuner et al., 2011). Negation detection distinguishes affirmed from negated findings (Chapman et al., 2001). Temporal relation extraction orders events and time expressions (Bethard et al., 2016). De-identification removes protected health information from clinical narratives (Stubbs and Uzuner, 2015).\n\nOur work targets cross-hospital generalization for concept extraction while preserving privacy.",
    "reason": "Multiple tasks are listed back-to-back with citations but no transitions or explicit connections among them, making it unclear how each relates to the others or to the paper’s focus.",
    "start": 226,
    "end": 611,
    "label": "Coherence"
  },
  {
    "span": "(2020, Park et al.)",
    "document": "Introduction\n\nNeural machine translation shifted from RNNs to Transformers, enabling better parallelism and context modeling (Bahdanau et al., 2015; Vaswani et al., 2017). Large-scale pretraining further boosts low-resource transfer (Lample and Conneau, 2019). (2020, Park et al.) integrate visual cues into MT for disambiguation, while others harness syntax (Eriguchi et al., 2017) and document context (Maruf et al., 2019). We investigate whether lightweight adapters can attain similar gains with reduced computational cost.",
    "reason": "Incorrect ordering in author–year style; should be 'Park et al. (2020)' or '(Park et al., 2020)'.",
    "start": 261,
    "end": 280,
    "label": "Format"
  },
  {
    "span": "Early studies proved that deeper GNNs generalize better on citation networks.",
    "document": "Related Work\n\nGraph neural networks (GNNs) propagate and transform node features along the edges of a graph, enabling learning from relational structure [1]. Over-smoothing and depth-efficiency trade-offs have been widely discussed [2]. Early studies proved that deeper GNNs generalize better on citation networks. Subsequent work introduced residual connections and normalization to mitigate degradation with depth [3].",
    "reason": "Asserts a prior finding ('proved that deeper GNNs generalize better') without citing any study.",
    "start": 237,
    "end": 314,
    "label": "Unsupported_claim"
  },
  {
    "span": "User-level features indicate susceptibility (Vosoughi et al., 2018). Topic models uncover discourse themes (Blei et al., 2003). Pretrained transformers detect stance (Liu et al., 2019). Network cascades reveal diffusion patterns (Goel et al., 2016).",
    "document": "Related Work\n\nDetecting misinformation requires integrating content signals with user behavior and network structure. Early approaches relied on linguistic markers and simple propagation cues, while recent methods exploit deep contextual encoders and temporal graphs (Rubin et al., 2015; Shu et al., 2020).\n\nUser-level features indicate susceptibility (Vosoughi et al., 2018). Topic models uncover discourse themes (Blei et al., 2003). Pretrained transformers detect stance (Liu et al., 2019). Network cascades reveal diffusion patterns (Goel et al., 2016).\n\nOur model unifies stance-aware encoding with diffusion-informed priors to provide robust early detection in streaming settings.",
    "reason": "The span enumerates heterogeneous strands (user features, topic models, transformers, diffusion cascades) without transitions or explicit ties between them, leading to an abrupt and incoherent flow.",
    "start": 308,
    "end": 557,
    "label": "Coherence"
  },
  {
    "span": "Exposure-aware ranking corrects group-level disparities (Singh and Joachims, 2018). Counterfactual learning reduces position bias (Joachims et al., 2017). Differential privacy guards user data (Dwork et al., 2006). Calibration aligns predicted and observed preferences (Steck, 2018).",
    "document": "Related Work\n\nFairness in Recommender Systems\n\nFairness in recommendation encompasses provider exposure, user-level parity, and content diversity. A growing body of work develops metrics and algorithms to mitigate disparate impact while maintaining utility. We organize prior work along ranking fairness, debiasing from implicit feedback, and privacy-aware modeling.\n\nRanking, Debiasing, and Privacy\n\nExposure-aware ranking corrects group-level disparities (Singh and Joachims, 2018). Counterfactual learning reduces position bias (Joachims et al., 2017). Differential privacy guards user data (Dwork et al., 2006). Calibration aligns predicted and observed preferences (Steck, 2018).\n\nOur Position\n\nWe propose a unified objective that trades off exposure fairness and recommendation quality under a differential privacy constraint, with provable guarantees and scalable optimization.",
    "reason": "The sentences jump across distinct topics—exposure fairness, counterfactual debiasing, privacy, and calibration—without transitions clarifying their connections. The relationships are left implicit, creating an abrupt sequence that undermines coherence.",
    "start": 401,
    "end": 684,
    "label": "Coherence"
  },
  {
    "span": "(Lopez 2021)",
    "document": "Related Work\n\nAlgorithmic fairness has been studied across definitions such as demographic parity, equalized odds, and calibration (Barocas et al., 2019; Hardt et al., 2016; Kleinberg et al., 2017). Fairness-aware losses penalize disparity during training and can be combined with postprocessing (Pleiss et al., 2017). Recent work explores representation learning that removes sensitive information while retaining utility (Zemel et al., 2013; Edwards and Storkey, 2016). We build on adversarial debiasing and introduce a group-conditional margin that adapts to base-rate differences (Lopez 2021), improving both accuracy and equity on benchmark datasets.\n\nIntroduction\n\nWe evaluate on COMPAS and Adult, following established preprocessing and splits (Beutel et al., 2019), and compare against in-processing and postprocessing baselines.",
    "reason": "Missing comma between author and year in a parenthetical citation; should be '(Lopez, 2021)'.",
    "start": 584,
    "end": 596,
    "label": "Format"
  },
  {
    "span": "Exploration in sparse-reward RL has been addressed through count-based bonuses (Bellemare et al., 2016; Tang et al., 2017), intrinsic motivation via prediction error or curiosity (Pathak et al., 2017; Burda et al., 2019), and entropy regularization and maximum entropy objectives (Haarnoja et al., 2018; Mnih et al., 2016).",
    "document": "Introduction\n\nReinforcement learning (RL) in sparse-reward environments remains difficult because agents must uncover rewarding states with little guidance. Effective exploration is essential to avoid premature convergence to suboptimal behaviors and to ensure sample efficiency.\n\nExploration in sparse-reward RL has been addressed through count-based bonuses (Bellemare et al., 2016; Tang et al., 2017), intrinsic motivation via prediction error or curiosity (Pathak et al., 2017; Burda et al., 2019), and entropy regularization and maximum entropy objectives (Haarnoja et al., 2018; Mnih et al., 2016).\n\nWe introduce a goal-conditioned successor feature prior that shapes exploration by predicting long-horizon controllability, requiring no environment resets or expert data. We evaluate our method on continuous-control and hard-exploration Atari benchmarks.\n",
    "reason": "The span catalogs prior exploration strategies without explaining how they inform or contrast with the proposed approach, leaving the gap and motivation unstated.",
    "start": 281,
    "end": 604,
    "label": "Lacks_synthesis"
  },
  {
    "span": "(Zhao et al.), 2018",
    "document": "Introduction\n\nTime-series classification has benefited from convolutional and recurrent architectures, alongside shapelet-based interpretable models (Wang et al., 2017; Fawaz et al., 2019). Recent transformer variants introduce frequency-aware attention and multiresolution encoders to capture long-term dependencies (Zerveas et al., 2021; Wu et al., 2021). Prior studies report substantial gains on benchmark datasets (Zhao et al.), 2018 and highlight the value of augmentations such as jittering and time warping (Um et al., 2017). We extend this line by integrating spectral priors with instance-dependent augmentations learned from data, improving robustness under covariate shift.",
    "reason": "Year placed outside the parenthetical citation; should be \"(Zhao et al., 2018)\" or narrative style \"Zhao et al. (2018)\".",
    "start": 419,
    "end": 438,
    "label": "Format"
  },
  {
    "span": "(Deng and Yu 2014)",
    "document": "Related Work\n\nAcoustic modeling has evolved from Gaussian mixture models to deep neural networks. A popular baseline for hybrid HMM-DNN systems (Deng and Yu 2014) employs context-dependent states with sequence-discriminative training. Subsequent architectures integrate convolutional front-ends and attention pooling to improve robustness under noise (Kumar et al., 2018; Silva and Wong, 2020).",
    "reason": "Missing comma between authors and year in a parenthetical citation: should be “(Deng and Yu, 2014)”.",
    "start": 144,
    "end": 162,
    "label": "Format"
  },
  {
    "span": "Xie et al. (2020) introduced MixMatch to unify consistency regularization and entropy minimization. Sohn et al. (2020) proposed FixMatch with pseudo-labeling and strong augmentations. Cubuk et al. (2019) presented AutoAugment for supervised data augmentation. RandAugment simplified policy search with fewer parameters (Cubuk et al., 2020).",
    "document": "Related Work\n\nSemi-supervised learning (SSL) benefits from consistency constraints, confidence-based pseudo-labels, and augmentation strategies that expand the effective training distribution. A key question is how to design augmentations and thresholds that avoid confirmation bias.\n\nXie et al. (2020) introduced MixMatch to unify consistency regularization and entropy minimization. Sohn et al. (2020) proposed FixMatch with pseudo-labeling and strong augmentations. Cubuk et al. (2019) presented AutoAugment for supervised data augmentation. RandAugment simplified policy search with fewer parameters (Cubuk et al., 2020).\n\nComplementary work leverages unlabeled-to-labeled ratio scheduling, distribution alignment, and teacher-student filtering (Berthelot et al., 2019; Zoph et al., 2020). We study augmentation robustness across imbalance and label noise.",
    "reason": "The cited works are listed without articulating their relationships, especially the shift from SSL methods to general supervised augmentation papers, resulting in abrupt, unconnected sentences.",
    "start": 285,
    "end": 625,
    "label": "Coherence"
  },
  {
    "span": "Recent work has shown that 3D geometry is essential for accurate toxicity prediction.",
    "document": "Related Work\n\nPredicting molecular properties with machine learning has progressed from fixed fingerprints to learned graph representations that capture local and global chemical structure (Rogers and Hahn, 2010; Duvenaud et al., 2015; Gilmer et al., 2017). Message passing neural networks (MPNNs) model atom–bond interactions, while attention mechanisms and pooling strategies aim to aggregate informative substructures (Veličković et al., 2018; Ying et al., 2018).\n\nIncorporating three-dimensional information can benefit tasks sensitive to stereochemistry and conformational effects, motivating models that operate on 3D structures or learned distance matrices (Schütt et al., 2017; Klicpera et al., 2020). Recent work has shown that 3D geometry is essential for accurate toxicity prediction. However, acquiring high-quality conformers at scale is computationally expensive, and experimental structures are sparse for many compounds.\n\nWe propose a geometry-aware pretraining strategy that distills coarse 3D cues from fast conformer ensembles into 2D graph encoders, narrowing the performance gap while preserving computational efficiency.",
    "reason": "This is a 'recent work has shown' claim about a specific outcome (toxicity prediction) without citing any supporting studies.",
    "start": 710,
    "end": 795,
    "label": "Unsupported_claim"
  },
  {
    "span": "Several recent works use reinforcement learning from unit tests to improve pass@k for code generation models.",
    "document": "Introduction\n\nTransformer-based code generation has advanced rapidly with large-scale pretraining on source repositories and problem descriptions. Yet, maximizing functional correctness remains challenging because likelihood under the model does not align with execution success. Several recent works use reinforcement learning from unit tests to improve pass@k for code generation models. Other approaches integrate execution feedback during decoding, apply constraint satisfaction to ensure API adherence, or perform retrieval-augmented generation from similar code snippets.\n\nDespite these advances, evaluation practices vary widely across programming languages, test coverage levels, and deduplication policies. We propose a standardized evaluation suite with consistent test-time sampling, seed control, and problem difficulty stratification, and we analyze generalization under partial credit scoring.",
    "reason": "References 'recent works' and a specific methodological trend without providing citations, violating rule (d).",
    "start": 280,
    "end": 389,
    "label": "Unsupported_claim"
  },
  {
    "span": "End-to-end automatic speech recognition has progressed through CTC models, attention-based encoder–decoder architectures, and transducer frameworks. Streaming recognition emphasizes low latency and stability via chunked attention, monotonic alignment, and predictive coding. Data augmentation such as SpecAugment and noise perturbation is commonly used to improve robustness.",
    "document": "Introduction\n\nAutomatic speech recognition (ASR) systems aim to convert acoustic signals into textual transcriptions under real-time constraints and diverse acoustic environments. End-to-end approaches have simplified training pipelines and enabled rapid iteration.\n\nEnd-to-end automatic speech recognition has progressed through CTC models, attention-based encoder–decoder architectures, and transducer frameworks. Streaming recognition emphasizes low latency and stability via chunked attention, monotonic alignment, and predictive coding. Data augmentation such as SpecAugment and noise perturbation is commonly used to improve robustness.\n\nRecent benchmarks highlight challenges from domain mismatch, speaker variability, and far-field conditions.\n\nWe evaluate streaming models on multi-domain datasets with strict latency budgets.",
    "reason": "This span summarizes prior work without stating how it informs the authors' approach, what gap remains, or why their research is needed.",
    "start": 267,
    "end": 642,
    "label": "Lacks_synthesis"
  },
  {
    "span": "Gilmer et al. (2017) formalized message passing neural networks for molecular property prediction. Veličković et al. (2018) introduced graph attention networks for node-level tasks. Hu et al. (2019) proposed pre-training strategies for graph neural networks. Yang et al. (2019) curated the Open Graph Benchmark for large-scale evaluation.",
    "document": "Related Work\n\nGraph neural networks (GNNs) have become a central tool for learning over molecular graphs, enabling end-to-end prediction of physical, chemical, and biological properties (Duvenaud et al., 2015; Kearnes et al., 2016). Extensions include attention mechanisms, message scheduling, equivariance, and multi-task learning for drug discovery (Ramsundar et al., 2017; Anderson et al., 2019; Satorras et al., 2021).\n\nGilmer et al. (2017) formalized message passing neural networks for molecular property prediction. Veličković et al. (2018) introduced graph attention networks for node-level tasks. Hu et al. (2019) proposed pre-training strategies for graph neural networks. Yang et al. (2019) curated the Open Graph Benchmark for large-scale evaluation.\n\nWhile these advances improved representation learning, challenges remain in out-of-distribution generalization and data efficiency (Wang et al., 2022; Scarselli et al., 2022). Our approach complements prior work by integrating physically motivated constraints into pre-training to enhance extrapolation on novel chemistries.",
    "reason": "The span enumerates multiple cited works without articulating their connections or how one leads to the next. The relationships are implied but never stated, resulting in low coherence across the sentences.",
    "start": 424,
    "end": 762,
    "label": "Coherence"
  },
  {
    "span": "Prompting large language models and augmenting them with tools have been widely studied (Brown et al., 2020; Schick and Schutze, 2021; Wei et al., 2022; Press et al., 2022; Parisi et al., 2022).",
    "document": "Related Work\n\nLarge Language Models and Prompting\nPrompt design has emerged as a key mechanism to steer large language models (LLMs) without task-specific fine-tuning. Techniques span manual templates, automatic prompt search, and instruction tuning.\n\nPrompting large language models and augmenting them with tools have been widely studied (Brown et al., 2020; Schick and Schutze, 2021; Wei et al., 2022; Press et al., 2022; Parisi et al., 2022). Retrieval augmentation and program induction further extend LLM capabilities, especially in knowledge-intensive and compositional tasks.\n\nEvaluation and Safety\nConcurrent work evaluates robustness, calibration, and safety of prompted LLMs, highlighting brittleness to phrasing and susceptibility to adversarial inputs.",
    "reason": "This sentence lists prior areas and citations without explaining their relation to the paper's aims, limitations to be addressed, or the authors' stance (criterion a and c).",
    "start": 252,
    "end": 446,
    "label": "Lacks_synthesis"
  },
  {
    "span": "(Lopez and Wong, 2022)",
    "document": "Introduction\n\nFederated learning (FL) enables collaborative model training across decentralized clients without centralizing raw data, addressing privacy and regulatory concerns (McMahan et al., 2017; Kairouz et al., 2021). Despite its promise, FL suffers from statistical heterogeneity and systems constraints such as stragglers and limited bandwidth (Li et al., 2020; Bonawitz et al., 2019). Personalization techniques adapt global models to client-specific distributions via fine-tuning, meta-learning, or multi-task formulations (Arivazhagan et al., 2019; Fallah et al., 2020). Robust aggregation mitigates the impact of adversarial or corrupted updates (Blanchard et al., 2017; Yin et al., 2018). Recent compression approaches reduce communication overhead while maintaining accuracy (Alistarh et al., 2017; Lin et al., 2018). We compare to adaptive client sampling (Lopez and Wong, 2022) and propose a scheduler that jointly optimizes fairness and convergence under variable client availability.\n",
    "reason": "Inside parentheses, APA style uses an ampersand between two authors; it should be \"(Lopez & Wong, 2022)\" instead of \"(Lopez and Wong, 2022)\".",
    "start": 871,
    "end": 893,
    "label": "Format"
  },
  {
    "span": "Recently, prompt-based methods for vision-language models have been explored under different formulations, including textual prompt tuning, visual prompt insertion, and multimodal prompt composition (Zhou et al., 2022; Jia et al., 2022; Tsimpoukelli et al., 2021; Bahng et al., 2022).",
    "document": "Related Work\n\nVision-language models (VLMs) pretrained on large image-text corpora have demonstrated strong transfer to downstream tasks with minimal supervision. A central question is how to efficiently adapt these models to new tasks without full fine-tuning.\n\nRecently, prompt-based methods for vision-language models have been explored under different formulations, including textual prompt tuning, visual prompt insertion, and multimodal prompt composition (Zhou et al., 2022; Jia et al., 2022; Tsimpoukelli et al., 2021; Bahng et al., 2022).\n\nAdapter-based approaches introduce lightweight modules in intermediate layers to steer representations during downstream adaptation, while linear probing leaves the encoder frozen and trains only a classifier head. Efficient fine-tuning techniques trade off compute, memory, and sample efficiency in different ways.\n\nOur method investigates a task-consistent prompt allocation strategy that balances textual and visual prompt capacity under a fixed parameter budget.",
    "reason": "The span enumerates categories and citations of prompt-based VLM methods without articulating how they relate to the present work or what gap remains, matching (a) and (c).",
    "start": 263,
    "end": 547,
    "label": "Lacks_synthesis"
  },
  {
    "span": "Previous studies have shown that self-supervised pretraining on unlabeled EHR sequences consistently improves in-hospital mortality prediction.",
    "document": "Introduction\n\nElectronic Health Records (EHR) offer longitudinal, multimodal data for clinical prediction tasks, yet sparsity, irregular sampling, and heterogeneity hinder modeling. Representation learning approaches have drawn on masked modeling, contrastive objectives, and generative forecasting to leverage unlabeled encounters. Previous studies have shown that self-supervised pretraining on unlabeled EHR sequences consistently improves in-hospital mortality prediction. However, few works examine robustness across institutions and coding shifts, and even fewer analyze calibration under temporal drift and interventions. We present a cross-hospital study of pretraining strategies, evaluating discrimination, calibration, and fairness across demographic subgroups, and we release protocols for reproducible evaluation under temporal shifts.",
    "reason": "Claims findings from prior studies with no references to those studies, which are necessary to substantiate the statement.",
    "start": 333,
    "end": 476,
    "label": "Unsupported_claim"
  },
  {
    "span": "Kumar et al. 1",
    "document": "Related Work\n\nAutomatic evaluation metrics for natural language generation aim to approximate human judgments with inexpensive proxies. N-gram-based measures such as BLEU and ROUGE are widely used but correlate weakly with semantics (Papineni et al., 2002; Lin, 2004). Embedding-based metrics leverage contextual similarity to improve robustness (Zhang et al., 2020; Sellam et al., 2020). Recent studies stress the importance of calibration and system-level reliability (Mathur et al., 2020). Following Kumar et al. 1, we examine whether confidence-aware metrics better capture human preferences on summarization and data-to-text tasks.",
    "reason": "Improper use of a footnote-style number after an author–year citation; should include the year (e.g., Kumar et al., 2021) or be formatted as a proper footnote.",
    "start": 503,
    "end": 517,
    "label": "Format"
  },
  {
    "span": "Transformer-based time-series forecasters such as Informer, Autoformer, FEDformer, and PatchTST have been proposed for long-horizon prediction (Zhou et al., 2021; Wu et al., 2021; Zhou et al., 2022; Nie et al., 2023).",
    "document": "Introduction\n\nLong-horizon time-series forecasting\n\nAccurate multi-step forecasting under sparse supervision and nonstationarity is critical in energy, finance, and climate. Transformers have been adapted to handle long-range dependencies via sparse attention, decomposition, and frequency-domain modeling.\n\nTransformer-based time-series forecasters such as Informer, Autoformer, FEDformer, and PatchTST have been proposed for long-horizon prediction (Zhou et al., 2021; Wu et al., 2021; Zhou et al., 2022; Nie et al., 2023).\n\nOpen challenges\n\nDespite progress, evaluation protocols vary widely, leakage issues persist, and improvements are inconsistent across datasets and horizons. Robustness to covariate shift and missingness remains underexplored.\n\nContributions\n\nWe revisit architectural choices under standardized splits and introduce a lightweight decomposition prior that improves stability under shift.",
    "reason": "The span lists prior Transformer models without articulating their relation to the authors’ approach or explicitly stating the gap being addressed, reflecting a lack of synthesis (criteria a and b).",
    "start": 308,
    "end": 525,
    "label": "Lacks_synthesis"
  },
  {
    "span": "Johnson and Wei, (2020)",
    "document": "Related Work\n\nAbstractive summarization has moved toward pretrained encoder–decoder models with strong generation capabilities (Lin and Porter, 2019; Ahmed et al., 2021). Johnson and Wei, (2020) propose content planning modules to improve coherence, while Shi and Kumar (2021) introduce entity-aware attention to reduce hallucination. Recent evaluations emphasize faithfulness metrics and factual consistency against source documents (Miller and Cho, 2022; Parker and Sun, 2022).\n\nOur method integrates a planning decoder with constrained decoding, combining sentence-level discourse cues and entity coreference signals to balance informativeness and faithfulness.",
    "reason": "Narrative citation includes an unnecessary comma before the year. Correct form is \"Johnson and Wei (2020)\" without a comma.",
    "start": 171,
    "end": 194,
    "label": "Format"
  },
  {
    "span": "Graph-based methods propagate labels over similarity graphs to exploit manifold structure (Zhu and Ghahramani, 2002). Pre-trained language models like BERT demonstrate strong few-shot transfer (Devlin et al., 2019). Curriculum learning schedules have been shown to improve convergence in noisy settings (Bengio et al., 2009). MixUp improves generalization by interpolating inputs and labels (Zhang et al., 2018).",
    "document": "Related Work\n\nSemi-supervised learning for text has leveraged consistency regularization and perturbation-based objectives to stabilize predictions under input noise (Miyato et al., 2018; Xie et al., 2020). Pseudo-labeling assigns confident targets to unlabeled examples and iterates training, often with temperature scaling or entropy minimization to improve reliability (Lee, 2013; Arazo et al., 2020). Data augmentation tailored for language, including back-translation and word-level noising, further improves utilization of unlabeled corpora (Sennrich et al., 2016; Wei and Zou, 2019).\n\nGraph-based methods propagate labels over similarity graphs to exploit manifold structure (Zhu and Ghahramani, 2002). Pre-trained language models like BERT demonstrate strong few-shot transfer (Devlin et al., 2019). Curriculum learning schedules have been shown to improve convergence in noisy settings (Bengio et al., 2009). MixUp improves generalization by interpolating inputs and labels (Zhang et al., 2018).\n\nOur work focuses on uncertainty-aware pseudo-labeling combined with text-specific augmentations, aiming to close the gap between consistency objectives and representation learning in pre-trained encoders.",
    "reason": "The cited works in the span shift abruptly across unrelated topics (graph SSL, pre-trained LMs, curriculum learning, MixUp) without transitions or an explicit explanation of how each relates to the previous sentence or to semi-supervised NLP.",
    "start": 592,
    "end": 1004,
    "label": "Coherence"
  },
  {
    "span": "(Clark et al. 2016)",
    "document": "Related Work\n\nNeural reading comprehension systems have evolved from simple attention mechanisms over passages to pretrained transformer-based readers (Hermann et al., 2015; Chen et al., 2017; Karpukhin et al., 2020). Distant supervision and large-scale pretraining substantially improve generalization, but robustness and calibration remain challenges under adversarial or out-of-domain conditions (Jia and Liang, 2017; Kamath et al., 2020).\n\nPrior studies (Clark et al. 2016) explored multi-hop reasoning with attention composition, inspiring later architectures that interleave retrieval and reading (Yang et al., 2018; Xiong et al., 2021). We investigate a retrieval-augmented decoder that adaptively queries evidence while estimating uncertainty, reducing overconfidence on distractors.\n\nOur analysis spans open-domain QA and multi-hop benchmarks, providing insights into trade-offs between retrieval depth, latency, and answer accuracy (Lee et al., 2019; Izacard and Grave, 2021).",
    "reason": "Missing comma before the year in an author–year parenthetical citation; should be (Clark et al., 2016).",
    "start": 458,
    "end": 477,
    "label": "Format"
  },
  {
    "span": "(Johnson et al., 2020))",
    "document": "Introduction\n\nTopic modeling aims to discover latent semantic structure from large text corpora (Blei et al., 2003). While classical LDA assumes exchangeability and simple priors, neural topic models incorporate amortized inference and richer priors for flexibility (Miao et al., 2017; Srivastava and Sutton, 2017). Prior work (Johnson et al., 2020)) proposes amortized variational updates with sparsity-inducing penalties to improve topic interpretability under limited supervision. Complementary methods regularize with mutual information or anchor-based constraints to control drift and redundancy (Zhang et al., 2018; Arora et al., 2013).",
    "reason": "Extra closing parenthesis in the citation; it should be a single closing parenthesis: “(Johnson et al., 2020)”.",
    "start": 327,
    "end": 350,
    "label": "Format"
  },
  {
    "span": "Safety interventions for open-domain assistants include toxicity filters, refusal policies, post-hoc red teaming, RL from human feedback, and constitutional training (Gehman et al., 2020; Bai et al., 2022; Askell et al., 2021; Ouyang et al., 2022; Anthropic, 2023).",
    "document": "Related Work\n\nAs large conversational models are deployed broadly, mitigating harmful behaviors such as toxicity, harassment, and disallowed instructions is paramount. Approaches range from data curation to model-internal constraints and reinforcement learning with preference signals.\n\nSafety interventions for open-domain assistants include toxicity filters, refusal policies, post-hoc red teaming, RL from human feedback, and constitutional training (Gehman et al., 2020; Bai et al., 2022; Askell et al., 2021; Ouyang et al., 2022; Anthropic, 2023). Our work presents SafeMix, a training-time data mixing strategy guided by calibrated safety classifiers to improve refusal consistency without degrading helpfulness.\n\nWe evaluate on public safety suites and live A/B tests, reporting reductions in unsafe response rates and stable user satisfaction metrics.\n",
    "reason": "The span lists prior safety methods but does not connect them to the authors’ motivation or identify what remains unresolved; the following sentence jumps to the contribution without synthesis.",
    "start": 287,
    "end": 552,
    "label": "Lacks_synthesis"
  },
  {
    "span": "In (Doe et al., 2019)",
    "document": "Introduction\n\nGraph neural networks (GNNs) have emerged as a powerful paradigm for learning on relational data, enabling message passing over nodes and edges (Kipf and Welling, 2017; Hamilton et al., 2017). In (Doe et al., 2019), a relational attention mechanism was introduced to modulate messages based on typed edges in heterogeneous networks. Subsequent variants extend neighborhood sampling, stability, and expressivity, with applications ranging from molecular property prediction to recommendation (Velickovic et al., 2018; Xu et al., 2019). Despite these advances, robustness to distribution shift and scalability to dynamic graphs remain open challenges (Rossi et al., 2020).",
    "reason": "Wrong citation style: the preposition should precede a narrative citation, e.g., “In Doe et al. (2019)” rather than “In (Doe et al., 2019)”.",
    "start": 207,
    "end": 228,
    "label": "Format"
  },
  {
    "span": "[Miller and Davis, 2020]",
    "document": "Related Work\n\nDomain adaptation in reinforcement learning tackles shifts in dynamics or reward specification without extensive target-domain interaction (Higgins et al., 2017; Rusu et al., 2016). Adversarial alignment has been applied to state features and policy embeddings to reduce representation mismatch (Tzeng et al., 2017; Ganin and Lempitsky, 2015). Robust policy learning under transition noise was investigated in [Miller and Davis, 2020], who propose a discriminator-guided objective to preserve controllability across domains. We instead regularize the value landscape to encourage smooth generalization (Zhang and Dauphin, 2019).",
    "reason": "Wrong bracket style; the rest of the paper uses APA-like parentheses, so the citation should be \"(Miller and Davis, 2020)\" not square brackets.",
    "start": 424,
    "end": 448,
    "label": "Format"
  },
  {
    "span": "Smith et al., 2021]",
    "document": "Introduction\n\nGraph neural networks (GNNs) excel at combining node features with relational structure, enabling state-of-the-art performance in chemistry and recommendation (Velasquez and Ito, 2019; Park and Newman, 2020). Recent work (Smith et al., 2021] demonstrates that message passing can suffer from over-smoothing, motivating architectural changes that preserve discriminability across layers (Hu and Tran, 2020; Cheung et al., 2022). Complementary approaches add positional encodings to capture long-range dependencies (Meyer and Roth, 2021), while subgraph extraction improves scalability (Gao et al., 2022).\n\nWe propose a residual diffusion operator that stabilizes training and enhances expressivity on heterophilous graphs, building upon theoretical insights into spectral filtering (Rahman and Yu, 2020) and empirical advances in scalable batching (Cho and Patel, 2021).",
    "reason": "Mismatched bracket in the parenthetical citation: closing square bracket without an opening square bracket. Should be \"(Smith et al., 2021)\".",
    "start": 236,
    "end": 255,
    "label": "Format"
  },
  {
    "span": "BERT was used in an AES task trained on essays from non-native speakers with prompt-specific calibration.",
    "document": "Introduction\n\nAutomatic Essay Scoring (AES) aims to predict holistic and analytic scores for student writing (Attali and Burstein, 2006). Neural models have progressively improved AES by leveraging contextual embeddings and prompt-aware architectures (Taghipour and Ng, 2016; Devlin et al., 2019). Public datasets such as ASAP and TOEFL11 have enabled reproducible comparisons across systems (Shermis and Burstein, 2013).\n\nBERT was used in an AES task trained on essays from non-native speakers with prompt-specific calibration. However, the efficacy of pretraining for cross-prompt generalization and fairness across proficiency levels remains an open question. In this work, we investigate calibration strategies that reduce prompt leakage while preserving predictive performance.\n\nRelated Work\n\nPrior research has examined domain adaptation between prompts (Jin et al., 2018) and explored auxiliary tasks like error detection to improve AES (Dong et al., 2017). More recent studies investigate bias mitigation and rater variance modeling (Uto and Uchida, 2020).",
    "reason": "Mentions a specific prior setup (BERT used in non-native AES with prompt-specific calibration) without citing the study that introduced it.",
    "start": 423,
    "end": 528,
    "label": "Unsupported_claim"
  },
  {
    "span": "In a previous study, the authors claim that graph pooling improves interpretability.",
    "document": "Related Work\n\nLearning to rank with graph neural networks (GNNs) has gained attention for capturing higher-order item interactions. Recent approaches construct query-document graphs and propagate relevance signals via message passing. To address scalability, sparsification and pooling layers are often introduced. In a previous study, the authors claim that graph pooling improves interpretability. Concurrently, counterfactual ranking diagnostics and attribution methods have been proposed to explain learned relevance signals. Our work focuses on hierarchical pooling with stability constraints to improve both ranking effectiveness and explanation consistency.",
    "reason": "References a 'previous study' and its claim without citing the study (rule a, e.ii).",
    "start": 315,
    "end": 399,
    "label": "Unsupported_claim"
  },
  {
    "span": "MIMIC-III dataset",
    "document": "Introduction\n\nAutomated phenotyping from clinical notes enables large-scale cohort identification and outcome modeling, but progress is often hindered by domain-specific language and label scarcity. Publicly available resources have catalyzed research into clinical NLP methods and evaluation practices. In particular, the MIMIC-III dataset provides de-identified intensive care records that include notes, laboratory results, and structured events, supporting a wide range of clinical prediction tasks. Building on this resource, recent methods explore weak supervision and domain-adaptive pretraining to mitigate annotation costs. We propose a hierarchical contrastive learning framework that leverages section structure and clinical ontologies for improved phenotyping performance.\n",
    "reason": "First mention of a specific dataset is not accompanied by a citation, which is required for prior resources.",
    "start": 323,
    "end": 340,
    "label": "Unsupported_claim"
  },
  {
    "span": "BERT-based scorers have already achieved over 0.85 QWK on the ASAP dataset.",
    "document": "Introduction\n\nAutomated Essay Scoring (AES) seeks to approximate human ratings to support scalable writing assessment and feedback. Early AES systems relied on handcrafted linguistic and discourse features (Attali and Burstein, 2006), whereas recent neural models learn text representations end to end (Dong and Zhang, 2016; Taghipour and Ng, 2016). Quadratic Weighted Kappa (QWK) is a common agreement metric that emphasizes near-miss penalties among ordinal labels. BERT-based scorers have already achieved over 0.85 QWK on the ASAP dataset. However, performance can drop sharply under prompt shift and adversarial perturbations, motivating robust training objectives and cross-prompt transfer methods.\n",
    "reason": "Makes a quantitative claim about prior results on a named dataset without any supporting citation.",
    "start": 468,
    "end": 543,
    "label": "Unsupported_claim"
  },
  {
    "span": "Sato et al.",
    "document": "Related Work\n\nNeural sequence labeling has evolved from CRF-based pipelines to end-to-end neural architectures. Early approaches relied on handcrafted features and limited context windows (Collobert et al., 2011). With the advent of contextual language models, BiLSTM-CRF models were superseded by Transformer encoders (Vaswani et al., 2017; Devlin et al., 2019). In contrast to earlier heuristics, Sato et al. extend the encoder with span-level attention to better capture entity boundaries, demonstrating consistent gains on CoNLL benchmarks. Subsequent studies explored curriculum and active learning to reduce annotation costs (Shen et al., 2017; Ein-Dor et al., 2020). Our work differs by analyzing calibration under distribution shift.",
    "reason": "Narrative citation is missing the publication year; should be formatted as Sato et al. (YYYY).",
    "start": 399,
    "end": 410,
    "label": "Format"
  },
  {
    "span": "Vatswani et al.",
    "document": "Introduction\n\nGraph neural networks (GNNs) have emerged as a powerful paradigm for learning on relational data, enabling state-of-the-art performance in node classification, link prediction, and graph-level tasks (Kipf and Welling, 2017; Hamilton et al., 2017; Xu et al., 2019). Despite their success, standard message-passing GNNs face limitations when scaling to large graphs and capturing long-range dependencies.\n\nVatswani et al. proposed hierarchical pooling strategies to mitigate over-smoothing and improve scalability, while subsequent work explored positional encodings and global attention to extend the receptive field (Ying et al., 2018; Dwivedi et al., 2021). In this paper, we unify hierarchical and spectral perspectives via multiscale propagation and learn task-adaptive diffusion operators that remain computationally efficient on million-node graphs.\n\nWe evaluate our approach across diverse benchmarks, including citation networks, e-commerce graphs, and molecular property prediction, demonstrating consistent improvements over strong baselines (Shchur et al., 2018; Hu et al., 2020).",
    "reason": "Narrative citation is missing the publication year; it should be formatted as Vatswani et al. (YEAR) rather than just 'Vatswani et al.'.",
    "start": 418,
    "end": 433,
    "label": "Format"
  },
  {
    "span": "[Miller, 2020]",
    "document": "Introduction\n\nSelf-supervised learning has transformed visual representation learning by exploiting pretext tasks and large-scale unlabeled data (He et al., 2020; Chen et al., 2020). Contrastive objectives align augmented views while avoiding collapse (Chen et al., 2020; Grill et al., 2020), and masked image modeling offers a complementary paradigm (Bao et al., 2022; He et al., 2022).\n\nTransfer to downstream tasks such as detection and segmentation depends on invariance design and augmentation breadth (Kolesnikov et al., 2019; Caron et al., 2021). Furthermore, evaluation protocols require careful control of compute and optimizer settings to ensure fair comparison (Musgrave et al., 2020; Kornblith et al., 2019).\n\nAs shown in [Miller, 2020], naive linear probing can misrepresent representation quality under class imbalance. We therefore adopt balanced splits and report both linear and few-shot metrics to contextualize gains (Zhao et al., 2021; Tian et al., 2020).",
    "reason": "Wrong citation bracket style: using square brackets '[Miller, 2020]' in an author–year style context where parentheses '(Miller, 2020)' are expected.",
    "start": 734,
    "end": 748,
    "label": "Format"
  },
  {
    "span": "Most prior approaches rely on lexicon-based features rather than deep representations.",
    "document": "Related Work\n\nSentiment analysis on social media presents unique challenges due to informal language, sarcasm, and domain drift. Early systems used bag-of-words and sentiment lexicons to capture polarity cues, while more recent methods employ word embeddings and transformers. Most prior approaches rely on lexicon-based features rather than deep representations. Complementary research addresses robustness through domain adaptation and debiasing techniques. Despite advances, cross-platform generalization remains an open problem.",
    "reason": "Generalizes about 'most prior approaches' with no citations or evidence.",
    "start": 277,
    "end": 363,
    "label": "Unsupported_claim"
  },
  {
    "span": "many recent works on self-supervised video pretraining",
    "document": "Related Work\n\nEarly approaches to video representation learning relied heavily on supervised training on large-scale labeled datasets, which limited domain transfer and introduced substantial annotation costs. In contrast, self-supervised learning aims to leverage vast unlabeled video corpora to learn temporally coherent and semantically meaningful features. Recently, there have been many recent works on self-supervised video pretraining proposing contrastive, predictive, and masked modeling objectives to learn frame and clip embeddings. While these approaches substantially reduce annotation requirements, their performance can vary widely across domains such as sports, egocentric, and instructional videos. Our work focuses on cross-domain transfer by combining temporal masking with cross-modal alignment signals from audio.\n",
    "reason": "Mentions 'recent works' without providing citations to specific studies, violating the requirement to back up such claims.",
    "start": 387,
    "end": 441,
    "label": "Unsupported_claim"
  },
  {
    "span": "(Garcia et. al., 2019)",
    "document": "Related Work\n\nMultimodal learning exploits complementary signals across text, vision, and audio to improve representation quality (Ngiam et al., 2011; Baltrušaitis et al., 2019). Vision–language pre-training has achieved strong transfer to downstream tasks such as VQA and captioning (Lu et al., 2019; Chen et al., 2020).\n\nAlignment and fusion strategies vary from early concatenation to cross-attention mechanisms (Tsai et al., 2019). Recent studies emphasize modality-robust training under missing or noisy inputs (Garcia et. al., 2019) and propose consistency objectives to stabilize learning (Chen and Li, 2021).\n\nOur method introduces a selective gating module that dynamically reweights modalities based on estimated reliability, improving robustness in the presence of partial observations.",
    "reason": "Incorrect punctuation in the citation: “et. al.” should be “et al.” with no period after “et” and a period after “al.”",
    "start": 516,
    "end": 538,
    "label": "Format"
  },
  {
    "span": "We adopt the MoleculeNet benchmarks as a representative suite for small-molecule property prediction.",
    "document": "Introduction\n\nGraph neural networks (GNNs) have become the standard for molecular property prediction, leveraging message passing over atom–bond graphs to capture local chemical environments. Advances include attention mechanisms, geometric features, and pretraining strategies over large unlabeled compound libraries. We adopt the MoleculeNet benchmarks as a representative suite for small-molecule property prediction. Despite widespread use, there remain inconsistencies in scaffold splitting, hyperparameter tuning, and metric aggregation that complicate fair comparison across models.\n\nThis work proposes a unified evaluation protocol with fixed splits, standardized featurization, and a statistically grounded model selection procedure. We further investigate calibration quality and out-of-distribution robustness using scaffold and temporal splits.",
    "reason": "Introduces a specific benchmark suite at first mention without a citation to its source, violating rule (a).",
    "start": 319,
    "end": 420,
    "label": "Unsupported_claim"
  },
  {
    "span": "[Chen et al., 2019]",
    "document": "Introduction\n\nGraph neural networks (GNNs) generalize convolution to non-Euclidean domains by aggregating neighborhood information (Kipf and Welling, 2017; Hamilton et al., 2017). Variants address over-smoothing and scalability via residual connections, sampling, and attention (Velickovic et al., 2018; Chen et al., 2018; Zou et al., 2019). Pre-training on large heterogeneous graphs has emerged as a promising direction (Hu et al., 2020; You et al., 2020).\n\nDespite progress, distribution shift and spurious correlations hinder generalization to new graphs and tasks (Bevilacqua et al., 2021; Sui et al., 2022). Causal regularization and invariant risk minimization have been proposed to address these issues (Bica et al., 2020; Wu et al., 2022). Robustness to structural perturbations is often evaluated using synthetic attacks and randomized edge drops (Zügner et al., 2018; Rong et al., 2020).\n\nWe explore test-time adaptation with structure-aware normalization that conditions on ego-net distributions. Our method complements attention-based robustness and subgraph training (Frasca et al., 2020; Jin et al., 2020) while requiring no retraining. Prior normalization strategies focus on feature covariate shift [Chen et al., 2019] but overlook degree and motif statistics that drift significantly across domains. We show that adjusting for these structural shifts improves OOD performance without sacrificing in-distribution accuracy.",
    "reason": "Uses square brackets for an author–year citation in a context that otherwise follows parenthetical style; it should be '(Chen et al., 2019)'.",
    "start": 1216,
    "end": 1235,
    "label": "Format"
  },
  {
    "span": "The 2021 WMT shared task introduced a benchmark for Tibetan–English translation.",
    "document": "Introduction\n\nNeural machine translation (NMT) has rapidly advanced translation quality for high-resource language pairs through large-scale pretraining and back-translation (Sennrich et al., 2016; Conneau and Lample, 2019; Liu et al., 2020). However, performance in low-resource and morphologically rich languages remains limited by data scarcity and domain mismatch. Recent work explores multilingual transfer, vocabulary sharing, and data augmentation to bridge these gaps (Johnson et al., 2017; Neubig and Hu, 2018).\n\nCommunity benchmarks have catalyzed progress by standardizing evaluation protocols and datasets through shared tasks such as WMT and IWSLT (Cettolo et al., 2014). The 2021 WMT shared task introduced a benchmark for Tibetan–English translation. While such initiatives are vital, consistent improvements require principled strategies for leveraging monolingual resources and typological priors.\n\nIn this paper, we present a lexicon-guided pretraining pipeline that exploits dictionary constraints during denoising to induce robust cross-lingual representations for extremely low-resource settings. We demonstrate gains on two low-resource pairs and conduct ablations on lexicon coverage and quality.",
    "reason": "This first mention of a specific shared task and benchmark lacks a citation to the task description or dataset, violating the requirement to cite prior tasks and datasets.",
    "start": 685,
    "end": 765,
    "label": "Unsupported_claim"
  },
  {
    "span": "BERT was used in an AES task trained on essays from grades 6-8.",
    "document": "Related Work\n\nAutomated Essay Scoring. Early AES relied on handcrafted features (Attali and Burstein, 2006). Neural approaches replaced feature engineering with CNN/RNN encoders (Taghipour and Ng, 2016; Dong and Zhang, 2016). BERT was used in an AES task trained on essays from grades 6-8. Later work explored multi-aspect scoring and cross-prompt generalization with pre-trained transformers (Ke and Ng, 2019; Uto et al., 2020).",
    "reason": "Claims a specific prior setup (BERT applied to AES on grades 6-8 essays) without citing the study.",
    "start": 226,
    "end": 289,
    "label": "Unsupported_claim"
  },
  {
    "span": "Program synthesis from natural language has been approached with sequence-to-sequence models, grammar-constrained decoding, neuro-symbolic execution guidance, and retrieval-augmented generation (Yin and Neubig, 2017; Rabinovich et al., 2017; Chen et al., 2019; Austin et al., 2021).",
    "document": "Introduction\n\nTranslating natural language specifications into executable programs has applications in end-user programming, data wrangling, and developer productivity. Key challenges include compositional generalization, robustness to ambiguous or underspecified inputs, and alignment with domain-specific language (DSL) constraints.\n\nProgram synthesis from natural language has been approached with sequence-to-sequence models, grammar-constrained decoding, neuro-symbolic execution guidance, and retrieval-augmented generation (Yin and Neubig, 2017; Rabinovich et al., 2017; Chen et al., 2019; Austin et al., 2021). We propose Spec2Plan, which decomposes generation into a latent planning stage followed by constrained realization in the target DSL.\n\nExperiments on three DSLs show improved exact match and execution accuracy, especially on long compositions.\n",
    "reason": "The span describes prior approaches but does not articulate how they relate to or motivate the proposed decomposition; the gap is not made explicit.",
    "start": 336,
    "end": 618,
    "label": "Lacks_synthesis"
  },
  {
    "span": "Typically, the answer tokens are predicted from the model's word-piece vocabulary but here we incorporate the prediction from the entity vocabulary queried by the entity [MASK] token.",
    "document": "Introduction\n\nPretrained language models have become crucial for achieving state-of-the-art performance in modern natural language processing. In particular, multilingual language models (Conneau and Lample, 2019;Conneau et al., 2020a;Doddapaneni et al., 2021) have attracted considerable attention particularly due to their utility in cross-lingual transfer.\n\nIn zero-shot cross-lingual transfer, a pretrained encoder is fine-tuned in a single resource-rich language (typically English), and then evaluated on other languages never seen during fine-tuning. A key to solving cross-lingual transfer tasks is to obtain representations that generalize well across languages. Several studies aim to improve multilingual models with cross-lingual supervision such as bilingual word dictionaries (Conneau et al., 2020b) or parallel sentences (Conneau and Lample, 2019).\n\nAnother source of such information is the crosslingual mappings of Wikipedia entities (articles). Wikipedia entities are aligned across languages via inter-language links and the text contains numerous entity annotations (hyperlinks). With these data, models can learn cross-lingual correspondence such as the words Tokyo and 東京 refers to the same entity. Wikipedia entity annotations have been shown to provide rich cross-lingual alignment information to improve multilingual language models (Iacer Calixto and Pasini, 2021;Xiaoze Jian and Duan, 2021). However, previous studies only incorporate entity information through an auxiliary loss function during pretraining, and the models do not explicitly have entity representations used for downstream tasks.\n\nIn this study, we investigate the effectiveness of entity representations in multilingual language models. Entity representations are known to enhance language models in mono-lingual settings (Zhang et al., 2019;Peters et al., 2019;Xiong et al., 2020;Yamada et al., 2020) presumably by introducing real-world knowledge. We argue that using entity representations facilitates cross-lingual transfer by providing languageindependent features. To this end, we present a multilingual extension of LUKE (Yamada et al., 2020). The model is trained with the multilingual masked language modeling (MLM) task as well as the masked entity prediction (MEP) task with Wikipedia entity embeddings.\n\nWe investigate two ways of using the entity representations in cross-lingual transfer tasks: (1) perform entity linking for the input text, and append the detected entity tokens to the input sequence. The entity tokens are expected to provide languageindependent features to the model. We evaluate this approach with cross-lingual question answering (QA) datasets: XQuAD (Artetxe et al., 2020) and MLQA ; (2) use the entity [MASK] token from the MEP task as a language-independent feature extractor. In the MEP task, word tokens in a mention span are associated with an entity [MASK] token, the contextualized representation of which is used to train the model to predict its original identity. Here, we apply similar input formulations to tasks involving mention-span classification, relation extraction (RE) and named entity recognition (NER): the attribute of a mention or a pair of mentions is predicted using their contextualized entity [MASK] feature. We evaluate this approach with the RELX (Köksal and Özgür, 2020) and CoNLL NER (Tjong Kim Sang, 2002;Tjong Kim Sang and De Meulder, 2003) datasets.\n\nThe experimental results show that these entitybased approaches consistently outperform wordbased baselines. Our analysis reveals that entity representations provide more language-agnostic features to solve the downstream tasks.\n\nWe also explore solving a multilingual zero-shot cloze prompt task  with the entity [MASK] token. Recent studies have shown that we can address various downstream tasks by querying a language model for blanks in prompts (Petroni et al., 2019;Cui et al., 2021). Typically, the answer tokens are predicted from the model's word-piece vocabulary but here we incorporate the prediction from the entity vocabulary queried by the entity [MASK] token. We evaluate our approach with the mLAMA dataset (Kassner et al., 2021) in various languages and show that using the entity [MASK] token reduces language bias and elicits correct factual knowledge more likely than using only the word [MASK] token.\n\n ",
    "start": 3909,
    "end": 4092,
    "label": "Unsupported_claim"
  },
  {
    "span": "[23]",
    "document": "Introduction\n\nBenchmark suites have accelerated progress in information extraction by providing consistent evaluation protocols. Earlier benchmarks used rule-based pipelines [23] that coupled sentence parsing with handcrafted templates, while more recent collections emphasize end-to-end neural models (Lample et al., 2016; Peters et al., 2018). We adopt the author–year style throughout this paper to facilitate readability and disambiguation.\n\nOur new dataset introduces balanced event types and reduces lexical overlap between train and test to better assess generalization.",
    "reason": "Numeric bracket citation is inconsistent with the author–year citation style used elsewhere in the document.",
    "start": 174,
    "end": 178,
    "label": "Format"
  },
  {
    "span": "(Smith et al., 2018; Jones, 2019.",
    "document": "Introduction\n\nGraph neural networks have become a central paradigm for learning over relational data, enabling state-of-the-art results in chemistry, recommendation, and social analysis. Recent surveys (Smith et al., 2018; Jones, 2019. highlight the growth of architectures that propagate and transform information over nodes and edges while preserving permutation invariance. However, a persistent challenge is understanding when the added complexity of deeper message passing yields tangible gains. Early work focused on spectral methods for convolution on graphs (Defferrard et al., 2016) and localized filters (Hamilton et al., 2017), while later studies explored scaling to large graphs with sampling and pruning strategies (Chen et al., 2018; Chiang et al., 2019).\n\nIn this paper, we revisit the bias-variance trade-offs inherent to deeper propagation and propose a simple benchmark for disentangling the effects of depth, width, and normalization. We also present a unified training recipe that stabilizes optimization across architectures.",
    "reason": "Missing closing parenthesis in the multi-citation; it should be '(Smith et al., 2018; Jones, 2019)'.",
    "start": 202,
    "end": 235,
    "label": "Format"
  },
  {
    "span": "RoBERTa-large was used in an automated essay scoring task trained on TOEFL11 essays.",
    "document": "Related Work\n\nAutomated essay scoring (AES) leverages both handcrafted features and neural representations to predict holistic and trait-specific writing quality (Shermis and Burstein, 2013; Taghipour and Ng, 2016; Dong and Zhang, 2016). Pretrained language models have improved robustness to topic drift and style variation in AES, particularly under limited supervision (Uto et al., 2020; Rodriguez et al., 2021).\n\nRoBERTa-large was used in an automated essay scoring task trained on TOEFL11 essays.\n\nWe extend prior approaches with compositional calibration across prompts and assess transfer to unseen proficiency distributions with stratified metrics.",
    "reason": "References a specific model-dataset setup (RoBERTa-large on TOEFL11) without citing a source; first mention of a dataset and prior setup requires citation.",
    "start": 417,
    "end": 501,
    "label": "Unsupported_claim"
  },
  {
    "span": "In a previous study, the authors reported a 12% absolute gain using attention gates.",
    "document": "Related Work\n\nMedical image segmentation has been dominated by encoder-decoder architectures such as U-Net and its variants. Extensions have explored multi-scale feature aggregation, residual connections, and attention mechanisms to refine boundary localization and suppress false positives. In a previous study, the authors reported a 12% absolute gain using attention gates. While attention has shown promise, its effectiveness varies with organ shape variability and imaging modality, motivating more principled approaches to spatial context modeling.\n\nRecent literature also investigates self-supervised pretraining on large unlabeled cohorts, arguing that representation quality is the primary bottleneck. We situate our method in this landscape by combining lightweight attention with topology-aware losses designed for small, tortuous structures.",
    "reason": "Refers to a specific prior study and quantitative result but provides no citation (definition a and b).",
    "start": 292,
    "end": 376,
    "label": "Unsupported_claim"
  },
  {
    "span": "(Olsen, et al., 2017)",
    "document": "Introduction\n\nTopic modeling for short texts remains challenging due to sparsity and context fragmentation. Neural topic models (Olsen, et al., 2017) have been explored to incorporate word embeddings and amortized inference. Subsequent work improved coherence through prior smoothing and contrastive objectives (Miao et al., 2017; Dieng et al., 2020).\n\nWe revisit amortized inference with stability-focused training and present a robustness analysis under vocabulary shift.",
    "reason": "Improper comma before 'et al.' in an author–year citation; standard style omits the comma: '(Olsen et al., 2017)'.",
    "start": 128,
    "end": 149,
    "label": "Format"
  },
  {
    "span": "The widely used SQuAD dataset has significant annotation artifacts that models exploit.",
    "document": "Introduction\n\nMachine reading comprehension benchmarks have driven rapid progress in extractive and generative question answering. The widely used SQuAD dataset has significant annotation artifacts that models exploit. As a result, improvements on leaderboards are not always indicative of genuine reasoning abilities. This motivates our focus on adversarial evaluation and causal analysis of model behavior.",
    "reason": "Mentions a specific dataset and asserts a known issue without citing supporting studies; per rules (a) and (b), this requires evidence.",
    "start": 131,
    "end": 218,
    "label": "Unsupported_claim"
  },
  {
    "span": "several shared tasks have standardized evaluation for KG-aware recommendation",
    "document": "Related Work\n\nIncorporating knowledge graphs (KGs) into recommender systems has been shown to improve transparency and alleviate data sparsity. Early work injected path-based features into factorization models, while recent methods employ graph neural networks to propagate high-order semantic signals. To facilitate comparison, several shared tasks have standardized evaluation for KG-aware recommendation, focusing on link prediction over user–item–entity graphs and cold-start generalization.\n\nDespite stronger accuracy, deploying KG-enhanced recommenders introduces latency constraints due to neighborhood expansion and feature joins at inference time. Current research explores lightweight propagation, caching strategies, and distillation from graph encoders into ID-based rankers. Our work contributes a training recipe that preserves interpretability while meeting strict latency budgets.",
    "reason": "Claims the existence of multiple shared tasks that standardized evaluation without citing any of the tasks or competitions.",
    "start": 329,
    "end": 406,
    "label": "Unsupported_claim"
  },
  {
    "span": "A prior dataset pairs programming problems with unit tests for Python and Java.",
    "document": "Introduction\n\nProgram synthesis from natural language has benefited from large code corpora and advances in transformer decoders. Evaluations typically involve generating a function that satisfies a textual specification or docstring and verifying functional correctness using hidden tests. A prior dataset pairs programming problems with unit tests for Python and Java. However, discrepancies in test coverage and problem ambiguity complicate reliable measurement. We propose a new benchmark with standardized specifications, richer public tests for debugging, and adversarial holdout suites to reduce overfitting to test distributions.\n",
    "reason": "References a specific prior dataset without naming or citing it (violates rule a).",
    "start": 291,
    "end": 370,
    "label": "Unsupported_claim"
  },
  {
    "span": "Most studies report Dice scores below 70% for the pancreas in multi-organ CT settings.",
    "document": "Introduction\n\nAutomatic segmentation of abdominal organs in computed tomography (CT) is a prerequisite for quantitative analysis and preoperative planning. While large, high-contrast structures like the liver are relatively straightforward, the pancreas poses unique challenges due to its small size, variable shape, and low boundary contrast. Multi-organ joint models promise shared context but must avoid overshadowing small, hard targets.\n\nMost studies report Dice scores below 70% for the pancreas in multi-organ CT settings.\n\nTo address these issues, we propose a cascaded architecture with uncertainty-aware refinement focused on small structures, combined with a topology-preserving loss that regularizes boundary predictions.",
    "reason": "Provides a quantitative performance claim about prior literature without citing any sources or evidence (violates rule b).",
    "start": 443,
    "end": 529,
    "label": "Unsupported_claim"
  },
  {
    "span": "Recent multimodal misinformation detection methods fuse textual cues with images (Jin et al., 2017; Khattar et al., 2019; Qi et al., 2021), incorporate social network signals such as propagation trees and user features (Shu et al., 2019; Wu et al., 2020), leverage knowledge graphs for entity grounding (Zhou et al., 2020; Cui et al., 2020), and extend to video via audio-visual alignment (Aneja et al., 2021; Li et al., 2021). Pre-trained transformers are widely adopted for cross-modal fusion (Lu et al., 2019; Chen et al., 2020).",
    "document": "Related Work\n\nMisinformation detection has evolved from binary veracity prediction on article text to multimodal, network-aware modeling. Incorporating multiple signals is crucial due to style transfer, paraphrase, and adversarial manipulation.\n\nRecent multimodal misinformation detection methods fuse textual cues with images (Jin et al., 2017; Khattar et al., 2019; Qi et al., 2021), incorporate social network signals such as propagation trees and user features (Shu et al., 2019; Wu et al., 2020), leverage knowledge graphs for entity grounding (Zhou et al., 2020; Cui et al., 2020), and extend to video via audio-visual alignment (Aneja et al., 2021; Li et al., 2021). Pre-trained transformers are widely adopted for cross-modal fusion (Lu et al., 2019; Chen et al., 2020).\n\nDatasets increasingly include manipulated imagery and cross-platform posts, but label quality, temporal drift, and domain transfer remain open issues. We investigate temporally robust detection via time-aware contrastive pretraining that aligns content and context under evolving memes.",
    "reason": "The span summarizes prior work and tools but does not clarify how they relate to the paper’s approach or what gap remains, meeting (a) and (c).",
    "start": 246,
    "end": 778,
    "label": "Lacks_synthesis"
  },
  {
    "span": "Fairness in language models has been evaluated with metrics such as WEAT and SEAT (Caliskan et al., 2017; May et al., 2019), bias probes (Kurita et al., 2019), and downstream parity measures (Borkan et al., 2019). Debiasing techniques include counterfactual data augmentation (Zmigrod et al., 2019), adversarial training (Zhang et al., 2018), and representation projection (Bolukbasi et al., 2016).",
    "document": "Introduction\n\nLarge language models can encode and amplify harmful social biases, necessitating methods to measure and mitigate disparate performance and offensive outputs across demographic groups.\n\nFairness in language models has been evaluated with metrics such as WEAT and SEAT (Caliskan et al., 2017; May et al., 2019), bias probes (Kurita et al., 2019), and downstream parity measures (Borkan et al., 2019). Debiasing techniques include counterfactual data augmentation (Zmigrod et al., 2019), adversarial training (Zhang et al., 2018), and representation projection (Bolukbasi et al., 2016).\n\nWe later introduce group-conditional calibration and evaluate on multilingual toxicity detection. However, we first formalize a setting with label shift and skewed group priors.\n",
    "reason": "Violates (a) and (c): enumerates metrics and methods without articulating the authors' viewpoint, the gap, or how these works inform the proposed approach.",
    "start": 200,
    "end": 598,
    "label": "Lacks_synthesis"
  },
  {
    "span": "Forecasting models capture seasonality and trend (Hyndman and Athanasopoulos, 2018). Density estimation identifies outliers in latent space (An and Cho, 2015). Change-point detection locates distributional shifts (Truong et al., 2020). Streaming systems handle high-velocity data (Babcock et al., 2002).",
    "document": "Introduction\n\nTime series anomaly detection is crucial in operations, finance, and healthcare. Practical solutions must reconcile forecasting uncertainty, multivariate dependencies, and streaming constraints.\n\nForecasting models capture seasonality and trend (Hyndman and Athanasopoulos, 2018). Density estimation identifies outliers in latent space (An and Cho, 2015). Change-point detection locates distributional shifts (Truong et al., 2020). Streaming systems handle high-velocity data (Babcock et al., 2002).\n\nWe propose a unified probabilistic scoring framework that separates predictable dynamics from residual anomalies and supports bounded-delay streaming inference.",
    "reason": "The span juxtaposes forecasting, density estimation, change-point detection, and streaming systems without explaining their relationships, leading to abrupt topic shifts and weak coherence.",
    "start": 210,
    "end": 513,
    "label": "Coherence"
  },
  {
    "span": "(Miller, 2017 Zhang and Li, 2018)",
    "document": "Related Work\n\nSelf-training extends labeled sets with model-predicted pseudo-labels, often with confidence thresholds or augmentation-based agreement (Xie et al., 2020; Sohn et al., 2020). For semi-supervised parsing, consistency losses encourage stable outputs across noise processes (Clark et al., 2018). Recent work in speech extends this idea to sequence-level perturbations (Baevski et al., 2020). In NLP, studies report that agreement-based filtering reduces confirmation bias (Arazo et al., 2020). Prior analyses on label quality show a trade-off between coverage and precision (Miller, 2017 Zhang and Li, 2018), which motivates our dynamic thresholding scheme.",
    "reason": "Missing separator between multiple citations inside the same parentheses; should include a semicolon between them.",
    "start": 585,
    "end": 618,
    "label": "Format"
  },
  {
    "span": "The widely used XSum dataset contains 226,711 document–summary pairs.",
    "document": "Related Work Abstractive summarization has benefited from self-supervised pretraining and large-scale datasets for news and dialogue (See et al., 2017; Lewis et al., 2020). However, factual consistency and faithfulness remain major concerns, motivating research on constrained decoding and retrieval-augmented generation (Zhang et al., 2020; Kryscinski et al., 2020). The widely used XSum dataset contains 226,711 document–summary pairs. We focus on extreme summarization in low-resource domains and study cross-domain transfer.",
    "reason": "Presents a specific dataset statistic without a supporting citation, violating rule (b).",
    "start": 368,
    "end": 437,
    "label": "Unsupported_claim"
  },
  {
    "span": "sentiment analysis (SST movie reviews)",
    "document": "Introduction\n\nThe usefulness of learned self-attention functions often correlates with how well it aligns with human attention (Das et al., 2016;Klerke et al., 2016;Barrett et al., 2018;Klerke and Plank, 2019). In this paper, we evaluate how well attention flow (Abnar and Zuidema, 2020) in large language models, namely BERT (Devlin et al., 2019), RoBERTa (Liu et al., 2019) and T5 (Raffel et al., 2020), aligns with human eye fixations during task-specific reading, compared to other shallow sequence labeling models (Lecun and Bengio, 1995;Vaswani et al., 2017) and a classic, heuristic model of human reading (Reichle et al., 2003). We compare the learned attention functions and the heuristic model across two task-specific English reading tasks, namely sentiment analysis (SST movie reviews) and relation extraction (Wikipedia), as well as natural reading, using a publicly available data set with eye-tracking recordings of native speakers of English (Hollenstein et al., 2018).\n\nContributions We compare human and model attention patterns on both sentiment reading and relation extraction tasks. In our analysis, we compare human attention to pre-trained Transformers (BERT, RoBERTa and T5), from-scratch training of two shallow sequence labeling architectures (Lecun and Bengio, 1995; Vaswani et al., 2017), as well as to a frequency baseline and a heuristic, cognitively inspired model of human reading called the E-Z Reader (Reichle et al., 2003). We find that the heuristic model correlates well with human reading, as has been reported in Sood et al. (2020b). However when we apply attention flow (Abnar and Zuidema, 2020), the pre-trained Transformer models also reach comparable levels of correlation strength. Further fine-tuning experiments on BERT did not result in increased correlation to human fixations. To understand what drives the differences between models, we perform an in-depth analysis of the effect of word predictability and POS tags on correlation strength. It reveals that Transformer models do not accurately capture tail phenomena for hard-to-predict words (in contrast to the E-Z Reader) and that Transformer attention flow shows comparably weak correlation on (proper) nouns while the E-Z Reader predicts importance of these more accurately, especially on the sentiment reading task. In addition we investigate a subset of the ZuCo corpus for which aligned task-specific and natural reading data is available and find that Transformers correlate stronger to natural reading patterns. But how faithful are these different attention patterns at producing correct task-classification on a state-of-the-art NLP model? We test this via an input reduction experiment on task-tuned BERT models which highlights the trade-off between a model’s faithfulness and sparsity when comparing importance scores to human attention, i.e., less sparse (higher entropy) attention vectors seem to be less faithful with respect to model predictions. Our code is available at github.com/anon.\n\n ",
    "start": 760,
    "end": 797,
    "label": "Unsupported_claim"
  },
  {
    "span": "relation extraction (Wikipedia)",
    "document": "Introduction\n\nThe usefulness of learned self-attention functions often correlates with how well it aligns with human attention (Das et al., 2016;Klerke et al., 2016;Barrett et al., 2018;Klerke and Plank, 2019). In this paper, we evaluate how well attention flow (Abnar and Zuidema, 2020) in large language models, namely BERT (Devlin et al., 2019), RoBERTa (Liu et al., 2019) and T5 (Raffel et al., 2020), aligns with human eye fixations during task-specific reading, compared to other shallow sequence labeling models (Lecun and Bengio, 1995;Vaswani et al., 2017) and a classic, heuristic model of human reading (Reichle et al., 2003). We compare the learned attention functions and the heuristic model across two task-specific English reading tasks, namely sentiment analysis (SST movie reviews) and relation extraction (Wikipedia), as well as natural reading, using a publicly available data set with eye-tracking recordings of native speakers of English (Hollenstein et al., 2018).\n\nContributions We compare human and model attention patterns on both sentiment reading and relation extraction tasks. In our analysis, we compare human attention to pre-trained Transformers (BERT, RoBERTa and T5), from-scratch training of two shallow sequence labeling architectures (Lecun and Bengio, 1995; Vaswani et al., 2017), as well as to a frequency baseline and a heuristic, cognitively inspired model of human reading called the E-Z Reader (Reichle et al., 2003). We find that the heuristic model correlates well with human reading, as has been reported in Sood et al. (2020b). However when we apply attention flow (Abnar and Zuidema, 2020), the pre-trained Transformer models also reach comparable levels of correlation strength. Further fine-tuning experiments on BERT did not result in increased correlation to human fixations. To understand what drives the differences between models, we perform an in-depth analysis of the effect of word predictability and POS tags on correlation strength. It reveals that Transformer models do not accurately capture tail phenomena for hard-to-predict words (in contrast to the E-Z Reader) and that Transformer attention flow shows comparably weak correlation on (proper) nouns while the E-Z Reader predicts importance of these more accurately, especially on the sentiment reading task. In addition we investigate a subset of the ZuCo corpus for which aligned task-specific and natural reading data is available and find that Transformers correlate stronger to natural reading patterns. But how faithful are these different attention patterns at producing correct task-classification on a state-of-the-art NLP model? We test this via an input reduction experiment on task-tuned BERT models which highlights the trade-off between a model’s faithfulness and sparsity when comparing importance scores to human attention, i.e., less sparse (higher entropy) attention vectors seem to be less faithful with respect to model predictions. Our code is available at github.com/anon.\n\n ",
    "start": 803,
    "end": 833,
    "label": "Unsupported_claim"
  },
  {
    "span": "the ZuCo corpus",
    "document": "Introduction\n\nThe usefulness of learned self-attention functions often correlates with how well it aligns with human attention (Das et al., 2016;Klerke et al., 2016;Barrett et al., 2018;Klerke and Plank, 2019). In this paper, we evaluate how well attention flow (Abnar and Zuidema, 2020) in large language models, namely BERT (Devlin et al., 2019), RoBERTa (Liu et al., 2019) and T5 (Raffel et al., 2020), aligns with human eye fixations during task-specific reading, compared to other shallow sequence labeling models (Lecun and Bengio, 1995;Vaswani et al., 2017) and a classic, heuristic model of human reading (Reichle et al., 2003). We compare the learned attention functions and the heuristic model across two task-specific English reading tasks, namely sentiment analysis (SST movie reviews) and relation extraction (Wikipedia), as well as natural reading, using a publicly available data set with eye-tracking recordings of native speakers of English (Hollenstein et al., 2018).\n\nContributions We compare human and model attention patterns on both sentiment reading and relation extraction tasks. In our analysis, we compare human attention to pre-trained Transformers (BERT, RoBERTa and T5), from-scratch training of two shallow sequence labeling architectures (Lecun and Bengio, 1995; Vaswani et al., 2017), as well as to a frequency baseline and a heuristic, cognitively inspired model of human reading called the E-Z Reader (Reichle et al., 2003). We find that the heuristic model correlates well with human reading, as has been reported in Sood et al. (2020b). However when we apply attention flow (Abnar and Zuidema, 2020), the pre-trained Transformer models also reach comparable levels of correlation strength. Further fine-tuning experiments on BERT did not result in increased correlation to human fixations. To understand what drives the differences between models, we perform an in-depth analysis of the effect of word predictability and POS tags on correlation strength. It reveals that Transformer models do not accurately capture tail phenomena for hard-to-predict words (in contrast to the E-Z Reader) and that Transformer attention flow shows comparably weak correlation on (proper) nouns while the E-Z Reader predicts importance of these more accurately, especially on the sentiment reading task. In addition we investigate a subset of the ZuCo corpus for which aligned task-specific and natural reading data is available and find that Transformers correlate stronger to natural reading patterns. But how faithful are these different attention patterns at producing correct task-classification on a state-of-the-art NLP model? We test this via an input reduction experiment on task-tuned BERT models which highlights the trade-off between a model’s faithfulness and sparsity when comparing importance scores to human attention, i.e., less sparse (higher entropy) attention vectors seem to be less faithful with respect to model predictions. Our code is available at github.com/anon.\n\n ",
    "start": 2362,
    "end": 2376,
    "label": "Unsupported_claim"
  },
  {
    "span": "Recent works demonstrate that prompt tuning consistently outperforms full fine-tuning on low-resource NER.",
    "document": "Introduction\nParameter-efficient transfer learning has become a central theme in modern NLP, with approaches such as adapters, low-rank updates, and prompt-based methods seeking to reduce computational overhead while preserving accuracy. These techniques are particularly attractive in settings where task-specific labeled data are scarce and models must be adapted frequently.\n\nRelated Work\nPrompt-based learning repurposes frozen language models by steering behavior through task-specific instructions or learned prompts. Compared to full fine-tuning, these methods modify a much smaller number of parameters while retaining strong performance. Recent works demonstrate that prompt tuning consistently outperforms full fine-tuning on low-resource NER. Despite a growing body of scholarship on prompts, evaluation protocols and data splits across named entity recognition benchmarks vary widely, making direct comparisons challenging. Our study focuses on disentangling the contribution of label space size and tokenization effects under a unified evaluation protocol for low-resource NER.",
    "reason": "Claims about 'recent works' and comparative performance require citations; the first mention of evidence that prompt tuning outperforms full fine-tuning lacks references (violates d and a).",
    "start": 647,
    "end": 753,
    "label": "Unsupported_claim"
  },
  {
    "span": "(2018, Chen et al.)",
    "document": "Related Work\n\nLearned indexes replace static data structures with models that map keys to approximate positions, reducing lookup latency for skewed workloads (Kraska et al., 2018; Ding et al., 2020). While early designs focused on read-only settings, more recent work explores dynamic updates and concurrency control to support production environments. For example, (2018, Chen et al.) propose a hierarchical model index with adaptive error bounds, but do not address multi-tenant interference under mixed read/write loads. Subsequent work introduces calibration layers to bound errors across shifting key distributions (Marcus et al., 2020).\n\nOur approach complements these efforts by combining error-aware routing with lightweight online retraining to sustain predictable latency under bursty traffic.",
    "reason": "Wrong author–year order in a parenthetical citation; should be '(Chen et al., 2018)'.",
    "start": 366,
    "end": 385,
    "label": "Format"
  },
  {
    "span": "The Atari 2600 suite has been solved by model-free methods at or above human performance on most games.",
    "document": "Related Work\n\nThe Atari 2600 benchmark has long served as a testbed for generalization and sample efficiency in deep reinforcement learning. Value-based methods with experience replay popularized the use of high-capacity function approximators for discrete control, while actor-critic algorithms improved stability and exploration in continuous settings. Model-based approaches have more recently revisited planning with learned dynamics to improve data efficiency, although scaling them remains challenging. The Atari 2600 suite has been solved by model-free methods at or above human performance on most games. Despite these advances, training remains data-intensive, and performance varies widely across titles with sparse rewards or deceptive dynamics. Our work targets this regime by introducing a return-conditioned exploration prior that adapts to reward sparsity without additional supervision.",
    "reason": "Makes a broad claim about prior results on a standard benchmark without citing supporting studies.",
    "start": 509,
    "end": 612,
    "label": "Unsupported_claim"
  },
  {
    "span": "(Brooks, 2016)).",
    "document": "Related Work\n\nGraph neural networks unify message passing with spectral methods to learn from relational structure (Kipf and Welling, 2017; Hamilton et al., 2017). Early over-smoothing analyses motivated residual connections and normalization layers (Li et al., 2018; Oono and Suzuki, 2020). Several sampling strategies reduce training cost for large graphs while preserving accuracy (Chen et al., 2018; Zeng et al., 2019). We situate our work within prior analyses of inductive bias in hierarchical pooling (Brooks, 2016)). and propose a curvature-aware pooling operator that mitigates information loss.",
    "reason": "Extra closing parenthesis after the citation; should end with a single “)”.",
    "start": 508,
    "end": 524,
    "label": "Format"
  },
  {
    "span": "Chen et al. 1",
    "document": "Related Work\n\nFeedback-efficient learning has leveraged weak supervision, distillation, and semi-supervision to reduce labeling needs. Early studies by Chen et al. 1 explored interactive labeling interfaces for span selection, showing that lightweight feedback can substantially improve coverage. Later, weak supervision frameworks combined heuristics and knowledge bases to generate pseudo-labels (Saab and Kumar, 2019), while self-training stabilized performance with confidence filtering (Ortiz et al., 2020). We extend this line by using minimal binary feedback as a reinforcement signal for extractive QA.",
    "reason": "Improper footnote-style marker used in place of a citation year; should include a year (e.g., \"Chen et al. (2017)\") or be formatted as a proper footnote.",
    "start": 152,
    "end": 165,
    "label": "Format"
  },
  {
    "span": "Recent works show transformer-based detectors surpass CNN architectures on small object detection in aerial imagery.",
    "document": "Related Work\n\nObject detection in aerial imagery poses unique challenges, including extreme scale variation, densely packed instances, and viewpoint changes. Traditional two-stage detectors benefited from region proposal mechanisms and strong localization priors, while one-stage models emphasized speed and end-to-end optimization. With the advent of attention mechanisms, detection architectures increasingly incorporate global context aggregation to better capture small, far-apart cues essential for remote sensing scenes. Recent works show transformer-based detectors surpass CNN architectures on small object detection in aerial imagery. Despite these advances, label noise, domain shifts across sensors, and the scarcity of fine-grained instance annotations limit generalization. Complementary strands of research have explored multi-scale feature fusion, deformable sampling, and oriented bounding boxes tailored to rotational variance. In parallel, self-supervised pretraining on unlabeled satellite tiles and pseudo-labeling pipelines have been proposed to reduce annotation burdens. Our study focuses on the interplay between multiscale attention and oriented localization, presenting an analysis across varying ground sampling distances and object densities.",
    "reason": "Uses the phrase \"Recent works\" and asserts a performance comparison without citing any sources; such claims require citations (rules a and d).",
    "start": 527,
    "end": 643,
    "label": "Unsupported_claim"
  },
  {
    "span": "A number of public benchmarks exist for lesion segmentation, such as BraTS and ISIC, which have standardized evaluation protocols.",
    "document": "Introduction\n\nMedical image segmentation is foundational for computer-aided diagnosis and treatment planning. Deep convolutional networks and, more recently, vision transformers have delivered significant gains in delineating anatomical structures and pathological regions. A number of public benchmarks exist for lesion segmentation, such as BraTS and ISIC, which have standardized evaluation protocols. Despite these resources, domain shift across scanners, institutions, and patient populations continues to hinder generalization.\n\nWe address this challenge by introducing a domain-adaptive training regime that regularizes feature distribution alignment while preserving fine-grained boundaries. Our method uses a dual-head architecture and a curriculum of augmentations simulating scanner variability. We evaluate on multi-site MRI and dermoscopy datasets under cross-domain splits and report improvements in Dice and Hausdorff distance.\n\nBeyond accuracy, we analyze calibration and uncertainty estimates to better characterize model reliability in clinical workflows.",
    "reason": "Mentions specific datasets/benchmarks (BraTS and ISIC) without citing their corresponding references.",
    "start": 274,
    "end": 404,
    "label": "Unsupported_claim"
  },
  {
    "span": " (Nguyen et al., 2018; Lee and Kim, 2020;,",
    "document": "Introduction\n\nGraph neural networks (GNNs) have become a primary tool for learning over structured data, enabling advances in node classification, link prediction, and graph-level reasoning. Early convolutional variants propagate neighborhood information with learned filters to capture local structure, while more recent architectures incorporate attention and positional features to model long-range dependencies. Recent surveys summarize these trends (Nguyen et al., 2018; Lee and Kim, 2020;, highlighting open challenges in scalability and dynamic graph modeling. In parallel, benchmarks have evolved to include heterogeneous and temporal graphs, reflecting real-world constraints and richer semantics. Despite considerable progress, questions remain about inductive generalization across graphs and the stability of training procedures under distribution shift, as noted by prior empirical studies (Patel and Rao, 2019; Zhou et al., 2021).",
    "reason": "Citation group has a dangling comma and a missing closing parenthesis; it should be formatted as a complete parenthetical list, e.g., “(Nguyen et al., 2018; Lee and Kim, 2020)” without the trailing comma.",
    "start": 453,
    "end": 495,
    "label": "Format"
  },
  {
    "span": "In prior competitions, sim-to-real transfer often fails without domain randomization",
    "document": "Introduction\n\nBridging the gap between simulation and reality is a central challenge in robot learning. Simulators provide cheap, safe data, but policies trained purely in sim can degrade when deployed on physical robots due to unmodeled dynamics and sensor noise.\n\nIn prior competitions, sim-to-real transfer often fails without domain randomization. This observation has motivated techniques that randomize physics and rendering parameters during training to improve robustness at deployment.\n\nWe revisit this hypothesis by systematically varying randomization dimensions and measuring transfer on manipulation tasks. Our results show that targeted randomizations can outperform blanket schemes while reducing training instability.\n",
    "reason": "Refers to 'prior competitions' and asserts a failure mode without citing any competitions or studies; per rule (a) and (b), such claims require citations.",
    "start": 266,
    "end": 350,
    "label": "Unsupported_claim"
  },
  {
    "span": "Metric-based methods learn an embedding space where nearest neighbors determine class labels (Vinyals et al., 2016; Snell et al., 2017). Optimization-based approaches adapt model parameters with a few gradient steps (Finn et al., 2017). Data augmentation synthesizes additional samples via hallucination or generative models (Hariharan and Girshick, 2017; Wang et al., 2018). Semi-supervised variants exploit unlabeled support examples (Ren et al., 2018).",
    "document": "Related Work\n\nFew-Shot Learning\nLearning from limited labeled data has spurred methods that transfer inductive biases from base classes or leverage auxiliary objectives to improve generalization to novel classes (Chen et al., 2019). Two major paradigms are metric-based classification and rapid adaptation.\n\nParadigms and Extensions\nMetric-based methods learn an embedding space where nearest neighbors determine class labels (Vinyals et al., 2016; Snell et al., 2017). Optimization-based approaches adapt model parameters with a few gradient steps (Finn et al., 2017). Data augmentation synthesizes additional samples via hallucination or generative models (Hariharan and Girshick, 2017; Wang et al., 2018). Semi-supervised variants exploit unlabeled support examples (Ren et al., 2018). More recent work explores transductive inference and task-conditioned normalization to reduce query-support shift (Liu et al., 2019; Oreshkin et al., 2018).\n\nBenchmarks\nEpisode-based evaluation on miniImageNet, tieredImageNet, and Meta-Dataset provides standardized comparisons, though distributional shift and class imbalance remain challenges (Triantafillou et al., 2019).",
    "reason": "The span presents several categories of few-shot methods in isolation without transitions or clarifying how they relate or differ, resulting in an abrupt, incoherent sequence of citations.",
    "start": 333,
    "end": 788,
    "label": "Coherence"
  },
  {
    "span": "Hardt et al. (2016) defined equalized odds for fair classification. Kleinberg et al. (2017) proved impossibility results for fairness metrics. Mitchell et al. (2019) proposed model cards for transparency. Buolamwini and Gebru (2018) studied gender and skin-type bias in face recognition.",
    "document": "Related Work\n\nAlgorithmic fairness encompasses a variety of criteria and auditing practices intended to assess and mitigate harms across demographic groups (Barocas et al., 2019). Approaches span pre-, in-, and post-processing, as well as documentation frameworks that promote transparency (Zemel et al., 2013; Raji et al., 2020).\n\nHardt et al. (2016) defined equalized odds for fair classification. Kleinberg et al. (2017) proved impossibility results for fairness metrics. Mitchell et al. (2019) proposed model cards for transparency. Buolamwini and Gebru (2018) studied gender and skin-type bias in face recognition.\n\nAlthough these strands inform practice, their integration into end-to-end auditing pipelines for multimodal systems remains limited. We present a modular auditor that unifies metric diagnostics with dataset statements and group-conditional error analysis under distribution shift.",
    "reason": "The cited works cover metrics, impossibility, documentation, and bias audits but are listed without connective explanations or transitions indicating how they relate, resulting in an abrupt, low-coherence sequence.",
    "start": 332,
    "end": 619,
    "label": "Coherence"
  },
  {
    "span": "Vastwani et al. 1",
    "document": "Introduction\n\nModern recommender systems must balance personalization with fairness and transparency constraints (Ricci et al., 2015; Ekstrand et al., 2022). Recent studies emphasize user-controllable objectives and counterfactual evaluation protocols to mitigate bias while preserving accuracy (Bonner and Vasile, 2018; Schnabel et al., 2016).\n\nSeveral early hybrid models combined collaborative filtering with content features to address cold-start conditions; see Vastwani et al. 1 for a comprehensive overview of hybridization strategies and their empirical trade-offs. More recent approaches incorporate causal inference to disentangle exposure from preference signals (Saito, 2020; Wang et al., 2020).\n\nWe build on this foundation by proposing a propensity-aware ranking objective that unifies debiasing and calibration within a single training procedure.",
    "reason": "Wrong use of footnotes/citation: an author string followed by a bare footnote number lacks year and proper formatting; it should be a standard citation with year (e.g., 'Vastwani et al. (2018)') or a properly formatted footnote.",
    "start": 467,
    "end": 484,
    "label": "Format"
  },
  {
    "span": "BERT was used in an AES task trained on essays from multiple prompts.",
    "document": "Introduction\n\nAutomated essay scoring (AES) systems aim to predict holistic or trait-specific scores that agree with human raters. Traditional AES models rely on carefully engineered features such as discourse structure, lexical complexity, and error rates. With the advent of pretrained language models, researchers have explored fine-tuning contextual encoders on scored essays to capture semantic and syntactic cues jointly. BERT was used in an AES task trained on essays from multiple prompts. Despite improved correlations with human scores, concerns remain regarding fairness across demographics and susceptibility to adversarial input.",
    "reason": "Mentions a specific prior setup (BERT used in AES with multiple prompts) without any citation (example iii, rule a/b).",
    "start": 428,
    "end": 497,
    "label": "Unsupported_claim"
  },
  {
    "span": "Classical decomposition separates trend and seasonality in time series (Cleveland et al., 1990). Transformers capture long-range dependencies via self-attention (Zhou et al., 2021). Industrial anomaly detection benefits from modeling forecasting residuals (Audibert et al., 2020).",
    "document": "Introduction\n\nForecasting long-horizon, multivariate time series is essential for capacity planning and anomaly detection. Traditional statistical methods such as ARIMA and STL provide interpretable decompositions but struggle with complex cross-series dependencies (Box and Jenkins, 1976; Cleveland et al., 1990). Neural sequence models including dilated CNNs and attention mechanisms have improved expressivity for irregular patterns (Bai et al., 2018; Zhou et al., 2021).\n\nClassical decomposition separates trend and seasonality in time series (Cleveland et al., 1990). Transformers capture long-range dependencies via self-attention (Zhou et al., 2021). Industrial anomaly detection benefits from modeling forecasting residuals (Audibert et al., 2020). Recent work adds probabilistic calibration and covariate shift adaptation (Salinas et al., 2020; Rangapuram et al., 2018). We contribute a decomposition-informed attention module with uncertainty-aware loss for robust detection.",
    "reason": "The span abruptly lists decomposition, transformer forecasting, and anomaly detection without transitions or an explicit rationale tying them together, making the relationships between the cited works unclear.",
    "start": 476,
    "end": 756,
    "label": "Coherence"
  },
  {
    "span": "The CNN/Daily Mail dataset has over 1.3 million articles",
    "document": "Introduction\n\nAbstractive text summarization seeks to generate fluent summaries that capture salient content (See et al., 2017; Lewis et al., 2020). While encoder-decoder models with attention have become dominant, data scale remains a crucial factor for training high-capacity models. The CNN/Daily Mail dataset has over 1.3 million articles and is a standard benchmark for news summarization, enabling pretraining of summarizers prior to fine-tuning on niche domains. However, summaries in news often follow journalistic style and may not generalize to scientific prose (Cohan et al., 2018). To address domain shift, recent lines of work explore content planning and factuality constraints (Zhang et al., 2020; Kryscinski et al., 2020). In this paper, we propose a planning-aware summarizer that explicitly models discourse salience across sections.",
    "reason": "Mentions a specific dataset and a concrete statistic without providing a citation at the first mention.",
    "start": 286,
    "end": 342,
    "label": "Unsupported_claim"
  },
  {
    "span": "Conversational recommender systems have leveraged reinforcement learning for dialog policy (Lei et al., 2020; Zhang et al., 2020), knowledge graphs for reasoning (Wang et al., 2019; Chen et al., 2020), memory networks for user preference tracking (Zhou et al., 2020), and pre-trained language models for response generation (Roller et al., 2021; Li et al., 2021).",
    "document": "Related Work\n\nConversational recommendation combines natural language understanding, interactive preference elicitation, and item selection. Systems must manage exploration, handle sparse signals, and avoid repetitive or irrelevant questions during multi-turn interactions.\n\nConversational recommender systems have leveraged reinforcement learning for dialog policy (Lei et al., 2020; Zhang et al., 2020), knowledge graphs for reasoning (Wang et al., 2019; Chen et al., 2020), memory networks for user preference tracking (Zhou et al., 2020), and pre-trained language models for response generation (Roller et al., 2021; Li et al., 2021).\n\nOur work focuses on controllable question selection under cold-start. We introduce an information-to-friction ratio that balances elicitation gain and user burden, and a constrained policy optimization algorithm that improves satisfaction metrics while preserving recommendation quality on CRSBench.",
    "reason": "Lists prior approaches and ingredients without clarifying how they relate to the paper’s focus on controllable question selection or what gap persists, thus lacking synthesis (criterion a/c).",
    "start": 275,
    "end": 638,
    "label": "Lacks_synthesis"
  },
  {
    "span": "Vision Transformers require large-scale pretraining to perform well on small datasets (Dosovitskiy et al., 2021; Touvron et al., 2021; Steiner et al., 2021). Recent works introduce data-efficient training via distillation, token reduction, and inductive biases (DeiT, Touvron et al., 2021; Yuan et al., 2021; Chen et al., 2021).",
    "document": "Related Work\n\nTransformer-based architectures have become competitive in vision tasks by replacing convolutional inductive biases with flexible tokenized representations. However, their data and compute demands raise barriers to adoption in small-scale or domain-specific settings.\n\nVision Transformers require large-scale pretraining to perform well on small datasets (Dosovitskiy et al., 2021; Touvron et al., 2021; Steiner et al., 2021). Recent works introduce data-efficient training via distillation, token reduction, and inductive biases (DeiT, Touvron et al., 2021; Yuan et al., 2021; Chen et al., 2021).\n\nWe re-examine patch embedding design and propose a lightweight convolutional tokenizer with parameter sharing that preserves transformer flexibility while improving sample efficiency. Our results show consistent gains in low-shot transfer and limited-epoch training.",
    "reason": "The span lists prior efforts and techniques without connecting them to the authors’ problem framing or explaining what remains unresolved, thus lacking synthesis and author motivation.",
    "start": 283,
    "end": 611,
    "label": "Lacks_synthesis"
  },
  {
    "span": "LibriSpeech",
    "document": "Introduction\n\nEnd-to-end automatic speech recognition (ASR) replaces modular pipelines with differentiable models mapping acoustics directly to text. Self-attention encoders and transducer decoders have achieved strong performance in both streaming and non-streaming regimes. To quantify improvements, we evaluate on LibriSpeech and TED-LIUM with standard decoding setups and language models. We also examine robustness to background noise and speaker overlap.",
    "reason": "Invokes a specific dataset without citing its original dataset paper, violating the requirement to cite datasets at first mention (rule a).",
    "start": 317,
    "end": 328,
    "label": "Unsupported_claim"
  },
  {
    "span": "Brown et al. (2020) introduced GPT-3 for few-shot prompting. Calibrated prompting aims to adjust for verbalizer bias (Zhao et al., 2021). PET uses masked language models with patterns and verbalizers (Schick and Schütze, 2021). Chain-of-thought prompting elicits step-by-step reasoning (Wei et al., 2022).",
    "document": "Related Work\n\nPrompting for pretrained language models has enabled strong performance with limited supervision. Research has explored template design, answer space calibration, and reasoning induction to better align model behavior with task requirements.\n\nBrown et al. (2020) introduced GPT-3 for few-shot prompting. Calibrated prompting aims to adjust for verbalizer bias (Zhao et al., 2021). PET uses masked language models with patterns and verbalizers (Schick and Schütze, 2021). Chain-of-thought prompting elicits step-by-step reasoning (Wei et al., 2022).\n\nOur study focuses on learning prompt policies that adapt to instance difficulty, complementing prior work by optimizing selection rather than template design.",
    "reason": "The span lists multiple prompting papers in succession without transitions or explanation of how each relates to the others, leaving the connections between the cited works implicit and abrupt.",
    "start": 257,
    "end": 562,
    "label": "Coherence"
  },
  {
    "span": "Smith et al.",
    "document": "Related Work\n\nGraph neural networks (GNNs) extend convolution to irregular structures by propagating and aggregating node features along edges (Kipf and Welling, 2017; Hamilton et al., 2017). Attention mechanisms further enhance expressivity by weighting neighborhoods (Velickovic et al., 2018; Brody et al., 2022). Despite their success, over-smoothing and over-squashing remain central challenges (Li et al., 2018; Alon and Yahav, 2021).\n\nSeveral strategies mitigate these limitations, including residual connections, personalized PageRank diffusion, and subgraph sampling (Klicpera et al., 2019; Chen et al., 2020; Zhao and Akoglu, 2020). For scalability, sampling-based training reduces variance while maintaining accuracy (Hamilton et al., 2017; Zeng et al., 2019). Smith et al. propose sparsity-inducing regularizers to counteract over-smoothing while preserving label signal propagation, inspiring our use of structure-aware penalties.\n\nOur work differs by coupling spectral filtering with learned structural priors, enabling deeper message passing without collapsing node distinctions.",
    "reason": "Narrative citation missing year; in author–year style, a narrative mention should include the year as in “Smith et al. (2020)”.",
    "start": 771,
    "end": 783,
    "label": "Format"
  },
  {
    "span": "Back-translation synthesizes in-domain target sentences to augment parallel data (Sennrich et al., 2016; Edunov et al., 2018). Instance weighting rebalances training examples according to domain relevance (Axelrod et al., 2011). Multilingual pivoting transfers knowledge from related languages for low-resource domains (Johnson et al., 2017). Continual learning mitigates catastrophic forgetting during domain shifts (Thompson et al., 2019).",
    "document": "Related Work\n\nDomain Adaptation for Neural Machine Translation\nNeural MT degrades when test-time distributions diverge from training data, motivating adaptation strategies that leverage in-domain monolingual corpora, reweight examples, or alter training dynamics (Chu and Wang, 2018). Despite numerous techniques, consistent comparisons are complicated by differing data scales and evaluation domains.\n\nAdaptation Techniques\nBack-translation synthesizes in-domain target sentences to augment parallel data (Sennrich et al., 2016; Edunov et al., 2018). Instance weighting rebalances training examples according to domain relevance (Axelrod et al., 2011). Multilingual pivoting transfers knowledge from related languages for low-resource domains (Johnson et al., 2017). Continual learning mitigates catastrophic forgetting during domain shifts (Thompson et al., 2019). Recent work also explores adapters and prompts for parameter-efficient adaptation with large encoder-decoders (Bapna and Firat, 2019; Lester et al., 2021).\n\nEvaluation Considerations\nStandardized protocols such as WMT domain splits and medical/legal test sets help isolate improvements from data scaling effects (Farajian et al., 2017). We build on these settings to compare parameter-efficient and data-centric approaches under matched compute budgets.",
    "reason": "The span enumerates disparate adaptation methods with no transitions or explanation of how they compare or connect, leaving the relationships between the cited works implicit and unclear.",
    "start": 425,
    "end": 866,
    "label": "Coherence"
  },
  {
    "span": "Brown & Lee (2021)",
    "document": "Related Work\n\nCausal representation learning aims to uncover latent factors and their relationships from high-dimensional observations (Scholkopf et al., 2021; Locatello et al., 2020). Identifiability results often require multiple environments or interventions (Peters et al., 2016; Bengio et al., 2019), and practical algorithms leverage invariances across domains (Arjovsky et al., 2019; Ahuja et al., 2020).\n\nInvariant risk minimization and its variants seek predictors stable across shifts (Arjovsky et al., 2019; Krueger et al., 2021), while causal discovery from nonstationary data exploits changing mechanisms (Zhang et al., 2017; Huang et al., 2020). Recent benchmarks emphasize out-of-distribution evaluation (Gulrajani and Lopez-Paz, 2021; Wiles et al., 2022).\n\nFollowing Brown & Lee (2021), we consider a setting with weakly aligned views and propose a contrastive objective that preserves intervention-invariant structure. Our contribution differs by adding a mediator-regularizer that discourages spurious pathways.\n\nWe validate on synthetic and real multi-view datasets, providing ablations on environment count and shift magnitude.",
    "reason": "Wrong conjunction for narrative author listing; in narrative author-year style, \"and\" should be used instead of \"&\" outside of parentheses.",
    "start": 783,
    "end": 801,
    "label": "Format"
  },
  {
    "span": "Social navigation approaches incorporate proxemics (Pacchierotti et al., 2006; Truong and Ngo, 2017), trajectory forecasting with social forces (Helbing and Molnár, 1995; Pellegrini et al., 2009), learning from demonstrations (Kretzschmar et al., 2016; Tai et al., 2018), and deep RL with human-aware rewards (Chen et al., 2017; Everett et al., 2021).",
    "document": "Related Work\n\nRobots moving among people must respect social norms while ensuring safety and efficiency. Modeling human trajectories, predicting intent, and adapting robot plans in real time are central challenges in crowded indoor spaces.\n\nSocial navigation approaches incorporate proxemics (Pacchierotti et al., 2006; Truong and Ngo, 2017), trajectory forecasting with social forces (Helbing and Molnár, 1995; Pellegrini et al., 2009), learning from demonstrations (Kretzschmar et al., 2016; Tai et al., 2018), and deep RL with human-aware rewards (Chen et al., 2017; Everett et al., 2021).\n\nRecent datasets capture dense pedestrian interactions with onboard sensing (Sadeghian et al., 2018; Kothari et al., 2021). We target semi-structured hallways and propose an intent-conditioned planner with uncertainty-aware safety margins learned from partial observability.\n",
    "reason": "The span lists categories of methods and citations but does not relate them to the paper’s scenario, limitations they have, or why a new method is needed, showing lack of synthesis per (a) and (c).",
    "start": 241,
    "end": 592,
    "label": "Lacks_synthesis"
  },
  {
    "span": "Garcia et al. 1",
    "document": "Introduction\n\nFairness in machine learning encompasses statistical parity, equalized odds, and calibration criteria that often conflict in practice (Barocas et al., 2019; Kleinberg et al., 2017; Mitchell et al., 2019). Garcia et al. 1 argue that interventions must be tailored to data collection processes rather than only algorithmic post-processing. Parallel lines of work study subgroup robustness and representation harms (Buolamwini and Gebru, 2018; Blodgett et al., 2020). We take a data-centric perspective and examine how label noise and sampling bias interact with fairness constraints in imbalanced classification.\n",
    "reason": "Improper footnote-style marker after an author name without a year. It should include the publication year as a proper citation, e.g., \"Garcia et al. (2020)\", or be converted into a correctly formatted footnote using the paper’s footnote style.",
    "start": 219,
    "end": 234,
    "label": "Format"
  },
  {
    "span": "Safety mechanisms in human-robot collaboration include speed-and-separation monitoring, power-and-force limiting, and supervised autonomy with override policies (ISO 10218; Haddadin et al., 2017; Lasota et al., 2017). Probabilistic risk assessment and formal verification techniques offer assurances under modeled uncertainties (Sadraddini and Belta, 2017; Alami et al., 2020).",
    "document": "Related Work\n\nAs robots transition from cages to shared workspaces with humans, safety becomes a primary design constraint. Standards and algorithms aim to prevent harm while preserving productivity.\n\nSafety mechanisms in human-robot collaboration include speed-and-separation monitoring, power-and-force limiting, and supervised autonomy with override policies (ISO 10218; Haddadin et al., 2017; Lasota et al., 2017). Probabilistic risk assessment and formal verification techniques offer assurances under modeled uncertainties (Sadraddini and Belta, 2017; Alami et al., 2020).\n\nThis paper targets data-driven safety under distribution shift in dynamic environments. We propose a conservative policy adaptation scheme that updates safety margins based on online intent estimation, maintaining compliance while reducing unnecessary stops.",
    "reason": "The span compiles mechanisms and methods without indicating how they relate to distribution shift or the proposed approach, reflecting (a) and (c).",
    "start": 201,
    "end": 578,
    "label": "Lacks_synthesis"
  },
  {
    "span": "The SemEval 2020 shared task on offensive language identification used macro-F1 as the official ranking metric.",
    "document": "Related Work\n\nAutomatic detection of abusive and offensive language has been studied across social media platforms, ranging from Twitter to Reddit. Earlier datasets emphasized binary toxicity labels, while later resources introduced fine-grained categories for insult types and targets. The SemEval 2020 shared task on offensive language identification used macro-F1 as the official ranking metric. Methods typically combine pretrained encoders with task-specific heads, and address domain shift via continual pretraining on in-domain corpora. Despite progress, cross-domain robustness and fairness across demographic groups remain open challenges.",
    "reason": "Mentions a specific shared task and its setup without citing the task overview or dataset paper (rule a).",
    "start": 287,
    "end": 398,
    "label": "Unsupported_claim"
  },
  {
    "span": "Patel",
    "document": "Introduction\n\nInformation retrieval systems increasingly integrate dense representations to improve recall on semantically rich queries. According to Patel, retrieval-augmented generation can bridge gaps between sparse and dense indexing by conditioning generation on retrieved evidence. Concurrent work explores late interaction models that maintain token-level matching while scaling to large corpora (Khattab and Zaharia, 2020) and hybrid pipelines that combine BM25 with learned rerankers (Nogueira and Cho, 2019). Despite these advances, robust evaluation across domains and query intents remains underexplored.\n\nWe introduce a domain-balanced benchmark that jointly measures recall, precision, and answer faithfulness for retrieval-augmented systems.",
    "reason": "Narrative citation missing year; it should be 'Patel (YEAR)' when used to attribute a specific prior work.",
    "start": 150,
    "end": 155,
    "label": "Format"
  },
  {
    "span": "In a previous study, the authors claim that attention heads specialize for syntax.",
    "document": "Related Work\n\nInterpretability research for transformer-based language models investigates how internal components correlate with linguistic phenomena. Probing classifiers and attention pattern analyses have been used to link model behavior to syntax and semantics.\n\nIn a previous study, the authors claim that attention heads specialize for syntax. Subsequent work questions whether such correlations indicate causation or arise from confounds in probing tasks.\n\nOur analysis departs from attention correlation and instead uses targeted interventions to assess whether syntactic cues causally affect predictions in masked language modeling.",
    "reason": "References a prior study and its claim without providing a citation (rule a, e).",
    "start": 267,
    "end": 349,
    "label": "Unsupported_claim"
  },
  {
    "span": "Many recent works show that small language models outperform GPT-4 on constrained code synthesis when trained purely on unit tests.",
    "document": "Introduction\n\nNeural code generation maps natural language intent to executable programs and has become a core capability in software engineering assistants. Despite rapid progress, deploying these models in real development environments requires strong correctness under tight resource budgets and privacy constraints.\n\nA growing trend is to pair code generation with unit-test feedback so that models can iteratively refine outputs without direct human supervision. In practice, the availability of test suites offers a structured signal that can regularize generation and reduce hallucinations. Many recent works show that small language models outperform GPT-4 on constrained code synthesis when trained purely on unit tests. However, the empirical landscape is fragmented and evaluations vary widely in terms of languages, libraries, and test-time intervention policies.\n\nIn this paper, we study unit-test-driven synthesis at scale across multiple programming languages and libraries. We introduce a unified benchmark protocol, analyze failure modes across categories of compiler and runtime errors, and present a light-weight verification-guided decoding strategy. Our results indicate that careful test orchestration and decoding policies can close most of the gap to much larger models in constrained settings.\n",
    "reason": "This sentence claims evidence from 'many recent works' and a comparative performance claim versus GPT-4 without providing any citations to those works.",
    "start": 598,
    "end": 729,
    "label": "Unsupported_claim"
  },
  {
    "span": "Patel et al. 3",
    "document": "Introduction\n\nEvaluating fairness. Prior audits reveal systematic disparities in calibration and coverage across demographic groups (Buolamwini and Gebru, 2018; Raji et al., 2020). As noted by Patel et al. 3, post-hoc thresholding can mask subgroup errors when aggregate metrics are reported. We therefore report both calibrated and uncalibrated risk under group-wise partitions and propose an uncertainty-aware training objective.\n",
    "reason": "Wrong use of a footnote-like numeral in place of a proper citation. Should include the publication year (e.g., \"Patel et al. (2021)\") or be formatted as an actual footnote/endnote.",
    "start": 193,
    "end": 207,
    "label": "Format"
  },
  {
    "span": "Personalized FL has explored meta-learning, clustering clients, and multi-task optimization (Smith et al., 2017; Fallah et al., 2020; Hanzely and Richtárik, 2020; Arivazhagan et al., 2019; Dinh et al., 2020).",
    "document": "Related Work\nFederated learning (FL) enables on-device training without centralizing raw data, but statistical heterogeneity across clients undermines global aggregation. A growing literature develops techniques to mitigate non-IID data and improve convergence under partial participation.\nPersonalized FL has explored meta-learning, clustering clients, and multi-task optimization (Smith et al., 2017; Fallah et al., 2020; Hanzely and Richtárik, 2020; Arivazhagan et al., 2019; Dinh et al., 2020). Additional directions regularize local models toward a shared reference, interpolate between local and global optima, or adapt representation layers (Li et al., 2020; Collins et al., 2021; Mansour et al., 2020).\nCommunication efficiency and fairness have been examined through compression, adaptive sampling, and client reweighting (Suresh et al., 2017; Karimireddy et al., 2020; Li et al., 2019). Privacy is typically enforced via secure aggregation and differential privacy (Bonawitz et al., 2017; McMahan et al., 2018).",
    "reason": "The span enumerates approaches and citations but does not connect them to the authors’ problem setting or specify what limitation remains, thus lacking synthesis.",
    "start": 290,
    "end": 498,
    "label": "Lacks_synthesis"
  },
  {
    "span": "Common augmentation practices include speed perturbation, SpecAugment, and noise mixing (Ko et al., 2015; Park et al., 2019; Reddy et al., 2020).",
    "document": "Introduction\n\nLow-resource automatic speech recognition (ASR) suffers from data scarcity and domain mismatch. Data augmentation is a practical strategy to improve generalization without additional labeled data.\n\nRelated Work\n\nCommon augmentation practices include speed perturbation, SpecAugment, and noise mixing (Ko et al., 2015; Park et al., 2019; Reddy et al., 2020). Synthetic data generation using TTS and voice conversion has been explored to diversify speakers and acoustic conditions (Rosenberg et al., 2019; Jia et al., 2021). Semi-supervised approaches leverage pseudo-labels and consistency training (Kahn et al., 2020; Xu et al., 2020).\n\nWe introduce pronunciation-aware augmentation that perturbs grapheme-to-phoneme alignments to better cover dialectal variants.",
    "reason": "The span only enumerates existing augmentation techniques without clarifying their limitations or linking them to the authors’ proposed approach.",
    "start": 226,
    "end": 371,
    "label": "Lacks_synthesis"
  },
  {
    "span": "Transformer variants now dominate the MovieLens leaderboard.",
    "document": "Related Work\n\nRecommendation algorithms have evolved from neighborhood methods to latent factor models and, more recently, sequence-aware neural architectures. Temporal dynamics and context modeling are crucial for capturing evolving user preferences in real-world platforms. Transformer variants now dominate the MovieLens leaderboard. However, their performance often hinges on heavy feature engineering and extensive hyperparameter tuning, which impedes fair comparison. We propose a lightweight architecture with calibrated attention that achieves strong results under standardized protocols.",
    "reason": "Asserts leaderboard dominance without citing the leaderboard or supporting studies.",
    "start": 276,
    "end": 336,
    "label": "Unsupported_claim"
  },
  {
    "span": "the WMT20 News Translation task",
    "document": "Introduction\n\nBenchmarking progress in machine translation (MT) typically relies on standardized shared tasks that provide parallel data and evaluation protocols. In this work, we focus on news domain translation and aim to ensure comparability with widely reported leaderboards. We evaluate on the WMT20 News Translation task to facilitate comparison with prior systems and test sets while controlling for domain shift. Our analysis isolates the contribution of data filtering and architecture choices across several language pairs.",
    "reason": "References a specific shared task without citing the official task or its overview paper.",
    "start": 295,
    "end": 326,
    "label": "Unsupported_claim"
  },
  {
    "span": "A common issue occurs that can potentially impact the validity of results is filtering the set of systems to be evaluated via automatic metric scores.",
    "document": "Problems in Past Evaluations\n\nA common issue occurs that can potentially impact the validity of results is filtering the set of systems to be evaluated via automatic metric scores. Since metric scores are known to be a poor substitute for human assessment, this only results in the pos-sibility that the best system according to human judges is inadvertently filtered out at this stage. For example, ConvAI2 (Dinan et al., 2019) ranked models firstly using automatic metrics before top models according to metric scores were assessed by crowd-sourced workers on Mechanical Turk, while similarly in the sixth Dialog System Technology Challenge (DSTC6) systems were filtered according to metric scores prior to human evaluation.\n\nIn terms of the live evaluation, competitions such as Convai2 report such evaluations as highly challenging, with many of the resulting dialogues reported to be senseless, offensive, or simply not in line with instructions and ultimately live evaluation results have been discarded.\n\nDespite challenges, competitions that operate in the public domain, making data and evaluation techniques available to researchers (such as ourselves) should be applauded for such efforts.\n\nOn the other hand, competitions that (for one reason or another) do not release data and evaluation techniques into the public domain have reported relative success in terms of human evaluation. However until such methods can be accessed and independently verified through replication studies, they will unfortunately have little impact . The first Amazon Alexa Socialbot Grand Challenge required human assessors to score how coherent and engaging conversations were on a 1-5 rating scale by two distinct groups: volunteer Amazon employees (experts), and general Alexa users (crowds) (Ram et al., 2018), are reported to achieve a correlation of overall scores for the two types of human assessors at 0.93. The absolute average rating across all chatbots was reported to be 20% lower for experts compared to general users. In an additional effort to evaluate models, conversational user experience, coherence, engagement, domain coverage, topical diversity, and conversational depth were assessed (1-5 scale), with combined scores reported to correlate with those of general users at r = 0.66. In addition to methods and data not being publicly available, correlations are difficult to interpret since no detail is provided about the number of judgments on which the correlation is calculated for example.\n\nIn addition to competitions that generally aim to include human evaluation of systems, automatic metrics are often proposed for dialogue evaluation, themselves requiring a human evaluation data set on which to evaluate the proposed metric. How-ever, inappropriate statistics are often applied. For example, Pang et al. (2020) propose a holistic metric to automatically evaluate four distinct aspects of dialogue, and a human evaluation experiment is deployed on Mechanical Turk using a 1-5 rating scale. The mean correlation between human assessors is reported as r = 0.61. However, mean correlations are unfortunately difficult to interpret, since correlation coefficients are not additive , averages calculated in the usual way cannot be assumed to reflect central tendency, and unfortunately, the distribution of correlations is not reported (Alexander, 1990). Mehri and Eskenazi (2020b) propose USR (Un-Supervised and Reference-free), an unsupervised model that predicts the quality of dialog for a range of criteria using various rating scales: understandable (0-1 rating scale), natural (1-3), maintains context (1-3), interesting (1-3), uses knowledge (0-1); overall quality (1-5). Despite human evaluation being carried out by experts inter-annotator agreement levels varied depending on criteria being measured, ranging from as low as 0.298. Additionally, although correlations between human assessments are reported as significant at p < 0.01, despite such statistics often being reported for correlations, they are unfortunately not very meaningful in terms of their impact on correlation interpretation and can be somewhat misleading. Contrary to common expectations, even small effect sizes (low r) can produce very low p-values (strong significance) in such tests. Aiming to achieve a significant correlation is an extremely low bar to reach in terms of consistency, since a low p-value in this case simply rejects the null hypothesis that the correlation is zero.\n\nIn addition to the above issues, human evaluation of dialogue systems rarely take into account the fact that differences in performance can occur simply by chance. The method of human evaluation we propose provides a means of applying standard tests for statistical significance to avoid concluding differences that are highly likely to have occurred simply by chance.\n\n ",
    "start": 31,
    "end": 180,
    "label": "Unsupported_claim"
  },
  {
    "span": "Since metric scores are known to be a poor substitute for human assessment, this only results in the pos-sibility that the best system according to human judges is inadvertently filtered out at this stage.",
    "document": "Problems in Past Evaluations\n\nA common issue occurs that can potentially impact the validity of results is filtering the set of systems to be evaluated via automatic metric scores. Since metric scores are known to be a poor substitute for human assessment, this only results in the pos-sibility that the best system according to human judges is inadvertently filtered out at this stage. For example, ConvAI2 (Dinan et al., 2019) ranked models firstly using automatic metrics before top models according to metric scores were assessed by crowd-sourced workers on Mechanical Turk, while similarly in the sixth Dialog System Technology Challenge (DSTC6) systems were filtered according to metric scores prior to human evaluation.\n\nIn terms of the live evaluation, competitions such as Convai2 report such evaluations as highly challenging, with many of the resulting dialogues reported to be senseless, offensive, or simply not in line with instructions and ultimately live evaluation results have been discarded.\n\nDespite challenges, competitions that operate in the public domain, making data and evaluation techniques available to researchers (such as ourselves) should be applauded for such efforts.\n\nOn the other hand, competitions that (for one reason or another) do not release data and evaluation techniques into the public domain have reported relative success in terms of human evaluation. However until such methods can be accessed and independently verified through replication studies, they will unfortunately have little impact . The first Amazon Alexa Socialbot Grand Challenge required human assessors to score how coherent and engaging conversations were on a 1-5 rating scale by two distinct groups: volunteer Amazon employees (experts), and general Alexa users (crowds) (Ram et al., 2018), are reported to achieve a correlation of overall scores for the two types of human assessors at 0.93. The absolute average rating across all chatbots was reported to be 20% lower for experts compared to general users. In an additional effort to evaluate models, conversational user experience, coherence, engagement, domain coverage, topical diversity, and conversational depth were assessed (1-5 scale), with combined scores reported to correlate with those of general users at r = 0.66. In addition to methods and data not being publicly available, correlations are difficult to interpret since no detail is provided about the number of judgments on which the correlation is calculated for example.\n\nIn addition to competitions that generally aim to include human evaluation of systems, automatic metrics are often proposed for dialogue evaluation, themselves requiring a human evaluation data set on which to evaluate the proposed metric. How-ever, inappropriate statistics are often applied. For example, Pang et al. (2020) propose a holistic metric to automatically evaluate four distinct aspects of dialogue, and a human evaluation experiment is deployed on Mechanical Turk using a 1-5 rating scale. The mean correlation between human assessors is reported as r = 0.61. However, mean correlations are unfortunately difficult to interpret, since correlation coefficients are not additive , averages calculated in the usual way cannot be assumed to reflect central tendency, and unfortunately, the distribution of correlations is not reported (Alexander, 1990). Mehri and Eskenazi (2020b) propose USR (Un-Supervised and Reference-free), an unsupervised model that predicts the quality of dialog for a range of criteria using various rating scales: understandable (0-1 rating scale), natural (1-3), maintains context (1-3), interesting (1-3), uses knowledge (0-1); overall quality (1-5). Despite human evaluation being carried out by experts inter-annotator agreement levels varied depending on criteria being measured, ranging from as low as 0.298. Additionally, although correlations between human assessments are reported as significant at p < 0.01, despite such statistics often being reported for correlations, they are unfortunately not very meaningful in terms of their impact on correlation interpretation and can be somewhat misleading. Contrary to common expectations, even small effect sizes (low r) can produce very low p-values (strong significance) in such tests. Aiming to achieve a significant correlation is an extremely low bar to reach in terms of consistency, since a low p-value in this case simply rejects the null hypothesis that the correlation is zero.\n\nIn addition to the above issues, human evaluation of dialogue systems rarely take into account the fact that differences in performance can occur simply by chance. The method of human evaluation we propose provides a means of applying standard tests for statistical significance to avoid concluding differences that are highly likely to have occurred simply by chance.\n\n ",
    "start": 182,
    "end": 386,
    "label": "Unsupported_claim"
  },
  {
    "span": "in the sixth Dialog System Technology Challenge (DSTC6) systems were filtered according to metric scores prior to human evaluation.",
    "document": "Problems in Past Evaluations\n\nA common issue occurs that can potentially impact the validity of results is filtering the set of systems to be evaluated via automatic metric scores. Since metric scores are known to be a poor substitute for human assessment, this only results in the pos-sibility that the best system according to human judges is inadvertently filtered out at this stage. For example, ConvAI2 (Dinan et al., 2019) ranked models firstly using automatic metrics before top models according to metric scores were assessed by crowd-sourced workers on Mechanical Turk, while similarly in the sixth Dialog System Technology Challenge (DSTC6) systems were filtered according to metric scores prior to human evaluation.\n\nIn terms of the live evaluation, competitions such as Convai2 report such evaluations as highly challenging, with many of the resulting dialogues reported to be senseless, offensive, or simply not in line with instructions and ultimately live evaluation results have been discarded.\n\nDespite challenges, competitions that operate in the public domain, making data and evaluation techniques available to researchers (such as ourselves) should be applauded for such efforts.\n\nOn the other hand, competitions that (for one reason or another) do not release data and evaluation techniques into the public domain have reported relative success in terms of human evaluation. However until such methods can be accessed and independently verified through replication studies, they will unfortunately have little impact . The first Amazon Alexa Socialbot Grand Challenge required human assessors to score how coherent and engaging conversations were on a 1-5 rating scale by two distinct groups: volunteer Amazon employees (experts), and general Alexa users (crowds) (Ram et al., 2018), are reported to achieve a correlation of overall scores for the two types of human assessors at 0.93. The absolute average rating across all chatbots was reported to be 20% lower for experts compared to general users. In an additional effort to evaluate models, conversational user experience, coherence, engagement, domain coverage, topical diversity, and conversational depth were assessed (1-5 scale), with combined scores reported to correlate with those of general users at r = 0.66. In addition to methods and data not being publicly available, correlations are difficult to interpret since no detail is provided about the number of judgments on which the correlation is calculated for example.\n\nIn addition to competitions that generally aim to include human evaluation of systems, automatic metrics are often proposed for dialogue evaluation, themselves requiring a human evaluation data set on which to evaluate the proposed metric. How-ever, inappropriate statistics are often applied. For example, Pang et al. (2020) propose a holistic metric to automatically evaluate four distinct aspects of dialogue, and a human evaluation experiment is deployed on Mechanical Turk using a 1-5 rating scale. The mean correlation between human assessors is reported as r = 0.61. However, mean correlations are unfortunately difficult to interpret, since correlation coefficients are not additive , averages calculated in the usual way cannot be assumed to reflect central tendency, and unfortunately, the distribution of correlations is not reported (Alexander, 1990). Mehri and Eskenazi (2020b) propose USR (Un-Supervised and Reference-free), an unsupervised model that predicts the quality of dialog for a range of criteria using various rating scales: understandable (0-1 rating scale), natural (1-3), maintains context (1-3), interesting (1-3), uses knowledge (0-1); overall quality (1-5). Despite human evaluation being carried out by experts inter-annotator agreement levels varied depending on criteria being measured, ranging from as low as 0.298. Additionally, although correlations between human assessments are reported as significant at p < 0.01, despite such statistics often being reported for correlations, they are unfortunately not very meaningful in terms of their impact on correlation interpretation and can be somewhat misleading. Contrary to common expectations, even small effect sizes (low r) can produce very low p-values (strong significance) in such tests. Aiming to achieve a significant correlation is an extremely low bar to reach in terms of consistency, since a low p-value in this case simply rejects the null hypothesis that the correlation is zero.\n\nIn addition to the above issues, human evaluation of dialogue systems rarely take into account the fact that differences in performance can occur simply by chance. The method of human evaluation we propose provides a means of applying standard tests for statistical significance to avoid concluding differences that are highly likely to have occurred simply by chance.\n\n ",
    "start": 596,
    "end": 726,
    "label": "Unsupported_claim"
  },
  {
    "span": "In terms of the live evaluation, competitions such as Convai2 report such evaluations as highly challenging, with many of the resulting dialogues reported to be senseless, offensive, or simply not in line with instructions and ultimately live evaluation results have been discarded.",
    "document": "Problems in Past Evaluations\n\nA common issue occurs that can potentially impact the validity of results is filtering the set of systems to be evaluated via automatic metric scores. Since metric scores are known to be a poor substitute for human assessment, this only results in the pos-sibility that the best system according to human judges is inadvertently filtered out at this stage. For example, ConvAI2 (Dinan et al., 2019) ranked models firstly using automatic metrics before top models according to metric scores were assessed by crowd-sourced workers on Mechanical Turk, while similarly in the sixth Dialog System Technology Challenge (DSTC6) systems were filtered according to metric scores prior to human evaluation.\n\nIn terms of the live evaluation, competitions such as Convai2 report such evaluations as highly challenging, with many of the resulting dialogues reported to be senseless, offensive, or simply not in line with instructions and ultimately live evaluation results have been discarded.\n\nDespite challenges, competitions that operate in the public domain, making data and evaluation techniques available to researchers (such as ourselves) should be applauded for such efforts.\n\nOn the other hand, competitions that (for one reason or another) do not release data and evaluation techniques into the public domain have reported relative success in terms of human evaluation. However until such methods can be accessed and independently verified through replication studies, they will unfortunately have little impact . The first Amazon Alexa Socialbot Grand Challenge required human assessors to score how coherent and engaging conversations were on a 1-5 rating scale by two distinct groups: volunteer Amazon employees (experts), and general Alexa users (crowds) (Ram et al., 2018), are reported to achieve a correlation of overall scores for the two types of human assessors at 0.93. The absolute average rating across all chatbots was reported to be 20% lower for experts compared to general users. In an additional effort to evaluate models, conversational user experience, coherence, engagement, domain coverage, topical diversity, and conversational depth were assessed (1-5 scale), with combined scores reported to correlate with those of general users at r = 0.66. In addition to methods and data not being publicly available, correlations are difficult to interpret since no detail is provided about the number of judgments on which the correlation is calculated for example.\n\nIn addition to competitions that generally aim to include human evaluation of systems, automatic metrics are often proposed for dialogue evaluation, themselves requiring a human evaluation data set on which to evaluate the proposed metric. How-ever, inappropriate statistics are often applied. For example, Pang et al. (2020) propose a holistic metric to automatically evaluate four distinct aspects of dialogue, and a human evaluation experiment is deployed on Mechanical Turk using a 1-5 rating scale. The mean correlation between human assessors is reported as r = 0.61. However, mean correlations are unfortunately difficult to interpret, since correlation coefficients are not additive , averages calculated in the usual way cannot be assumed to reflect central tendency, and unfortunately, the distribution of correlations is not reported (Alexander, 1990). Mehri and Eskenazi (2020b) propose USR (Un-Supervised and Reference-free), an unsupervised model that predicts the quality of dialog for a range of criteria using various rating scales: understandable (0-1 rating scale), natural (1-3), maintains context (1-3), interesting (1-3), uses knowledge (0-1); overall quality (1-5). Despite human evaluation being carried out by experts inter-annotator agreement levels varied depending on criteria being measured, ranging from as low as 0.298. Additionally, although correlations between human assessments are reported as significant at p < 0.01, despite such statistics often being reported for correlations, they are unfortunately not very meaningful in terms of their impact on correlation interpretation and can be somewhat misleading. Contrary to common expectations, even small effect sizes (low r) can produce very low p-values (strong significance) in such tests. Aiming to achieve a significant correlation is an extremely low bar to reach in terms of consistency, since a low p-value in this case simply rejects the null hypothesis that the correlation is zero.\n\nIn addition to the above issues, human evaluation of dialogue systems rarely take into account the fact that differences in performance can occur simply by chance. The method of human evaluation we propose provides a means of applying standard tests for statistical significance to avoid concluding differences that are highly likely to have occurred simply by chance.\n\n ",
    "start": 729,
    "end": 1010,
    "label": "Unsupported_claim"
  },
  {
    "span": "On the other hand, competitions that (for one reason or another) do not release data and evaluation techniques into the public domain have reported relative success in terms of human evaluation.",
    "document": "Problems in Past Evaluations\n\nA common issue occurs that can potentially impact the validity of results is filtering the set of systems to be evaluated via automatic metric scores. Since metric scores are known to be a poor substitute for human assessment, this only results in the pos-sibility that the best system according to human judges is inadvertently filtered out at this stage. For example, ConvAI2 (Dinan et al., 2019) ranked models firstly using automatic metrics before top models according to metric scores were assessed by crowd-sourced workers on Mechanical Turk, while similarly in the sixth Dialog System Technology Challenge (DSTC6) systems were filtered according to metric scores prior to human evaluation.\n\nIn terms of the live evaluation, competitions such as Convai2 report such evaluations as highly challenging, with many of the resulting dialogues reported to be senseless, offensive, or simply not in line with instructions and ultimately live evaluation results have been discarded.\n\nDespite challenges, competitions that operate in the public domain, making data and evaluation techniques available to researchers (such as ourselves) should be applauded for such efforts.\n\nOn the other hand, competitions that (for one reason or another) do not release data and evaluation techniques into the public domain have reported relative success in terms of human evaluation. However until such methods can be accessed and independently verified through replication studies, they will unfortunately have little impact . The first Amazon Alexa Socialbot Grand Challenge required human assessors to score how coherent and engaging conversations were on a 1-5 rating scale by two distinct groups: volunteer Amazon employees (experts), and general Alexa users (crowds) (Ram et al., 2018), are reported to achieve a correlation of overall scores for the two types of human assessors at 0.93. The absolute average rating across all chatbots was reported to be 20% lower for experts compared to general users. In an additional effort to evaluate models, conversational user experience, coherence, engagement, domain coverage, topical diversity, and conversational depth were assessed (1-5 scale), with combined scores reported to correlate with those of general users at r = 0.66. In addition to methods and data not being publicly available, correlations are difficult to interpret since no detail is provided about the number of judgments on which the correlation is calculated for example.\n\nIn addition to competitions that generally aim to include human evaluation of systems, automatic metrics are often proposed for dialogue evaluation, themselves requiring a human evaluation data set on which to evaluate the proposed metric. How-ever, inappropriate statistics are often applied. For example, Pang et al. (2020) propose a holistic metric to automatically evaluate four distinct aspects of dialogue, and a human evaluation experiment is deployed on Mechanical Turk using a 1-5 rating scale. The mean correlation between human assessors is reported as r = 0.61. However, mean correlations are unfortunately difficult to interpret, since correlation coefficients are not additive , averages calculated in the usual way cannot be assumed to reflect central tendency, and unfortunately, the distribution of correlations is not reported (Alexander, 1990). Mehri and Eskenazi (2020b) propose USR (Un-Supervised and Reference-free), an unsupervised model that predicts the quality of dialog for a range of criteria using various rating scales: understandable (0-1 rating scale), natural (1-3), maintains context (1-3), interesting (1-3), uses knowledge (0-1); overall quality (1-5). Despite human evaluation being carried out by experts inter-annotator agreement levels varied depending on criteria being measured, ranging from as low as 0.298. Additionally, although correlations between human assessments are reported as significant at p < 0.01, despite such statistics often being reported for correlations, they are unfortunately not very meaningful in terms of their impact on correlation interpretation and can be somewhat misleading. Contrary to common expectations, even small effect sizes (low r) can produce very low p-values (strong significance) in such tests. Aiming to achieve a significant correlation is an extremely low bar to reach in terms of consistency, since a low p-value in this case simply rejects the null hypothesis that the correlation is zero.\n\nIn addition to the above issues, human evaluation of dialogue systems rarely take into account the fact that differences in performance can occur simply by chance. The method of human evaluation we propose provides a means of applying standard tests for statistical significance to avoid concluding differences that are highly likely to have occurred simply by chance.\n\n ",
    "start": 1203,
    "end": 1396,
    "label": "Unsupported_claim"
  },
  {
    "span": "However until such methods can be accessed and independently verified through replication studies, they will unfortunately have little impact .",
    "document": "Problems in Past Evaluations\n\nA common issue occurs that can potentially impact the validity of results is filtering the set of systems to be evaluated via automatic metric scores. Since metric scores are known to be a poor substitute for human assessment, this only results in the pos-sibility that the best system according to human judges is inadvertently filtered out at this stage. For example, ConvAI2 (Dinan et al., 2019) ranked models firstly using automatic metrics before top models according to metric scores were assessed by crowd-sourced workers on Mechanical Turk, while similarly in the sixth Dialog System Technology Challenge (DSTC6) systems were filtered according to metric scores prior to human evaluation.\n\nIn terms of the live evaluation, competitions such as Convai2 report such evaluations as highly challenging, with many of the resulting dialogues reported to be senseless, offensive, or simply not in line with instructions and ultimately live evaluation results have been discarded.\n\nDespite challenges, competitions that operate in the public domain, making data and evaluation techniques available to researchers (such as ourselves) should be applauded for such efforts.\n\nOn the other hand, competitions that (for one reason or another) do not release data and evaluation techniques into the public domain have reported relative success in terms of human evaluation. However until such methods can be accessed and independently verified through replication studies, they will unfortunately have little impact . The first Amazon Alexa Socialbot Grand Challenge required human assessors to score how coherent and engaging conversations were on a 1-5 rating scale by two distinct groups: volunteer Amazon employees (experts), and general Alexa users (crowds) (Ram et al., 2018), are reported to achieve a correlation of overall scores for the two types of human assessors at 0.93. The absolute average rating across all chatbots was reported to be 20% lower for experts compared to general users. In an additional effort to evaluate models, conversational user experience, coherence, engagement, domain coverage, topical diversity, and conversational depth were assessed (1-5 scale), with combined scores reported to correlate with those of general users at r = 0.66. In addition to methods and data not being publicly available, correlations are difficult to interpret since no detail is provided about the number of judgments on which the correlation is calculated for example.\n\nIn addition to competitions that generally aim to include human evaluation of systems, automatic metrics are often proposed for dialogue evaluation, themselves requiring a human evaluation data set on which to evaluate the proposed metric. How-ever, inappropriate statistics are often applied. For example, Pang et al. (2020) propose a holistic metric to automatically evaluate four distinct aspects of dialogue, and a human evaluation experiment is deployed on Mechanical Turk using a 1-5 rating scale. The mean correlation between human assessors is reported as r = 0.61. However, mean correlations are unfortunately difficult to interpret, since correlation coefficients are not additive , averages calculated in the usual way cannot be assumed to reflect central tendency, and unfortunately, the distribution of correlations is not reported (Alexander, 1990). Mehri and Eskenazi (2020b) propose USR (Un-Supervised and Reference-free), an unsupervised model that predicts the quality of dialog for a range of criteria using various rating scales: understandable (0-1 rating scale), natural (1-3), maintains context (1-3), interesting (1-3), uses knowledge (0-1); overall quality (1-5). Despite human evaluation being carried out by experts inter-annotator agreement levels varied depending on criteria being measured, ranging from as low as 0.298. Additionally, although correlations between human assessments are reported as significant at p < 0.01, despite such statistics often being reported for correlations, they are unfortunately not very meaningful in terms of their impact on correlation interpretation and can be somewhat misleading. Contrary to common expectations, even small effect sizes (low r) can produce very low p-values (strong significance) in such tests. Aiming to achieve a significant correlation is an extremely low bar to reach in terms of consistency, since a low p-value in this case simply rejects the null hypothesis that the correlation is zero.\n\nIn addition to the above issues, human evaluation of dialogue systems rarely take into account the fact that differences in performance can occur simply by chance. The method of human evaluation we propose provides a means of applying standard tests for statistical significance to avoid concluding differences that are highly likely to have occurred simply by chance.\n\n ",
    "start": 1398,
    "end": 1540,
    "label": "Unsupported_claim"
  },
  {
    "span": "The first Amazon Alexa Socialbot Grand Challenge",
    "document": "Problems in Past Evaluations\n\nA common issue occurs that can potentially impact the validity of results is filtering the set of systems to be evaluated via automatic metric scores. Since metric scores are known to be a poor substitute for human assessment, this only results in the pos-sibility that the best system according to human judges is inadvertently filtered out at this stage. For example, ConvAI2 (Dinan et al., 2019) ranked models firstly using automatic metrics before top models according to metric scores were assessed by crowd-sourced workers on Mechanical Turk, while similarly in the sixth Dialog System Technology Challenge (DSTC6) systems were filtered according to metric scores prior to human evaluation.\n\nIn terms of the live evaluation, competitions such as Convai2 report such evaluations as highly challenging, with many of the resulting dialogues reported to be senseless, offensive, or simply not in line with instructions and ultimately live evaluation results have been discarded.\n\nDespite challenges, competitions that operate in the public domain, making data and evaluation techniques available to researchers (such as ourselves) should be applauded for such efforts.\n\nOn the other hand, competitions that (for one reason or another) do not release data and evaluation techniques into the public domain have reported relative success in terms of human evaluation. However until such methods can be accessed and independently verified through replication studies, they will unfortunately have little impact . The first Amazon Alexa Socialbot Grand Challenge required human assessors to score how coherent and engaging conversations were on a 1-5 rating scale by two distinct groups: volunteer Amazon employees (experts), and general Alexa users (crowds) (Ram et al., 2018), are reported to achieve a correlation of overall scores for the two types of human assessors at 0.93. The absolute average rating across all chatbots was reported to be 20% lower for experts compared to general users. In an additional effort to evaluate models, conversational user experience, coherence, engagement, domain coverage, topical diversity, and conversational depth were assessed (1-5 scale), with combined scores reported to correlate with those of general users at r = 0.66. In addition to methods and data not being publicly available, correlations are difficult to interpret since no detail is provided about the number of judgments on which the correlation is calculated for example.\n\nIn addition to competitions that generally aim to include human evaluation of systems, automatic metrics are often proposed for dialogue evaluation, themselves requiring a human evaluation data set on which to evaluate the proposed metric. How-ever, inappropriate statistics are often applied. For example, Pang et al. (2020) propose a holistic metric to automatically evaluate four distinct aspects of dialogue, and a human evaluation experiment is deployed on Mechanical Turk using a 1-5 rating scale. The mean correlation between human assessors is reported as r = 0.61. However, mean correlations are unfortunately difficult to interpret, since correlation coefficients are not additive , averages calculated in the usual way cannot be assumed to reflect central tendency, and unfortunately, the distribution of correlations is not reported (Alexander, 1990). Mehri and Eskenazi (2020b) propose USR (Un-Supervised and Reference-free), an unsupervised model that predicts the quality of dialog for a range of criteria using various rating scales: understandable (0-1 rating scale), natural (1-3), maintains context (1-3), interesting (1-3), uses knowledge (0-1); overall quality (1-5). Despite human evaluation being carried out by experts inter-annotator agreement levels varied depending on criteria being measured, ranging from as low as 0.298. Additionally, although correlations between human assessments are reported as significant at p < 0.01, despite such statistics often being reported for correlations, they are unfortunately not very meaningful in terms of their impact on correlation interpretation and can be somewhat misleading. Contrary to common expectations, even small effect sizes (low r) can produce very low p-values (strong significance) in such tests. Aiming to achieve a significant correlation is an extremely low bar to reach in terms of consistency, since a low p-value in this case simply rejects the null hypothesis that the correlation is zero.\n\nIn addition to the above issues, human evaluation of dialogue systems rarely take into account the fact that differences in performance can occur simply by chance. The method of human evaluation we propose provides a means of applying standard tests for statistical significance to avoid concluding differences that are highly likely to have occurred simply by chance.\n\n ",
    "start": 1542,
    "end": 1589,
    "label": "Unsupported_claim"
  },
  {
    "span": "In addition to the above issues, human evaluation of dialogue systems rarely take into account the fact that differences in performance can occur simply by chance.",
    "document": "Problems in Past Evaluations\n\nA common issue occurs that can potentially impact the validity of results is filtering the set of systems to be evaluated via automatic metric scores. Since metric scores are known to be a poor substitute for human assessment, this only results in the pos-sibility that the best system according to human judges is inadvertently filtered out at this stage. For example, ConvAI2 (Dinan et al., 2019) ranked models firstly using automatic metrics before top models according to metric scores were assessed by crowd-sourced workers on Mechanical Turk, while similarly in the sixth Dialog System Technology Challenge (DSTC6) systems were filtered according to metric scores prior to human evaluation.\n\nIn terms of the live evaluation, competitions such as Convai2 report such evaluations as highly challenging, with many of the resulting dialogues reported to be senseless, offensive, or simply not in line with instructions and ultimately live evaluation results have been discarded.\n\nDespite challenges, competitions that operate in the public domain, making data and evaluation techniques available to researchers (such as ourselves) should be applauded for such efforts.\n\nOn the other hand, competitions that (for one reason or another) do not release data and evaluation techniques into the public domain have reported relative success in terms of human evaluation. However until such methods can be accessed and independently verified through replication studies, they will unfortunately have little impact . The first Amazon Alexa Socialbot Grand Challenge required human assessors to score how coherent and engaging conversations were on a 1-5 rating scale by two distinct groups: volunteer Amazon employees (experts), and general Alexa users (crowds) (Ram et al., 2018), are reported to achieve a correlation of overall scores for the two types of human assessors at 0.93. The absolute average rating across all chatbots was reported to be 20% lower for experts compared to general users. In an additional effort to evaluate models, conversational user experience, coherence, engagement, domain coverage, topical diversity, and conversational depth were assessed (1-5 scale), with combined scores reported to correlate with those of general users at r = 0.66. In addition to methods and data not being publicly available, correlations are difficult to interpret since no detail is provided about the number of judgments on which the correlation is calculated for example.\n\nIn addition to competitions that generally aim to include human evaluation of systems, automatic metrics are often proposed for dialogue evaluation, themselves requiring a human evaluation data set on which to evaluate the proposed metric. How-ever, inappropriate statistics are often applied. For example, Pang et al. (2020) propose a holistic metric to automatically evaluate four distinct aspects of dialogue, and a human evaluation experiment is deployed on Mechanical Turk using a 1-5 rating scale. The mean correlation between human assessors is reported as r = 0.61. However, mean correlations are unfortunately difficult to interpret, since correlation coefficients are not additive , averages calculated in the usual way cannot be assumed to reflect central tendency, and unfortunately, the distribution of correlations is not reported (Alexander, 1990). Mehri and Eskenazi (2020b) propose USR (Un-Supervised and Reference-free), an unsupervised model that predicts the quality of dialog for a range of criteria using various rating scales: understandable (0-1 rating scale), natural (1-3), maintains context (1-3), interesting (1-3), uses knowledge (0-1); overall quality (1-5). Despite human evaluation being carried out by experts inter-annotator agreement levels varied depending on criteria being measured, ranging from as low as 0.298. Additionally, although correlations between human assessments are reported as significant at p < 0.01, despite such statistics often being reported for correlations, they are unfortunately not very meaningful in terms of their impact on correlation interpretation and can be somewhat misleading. Contrary to common expectations, even small effect sizes (low r) can produce very low p-values (strong significance) in such tests. Aiming to achieve a significant correlation is an extremely low bar to reach in terms of consistency, since a low p-value in this case simply rejects the null hypothesis that the correlation is zero.\n\nIn addition to the above issues, human evaluation of dialogue systems rarely take into account the fact that differences in performance can occur simply by chance. The method of human evaluation we propose provides a means of applying standard tests for statistical significance to avoid concluding differences that are highly likely to have occurred simply by chance.\n\n ",
    "start": 4489,
    "end": 4651,
    "label": "Unsupported_claim"
  },
  {
    "span": "Low-resource ASR has been studied via multilingual pretraining, self-training, and data augmentation such as SpecAugment and noise mixing (Kahn et al., 2020; Watanabe et al., 2018; Park et al., 2019; Nguyen et al., 2020). End-to-end CTC/attention hybrids and transducer models are widely used (Graves et al., 2006; Kim et al., 2017; Graves, 2012).",
    "document": "Related Work\n\nAutomatic speech recognition in low-resource settings requires leveraging unlabeled audio, cross-lingual transfer, and architectural biases to compensate for data scarcity. Numerous techniques address one or more of these axes.\n\nLow-resource ASR has been studied via multilingual pretraining, self-training, and data augmentation such as SpecAugment and noise mixing (Kahn et al., 2020; Watanabe et al., 2018; Park et al., 2019; Nguyen et al., 2020). End-to-end CTC/attention hybrids and transducer models are widely used (Graves et al., 2006; Kim et al., 2017; Graves, 2012).\n\nOur work focuses on stability of pseudo-labeling under domain shift and proposes a curriculum that schedules augmentation strength and confidence thresholds. We show improvements on cross-domain few-hour corpora.",
    "reason": "The span enumerates approaches and model families without explaining their relationships, limitations, or how they inform the authors’ approach, thus lacking synthesis in connecting prior work to the paper’s aims.",
    "start": 243,
    "end": 590,
    "label": "Lacks_synthesis"
  },
  {
    "span": "Chen et al. (2021) demonstrated large language models can translate natural language to code. Li et al. (2022) presented AlphaCode for competitive programming. Austin et al. (2021) studied program synthesis with few-shot prompting. Nijkamp et al. (2023) explored code generation with self-consistency sampling.",
    "document": "Related Work\n\nProgram synthesis with pretrained language models has advanced rapidly, driven by larger models, code-oriented corpora, and inference-time strategies that trade compute for reliability.\n\nChen et al. (2021) demonstrated large language models can translate natural language to code. Li et al. (2022) presented AlphaCode for competitive programming. Austin et al. (2021) studied program synthesis with few-shot prompting. Nijkamp et al. (2023) explored code generation with self-consistency sampling.\n\nOur approach introduces execution-guided reranking with counterexample generation to improve functional correctness under strict time budgets.",
    "reason": "Multiple sentences enumerate prior works with no transitions or explanation of how they relate to each other or to the problem setup, creating an abrupt and implicit connection (issues a and b).",
    "start": 201,
    "end": 511,
    "label": "Coherence"
  },
  {
    "span": "(Kumar et al., 2021)",
    "document": "Related Work\n\nGraph neural networks (GNNs) extend message passing to structured data and have achieved state-of-the-art results in chemistry, recommendation, and program analysis (Gilmer et al., 2017; Hamilton et al., 2017). In (Kumar et al., 2021) we categorize temporal GNNs into snapshot-based and continuous-time variants, emphasizing how time encoding affects expressivity. Positional encodings for graphs improve long-range dependencies (Dwivedi et al., 2020; Ying et al., 2021), while training stability can be enhanced via normalization and residual connections (Chen et al., 2020). Heterogeneous graphs introduce typed nodes and edges that require specialized aggregation schemes (Hu et al., 2020; Schlichtkrull et al., 2018). Our work focuses on dynamic graphs, unifying continuous-time event modeling with scalable batching to handle millions of interactions.\n",
    "reason": "Wrong citation style for a narrative construction; should be “In Kumar et al. (2021) we ...” rather than placing the authors and year in parentheses immediately after “In”.",
    "start": 228,
    "end": 248,
    "label": "Format"
  },
  {
    "span": "Bandit and RL-based recommenders employ policy gradient (Zhao et al., 2018), deep Q-learning (Chen et al., 2019), and actor-critic methods (Xin et al., 2020).",
    "document": "Related Work\n\nRecommender systems increasingly optimize long-term user satisfaction by modeling sequential interactions as decision processes. Reinforcement learning (RL) provides a formal framework to balance exploration and exploitation in this setting.\n\nBandit and RL-based recommenders employ policy gradient (Zhao et al., 2018), deep Q-learning (Chen et al., 2019), and actor-critic methods (Xin et al., 2020). Offline RL studies address counterfactual estimation and distribution shift (Swaminathan and Joachims, 2015; Levine et al., 2020). Slate and list-wise formulations consider combinatorial action spaces (Ie et al., 2019; Chen et al., 2022).\n\nWe propose a conservative list-wise policy with uncertainty-aware re-ranking to improve robustness in batch-constrained settings.",
    "reason": "The span lists RL approaches and citations but fails to articulate how they relate to the present work or identify a gap, thus lacking synthesis.",
    "start": 257,
    "end": 415,
    "label": "Lacks_synthesis"
  },
  {
    "span": "There are many recent works that explore reference-free evaluation for chit-chat.",
    "document": "Related Work\n\nEvaluating open-domain dialogue remains challenging due to the multiplicity of valid responses and the weak correlation between reference-based metrics and human judgments. There are many recent works that explore reference-free evaluation for chit-chat. These methods aim to estimate conversational quality by modeling aspects such as coherence, engagement, and consistency directly from the generated text and context, bypassing the need for gold references.\n\nNevertheless, agreement among human raters is often low, and metric reliability varies across datasets and domains. This has spurred interest in multi-faceted evaluation protocols that combine automatic metrics with targeted human studies. Our study contributes to this line by assessing metric robustness under adversarial perturbations and distribution shift.",
    "reason": "General claim about 'many recent works' without providing any citations (rule d).",
    "start": 187,
    "end": 268,
    "label": "Unsupported_claim"
  },
  {
    "span": "((Miller, 2018))",
    "document": "Introduction\n\nComputational social science leverages large-scale digital traces to study collective behavior (Lazer et al., 2009). Text and network analyses uncover ideological polarization, misinformation diffusion, and mobilization dynamics (Conover et al., 2011; Vosoughi et al., 2018; Barberá, 2015).\n\nA key challenge is causal inference from observational data subject to selection bias and confounders (Rosenbaum, 2002; Imbens and Rubin, 2015). Recent work combines natural experiments with machine learning to approximate counterfactuals (Athey and Imbens, 2017; Varian, 2016). ((Miller, 2018)) argue for integrating qualitative audits with quantitative pipelines to improve construct validity, aligning with calls for measurement transparency (Jacobs and Wallach, 2021).\n\nWe extend this agenda by proposing a mixed-methods protocol that couples topic-model diagnostics with researcher annotation, and we validate the approach on studies of online civic participation.",
    "reason": "Double parentheses around a single parenthetical citation; should be a single set of parentheses.",
    "start": 585,
    "end": 601,
    "label": "Format"
  },
  {
    "span": "The standard LibriSpeech 100h setup uses a tri-gram language model for decoding.",
    "document": "Introduction\nEnd-to-end automatic speech recognition (ASR) has increasingly relied on self-supervised pretraining and robust decoding strategies to close the gap with hybrid systems. While large-scale pretraining reduces label reliance, decoding choices still significantly influence word error rate.\n\nRelated Work\nBenchmarks on LibriSpeech commonly report results on the 100h, 360h, and 960h subsets with shallow fusion decoding. The standard LibriSpeech 100h setup uses a tri-gram language model for decoding. Nevertheless, the strength and domain of the external language model, as well as beam size and pruning heuristics, can change outcomes by several absolute WER points. We therefore re-evaluate decoding configurations under parameter-controlled comparisons and report sensitivity analyses.",
    "reason": "Asserting a specific, 'standard' configuration for a benchmark requires a supporting reference to prior protocols; no citation is provided (violates a).",
    "start": 431,
    "end": 511,
    "label": "Unsupported_claim"
  },
  {
    "span": "CutMix blends images and labels to encourage localization (Yun et al., 2019). RandAugment tunes a small number of augmentation hyperparameters to discover strong policies (Cubuk et al., 2020). Adversarial training perturbs pixels to improve robustness (Madry et al., 2018). Semi-supervised consistency regularization exploits unlabeled images by enforcing invariance (Berthelot et al., 2019).",
    "document": "Related Work\n\nData Augmentation for Visual Recognition\n\nData augmentation has been a long-standing strategy for improving generalization in vision models by increasing data diversity without additional labeling. Classic transformations include flips, crops, and color jitter (Krizhevsky et al., 2012), and more recent work has explored learned policies and mixing strategies. Our method aims to adapt augmentation intensity to instance difficulty.\n\nPolicy Search and Mixing Methods\n\nAutomated policy search explores combinations of primitive transforms to identify strong augmentation strategies. AutoAugment searches a large space of operations and magnitudes using reinforcement learning (Cubuk et al., 2019). MixUp linearly interpolates both images and labels to produce convex combinations of samples (Zhang et al., 2018).\n\nCutMix blends images and labels to encourage localization (Yun et al., 2019). RandAugment tunes a small number of augmentation hyperparameters to discover strong policies (Cubuk et al., 2020). Adversarial training perturbs pixels to improve robustness (Madry et al., 2018). Semi-supervised consistency regularization exploits unlabeled images by enforcing invariance (Berthelot et al., 2019).\n\nAdaptive and Sample-Aware Augmentation\n\nBeyond fixed policies, several works adapt augmentation strength to model confidence or training progress. AdaAug scales magnitudes based on loss signals (Li et al., 2021). Curriculum augmentation ramps up distortion schedules over epochs (Soviany et al., 2020). Our approach differs by targeting per-instance gradient sensitivity and adjusting transforms on the fly.",
    "reason": "The sentences list four works in succession without transitions or explicit relationships. The jump from augmentation techniques (CutMix, RandAugment) to adversarial training and then to semi-supervised consistency is abrupt and does not clarify how each connects to the previous, creating coherence issues across multiple sentences.",
    "start": 828,
    "end": 1220,
    "label": "Coherence"
  },
  {
    "span": "Wang et al., 2020]",
    "document": "Related Work\n\nSelf-supervised speech representation learning has rapidly advanced ASR and spoken language understanding (Schneider et al., 2019; Baevski et al., 2020; Hsu et al., 2021). Contrastive pretraining with masked prediction yields robust features that transfer across languages and domains (Conneau et al., 2021; Chung et al., 2021). However, label-efficiency and domain robustness remain open problems, especially for noisy, far-field recordings (Zhang et al., 2021).\n\nAugmentation strategies such as SpecAugment and time warping are widely used, but their interactions with large-scale pretraining are not fully understood (Park et al., 2019; Ko et al., 2015). Pseudo-labeling helps in semi-supervised regimes, yet confidence calibration is critical to avoid confirmation bias (Xu et al., 2020; Wang et al., 2020]).\n\nOur work studies curriculum schedules for pseudo-label filtering and proposes a representation consistency loss that improves performance under domain shift. We evaluate on multilingual corpora with realistic noise conditions, measuring gains under low-resource settings.",
    "reason": "Unmatched closing square bracket used in an author–year citation; should use closing parenthesis.",
    "start": 806,
    "end": 824,
    "label": "Format"
  },
  {
    "span": "(Nguyen and Lee, 2022",
    "document": "Introduction\n\nGraph-based anomaly detection benefits from relational inductive biases that capture neighborhood consistency. Prior approaches include reconstruction objectives (Kipf and Welling, 2016; Salha-Galvan et al., 2022) and contrastive learning (Velickovic et al., 2019). We introduce a prototype-based learner that clusters normal patterns and flags deviations, inspired by metric learning for images (Koch et al., 2015) and extended to graphs (Nguyen and Lee, 2022 with a stability constraint.\n\nRelated Work\n\nRobust training under distribution shift (Sagawa et al., 2020) motivates our use of group-aware validation. We also compare to density estimators tailored to graphs (Zhao and Akoglu, 2021).",
    "reason": "Missing closing parenthesis in the parenthetical citation. It should be “(Nguyen and Lee, 2022)” or used narratively as “Nguyen and Lee (2022)”.",
    "start": 453,
    "end": 474,
    "label": "Format"
  },
  {
    "span": "Prior multimodal sentiment systems combine text, audio, and video using early fusion, late fusion, or hybrid schemes (Poria et al., 2017; Tsai et al., 2019; Mai et al., 2020). Transformer-based cross-modal fusion modules have also been proposed (Zadeh et al., 2018; Tsai et al., 2019; Sun et al., 2020).",
    "document": "Introduction\n\nMultimodal sentiment analysis seeks to infer affective states by integrating cues from language, acoustics, and vision. The field has moved from heuristic feature concatenation to deep models capable of learning cross-modal interactions.\n\nPrior multimodal sentiment systems combine text, audio, and video using early fusion, late fusion, or hybrid schemes (Poria et al., 2017; Tsai et al., 2019; Mai et al., 2020). Transformer-based cross-modal fusion modules have also been proposed (Zadeh et al., 2018; Tsai et al., 2019; Sun et al., 2020).\n\nIn this paper, we explore a temporal alignment encoder and evaluate on benchmark datasets with standard metrics.",
    "reason": "The span lists approaches and citations without connecting them to the authors’ choices or stating what is missing, offering no synthesis or perspective.",
    "start": 253,
    "end": 556,
    "label": "Lacks_synthesis"
  },
  {
    "span": "Transformer-based architectures have been adapted to medical image segmentation by inserting self-attention into U-Net decoders or replacing convolutions with hierarchical attention blocks (Chen et al., 2021; Cao et al., 2021; Xie et al., 2021). Hybrid CNN-Transformer designs report gains on CT and MRI benchmarks (Hatamizadeh et al., 2022; Zhang et al., 2021).",
    "document": "Introduction\n\nAccurate delineation of anatomical structures in medical images is a core prerequisite for computer-assisted diagnosis and treatment planning. Despite strong feature hierarchies from convolutional networks, long-range context modeling remains a challenge in high-resolution scans.\n\nTransformer-based architectures have been adapted to medical image segmentation by inserting self-attention into U-Net decoders or replacing convolutions with hierarchical attention blocks (Chen et al., 2021; Cao et al., 2021; Xie et al., 2021). Hybrid CNN-Transformer designs report gains on CT and MRI benchmarks (Hatamizadeh et al., 2022; Zhang et al., 2021).\n\nWe present a memory-efficient global–local attention module that preserves fine boundaries while capturing organ-scale dependencies. Integrated into a lightweight U-Net backbone, our approach achieves competitive accuracy under strict memory budgets and supports 3D volumes with variable spacing. Extensive experiments on multi-center datasets validate robustness to scanner and protocol shifts.\n\nWe release code and pre-trained weights to facilitate reproducibility and clinical translation.",
    "reason": "This span lists prior Transformer-based segmentation works and their reported gains without explaining how they relate to or motivate the present approach, leaving the gap and perspective unstated (a, c).",
    "start": 296,
    "end": 658,
    "label": "Lacks_synthesis"
  },
  {
    "span": "IEMOCAP contains approximately 12 hours of dyadic interactions.",
    "document": "Introduction\n\nSpeech emotion recognition (SER) seeks to infer affective states from acoustic and linguistic signals. Benchmark datasets facilitate comparative evaluation across modeling approaches and feature representations. IEMOCAP contains approximately 12 hours of dyadic interactions. While widely used, class imbalance and speaker overlap can inflate reported performance when not properly controlled. We present a speaker-disjoint evaluation protocol with uncertainty-aware calibration to improve reliability.",
    "reason": "This is a specific dataset fact stated without citing the dataset source, violating rule (a) and (b).",
    "start": 226,
    "end": 289,
    "label": "Unsupported_claim"
  },
  {
    "span": "The WMT23 shared task emphasized document-level metrics over sentence-level evaluation.",
    "document": "Related Work\n\nDocument-level machine translation (DocMT) extends sentence-level models by modeling cross-sentence context [1,2]. Shared tasks have encouraged evaluation beyond isolated sentences to capture discourse phenomena. The WMT23 shared task emphasized document-level metrics over sentence-level evaluation. In parallel, pretraining on large monolingual corpora has been shown to benefit DocMT via context-aware encoders [3].",
    "reason": "Mentions a specific shared task and its emphasis but provides no citation to the task description or report.",
    "start": 227,
    "end": 314,
    "label": "Unsupported_claim"
  },
  {
    "span": "Multimodal summarization approaches include early fusion of visual and textual tokens, late fusion via re-ranking, and cross-attention mechanisms between image regions and sentences (Li et al., 2018; Chen and Bansal, 2018; Sanabria et al., 2019; Zhu et al., 2020).",
    "document": "Related Work\n\nMultimodal summarization. Generating summaries that reflect both visual and textual evidence has been approached with encoder-decoder models and alignment modules. Multimodal summarization approaches include early fusion of visual and textual tokens, late fusion via re-ranking, and cross-attention mechanisms between image regions and sentences (Li et al., 2018; Chen and Bansal, 2018; Sanabria et al., 2019; Zhu et al., 2020). Some work explores reinforcement learning to optimize summary quality metrics.\n\nEvaluation challenges. Existing metrics often focus on textual overlap and may not capture visual grounding fidelity, complicating fair assessment across datasets.\n\nWe propose a grounding-aware metric and a training objective that aligns salient visual evidence with summary content.\n",
    "reason": "The span summarizes prior categories and citations but does not indicate how they succeed or fail relative to the paper’s goals; it offers no perspective on gaps or how the new metric/objective addresses them.",
    "start": 178,
    "end": 442,
    "label": "Lacks_synthesis"
  },
  {
    "span": "There have been many recent works demonstrating that prompt tuning outperforms full fine-tuning on small datasets.",
    "document": "Introduction\n\nLarge language models (LLMs) have shifted the paradigm in NLP by enabling task adaptation through in-context learning and lightweight parameter updates. While full fine-tuning optimizes all model parameters for a target task, parameter-efficient tuning methods such as prompt tuning and adapter-based updates have emerged as practical alternatives for constrained settings. Prior studies report strong performance of parameter-efficient methods when compute and data are limited, particularly for classification and sequence labeling tasks.\n\nPrompt tuning frames downstream adaptation as learning task-specific prompts that steer frozen language models. Early work introduced soft prompts learned via gradient descent, showing competitive results with vastly fewer trainable parameters compared to full fine-tuning. There have been many recent works demonstrating that prompt tuning outperforms full fine-tuning on small datasets. Despite these advances, systematic comparisons across tasks and data regimes remain sparse, and evaluation protocols often differ in ways that complicate meta-analysis.\n\nIn this paper, we present a unified benchmark for parameter-efficient tuning across text classification, natural language inference, and information extraction. We control for prompt length, initialization, and optimization settings to provide apples-to-apples comparisons. We further analyze robustness under domain shift and quantify the trade-offs between sample efficiency and headroom at scale.",
    "reason": "The sentence claims broad evidence from 'many recent works' but provides no citations to specific papers (violates rule d) and asserts a comparative performance outcome without evidence (violates a/b).",
    "start": 830,
    "end": 944,
    "label": "Unsupported_claim"
  },
  {
    "span": "BERT was used in an AES task trained on essays from ASAP.",
    "document": "Related Work Automated essay scoring (AES) systems leverage features ranging from surface-level fluency to discourse structure and content relevance (Page, 1966; Attali and Burstein, 2006). Neural approaches model holistic quality using pretrained encoders and ordinal regression objectives, with gains from prompt-specific calibration (Taghipour and Ng, 2016; Dong et al., 2017). BERT was used in an AES task trained on essays from ASAP. We analyze prompt transfer and robustness to adversarial paraphrasing.",
    "reason": "Mentions a specific model–dataset setup without providing a citation to the work that did it, matching example (iii) and rule (a).",
    "start": 381,
    "end": 438,
    "label": "Unsupported_claim"
  },
  {
    "span": "[Miller et al., 2015]",
    "document": "Related Work\n\nExploration in reinforcement learning (RL) has been approached through intrinsic motivation, optimism under uncertainty, and posterior sampling (Auer et al., 2002; Osband et al., 2016). Count-based bonuses approximate novelty in high-dimensional spaces via density models or hashing (Bellemare et al., 2016; Tang et al., 2017). The use of curiosity-driven objectives traces back to ideas in developmental learning [Miller et al., 2015], but has recently been instantiated with predictive world models that reward disagreement (Pathak et al., 2017; Sekar et al., 2020). Our work combines optimism with representation learning to avoid detours into stochastic traps.",
    "reason": "Wrong bracket style for author–year in-text citation; should use parentheses instead of square brackets, e.g., “(Miller et al., 2015)”.",
    "start": 428,
    "end": 449,
    "label": "Format"
  },
  {
    "span": "DeepCoder predicts library calls from input-output pairs using neural priors (Balog et al., 2017). RobustFill targets string transformations with DSL-based neural synthesis (Devlin et al., 2017). Neural-Guided Deductive Search integrates learned heuristics into symbolic search (Neelakantan et al., 2018). Large language models solve coding tasks with few-shot prompts (Chen et al., 2021).",
    "document": "Related Work\n\nLearning to Synthesize Programs\n\nProgram synthesis research spans neural, symbolic, and neuro-symbolic paradigms. Differences arise in the expressivity of the underlying DSL, the supervision available (input-output pairs vs. execution traces vs. natural language), and the degree to which search is learned or enumerated.\n\nDeepCoder predicts library calls from input-output pairs using neural priors (Balog et al., 2017). RobustFill targets string transformations with DSL-based neural synthesis (Devlin et al., 2017). Neural-Guided Deductive Search integrates learned heuristics into symbolic search (Neelakantan et al., 2018). Large language models solve coding tasks with few-shot prompts (Chen et al., 2021).\n\nSpec-Guided and Constraint-Based Methods\n\nConstraint solvers and type systems constrain the search space (Polikarpova et al., 2016), while sketch-based methods specify partial programs (Solar-Lezama, 2008). Recent work aligns natural language with code via contrastive objectives (Yin and Neubig, 2018).\n\nContribution\n\nWe present a hybrid framework that conditions a symbolic enumerator on a learned latent sketch, enabling controllable synthesis under weak supervision and noisy specifications.",
    "reason": "The span strings together summaries of different synthesis paradigms without stating how they are connected or contrasted, and it abruptly jumps to large language models, leaving the relationships implied rather than explicit.",
    "start": 337,
    "end": 726,
    "label": "Coherence"
  },
  {
    "span": "SemEval-2013 Twitter sentiment task",
    "document": "Related Work\n\nSentiment analysis has evolved from lexicon-driven methods to deep contextualized representations. Social media introduces unique challenges such as sarcasm, brevity, and noisy orthography. The SemEval-2013 Twitter sentiment task established a common benchmark for short, informal posts and stimulated progress on domain-specific modeling. Subsequent shared tasks expanded label inventories and multilingual coverage, and neural architectures became the de facto standard. Despite these advances, robust generalization across topics and time remains difficult.",
    "reason": "Mentions a specific shared task without citing its organizing paper or proceedings, which is required for first mention (rule a).",
    "start": 208,
    "end": 243,
    "label": "Unsupported_claim"
  },
  {
    "span": "Prompt tuning improves sample efficiency (Lester et al., 2021). In-context learning allows zero-shot generalization (Brown et al., 2020). Calibrate-before-use mitigates selection bias in prompts (Zhao et al., 2021).",
    "document": "Introduction\n\nLarge language models (LLMs) have reshaped NLP by enabling powerful few-shot and zero-shot capabilities through prompting strategies. Despite rapid progress, the literature around controlling, calibrating, and adapting prompts is fragmented, making it difficult to understand how individual techniques relate and when they should be applied.\n\nPrompt tuning improves sample efficiency (Lester et al., 2021). In-context learning allows zero-shot generalization (Brown et al., 2020). Calibrate-before-use mitigates selection bias in prompts (Zhao et al., 2021). Recent work has also examined instruction tuning to align models with human-preferred behaviors (Ouyang et al., 2022), and retrieval-augmented prompting to ground generations in external knowledge (Lewis et al., 2020). However, a unified account of how these methods interact under distribution shift remains lacking.\n\nIn this paper, we propose a taxonomy of prompting interventions based on their control point (input, latent prompt, output calibration, and external memory) and provide systematic evaluations across tasks with controlled shifts. We further present ablation studies to disentangle the contributions of template design, demonstration selection, and calibration.",
    "reason": "The three consecutive sentences list distinct prompting methods without transitions or explicit relationships. The connection among the cited works is abrupt and the relevance of each to the preceding sentence is not stated, matching criteria (a) and (b).",
    "start": 357,
    "end": 572,
    "label": "Coherence"
  },
  {
    "span": "Box and Jenkins (1970) introduced ARIMA for univariate time-series forecasting. Taylor and Letham (2017) proposed Prophet for decomposable trend-seasonality models. Lim et al. (2021) developed Temporal Fusion Transformers for interpretable forecasting.",
    "document": "Related Work\n\nTime-series forecasting has evolved from statistical decomposition to deep sequence models with attention. Different paradigms offer trade-offs in flexibility, interpretability, and data efficiency.\n\nBox and Jenkins (1970) introduced ARIMA for univariate time-series forecasting. Taylor and Letham (2017) proposed Prophet for decomposable trend-seasonality models. Lim et al. (2021) developed Temporal Fusion Transformers for interpretable forecasting. Wu et al. (2021) analyzed frequency-domain properties of transformer forecasters.\n\nWe propose a hybrid spectral-decomposed transformer that preserves seasonal structure while enabling multihorizon uncertainty estimation.",
    "reason": "The span enumerates methods from distinct paradigms without articulating how each builds on or differs from the others, lacking transitions and explicit relationships.",
    "start": 214,
    "end": 466,
    "label": "Coherence"
  },
  {
    "span": "(Garcia et. al., 2015)",
    "document": "Related Work\n\nRobotic manipulation research has progressed from classical model-based controllers to learning-driven policies that handle contact-rich tasks (Kumar and Bai, 2018; Santos and Lee, 2020). Demonstration-driven learning reduces sample complexity by initializing policies with expert trajectories (Rossi and Patel, 2019). Early work on residual learning combined analytic controllers with neural corrections (Garcia et. al., 2015), and subsequent studies unified planning and learning for long-horizon tasks (Mendes and Zhu, 2021).\n\nWe extend residual policies with uncertainty-aware modulation that down-weights learned corrections under distribution shift. Experiments on peg-in-hole and cable routing tasks show improved success rates and reduced contact forces compared to strong baselines (Huang and Rivera, 2022).",
    "reason": "Incorrect abbreviation 'et. al.' in the citation; should be 'et al.' as in '(Garcia et al., 2015)'.",
    "start": 419,
    "end": 441,
    "label": "Format"
  },
  {
    "span": "Feature-based SLAM tracks keypoints across frames (Mur-Artal and Tardós, 2017). Direct methods optimize photometric error over pixel intensities (Engel et al., 2014). Loop closure detection reduces drift over long trajectories (Cummins and Newman, 2008). Learned depth priors aid reconstruction in textureless regions (Eigen et al., 2014).",
    "document": "Related Work\n\nSimultaneous localization and mapping (SLAM) underpins autonomous navigation by estimating camera trajectory and building a map of the environment. Classical pipelines balance accuracy and real-time performance, while learning-based components promise improved robustness in challenging conditions.\n\nFeature-based SLAM tracks keypoints across frames (Mur-Artal and Tardós, 2017). Direct methods optimize photometric error over pixel intensities (Engel et al., 2014). Loop closure detection reduces drift over long trajectories (Cummins and Newman, 2008). Learned depth priors aid reconstruction in textureless regions (Eigen et al., 2014).\n\nOur approach combines a feature-based frontend with a learned depth prior and a lightweight place-recognition module to improve performance on low-texture indoor datasets.",
    "reason": "The span presents multiple lines of work as isolated statements without transitions or explicit relational links, causing abrupt shifts and unclear connections.",
    "start": 314,
    "end": 653,
    "label": "Coherence"
  },
  {
    "span": "Recent studies employ pre-trained language models for automated program repair, fine-tuning them on bug-fix pairs or leveraging edit-based decoding (Sridhar et al., 2022; Fang and Du, 2022; Zhao et al., 2023). Other work integrates reinforcement learning, retrieval of similar fixes, and feedback from unit tests to guide generation (Min et al., 2022; Ortega et al., 2023; He and Luo, 2023).",
    "document": "Related Work\nAutomated program repair with generative models. Recent studies employ pre-trained language models for automated program repair, fine-tuning them on bug-fix pairs or leveraging edit-based decoding (Sridhar et al., 2022; Fang and Du, 2022; Zhao et al., 2023). Other work integrates reinforcement learning, retrieval of similar fixes, and feedback from unit tests to guide generation (Min et al., 2022; Ortega et al., 2023; He and Luo, 2023). Data filtering and noise-robust training from mined commits have also been explored (Kang et al., 2022; Rossi and Kim, 2023).\n\nSpecification and constraints. Approaches to incorporate specifications include symbolic constraints, API contracts, and type-guided decoding (Basu et al., 2020; Tran and Vo, 2021; Park et al., 2022). Test minimization and flaky test handling are known to affect repair validity (Goyal and Singh, 2021; Nair et al., 2022).\n\nIn contrast to prior work that relies solely on unit tests, we couple natural-language intent from issue reports with code context to align repairs with developer-stated goals, and propose a multi-view confidence estimator to reject spurious fixes.",
    "reason": "The span summarizes earlier efforts without indicating how they bear on the authors' proposed direction, what gaps persist, or why new techniques are necessary; it lacks synthesis and author motivation.",
    "start": 62,
    "end": 453,
    "label": "Lacks_synthesis"
  },
  {
    "span": "A recent shared task on abusive language detection highlighted the importance of context-aware models.",
    "document": "Related Work\n\nAbusive language detection. Early work focused on surface features and lexicons, but modern systems rely on contextual encoders and multi-task learning to capture implicit abuse and target specificity. Conversation structure and user history have been explored to disambiguate sarcasm and reclaimed slurs.\n\nA recent shared task on abusive language detection highlighted the importance of context-aware models. Complementary efforts study cross-platform transfer and domain adaptation, noting substantial performance drops under distribution shift. Data quality, annotation guidelines, and demographic representativeness remain open challenges.\n\nExplainability. Rationale extraction and counterfactual data augmentation have been proposed to improve transparency and fairness.",
    "reason": "Mentions a 'recent shared task' and draws a lesson from it without providing a citation to the task.",
    "start": 321,
    "end": 423,
    "label": "Unsupported_claim"
  },
  {
    "span": "(Rosenblatt, 1958, Rumelhart et al., 1986)",
    "document": "Related Work\n\nNeural network research has evolved from early linear threshold units to deep multilayer perceptrons and modern architectures. The perceptron established foundational ideas in pattern recognition (Rosenblatt, 1958). The resurgence of backpropagation enabled effective training of multilayer networks and paved the way for large-scale applications (Rumelhart et al., 1986; LeCun et al., 1998). Surveys have synthesized these developments across theory and practice (Goodfellow et al., 2016; Schmidhuber, 2015). Prior work (Rosenblatt, 1958, Rumelhart et al., 1986) emphasizes the role of differentiable modules, which we generalize in our compositional framework.",
    "reason": "Multiple citations inside one set of parentheses are separated by a comma instead of a semicolon; should be '(Rosenblatt, 1958; Rumelhart et al., 1986)'.",
    "start": 535,
    "end": 577,
    "label": "Format"
  },
  {
    "span": "(Chen et al., 2018;,",
    "document": "Related Work\n\nNeural machine translation (NMT) has advanced rapidly with attention-based encoder–decoder architectures and large-scale pretraining (Bahdanau et al., 2015; Vaswani et al., 2017; Conneau and Lample, 2019). Data augmentation and back-translation have proven essential for low-resource directions (Sennrich et al., 2016; Edunov et al., 2018).\n\nEfficiency has been addressed through distillation, pruning, and lightweight layers (Kim and Rush, 2016; Sanh et al., 2019). Recent work explores architecture modifications to reduce quadratic attention costs (Chen et al., 2018;, while others adopt sparse or linearized attention mechanisms (Kitaev et al., 2020; Choromanski et al., 2021).\n\nOur approach complements these methods by introducing a latency-aware decoding objective that preserves adequacy under strict real-time constraints.",
    "reason": "Punctuation/formatting error inside the citation: there is an extraneous semicolon and trailing comma before the closing parenthesis; it should be '(Chen et al., 2018)'.",
    "start": 565,
    "end": 585,
    "label": "Format"
  },
  {
    "span": "vast majority of existing multilingual ToD datasets do not consider the real use cases when using a ToD system to search for local entities in a country.",
    "document": "Related Work\n\nOver the last few years, the success of ToD systems is largely driven by the joint advent of neural network models (Eric et al., 2017;Wu et al., 2019; and collections of largescale annotation corpora. These corpora cover a wide range of topics from a single domain (e.g., ATIS (Hemphill et al., 1990), DSTC 2 (Henderson et al., 2014), Frames (El Asri et al., 2017, KVRET (Eric et al., 2017), WoZ 2.0 (Wen et al., 2017), M2M (Schatzmann et al., 2007)) to multiple domains (e.g., MultiWoZ (Budzianowski et al., 2018), SGD ). Most notably among these collections, MultiWoZ is a large-scale multidomain dataset that focuses on transitions between different domains or scenarios in real conversations (Budzianowski et al., 2018). Due to the high cost of collecting task-oriented dialogues, only a few monolingual or bilingual non-English ToD datasets are available Quan et al., 2020;Lin et al., 2021). While there is an increasing interest in data curation for multilingual ToD systems, a vast majority of existing multilingual ToD datasets do not consider the real use cases when using a ToD system to search for local entities in a country. We fill this gap in this paper to provide the first analysis on three previously unexplored use cases.\n\n ",
    "start": 998,
    "end": 1151,
    "label": "Unsupported_claim"
  },
  {
    "span": "In a previous study, the authors demonstrated that spatial attention alone is sufficient for accurate rush-hour prediction.",
    "document": "Related Work\n\nTraffic forecasting has been widely studied using temporal convolutional networks and recurrent architectures, with recent advances leveraging graph neural networks to capture spatial dependencies across road segments. Attention mechanisms have also been explored to model dynamic spatial-temporal interactions under varying congestion patterns.\n\nIn a previous study, the authors demonstrated that spatial attention alone is sufficient for accurate rush-hour prediction. Subsequent models incorporate both spatial and temporal components but differ in how they normalize edge influence and handle missing sensor readings. Our approach extends adaptive graph construction with learned temporal kernels to better capture non-recurrent events.\n\nBeyond accuracy, several works emphasize calibration and uncertainty estimation to support decision-making in intelligent transportation applications.",
    "reason": "Refers to a specific 'previous study' and its findings without a citation (rule a/b).",
    "start": 361,
    "end": 484,
    "label": "Unsupported_claim"
  },
  {
    "span": "(Nguyen et al, 2020)",
    "document": "Introduction\n\nContrastive learning has reshaped representation learning by emphasizing instance discrimination and invariances across augmentations (Chen et al., 2020; He et al., 2020). When applied to text, careful selection of positives and hard negatives is crucial for semantic alignment (Gao et al., 2021; SimCSE, 2021). Prior multilingual adaptations indicate that language-specific augmentations can harm cross-lingual consistency (Zhao and Schütze, 2021) (Nguyen et al, 2020). We extend these insights by proposing alignment-aware sampling that balances lexical and syntactic perturbations.",
    "reason": "Missing period after 'al' in 'et al.' within a parenthetical citation; should be \"(Nguyen et al., 2020)\".",
    "start": 463,
    "end": 483,
    "label": "Format"
  },
  {
    "span": "The MovieLens-20M dataset is known to be highly biased toward blockbuster items.",
    "document": "Introduction\n\nPersonalized recommendation systems commonly rely on collaborative filtering to exploit user–item interaction patterns (Koren et al., 2009; He et al., 2017). With the advent of implicit feedback, loss functions tailored to ranking have become standard, and regularization techniques mitigate popularity-driven overfitting (Rendle et al., 2009).\n\nNevertheless, dataset characteristics strongly influence evaluation outcomes. The MovieLens-20M dataset is known to be highly biased toward blockbuster items. This skew can inflate top-k metrics for algorithms that prioritize popularity, thereby obscuring true personalization capabilities. We therefore complement conventional benchmarks with stratified evaluations over head, mid, and tail items.",
    "reason": "Claims a specific property of a named dataset without providing a citation to empirical analyses (rule a for dataset mention; rule b for specific, niche information).",
    "start": 438,
    "end": 518,
    "label": "Unsupported_claim"
  },
  {
    "span": "Domain adaptation for neural machine translation has been approached through fine-tuning on in-domain parallel data (Luong and Manning, 2015; Sennrich et al., 2016), multi-domain training with domain tags or adapters (Kobus et al., 2017; Bapna and Firat, 2019), and data selection or weighting strategies (van der Wees et al., 2017; Wang et al., 2017). Vocabulary alignment and lexicon constraints have also been explored to mitigate domain shift (Arthur et al., 2016; Song et al., 2019).",
    "document": "Related Work\n\nNeural machine translation (NMT) systems often degrade when applied to domains that differ from the training distribution. Domain adaptation aims to recover performance by tailoring models to new text varieties while avoiding catastrophic forgetting.\n\nDomain adaptation for neural machine translation has been approached through fine-tuning on in-domain parallel data (Luong and Manning, 2015; Sennrich et al., 2016), multi-domain training with domain tags or adapters (Kobus et al., 2017; Bapna and Firat, 2019), and data selection or weighting strategies (van der Wees et al., 2017; Wang et al., 2017). Vocabulary alignment and lexicon constraints have also been explored to mitigate domain shift (Arthur et al., 2016; Song et al., 2019).\n\nAlthough effective, these strategies can be expensive to maintain across many domains. In this work, we investigate light-weight, test-time adaptation that relies only on unlabelled target-domain monolingual text, proposing an entropy-regularized objective that preserves translation adequacy while adapting fluency.",
    "reason": "The span enumerates prior adaptation techniques and cites works but does not connect them to the authors' proposed direction or identify what remains unresolved. It lacks synthesis under (a) and (b)/(c).",
    "start": 266,
    "end": 754,
    "label": "Lacks_synthesis"
  },
  {
    "span": "Hundman et al. (2018) used LSTM-based models for spacecraft telemetry anomaly detection. Xu et al. (2018) proposed DAGMM for unsupervised anomaly detection. Ren et al. (2019) introduced spectral residual transforms for real-time detection. Li et al. (2019) developed OmniAnomaly using stochastic recurrent neural networks.",
    "document": "Related Work\n\nTime-series anomaly detection methods span supervised, semi-supervised, and unsupervised settings, targeting rare deviations in temporal patterns under nonstationarity and noise. Models trade off latency, interpretability, and detection power depending on application constraints.\n\nHundman et al. (2018) used LSTM-based models for spacecraft telemetry anomaly detection. Xu et al. (2018) proposed DAGMM for unsupervised anomaly detection. Ren et al. (2019) introduced spectral residual transforms for real-time detection. Li et al. (2019) developed OmniAnomaly using stochastic recurrent neural networks.\n\nWe focus on probabilistic state-space models with contrastive scoring that unify reconstruction and forecasting signals for robust detection.",
    "reason": "The span is a list of studies without transitions or explicit relational explanation, causing abrupt shifts and leaving the connections between works implicit (issues a and b).",
    "start": 296,
    "end": 618,
    "label": "Coherence"
  },
  {
    "span": "Most prior sim-to-real pipelines rely solely on visual randomization and neglect dynamics randomization.",
    "document": "Related Work\n\nBridging the gap between simulation and reality often relies on domain randomization, which perturbs textures, lighting, and camera parameters during training (Tobin et al., 2017; Tremblay et al., 2018). Subsequent works extend randomization to sensor noise and calibration drift, with mixed results depending on task sensitivity (Peng et al., 2018; OpenAI et al., 2019). Another line of research focuses on system identification and online adaptation to correct residual errors at deployment (Chebotar et al., 2019; Yu et al., 2020).\n\nMost prior sim-to-real pipelines rely solely on visual randomization and neglect dynamics randomization. We revisit this design choice by introducing a structured dynamics prior and a curriculum over mass–friction–compliance parameters that preserves task feasibility while promoting robust control.",
    "reason": "Generalizes about prior work practices without citing specific evidence or surveys (rule a/b).",
    "start": 550,
    "end": 654,
    "label": "Unsupported_claim"
  },
  {
    "span": "Kavraki et al. (1996) introduced PRM for roadmap construction. LaValle and Kuffner (2001) developed RRTs for rapid exploration. Zucker et al. (2013) proposed CHOMP for trajectory optimization. Levine and Koltun (2013) learned policies with guided policy search. SLAM methods estimate robot pose and map concurrently (Durrant-Whyte and Bailey, 2006).",
    "document": "Related Work\n\nMotion Planning and Learning for Robotics\n\nRobotic navigation requires planning feasible, collision-free trajectories under uncertainty. We study how learning-based costs can be integrated with sampling-based planners to improve success rates in cluttered spaces.\n\nKavraki et al. (1996) introduced PRM for roadmap construction. LaValle and Kuffner (2001) developed RRTs for rapid exploration. Zucker et al. (2013) proposed CHOMP for trajectory optimization. Levine and Koltun (2013) learned policies with guided policy search. SLAM methods estimate robot pose and map concurrently (Durrant-Whyte and Bailey, 2006).\n\nOur algorithm augments RRT* with a learned heuristic informed by offline demonstrations and online collision checks.",
    "reason": "The final sentence on SLAM is inserted without connecting it to planning or learning methods; the relationship to prior works is implied but not stated.",
    "start": 279,
    "end": 628,
    "label": "Coherence"
  },
  {
    "span": "there are many recent works that explore this topic",
    "document": "Introduction\n\nRecommender systems are integral to modern online platforms, where the goal is to surface relevant items to users from rapidly growing catalogs. Graph neural networks (GNNs) have emerged as a promising paradigm for capturing high-order collaborative signals by modeling users and items as nodes connected through various interaction edges. In this paper, we study inductive representation learning for recommendations with side information and temporal signals.\n\nWhile traditional matrix factorization methods struggle to incorporate complex relational structure, GNN-based models can naturally aggregate neighborhood information and adapt to evolving graphs. In the area of sequential recommendation, there are many recent works that explore this topic, but they often focus on topological signals without explicitly modeling temporal decay or cold-start dynamics. We propose a time-aware propagation mechanism that jointly encodes user history and side features, enabling robust generalization to new items and users.\n\nOur contributions are threefold: (1) we introduce a temporal message passing operator tailored to recommendation graphs; (2) we present a scalable sampling strategy for long user sequences; and (3) we provide a comprehensive evaluation across multiple public benchmarks, demonstrating consistent gains over strong baselines.",
    "reason": "The phrase \"there are many recent works that explore this topic\" makes a claim about prior literature without providing citations to those recent works (rule d: mentions of recent works should be backed up by citations).",
    "start": 716,
    "end": 767,
    "label": "Unsupported_claim"
  },
  {
    "span": "Statistics indicate that more than 70% of mobile users opt out of data sharing.",
    "document": "Introduction\n\nFederated learning enables collaborative model training across edge devices without centralizing raw data, offering a promising path for privacy-preserving analytics. Adoption in mobile ecosystems is motivated by stringent regulatory requirements and increasing user concerns about tracking. Statistics indicate that more than 70% of mobile users opt out of data sharing. This opt-out behavior reduces the volume and diversity of on-device data available for training, exacerbating selection bias and non-iid effects. We propose an adaptive participation protocol that jointly models user availability and privacy preferences to stabilize training under high opt-out rates.\n",
    "reason": "A concrete statistic is presented without any source or citation, which constitutes an unsupported claim (rule b).",
    "start": 306,
    "end": 385,
    "label": "Unsupported_claim"
  },
  {
    "span": "Corbett and Anderson (1995) introduced Bayesian Knowledge Tracing for latent mastery. Piech et al. (2015) proposed Deep Knowledge Tracing with recurrent networks. Zhang et al. (2017) developed DKVMN with key-value memory. Ghosh et al. (2020) presented AKT with attention over skills.",
    "document": "Related Work\n\nStudent modeling has progressed from probabilistic latent-state models to deep sequence models that capture complex learning dynamics. These methods inform adaptive tutoring and assessment.\n\nCorbett and Anderson (1995) introduced Bayesian Knowledge Tracing for latent mastery. Piech et al. (2015) proposed Deep Knowledge Tracing with recurrent networks. Zhang et al. (2017) developed DKVMN with key-value memory. Ghosh et al. (2020) presented AKT with attention over skills.\n\nWe extend knowledge tracing with curricular structure priors that capture prerequisite graphs, complementing existing sequence architectures.",
    "reason": "The span strings together four citations in separate sentences without transitions or explicit connections, leaving their relationships implied rather than stated.",
    "start": 205,
    "end": 488,
    "label": "Coherence"
  },
  {
    "span": "Alignment of large language models has been approached through supervised fine-tuning on human-preferred outputs (Ziegler et al., 2019; Ouyang et al., 2022), reinforcement learning from human feedback (Christiano et al., 2017; Stiennon et al., 2020), rule- or principle-based steering such as constitutional guidance (Bai et al., 2022), debate and critique mechanisms (Irving et al., 2018; Saunders et al., 2022), and tool-use scaffolding for safer reasoning (Schick et al., 2023; Nakano et al., 2021). Safety evaluations span harmlessness, factuality, and bias (Weidinger et al., 2021; Perez et al., 2022).",
    "document": "Related Work\n\nAs language models scale, alignment methods seek to better match human intent and norms while avoiding harmful or deceptive outputs. Techniques vary in data sources, optimization objectives, and evaluation protocols.\n\nAlignment of large language models has been approached through supervised fine-tuning on human-preferred outputs (Ziegler et al., 2019; Ouyang et al., 2022), reinforcement learning from human feedback (Christiano et al., 2017; Stiennon et al., 2020), rule- or principle-based steering such as constitutional guidance (Bai et al., 2022), debate and critique mechanisms (Irving et al., 2018; Saunders et al., 2022), and tool-use scaffolding for safer reasoning (Schick et al., 2023; Nakano et al., 2021). Safety evaluations span harmlessness, factuality, and bias (Weidinger et al., 2021; Perez et al., 2022).\n\nWe study data- and compute-efficient alignment by exploiting synthetic preference data from multi-turn rollouts with self-review, emphasizing stability without auxiliary reward models.",
    "reason": "The span enumerates alignment approaches and evaluations without explaining their relationship to the paper’s method or the precise gap, showing a lack of synthesis per (a) and (c).",
    "start": 232,
    "end": 839,
    "label": "Lacks_synthesis"
  },
  {
    "span": "[Lee et al., 2018]",
    "document": "Related Work\n\nNeural recommender systems leverage implicit feedback and side information to model user preference (He et al., 2017; Rendle, 2010). Context-aware ranking has been explored with factorization machines and attention networks (Xiao et al., 2017; Zhou et al., 2018). A hybrid sequential model [Lee et al., 2018] demonstrated the benefits of combining short- and long-term dynamics. We build on these insights with a contrastive objective that aligns user and item trajectories.\n\nSelf-supervised pretraining further improves representations for cold-start scenarios (Sun et al., 2019; Yao et al., 2021).",
    "reason": "Wrong bracket style; uses square brackets instead of parentheses, inconsistent with the paper’s citation style.",
    "start": 304,
    "end": 322,
    "label": "Format"
  },
  {
    "span": "COCO 2017",
    "document": "Introduction\n\nObject detection seeks to localize and categorize instances of interest within images. Advances in backbone design, feature pyramids, and training schedules have steadily improved accuracy–speed trade-offs. For empirical validation, we adopt standard benchmarks including COCO 2017 and Pascal VOC, reporting Average Precision under multiple IoU thresholds. We further provide ablations on input scale, data augmentation, and label assignment strategies.",
    "reason": "Mentions a specific dataset/split without citing the dataset paper or official release, which should be done at first mention (rule a).",
    "start": 286,
    "end": 295,
    "label": "Unsupported_claim"
  },
  {
    "span": "Large-scale EHR prediction models typically report AUROC above 0.90 for in-hospital mortality.",
    "document": "Introduction\n\nPredictive modeling with electronic health records (EHR) has benefited from temporal deep learning architectures that capture irregular sampling and multimodal signals (Lipton et al., 2016; Rajkomar et al., 2018). Recent work examines model calibration, fairness, and domain shift across sites, emphasizing the need for robust evaluation beyond discrimination metrics (Suresh et al., 2017; Finlayson et al., 2019). Large-scale EHR prediction models typically report AUROC above 0.90 for in-hospital mortality. However, such performance can mask poor calibration, subgroup disparities, and brittleness under distribution shift. We propose a benchmark that jointly evaluates discrimination, calibration, and stability across time and hospitals.",
    "reason": "Presents a numerical performance claim about prior work without citing any studies or benchmarks to substantiate it.",
    "start": 429,
    "end": 523,
    "label": "Unsupported_claim"
  },
  {
    "span": "Differentially private training mechanisms such as DP-SGD and PATE provide formal privacy guarantees for learning from sensitive text (Abadi et al., 2016; Papernot et al., 2017). Recent studies investigate the privacy-utility trade-off for large language models under gradient clipping and noise injection (Yu et al., 2021; Li et al., 2022).",
    "document": "Introduction\n\nAs language technologies are increasingly trained on sensitive user data, differential privacy (DP) offers formal protections against information leakage in model parameters and outputs. Practical deployments must balance privacy budgets with utility and scalability.\n\nDifferentially private training mechanisms such as DP-SGD and PATE provide formal privacy guarantees for learning from sensitive text (Abadi et al., 2016; Papernot et al., 2017). Recent studies investigate the privacy-utility trade-off for large language models under gradient clipping and noise injection (Yu et al., 2021; Li et al., 2022).\n\nWe introduce DP-LowRankAdapt, a private fine-tuning strategy that combines low-rank adapters with privatized optimizer states, reducing sensitivity while preserving adaptation capacity. Our accountant exploits per-layer clipping schedules to tighten the privacy loss.\n\nWe evaluate DP-LowRankAdapt on sentiment, summarization, and QA, reporting accuracy under fixed epsilon budgets and assessing memorization via extraction attacks. We analyze adapter rank and clipping schedules for privacy-utility trade-offs.",
    "reason": "The span lists DP mechanisms and studies but does not tie them to the paper’s approach or articulate the specific gap addressed, so it lacks synthesis (criteria a and c).",
    "start": 283,
    "end": 624,
    "label": "Lacks_synthesis"
  },
  {
    "span": "(Brown et al., 2019",
    "document": "Introduction\n\nFederated learning enables on-device training without centralizing data (McMahan et al., 2017; Kairouz et al., 2021). However, optimization remains difficult under heterogeneous client distributions. Prior analysis (Brown et al., 2019 suggests that client drift leads to unstable convergence, motivating personalized objectives (Li et al., 2021). We complement these findings by proposing an adaptive client mixing schedule.\n\nPrivacy-preserving aggregation and secure computation have also been explored to mitigate leakage risks (Bonawitz et al., 2019; Truex et al., 2019). Our approach is orthogonal to these concerns and focuses on optimization stability.",
    "reason": "Missing closing parenthesis in the parenthetical citation.",
    "start": 229,
    "end": 248,
    "label": "Format"
  },
  {
    "span": "Ibid., 2020",
    "document": "Introduction\n\nTime-series forecasting under covariate shifts has motivated advances in domain adaptation and invariant representation learning (Tashman, 2000; Ahmed et al., 2010). Recent transformer models capture long-range dependencies with seasonal and trend decompositions (Wu et al., 2021; Zerveas et al., 2021). Huang et al. (2020) propose contrastive pre-training to improve sample efficiency in data-scarce regimes. However, subsequent applications often omit robust validation protocols; as shown in Ibid., 2020, leakage across rolling windows can inflate scores. We address this by aligning training horizons with evaluation splits and by penalizing temporal overlap in the loss.",
    "reason": "Improper use of “Ibid.” in an author–year in-text citation; should include a proper author and year or use a valid cross-reference, not “Ibid., 2020”.",
    "start": 509,
    "end": 520,
    "label": "Format"
  },
  {
    "span": "Classical anomaly detection in time series often builds on ARIMA and state space models that capture linear temporal dependencies under stationarity assumptions. Deep autoencoder methods learn compressed reconstructions and flag deviations by residual magnitude. Sequence-to-sequence architectures predict future windows and treat large forecast errors as anomalies. Recent transformer-based models improve long-range dependency modeling with self-attention and seasonal-trend decomposition. We introduce a hybrid detector combining a temporal convolutional backbone with a sparse attention module.",
    "document": "Related Work\n\nDetecting anomalous behavior in univariate and multivariate time series is fundamental in monitoring, finance, and industrial IoT. Methods vary in their assumptions about generative processes, noise structure, and the availability of labels.\n\nClassical anomaly detection in time series often builds on ARIMA and state space models that capture linear temporal dependencies under stationarity assumptions. Deep autoencoder methods learn compressed reconstructions and flag deviations by residual magnitude. Sequence-to-sequence architectures predict future windows and treat large forecast errors as anomalies. Recent transformer-based models improve long-range dependency modeling with self-attention and seasonal-trend decomposition. We introduce a hybrid detector combining a temporal convolutional backbone with a sparse attention module.\n\nOur evaluation spans benchmarks with injected and real anomalies, comparing precision-recall and early detection latency under different noise regimes.",
    "reason": "The span lists prior classical and neural approaches and then states the authors' design choice without synthesizing why existing techniques are inadequate or which specific limitations the hybrid is meant to overcome.",
    "start": 257,
    "end": 855,
    "label": "Lacks_synthesis"
  },
  {
    "span": "Earlier benchmarks consistently report 10–15% relative WER reductions from SpecAugment-like techniques.",
    "document": "Introduction\n\nEnd-to-end automatic speech recognition (ASR) has advanced rapidly with encoder–decoder architectures and self-supervised pretraining. Data augmentation has become a standard ingredient to improve robustness, with SpecAugment introducing time and frequency masking in the spectrogram domain. Earlier benchmarks consistently report 10–15% relative WER reductions from SpecAugment-like techniques. While augmentation helps generalization, its interaction with label scarcity, domain mismatch, and model scale is less understood. We therefore study how augmentation policies should be adapted under low-resource constraints and evaluate across multiple corpora with varying noise profiles.",
    "reason": "Provides a numeric claim about prior benchmark results without supporting citations (rule b).",
    "start": 306,
    "end": 409,
    "label": "Unsupported_claim"
  },
  {
    "span": "In (Vaswani et al., 2017)",
    "document": "Introduction\n\nNeural sequence modeling has traditionally relied on recurrent architectures with attention to capture long-range dependencies (Bahdanau et al., 2015; Luong et al., 2015). However, the computational bottlenecks of recurrence motivated alternative architectures that emphasize parallelism and global receptive fields.\n\nIn (Vaswani et al., 2017) the Transformer dispenses with recurrence entirely and uses multi-head self-attention to model token interactions in parallel, enabling significant speedups and improved performance in translation and language understanding (Dai et al., 2019; Dehghani et al., 2019). Subsequent work extended the approach with deeper stacks, improved positional encodings, and more efficient attention mechanisms (Shaw et al., 2018; Kitaev et al., 2020; Beltagy et al., 2020). Our work builds on these ideas but targets low-resource regimes where memory and compute are constrained.",
    "reason": "Wrong citation style: narrative sentence begins with 'In' followed by a parenthetical citation; should be 'In Vaswani et al. (2017)'.",
    "start": 332,
    "end": 357,
    "label": "Format"
  },
  {
    "span": "Nguyen et al., 2019)",
    "document": "Related Work\n\nTime-series forecasting with probabilistic models spans Gaussian processes, deep state space models, and transformer-based sequence models (Hyndman and Athanasopoulos, 2018; Salinas et al., 2020; Lim et al., 2021). We adopt a probabilistic perspective on covariate shift, extending importance weighting to nonstationary seasonalities. Prior Bayesian treatments Nguyen et al., 2019) derive hierarchical priors to share information across related series. Recent transformers integrate seasonal positional encodings and sparse attention to handle long horizons (Zhou et al., 2021; Wu et al., 2021). Our approach complements these by calibrating quantiles with a conformal layer that adapts to regime changes.\n",
    "reason": "Missing opening parenthesis for a parenthetical citation; the citation appears with only a closing parenthesis and should be “(Nguyen et al., 2019)” or used as a narrative citation with the year in parentheses.",
    "start": 375,
    "end": 395,
    "label": "Format"
  },
  {
    "span": "The CHEMPROT dataset is often used for benchmarking chemical–protein relation extraction in the biomedical NLP community.",
    "document": "Introduction\n\nRelation extraction in biomedical text supports downstream applications such as knowledge base construction and drug repurposing (Li et al., 2016; Peng et al., 2017). Pretrained language models adapted to biomedical corpora improve extraction accuracy over general-domain encoders (Beltagy et al., 2019; Lee et al., 2020). The CHEMPROT dataset is often used for benchmarking chemical–protein relation extraction in the biomedical NLP community. Nonetheless, label imbalance and annotation ambiguity motivate robust training objectives and calibrated decision thresholds. We introduce a contrastive calibration framework that improves minority relation detection while controlling overconfidence.",
    "reason": "Mentions a specific dataset at first mention without providing a citation to the dataset or its source.",
    "start": 337,
    "end": 458,
    "label": "Unsupported_claim"
  },
  {
    "span": "(Nguyen 2021)",
    "document": "Introduction\n\nRecent advances in few-shot learning rely on meta-training over a distribution of tasks to enable rapid adaptation (Finn et al., 2017; Snell et al., 2017). However, robustness to distribution shift remains limited (Yin et al., 2020). Several methods propose distributionally robust objectives to mitigate this issue (Sagawa et al., 2020; (Nguyen 2021)).\n\nWe propose a hierarchical meta-learner that explicitly models subpopulation structure and demonstrates improved worst-group performance.\n",
    "reason": "Missing comma between author and year in parenthetical citation; should be '(Nguyen, 2021)'.",
    "start": 352,
    "end": 365,
    "label": "Format"
  },
  {
    "span": "It has been widely shown that deeper GNNs always suffer from oversmoothing beyond 3 layers.",
    "document": "Related Work\n\nGraph neural networks (GNNs) have emerged as powerful models for learning over relational data. Architectural choices such as message passing depth, normalization, and residual connections strongly affect performance on node classification and link prediction tasks. It has been widely shown that deeper GNNs always suffer from oversmoothing beyond 3 layers. To address this, recent approaches incorporate skip connections, decoupled propagation, or spectral regularization to mitigate representation collapse.\n\nNonetheless, the interaction between depth, graph topology, and training dynamics remains incompletely understood. Our work revisits depth scaling in heterogeneous graphs, analyzing the role of degree distribution and feature homophily under controlled settings.",
    "reason": "Asserts a broad, field-specific conclusion ('widely shown' and 'always') with no citations to supporting studies (rule b and d).",
    "start": 281,
    "end": 372,
    "label": "Unsupported_claim"
  },
  {
    "span": "by (Kim et al., 2016)",
    "document": "Related Work\n\nData augmentation for named entity recognition (NER) aims to reduce overfitting and improve robustness under domain shifts (Dai and Adel, 2020; Ding et al., 2021). Span-level perturbations and synonym replacement provide simple yet effective regularization (Wei and Zou, 2019; Kobayashi, 2018). Template- and ontology-driven methods can preserve type consistency but risk reduced lexical diversity (Zeng et al., 2020; Wang et al., 2021). Contextual augmentation with masked language models yields fluent and type-respecting variants (Kumar et al., 2020; Anaby-Tavor et al., 2020). Prior work by (Kim et al., 2016) explores paraphrase-based augmentation, showing gains on small datasets. We extend these ideas with constrained decoding to maintain span boundaries and evaluate across low-resource settings.\n",
    "reason": "Wrong citation style: a narrative construction places a preposition directly before a parenthetical citation; should be narrative (\"Prior work by Kim et al. (2016)\") or rephrased.",
    "start": 606,
    "end": 627,
    "label": "Format"
  },
  {
    "span": "[24]",
    "document": "Related Work\n\nUnsupervised domain adaptation aims to transfer knowledge from labeled source domains to unlabeled targets (Ganin et al., 2016; Tzeng et al., 2017). Discrepancy-based methods minimize distribution gaps via moment matching or MMD (Long et al., 2015; Pan et al., 2011), while adversarial approaches learn domain-invariant features through confusion losses (Ganin and Lempitsky, 2015; Saito et al., 2018). Self-training with pseudo-labels has become a strong baseline, particularly when combined with consistency regularization (French et al., 2018; Zou et al., 2019). Recent works have shown promising results using curriculum learning [24] and target-specific augmentation (Xu et al., 2020; Kim and Kim, 2020), but robustness under large label shifts remains challenging.",
    "reason": "Inconsistent citation style: numeric bracket '[24]' appears in an author–year context. It should be replaced with an author–year citation (e.g., 'as shown by Santos et al. (2019)') or the paper should uniformly use numeric style.",
    "start": 648,
    "end": 652,
    "label": "Format"
  },
  {
    "span": "Abadi et al. (2016) proposed differentially private stochastic gradient descent. Shokri and Shmatikov (2015) studied privacy-preserving distributed learning. Hitaj et al. (2017) demonstrated GAN-based leakage attacks on federated learning.",
    "document": "Related Work\n\nPrivacy-preserving machine learning seeks to protect sensitive data while enabling effective model training and inference. Techniques include cryptographic protocols, perturbation-based privacy, and systems that limit exposure of individual contributions. Practical deployments must navigate a trade-off between privacy guarantees, utility, and computational cost.\n\nDifferential privacy and federated learning\n\nAbadi et al. (2016) proposed differentially private stochastic gradient descent. Shokri and Shmatikov (2015) studied privacy-preserving distributed learning. Hitaj et al. (2017) demonstrated GAN-based leakage attacks on federated learning. McMahan et al. (2017) introduced federated averaging.\n\nSecure computation and analytics\n\nComplementary approaches leverage homomorphic encryption, secure multiparty computation, and trusted execution environments to conduct analytics without direct data sharing, though overheads remain a key barrier.\n\nOur approach integrates record-level differential privacy with personalization-aware aggregation to retain accuracy under skewed user distributions, and we provide formal privacy accounting alongside empirical robustness to known inference attacks.",
    "reason": "The span lists separate works with no transitions or explanation of how they relate, leaving the connection among them implicit and abrupt. This is a multi-sentence coherence issue under (a) and (b).",
    "start": 425,
    "end": 664,
    "label": "Coherence"
  },
  {
    "span": "Matrix profile identifies discord subsequences in an unsupervised manner (Yeh et al., 2016). Variational autoencoders reconstruct normal patterns and signal deviations by residuals (Kingma and Welling, 2014; An and Cho, 2015).",
    "document": "Related Work\n\nAnomaly detection in time series underpins applications from manufacturing to cloud operations. Methods range from distance-based discord discovery to deep generative models that learn normal behavior and flag deviations.\n\nClassical approaches include z-score thresholding on engineered features and nearest-neighbor discord search, which offer interpretability but may miss context-dependent anomalies (Keogh et al., 2005; Chandola et al., 2009). Matrix profile identifies discord subsequences in an unsupervised manner (Yeh et al., 2016). Variational autoencoders reconstruct normal patterns and signal deviations by residuals (Kingma and Welling, 2014; An and Cho, 2015). Forecasting-based detectors predict future points and mark large prediction errors as anomalies (Breunig et al., 2000; Hundman et al., 2018).\n\nWe propose a context-aware reconstruction objective that penalizes off-manifold deviations conditioned on seasonal regimes, improving precision at fixed recall.",
    "reason": "Two sequential sentences switch from matrix profile to VAEs without stating how they compare or connect, lacking transitional phrasing and explicit relations.",
    "start": 462,
    "end": 688,
    "label": "Coherence"
  },
  {
    "span": "Prompting and few-shot learning have been applied for code generation across tasks (Chen et al., 2021; Austin et al., 2021; Nijkamp et al., 2022; Li et al., 2022). Building on this line of work, we present a new system for competitive programming.",
    "document": "Related Work\n\nLarge language models for program synthesis. Recent advances in pre-trained transformers have enabled models to generate code from natural language, type signatures, and unit tests. Instruction tuning and reinforcement learning from human feedback further refine outputs (Ouyang et al., 2022; Bai et al., 2022).\n\nPrompting and few-shot learning have been applied for code generation across tasks (Chen et al., 2021; Austin et al., 2021; Nijkamp et al., 2022; Li et al., 2022). Building on this line of work, we present a new system for competitive programming.\n\nVerification and repair. To improve correctness, research explores execution-guided decoding, test-time search, and iterative debugging with test feedback (Chen et al., 2021; Le et al., 2022; Xia et al., 2023). Static analysis signals and type constraints have also been integrated into decoding strategies (Shi et al., 2023; Brix et al., 2022).",
    "reason": "The span moves from a list of prior prompting-based approaches directly to the authors' contribution without specifying what those approaches lack or how the new system addresses a specific unresolved issue.",
    "start": 327,
    "end": 574,
    "label": "Lacks_synthesis"
  },
  {
    "span": "Multimodal translation augments text with visual signals to resolve ambiguities (Specia et al., 2016; Elliott et al., 2017). Early models fuse image features via concatenation or gating (Caglayan et al., 2016; Calixto et al., 2017), while later work leverages cross-modal attention and pre-trained vision encoders (Yao and Wan, 2020; Caglayan et al., 2020).",
    "document": "Introduction\n\nMultimodal machine translation aims to improve translation quality by leveraging non-textual context, particularly images, to disambiguate referents and capture scene-level semantics. However, integration strategies must avoid overreliance on visual noise, which can degrade performance when images are weakly informative.\n\nMultimodal translation augments text with visual signals to resolve ambiguities (Specia et al., 2016; Elliott et al., 2017). Early models fuse image features via concatenation or gating (Caglayan et al., 2016; Calixto et al., 2017), while later work leverages cross-modal attention and pre-trained vision encoders (Yao and Wan, 2020; Caglayan et al., 2020).\n\nWe introduce Contrastively Guided Fusion (CGF), which aligns textual queries with salient visual regions using contrastive objectives and dynamically down-weights non-informative visual cues. Our method integrates a sparsity-inducing gate to modulate cross-modal exchange.\n\nExperiments on Multi30K and Ambiguous Captions show that CGF improves BLEU and COMET while being robust to corrupted or mismatched images. Ablations quantify the impact of contrastive alignment and gating on visual overreliance.",
    "reason": "The span summarizes prior multimodal MT methods but does not connect them to the authors’ approach or identify the specific shortcoming that motivates their work, thus lacking synthesis (criteria a and c).",
    "start": 338,
    "end": 695,
    "label": "Lacks_synthesis"
  },
  {
    "span": "(Jones et al., 2018,; Miller, 2020)",
    "document": "Related Work\n\nBenchmark curation has exposed spurious correlations that inflate apparent progress in textual entailment and commonsense reasoning (Gururangan et al., 2018; Poliak et al., 2018; Niven and Kao, 2019). Adversarial filtering and contrast sets have been proposed to address this issue (Zellers et al., 2019; Gardner et al., 2020). Several datasets focus on minimal pairs to isolate specific reasoning skills (McCoy et al., 2019; Kaushik et al., 2020). Meanwhile, error analyses point to reliance on shallow heuristics rather than true inference (Ribeiro et al., 2020; Geirhos et al., 2020).\n\nOur work builds a diagnostic suite that targets lexical, syntactic, and pragmatic confounds simultaneously. We synthesize controlled perturbations to measure sensitivity and transfer, comparing findings across prior resources (Jones et al., 2018,; Miller, 2020) and contemporary pretrained models.",
    "reason": "Malformed separator in a multi-citation group with an extra comma before the semicolon; should be \"(Jones et al., 2018; Miller, 2020)\".",
    "start": 829,
    "end": 864,
    "label": "Format"
  },
  {
    "span": "It is widely known that IPS suffers from high variance in sparse regimes",
    "document": "Introduction\n\nCounterfactual learning for recommender systems seeks to correct exposure bias by reweighting logged interactions under a stochastic logging policy. Inverse propensity scoring (IPS) provides an unbiased objective but can be unstable when propensities are small or user–item interactions are sparse.\n\nIt is widely known that IPS suffers from high variance in sparse regimes, motivating doubly robust estimators and self-normalization techniques. Yet, these remedies can introduce bias or require strong modeling assumptions that are difficult to validate at scale.\n\nWe propose a variance-controlled objective that adaptively truncates high-weight samples using a calibration signal derived from user and item uncertainty. Our method balances bias–variance trade-offs without access to explicit propensities and is amenable to large-scale training.",
    "reason": "This niche, field-specific claim about IPS variance is stated without citation to foundational work; per rule b, such specific knowledge should be cited.",
    "start": 314,
    "end": 386,
    "label": "Unsupported_claim"
  },
  {
    "span": ". To get the solution efficiently, Cuturi (2013) provides a regularizer inspired by a probabilistic theory and then uses Sinkhorn's algorithm. Kusner et al. (2015) relax the problem to get the quadratic-time solution by removing one of the constraints, and Wu et al. (2018) introduce a kernel method to approximate the optimal transport.\n",
    "document": "Related work\n\nSemantic textual similarity\n\nMost recent studies tried to leverage a pretrained language model with various model architectures and training objectives for STS tasks, achieving the state-of-the-art performance. In terms of model architecture, Devlin et al. (2019) focus on exhaustive cross-correlation between sentences by taking a concatenated text of two sentences as an input, while Reimers and Gurevych (2019) improve scalability based on a Siamese network and Humeau et al. (2020) adopt a hybrid approach. Along with the progress of model architectures, many advanced objectives for STS tasks were proposed as well. Specifically, Reimers and Gurevych (2019) mainly use the classification objective for an NLI dataset, and Wu et al. (2020) adopt contrastive learning to utilize self-supervision from a large corpus. Yan et al. (2021); Gao et al. (2021) incorporate a parallel corpus such as NLI datasets into their contrastive learning framework.\n\nDespite their effectiveness, the interpretability of the above models for STS tasks was not fully explored (Belinkov and Glass, 2019). One related task is interpretable STS, which aims to predict chunk alignment between two sentences . For this task, a variety of supervised approaches were proposed based on neural networks (Konopík et al., 2016;, linear programming (Tekumalla and Jat, 2016), and pretrained models (Maji et al., 2020). However, these methods cannot predict the similarity between sentences because they focus on finding chunk alignment only. To the best of our knowledge, no previous approaches based on a pretrained model have taken into account both sentence similarity and interpretation.\n\nOptimal transport\n\nOptimal transport (Monge, 1781) has been successfully adopted in natural language processing due to its ability to find a plausible correspondence between two objects (Li et al., 2020;. For example, Kusner et al. (2015) adopt optimal transport to measure the distance between two documents with pretrained word vectors. In addition, Swanson et al. (2020) discover the rationale in textmatching via optimal transport, thereby improving model interpretability.\n\nOne well-known limitation of optimal transport is that finding the optimal solution is computationally intensive, and thus approximation schemes for this problem have been extensively researched (Grauman and Darrell, 2004;Shirdhonkar and Jacobs, 2008). To get the solution efficiently, Cuturi (2013) provides a regularizer inspired by a probabilistic theory and then uses Sinkhorn's algorithm. Kusner et al. (2015) relax the problem to get the quadratic-time solution by removing one of the constraints, and Wu et al. (2018) introduce a kernel method to approximate the optimal transport.\n\n ",
    "start": 2408,
    "end": 2746,
    "label": "Coherence"
  },
  {
    "span": "Recent works have achieved word error rates below 5% on LibriSpeech test-clean.",
    "document": "Introduction\n\nEnd-to-end automatic speech recognition (ASR) has advanced rapidly with encoder-decoder architectures trained on large collections of read and conversational audio. Connectionist temporal classification and attention-based transducers have both demonstrated strong performance by learning to align acoustic features with subword targets. Self-supervised pretraining on unlabeled speech further reduces the amount of labeled data needed for competitive recognition in low-resource settings. Recent works have achieved word error rates below 5% on LibriSpeech test-clean. However, these systems often rely on domain-matched training conditions and aggressive data augmentation, which can limit generalization to noisy, far-field environments. We revisit robustness by integrating a modulation-invariant front end with a curriculum on signal-to-noise ratios.",
    "reason": "Uses the phrase 'Recent works' with a performance claim but does not provide any citations.",
    "start": 504,
    "end": 583,
    "label": "Unsupported_claim"
  },
  {
    "span": "Sequence-to-sequence models produce function summaries from code (Iyer et al., 2016). Pointer-generators help copy identifiers (See et al., 2017). Pretrained models like CodeBERT improved retrieval and summarization (Feng et al., 2020).",
    "document": "Related Work\n\nCode summarization translates source code into concise natural language descriptions. Challenges include handling long identifiers, out-of-vocabulary tokens, and capturing program semantics beyond syntax.\n\nSequence-to-sequence models produce function summaries from code (Iyer et al., 2016). Pointer-generators help copy identifiers (See et al., 2017). Pretrained models like CodeBERT improved retrieval and summarization (Feng et al., 2020).\n\nRecent methods incorporate AST structures and data-flow graphs to ground generation in program semantics. Our approach unifies structural encodings with retrieval-augmented decoding for better factuality.",
    "reason": "The span provides a list of works in separate sentences without transitions or explanation of their relationships, resulting in an abrupt, incoherent progression.",
    "start": 220,
    "end": 456,
    "label": "Coherence"
  },
  {
    "span": "Self-supervised pretraining has produced transferable visual features. SimCLR leverages contrastive objectives with strong augmentations (Chen et al., 2020). BYOL removes negative samples via online and target networks (Grill et al., 2020). DINO learns with self-distillation and centering (Caron et al., 2021). Masked image modeling reconstructs patches (He et al., 2022). Data augmentations influence invariances (Tian et al., 2020).",
    "document": "Related Work\n\nLearning visual representations without labels has achieved competitive performance on downstream tasks. Contrastive methods, redundancy reduction, and generative masking objectives characterize the current landscape, but their invariances and failure modes differ substantially. Understanding these differences is important for transfer and robustness.\n\nSelf-supervised pretraining has produced transferable visual features. SimCLR leverages contrastive objectives with strong augmentations (Chen et al., 2020). BYOL removes negative samples via online and target networks (Grill et al., 2020). DINO learns with self-distillation and centering (Caron et al., 2021). Masked image modeling reconstructs patches (He et al., 2022). Data augmentations influence invariances (Tian et al., 2020).\n\nWe analyze invariance profiles across methods and propose a curriculum that harmonizes augmentation strength with masking ratio.",
    "reason": "The span lists several self-supervised methods and an augmentation study without articulating how they relate to each other; sentences are juxtaposed with no explicit connective reasoning, producing an abrupt, incoherent flow.",
    "start": 369,
    "end": 804,
    "label": "Coherence"
  },
  {
    "span": " There are also task-specific BERT models, especially for the task of grammatical error correction since an important type of error is caused by characters pronounced with the same pinyin.",
    "document": "Related work\n\nWe describe related works on pinyin input method and pinyin-enhanced pretrained models here.\n\nPinyin Input Method \n\nWe describe existing works based on whether the input pinyin is perfect or abbreviated. A majority of existing works focus on perfect pinyin. Traditional models are typically based on statistical language models (Chen and Lee, 2000) and statistical machine translation (Yang et al., 2012). Recent works are usually built with neural network. For example, Moon IME (Huang et al., 2018) integrates attention-based neural network and an information retrieval module. Zhang et al. (2019) improves an LSTM-\nbased encoder-decoder model with online vocabulary adaptation. For abbreviated pinyin, CoCAT (Huang et al., 2015) uses machine translation technology to reduce the number of the typing letters. Huang and Zhao (2018) propose an LSTM-based encoder-decoder approach with the concatenation of context words and abbreviated pinyin as input. Our work differs from existing works in that we are the first one to exploit GPT and verify the pros and cons of GPT in different situations. In addition, there are some works handling\npinyin with typing errors. Chen and Lee (2000) investigate a typing model which handles spelling correction in sentence-based pinyin input method. CHIME (Zheng et al., 2011) is a error-tolerant Chinese pinyin input method. It finds similar pinyin which will be further ranked with Chinese specific features. Jia and Zhao (2014) propose a joint graph model to globally optimize the tasks of pinyin input method and typo correction. We leave error-tolerant pinyin input method as a future work. \n\nPinyin-enhanced Pretrained Models \n\nOur methodology also relates to pretrained models that use pinyin information. Sun et al. (2021) propose a general-purpose Chinese BERT with\nnew embedding layers to inject pinyin and glyph information of characters. There are also task-specific BERT models, especially for the task of grammatical error correction since an important type of error is caused by characters pronounced with the same pinyin. Zhang et al. (2021a) add a pinyin embedding layer and learns to predict characters from similarly pronounced candidates. PLOME (Liu et al., 2021) add two embedding layers implemented with two GRU networks to inject both pinyin and shape of characters, respectively. Xu et al. (2021) add a hierarchical encoder to inject the pinyin letters at character and sentence levels, and add a ResNet encoder to use graphic features of character image.\n\n ",
    "start": 1899,
    "end": 2087,
    "label": "Unsupported_claim"
  },
  {
    "span": "Zhang et al. (2019) improves an LSTM-\nbased encoder-decoder model with online vocabulary adaptation. For abbreviated pinyin, CoCAT (Huang et al., 2015) uses machine translation technology to reduce the number of the typing letters. Huang and Zhao (2018) propose an LSTM-based encoder-decoder approach with the concatenation of context words and abbreviated pinyin as input.",
    "document": "Related work\n\nWe describe related works on pinyin input method and pinyin-enhanced pretrained models here.\n\nPinyin Input Method \n\nWe describe existing works based on whether the input pinyin is perfect or abbreviated. A majority of existing works focus on perfect pinyin. Traditional models are typically based on statistical language models (Chen and Lee, 2000) and statistical machine translation (Yang et al., 2012). Recent works are usually built with neural network. For example, Moon IME (Huang et al., 2018) integrates attention-based neural network and an information retrieval module. Zhang et al. (2019) improves an LSTM-\nbased encoder-decoder model with online vocabulary adaptation. For abbreviated pinyin, CoCAT (Huang et al., 2015) uses machine translation technology to reduce the number of the typing letters. Huang and Zhao (2018) propose an LSTM-based encoder-decoder approach with the concatenation of context words and abbreviated pinyin as input. Our work differs from existing works in that we are the first one to exploit GPT and verify the pros and cons of GPT in different situations. In addition, there are some works handling\npinyin with typing errors. Chen and Lee (2000) investigate a typing model which handles spelling correction in sentence-based pinyin input method. CHIME (Zheng et al., 2011) is a error-tolerant Chinese pinyin input method. It finds similar pinyin which will be further ranked with Chinese specific features. Jia and Zhao (2014) propose a joint graph model to globally optimize the tasks of pinyin input method and typo correction. We leave error-tolerant pinyin input method as a future work. \n\nPinyin-enhanced Pretrained Models \n\nOur methodology also relates to pretrained models that use pinyin information. Sun et al. (2021) propose a general-purpose Chinese BERT with\nnew embedding layers to inject pinyin and glyph information of characters. There are also task-specific BERT models, especially for the task of grammatical error correction since an important type of error is caused by characters pronounced with the same pinyin. Zhang et al. (2021a) add a pinyin embedding layer and learns to predict characters from similarly pronounced candidates. PLOME (Liu et al., 2021) add two embedding layers implemented with two GRU networks to inject both pinyin and shape of characters, respectively. Xu et al. (2021) add a hierarchical encoder to inject the pinyin letters at character and sentence levels, and add a ResNet encoder to use graphic features of character image.\n\n ",
    "start": 594,
    "end": 967,
    "label": "Coherence"
  },
  {
    "span": "Sun et al. (2021) propose a general-purpose Chinese BERT with\nnew embedding layers to inject pinyin and glyph information of characters. There are also task-specific BERT models, especially for the task of grammatical error correction since an important type of error is caused by characters pronounced with the same pinyin. Zhang et al. (2021a) add a pinyin embedding layer and learns to predict characters from similarly pronounced candidates. PLOME (Liu et al., 2021) add two embedding layers implemented with two GRU networks to inject both pinyin and shape of characters, respectively. Xu et al. (2021) add a hierarchical encoder to inject the pinyin letters at character and sentence levels, and add a ResNet encoder to use graphic features of character image.",
    "document": "Related work\n\nWe describe related works on pinyin input method and pinyin-enhanced pretrained models here.\n\nPinyin Input Method \n\nWe describe existing works based on whether the input pinyin is perfect or abbreviated. A majority of existing works focus on perfect pinyin. Traditional models are typically based on statistical language models (Chen and Lee, 2000) and statistical machine translation (Yang et al., 2012). Recent works are usually built with neural network. For example, Moon IME (Huang et al., 2018) integrates attention-based neural network and an information retrieval module. Zhang et al. (2019) improves an LSTM-\nbased encoder-decoder model with online vocabulary adaptation. For abbreviated pinyin, CoCAT (Huang et al., 2015) uses machine translation technology to reduce the number of the typing letters. Huang and Zhao (2018) propose an LSTM-based encoder-decoder approach with the concatenation of context words and abbreviated pinyin as input. Our work differs from existing works in that we are the first one to exploit GPT and verify the pros and cons of GPT in different situations. In addition, there are some works handling\npinyin with typing errors. Chen and Lee (2000) investigate a typing model which handles spelling correction in sentence-based pinyin input method. CHIME (Zheng et al., 2011) is a error-tolerant Chinese pinyin input method. It finds similar pinyin which will be further ranked with Chinese specific features. Jia and Zhao (2014) propose a joint graph model to globally optimize the tasks of pinyin input method and typo correction. We leave error-tolerant pinyin input method as a future work. \n\nPinyin-enhanced Pretrained Models \n\nOur methodology also relates to pretrained models that use pinyin information. Sun et al. (2021) propose a general-purpose Chinese BERT with\nnew embedding layers to inject pinyin and glyph information of characters. There are also task-specific BERT models, especially for the task of grammatical error correction since an important type of error is caused by characters pronounced with the same pinyin. Zhang et al. (2021a) add a pinyin embedding layer and learns to predict characters from similarly pronounced candidates. PLOME (Liu et al., 2021) add two embedding layers implemented with two GRU networks to inject both pinyin and shape of characters, respectively. Xu et al. (2021) add a hierarchical encoder to inject the pinyin letters at character and sentence levels, and add a ResNet encoder to use graphic features of character image.\n\n ",
    "start": 1763,
    "end": 2529,
    "label": "Coherence"
  },
  {
    "span": "Our work differs from existing works in that we are the first one to exploit GPT and verify the pros and cons of GPT in different situations. In addition, there are some works handling\npinyin with typing errors. ",
    "document": "Related work\n\nWe describe related works on pinyin input method and pinyin-enhanced pretrained models here.\n\nPinyin Input Method \n\nWe describe existing works based on whether the input pinyin is perfect or abbreviated. A majority of existing works focus on perfect pinyin. Traditional models are typically based on statistical language models (Chen and Lee, 2000) and statistical machine translation (Yang et al., 2012). Recent works are usually built with neural network. For example, Moon IME (Huang et al., 2018) integrates attention-based neural network and an information retrieval module. Zhang et al. (2019) improves an LSTM-\nbased encoder-decoder model with online vocabulary adaptation. For abbreviated pinyin, CoCAT (Huang et al., 2015) uses machine translation technology to reduce the number of the typing letters. Huang and Zhao (2018) propose an LSTM-based encoder-decoder approach with the concatenation of context words and abbreviated pinyin as input. Our work differs from existing works in that we are the first one to exploit GPT and verify the pros and cons of GPT in different situations. In addition, there are some works handling\npinyin with typing errors. Chen and Lee (2000) investigate a typing model which handles spelling correction in sentence-based pinyin input method. CHIME (Zheng et al., 2011) is a error-tolerant Chinese pinyin input method. It finds similar pinyin which will be further ranked with Chinese specific features. Jia and Zhao (2014) propose a joint graph model to globally optimize the tasks of pinyin input method and typo correction. We leave error-tolerant pinyin input method as a future work. \n\nPinyin-enhanced Pretrained Models \n\nOur methodology also relates to pretrained models that use pinyin information. Sun et al. (2021) propose a general-purpose Chinese BERT with\nnew embedding layers to inject pinyin and glyph information of characters. There are also task-specific BERT models, especially for the task of grammatical error correction since an important type of error is caused by characters pronounced with the same pinyin. Zhang et al. (2021a) add a pinyin embedding layer and learns to predict characters from similarly pronounced candidates. PLOME (Liu et al., 2021) add two embedding layers implemented with two GRU networks to inject both pinyin and shape of characters, respectively. Xu et al. (2021) add a hierarchical encoder to inject the pinyin letters at character and sentence levels, and add a ResNet encoder to use graphic features of character image.\n\n ",
    "start": 968,
    "end": 1180,
    "label": "Coherence"
  },
  {
    "span": "Chen et al. (2021) release Codex for translating natural language to code. Austin et al. (2021) analyze program synthesis with self-sampling strategies. Syntax-guided synthesis integrates grammar constraints (Alur et al., 2013). Lemieux et al. (2019) use input-output examples to repair programs.",
    "document": "Related Work\n\nProgram synthesis from natural language combines large language models with constraints and feedback. We summarize approaches spanning autoregressive decoding, constraint satisfaction, and repair.\n\nChen et al. (2021) release Codex for translating natural language to code. Austin et al. (2021) analyze program synthesis with self-sampling strategies. Syntax-guided synthesis integrates grammar constraints (Alur et al., 2013). Lemieux et al. (2019) use input-output examples to repair programs.\n\nIn contrast, we investigate verifier-guided decoding that interleaves execution feedback with beam search under resource limits.",
    "reason": "The works are introduced as isolated statements with no connective tissue explaining how LLM-based synthesis relates to syntax guidance or repair; the relationships among these multiple sentences are left implicit.",
    "start": 212,
    "end": 508,
    "label": "Coherence"
  },
  {
    "span": "Recent works have demonstrated strong gains from contrastive pretraining in low-resource ASR",
    "document": "Related Work\n\nSelf-supervised learning for automatic speech recognition (ASR) has reduced labeled data requirements by leveraging untranscribed audio. Methods based on masked acoustic modeling and predictive coding have been particularly successful in resource-rich settings. However, their behavior under extreme label scarcity remains less understood.\n\nRecent works have demonstrated strong gains from contrastive pretraining in low-resource ASR, motivating a closer look at task and domain mismatches between pretraining and fine-tuning. In parallel, multilingual representations have been explored to transfer knowledge across typologically diverse languages, but challenges such as phoneme inventory mismatch and prosodic variation persist.\n\nOur study complements this line of research by isolating the contribution of representation quality from data augmentation and decoding strategies, and by evaluating across a suite of low-resource corpora with consistent tokenization and beam-search parameters.\n",
    "reason": "Uses the phrase 'Recent works' to claim performance gains without citing any supporting studies.",
    "start": 355,
    "end": 447,
    "label": "Unsupported_claim"
  },
  {
    "span": "(Kim et al., 2018",
    "document": "Introduction\n\nGraph neural networks (GNNs) have become a default choice for relational reasoning (Kipf and Welling, 2017; Hamilton et al., 2017). Regularization techniques such as dropout on edges and feature perturbations help prevent over-smoothing (Rong et al., 2020; Zhao and Akoglu, 2020). Recent work suggests that positional encodings improve expressivity for long-range dependencies (Dwivedi et al., 2021). However, empirical studies often omit calibration and uncertainty estimation, despite evidence that calibrated posteriors enable safer deployment (Kim et al., 2018 and (Guo et al., 2017). We revisit calibration under distribution shift with node- and graph-level tasks.",
    "reason": "Parenthetical citation is missing the closing bracket; should be '(Kim et al., 2018)'.",
    "start": 561,
    "end": 578,
    "label": "Format"
  },
  {
    "span": "In a previous study, the authors showed that back-translation eliminates exposure bias.",
    "document": "Related Work\n\nData augmentation in machine translation (MT) has proven crucial for improving generalization under limited parallel data. Back-translation leverages monolingual target data by generating synthetic source sentences, augmenting the parallel corpus used to train the forward model. Variants incorporate noisy channel objectives, tagged back-translations, and iterative refinement. In a previous study, the authors showed that back-translation eliminates exposure bias. Other lines of work address domain adaptation via fine-tuning on in-domain data, vocabulary smoothing, and contrastive learning. Despite these advances, the interactions between synthetic data quality, sampling strategies, and domain shift are not fully understood, motivating our systematic analysis.\n",
    "reason": "Refers to a specific prior study and a strong claimed result without citing the study (violates rule a).",
    "start": 393,
    "end": 480,
    "label": "Unsupported_claim"
  },
  {
    "span": "SpecAugment is now the default augmentation in most competitive ASR systems.",
    "document": "Related Work\n\nEnd-to-end automatic speech recognition (ASR) has advanced with encoder–decoder and CTC-based architectures, aided by large-scale self-supervised pretraining (Graves et al., 2013; Chan et al., 2016; Baevski et al., 2020). Data augmentation plays a key role in robustness, with time–frequency masking and time warping proposed in SpecAugment (Park et al., 2019). Noisy student training and synthetic data have further improved performance on noisy conditions (Xie et al., 2020).\n\nSpecAugment is now the default augmentation in most competitive ASR systems. Nevertheless, the interaction between masking policies and learned representations in pretrained encoders remains under-characterized.\n\nWe analyze augmentation–pretraining synergies and introduce policy schedules that adapt to model confidence.",
    "reason": "Claims widespread adoption across competitive systems without citing surveys, benchmarks, or leaderboards to substantiate the claim (rule b and d).",
    "start": 493,
    "end": 569,
    "label": "Unsupported_claim"
  },
  {
    "span": "Brown et al. (2020) introduced in-context learning with large autoregressive models. Gao et al. (2021) explored prompt-based fine-tuning under few-shot constraints. Liu et al. (2021) presented a survey of prompt engineering techniques across tasks. Shi et al. (2023) investigated calibration of prompted models.",
    "document": "Related Work\n\nPrompt-based learning has reshaped how NLP systems adapt to downstream tasks by reusing pre-trained language models as in-context reasoners or lightly tuned learners. Early approaches emphasized crafting task descriptions and verbalizers to align model priors with label spaces, while later methods extended to soft prompts and multi-step reasoning.\n\nBrown et al. (2020) introduced in-context learning with large autoregressive models. Gao et al. (2021) explored prompt-based fine-tuning under few-shot constraints. Liu et al. (2021) presented a survey of prompt engineering techniques across tasks. Shi et al. (2023) investigated calibration of prompted models.\n\nConcurrently, retrieval-augmented prompting and instruction tuning sought to reduce sensitivity to template wording and to improve generalization across tasks (Sanh et al., 2022; Ouyang et al., 2022). Despite these advances, the stability of prompt optimization in noisy or domain-shifted settings remains an open challenge, motivating our study of robustness criteria and evaluation protocols.",
    "reason": "The paragraph lists four cited works in consecutive sentences without transitions or explicit relationships among them, making the connection between each paper abrupt and unclear.",
    "start": 365,
    "end": 676,
    "label": "Coherence"
  },
  {
    "span": "Recent works have shown impressive gains on low-resource languages such as Marathi and Amharic.",
    "document": "Introduction\n\nAutomatic text summarization has advanced rapidly with the advent of pre-trained multilingual encoders and cross-lingual transfer. Prior approaches in high-resource settings have benefited from large-scale datasets and robust evaluation metrics, yet low-resource scenarios remain challenging due to scarcity of aligned summaries and domain mismatch.\n\nRecent works have shown impressive gains on low-resource languages such as Marathi and Amharic. However, evaluations are often inconsistent across datasets and metrics, making direct comparisons difficult. In this paper, we propose a unified multilingual evaluation suite and a transfer-learning strategy that reduces annotation cost while improving robustness across domains.\n\nWe further analyze failure modes that are specific to morphologically rich and code-mixed settings, and we provide recommendations for future benchmark design.",
    "reason": "Mentions 'recent works' achieving gains without providing any citations to support the claim (rule d).",
    "start": 365,
    "end": 460,
    "label": "Unsupported_claim"
  },
  {
    "span": "Recent works have conclusively shown that temporal attention is superior to convolution for long-horizon traffic prediction.",
    "document": "Related Work\n\nSpatio-temporal forecasting models for traffic speed and volume have evolved from classical autoregressive baselines (Williams and Hoel, 2003) to graph-based deep architectures that encode road topology and temporal dynamics (Li et al., 2018; Yu et al., 2018). Graph convolutional networks (GCNs) and their temporal extensions integrate neighborhood information with recurrent or convolutional temporal modules, demonstrating strong performance on urban traffic benchmarks (Wu et al., 2019; Bai et al., 2020).\n\nSelf-attention has emerged as a compelling alternative to recurrent models, enabling long-range temporal dependencies and dynamic receptive fields across nodes (Vaswani et al., 2017; Cao et al., 2021). Hybrid models combine attention with graph propagation to jointly capture structural and temporal correlations under distribution shift (Jiang et al., 2020). Recent works have conclusively shown that temporal attention is superior to convolution for long-horizon traffic prediction. Despite these advances, challenges remain in handling sensor failures, non-recurrent events, and topology changes due to construction and incidents.\n\nOur work revisits long-horizon prediction under severe missingness and sparse supervision, proposing a masked consistency objective that is topology-aware and robust to node dropout.",
    "reason": "The statement asserts a definitive prior-work conclusion without providing any citations to specific studies, violating the requirement to cite when referencing prior findings.",
    "start": 885,
    "end": 1009,
    "label": "Unsupported_claim"
  },
  {
    "span": "MOOC dropout rates regularly exceed 90%",
    "document": "Introduction\n\nPredicting learner persistence in massive open online courses (MOOCs) is crucial for timely interventions and course design. Despite rich clickstream traces and forum interactions, models often overfit to course-specific artifacts and fail to generalize to new cohorts.\n\nRelated Work\n\nEngagement features such as session length and assessment latency correlate with persistence, and temporal models capture weekly rhythms of activity. MOOC dropout rates regularly exceed 90%, motivating early-warning systems that can trigger nudges and personalized content. However, cross-course transfer remains limited due to heterogeneity in platforms and curricula.",
    "reason": "Asserts a specific statistic without citation or evidence, violating rule (b).",
    "start": 449,
    "end": 488,
    "label": "Unsupported_claim"
  },
  {
    "span": "Neural-guided search improves performance on synthesis from specifications (Balog et al., 2017). The CoNaLa dataset provides natural language to code pairs (Yin et al., 2018). Type systems restrict candidate programs to satisfy interface constraints (Padhye et al., 2019).",
    "document": "Related Work\n\nProgram synthesis from natural language combines semantic parsing, search, and neural guidance to map intents to executable code. Approaches differ in the target DSL, supervision regimes, and the degree of symbolic structure exploited during decoding.\n\nNeural-guided search improves performance on synthesis from specifications (Balog et al., 2017). The CoNaLa dataset provides natural language to code pairs (Yin et al., 2018). Type systems restrict candidate programs to satisfy interface constraints (Padhye et al., 2019). Supervised sequence-to-sequence models benefit from constrained decoding over grammar productions (Dong and Lapata, 2016), and retrieval-augmented methods condition on similar examples to reduce search complexity (Hashimoto et al., 2018).\n\nOur method integrates type-aware constraints with example-based retrieval to prune the search space while maintaining natural language flexibility.",
    "reason": "The cited works are presented as disconnected statements (neural search, datasets, type systems) with no transitions or explanation of how they relate, causing abrupt topic shifts.",
    "start": 267,
    "end": 539,
    "label": "Coherence"
  },
  {
    "span": "It is widely known that MovieLens-20M contains severe popularity bias.",
    "document": "Introduction\n\nRecommender systems increasingly grapple with confounding factors such as exposure bias, selection bias, and popularity bias. Traditional matrix factorization and neural collaborative filtering focus on rating prediction and implicit feedback modeling but often overlook the causal mechanisms that lead to observed interactions. Recent work on debiasing has introduced inverse propensity scoring, exposure modeling, and counterfactual inference to correct for biased feedback.\n\nIt is widely known that MovieLens-20M contains severe popularity bias. Although popularity skew is present in many public benchmarks, the degree and impact of this bias can vary substantially by curation and time period. Without appropriate correction, models can overfit to head items and degrade long-tail user satisfaction.\n\nTo address this, we propose a two-stage estimator that disentangles exposure from preference using weak supervision signals derived from randomized recommendations.",
    "reason": "Asserts a commonly accepted property of a specific dataset without citing any supporting evidence or dataset analysis.",
    "start": 492,
    "end": 562,
    "label": "Unsupported_claim"
  },
  {
    "span": "We follow the setup where BERT was used in an AES task trained on essays from grade 6 to 12.",
    "document": "Introduction\n\nAutomated essay scoring (AES) aims to predict holistic or trait-specific writing quality. Transformer encoders have recently been explored to leverage contextual representations, while ensuring fairness and interpretability remains a critical challenge. Grade heterogeneity introduces distributional shifts in vocabulary, structure, and discourse features.\n\nWe follow the setup where BERT was used in an AES task trained on essays from grade 6 to 12. Our framework extends this configuration with prompt-based conditioning on rubric descriptors and calibration techniques to align score distributions with human raters. We examine cross-prompt generalization and the impact of length normalization.",
    "reason": "Describes a specific prior setup using BERT for AES without citing the work that introduced it.",
    "start": 372,
    "end": 464,
    "label": "Unsupported_claim"
  },
  {
    "span": "Secure aggregation prevents servers from seeing individual updates (Bonawitz et al., 2017). Differentially private SGD bounds information leakage during training (Abadi et al., 2016). Split learning partitions models across clients and server (Gupta and Raskar, 2018).",
    "document": "Related Work\n\nPrivacy-preserving machine learning encompasses cryptographic protocols, statistical privacy guarantees, and architectural partitioning. Deployments often need to balance accuracy, communication cost, and threat models spanning honest-but-curious to malicious adversaries.\n\nSecure aggregation prevents servers from seeing individual updates (Bonawitz et al., 2017). Differentially private SGD bounds information leakage during training (Abadi et al., 2016). Split learning partitions models across clients and server (Gupta and Raskar, 2018). Hardware-based trusted execution can also reduce attack surfaces (Hunt et al., 2018). However, how these techniques interact under heterogeneous client data and partial participation is not well understood.\n\nWe propose a modular framework that composes secure aggregation with DP accounting and selective split points, and we analyze accuracy-privacy-communication trade-offs under realistic participation patterns.",
    "reason": "The span lists three privacy techniques from different paradigms without transitions or an explicit statement of their relationships or comparative roles. The abrupt sequence causes a coherence issue across multiple sentences.",
    "start": 288,
    "end": 556,
    "label": "Coherence"
  },
  {
    "span": "Prompt-based learning improves few-shot performance (Brown et al., 2020). Gao et al. (2021) use automatic prompt search. Instruction tuning scales to thousands of tasks (Wei et al., 2022). Chain-of-thought prompting elicits reasoning (Wei et al., 2022b).",
    "document": "Related Work\n\nPrompting and Conditioning Large Language Models\n\nLarge language models can be adapted to new tasks via prompting rather than gradient-based fine-tuning. Methods vary in how they select prompts, incorporate demonstrations, and align models with user instructions.\n\nPrompting Paradigms\n\nPrompt-based learning improves few-shot performance (Brown et al., 2020). Gao et al. (2021) use automatic prompt search. Instruction tuning scales to thousands of tasks (Wei et al., 2022). Chain-of-thought prompting elicits reasoning (Wei et al., 2022b).\n\nAlignment and Safety\n\nReinforcement learning from human feedback and constitutional objectives improve helpfulness and harmlessness (Ouyang et al., 2022; Bai et al., 2022). Our approach studies domain-specific prompt selection under latency constraints.",
    "reason": "The cited works are presented as a list without indicating how automatic prompt search relates to instruction tuning or chain-of-thought, lacking transitions and explicit relationships between them.",
    "start": 300,
    "end": 554,
    "label": "Coherence"
  },
  {
    "span": "(Chen and Malik, 2017",
    "document": "Introduction\n\nMultimodal representation learning seeks to align and fuse signals across text, audio, and vision. Cross-modal objectives such as image-text contrastive learning have enabled strong zero-shot transfer (Radford et al., 2021; Jia et al., 2021). Early vision-language models relied on region-level features and co-attention for grounding (Anderson et al., 2018; Lu et al., 2019), whereas recent unified encoders operate on dense patches and subword tokens for end-to-end finetuning (Kim et al., 2021). While pretraining on web-scale aligned pairs is effective, curating hard negatives remains challenging (Chen and Malik, 2017 and subsequent work has explored curriculum mining to mitigate spurious correlations. We investigate whether incorporating semantic control codes during pretraining improves compositional generalization without sacrificing retrieval accuracy.\n\nRelated Work\n\nGenerative modeling for cross-modal synthesis leverages diffusion or autoregressive decoders guided by textual prompts (Ramesh et al., 2022; Saharia et al., 2022). Efforts on evaluating compositionality propose counterfactual edits and structured probes to disentangle co-occurrence from causal grounding (Atzmon et al., 2020; Parcalabescu et al., 2021).",
    "reason": "Missing closing parenthesis in the parenthetical citation; should be \"(Chen and Malik, 2017)\".",
    "start": 616,
    "end": 637,
    "label": "Format"
  },
  {
    "span": "Vision Transformers benefit from large-scale pretraining on ImageNet-21k (Dosovitskiy et al., 2021). Knowledge distillation transfers capacity from a teacher CNN (Hinton et al., 2015). Masked image modeling reconstructs patches to learn representations (He et al., 2022).",
    "document": "Related Work\n\nTransformers for Vision. Self-attention architectures have shown competitive or superior results to CNNs when trained at scale, though they often require substantial data or regularization to avoid overfitting.\n\nPretraining Strategies. Both supervised and self-supervised approaches aim to improve data efficiency and transfer, including contrastive learning, masked reconstruction, and hybrid tokenization schemes.\n\nScaling and Supervision. Vision Transformers benefit from large-scale pretraining on ImageNet-21k (Dosovitskiy et al., 2021). Knowledge distillation transfers capacity from a teacher CNN (Hinton et al., 2015). Masked image modeling reconstructs patches to learn representations (He et al., 2022).\n\nRegularization and Augmentation. Complementary techniques such as stochastic depth, strong augmentations, and token mixing further improve generalization and robustness.",
    "reason": "The span presents three disjoint points—supervised pretraining scale, distillation from CNNs, and self-supervised masked modeling—without clarifying their relationships or transitions, making the connections between cited works unclear.",
    "start": 456,
    "end": 727,
    "label": "Coherence"
  },
  {
    "span": "the Common Voice corpus",
    "document": "Introduction\n\nEnd-to-end automatic speech recognition (ASR) has benefited from large supervised and semi-supervised corpora that cover diverse speakers and recording conditions. Benchmarks such as LibriSpeech (Panayotov et al., 2015) and TED-LIUM (Rousseau et al., 2014) provide clean and conversational speech, respectively. To broaden accents and recording conditions, the Common Voice corpus is also frequently used. However, accent imbalance and noise variability remain major hurdles for robust ASR.",
    "reason": "Refers to a specific dataset without citing its source or accompanying paper.",
    "start": 371,
    "end": 394,
    "label": "Unsupported_claim"
  },
  {
    "span": "Most existing methods for Hindi–English code-mixed sentiment rely on lexicon translation.",
    "document": "Related Work\n\nCode-mixed sentiment analysis examines text where speakers fluidly interleave multiple languages, often using non-standard spellings and transliteration. Prior research has explored character-level models, subword tokenization, and phonetic normalization to handle orthographic variation. Domain-specific resources, including lexica and task-specific datasets, have been introduced to improve performance.\n\nMost existing methods for Hindi–English code-mixed sentiment rely on lexicon translation. While lexicon augmentation can be helpful, recent neural encoders and multilingual pretrained models offer alternatives that may better capture context and code-switching phenomena without explicit dictionary lookups.\n\nWe investigate a contrastive pretraining strategy that aligns contextualized representations across Hindi, English, and code-mixed inputs to reduce reliance on brittle lexical resources.",
    "reason": "Claims a predominant approach in prior work but provides no citations to substantiate this characterization.",
    "start": 421,
    "end": 510,
    "label": "Unsupported_claim"
  },
  {
    "span": "[Chen et al., 2017]",
    "document": "Introduction\n\nDomain adaptation seeks to transfer knowledge from labeled source domains to unlabeled targets (Pan and Yang, 2010). Adversarial feature alignment reduces distributional shifts by learning domain-invariant representations (Ganin et al., 2016; Tzeng et al., 2017). Prior work [Chen et al., 2017] studies conditional alignment but relies on strong assumptions about class balance across domains.\n\nWe introduce a label-shift-aware objective that jointly calibrates class priors and aligns conditional distributions, leading to improved transfer in imbalanced settings.\n",
    "reason": "Wrong bracket style for author–year citation; should use parentheses '(Chen et al., 2017)' instead of square brackets.",
    "start": 289,
    "end": 308,
    "label": "Format"
  },
  {
    "span": "We are the first to explore continual learning for code LLMs on issue-to-PR linking.",
    "document": "Introduction\n\nLarge language models trained on code have rapidly improved performance on tasks like code completion, repair, and summarization. Software repositories, however, evolve continuously, creating a non-stationary distribution that challenges static training regimes. We are the first to explore continual learning for code LLMs on issue-to-PR linking. We formalize an evaluation protocol that simulates realistic project evolution and analyze the trade-offs between rehearsal-based methods and regularization approaches under constrained memory budgets.\n",
    "reason": "Makes a novelty claim about being the first in the area without citing any prior art surveys or related attempts.",
    "start": 277,
    "end": 361,
    "label": "Unsupported_claim"
  },
  {
    "span": "Causal graphs formalize intervention effects in sequential decisions (Pearl, 2009). Off-policy evaluation estimates counterfactual returns from logged data (Precup et al., 2000). Model-based RL learns dynamics for planning (Deisenroth and Rasmussen, 2011). Instrumental variables address unobserved confounding (Angrist and Imbens, 1995).",
    "document": "Related Work\n\nUnderstanding causality in reinforcement learning (RL) is essential for safe deployment in settings where actions influence future data collection. The interplay between causal inference and RL spans identification, estimation, and policy optimization, yet integrating these components under realistic partial observability remains challenging.\n\nCausal graphs formalize intervention effects in sequential decisions (Pearl, 2009). Off-policy evaluation estimates counterfactual returns from logged data (Precup et al., 2000). Model-based RL learns dynamics for planning (Deisenroth and Rasmussen, 2011). Instrumental variables address unobserved confounding (Angrist and Imbens, 1995).\n\nWe propose a framework that unifies off-policy evaluation with causal structure learning to mitigate confounding in logged bandit and RL datasets.",
    "reason": "The span places distinct topics side by side without transitions or an explanation of how they relate, creating a coherence gap between sentences and cited works.",
    "start": 360,
    "end": 698,
    "label": "Coherence"
  },
  {
    "span": "Fairness in machine learning spans multiple criteria. Demographic parity enforces independence between predictions and sensitive attributes (Dwork et al., 2012). Equalized odds constrains error rates across groups (Hardt et al., 2016). Calibration aligns predicted probabilities with outcomes (Pleiss et al., 2017). Counterfactual fairness reasons over causal graphs (Kusner et al., 2017). Differential privacy protects individual information during training (Abadi et al., 2016).",
    "document": "Related Work\n\nAs predictive models are deployed in high-stakes domains, fairness has emerged as a key consideration. The literature includes statistical definitions, causal formulations, and interventions at data, algorithm, and evaluation levels. These approaches are not mutually exclusive but often trade off utility and constraints.\n\nFairness in machine learning spans multiple criteria. Demographic parity enforces independence between predictions and sensitive attributes (Dwork et al., 2012). Equalized odds constrains error rates across groups (Hardt et al., 2016). Calibration aligns predicted probabilities with outcomes (Pleiss et al., 2017). Counterfactual fairness reasons over causal graphs (Kusner et al., 2017). Differential privacy protects individual information during training (Abadi et al., 2016).\n\nWe propose a risk-aware auditing framework that quantifies disparities under distribution shift and measurement error.",
    "reason": "The span abruptly mixes fairness definitions with privacy without transitions or explaining their relationships, leaving the reader to infer connections and weakening coherence across sentences.",
    "start": 338,
    "end": 818,
    "label": "Coherence"
  },
  {
    "span": "Public TSAD benchmarks contain about 15% label noise on average.",
    "document": "Introduction\n\nTime-series anomaly detection (TSAD) underpins applications in monitoring, predictive maintenance, and cybersecurity. Supervised TSAD is often impractical due to the rarity and heterogeneity of anomalies, driving interest in unsupervised and weakly supervised methods. Benchmarking is complicated by differences in anomaly definitions, sampling rates, and labeling quality across datasets.\n\nPublic TSAD benchmarks contain about 15% label noise on average. Label noise can significantly bias evaluation, favoring methods that over-segment anomalies or exploit temporal leakage in splits.\n\nWe contribute a noise-aware evaluation protocol and a synthetic corruption suite that stress-tests robustness to mislabeled anomalies, enabling fairer comparisons across methods.",
    "reason": "Presents a quantitative statistic about public benchmarks without citing any empirical study or analysis.",
    "start": 405,
    "end": 469,
    "label": "Unsupported_claim"
  },
  {
    "span": "A previous study introduced a masked autoencoder specifically for radiographs and reported large gains on classification and localization",
    "document": "Related Work\n\nSelf-supervised learning with masked image modeling has achieved strong results in natural image understanding by reconstructing missing patches from context. Extensions to medical imaging are actively explored due to the scarcity of labeled data and the domain shift relative to natural images.\n\nA previous study introduced a masked autoencoder specifically for radiographs and reported large gains on classification and localization. However, most adaptations reuse generic masking strategies that may not align with anatomical structures, potentially limiting performance on tasks requiring fine-grained spatial cues.\n\nOur method introduces anatomy-aware masking guided by coarse organ proposals, encouraging the model to learn contextually relevant representations for downstream detection and segmentation.",
    "reason": "Claims a prior study and its findings without citing or identifying the study (rule a and b).",
    "start": 311,
    "end": 448,
    "label": "Unsupported_claim"
  },
  {
    "span": "[12]",
    "document": "Related Work\n\nTime-series forecasting. Classical statistical models such as ARIMA and Exponential Smoothing remain competitive for short horizons and stationary signals (Hyndman and Athanasopoulos, 2018). Deep architectures, including temporal convolutional networks and transformers, capture long-range dependencies and multi-scale seasonality (Bai et al., 2018; Lim et al., 2021). Recent benchmarks emphasize covariate selection and cross-domain evaluation, as shown in [12], while probabilistic objectives improve calibration under distribution shift (Salinas et al., 2020; Rasul et al., 2021).",
    "reason": "Numeric bracketed citation used in an author–year context. It should be converted to an author–year citation (e.g., \"as shown in Author et al. (YEAR)\" or \"(Author et al., YEAR)\").",
    "start": 472,
    "end": 476,
    "label": "Format"
  },
  {
    "span": "the MoleculeNet benchmark",
    "document": "Related Work\n\nGraph neural networks (GNNs) have become a standard approach for molecular property prediction, capturing local chemical environments and long-range interactions through message passing (Gilmer et al., 2017; Yang et al., 2019). Pretraining strategies based on masked atom modeling and contrastive views have further improved generalization to new scaffolds (Hu et al., 2020; Sun et al., 2021). Most prior work evaluates on the MoleculeNet benchmark, reporting ROC-AUC and RMSE across classification and regression tasks with scaffold splits.\n\nWe revisit architectural choices in light of recent findings on positional encodings and equivariant representations, and we provide a unified evaluation harness with strong regularization baselines to contextualize claimed gains.",
    "reason": "First mention of a widely used benchmark ('MoleculeNet') lacks a citation to its original introduction, violating rule (a).",
    "start": 437,
    "end": 462,
    "label": "Unsupported_claim"
  },
  {
    "span": "There are many recent works exploring user simulators to evaluate dialog policies.",
    "document": "Related Work\n\nConversational recommender systems (CRS) integrate recommendation with multi-turn natural language interaction. Early approaches relied on slot-filling dialogs over predefined attributes, while recent methods learn end-to-end policies conditioned on user feedback and item knowledge. Evaluation remains difficult because human studies are costly and offline metrics may not reflect interactive quality.\n\nThere are many recent works exploring user simulators to evaluate dialog policies.\n\nBeyond simulators, CRS research investigates knowledge grounding, preference elicitation strategies, and personalization. Our approach targets sample-efficient policy optimization by combining offline value estimation with lightweight on-policy updates.",
    "reason": "Uses a vague reference to 'many recent works' without providing citations (violates rule d).",
    "start": 418,
    "end": 500,
    "label": "Unsupported_claim"
  },
  {
    "span": "(BERT Devlin et al., 2019)",
    "document": "Related Work\n\nPre-trained encoders have become the de facto foundation for NLP tasks. Masked language modeling pretraining yields strong transfer to downstream tasks such as QA and NER (Peters et al., 2018; Liu et al., 2019). We fine-tune (BERT Devlin et al., 2019) as a baseline and compare to more recent encoders that incorporate longer context windows (Beltagy et al., 2020) and multi-task objectives (Clark et al., 2019). Despite strong performance, domain mismatch can degrade results, motivating adaptive pretraining strategies.",
    "reason": "Wrong citation style: the model name is combined inside the parenthetical citation. It should be “BERT (Devlin et al., 2019)” or just “(Devlin et al., 2019)” if not naming the model in text.",
    "start": 239,
    "end": 265,
    "label": "Format"
  },
  {
    "span": "Meta-learning approaches such as MAML, ProtoNets, and Relation Networks have been extensively studied for few-shot image classification (Finn et al., 2017; Snell et al., 2017; Sung et al., 2018; Rusu et al., 2019). Recent transformer-based methods further improve performance by exploiting cross-task attention and better feature reuse (Ye et al., 2020; Tian et al., 2020; Zhou et al., 2021).",
    "document": "Introduction\n\nFew-shot learning seeks to recognize novel categories from only a handful of labeled examples, reducing annotation costs in domains where labels are scarce or expensive. A key challenge is to learn transferable inductive biases that generalize across tasks and domains.\n\nMeta-learning approaches such as MAML, ProtoNets, and Relation Networks have been extensively studied for few-shot image classification (Finn et al., 2017; Snell et al., 2017; Sung et al., 2018; Rusu et al., 2019). Recent transformer-based methods further improve performance by exploiting cross-task attention and better feature reuse (Ye et al., 2020; Tian et al., 2020; Zhou et al., 2021).\n\nDespite overall progress, few-shot performance remains brittle under domain shift and label noise. We address this by proposing a task-adaptive calibration framework that jointly estimates class-conditional uncertainty and reweights support examples via a lightweight hypernetwork, improving robustness without additional pretraining.",
    "reason": "The span summarizes families of methods and cites examples but does not connect them to the paper's goals, identify shortcomings, or articulate why another approach is needed.",
    "start": 285,
    "end": 677,
    "label": "Lacks_synthesis"
  },
  {
    "span": "Post-training quantization reduces precision to lower compute and memory (Banner et al., 2019). Pruning removes redundant weights or channels (Han et al., 2015). Neural architecture search explores efficient designs under constraints (Tan and Le, 2019). Knowledge distillation transfers accuracy from large to small models (Hinton et al., 2015). Specialized accelerators optimize execution for specific operators (Chen et al., 2016).",
    "document": "Related Work\n\nEnergy-Efficient Neural Networks on the Edge\n\nDeploying deep models on resource-constrained devices requires careful co-design of architectures, training, and hardware. Methods reduce compute, memory, and energy while maintaining accuracy under real-time and thermal constraints.\n\nPost-training quantization reduces precision to lower compute and memory (Banner et al., 2019). Pruning removes redundant weights or channels (Han et al., 2015). Neural architecture search explores efficient designs under constraints (Tan and Le, 2019). Knowledge distillation transfers accuracy from large to small models (Hinton et al., 2015). Specialized accelerators optimize execution for specific operators (Chen et al., 2016).\n\nSystem Co-Design\n\nRecent work coordinates compression with compiler optimizations (Cai et al., 2020) and hardware-aware training that penalizes latency or energy (Cai et al., 2019). Runtime schedulers adapt precision and activation sparsity to input difficulty (Yu et al., 2018).\n\nOur Approach\n\nWe present an energy-aware training framework with differentiable latency proxies and adaptive quantization, jointly optimizing accuracy and measured device energy.",
    "reason": "The span enumerates techniques across model compression and hardware with no transitions or explicit relationships; the connections are abrupt and left implicit, harming coherence.",
    "start": 295,
    "end": 728,
    "label": "Coherence"
  },
  {
    "span": "Klein and Manning (2003",
    "document": "Introduction\n\nSyntactic inductive biases remain crucial in low-resource neural machine translation (NMT). Early statistical parsers (Klein and Manning (2003) provided strong priors for reordering and phrase extraction, which inspired syntax-aware encoders in NMT (Eriguchi et al., 2016; Chen et al., 2017). With Transformers (Vaswani et al., 2017), structural information is commonly injected via dependency distances (Shaw et al., 2018) or latent trees (Kim et al., 2019). Pretraining further amplifies gains when tasks share structural signals (Song et al., 2019; Wang et al., 2020). However, most prior work assumes large parallel corpora, leaving open questions about how to transfer syntactic knowledge across domains. We propose a constrained alignment objective that distills parse-informed attention patterns under limited bilingual supervision.",
    "reason": "Missing closing parenthesis in the narrative citation; it should be 'Klein and Manning (2003)'.",
    "start": 133,
    "end": 156,
    "label": "Format"
  },
  {
    "span": "(Nguyen et. al., 2018)",
    "document": "Introduction\n\nTask-oriented dialogue systems aim to assist users in completing goals such as booking or troubleshooting. Neural approaches model belief tracking and policy learning jointly to reduce error propagation (Wen et al., 2017; Lei et al., 2018). Despite progress, data sparsity and domain adaptation remain open challenges (Budzianowski et al., 2018). Prior studies (Nguyen et. al., 2018) propose few-shot methods for slot induction, while others incorporate external knowledge bases to improve grounding (Zhang et al., 2020; He et al., 2021). We propose a hybrid retriever-generator that adapts to new domains with minimal supervision.",
    "reason": "Incorrect abbreviation punctuation in the citation: 'et. al.' should be 'et al.' without the extra period after 'et'.",
    "start": 375,
    "end": 397,
    "label": "Format"
  },
  {
    "span": "((Lee et al., 2017))",
    "document": "Related Work\n\nProgram repair research explores both search-based and learning-based strategies to generate patches that satisfy test suites. Data-driven patch generation ((Lee et al., 2017)) pioneered large-scale mining of historical bug-fix patterns to synthesize candidates. Neural approaches learn edit representations directly from code-change corpora (Chen and Larsen, 2019; Tarlow et al., 2020). Hybrid systems combine semantic constraints with learned priors to reduce overfitting to tests (Ng and Roy, 2021).",
    "reason": "Extraneous/doubled parentheses around the citation; should be a single parenthetical \"(Lee et al., 2017)\".",
    "start": 170,
    "end": 190,
    "label": "Format"
  },
  {
    "span": "[Tran et al., 2020)",
    "document": "Introduction\n\nModel-based reinforcement learning (MBRL) seeks data efficiency by leveraging learned dynamics for planning (Deisenroth and Rasmussen, 2011; Chua et al., 2018). Uncertainty-aware models mitigate exploitation of model errors during policy improvement (Gal and Ghahramani, 2016; Kurutach et al., 2018). As shown in [Tran et al., 2020) hybrid planners can combine value expansions with short-horizon rollouts to stabilize learning. We build on this line by incorporating a consistency constraint between imagined and real trajectories, yielding stronger generalization under stochastic transitions.\n",
    "reason": "Mismatched brackets in a citation; it starts with a square bracket and ends with a parenthesis. It should use matching parentheses as “(Tran et al., 2020)” or consistently use the chosen style.",
    "start": 327,
    "end": 346,
    "label": "Format"
  },
  {
    "span": "(2020, Li et al.)",
    "document": "Related Work\n\nLarge-scale paraphrase corpora have been used to train semantic similarity models and paraphrase generation systems (Dolan et al., 2004; Wieting and Gimpel, 2018). However, most benchmarks emphasize sentence-level variation rather than document-level discourse. Prior datasets (2020, Li et al.) are limited in size and domain diversity, making it difficult to evaluate cross-domain generalization. We address this gap with a multi-domain, multi-style paraphrase collection.",
    "reason": "Elements inside the parenthetical citation are in the wrong order; should be '(Li et al., 2020)'.",
    "start": 291,
    "end": 308,
    "label": "Format"
  }
]