[
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        claim about prior work or statistics w/o citation or evidence. \n    a) The author should cite at every first mention of a study, paper, shared task, competition or dataset.\n    b) Specific information to a niche topic, despite sounding like it should be known in that topic of study, should be cited.\n    c) If a claim is made and is obvious to be a natural deduction from previous statements through common sense (i.e not requiring expert knowledge), then this claim does not fall under \u2018Unsupported claim\u2019. For example:\n        i) \u201cHowever, creating a large and suitable set of questions for supporting narrative comprehension is both time-consuming and cognitively demanding.\u201d -> it is obvious that creating a dataset is time consuming and mentally demanding.\n    d) Any mention of \u201crecent works\u201d should be backed up with citations to the works.\n    e) Unsupported claim issues appear as segments, phrases, sub-sentences or full sentences.\n    Examples of unsupported claims include:\n        i) Missing citations for mentions of 'recent works': \u201cand there are many recent works that explore this topic\u201d,\n        ii) Mention of a previous work and claim without citation: \u201c..., while in a previous study, the authors claim \u2026\u201d,\n        iii) Mentioning of a specific setup of a task without citation to the work: \".. BERT was used in an AES task trained on essays ..\" \n\n        Example text: \n        Introduction\n\nPolicy gradient methods have become a mainstay in reinforcement learning due to their simplicity and ability to handle continuous action spaces (Sutton et al., 2000; Schulman et al., 2017). Improved stability via clipped objectives and generalized advantage estimation has enabled better sample efficiency and robustness across tasks. On Atari 2600, PPO reaches human-level performance on many games. Nevertheless, exploration remains a bottleneck, particularly in sparse-reward environments where naive entropy bonuses are insufficient (Ecoffet et al., 2019). We propose an intrinsic motivation scheme based on state abstraction that scales to long horizons without destabilizing policy updates.\n",
        "completion": "On Atari 2600, PPO reaches human-level performance on many games."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        claim about prior work or statistics w/o citation or evidence. \n    a) The author should cite at every first mention of a study, paper, shared task, competition or dataset.\n    b) Specific information to a niche topic, despite sounding like it should be known in that topic of study, should be cited.\n    c) If a claim is made and is obvious to be a natural deduction from previous statements through common sense (i.e not requiring expert knowledge), then this claim does not fall under \u2018Unsupported claim\u2019. For example:\n        i) \u201cHowever, creating a large and suitable set of questions for supporting narrative comprehension is both time-consuming and cognitively demanding.\u201d -> it is obvious that creating a dataset is time consuming and mentally demanding.\n    d) Any mention of \u201crecent works\u201d should be backed up with citations to the works.\n    e) Unsupported claim issues appear as segments, phrases, sub-sentences or full sentences.\n    Examples of unsupported claims include:\n        i) Missing citations for mentions of 'recent works': \u201cand there are many recent works that explore this topic\u201d,\n        ii) Mention of a previous work and claim without citation: \u201c..., while in a previous study, the authors claim \u2026\u201d,\n        iii) Mentioning of a specific setup of a task without citation to the work: \".. BERT was used in an AES task trained on essays ..\" \n\n        Example text: \n        Introduction\n\nPolicy gradient methods have become a mainstay in reinforcement learning due to their simplicity and ability to handle continuous action spaces (Sutton et al., 2000; Schulman et al., 2017). Improved stability via clipped objectives and generalized advantage estimation has enabled better sample efficiency and robustness across tasks. On Atari 2600, PPO reaches human-level performance on many games. Nevertheless, exploration remains a bottleneck, particularly in sparse-reward environments where naive entropy bonuses are insufficient (Ecoffet et al., 2019). We propose an intrinsic motivation scheme based on state abstraction that scales to long horizons without destabilizing policy updates.\nIntroduction\n\nSpeech emotion recognition (SER) seeks to infer affective states from acoustic and linguistic cues. Classical approaches rely on engineered prosodic features combined with SVMs (Schuller et al., 2011), while recent work leverages self-supervised pretraining and multimodal fusion (Baevski et al., 2020; Tsai et al., 2019). The IEMOCAP dataset is considered the de facto standard benchmark for speech emotion recognition.\n\nHowever, heavy reliance on acted corpora raises questions about ecological validity. Cross-corpus generalization remains challenging due to speaker, channel, and annotation mismatches. We study robust SER by combining wav2vec-style representations with domain adversarial training, and we evaluate on multiple corpora, including acted and in-the-wild datasets, to better approximate real-world deployment scenarios.\n",
        "completion": "The IEMOCAP dataset is considered the de facto standard benchmark for speech emotion recognition."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        claim about prior work or statistics w/o citation or evidence. \n    a) The author should cite at every first mention of a study, paper, shared task, competition or dataset.\n    b) Specific information to a niche topic, despite sounding like it should be known in that topic of study, should be cited.\n    c) If a claim is made and is obvious to be a natural deduction from previous statements through common sense (i.e not requiring expert knowledge), then this claim does not fall under \u2018Unsupported claim\u2019. For example:\n        i) \u201cHowever, creating a large and suitable set of questions for supporting narrative comprehension is both time-consuming and cognitively demanding.\u201d -> it is obvious that creating a dataset is time consuming and mentally demanding.\n    d) Any mention of \u201crecent works\u201d should be backed up with citations to the works.\n    e) Unsupported claim issues appear as segments, phrases, sub-sentences or full sentences.\n    Examples of unsupported claims include:\n        i) Missing citations for mentions of 'recent works': \u201cand there are many recent works that explore this topic\u201d,\n        ii) Mention of a previous work and claim without citation: \u201c..., while in a previous study, the authors claim \u2026\u201d,\n        iii) Mentioning of a specific setup of a task without citation to the work: \".. BERT was used in an AES task trained on essays ..\" \n\n        Example text: \n        Introduction\n\nPolicy gradient methods have become a mainstay in reinforcement learning due to their simplicity and ability to handle continuous action spaces (Sutton et al., 2000; Schulman et al., 2017). Improved stability via clipped objectives and generalized advantage estimation has enabled better sample efficiency and robustness across tasks. On Atari 2600, PPO reaches human-level performance on many games. Nevertheless, exploration remains a bottleneck, particularly in sparse-reward environments where naive entropy bonuses are insufficient (Ecoffet et al., 2019). We propose an intrinsic motivation scheme based on state abstraction that scales to long horizons without destabilizing policy updates.\nIntroduction\n\nSpeech emotion recognition (SER) seeks to infer affective states from acoustic and linguistic cues. Classical approaches rely on engineered prosodic features combined with SVMs (Schuller et al., 2011), while recent work leverages self-supervised pretraining and multimodal fusion (Baevski et al., 2020; Tsai et al., 2019). The IEMOCAP dataset is considered the de facto standard benchmark for speech emotion recognition.\n\nHowever, heavy reliance on acted corpora raises questions about ecological validity. Cross-corpus generalization remains challenging due to speaker, channel, and annotation mismatches. We study robust SER by combining wav2vec-style representations with domain adversarial training, and we evaluate on multiple corpora, including acted and in-the-wild datasets, to better approximate real-world deployment scenarios.\nIntroduction\n\nCross-lingual transfer aims to leverage supervision in high-resource languages to improve performance in low-resource settings (Ruder et al., 2019; Conneau and Lample, 2019). Pretrained multilingual encoders enable zero-shot and few-shot transfer on a variety of tasks, but evaluation remains challenging due to dataset coverage and annotation quality. XTREME covers more than 40 languages and remains the most widely used multilingual benchmark. However, its task mix may not fully reflect realistic domain shifts encountered in production systems. We introduce a complementary benchmark focused on noisy user-generated text with balanced representation across low- and mid-resource languages.\n",
        "completion": "XTREME covers more than 40 languages and remains the most widely used multilingual benchmark."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        claim about prior work or statistics w/o citation or evidence. \n    a) The author should cite at every first mention of a study, paper, shared task, competition or dataset.\n    b) Specific information to a niche topic, despite sounding like it should be known in that topic of study, should be cited.\n    c) If a claim is made and is obvious to be a natural deduction from previous statements through common sense (i.e not requiring expert knowledge), then this claim does not fall under \u2018Unsupported claim\u2019. For example:\n        i) \u201cHowever, creating a large and suitable set of questions for supporting narrative comprehension is both time-consuming and cognitively demanding.\u201d -> it is obvious that creating a dataset is time consuming and mentally demanding.\n    d) Any mention of \u201crecent works\u201d should be backed up with citations to the works.\n    e) Unsupported claim issues appear as segments, phrases, sub-sentences or full sentences.\n    Examples of unsupported claims include:\n        i) Missing citations for mentions of 'recent works': \u201cand there are many recent works that explore this topic\u201d,\n        ii) Mention of a previous work and claim without citation: \u201c..., while in a previous study, the authors claim \u2026\u201d,\n        iii) Mentioning of a specific setup of a task without citation to the work: \".. BERT was used in an AES task trained on essays ..\" \n\n        Example text: \n        Introduction\n\nPolicy gradient methods have become a mainstay in reinforcement learning due to their simplicity and ability to handle continuous action spaces (Sutton et al., 2000; Schulman et al., 2017). Improved stability via clipped objectives and generalized advantage estimation has enabled better sample efficiency and robustness across tasks. On Atari 2600, PPO reaches human-level performance on many games. Nevertheless, exploration remains a bottleneck, particularly in sparse-reward environments where naive entropy bonuses are insufficient (Ecoffet et al., 2019). We propose an intrinsic motivation scheme based on state abstraction that scales to long horizons without destabilizing policy updates.\nIntroduction\n\nSpeech emotion recognition (SER) seeks to infer affective states from acoustic and linguistic cues. Classical approaches rely on engineered prosodic features combined with SVMs (Schuller et al., 2011), while recent work leverages self-supervised pretraining and multimodal fusion (Baevski et al., 2020; Tsai et al., 2019). The IEMOCAP dataset is considered the de facto standard benchmark for speech emotion recognition.\n\nHowever, heavy reliance on acted corpora raises questions about ecological validity. Cross-corpus generalization remains challenging due to speaker, channel, and annotation mismatches. We study robust SER by combining wav2vec-style representations with domain adversarial training, and we evaluate on multiple corpora, including acted and in-the-wild datasets, to better approximate real-world deployment scenarios.\nIntroduction\n\nCross-lingual transfer aims to leverage supervision in high-resource languages to improve performance in low-resource settings (Ruder et al., 2019; Conneau and Lample, 2019). Pretrained multilingual encoders enable zero-shot and few-shot transfer on a variety of tasks, but evaluation remains challenging due to dataset coverage and annotation quality. XTREME covers more than 40 languages and remains the most widely used multilingual benchmark. However, its task mix may not fully reflect realistic domain shifts encountered in production systems. We introduce a complementary benchmark focused on noisy user-generated text with balanced representation across low- and mid-resource languages.\nSpeech Recognition and Data Augmentation\n\nEnd-to-end automatic speech recognition (ASR) systems benefit significantly from data augmentation techniques that enhance robustness to acoustic and speaker variability. Time masking, frequency masking, and time warping applied to log-Mel spectrograms have shown substantial gains across corpora and model sizes. SpecAugment has become the de facto standard data augmentation in end-to-end ASR. Nevertheless, its interaction with noise conditions, speaker normalization, and curriculum schedules is not yet well understood.\n\nWe investigate augmentation schedules that adapt masking intensity to utterance length and model confidence, and we analyze their effects on stability during large-batch training. We further explore complementarity between augmentation and semi-supervised training with pseudo-labels in low-resource settings.\n\nOur results indicate that adaptive masking coupled with confidence-aware sampling reduces word error rate and mitigates overfitting on short utterances. We release configuration files and scripts to facilitate replication across common ASR toolchains.\n",
        "completion": "SpecAugment has become the de facto standard data augmentation in end-to-end ASR."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        claim about prior work or statistics w/o citation or evidence. \n    a) The author should cite at every first mention of a study, paper, shared task, competition or dataset.\n    b) Specific information to a niche topic, despite sounding like it should be known in that topic of study, should be cited.\n    c) If a claim is made and is obvious to be a natural deduction from previous statements through common sense (i.e not requiring expert knowledge), then this claim does not fall under \u2018Unsupported claim\u2019. For example:\n        i) \u201cHowever, creating a large and suitable set of questions for supporting narrative comprehension is both time-consuming and cognitively demanding.\u201d -> it is obvious that creating a dataset is time consuming and mentally demanding.\n    d) Any mention of \u201crecent works\u201d should be backed up with citations to the works.\n    e) Unsupported claim issues appear as segments, phrases, sub-sentences or full sentences.\n    Examples of unsupported claims include:\n        i) Missing citations for mentions of 'recent works': \u201cand there are many recent works that explore this topic\u201d,\n        ii) Mention of a previous work and claim without citation: \u201c..., while in a previous study, the authors claim \u2026\u201d,\n        iii) Mentioning of a specific setup of a task without citation to the work: \".. BERT was used in an AES task trained on essays ..\" \n\n        Example text: \n        Introduction\n\nPolicy gradient methods have become a mainstay in reinforcement learning due to their simplicity and ability to handle continuous action spaces (Sutton et al., 2000; Schulman et al., 2017). Improved stability via clipped objectives and generalized advantage estimation has enabled better sample efficiency and robustness across tasks. On Atari 2600, PPO reaches human-level performance on many games. Nevertheless, exploration remains a bottleneck, particularly in sparse-reward environments where naive entropy bonuses are insufficient (Ecoffet et al., 2019). We propose an intrinsic motivation scheme based on state abstraction that scales to long horizons without destabilizing policy updates.\nIntroduction\n\nSpeech emotion recognition (SER) seeks to infer affective states from acoustic and linguistic cues. Classical approaches rely on engineered prosodic features combined with SVMs (Schuller et al., 2011), while recent work leverages self-supervised pretraining and multimodal fusion (Baevski et al., 2020; Tsai et al., 2019). The IEMOCAP dataset is considered the de facto standard benchmark for speech emotion recognition.\n\nHowever, heavy reliance on acted corpora raises questions about ecological validity. Cross-corpus generalization remains challenging due to speaker, channel, and annotation mismatches. We study robust SER by combining wav2vec-style representations with domain adversarial training, and we evaluate on multiple corpora, including acted and in-the-wild datasets, to better approximate real-world deployment scenarios.\nIntroduction\n\nCross-lingual transfer aims to leverage supervision in high-resource languages to improve performance in low-resource settings (Ruder et al., 2019; Conneau and Lample, 2019). Pretrained multilingual encoders enable zero-shot and few-shot transfer on a variety of tasks, but evaluation remains challenging due to dataset coverage and annotation quality. XTREME covers more than 40 languages and remains the most widely used multilingual benchmark. However, its task mix may not fully reflect realistic domain shifts encountered in production systems. We introduce a complementary benchmark focused on noisy user-generated text with balanced representation across low- and mid-resource languages.\nSpeech Recognition and Data Augmentation\n\nEnd-to-end automatic speech recognition (ASR) systems benefit significantly from data augmentation techniques that enhance robustness to acoustic and speaker variability. Time masking, frequency masking, and time warping applied to log-Mel spectrograms have shown substantial gains across corpora and model sizes. SpecAugment has become the de facto standard data augmentation in end-to-end ASR. Nevertheless, its interaction with noise conditions, speaker normalization, and curriculum schedules is not yet well understood.\n\nWe investigate augmentation schedules that adapt masking intensity to utterance length and model confidence, and we analyze their effects on stability during large-batch training. We further explore complementarity between augmentation and semi-supervised training with pseudo-labels in low-resource settings.\n\nOur results indicate that adaptive masking coupled with confidence-aware sampling reduces word error rate and mitigates overfitting on short utterances. We release configuration files and scripts to facilitate replication across common ASR toolchains.\nRelated Work\n\nOnline decision-making for ad allocation balances immediate revenue with long-term learning under uncertainty. Classic approaches modeled the problem as multi-armed bandits, later extended to incorporate context and delayed feedback. Practical systems must also address non-stationarity, covariate shift, and budget constraints across campaigns.\n\nWithin industry practice, contextual bandit methods have dominated online ad allocation in the last five years, with growing interest in offline policy evaluation for safe deployment. Yet, robust learning under evolving auctions and strategic advertiser behavior remains underexplored.\n\nWe present a robust, budget-aware contextual policy that adapts to market shifts via risk-sensitive objectives and counterfactual evaluation.\n",
        "completion": "contextual bandit methods have dominated online ad allocation in the last five years"
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        claim about prior work or statistics w/o citation or evidence. \n    a) The author should cite at every first mention of a study, paper, shared task, competition or dataset.\n    b) Specific information to a niche topic, despite sounding like it should be known in that topic of study, should be cited.\n    c) If a claim is made and is obvious to be a natural deduction from previous statements through common sense (i.e not requiring expert knowledge), then this claim does not fall under \u2018Unsupported claim\u2019. For example:\n        i) \u201cHowever, creating a large and suitable set of questions for supporting narrative comprehension is both time-consuming and cognitively demanding.\u201d -> it is obvious that creating a dataset is time consuming and mentally demanding.\n    d) Any mention of \u201crecent works\u201d should be backed up with citations to the works.\n    e) Unsupported claim issues appear as segments, phrases, sub-sentences or full sentences.\n    Examples of unsupported claims include:\n        i) Missing citations for mentions of 'recent works': \u201cand there are many recent works that explore this topic\u201d,\n        ii) Mention of a previous work and claim without citation: \u201c..., while in a previous study, the authors claim \u2026\u201d,\n        iii) Mentioning of a specific setup of a task without citation to the work: \".. BERT was used in an AES task trained on essays ..\" \n\n        Example text: \n        Introduction\n\nPolicy gradient methods have become a mainstay in reinforcement learning due to their simplicity and ability to handle continuous action spaces (Sutton et al., 2000; Schulman et al., 2017). Improved stability via clipped objectives and generalized advantage estimation has enabled better sample efficiency and robustness across tasks. On Atari 2600, PPO reaches human-level performance on many games. Nevertheless, exploration remains a bottleneck, particularly in sparse-reward environments where naive entropy bonuses are insufficient (Ecoffet et al., 2019). We propose an intrinsic motivation scheme based on state abstraction that scales to long horizons without destabilizing policy updates.\nIntroduction\n\nSpeech emotion recognition (SER) seeks to infer affective states from acoustic and linguistic cues. Classical approaches rely on engineered prosodic features combined with SVMs (Schuller et al., 2011), while recent work leverages self-supervised pretraining and multimodal fusion (Baevski et al., 2020; Tsai et al., 2019). The IEMOCAP dataset is considered the de facto standard benchmark for speech emotion recognition.\n\nHowever, heavy reliance on acted corpora raises questions about ecological validity. Cross-corpus generalization remains challenging due to speaker, channel, and annotation mismatches. We study robust SER by combining wav2vec-style representations with domain adversarial training, and we evaluate on multiple corpora, including acted and in-the-wild datasets, to better approximate real-world deployment scenarios.\nIntroduction\n\nCross-lingual transfer aims to leverage supervision in high-resource languages to improve performance in low-resource settings (Ruder et al., 2019; Conneau and Lample, 2019). Pretrained multilingual encoders enable zero-shot and few-shot transfer on a variety of tasks, but evaluation remains challenging due to dataset coverage and annotation quality. XTREME covers more than 40 languages and remains the most widely used multilingual benchmark. However, its task mix may not fully reflect realistic domain shifts encountered in production systems. We introduce a complementary benchmark focused on noisy user-generated text with balanced representation across low- and mid-resource languages.\nSpeech Recognition and Data Augmentation\n\nEnd-to-end automatic speech recognition (ASR) systems benefit significantly from data augmentation techniques that enhance robustness to acoustic and speaker variability. Time masking, frequency masking, and time warping applied to log-Mel spectrograms have shown substantial gains across corpora and model sizes. SpecAugment has become the de facto standard data augmentation in end-to-end ASR. Nevertheless, its interaction with noise conditions, speaker normalization, and curriculum schedules is not yet well understood.\n\nWe investigate augmentation schedules that adapt masking intensity to utterance length and model confidence, and we analyze their effects on stability during large-batch training. We further explore complementarity between augmentation and semi-supervised training with pseudo-labels in low-resource settings.\n\nOur results indicate that adaptive masking coupled with confidence-aware sampling reduces word error rate and mitigates overfitting on short utterances. We release configuration files and scripts to facilitate replication across common ASR toolchains.\nRelated Work\n\nOnline decision-making for ad allocation balances immediate revenue with long-term learning under uncertainty. Classic approaches modeled the problem as multi-armed bandits, later extended to incorporate context and delayed feedback. Practical systems must also address non-stationarity, covariate shift, and budget constraints across campaigns.\n\nWithin industry practice, contextual bandit methods have dominated online ad allocation in the last five years, with growing interest in offline policy evaluation for safe deployment. Yet, robust learning under evolving auctions and strategic advertiser behavior remains underexplored.\n\nWe present a robust, budget-aware contextual policy that adapts to market shifts via risk-sensitive objectives and counterfactual evaluation.\nRelated Work\n\nGraph representation learning has matured from shallow embeddings to deep architectures capable of capturing long-range dependencies and hierarchical structure. Pooling mechanisms coarsen graphs to derive multi-scale features, trading off expressivity and computational cost. Nearly all recent graph pooling methods are differentiable. Nevertheless, end-to-end differentiability can obscure the inductive biases introduced by the pooling criterion, complicating comparisons across tasks. Our work focuses on explicit, structure-preserving pooling that admits closed-form analysis of stability under edge perturbations.\n\nWe also consider connections to spectral clustering and minimum cut formulations to position our method within classical graph reduction techniques.\n",
        "completion": "Nearly all recent graph pooling methods are differentiable."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        claim about prior work or statistics w/o citation or evidence. \n    a) The author should cite at every first mention of a study, paper, shared task, competition or dataset.\n    b) Specific information to a niche topic, despite sounding like it should be known in that topic of study, should be cited.\n    c) If a claim is made and is obvious to be a natural deduction from previous statements through common sense (i.e not requiring expert knowledge), then this claim does not fall under \u2018Unsupported claim\u2019. For example:\n        i) \u201cHowever, creating a large and suitable set of questions for supporting narrative comprehension is both time-consuming and cognitively demanding.\u201d -> it is obvious that creating a dataset is time consuming and mentally demanding.\n    d) Any mention of \u201crecent works\u201d should be backed up with citations to the works.\n    e) Unsupported claim issues appear as segments, phrases, sub-sentences or full sentences.\n    Examples of unsupported claims include:\n        i) Missing citations for mentions of 'recent works': \u201cand there are many recent works that explore this topic\u201d,\n        ii) Mention of a previous work and claim without citation: \u201c..., while in a previous study, the authors claim \u2026\u201d,\n        iii) Mentioning of a specific setup of a task without citation to the work: \".. BERT was used in an AES task trained on essays ..\" \n\n        Example text: \n        Introduction\n\nPolicy gradient methods have become a mainstay in reinforcement learning due to their simplicity and ability to handle continuous action spaces (Sutton et al., 2000; Schulman et al., 2017). Improved stability via clipped objectives and generalized advantage estimation has enabled better sample efficiency and robustness across tasks. On Atari 2600, PPO reaches human-level performance on many games. Nevertheless, exploration remains a bottleneck, particularly in sparse-reward environments where naive entropy bonuses are insufficient (Ecoffet et al., 2019). We propose an intrinsic motivation scheme based on state abstraction that scales to long horizons without destabilizing policy updates.\nIntroduction\n\nSpeech emotion recognition (SER) seeks to infer affective states from acoustic and linguistic cues. Classical approaches rely on engineered prosodic features combined with SVMs (Schuller et al., 2011), while recent work leverages self-supervised pretraining and multimodal fusion (Baevski et al., 2020; Tsai et al., 2019). The IEMOCAP dataset is considered the de facto standard benchmark for speech emotion recognition.\n\nHowever, heavy reliance on acted corpora raises questions about ecological validity. Cross-corpus generalization remains challenging due to speaker, channel, and annotation mismatches. We study robust SER by combining wav2vec-style representations with domain adversarial training, and we evaluate on multiple corpora, including acted and in-the-wild datasets, to better approximate real-world deployment scenarios.\nIntroduction\n\nCross-lingual transfer aims to leverage supervision in high-resource languages to improve performance in low-resource settings (Ruder et al., 2019; Conneau and Lample, 2019). Pretrained multilingual encoders enable zero-shot and few-shot transfer on a variety of tasks, but evaluation remains challenging due to dataset coverage and annotation quality. XTREME covers more than 40 languages and remains the most widely used multilingual benchmark. However, its task mix may not fully reflect realistic domain shifts encountered in production systems. We introduce a complementary benchmark focused on noisy user-generated text with balanced representation across low- and mid-resource languages.\nSpeech Recognition and Data Augmentation\n\nEnd-to-end automatic speech recognition (ASR) systems benefit significantly from data augmentation techniques that enhance robustness to acoustic and speaker variability. Time masking, frequency masking, and time warping applied to log-Mel spectrograms have shown substantial gains across corpora and model sizes. SpecAugment has become the de facto standard data augmentation in end-to-end ASR. Nevertheless, its interaction with noise conditions, speaker normalization, and curriculum schedules is not yet well understood.\n\nWe investigate augmentation schedules that adapt masking intensity to utterance length and model confidence, and we analyze their effects on stability during large-batch training. We further explore complementarity between augmentation and semi-supervised training with pseudo-labels in low-resource settings.\n\nOur results indicate that adaptive masking coupled with confidence-aware sampling reduces word error rate and mitigates overfitting on short utterances. We release configuration files and scripts to facilitate replication across common ASR toolchains.\nRelated Work\n\nOnline decision-making for ad allocation balances immediate revenue with long-term learning under uncertainty. Classic approaches modeled the problem as multi-armed bandits, later extended to incorporate context and delayed feedback. Practical systems must also address non-stationarity, covariate shift, and budget constraints across campaigns.\n\nWithin industry practice, contextual bandit methods have dominated online ad allocation in the last five years, with growing interest in offline policy evaluation for safe deployment. Yet, robust learning under evolving auctions and strategic advertiser behavior remains underexplored.\n\nWe present a robust, budget-aware contextual policy that adapts to market shifts via risk-sensitive objectives and counterfactual evaluation.\nRelated Work\n\nGraph representation learning has matured from shallow embeddings to deep architectures capable of capturing long-range dependencies and hierarchical structure. Pooling mechanisms coarsen graphs to derive multi-scale features, trading off expressivity and computational cost. Nearly all recent graph pooling methods are differentiable. Nevertheless, end-to-end differentiability can obscure the inductive biases introduced by the pooling criterion, complicating comparisons across tasks. Our work focuses on explicit, structure-preserving pooling that admits closed-form analysis of stability under edge perturbations.\n\nWe also consider connections to spectral clustering and minimum cut formulations to position our method within classical graph reduction techniques.\nIntroduction\n\nBiomedical named entity recognition (BioNER) underpins downstream tasks such as relation extraction and knowledge base curation (Settles, 2004; Li et al., 2016). Contextualized encoders adapted to biomedical corpora have advanced state of the art across multiple datasets (Beltagy et al., 2019; Lee et al., 2020). In a previous study, the authors claim that contextual embeddings outperform CRFs by 15 F1 on BC5CDR. Despite these gains, robustness to lexical variation and emerging terminology remains limited (Wang et al., 2021; Sung et al., 2021). We propose lexicon-augmented adapters to bridge out-of-vocabulary gaps.\n",
        "completion": "In a previous study, the authors claim that contextual embeddings outperform CRFs by 15 F1 on BC5CDR."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        claim about prior work or statistics w/o citation or evidence. \n    a) The author should cite at every first mention of a study, paper, shared task, competition or dataset.\n    b) Specific information to a niche topic, despite sounding like it should be known in that topic of study, should be cited.\n    c) If a claim is made and is obvious to be a natural deduction from previous statements through common sense (i.e not requiring expert knowledge), then this claim does not fall under \u2018Unsupported claim\u2019. For example:\n        i) \u201cHowever, creating a large and suitable set of questions for supporting narrative comprehension is both time-consuming and cognitively demanding.\u201d -> it is obvious that creating a dataset is time consuming and mentally demanding.\n    d) Any mention of \u201crecent works\u201d should be backed up with citations to the works.\n    e) Unsupported claim issues appear as segments, phrases, sub-sentences or full sentences.\n    Examples of unsupported claims include:\n        i) Missing citations for mentions of 'recent works': \u201cand there are many recent works that explore this topic\u201d,\n        ii) Mention of a previous work and claim without citation: \u201c..., while in a previous study, the authors claim \u2026\u201d,\n        iii) Mentioning of a specific setup of a task without citation to the work: \".. BERT was used in an AES task trained on essays ..\" \n\n        Example text: \n        Introduction\n\nPolicy gradient methods have become a mainstay in reinforcement learning due to their simplicity and ability to handle continuous action spaces (Sutton et al., 2000; Schulman et al., 2017). Improved stability via clipped objectives and generalized advantage estimation has enabled better sample efficiency and robustness across tasks. On Atari 2600, PPO reaches human-level performance on many games. Nevertheless, exploration remains a bottleneck, particularly in sparse-reward environments where naive entropy bonuses are insufficient (Ecoffet et al., 2019). We propose an intrinsic motivation scheme based on state abstraction that scales to long horizons without destabilizing policy updates.\nIntroduction\n\nSpeech emotion recognition (SER) seeks to infer affective states from acoustic and linguistic cues. Classical approaches rely on engineered prosodic features combined with SVMs (Schuller et al., 2011), while recent work leverages self-supervised pretraining and multimodal fusion (Baevski et al., 2020; Tsai et al., 2019). The IEMOCAP dataset is considered the de facto standard benchmark for speech emotion recognition.\n\nHowever, heavy reliance on acted corpora raises questions about ecological validity. Cross-corpus generalization remains challenging due to speaker, channel, and annotation mismatches. We study robust SER by combining wav2vec-style representations with domain adversarial training, and we evaluate on multiple corpora, including acted and in-the-wild datasets, to better approximate real-world deployment scenarios.\nIntroduction\n\nCross-lingual transfer aims to leverage supervision in high-resource languages to improve performance in low-resource settings (Ruder et al., 2019; Conneau and Lample, 2019). Pretrained multilingual encoders enable zero-shot and few-shot transfer on a variety of tasks, but evaluation remains challenging due to dataset coverage and annotation quality. XTREME covers more than 40 languages and remains the most widely used multilingual benchmark. However, its task mix may not fully reflect realistic domain shifts encountered in production systems. We introduce a complementary benchmark focused on noisy user-generated text with balanced representation across low- and mid-resource languages.\nSpeech Recognition and Data Augmentation\n\nEnd-to-end automatic speech recognition (ASR) systems benefit significantly from data augmentation techniques that enhance robustness to acoustic and speaker variability. Time masking, frequency masking, and time warping applied to log-Mel spectrograms have shown substantial gains across corpora and model sizes. SpecAugment has become the de facto standard data augmentation in end-to-end ASR. Nevertheless, its interaction with noise conditions, speaker normalization, and curriculum schedules is not yet well understood.\n\nWe investigate augmentation schedules that adapt masking intensity to utterance length and model confidence, and we analyze their effects on stability during large-batch training. We further explore complementarity between augmentation and semi-supervised training with pseudo-labels in low-resource settings.\n\nOur results indicate that adaptive masking coupled with confidence-aware sampling reduces word error rate and mitigates overfitting on short utterances. We release configuration files and scripts to facilitate replication across common ASR toolchains.\nRelated Work\n\nOnline decision-making for ad allocation balances immediate revenue with long-term learning under uncertainty. Classic approaches modeled the problem as multi-armed bandits, later extended to incorporate context and delayed feedback. Practical systems must also address non-stationarity, covariate shift, and budget constraints across campaigns.\n\nWithin industry practice, contextual bandit methods have dominated online ad allocation in the last five years, with growing interest in offline policy evaluation for safe deployment. Yet, robust learning under evolving auctions and strategic advertiser behavior remains underexplored.\n\nWe present a robust, budget-aware contextual policy that adapts to market shifts via risk-sensitive objectives and counterfactual evaluation.\nRelated Work\n\nGraph representation learning has matured from shallow embeddings to deep architectures capable of capturing long-range dependencies and hierarchical structure. Pooling mechanisms coarsen graphs to derive multi-scale features, trading off expressivity and computational cost. Nearly all recent graph pooling methods are differentiable. Nevertheless, end-to-end differentiability can obscure the inductive biases introduced by the pooling criterion, complicating comparisons across tasks. Our work focuses on explicit, structure-preserving pooling that admits closed-form analysis of stability under edge perturbations.\n\nWe also consider connections to spectral clustering and minimum cut formulations to position our method within classical graph reduction techniques.\nIntroduction\n\nBiomedical named entity recognition (BioNER) underpins downstream tasks such as relation extraction and knowledge base curation (Settles, 2004; Li et al., 2016). Contextualized encoders adapted to biomedical corpora have advanced state of the art across multiple datasets (Beltagy et al., 2019; Lee et al., 2020). In a previous study, the authors claim that contextual embeddings outperform CRFs by 15 F1 on BC5CDR. Despite these gains, robustness to lexical variation and emerging terminology remains limited (Wang et al., 2021; Sung et al., 2021). We propose lexicon-augmented adapters to bridge out-of-vocabulary gaps.\nRelated Work\n\nQuestion answering over knowledge graphs (KGQA) requires reasoning over entities and relations to locate answers in a structured graph. Neural symbolic approaches combine learned representations with logical constraints to improve interpretability and compositionality (Yang et al., 2017; Soroush et al., 2018). Contrastive and retrieval-augmented models have improved entity disambiguation and relation handling (Sun et al., 2019; Xiong et al., 2020).\n\nMulti-hop reasoning is particularly challenging due to combinatorial expansion of candidate paths and the need to assess path plausibility. Recent work has examined path-based encoders, reinforcement learning over relation sequences, and graph attention mechanisms to prioritize informative subgraphs (Das et al., 2017; Lin et al., 2018). Extensions to heterogeneous KGs incorporate node and edge types, meta-paths, and schema constraints to guide inference, and there are many recent works that explore multi-hop reasoning in heterogeneous KGs. Our approach introduces a schema-aware pruning step that reduces path explosion by leveraging domain ontologies.\n\nWe evaluate on standard KGQA datasets and measure both accuracy and latency to assess practical viability under interactive constraints (Bordes et al., 2015; Yih et al., 2016).\n",
        "completion": "and there are many recent works that explore multi-hop reasoning in heterogeneous KGs."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        claim about prior work or statistics w/o citation or evidence. \n    a) The author should cite at every first mention of a study, paper, shared task, competition or dataset.\n    b) Specific information to a niche topic, despite sounding like it should be known in that topic of study, should be cited.\n    c) If a claim is made and is obvious to be a natural deduction from previous statements through common sense (i.e not requiring expert knowledge), then this claim does not fall under \u2018Unsupported claim\u2019. For example:\n        i) \u201cHowever, creating a large and suitable set of questions for supporting narrative comprehension is both time-consuming and cognitively demanding.\u201d -> it is obvious that creating a dataset is time consuming and mentally demanding.\n    d) Any mention of \u201crecent works\u201d should be backed up with citations to the works.\n    e) Unsupported claim issues appear as segments, phrases, sub-sentences or full sentences.\n    Examples of unsupported claims include:\n        i) Missing citations for mentions of 'recent works': \u201cand there are many recent works that explore this topic\u201d,\n        ii) Mention of a previous work and claim without citation: \u201c..., while in a previous study, the authors claim \u2026\u201d,\n        iii) Mentioning of a specific setup of a task without citation to the work: \".. BERT was used in an AES task trained on essays ..\" \n\n        Example text: \n        Introduction\n\nPolicy gradient methods have become a mainstay in reinforcement learning due to their simplicity and ability to handle continuous action spaces (Sutton et al., 2000; Schulman et al., 2017). Improved stability via clipped objectives and generalized advantage estimation has enabled better sample efficiency and robustness across tasks. On Atari 2600, PPO reaches human-level performance on many games. Nevertheless, exploration remains a bottleneck, particularly in sparse-reward environments where naive entropy bonuses are insufficient (Ecoffet et al., 2019). We propose an intrinsic motivation scheme based on state abstraction that scales to long horizons without destabilizing policy updates.\nIntroduction\n\nSpeech emotion recognition (SER) seeks to infer affective states from acoustic and linguistic cues. Classical approaches rely on engineered prosodic features combined with SVMs (Schuller et al., 2011), while recent work leverages self-supervised pretraining and multimodal fusion (Baevski et al., 2020; Tsai et al., 2019). The IEMOCAP dataset is considered the de facto standard benchmark for speech emotion recognition.\n\nHowever, heavy reliance on acted corpora raises questions about ecological validity. Cross-corpus generalization remains challenging due to speaker, channel, and annotation mismatches. We study robust SER by combining wav2vec-style representations with domain adversarial training, and we evaluate on multiple corpora, including acted and in-the-wild datasets, to better approximate real-world deployment scenarios.\nIntroduction\n\nCross-lingual transfer aims to leverage supervision in high-resource languages to improve performance in low-resource settings (Ruder et al., 2019; Conneau and Lample, 2019). Pretrained multilingual encoders enable zero-shot and few-shot transfer on a variety of tasks, but evaluation remains challenging due to dataset coverage and annotation quality. XTREME covers more than 40 languages and remains the most widely used multilingual benchmark. However, its task mix may not fully reflect realistic domain shifts encountered in production systems. We introduce a complementary benchmark focused on noisy user-generated text with balanced representation across low- and mid-resource languages.\nSpeech Recognition and Data Augmentation\n\nEnd-to-end automatic speech recognition (ASR) systems benefit significantly from data augmentation techniques that enhance robustness to acoustic and speaker variability. Time masking, frequency masking, and time warping applied to log-Mel spectrograms have shown substantial gains across corpora and model sizes. SpecAugment has become the de facto standard data augmentation in end-to-end ASR. Nevertheless, its interaction with noise conditions, speaker normalization, and curriculum schedules is not yet well understood.\n\nWe investigate augmentation schedules that adapt masking intensity to utterance length and model confidence, and we analyze their effects on stability during large-batch training. We further explore complementarity between augmentation and semi-supervised training with pseudo-labels in low-resource settings.\n\nOur results indicate that adaptive masking coupled with confidence-aware sampling reduces word error rate and mitigates overfitting on short utterances. We release configuration files and scripts to facilitate replication across common ASR toolchains.\nRelated Work\n\nOnline decision-making for ad allocation balances immediate revenue with long-term learning under uncertainty. Classic approaches modeled the problem as multi-armed bandits, later extended to incorporate context and delayed feedback. Practical systems must also address non-stationarity, covariate shift, and budget constraints across campaigns.\n\nWithin industry practice, contextual bandit methods have dominated online ad allocation in the last five years, with growing interest in offline policy evaluation for safe deployment. Yet, robust learning under evolving auctions and strategic advertiser behavior remains underexplored.\n\nWe present a robust, budget-aware contextual policy that adapts to market shifts via risk-sensitive objectives and counterfactual evaluation.\nRelated Work\n\nGraph representation learning has matured from shallow embeddings to deep architectures capable of capturing long-range dependencies and hierarchical structure. Pooling mechanisms coarsen graphs to derive multi-scale features, trading off expressivity and computational cost. Nearly all recent graph pooling methods are differentiable. Nevertheless, end-to-end differentiability can obscure the inductive biases introduced by the pooling criterion, complicating comparisons across tasks. Our work focuses on explicit, structure-preserving pooling that admits closed-form analysis of stability under edge perturbations.\n\nWe also consider connections to spectral clustering and minimum cut formulations to position our method within classical graph reduction techniques.\nIntroduction\n\nBiomedical named entity recognition (BioNER) underpins downstream tasks such as relation extraction and knowledge base curation (Settles, 2004; Li et al., 2016). Contextualized encoders adapted to biomedical corpora have advanced state of the art across multiple datasets (Beltagy et al., 2019; Lee et al., 2020). In a previous study, the authors claim that contextual embeddings outperform CRFs by 15 F1 on BC5CDR. Despite these gains, robustness to lexical variation and emerging terminology remains limited (Wang et al., 2021; Sung et al., 2021). We propose lexicon-augmented adapters to bridge out-of-vocabulary gaps.\nRelated Work\n\nQuestion answering over knowledge graphs (KGQA) requires reasoning over entities and relations to locate answers in a structured graph. Neural symbolic approaches combine learned representations with logical constraints to improve interpretability and compositionality (Yang et al., 2017; Soroush et al., 2018). Contrastive and retrieval-augmented models have improved entity disambiguation and relation handling (Sun et al., 2019; Xiong et al., 2020).\n\nMulti-hop reasoning is particularly challenging due to combinatorial expansion of candidate paths and the need to assess path plausibility. Recent work has examined path-based encoders, reinforcement learning over relation sequences, and graph attention mechanisms to prioritize informative subgraphs (Das et al., 2017; Lin et al., 2018). Extensions to heterogeneous KGs incorporate node and edge types, meta-paths, and schema constraints to guide inference, and there are many recent works that explore multi-hop reasoning in heterogeneous KGs. Our approach introduces a schema-aware pruning step that reduces path explosion by leveraging domain ontologies.\n\nWe evaluate on standard KGQA datasets and measure both accuracy and latency to assess practical viability under interactive constraints (Bordes et al., 2015; Yih et al., 2016).\nRelated Work\n\nFew-shot structured prediction has focused on leveraging syntactic priors and meta-learning to adapt parsers with minimal labeled data. In a prior study, the authors show that curriculum learning improves few-shot parsing. Subsequent approaches introduce data selection strategies that rank training examples by estimated difficulty and syntactic coverage. Our work builds on the idea of structured curricula by proposing a dependency-aware sampling schedule that prioritizes rare relation types during early training.\n\n",
        "completion": "In a prior study, the authors show that curriculum learning improves few-shot parsing."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        claim about prior work or statistics w/o citation or evidence. \n    a) The author should cite at every first mention of a study, paper, shared task, competition or dataset.\n    b) Specific information to a niche topic, despite sounding like it should be known in that topic of study, should be cited.\n    c) If a claim is made and is obvious to be a natural deduction from previous statements through common sense (i.e not requiring expert knowledge), then this claim does not fall under \u2018Unsupported claim\u2019. For example:\n        i) \u201cHowever, creating a large and suitable set of questions for supporting narrative comprehension is both time-consuming and cognitively demanding.\u201d -> it is obvious that creating a dataset is time consuming and mentally demanding.\n    d) Any mention of \u201crecent works\u201d should be backed up with citations to the works.\n    e) Unsupported claim issues appear as segments, phrases, sub-sentences or full sentences.\n    Examples of unsupported claims include:\n        i) Missing citations for mentions of 'recent works': \u201cand there are many recent works that explore this topic\u201d,\n        ii) Mention of a previous work and claim without citation: \u201c..., while in a previous study, the authors claim \u2026\u201d,\n        iii) Mentioning of a specific setup of a task without citation to the work: \".. BERT was used in an AES task trained on essays ..\" \n\n        Example text: \n        Introduction\n\nPolicy gradient methods have become a mainstay in reinforcement learning due to their simplicity and ability to handle continuous action spaces (Sutton et al., 2000; Schulman et al., 2017). Improved stability via clipped objectives and generalized advantage estimation has enabled better sample efficiency and robustness across tasks. On Atari 2600, PPO reaches human-level performance on many games. Nevertheless, exploration remains a bottleneck, particularly in sparse-reward environments where naive entropy bonuses are insufficient (Ecoffet et al., 2019). We propose an intrinsic motivation scheme based on state abstraction that scales to long horizons without destabilizing policy updates.\nIntroduction\n\nSpeech emotion recognition (SER) seeks to infer affective states from acoustic and linguistic cues. Classical approaches rely on engineered prosodic features combined with SVMs (Schuller et al., 2011), while recent work leverages self-supervised pretraining and multimodal fusion (Baevski et al., 2020; Tsai et al., 2019). The IEMOCAP dataset is considered the de facto standard benchmark for speech emotion recognition.\n\nHowever, heavy reliance on acted corpora raises questions about ecological validity. Cross-corpus generalization remains challenging due to speaker, channel, and annotation mismatches. We study robust SER by combining wav2vec-style representations with domain adversarial training, and we evaluate on multiple corpora, including acted and in-the-wild datasets, to better approximate real-world deployment scenarios.\nIntroduction\n\nCross-lingual transfer aims to leverage supervision in high-resource languages to improve performance in low-resource settings (Ruder et al., 2019; Conneau and Lample, 2019). Pretrained multilingual encoders enable zero-shot and few-shot transfer on a variety of tasks, but evaluation remains challenging due to dataset coverage and annotation quality. XTREME covers more than 40 languages and remains the most widely used multilingual benchmark. However, its task mix may not fully reflect realistic domain shifts encountered in production systems. We introduce a complementary benchmark focused on noisy user-generated text with balanced representation across low- and mid-resource languages.\nSpeech Recognition and Data Augmentation\n\nEnd-to-end automatic speech recognition (ASR) systems benefit significantly from data augmentation techniques that enhance robustness to acoustic and speaker variability. Time masking, frequency masking, and time warping applied to log-Mel spectrograms have shown substantial gains across corpora and model sizes. SpecAugment has become the de facto standard data augmentation in end-to-end ASR. Nevertheless, its interaction with noise conditions, speaker normalization, and curriculum schedules is not yet well understood.\n\nWe investigate augmentation schedules that adapt masking intensity to utterance length and model confidence, and we analyze their effects on stability during large-batch training. We further explore complementarity between augmentation and semi-supervised training with pseudo-labels in low-resource settings.\n\nOur results indicate that adaptive masking coupled with confidence-aware sampling reduces word error rate and mitigates overfitting on short utterances. We release configuration files and scripts to facilitate replication across common ASR toolchains.\nRelated Work\n\nOnline decision-making for ad allocation balances immediate revenue with long-term learning under uncertainty. Classic approaches modeled the problem as multi-armed bandits, later extended to incorporate context and delayed feedback. Practical systems must also address non-stationarity, covariate shift, and budget constraints across campaigns.\n\nWithin industry practice, contextual bandit methods have dominated online ad allocation in the last five years, with growing interest in offline policy evaluation for safe deployment. Yet, robust learning under evolving auctions and strategic advertiser behavior remains underexplored.\n\nWe present a robust, budget-aware contextual policy that adapts to market shifts via risk-sensitive objectives and counterfactual evaluation.\nRelated Work\n\nGraph representation learning has matured from shallow embeddings to deep architectures capable of capturing long-range dependencies and hierarchical structure. Pooling mechanisms coarsen graphs to derive multi-scale features, trading off expressivity and computational cost. Nearly all recent graph pooling methods are differentiable. Nevertheless, end-to-end differentiability can obscure the inductive biases introduced by the pooling criterion, complicating comparisons across tasks. Our work focuses on explicit, structure-preserving pooling that admits closed-form analysis of stability under edge perturbations.\n\nWe also consider connections to spectral clustering and minimum cut formulations to position our method within classical graph reduction techniques.\nIntroduction\n\nBiomedical named entity recognition (BioNER) underpins downstream tasks such as relation extraction and knowledge base curation (Settles, 2004; Li et al., 2016). Contextualized encoders adapted to biomedical corpora have advanced state of the art across multiple datasets (Beltagy et al., 2019; Lee et al., 2020). In a previous study, the authors claim that contextual embeddings outperform CRFs by 15 F1 on BC5CDR. Despite these gains, robustness to lexical variation and emerging terminology remains limited (Wang et al., 2021; Sung et al., 2021). We propose lexicon-augmented adapters to bridge out-of-vocabulary gaps.\nRelated Work\n\nQuestion answering over knowledge graphs (KGQA) requires reasoning over entities and relations to locate answers in a structured graph. Neural symbolic approaches combine learned representations with logical constraints to improve interpretability and compositionality (Yang et al., 2017; Soroush et al., 2018). Contrastive and retrieval-augmented models have improved entity disambiguation and relation handling (Sun et al., 2019; Xiong et al., 2020).\n\nMulti-hop reasoning is particularly challenging due to combinatorial expansion of candidate paths and the need to assess path plausibility. Recent work has examined path-based encoders, reinforcement learning over relation sequences, and graph attention mechanisms to prioritize informative subgraphs (Das et al., 2017; Lin et al., 2018). Extensions to heterogeneous KGs incorporate node and edge types, meta-paths, and schema constraints to guide inference, and there are many recent works that explore multi-hop reasoning in heterogeneous KGs. Our approach introduces a schema-aware pruning step that reduces path explosion by leveraging domain ontologies.\n\nWe evaluate on standard KGQA datasets and measure both accuracy and latency to assess practical viability under interactive constraints (Bordes et al., 2015; Yih et al., 2016).\nRelated Work\n\nFew-shot structured prediction has focused on leveraging syntactic priors and meta-learning to adapt parsers with minimal labeled data. In a prior study, the authors show that curriculum learning improves few-shot parsing. Subsequent approaches introduce data selection strategies that rank training examples by estimated difficulty and syntactic coverage. Our work builds on the idea of structured curricula by proposing a dependency-aware sampling schedule that prioritizes rare relation types during early training.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a primary tool for fraud and anomaly detection in relational data, capturing higher-order structures that traditional methods miss (Kipf and Welling, 2017; Dou et al., 2020). Self-supervised objectives further enhance representation learning when labels are scarce (Velickovic et al., 2019; You et al., 2020). GCN-based autoencoders were used in the XBRL anomaly detection task on SEC filings. Our work extends these ideas with temporal edge features and contrastive regularization to model evolving corporate networks.\n",
        "completion": "GCN-based autoencoders were used in the XBRL anomaly detection task on SEC filings."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        claim about prior work or statistics w/o citation or evidence. \n    a) The author should cite at every first mention of a study, paper, shared task, competition or dataset.\n    b) Specific information to a niche topic, despite sounding like it should be known in that topic of study, should be cited.\n    c) If a claim is made and is obvious to be a natural deduction from previous statements through common sense (i.e not requiring expert knowledge), then this claim does not fall under \u2018Unsupported claim\u2019. For example:\n        i) \u201cHowever, creating a large and suitable set of questions for supporting narrative comprehension is both time-consuming and cognitively demanding.\u201d -> it is obvious that creating a dataset is time consuming and mentally demanding.\n    d) Any mention of \u201crecent works\u201d should be backed up with citations to the works.\n    e) Unsupported claim issues appear as segments, phrases, sub-sentences or full sentences.\n    Examples of unsupported claims include:\n        i) Missing citations for mentions of 'recent works': \u201cand there are many recent works that explore this topic\u201d,\n        ii) Mention of a previous work and claim without citation: \u201c..., while in a previous study, the authors claim \u2026\u201d,\n        iii) Mentioning of a specific setup of a task without citation to the work: \".. BERT was used in an AES task trained on essays ..\" \n\n        Example text: \n        Introduction\n\nPolicy gradient methods have become a mainstay in reinforcement learning due to their simplicity and ability to handle continuous action spaces (Sutton et al., 2000; Schulman et al., 2017). Improved stability via clipped objectives and generalized advantage estimation has enabled better sample efficiency and robustness across tasks. On Atari 2600, PPO reaches human-level performance on many games. Nevertheless, exploration remains a bottleneck, particularly in sparse-reward environments where naive entropy bonuses are insufficient (Ecoffet et al., 2019). We propose an intrinsic motivation scheme based on state abstraction that scales to long horizons without destabilizing policy updates.\nIntroduction\n\nSpeech emotion recognition (SER) seeks to infer affective states from acoustic and linguistic cues. Classical approaches rely on engineered prosodic features combined with SVMs (Schuller et al., 2011), while recent work leverages self-supervised pretraining and multimodal fusion (Baevski et al., 2020; Tsai et al., 2019). The IEMOCAP dataset is considered the de facto standard benchmark for speech emotion recognition.\n\nHowever, heavy reliance on acted corpora raises questions about ecological validity. Cross-corpus generalization remains challenging due to speaker, channel, and annotation mismatches. We study robust SER by combining wav2vec-style representations with domain adversarial training, and we evaluate on multiple corpora, including acted and in-the-wild datasets, to better approximate real-world deployment scenarios.\nIntroduction\n\nCross-lingual transfer aims to leverage supervision in high-resource languages to improve performance in low-resource settings (Ruder et al., 2019; Conneau and Lample, 2019). Pretrained multilingual encoders enable zero-shot and few-shot transfer on a variety of tasks, but evaluation remains challenging due to dataset coverage and annotation quality. XTREME covers more than 40 languages and remains the most widely used multilingual benchmark. However, its task mix may not fully reflect realistic domain shifts encountered in production systems. We introduce a complementary benchmark focused on noisy user-generated text with balanced representation across low- and mid-resource languages.\nSpeech Recognition and Data Augmentation\n\nEnd-to-end automatic speech recognition (ASR) systems benefit significantly from data augmentation techniques that enhance robustness to acoustic and speaker variability. Time masking, frequency masking, and time warping applied to log-Mel spectrograms have shown substantial gains across corpora and model sizes. SpecAugment has become the de facto standard data augmentation in end-to-end ASR. Nevertheless, its interaction with noise conditions, speaker normalization, and curriculum schedules is not yet well understood.\n\nWe investigate augmentation schedules that adapt masking intensity to utterance length and model confidence, and we analyze their effects on stability during large-batch training. We further explore complementarity between augmentation and semi-supervised training with pseudo-labels in low-resource settings.\n\nOur results indicate that adaptive masking coupled with confidence-aware sampling reduces word error rate and mitigates overfitting on short utterances. We release configuration files and scripts to facilitate replication across common ASR toolchains.\nRelated Work\n\nOnline decision-making for ad allocation balances immediate revenue with long-term learning under uncertainty. Classic approaches modeled the problem as multi-armed bandits, later extended to incorporate context and delayed feedback. Practical systems must also address non-stationarity, covariate shift, and budget constraints across campaigns.\n\nWithin industry practice, contextual bandit methods have dominated online ad allocation in the last five years, with growing interest in offline policy evaluation for safe deployment. Yet, robust learning under evolving auctions and strategic advertiser behavior remains underexplored.\n\nWe present a robust, budget-aware contextual policy that adapts to market shifts via risk-sensitive objectives and counterfactual evaluation.\nRelated Work\n\nGraph representation learning has matured from shallow embeddings to deep architectures capable of capturing long-range dependencies and hierarchical structure. Pooling mechanisms coarsen graphs to derive multi-scale features, trading off expressivity and computational cost. Nearly all recent graph pooling methods are differentiable. Nevertheless, end-to-end differentiability can obscure the inductive biases introduced by the pooling criterion, complicating comparisons across tasks. Our work focuses on explicit, structure-preserving pooling that admits closed-form analysis of stability under edge perturbations.\n\nWe also consider connections to spectral clustering and minimum cut formulations to position our method within classical graph reduction techniques.\nIntroduction\n\nBiomedical named entity recognition (BioNER) underpins downstream tasks such as relation extraction and knowledge base curation (Settles, 2004; Li et al., 2016). Contextualized encoders adapted to biomedical corpora have advanced state of the art across multiple datasets (Beltagy et al., 2019; Lee et al., 2020). In a previous study, the authors claim that contextual embeddings outperform CRFs by 15 F1 on BC5CDR. Despite these gains, robustness to lexical variation and emerging terminology remains limited (Wang et al., 2021; Sung et al., 2021). We propose lexicon-augmented adapters to bridge out-of-vocabulary gaps.\nRelated Work\n\nQuestion answering over knowledge graphs (KGQA) requires reasoning over entities and relations to locate answers in a structured graph. Neural symbolic approaches combine learned representations with logical constraints to improve interpretability and compositionality (Yang et al., 2017; Soroush et al., 2018). Contrastive and retrieval-augmented models have improved entity disambiguation and relation handling (Sun et al., 2019; Xiong et al., 2020).\n\nMulti-hop reasoning is particularly challenging due to combinatorial expansion of candidate paths and the need to assess path plausibility. Recent work has examined path-based encoders, reinforcement learning over relation sequences, and graph attention mechanisms to prioritize informative subgraphs (Das et al., 2017; Lin et al., 2018). Extensions to heterogeneous KGs incorporate node and edge types, meta-paths, and schema constraints to guide inference, and there are many recent works that explore multi-hop reasoning in heterogeneous KGs. Our approach introduces a schema-aware pruning step that reduces path explosion by leveraging domain ontologies.\n\nWe evaluate on standard KGQA datasets and measure both accuracy and latency to assess practical viability under interactive constraints (Bordes et al., 2015; Yih et al., 2016).\nRelated Work\n\nFew-shot structured prediction has focused on leveraging syntactic priors and meta-learning to adapt parsers with minimal labeled data. In a prior study, the authors show that curriculum learning improves few-shot parsing. Subsequent approaches introduce data selection strategies that rank training examples by estimated difficulty and syntactic coverage. Our work builds on the idea of structured curricula by proposing a dependency-aware sampling schedule that prioritizes rare relation types during early training.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a primary tool for fraud and anomaly detection in relational data, capturing higher-order structures that traditional methods miss (Kipf and Welling, 2017; Dou et al., 2020). Self-supervised objectives further enhance representation learning when labels are scarce (Velickovic et al., 2019; You et al., 2020). GCN-based autoencoders were used in the XBRL anomaly detection task on SEC filings. Our work extends these ideas with temporal edge features and contrastive regularization to model evolving corporate networks.\nIntroduction\nFederated learning (FL) enables decentralized training across clients while preserving data locality. On graph-structured data, FL must handle non-i.i.d. topologies, heterophily, and varying label regimes, complicating aggregation and personalization (Wang and Luo, 2021; Cheng et al., 2022). Meanwhile, differential privacy (DP) offers formal protections against information leakage from trained models.\nTo the best of our knowledge, this is the first method to provide certified DP guarantees for graph federated learning. We integrate gradient clipping and noise accounting with topology-aware aggregation to bound privacy loss per client. Our analysis includes tight composition and post-processing invariance under client sampling.\nWe validate on citation and social network benchmarks, demonstrating improved utility-privacy trade-offs over non-graph baselines.\n",
        "completion": "To the best of our knowledge, this is the first method to provide certified DP guarantees for graph federated learning."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        claim about prior work or statistics w/o citation or evidence. \n    a) The author should cite at every first mention of a study, paper, shared task, competition or dataset.\n    b) Specific information to a niche topic, despite sounding like it should be known in that topic of study, should be cited.\n    c) If a claim is made and is obvious to be a natural deduction from previous statements through common sense (i.e not requiring expert knowledge), then this claim does not fall under \u2018Unsupported claim\u2019. For example:\n        i) \u201cHowever, creating a large and suitable set of questions for supporting narrative comprehension is both time-consuming and cognitively demanding.\u201d -> it is obvious that creating a dataset is time consuming and mentally demanding.\n    d) Any mention of \u201crecent works\u201d should be backed up with citations to the works.\n    e) Unsupported claim issues appear as segments, phrases, sub-sentences or full sentences.\n    Examples of unsupported claims include:\n        i) Missing citations for mentions of 'recent works': \u201cand there are many recent works that explore this topic\u201d,\n        ii) Mention of a previous work and claim without citation: \u201c..., while in a previous study, the authors claim \u2026\u201d,\n        iii) Mentioning of a specific setup of a task without citation to the work: \".. BERT was used in an AES task trained on essays ..\" \n\n        Example text: \n        Introduction\n\nPolicy gradient methods have become a mainstay in reinforcement learning due to their simplicity and ability to handle continuous action spaces (Sutton et al., 2000; Schulman et al., 2017). Improved stability via clipped objectives and generalized advantage estimation has enabled better sample efficiency and robustness across tasks. On Atari 2600, PPO reaches human-level performance on many games. Nevertheless, exploration remains a bottleneck, particularly in sparse-reward environments where naive entropy bonuses are insufficient (Ecoffet et al., 2019). We propose an intrinsic motivation scheme based on state abstraction that scales to long horizons without destabilizing policy updates.\nIntroduction\n\nSpeech emotion recognition (SER) seeks to infer affective states from acoustic and linguistic cues. Classical approaches rely on engineered prosodic features combined with SVMs (Schuller et al., 2011), while recent work leverages self-supervised pretraining and multimodal fusion (Baevski et al., 2020; Tsai et al., 2019). The IEMOCAP dataset is considered the de facto standard benchmark for speech emotion recognition.\n\nHowever, heavy reliance on acted corpora raises questions about ecological validity. Cross-corpus generalization remains challenging due to speaker, channel, and annotation mismatches. We study robust SER by combining wav2vec-style representations with domain adversarial training, and we evaluate on multiple corpora, including acted and in-the-wild datasets, to better approximate real-world deployment scenarios.\nIntroduction\n\nCross-lingual transfer aims to leverage supervision in high-resource languages to improve performance in low-resource settings (Ruder et al., 2019; Conneau and Lample, 2019). Pretrained multilingual encoders enable zero-shot and few-shot transfer on a variety of tasks, but evaluation remains challenging due to dataset coverage and annotation quality. XTREME covers more than 40 languages and remains the most widely used multilingual benchmark. However, its task mix may not fully reflect realistic domain shifts encountered in production systems. We introduce a complementary benchmark focused on noisy user-generated text with balanced representation across low- and mid-resource languages.\nSpeech Recognition and Data Augmentation\n\nEnd-to-end automatic speech recognition (ASR) systems benefit significantly from data augmentation techniques that enhance robustness to acoustic and speaker variability. Time masking, frequency masking, and time warping applied to log-Mel spectrograms have shown substantial gains across corpora and model sizes. SpecAugment has become the de facto standard data augmentation in end-to-end ASR. Nevertheless, its interaction with noise conditions, speaker normalization, and curriculum schedules is not yet well understood.\n\nWe investigate augmentation schedules that adapt masking intensity to utterance length and model confidence, and we analyze their effects on stability during large-batch training. We further explore complementarity between augmentation and semi-supervised training with pseudo-labels in low-resource settings.\n\nOur results indicate that adaptive masking coupled with confidence-aware sampling reduces word error rate and mitigates overfitting on short utterances. We release configuration files and scripts to facilitate replication across common ASR toolchains.\nRelated Work\n\nOnline decision-making for ad allocation balances immediate revenue with long-term learning under uncertainty. Classic approaches modeled the problem as multi-armed bandits, later extended to incorporate context and delayed feedback. Practical systems must also address non-stationarity, covariate shift, and budget constraints across campaigns.\n\nWithin industry practice, contextual bandit methods have dominated online ad allocation in the last five years, with growing interest in offline policy evaluation for safe deployment. Yet, robust learning under evolving auctions and strategic advertiser behavior remains underexplored.\n\nWe present a robust, budget-aware contextual policy that adapts to market shifts via risk-sensitive objectives and counterfactual evaluation.\nRelated Work\n\nGraph representation learning has matured from shallow embeddings to deep architectures capable of capturing long-range dependencies and hierarchical structure. Pooling mechanisms coarsen graphs to derive multi-scale features, trading off expressivity and computational cost. Nearly all recent graph pooling methods are differentiable. Nevertheless, end-to-end differentiability can obscure the inductive biases introduced by the pooling criterion, complicating comparisons across tasks. Our work focuses on explicit, structure-preserving pooling that admits closed-form analysis of stability under edge perturbations.\n\nWe also consider connections to spectral clustering and minimum cut formulations to position our method within classical graph reduction techniques.\nIntroduction\n\nBiomedical named entity recognition (BioNER) underpins downstream tasks such as relation extraction and knowledge base curation (Settles, 2004; Li et al., 2016). Contextualized encoders adapted to biomedical corpora have advanced state of the art across multiple datasets (Beltagy et al., 2019; Lee et al., 2020). In a previous study, the authors claim that contextual embeddings outperform CRFs by 15 F1 on BC5CDR. Despite these gains, robustness to lexical variation and emerging terminology remains limited (Wang et al., 2021; Sung et al., 2021). We propose lexicon-augmented adapters to bridge out-of-vocabulary gaps.\nRelated Work\n\nQuestion answering over knowledge graphs (KGQA) requires reasoning over entities and relations to locate answers in a structured graph. Neural symbolic approaches combine learned representations with logical constraints to improve interpretability and compositionality (Yang et al., 2017; Soroush et al., 2018). Contrastive and retrieval-augmented models have improved entity disambiguation and relation handling (Sun et al., 2019; Xiong et al., 2020).\n\nMulti-hop reasoning is particularly challenging due to combinatorial expansion of candidate paths and the need to assess path plausibility. Recent work has examined path-based encoders, reinforcement learning over relation sequences, and graph attention mechanisms to prioritize informative subgraphs (Das et al., 2017; Lin et al., 2018). Extensions to heterogeneous KGs incorporate node and edge types, meta-paths, and schema constraints to guide inference, and there are many recent works that explore multi-hop reasoning in heterogeneous KGs. Our approach introduces a schema-aware pruning step that reduces path explosion by leveraging domain ontologies.\n\nWe evaluate on standard KGQA datasets and measure both accuracy and latency to assess practical viability under interactive constraints (Bordes et al., 2015; Yih et al., 2016).\nRelated Work\n\nFew-shot structured prediction has focused on leveraging syntactic priors and meta-learning to adapt parsers with minimal labeled data. In a prior study, the authors show that curriculum learning improves few-shot parsing. Subsequent approaches introduce data selection strategies that rank training examples by estimated difficulty and syntactic coverage. Our work builds on the idea of structured curricula by proposing a dependency-aware sampling schedule that prioritizes rare relation types during early training.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a primary tool for fraud and anomaly detection in relational data, capturing higher-order structures that traditional methods miss (Kipf and Welling, 2017; Dou et al., 2020). Self-supervised objectives further enhance representation learning when labels are scarce (Velickovic et al., 2019; You et al., 2020). GCN-based autoencoders were used in the XBRL anomaly detection task on SEC filings. Our work extends these ideas with temporal edge features and contrastive regularization to model evolving corporate networks.\nIntroduction\nFederated learning (FL) enables decentralized training across clients while preserving data locality. On graph-structured data, FL must handle non-i.i.d. topologies, heterophily, and varying label regimes, complicating aggregation and personalization (Wang and Luo, 2021; Cheng et al., 2022). Meanwhile, differential privacy (DP) offers formal protections against information leakage from trained models.\nTo the best of our knowledge, this is the first method to provide certified DP guarantees for graph federated learning. We integrate gradient clipping and noise accounting with topology-aware aggregation to bound privacy loss per client. Our analysis includes tight composition and post-processing invariance under client sampling.\nWe validate on citation and social network benchmarks, demonstrating improved utility-privacy trade-offs over non-graph baselines.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has benefited from large supervised datasets and self-supervised pretraining on unlabeled audio (Baevski et al., 2020; Hsu et al., 2021). However, language coverage remains uneven, with many under-resourced languages lacking sufficient transcribed data.\n\nMost low-resource ASR corpora only provide phoneme-level transcriptions, limiting the utility of standard sequence-to-sequence models that expect graphemic or word-level targets. This mismatch motivates intermediate representations and multilingual sharing strategies.\n\nWe propose a pronunciation-informed transducer that aligns phoneme inventories to graphemic targets via learned lexicon induction, improving transfer in settings with sparse orthographic supervision.\n",
        "completion": "Most low-resource ASR corpora only provide phoneme-level transcriptions"
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        claim about prior work or statistics w/o citation or evidence. \n    a) The author should cite at every first mention of a study, paper, shared task, competition or dataset.\n    b) Specific information to a niche topic, despite sounding like it should be known in that topic of study, should be cited.\n    c) If a claim is made and is obvious to be a natural deduction from previous statements through common sense (i.e not requiring expert knowledge), then this claim does not fall under \u2018Unsupported claim\u2019. For example:\n        i) \u201cHowever, creating a large and suitable set of questions for supporting narrative comprehension is both time-consuming and cognitively demanding.\u201d -> it is obvious that creating a dataset is time consuming and mentally demanding.\n    d) Any mention of \u201crecent works\u201d should be backed up with citations to the works.\n    e) Unsupported claim issues appear as segments, phrases, sub-sentences or full sentences.\n    Examples of unsupported claims include:\n        i) Missing citations for mentions of 'recent works': \u201cand there are many recent works that explore this topic\u201d,\n        ii) Mention of a previous work and claim without citation: \u201c..., while in a previous study, the authors claim \u2026\u201d,\n        iii) Mentioning of a specific setup of a task without citation to the work: \".. BERT was used in an AES task trained on essays ..\" \n\n        Example text: \n        Introduction\n\nPolicy gradient methods have become a mainstay in reinforcement learning due to their simplicity and ability to handle continuous action spaces (Sutton et al., 2000; Schulman et al., 2017). Improved stability via clipped objectives and generalized advantage estimation has enabled better sample efficiency and robustness across tasks. On Atari 2600, PPO reaches human-level performance on many games. Nevertheless, exploration remains a bottleneck, particularly in sparse-reward environments where naive entropy bonuses are insufficient (Ecoffet et al., 2019). We propose an intrinsic motivation scheme based on state abstraction that scales to long horizons without destabilizing policy updates.\nIntroduction\n\nSpeech emotion recognition (SER) seeks to infer affective states from acoustic and linguistic cues. Classical approaches rely on engineered prosodic features combined with SVMs (Schuller et al., 2011), while recent work leverages self-supervised pretraining and multimodal fusion (Baevski et al., 2020; Tsai et al., 2019). The IEMOCAP dataset is considered the de facto standard benchmark for speech emotion recognition.\n\nHowever, heavy reliance on acted corpora raises questions about ecological validity. Cross-corpus generalization remains challenging due to speaker, channel, and annotation mismatches. We study robust SER by combining wav2vec-style representations with domain adversarial training, and we evaluate on multiple corpora, including acted and in-the-wild datasets, to better approximate real-world deployment scenarios.\nIntroduction\n\nCross-lingual transfer aims to leverage supervision in high-resource languages to improve performance in low-resource settings (Ruder et al., 2019; Conneau and Lample, 2019). Pretrained multilingual encoders enable zero-shot and few-shot transfer on a variety of tasks, but evaluation remains challenging due to dataset coverage and annotation quality. XTREME covers more than 40 languages and remains the most widely used multilingual benchmark. However, its task mix may not fully reflect realistic domain shifts encountered in production systems. We introduce a complementary benchmark focused on noisy user-generated text with balanced representation across low- and mid-resource languages.\nSpeech Recognition and Data Augmentation\n\nEnd-to-end automatic speech recognition (ASR) systems benefit significantly from data augmentation techniques that enhance robustness to acoustic and speaker variability. Time masking, frequency masking, and time warping applied to log-Mel spectrograms have shown substantial gains across corpora and model sizes. SpecAugment has become the de facto standard data augmentation in end-to-end ASR. Nevertheless, its interaction with noise conditions, speaker normalization, and curriculum schedules is not yet well understood.\n\nWe investigate augmentation schedules that adapt masking intensity to utterance length and model confidence, and we analyze their effects on stability during large-batch training. We further explore complementarity between augmentation and semi-supervised training with pseudo-labels in low-resource settings.\n\nOur results indicate that adaptive masking coupled with confidence-aware sampling reduces word error rate and mitigates overfitting on short utterances. We release configuration files and scripts to facilitate replication across common ASR toolchains.\nRelated Work\n\nOnline decision-making for ad allocation balances immediate revenue with long-term learning under uncertainty. Classic approaches modeled the problem as multi-armed bandits, later extended to incorporate context and delayed feedback. Practical systems must also address non-stationarity, covariate shift, and budget constraints across campaigns.\n\nWithin industry practice, contextual bandit methods have dominated online ad allocation in the last five years, with growing interest in offline policy evaluation for safe deployment. Yet, robust learning under evolving auctions and strategic advertiser behavior remains underexplored.\n\nWe present a robust, budget-aware contextual policy that adapts to market shifts via risk-sensitive objectives and counterfactual evaluation.\nRelated Work\n\nGraph representation learning has matured from shallow embeddings to deep architectures capable of capturing long-range dependencies and hierarchical structure. Pooling mechanisms coarsen graphs to derive multi-scale features, trading off expressivity and computational cost. Nearly all recent graph pooling methods are differentiable. Nevertheless, end-to-end differentiability can obscure the inductive biases introduced by the pooling criterion, complicating comparisons across tasks. Our work focuses on explicit, structure-preserving pooling that admits closed-form analysis of stability under edge perturbations.\n\nWe also consider connections to spectral clustering and minimum cut formulations to position our method within classical graph reduction techniques.\nIntroduction\n\nBiomedical named entity recognition (BioNER) underpins downstream tasks such as relation extraction and knowledge base curation (Settles, 2004; Li et al., 2016). Contextualized encoders adapted to biomedical corpora have advanced state of the art across multiple datasets (Beltagy et al., 2019; Lee et al., 2020). In a previous study, the authors claim that contextual embeddings outperform CRFs by 15 F1 on BC5CDR. Despite these gains, robustness to lexical variation and emerging terminology remains limited (Wang et al., 2021; Sung et al., 2021). We propose lexicon-augmented adapters to bridge out-of-vocabulary gaps.\nRelated Work\n\nQuestion answering over knowledge graphs (KGQA) requires reasoning over entities and relations to locate answers in a structured graph. Neural symbolic approaches combine learned representations with logical constraints to improve interpretability and compositionality (Yang et al., 2017; Soroush et al., 2018). Contrastive and retrieval-augmented models have improved entity disambiguation and relation handling (Sun et al., 2019; Xiong et al., 2020).\n\nMulti-hop reasoning is particularly challenging due to combinatorial expansion of candidate paths and the need to assess path plausibility. Recent work has examined path-based encoders, reinforcement learning over relation sequences, and graph attention mechanisms to prioritize informative subgraphs (Das et al., 2017; Lin et al., 2018). Extensions to heterogeneous KGs incorporate node and edge types, meta-paths, and schema constraints to guide inference, and there are many recent works that explore multi-hop reasoning in heterogeneous KGs. Our approach introduces a schema-aware pruning step that reduces path explosion by leveraging domain ontologies.\n\nWe evaluate on standard KGQA datasets and measure both accuracy and latency to assess practical viability under interactive constraints (Bordes et al., 2015; Yih et al., 2016).\nRelated Work\n\nFew-shot structured prediction has focused on leveraging syntactic priors and meta-learning to adapt parsers with minimal labeled data. In a prior study, the authors show that curriculum learning improves few-shot parsing. Subsequent approaches introduce data selection strategies that rank training examples by estimated difficulty and syntactic coverage. Our work builds on the idea of structured curricula by proposing a dependency-aware sampling schedule that prioritizes rare relation types during early training.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a primary tool for fraud and anomaly detection in relational data, capturing higher-order structures that traditional methods miss (Kipf and Welling, 2017; Dou et al., 2020). Self-supervised objectives further enhance representation learning when labels are scarce (Velickovic et al., 2019; You et al., 2020). GCN-based autoencoders were used in the XBRL anomaly detection task on SEC filings. Our work extends these ideas with temporal edge features and contrastive regularization to model evolving corporate networks.\nIntroduction\nFederated learning (FL) enables decentralized training across clients while preserving data locality. On graph-structured data, FL must handle non-i.i.d. topologies, heterophily, and varying label regimes, complicating aggregation and personalization (Wang and Luo, 2021; Cheng et al., 2022). Meanwhile, differential privacy (DP) offers formal protections against information leakage from trained models.\nTo the best of our knowledge, this is the first method to provide certified DP guarantees for graph federated learning. We integrate gradient clipping and noise accounting with topology-aware aggregation to bound privacy loss per client. Our analysis includes tight composition and post-processing invariance under client sampling.\nWe validate on citation and social network benchmarks, demonstrating improved utility-privacy trade-offs over non-graph baselines.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has benefited from large supervised datasets and self-supervised pretraining on unlabeled audio (Baevski et al., 2020; Hsu et al., 2021). However, language coverage remains uneven, with many under-resourced languages lacking sufficient transcribed data.\n\nMost low-resource ASR corpora only provide phoneme-level transcriptions, limiting the utility of standard sequence-to-sequence models that expect graphemic or word-level targets. This mismatch motivates intermediate representations and multilingual sharing strategies.\n\nWe propose a pronunciation-informed transducer that aligns phoneme inventories to graphemic targets via learned lexicon induction, improving transfer in settings with sparse orthographic supervision.\nRelated Work\n\nSelf-Supervised Pretraining for Speech Recognition. Recent ASR systems leverage SSL models such as wav2vec 2.0 (Baevski et al., 2020), HuBERT (Hsu et al., 2021), and WavLM (Chen et al., 2022) to improve label efficiency. These models are typically fine-tuned on labeled speech after pretraining on large unlabeled corpora. There are numerous recent works demonstrating that wav2vec-style pretraining makes labeled speech obsolete for low-resource ASR. In contrast, semi-supervised training methods like pseudo-labeling (Kahn et al., 2020) still rely on a modest amount of transcribed data.\n",
        "completion": "There are numerous recent works demonstrating that wav2vec-style pretraining makes labeled speech obsolete for low-resource ASR."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        claim about prior work or statistics w/o citation or evidence. \n    a) The author should cite at every first mention of a study, paper, shared task, competition or dataset.\n    b) Specific information to a niche topic, despite sounding like it should be known in that topic of study, should be cited.\n    c) If a claim is made and is obvious to be a natural deduction from previous statements through common sense (i.e not requiring expert knowledge), then this claim does not fall under \u2018Unsupported claim\u2019. For example:\n        i) \u201cHowever, creating a large and suitable set of questions for supporting narrative comprehension is both time-consuming and cognitively demanding.\u201d -> it is obvious that creating a dataset is time consuming and mentally demanding.\n    d) Any mention of \u201crecent works\u201d should be backed up with citations to the works.\n    e) Unsupported claim issues appear as segments, phrases, sub-sentences or full sentences.\n    Examples of unsupported claims include:\n        i) Missing citations for mentions of 'recent works': \u201cand there are many recent works that explore this topic\u201d,\n        ii) Mention of a previous work and claim without citation: \u201c..., while in a previous study, the authors claim \u2026\u201d,\n        iii) Mentioning of a specific setup of a task without citation to the work: \".. BERT was used in an AES task trained on essays ..\" \n\n        Example text: \n        Introduction\n\nPolicy gradient methods have become a mainstay in reinforcement learning due to their simplicity and ability to handle continuous action spaces (Sutton et al., 2000; Schulman et al., 2017). Improved stability via clipped objectives and generalized advantage estimation has enabled better sample efficiency and robustness across tasks. On Atari 2600, PPO reaches human-level performance on many games. Nevertheless, exploration remains a bottleneck, particularly in sparse-reward environments where naive entropy bonuses are insufficient (Ecoffet et al., 2019). We propose an intrinsic motivation scheme based on state abstraction that scales to long horizons without destabilizing policy updates.\nIntroduction\n\nSpeech emotion recognition (SER) seeks to infer affective states from acoustic and linguistic cues. Classical approaches rely on engineered prosodic features combined with SVMs (Schuller et al., 2011), while recent work leverages self-supervised pretraining and multimodal fusion (Baevski et al., 2020; Tsai et al., 2019). The IEMOCAP dataset is considered the de facto standard benchmark for speech emotion recognition.\n\nHowever, heavy reliance on acted corpora raises questions about ecological validity. Cross-corpus generalization remains challenging due to speaker, channel, and annotation mismatches. We study robust SER by combining wav2vec-style representations with domain adversarial training, and we evaluate on multiple corpora, including acted and in-the-wild datasets, to better approximate real-world deployment scenarios.\nIntroduction\n\nCross-lingual transfer aims to leverage supervision in high-resource languages to improve performance in low-resource settings (Ruder et al., 2019; Conneau and Lample, 2019). Pretrained multilingual encoders enable zero-shot and few-shot transfer on a variety of tasks, but evaluation remains challenging due to dataset coverage and annotation quality. XTREME covers more than 40 languages and remains the most widely used multilingual benchmark. However, its task mix may not fully reflect realistic domain shifts encountered in production systems. We introduce a complementary benchmark focused on noisy user-generated text with balanced representation across low- and mid-resource languages.\nSpeech Recognition and Data Augmentation\n\nEnd-to-end automatic speech recognition (ASR) systems benefit significantly from data augmentation techniques that enhance robustness to acoustic and speaker variability. Time masking, frequency masking, and time warping applied to log-Mel spectrograms have shown substantial gains across corpora and model sizes. SpecAugment has become the de facto standard data augmentation in end-to-end ASR. Nevertheless, its interaction with noise conditions, speaker normalization, and curriculum schedules is not yet well understood.\n\nWe investigate augmentation schedules that adapt masking intensity to utterance length and model confidence, and we analyze their effects on stability during large-batch training. We further explore complementarity between augmentation and semi-supervised training with pseudo-labels in low-resource settings.\n\nOur results indicate that adaptive masking coupled with confidence-aware sampling reduces word error rate and mitigates overfitting on short utterances. We release configuration files and scripts to facilitate replication across common ASR toolchains.\nRelated Work\n\nOnline decision-making for ad allocation balances immediate revenue with long-term learning under uncertainty. Classic approaches modeled the problem as multi-armed bandits, later extended to incorporate context and delayed feedback. Practical systems must also address non-stationarity, covariate shift, and budget constraints across campaigns.\n\nWithin industry practice, contextual bandit methods have dominated online ad allocation in the last five years, with growing interest in offline policy evaluation for safe deployment. Yet, robust learning under evolving auctions and strategic advertiser behavior remains underexplored.\n\nWe present a robust, budget-aware contextual policy that adapts to market shifts via risk-sensitive objectives and counterfactual evaluation.\nRelated Work\n\nGraph representation learning has matured from shallow embeddings to deep architectures capable of capturing long-range dependencies and hierarchical structure. Pooling mechanisms coarsen graphs to derive multi-scale features, trading off expressivity and computational cost. Nearly all recent graph pooling methods are differentiable. Nevertheless, end-to-end differentiability can obscure the inductive biases introduced by the pooling criterion, complicating comparisons across tasks. Our work focuses on explicit, structure-preserving pooling that admits closed-form analysis of stability under edge perturbations.\n\nWe also consider connections to spectral clustering and minimum cut formulations to position our method within classical graph reduction techniques.\nIntroduction\n\nBiomedical named entity recognition (BioNER) underpins downstream tasks such as relation extraction and knowledge base curation (Settles, 2004; Li et al., 2016). Contextualized encoders adapted to biomedical corpora have advanced state of the art across multiple datasets (Beltagy et al., 2019; Lee et al., 2020). In a previous study, the authors claim that contextual embeddings outperform CRFs by 15 F1 on BC5CDR. Despite these gains, robustness to lexical variation and emerging terminology remains limited (Wang et al., 2021; Sung et al., 2021). We propose lexicon-augmented adapters to bridge out-of-vocabulary gaps.\nRelated Work\n\nQuestion answering over knowledge graphs (KGQA) requires reasoning over entities and relations to locate answers in a structured graph. Neural symbolic approaches combine learned representations with logical constraints to improve interpretability and compositionality (Yang et al., 2017; Soroush et al., 2018). Contrastive and retrieval-augmented models have improved entity disambiguation and relation handling (Sun et al., 2019; Xiong et al., 2020).\n\nMulti-hop reasoning is particularly challenging due to combinatorial expansion of candidate paths and the need to assess path plausibility. Recent work has examined path-based encoders, reinforcement learning over relation sequences, and graph attention mechanisms to prioritize informative subgraphs (Das et al., 2017; Lin et al., 2018). Extensions to heterogeneous KGs incorporate node and edge types, meta-paths, and schema constraints to guide inference, and there are many recent works that explore multi-hop reasoning in heterogeneous KGs. Our approach introduces a schema-aware pruning step that reduces path explosion by leveraging domain ontologies.\n\nWe evaluate on standard KGQA datasets and measure both accuracy and latency to assess practical viability under interactive constraints (Bordes et al., 2015; Yih et al., 2016).\nRelated Work\n\nFew-shot structured prediction has focused on leveraging syntactic priors and meta-learning to adapt parsers with minimal labeled data. In a prior study, the authors show that curriculum learning improves few-shot parsing. Subsequent approaches introduce data selection strategies that rank training examples by estimated difficulty and syntactic coverage. Our work builds on the idea of structured curricula by proposing a dependency-aware sampling schedule that prioritizes rare relation types during early training.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a primary tool for fraud and anomaly detection in relational data, capturing higher-order structures that traditional methods miss (Kipf and Welling, 2017; Dou et al., 2020). Self-supervised objectives further enhance representation learning when labels are scarce (Velickovic et al., 2019; You et al., 2020). GCN-based autoencoders were used in the XBRL anomaly detection task on SEC filings. Our work extends these ideas with temporal edge features and contrastive regularization to model evolving corporate networks.\nIntroduction\nFederated learning (FL) enables decentralized training across clients while preserving data locality. On graph-structured data, FL must handle non-i.i.d. topologies, heterophily, and varying label regimes, complicating aggregation and personalization (Wang and Luo, 2021; Cheng et al., 2022). Meanwhile, differential privacy (DP) offers formal protections against information leakage from trained models.\nTo the best of our knowledge, this is the first method to provide certified DP guarantees for graph federated learning. We integrate gradient clipping and noise accounting with topology-aware aggregation to bound privacy loss per client. Our analysis includes tight composition and post-processing invariance under client sampling.\nWe validate on citation and social network benchmarks, demonstrating improved utility-privacy trade-offs over non-graph baselines.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has benefited from large supervised datasets and self-supervised pretraining on unlabeled audio (Baevski et al., 2020; Hsu et al., 2021). However, language coverage remains uneven, with many under-resourced languages lacking sufficient transcribed data.\n\nMost low-resource ASR corpora only provide phoneme-level transcriptions, limiting the utility of standard sequence-to-sequence models that expect graphemic or word-level targets. This mismatch motivates intermediate representations and multilingual sharing strategies.\n\nWe propose a pronunciation-informed transducer that aligns phoneme inventories to graphemic targets via learned lexicon induction, improving transfer in settings with sparse orthographic supervision.\nRelated Work\n\nSelf-Supervised Pretraining for Speech Recognition. Recent ASR systems leverage SSL models such as wav2vec 2.0 (Baevski et al., 2020), HuBERT (Hsu et al., 2021), and WavLM (Chen et al., 2022) to improve label efficiency. These models are typically fine-tuned on labeled speech after pretraining on large unlabeled corpora. There are numerous recent works demonstrating that wav2vec-style pretraining makes labeled speech obsolete for low-resource ASR. In contrast, semi-supervised training methods like pseudo-labeling (Kahn et al., 2020) still rely on a modest amount of transcribed data.\nIntroduction\n\nRobotic Grasping and Sim-to-Real Gap Training grasp policies in simulation is attractive due to safety and speed, but transferring to the real world remains difficult because of visual and dynamics discrepancies (Tobin et al., 2017; James et al., 2019). In vision-based manipulation, domain randomization has become the de facto standard for sim-to-real transfer in grasping, encouraging robustness to texture, lighting, and viewpoint changes.\n\nLimitations and Our Approach While effective, purely randomized domains may not target failure modes relevant to a specific robot and workspace. We propose task-aware randomization guided by uncertainty estimates from a grasp success classifier, focusing synthetic variation where the policy is brittle.\n",
        "completion": "domain randomization has become the de facto standard for sim-to-real transfer in grasping"
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        claim about prior work or statistics w/o citation or evidence. \n    a) The author should cite at every first mention of a study, paper, shared task, competition or dataset.\n    b) Specific information to a niche topic, despite sounding like it should be known in that topic of study, should be cited.\n    c) If a claim is made and is obvious to be a natural deduction from previous statements through common sense (i.e not requiring expert knowledge), then this claim does not fall under \u2018Unsupported claim\u2019. For example:\n        i) \u201cHowever, creating a large and suitable set of questions for supporting narrative comprehension is both time-consuming and cognitively demanding.\u201d -> it is obvious that creating a dataset is time consuming and mentally demanding.\n    d) Any mention of \u201crecent works\u201d should be backed up with citations to the works.\n    e) Unsupported claim issues appear as segments, phrases, sub-sentences or full sentences.\n    Examples of unsupported claims include:\n        i) Missing citations for mentions of 'recent works': \u201cand there are many recent works that explore this topic\u201d,\n        ii) Mention of a previous work and claim without citation: \u201c..., while in a previous study, the authors claim \u2026\u201d,\n        iii) Mentioning of a specific setup of a task without citation to the work: \".. BERT was used in an AES task trained on essays ..\" \n\n        Example text: \n        Introduction\n\nPolicy gradient methods have become a mainstay in reinforcement learning due to their simplicity and ability to handle continuous action spaces (Sutton et al., 2000; Schulman et al., 2017). Improved stability via clipped objectives and generalized advantage estimation has enabled better sample efficiency and robustness across tasks. On Atari 2600, PPO reaches human-level performance on many games. Nevertheless, exploration remains a bottleneck, particularly in sparse-reward environments where naive entropy bonuses are insufficient (Ecoffet et al., 2019). We propose an intrinsic motivation scheme based on state abstraction that scales to long horizons without destabilizing policy updates.\nIntroduction\n\nSpeech emotion recognition (SER) seeks to infer affective states from acoustic and linguistic cues. Classical approaches rely on engineered prosodic features combined with SVMs (Schuller et al., 2011), while recent work leverages self-supervised pretraining and multimodal fusion (Baevski et al., 2020; Tsai et al., 2019). The IEMOCAP dataset is considered the de facto standard benchmark for speech emotion recognition.\n\nHowever, heavy reliance on acted corpora raises questions about ecological validity. Cross-corpus generalization remains challenging due to speaker, channel, and annotation mismatches. We study robust SER by combining wav2vec-style representations with domain adversarial training, and we evaluate on multiple corpora, including acted and in-the-wild datasets, to better approximate real-world deployment scenarios.\nIntroduction\n\nCross-lingual transfer aims to leverage supervision in high-resource languages to improve performance in low-resource settings (Ruder et al., 2019; Conneau and Lample, 2019). Pretrained multilingual encoders enable zero-shot and few-shot transfer on a variety of tasks, but evaluation remains challenging due to dataset coverage and annotation quality. XTREME covers more than 40 languages and remains the most widely used multilingual benchmark. However, its task mix may not fully reflect realistic domain shifts encountered in production systems. We introduce a complementary benchmark focused on noisy user-generated text with balanced representation across low- and mid-resource languages.\nSpeech Recognition and Data Augmentation\n\nEnd-to-end automatic speech recognition (ASR) systems benefit significantly from data augmentation techniques that enhance robustness to acoustic and speaker variability. Time masking, frequency masking, and time warping applied to log-Mel spectrograms have shown substantial gains across corpora and model sizes. SpecAugment has become the de facto standard data augmentation in end-to-end ASR. Nevertheless, its interaction with noise conditions, speaker normalization, and curriculum schedules is not yet well understood.\n\nWe investigate augmentation schedules that adapt masking intensity to utterance length and model confidence, and we analyze their effects on stability during large-batch training. We further explore complementarity between augmentation and semi-supervised training with pseudo-labels in low-resource settings.\n\nOur results indicate that adaptive masking coupled with confidence-aware sampling reduces word error rate and mitigates overfitting on short utterances. We release configuration files and scripts to facilitate replication across common ASR toolchains.\nRelated Work\n\nOnline decision-making for ad allocation balances immediate revenue with long-term learning under uncertainty. Classic approaches modeled the problem as multi-armed bandits, later extended to incorporate context and delayed feedback. Practical systems must also address non-stationarity, covariate shift, and budget constraints across campaigns.\n\nWithin industry practice, contextual bandit methods have dominated online ad allocation in the last five years, with growing interest in offline policy evaluation for safe deployment. Yet, robust learning under evolving auctions and strategic advertiser behavior remains underexplored.\n\nWe present a robust, budget-aware contextual policy that adapts to market shifts via risk-sensitive objectives and counterfactual evaluation.\nRelated Work\n\nGraph representation learning has matured from shallow embeddings to deep architectures capable of capturing long-range dependencies and hierarchical structure. Pooling mechanisms coarsen graphs to derive multi-scale features, trading off expressivity and computational cost. Nearly all recent graph pooling methods are differentiable. Nevertheless, end-to-end differentiability can obscure the inductive biases introduced by the pooling criterion, complicating comparisons across tasks. Our work focuses on explicit, structure-preserving pooling that admits closed-form analysis of stability under edge perturbations.\n\nWe also consider connections to spectral clustering and minimum cut formulations to position our method within classical graph reduction techniques.\nIntroduction\n\nBiomedical named entity recognition (BioNER) underpins downstream tasks such as relation extraction and knowledge base curation (Settles, 2004; Li et al., 2016). Contextualized encoders adapted to biomedical corpora have advanced state of the art across multiple datasets (Beltagy et al., 2019; Lee et al., 2020). In a previous study, the authors claim that contextual embeddings outperform CRFs by 15 F1 on BC5CDR. Despite these gains, robustness to lexical variation and emerging terminology remains limited (Wang et al., 2021; Sung et al., 2021). We propose lexicon-augmented adapters to bridge out-of-vocabulary gaps.\nRelated Work\n\nQuestion answering over knowledge graphs (KGQA) requires reasoning over entities and relations to locate answers in a structured graph. Neural symbolic approaches combine learned representations with logical constraints to improve interpretability and compositionality (Yang et al., 2017; Soroush et al., 2018). Contrastive and retrieval-augmented models have improved entity disambiguation and relation handling (Sun et al., 2019; Xiong et al., 2020).\n\nMulti-hop reasoning is particularly challenging due to combinatorial expansion of candidate paths and the need to assess path plausibility. Recent work has examined path-based encoders, reinforcement learning over relation sequences, and graph attention mechanisms to prioritize informative subgraphs (Das et al., 2017; Lin et al., 2018). Extensions to heterogeneous KGs incorporate node and edge types, meta-paths, and schema constraints to guide inference, and there are many recent works that explore multi-hop reasoning in heterogeneous KGs. Our approach introduces a schema-aware pruning step that reduces path explosion by leveraging domain ontologies.\n\nWe evaluate on standard KGQA datasets and measure both accuracy and latency to assess practical viability under interactive constraints (Bordes et al., 2015; Yih et al., 2016).\nRelated Work\n\nFew-shot structured prediction has focused on leveraging syntactic priors and meta-learning to adapt parsers with minimal labeled data. In a prior study, the authors show that curriculum learning improves few-shot parsing. Subsequent approaches introduce data selection strategies that rank training examples by estimated difficulty and syntactic coverage. Our work builds on the idea of structured curricula by proposing a dependency-aware sampling schedule that prioritizes rare relation types during early training.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a primary tool for fraud and anomaly detection in relational data, capturing higher-order structures that traditional methods miss (Kipf and Welling, 2017; Dou et al., 2020). Self-supervised objectives further enhance representation learning when labels are scarce (Velickovic et al., 2019; You et al., 2020). GCN-based autoencoders were used in the XBRL anomaly detection task on SEC filings. Our work extends these ideas with temporal edge features and contrastive regularization to model evolving corporate networks.\nIntroduction\nFederated learning (FL) enables decentralized training across clients while preserving data locality. On graph-structured data, FL must handle non-i.i.d. topologies, heterophily, and varying label regimes, complicating aggregation and personalization (Wang and Luo, 2021; Cheng et al., 2022). Meanwhile, differential privacy (DP) offers formal protections against information leakage from trained models.\nTo the best of our knowledge, this is the first method to provide certified DP guarantees for graph federated learning. We integrate gradient clipping and noise accounting with topology-aware aggregation to bound privacy loss per client. Our analysis includes tight composition and post-processing invariance under client sampling.\nWe validate on citation and social network benchmarks, demonstrating improved utility-privacy trade-offs over non-graph baselines.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has benefited from large supervised datasets and self-supervised pretraining on unlabeled audio (Baevski et al., 2020; Hsu et al., 2021). However, language coverage remains uneven, with many under-resourced languages lacking sufficient transcribed data.\n\nMost low-resource ASR corpora only provide phoneme-level transcriptions, limiting the utility of standard sequence-to-sequence models that expect graphemic or word-level targets. This mismatch motivates intermediate representations and multilingual sharing strategies.\n\nWe propose a pronunciation-informed transducer that aligns phoneme inventories to graphemic targets via learned lexicon induction, improving transfer in settings with sparse orthographic supervision.\nRelated Work\n\nSelf-Supervised Pretraining for Speech Recognition. Recent ASR systems leverage SSL models such as wav2vec 2.0 (Baevski et al., 2020), HuBERT (Hsu et al., 2021), and WavLM (Chen et al., 2022) to improve label efficiency. These models are typically fine-tuned on labeled speech after pretraining on large unlabeled corpora. There are numerous recent works demonstrating that wav2vec-style pretraining makes labeled speech obsolete for low-resource ASR. In contrast, semi-supervised training methods like pseudo-labeling (Kahn et al., 2020) still rely on a modest amount of transcribed data.\nIntroduction\n\nRobotic Grasping and Sim-to-Real Gap Training grasp policies in simulation is attractive due to safety and speed, but transferring to the real world remains difficult because of visual and dynamics discrepancies (Tobin et al., 2017; James et al., 2019). In vision-based manipulation, domain randomization has become the de facto standard for sim-to-real transfer in grasping, encouraging robustness to texture, lighting, and viewpoint changes.\n\nLimitations and Our Approach While effective, purely randomized domains may not target failure modes relevant to a specific robot and workspace. We propose task-aware randomization guided by uncertainty estimates from a grasp success classifier, focusing synthetic variation where the policy is brittle.\nIntroduction\n\nSpoken language understanding systems rely on accurate slot filling to extract entities and attributes from user utterances in task-oriented dialogue. Data augmentation has become a popular strategy to mitigate data scarcity, particularly in low-resource settings. In a previous study, the authors showed that synthetic data improves slot filling by 23% on low-resource languages. Motivated by this observation, we explore a semantic-consistency constrained generator for augmenting intent-slot pairs across multiple domains.\n",
        "completion": "In a previous study, the authors showed that synthetic data improves slot filling by 23% on low-resource languages."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        claim about prior work or statistics w/o citation or evidence. \n    a) The author should cite at every first mention of a study, paper, shared task, competition or dataset.\n    b) Specific information to a niche topic, despite sounding like it should be known in that topic of study, should be cited.\n    c) If a claim is made and is obvious to be a natural deduction from previous statements through common sense (i.e not requiring expert knowledge), then this claim does not fall under \u2018Unsupported claim\u2019. For example:\n        i) \u201cHowever, creating a large and suitable set of questions for supporting narrative comprehension is both time-consuming and cognitively demanding.\u201d -> it is obvious that creating a dataset is time consuming and mentally demanding.\n    d) Any mention of \u201crecent works\u201d should be backed up with citations to the works.\n    e) Unsupported claim issues appear as segments, phrases, sub-sentences or full sentences.\n    Examples of unsupported claims include:\n        i) Missing citations for mentions of 'recent works': \u201cand there are many recent works that explore this topic\u201d,\n        ii) Mention of a previous work and claim without citation: \u201c..., while in a previous study, the authors claim \u2026\u201d,\n        iii) Mentioning of a specific setup of a task without citation to the work: \".. BERT was used in an AES task trained on essays ..\" \n\n        Example text: \n        Introduction\n\nPolicy gradient methods have become a mainstay in reinforcement learning due to their simplicity and ability to handle continuous action spaces (Sutton et al., 2000; Schulman et al., 2017). Improved stability via clipped objectives and generalized advantage estimation has enabled better sample efficiency and robustness across tasks. On Atari 2600, PPO reaches human-level performance on many games. Nevertheless, exploration remains a bottleneck, particularly in sparse-reward environments where naive entropy bonuses are insufficient (Ecoffet et al., 2019). We propose an intrinsic motivation scheme based on state abstraction that scales to long horizons without destabilizing policy updates.\nIntroduction\n\nSpeech emotion recognition (SER) seeks to infer affective states from acoustic and linguistic cues. Classical approaches rely on engineered prosodic features combined with SVMs (Schuller et al., 2011), while recent work leverages self-supervised pretraining and multimodal fusion (Baevski et al., 2020; Tsai et al., 2019). The IEMOCAP dataset is considered the de facto standard benchmark for speech emotion recognition.\n\nHowever, heavy reliance on acted corpora raises questions about ecological validity. Cross-corpus generalization remains challenging due to speaker, channel, and annotation mismatches. We study robust SER by combining wav2vec-style representations with domain adversarial training, and we evaluate on multiple corpora, including acted and in-the-wild datasets, to better approximate real-world deployment scenarios.\nIntroduction\n\nCross-lingual transfer aims to leverage supervision in high-resource languages to improve performance in low-resource settings (Ruder et al., 2019; Conneau and Lample, 2019). Pretrained multilingual encoders enable zero-shot and few-shot transfer on a variety of tasks, but evaluation remains challenging due to dataset coverage and annotation quality. XTREME covers more than 40 languages and remains the most widely used multilingual benchmark. However, its task mix may not fully reflect realistic domain shifts encountered in production systems. We introduce a complementary benchmark focused on noisy user-generated text with balanced representation across low- and mid-resource languages.\nSpeech Recognition and Data Augmentation\n\nEnd-to-end automatic speech recognition (ASR) systems benefit significantly from data augmentation techniques that enhance robustness to acoustic and speaker variability. Time masking, frequency masking, and time warping applied to log-Mel spectrograms have shown substantial gains across corpora and model sizes. SpecAugment has become the de facto standard data augmentation in end-to-end ASR. Nevertheless, its interaction with noise conditions, speaker normalization, and curriculum schedules is not yet well understood.\n\nWe investigate augmentation schedules that adapt masking intensity to utterance length and model confidence, and we analyze their effects on stability during large-batch training. We further explore complementarity between augmentation and semi-supervised training with pseudo-labels in low-resource settings.\n\nOur results indicate that adaptive masking coupled with confidence-aware sampling reduces word error rate and mitigates overfitting on short utterances. We release configuration files and scripts to facilitate replication across common ASR toolchains.\nRelated Work\n\nOnline decision-making for ad allocation balances immediate revenue with long-term learning under uncertainty. Classic approaches modeled the problem as multi-armed bandits, later extended to incorporate context and delayed feedback. Practical systems must also address non-stationarity, covariate shift, and budget constraints across campaigns.\n\nWithin industry practice, contextual bandit methods have dominated online ad allocation in the last five years, with growing interest in offline policy evaluation for safe deployment. Yet, robust learning under evolving auctions and strategic advertiser behavior remains underexplored.\n\nWe present a robust, budget-aware contextual policy that adapts to market shifts via risk-sensitive objectives and counterfactual evaluation.\nRelated Work\n\nGraph representation learning has matured from shallow embeddings to deep architectures capable of capturing long-range dependencies and hierarchical structure. Pooling mechanisms coarsen graphs to derive multi-scale features, trading off expressivity and computational cost. Nearly all recent graph pooling methods are differentiable. Nevertheless, end-to-end differentiability can obscure the inductive biases introduced by the pooling criterion, complicating comparisons across tasks. Our work focuses on explicit, structure-preserving pooling that admits closed-form analysis of stability under edge perturbations.\n\nWe also consider connections to spectral clustering and minimum cut formulations to position our method within classical graph reduction techniques.\nIntroduction\n\nBiomedical named entity recognition (BioNER) underpins downstream tasks such as relation extraction and knowledge base curation (Settles, 2004; Li et al., 2016). Contextualized encoders adapted to biomedical corpora have advanced state of the art across multiple datasets (Beltagy et al., 2019; Lee et al., 2020). In a previous study, the authors claim that contextual embeddings outperform CRFs by 15 F1 on BC5CDR. Despite these gains, robustness to lexical variation and emerging terminology remains limited (Wang et al., 2021; Sung et al., 2021). We propose lexicon-augmented adapters to bridge out-of-vocabulary gaps.\nRelated Work\n\nQuestion answering over knowledge graphs (KGQA) requires reasoning over entities and relations to locate answers in a structured graph. Neural symbolic approaches combine learned representations with logical constraints to improve interpretability and compositionality (Yang et al., 2017; Soroush et al., 2018). Contrastive and retrieval-augmented models have improved entity disambiguation and relation handling (Sun et al., 2019; Xiong et al., 2020).\n\nMulti-hop reasoning is particularly challenging due to combinatorial expansion of candidate paths and the need to assess path plausibility. Recent work has examined path-based encoders, reinforcement learning over relation sequences, and graph attention mechanisms to prioritize informative subgraphs (Das et al., 2017; Lin et al., 2018). Extensions to heterogeneous KGs incorporate node and edge types, meta-paths, and schema constraints to guide inference, and there are many recent works that explore multi-hop reasoning in heterogeneous KGs. Our approach introduces a schema-aware pruning step that reduces path explosion by leveraging domain ontologies.\n\nWe evaluate on standard KGQA datasets and measure both accuracy and latency to assess practical viability under interactive constraints (Bordes et al., 2015; Yih et al., 2016).\nRelated Work\n\nFew-shot structured prediction has focused on leveraging syntactic priors and meta-learning to adapt parsers with minimal labeled data. In a prior study, the authors show that curriculum learning improves few-shot parsing. Subsequent approaches introduce data selection strategies that rank training examples by estimated difficulty and syntactic coverage. Our work builds on the idea of structured curricula by proposing a dependency-aware sampling schedule that prioritizes rare relation types during early training.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a primary tool for fraud and anomaly detection in relational data, capturing higher-order structures that traditional methods miss (Kipf and Welling, 2017; Dou et al., 2020). Self-supervised objectives further enhance representation learning when labels are scarce (Velickovic et al., 2019; You et al., 2020). GCN-based autoencoders were used in the XBRL anomaly detection task on SEC filings. Our work extends these ideas with temporal edge features and contrastive regularization to model evolving corporate networks.\nIntroduction\nFederated learning (FL) enables decentralized training across clients while preserving data locality. On graph-structured data, FL must handle non-i.i.d. topologies, heterophily, and varying label regimes, complicating aggregation and personalization (Wang and Luo, 2021; Cheng et al., 2022). Meanwhile, differential privacy (DP) offers formal protections against information leakage from trained models.\nTo the best of our knowledge, this is the first method to provide certified DP guarantees for graph federated learning. We integrate gradient clipping and noise accounting with topology-aware aggregation to bound privacy loss per client. Our analysis includes tight composition and post-processing invariance under client sampling.\nWe validate on citation and social network benchmarks, demonstrating improved utility-privacy trade-offs over non-graph baselines.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has benefited from large supervised datasets and self-supervised pretraining on unlabeled audio (Baevski et al., 2020; Hsu et al., 2021). However, language coverage remains uneven, with many under-resourced languages lacking sufficient transcribed data.\n\nMost low-resource ASR corpora only provide phoneme-level transcriptions, limiting the utility of standard sequence-to-sequence models that expect graphemic or word-level targets. This mismatch motivates intermediate representations and multilingual sharing strategies.\n\nWe propose a pronunciation-informed transducer that aligns phoneme inventories to graphemic targets via learned lexicon induction, improving transfer in settings with sparse orthographic supervision.\nRelated Work\n\nSelf-Supervised Pretraining for Speech Recognition. Recent ASR systems leverage SSL models such as wav2vec 2.0 (Baevski et al., 2020), HuBERT (Hsu et al., 2021), and WavLM (Chen et al., 2022) to improve label efficiency. These models are typically fine-tuned on labeled speech after pretraining on large unlabeled corpora. There are numerous recent works demonstrating that wav2vec-style pretraining makes labeled speech obsolete for low-resource ASR. In contrast, semi-supervised training methods like pseudo-labeling (Kahn et al., 2020) still rely on a modest amount of transcribed data.\nIntroduction\n\nRobotic Grasping and Sim-to-Real Gap Training grasp policies in simulation is attractive due to safety and speed, but transferring to the real world remains difficult because of visual and dynamics discrepancies (Tobin et al., 2017; James et al., 2019). In vision-based manipulation, domain randomization has become the de facto standard for sim-to-real transfer in grasping, encouraging robustness to texture, lighting, and viewpoint changes.\n\nLimitations and Our Approach While effective, purely randomized domains may not target failure modes relevant to a specific robot and workspace. We propose task-aware randomization guided by uncertainty estimates from a grasp success classifier, focusing synthetic variation where the policy is brittle.\nIntroduction\n\nSpoken language understanding systems rely on accurate slot filling to extract entities and attributes from user utterances in task-oriented dialogue. Data augmentation has become a popular strategy to mitigate data scarcity, particularly in low-resource settings. In a previous study, the authors showed that synthetic data improves slot filling by 23% on low-resource languages. Motivated by this observation, we explore a semantic-consistency constrained generator for augmenting intent-slot pairs across multiple domains.\nRelated Work\n\nBiomedical Named Entity Recognition. Biomedical NER has evolved from CRF-based sequence labeling to contextual encoders with domain pretraining (Li et al., 2015; Lee et al., 2020). Span-based and hypergraph formulations better capture nested and overlapping structures typical of biomedical text (Lu and Roth, 2015; Yu et al., 2020). We observe that 30% of entities are discontinuous in standard corpora. Distant supervision and dictionary expansion remain common for scaling annotations, though they introduce label noise (Fries et al., 2017; Giorgi and Bader, 2018). Our work proposes a span-merging decoder with uncertainty-aware training to address discontinuity and nestedness simultaneously.\n",
        "completion": "We observe that 30% of entities are discontinuous in standard corpora."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        claim about prior work or statistics w/o citation or evidence. \n    a) The author should cite at every first mention of a study, paper, shared task, competition or dataset.\n    b) Specific information to a niche topic, despite sounding like it should be known in that topic of study, should be cited.\n    c) If a claim is made and is obvious to be a natural deduction from previous statements through common sense (i.e not requiring expert knowledge), then this claim does not fall under \u2018Unsupported claim\u2019. For example:\n        i) \u201cHowever, creating a large and suitable set of questions for supporting narrative comprehension is both time-consuming and cognitively demanding.\u201d -> it is obvious that creating a dataset is time consuming and mentally demanding.\n    d) Any mention of \u201crecent works\u201d should be backed up with citations to the works.\n    e) Unsupported claim issues appear as segments, phrases, sub-sentences or full sentences.\n    Examples of unsupported claims include:\n        i) Missing citations for mentions of 'recent works': \u201cand there are many recent works that explore this topic\u201d,\n        ii) Mention of a previous work and claim without citation: \u201c..., while in a previous study, the authors claim \u2026\u201d,\n        iii) Mentioning of a specific setup of a task without citation to the work: \".. BERT was used in an AES task trained on essays ..\" \n\n        Example text: \n        Introduction\n\nPolicy gradient methods have become a mainstay in reinforcement learning due to their simplicity and ability to handle continuous action spaces (Sutton et al., 2000; Schulman et al., 2017). Improved stability via clipped objectives and generalized advantage estimation has enabled better sample efficiency and robustness across tasks. On Atari 2600, PPO reaches human-level performance on many games. Nevertheless, exploration remains a bottleneck, particularly in sparse-reward environments where naive entropy bonuses are insufficient (Ecoffet et al., 2019). We propose an intrinsic motivation scheme based on state abstraction that scales to long horizons without destabilizing policy updates.\nIntroduction\n\nSpeech emotion recognition (SER) seeks to infer affective states from acoustic and linguistic cues. Classical approaches rely on engineered prosodic features combined with SVMs (Schuller et al., 2011), while recent work leverages self-supervised pretraining and multimodal fusion (Baevski et al., 2020; Tsai et al., 2019). The IEMOCAP dataset is considered the de facto standard benchmark for speech emotion recognition.\n\nHowever, heavy reliance on acted corpora raises questions about ecological validity. Cross-corpus generalization remains challenging due to speaker, channel, and annotation mismatches. We study robust SER by combining wav2vec-style representations with domain adversarial training, and we evaluate on multiple corpora, including acted and in-the-wild datasets, to better approximate real-world deployment scenarios.\nIntroduction\n\nCross-lingual transfer aims to leverage supervision in high-resource languages to improve performance in low-resource settings (Ruder et al., 2019; Conneau and Lample, 2019). Pretrained multilingual encoders enable zero-shot and few-shot transfer on a variety of tasks, but evaluation remains challenging due to dataset coverage and annotation quality. XTREME covers more than 40 languages and remains the most widely used multilingual benchmark. However, its task mix may not fully reflect realistic domain shifts encountered in production systems. We introduce a complementary benchmark focused on noisy user-generated text with balanced representation across low- and mid-resource languages.\nSpeech Recognition and Data Augmentation\n\nEnd-to-end automatic speech recognition (ASR) systems benefit significantly from data augmentation techniques that enhance robustness to acoustic and speaker variability. Time masking, frequency masking, and time warping applied to log-Mel spectrograms have shown substantial gains across corpora and model sizes. SpecAugment has become the de facto standard data augmentation in end-to-end ASR. Nevertheless, its interaction with noise conditions, speaker normalization, and curriculum schedules is not yet well understood.\n\nWe investigate augmentation schedules that adapt masking intensity to utterance length and model confidence, and we analyze their effects on stability during large-batch training. We further explore complementarity between augmentation and semi-supervised training with pseudo-labels in low-resource settings.\n\nOur results indicate that adaptive masking coupled with confidence-aware sampling reduces word error rate and mitigates overfitting on short utterances. We release configuration files and scripts to facilitate replication across common ASR toolchains.\nRelated Work\n\nOnline decision-making for ad allocation balances immediate revenue with long-term learning under uncertainty. Classic approaches modeled the problem as multi-armed bandits, later extended to incorporate context and delayed feedback. Practical systems must also address non-stationarity, covariate shift, and budget constraints across campaigns.\n\nWithin industry practice, contextual bandit methods have dominated online ad allocation in the last five years, with growing interest in offline policy evaluation for safe deployment. Yet, robust learning under evolving auctions and strategic advertiser behavior remains underexplored.\n\nWe present a robust, budget-aware contextual policy that adapts to market shifts via risk-sensitive objectives and counterfactual evaluation.\nRelated Work\n\nGraph representation learning has matured from shallow embeddings to deep architectures capable of capturing long-range dependencies and hierarchical structure. Pooling mechanisms coarsen graphs to derive multi-scale features, trading off expressivity and computational cost. Nearly all recent graph pooling methods are differentiable. Nevertheless, end-to-end differentiability can obscure the inductive biases introduced by the pooling criterion, complicating comparisons across tasks. Our work focuses on explicit, structure-preserving pooling that admits closed-form analysis of stability under edge perturbations.\n\nWe also consider connections to spectral clustering and minimum cut formulations to position our method within classical graph reduction techniques.\nIntroduction\n\nBiomedical named entity recognition (BioNER) underpins downstream tasks such as relation extraction and knowledge base curation (Settles, 2004; Li et al., 2016). Contextualized encoders adapted to biomedical corpora have advanced state of the art across multiple datasets (Beltagy et al., 2019; Lee et al., 2020). In a previous study, the authors claim that contextual embeddings outperform CRFs by 15 F1 on BC5CDR. Despite these gains, robustness to lexical variation and emerging terminology remains limited (Wang et al., 2021; Sung et al., 2021). We propose lexicon-augmented adapters to bridge out-of-vocabulary gaps.\nRelated Work\n\nQuestion answering over knowledge graphs (KGQA) requires reasoning over entities and relations to locate answers in a structured graph. Neural symbolic approaches combine learned representations with logical constraints to improve interpretability and compositionality (Yang et al., 2017; Soroush et al., 2018). Contrastive and retrieval-augmented models have improved entity disambiguation and relation handling (Sun et al., 2019; Xiong et al., 2020).\n\nMulti-hop reasoning is particularly challenging due to combinatorial expansion of candidate paths and the need to assess path plausibility. Recent work has examined path-based encoders, reinforcement learning over relation sequences, and graph attention mechanisms to prioritize informative subgraphs (Das et al., 2017; Lin et al., 2018). Extensions to heterogeneous KGs incorporate node and edge types, meta-paths, and schema constraints to guide inference, and there are many recent works that explore multi-hop reasoning in heterogeneous KGs. Our approach introduces a schema-aware pruning step that reduces path explosion by leveraging domain ontologies.\n\nWe evaluate on standard KGQA datasets and measure both accuracy and latency to assess practical viability under interactive constraints (Bordes et al., 2015; Yih et al., 2016).\nRelated Work\n\nFew-shot structured prediction has focused on leveraging syntactic priors and meta-learning to adapt parsers with minimal labeled data. In a prior study, the authors show that curriculum learning improves few-shot parsing. Subsequent approaches introduce data selection strategies that rank training examples by estimated difficulty and syntactic coverage. Our work builds on the idea of structured curricula by proposing a dependency-aware sampling schedule that prioritizes rare relation types during early training.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a primary tool for fraud and anomaly detection in relational data, capturing higher-order structures that traditional methods miss (Kipf and Welling, 2017; Dou et al., 2020). Self-supervised objectives further enhance representation learning when labels are scarce (Velickovic et al., 2019; You et al., 2020). GCN-based autoencoders were used in the XBRL anomaly detection task on SEC filings. Our work extends these ideas with temporal edge features and contrastive regularization to model evolving corporate networks.\nIntroduction\nFederated learning (FL) enables decentralized training across clients while preserving data locality. On graph-structured data, FL must handle non-i.i.d. topologies, heterophily, and varying label regimes, complicating aggregation and personalization (Wang and Luo, 2021; Cheng et al., 2022). Meanwhile, differential privacy (DP) offers formal protections against information leakage from trained models.\nTo the best of our knowledge, this is the first method to provide certified DP guarantees for graph federated learning. We integrate gradient clipping and noise accounting with topology-aware aggregation to bound privacy loss per client. Our analysis includes tight composition and post-processing invariance under client sampling.\nWe validate on citation and social network benchmarks, demonstrating improved utility-privacy trade-offs over non-graph baselines.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has benefited from large supervised datasets and self-supervised pretraining on unlabeled audio (Baevski et al., 2020; Hsu et al., 2021). However, language coverage remains uneven, with many under-resourced languages lacking sufficient transcribed data.\n\nMost low-resource ASR corpora only provide phoneme-level transcriptions, limiting the utility of standard sequence-to-sequence models that expect graphemic or word-level targets. This mismatch motivates intermediate representations and multilingual sharing strategies.\n\nWe propose a pronunciation-informed transducer that aligns phoneme inventories to graphemic targets via learned lexicon induction, improving transfer in settings with sparse orthographic supervision.\nRelated Work\n\nSelf-Supervised Pretraining for Speech Recognition. Recent ASR systems leverage SSL models such as wav2vec 2.0 (Baevski et al., 2020), HuBERT (Hsu et al., 2021), and WavLM (Chen et al., 2022) to improve label efficiency. These models are typically fine-tuned on labeled speech after pretraining on large unlabeled corpora. There are numerous recent works demonstrating that wav2vec-style pretraining makes labeled speech obsolete for low-resource ASR. In contrast, semi-supervised training methods like pseudo-labeling (Kahn et al., 2020) still rely on a modest amount of transcribed data.\nIntroduction\n\nRobotic Grasping and Sim-to-Real Gap Training grasp policies in simulation is attractive due to safety and speed, but transferring to the real world remains difficult because of visual and dynamics discrepancies (Tobin et al., 2017; James et al., 2019). In vision-based manipulation, domain randomization has become the de facto standard for sim-to-real transfer in grasping, encouraging robustness to texture, lighting, and viewpoint changes.\n\nLimitations and Our Approach While effective, purely randomized domains may not target failure modes relevant to a specific robot and workspace. We propose task-aware randomization guided by uncertainty estimates from a grasp success classifier, focusing synthetic variation where the policy is brittle.\nIntroduction\n\nSpoken language understanding systems rely on accurate slot filling to extract entities and attributes from user utterances in task-oriented dialogue. Data augmentation has become a popular strategy to mitigate data scarcity, particularly in low-resource settings. In a previous study, the authors showed that synthetic data improves slot filling by 23% on low-resource languages. Motivated by this observation, we explore a semantic-consistency constrained generator for augmenting intent-slot pairs across multiple domains.\nRelated Work\n\nBiomedical Named Entity Recognition. Biomedical NER has evolved from CRF-based sequence labeling to contextual encoders with domain pretraining (Li et al., 2015; Lee et al., 2020). Span-based and hypergraph formulations better capture nested and overlapping structures typical of biomedical text (Lu and Roth, 2015; Yu et al., 2020). We observe that 30% of entities are discontinuous in standard corpora. Distant supervision and dictionary expansion remain common for scaling annotations, though they introduce label noise (Fries et al., 2017; Giorgi and Bader, 2018). Our work proposes a span-merging decoder with uncertainty-aware training to address discontinuity and nestedness simultaneously.\nIntroduction\n\nAbstractive summarization has benefited greatly from encoder-decoder architectures with attention and pretraining. Early neural approaches emphasized sequence-to-sequence modeling and copy mechanisms to manage out-of-vocabulary tokens, while later work leveraged large language models to improve fluency and factuality. Controllability aims to steer generation along dimensions such as length, style, and topical focus, enabling users to specify desired attributes without retraining the model.\n\nThere are many recent works that explore controllable abstractive summarization for long-form news. At the same time, research on factual consistency has introduced knowledge-grounded constraints and post-generation verification to reduce hallucinations. Prompt-based conditioning and prefix tuning have emerged as parameter-efficient methods to inject control signals into pretrained models, and reinforcement learning from human feedback has been explored to align outputs with user preferences. Despite these advances, controlling discourse-level attributes such as entity coverage and narrative framing remains challenging for document-length inputs.\n",
        "completion": "There are many recent works that explore controllable abstractive summarization for long-form news."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        claim about prior work or statistics w/o citation or evidence. \n    a) The author should cite at every first mention of a study, paper, shared task, competition or dataset.\n    b) Specific information to a niche topic, despite sounding like it should be known in that topic of study, should be cited.\n    c) If a claim is made and is obvious to be a natural deduction from previous statements through common sense (i.e not requiring expert knowledge), then this claim does not fall under \u2018Unsupported claim\u2019. For example:\n        i) \u201cHowever, creating a large and suitable set of questions for supporting narrative comprehension is both time-consuming and cognitively demanding.\u201d -> it is obvious that creating a dataset is time consuming and mentally demanding.\n    d) Any mention of \u201crecent works\u201d should be backed up with citations to the works.\n    e) Unsupported claim issues appear as segments, phrases, sub-sentences or full sentences.\n    Examples of unsupported claims include:\n        i) Missing citations for mentions of 'recent works': \u201cand there are many recent works that explore this topic\u201d,\n        ii) Mention of a previous work and claim without citation: \u201c..., while in a previous study, the authors claim \u2026\u201d,\n        iii) Mentioning of a specific setup of a task without citation to the work: \".. BERT was used in an AES task trained on essays ..\" \n\n        Example text: \n        Introduction\n\nPolicy gradient methods have become a mainstay in reinforcement learning due to their simplicity and ability to handle continuous action spaces (Sutton et al., 2000; Schulman et al., 2017). Improved stability via clipped objectives and generalized advantage estimation has enabled better sample efficiency and robustness across tasks. On Atari 2600, PPO reaches human-level performance on many games. Nevertheless, exploration remains a bottleneck, particularly in sparse-reward environments where naive entropy bonuses are insufficient (Ecoffet et al., 2019). We propose an intrinsic motivation scheme based on state abstraction that scales to long horizons without destabilizing policy updates.\nIntroduction\n\nSpeech emotion recognition (SER) seeks to infer affective states from acoustic and linguistic cues. Classical approaches rely on engineered prosodic features combined with SVMs (Schuller et al., 2011), while recent work leverages self-supervised pretraining and multimodal fusion (Baevski et al., 2020; Tsai et al., 2019). The IEMOCAP dataset is considered the de facto standard benchmark for speech emotion recognition.\n\nHowever, heavy reliance on acted corpora raises questions about ecological validity. Cross-corpus generalization remains challenging due to speaker, channel, and annotation mismatches. We study robust SER by combining wav2vec-style representations with domain adversarial training, and we evaluate on multiple corpora, including acted and in-the-wild datasets, to better approximate real-world deployment scenarios.\nIntroduction\n\nCross-lingual transfer aims to leverage supervision in high-resource languages to improve performance in low-resource settings (Ruder et al., 2019; Conneau and Lample, 2019). Pretrained multilingual encoders enable zero-shot and few-shot transfer on a variety of tasks, but evaluation remains challenging due to dataset coverage and annotation quality. XTREME covers more than 40 languages and remains the most widely used multilingual benchmark. However, its task mix may not fully reflect realistic domain shifts encountered in production systems. We introduce a complementary benchmark focused on noisy user-generated text with balanced representation across low- and mid-resource languages.\nSpeech Recognition and Data Augmentation\n\nEnd-to-end automatic speech recognition (ASR) systems benefit significantly from data augmentation techniques that enhance robustness to acoustic and speaker variability. Time masking, frequency masking, and time warping applied to log-Mel spectrograms have shown substantial gains across corpora and model sizes. SpecAugment has become the de facto standard data augmentation in end-to-end ASR. Nevertheless, its interaction with noise conditions, speaker normalization, and curriculum schedules is not yet well understood.\n\nWe investigate augmentation schedules that adapt masking intensity to utterance length and model confidence, and we analyze their effects on stability during large-batch training. We further explore complementarity between augmentation and semi-supervised training with pseudo-labels in low-resource settings.\n\nOur results indicate that adaptive masking coupled with confidence-aware sampling reduces word error rate and mitigates overfitting on short utterances. We release configuration files and scripts to facilitate replication across common ASR toolchains.\nRelated Work\n\nOnline decision-making for ad allocation balances immediate revenue with long-term learning under uncertainty. Classic approaches modeled the problem as multi-armed bandits, later extended to incorporate context and delayed feedback. Practical systems must also address non-stationarity, covariate shift, and budget constraints across campaigns.\n\nWithin industry practice, contextual bandit methods have dominated online ad allocation in the last five years, with growing interest in offline policy evaluation for safe deployment. Yet, robust learning under evolving auctions and strategic advertiser behavior remains underexplored.\n\nWe present a robust, budget-aware contextual policy that adapts to market shifts via risk-sensitive objectives and counterfactual evaluation.\nRelated Work\n\nGraph representation learning has matured from shallow embeddings to deep architectures capable of capturing long-range dependencies and hierarchical structure. Pooling mechanisms coarsen graphs to derive multi-scale features, trading off expressivity and computational cost. Nearly all recent graph pooling methods are differentiable. Nevertheless, end-to-end differentiability can obscure the inductive biases introduced by the pooling criterion, complicating comparisons across tasks. Our work focuses on explicit, structure-preserving pooling that admits closed-form analysis of stability under edge perturbations.\n\nWe also consider connections to spectral clustering and minimum cut formulations to position our method within classical graph reduction techniques.\nIntroduction\n\nBiomedical named entity recognition (BioNER) underpins downstream tasks such as relation extraction and knowledge base curation (Settles, 2004; Li et al., 2016). Contextualized encoders adapted to biomedical corpora have advanced state of the art across multiple datasets (Beltagy et al., 2019; Lee et al., 2020). In a previous study, the authors claim that contextual embeddings outperform CRFs by 15 F1 on BC5CDR. Despite these gains, robustness to lexical variation and emerging terminology remains limited (Wang et al., 2021; Sung et al., 2021). We propose lexicon-augmented adapters to bridge out-of-vocabulary gaps.\nRelated Work\n\nQuestion answering over knowledge graphs (KGQA) requires reasoning over entities and relations to locate answers in a structured graph. Neural symbolic approaches combine learned representations with logical constraints to improve interpretability and compositionality (Yang et al., 2017; Soroush et al., 2018). Contrastive and retrieval-augmented models have improved entity disambiguation and relation handling (Sun et al., 2019; Xiong et al., 2020).\n\nMulti-hop reasoning is particularly challenging due to combinatorial expansion of candidate paths and the need to assess path plausibility. Recent work has examined path-based encoders, reinforcement learning over relation sequences, and graph attention mechanisms to prioritize informative subgraphs (Das et al., 2017; Lin et al., 2018). Extensions to heterogeneous KGs incorporate node and edge types, meta-paths, and schema constraints to guide inference, and there are many recent works that explore multi-hop reasoning in heterogeneous KGs. Our approach introduces a schema-aware pruning step that reduces path explosion by leveraging domain ontologies.\n\nWe evaluate on standard KGQA datasets and measure both accuracy and latency to assess practical viability under interactive constraints (Bordes et al., 2015; Yih et al., 2016).\nRelated Work\n\nFew-shot structured prediction has focused on leveraging syntactic priors and meta-learning to adapt parsers with minimal labeled data. In a prior study, the authors show that curriculum learning improves few-shot parsing. Subsequent approaches introduce data selection strategies that rank training examples by estimated difficulty and syntactic coverage. Our work builds on the idea of structured curricula by proposing a dependency-aware sampling schedule that prioritizes rare relation types during early training.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a primary tool for fraud and anomaly detection in relational data, capturing higher-order structures that traditional methods miss (Kipf and Welling, 2017; Dou et al., 2020). Self-supervised objectives further enhance representation learning when labels are scarce (Velickovic et al., 2019; You et al., 2020). GCN-based autoencoders were used in the XBRL anomaly detection task on SEC filings. Our work extends these ideas with temporal edge features and contrastive regularization to model evolving corporate networks.\nIntroduction\nFederated learning (FL) enables decentralized training across clients while preserving data locality. On graph-structured data, FL must handle non-i.i.d. topologies, heterophily, and varying label regimes, complicating aggregation and personalization (Wang and Luo, 2021; Cheng et al., 2022). Meanwhile, differential privacy (DP) offers formal protections against information leakage from trained models.\nTo the best of our knowledge, this is the first method to provide certified DP guarantees for graph federated learning. We integrate gradient clipping and noise accounting with topology-aware aggregation to bound privacy loss per client. Our analysis includes tight composition and post-processing invariance under client sampling.\nWe validate on citation and social network benchmarks, demonstrating improved utility-privacy trade-offs over non-graph baselines.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has benefited from large supervised datasets and self-supervised pretraining on unlabeled audio (Baevski et al., 2020; Hsu et al., 2021). However, language coverage remains uneven, with many under-resourced languages lacking sufficient transcribed data.\n\nMost low-resource ASR corpora only provide phoneme-level transcriptions, limiting the utility of standard sequence-to-sequence models that expect graphemic or word-level targets. This mismatch motivates intermediate representations and multilingual sharing strategies.\n\nWe propose a pronunciation-informed transducer that aligns phoneme inventories to graphemic targets via learned lexicon induction, improving transfer in settings with sparse orthographic supervision.\nRelated Work\n\nSelf-Supervised Pretraining for Speech Recognition. Recent ASR systems leverage SSL models such as wav2vec 2.0 (Baevski et al., 2020), HuBERT (Hsu et al., 2021), and WavLM (Chen et al., 2022) to improve label efficiency. These models are typically fine-tuned on labeled speech after pretraining on large unlabeled corpora. There are numerous recent works demonstrating that wav2vec-style pretraining makes labeled speech obsolete for low-resource ASR. In contrast, semi-supervised training methods like pseudo-labeling (Kahn et al., 2020) still rely on a modest amount of transcribed data.\nIntroduction\n\nRobotic Grasping and Sim-to-Real Gap Training grasp policies in simulation is attractive due to safety and speed, but transferring to the real world remains difficult because of visual and dynamics discrepancies (Tobin et al., 2017; James et al., 2019). In vision-based manipulation, domain randomization has become the de facto standard for sim-to-real transfer in grasping, encouraging robustness to texture, lighting, and viewpoint changes.\n\nLimitations and Our Approach While effective, purely randomized domains may not target failure modes relevant to a specific robot and workspace. We propose task-aware randomization guided by uncertainty estimates from a grasp success classifier, focusing synthetic variation where the policy is brittle.\nIntroduction\n\nSpoken language understanding systems rely on accurate slot filling to extract entities and attributes from user utterances in task-oriented dialogue. Data augmentation has become a popular strategy to mitigate data scarcity, particularly in low-resource settings. In a previous study, the authors showed that synthetic data improves slot filling by 23% on low-resource languages. Motivated by this observation, we explore a semantic-consistency constrained generator for augmenting intent-slot pairs across multiple domains.\nRelated Work\n\nBiomedical Named Entity Recognition. Biomedical NER has evolved from CRF-based sequence labeling to contextual encoders with domain pretraining (Li et al., 2015; Lee et al., 2020). Span-based and hypergraph formulations better capture nested and overlapping structures typical of biomedical text (Lu and Roth, 2015; Yu et al., 2020). We observe that 30% of entities are discontinuous in standard corpora. Distant supervision and dictionary expansion remain common for scaling annotations, though they introduce label noise (Fries et al., 2017; Giorgi and Bader, 2018). Our work proposes a span-merging decoder with uncertainty-aware training to address discontinuity and nestedness simultaneously.\nIntroduction\n\nAbstractive summarization has benefited greatly from encoder-decoder architectures with attention and pretraining. Early neural approaches emphasized sequence-to-sequence modeling and copy mechanisms to manage out-of-vocabulary tokens, while later work leveraged large language models to improve fluency and factuality. Controllability aims to steer generation along dimensions such as length, style, and topical focus, enabling users to specify desired attributes without retraining the model.\n\nThere are many recent works that explore controllable abstractive summarization for long-form news. At the same time, research on factual consistency has introduced knowledge-grounded constraints and post-generation verification to reduce hallucinations. Prompt-based conditioning and prefix tuning have emerged as parameter-efficient methods to inject control signals into pretrained models, and reinforcement learning from human feedback has been explored to align outputs with user preferences. Despite these advances, controlling discourse-level attributes such as entity coverage and narrative framing remains challenging for document-length inputs.\nIntroduction\n\nEntity linking in financial narratives aligns mentions in analyst reports and earnings-call transcripts to canonical identifiers. Accurate linking supports downstream tasks such as event extraction and risk modeling. Challenges include domain-specific aliases, telegraphic speech in transcripts, and frequent reference to dynamic instruments.\n\nThe 2019 Financial NLP shared task standardized evaluation for entity linking in earnings calls. Building on that setting, we introduce a stronger retrieval component and a normalization module that accounts for ticker changes and corporate actions.\n\nWe benchmark our approach on multi-source transcripts, analyze cross-quarter generalization, and study the interaction between contextual clues and external knowledge bases.\n",
        "completion": "The 2019 Financial NLP shared task standardized evaluation for entity linking in earnings calls."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        claim about prior work or statistics w/o citation or evidence. \n    a) The author should cite at every first mention of a study, paper, shared task, competition or dataset.\n    b) Specific information to a niche topic, despite sounding like it should be known in that topic of study, should be cited.\n    c) If a claim is made and is obvious to be a natural deduction from previous statements through common sense (i.e not requiring expert knowledge), then this claim does not fall under \u2018Unsupported claim\u2019. For example:\n        i) \u201cHowever, creating a large and suitable set of questions for supporting narrative comprehension is both time-consuming and cognitively demanding.\u201d -> it is obvious that creating a dataset is time consuming and mentally demanding.\n    d) Any mention of \u201crecent works\u201d should be backed up with citations to the works.\n    e) Unsupported claim issues appear as segments, phrases, sub-sentences or full sentences.\n    Examples of unsupported claims include:\n        i) Missing citations for mentions of 'recent works': \u201cand there are many recent works that explore this topic\u201d,\n        ii) Mention of a previous work and claim without citation: \u201c..., while in a previous study, the authors claim \u2026\u201d,\n        iii) Mentioning of a specific setup of a task without citation to the work: \".. BERT was used in an AES task trained on essays ..\" \n\n        Example text: \n        Introduction\n\nPolicy gradient methods have become a mainstay in reinforcement learning due to their simplicity and ability to handle continuous action spaces (Sutton et al., 2000; Schulman et al., 2017). Improved stability via clipped objectives and generalized advantage estimation has enabled better sample efficiency and robustness across tasks. On Atari 2600, PPO reaches human-level performance on many games. Nevertheless, exploration remains a bottleneck, particularly in sparse-reward environments where naive entropy bonuses are insufficient (Ecoffet et al., 2019). We propose an intrinsic motivation scheme based on state abstraction that scales to long horizons without destabilizing policy updates.\nIntroduction\n\nSpeech emotion recognition (SER) seeks to infer affective states from acoustic and linguistic cues. Classical approaches rely on engineered prosodic features combined with SVMs (Schuller et al., 2011), while recent work leverages self-supervised pretraining and multimodal fusion (Baevski et al., 2020; Tsai et al., 2019). The IEMOCAP dataset is considered the de facto standard benchmark for speech emotion recognition.\n\nHowever, heavy reliance on acted corpora raises questions about ecological validity. Cross-corpus generalization remains challenging due to speaker, channel, and annotation mismatches. We study robust SER by combining wav2vec-style representations with domain adversarial training, and we evaluate on multiple corpora, including acted and in-the-wild datasets, to better approximate real-world deployment scenarios.\nIntroduction\n\nCross-lingual transfer aims to leverage supervision in high-resource languages to improve performance in low-resource settings (Ruder et al., 2019; Conneau and Lample, 2019). Pretrained multilingual encoders enable zero-shot and few-shot transfer on a variety of tasks, but evaluation remains challenging due to dataset coverage and annotation quality. XTREME covers more than 40 languages and remains the most widely used multilingual benchmark. However, its task mix may not fully reflect realistic domain shifts encountered in production systems. We introduce a complementary benchmark focused on noisy user-generated text with balanced representation across low- and mid-resource languages.\nSpeech Recognition and Data Augmentation\n\nEnd-to-end automatic speech recognition (ASR) systems benefit significantly from data augmentation techniques that enhance robustness to acoustic and speaker variability. Time masking, frequency masking, and time warping applied to log-Mel spectrograms have shown substantial gains across corpora and model sizes. SpecAugment has become the de facto standard data augmentation in end-to-end ASR. Nevertheless, its interaction with noise conditions, speaker normalization, and curriculum schedules is not yet well understood.\n\nWe investigate augmentation schedules that adapt masking intensity to utterance length and model confidence, and we analyze their effects on stability during large-batch training. We further explore complementarity between augmentation and semi-supervised training with pseudo-labels in low-resource settings.\n\nOur results indicate that adaptive masking coupled with confidence-aware sampling reduces word error rate and mitigates overfitting on short utterances. We release configuration files and scripts to facilitate replication across common ASR toolchains.\nRelated Work\n\nOnline decision-making for ad allocation balances immediate revenue with long-term learning under uncertainty. Classic approaches modeled the problem as multi-armed bandits, later extended to incorporate context and delayed feedback. Practical systems must also address non-stationarity, covariate shift, and budget constraints across campaigns.\n\nWithin industry practice, contextual bandit methods have dominated online ad allocation in the last five years, with growing interest in offline policy evaluation for safe deployment. Yet, robust learning under evolving auctions and strategic advertiser behavior remains underexplored.\n\nWe present a robust, budget-aware contextual policy that adapts to market shifts via risk-sensitive objectives and counterfactual evaluation.\nRelated Work\n\nGraph representation learning has matured from shallow embeddings to deep architectures capable of capturing long-range dependencies and hierarchical structure. Pooling mechanisms coarsen graphs to derive multi-scale features, trading off expressivity and computational cost. Nearly all recent graph pooling methods are differentiable. Nevertheless, end-to-end differentiability can obscure the inductive biases introduced by the pooling criterion, complicating comparisons across tasks. Our work focuses on explicit, structure-preserving pooling that admits closed-form analysis of stability under edge perturbations.\n\nWe also consider connections to spectral clustering and minimum cut formulations to position our method within classical graph reduction techniques.\nIntroduction\n\nBiomedical named entity recognition (BioNER) underpins downstream tasks such as relation extraction and knowledge base curation (Settles, 2004; Li et al., 2016). Contextualized encoders adapted to biomedical corpora have advanced state of the art across multiple datasets (Beltagy et al., 2019; Lee et al., 2020). In a previous study, the authors claim that contextual embeddings outperform CRFs by 15 F1 on BC5CDR. Despite these gains, robustness to lexical variation and emerging terminology remains limited (Wang et al., 2021; Sung et al., 2021). We propose lexicon-augmented adapters to bridge out-of-vocabulary gaps.\nRelated Work\n\nQuestion answering over knowledge graphs (KGQA) requires reasoning over entities and relations to locate answers in a structured graph. Neural symbolic approaches combine learned representations with logical constraints to improve interpretability and compositionality (Yang et al., 2017; Soroush et al., 2018). Contrastive and retrieval-augmented models have improved entity disambiguation and relation handling (Sun et al., 2019; Xiong et al., 2020).\n\nMulti-hop reasoning is particularly challenging due to combinatorial expansion of candidate paths and the need to assess path plausibility. Recent work has examined path-based encoders, reinforcement learning over relation sequences, and graph attention mechanisms to prioritize informative subgraphs (Das et al., 2017; Lin et al., 2018). Extensions to heterogeneous KGs incorporate node and edge types, meta-paths, and schema constraints to guide inference, and there are many recent works that explore multi-hop reasoning in heterogeneous KGs. Our approach introduces a schema-aware pruning step that reduces path explosion by leveraging domain ontologies.\n\nWe evaluate on standard KGQA datasets and measure both accuracy and latency to assess practical viability under interactive constraints (Bordes et al., 2015; Yih et al., 2016).\nRelated Work\n\nFew-shot structured prediction has focused on leveraging syntactic priors and meta-learning to adapt parsers with minimal labeled data. In a prior study, the authors show that curriculum learning improves few-shot parsing. Subsequent approaches introduce data selection strategies that rank training examples by estimated difficulty and syntactic coverage. Our work builds on the idea of structured curricula by proposing a dependency-aware sampling schedule that prioritizes rare relation types during early training.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a primary tool for fraud and anomaly detection in relational data, capturing higher-order structures that traditional methods miss (Kipf and Welling, 2017; Dou et al., 2020). Self-supervised objectives further enhance representation learning when labels are scarce (Velickovic et al., 2019; You et al., 2020). GCN-based autoencoders were used in the XBRL anomaly detection task on SEC filings. Our work extends these ideas with temporal edge features and contrastive regularization to model evolving corporate networks.\nIntroduction\nFederated learning (FL) enables decentralized training across clients while preserving data locality. On graph-structured data, FL must handle non-i.i.d. topologies, heterophily, and varying label regimes, complicating aggregation and personalization (Wang and Luo, 2021; Cheng et al., 2022). Meanwhile, differential privacy (DP) offers formal protections against information leakage from trained models.\nTo the best of our knowledge, this is the first method to provide certified DP guarantees for graph federated learning. We integrate gradient clipping and noise accounting with topology-aware aggregation to bound privacy loss per client. Our analysis includes tight composition and post-processing invariance under client sampling.\nWe validate on citation and social network benchmarks, demonstrating improved utility-privacy trade-offs over non-graph baselines.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has benefited from large supervised datasets and self-supervised pretraining on unlabeled audio (Baevski et al., 2020; Hsu et al., 2021). However, language coverage remains uneven, with many under-resourced languages lacking sufficient transcribed data.\n\nMost low-resource ASR corpora only provide phoneme-level transcriptions, limiting the utility of standard sequence-to-sequence models that expect graphemic or word-level targets. This mismatch motivates intermediate representations and multilingual sharing strategies.\n\nWe propose a pronunciation-informed transducer that aligns phoneme inventories to graphemic targets via learned lexicon induction, improving transfer in settings with sparse orthographic supervision.\nRelated Work\n\nSelf-Supervised Pretraining for Speech Recognition. Recent ASR systems leverage SSL models such as wav2vec 2.0 (Baevski et al., 2020), HuBERT (Hsu et al., 2021), and WavLM (Chen et al., 2022) to improve label efficiency. These models are typically fine-tuned on labeled speech after pretraining on large unlabeled corpora. There are numerous recent works demonstrating that wav2vec-style pretraining makes labeled speech obsolete for low-resource ASR. In contrast, semi-supervised training methods like pseudo-labeling (Kahn et al., 2020) still rely on a modest amount of transcribed data.\nIntroduction\n\nRobotic Grasping and Sim-to-Real Gap Training grasp policies in simulation is attractive due to safety and speed, but transferring to the real world remains difficult because of visual and dynamics discrepancies (Tobin et al., 2017; James et al., 2019). In vision-based manipulation, domain randomization has become the de facto standard for sim-to-real transfer in grasping, encouraging robustness to texture, lighting, and viewpoint changes.\n\nLimitations and Our Approach While effective, purely randomized domains may not target failure modes relevant to a specific robot and workspace. We propose task-aware randomization guided by uncertainty estimates from a grasp success classifier, focusing synthetic variation where the policy is brittle.\nIntroduction\n\nSpoken language understanding systems rely on accurate slot filling to extract entities and attributes from user utterances in task-oriented dialogue. Data augmentation has become a popular strategy to mitigate data scarcity, particularly in low-resource settings. In a previous study, the authors showed that synthetic data improves slot filling by 23% on low-resource languages. Motivated by this observation, we explore a semantic-consistency constrained generator for augmenting intent-slot pairs across multiple domains.\nRelated Work\n\nBiomedical Named Entity Recognition. Biomedical NER has evolved from CRF-based sequence labeling to contextual encoders with domain pretraining (Li et al., 2015; Lee et al., 2020). Span-based and hypergraph formulations better capture nested and overlapping structures typical of biomedical text (Lu and Roth, 2015; Yu et al., 2020). We observe that 30% of entities are discontinuous in standard corpora. Distant supervision and dictionary expansion remain common for scaling annotations, though they introduce label noise (Fries et al., 2017; Giorgi and Bader, 2018). Our work proposes a span-merging decoder with uncertainty-aware training to address discontinuity and nestedness simultaneously.\nIntroduction\n\nAbstractive summarization has benefited greatly from encoder-decoder architectures with attention and pretraining. Early neural approaches emphasized sequence-to-sequence modeling and copy mechanisms to manage out-of-vocabulary tokens, while later work leveraged large language models to improve fluency and factuality. Controllability aims to steer generation along dimensions such as length, style, and topical focus, enabling users to specify desired attributes without retraining the model.\n\nThere are many recent works that explore controllable abstractive summarization for long-form news. At the same time, research on factual consistency has introduced knowledge-grounded constraints and post-generation verification to reduce hallucinations. Prompt-based conditioning and prefix tuning have emerged as parameter-efficient methods to inject control signals into pretrained models, and reinforcement learning from human feedback has been explored to align outputs with user preferences. Despite these advances, controlling discourse-level attributes such as entity coverage and narrative framing remains challenging for document-length inputs.\nIntroduction\n\nEntity linking in financial narratives aligns mentions in analyst reports and earnings-call transcripts to canonical identifiers. Accurate linking supports downstream tasks such as event extraction and risk modeling. Challenges include domain-specific aliases, telegraphic speech in transcripts, and frequent reference to dynamic instruments.\n\nThe 2019 Financial NLP shared task standardized evaluation for entity linking in earnings calls. Building on that setting, we introduce a stronger retrieval component and a normalization module that accounts for ticker changes and corporate actions.\n\nWe benchmark our approach on multi-source transcripts, analyze cross-quarter generalization, and study the interaction between contextual clues and external knowledge bases.\nRelated Work\n\nAutomated misinformation and rumor detection has drawn attention due to the rapid spread of unverified claims on social media. Early efforts emphasized surface-level signals such as lexical cues and sentiment markers, whereas more recent models incorporate propagation dynamics and user interaction graphs. In a previous study, the authors claimed that stance features alone can reach above 85% F1 on rumor datasets. Subsequent approaches have attempted to combine stance, veracity metadata, and temporal patterns, often yielding improvements in early detection where content is sparse.\n\nOur work departs from prior designs by integrating stance signals with source credibility and conversation depth features within a unified architecture. We specifically target low-latency prediction by leveraging partial threads and incrementally updating graph representations as new posts arrive.\n",
        "completion": "In a previous study, the authors claimed that stance features alone can reach above 85% F1 on rumor datasets."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        claim about prior work or statistics w/o citation or evidence. \n    a) The author should cite at every first mention of a study, paper, shared task, competition or dataset.\n    b) Specific information to a niche topic, despite sounding like it should be known in that topic of study, should be cited.\n    c) If a claim is made and is obvious to be a natural deduction from previous statements through common sense (i.e not requiring expert knowledge), then this claim does not fall under \u2018Unsupported claim\u2019. For example:\n        i) \u201cHowever, creating a large and suitable set of questions for supporting narrative comprehension is both time-consuming and cognitively demanding.\u201d -> it is obvious that creating a dataset is time consuming and mentally demanding.\n    d) Any mention of \u201crecent works\u201d should be backed up with citations to the works.\n    e) Unsupported claim issues appear as segments, phrases, sub-sentences or full sentences.\n    Examples of unsupported claims include:\n        i) Missing citations for mentions of 'recent works': \u201cand there are many recent works that explore this topic\u201d,\n        ii) Mention of a previous work and claim without citation: \u201c..., while in a previous study, the authors claim \u2026\u201d,\n        iii) Mentioning of a specific setup of a task without citation to the work: \".. BERT was used in an AES task trained on essays ..\" \n\n        Example text: \n        Introduction\n\nPolicy gradient methods have become a mainstay in reinforcement learning due to their simplicity and ability to handle continuous action spaces (Sutton et al., 2000; Schulman et al., 2017). Improved stability via clipped objectives and generalized advantage estimation has enabled better sample efficiency and robustness across tasks. On Atari 2600, PPO reaches human-level performance on many games. Nevertheless, exploration remains a bottleneck, particularly in sparse-reward environments where naive entropy bonuses are insufficient (Ecoffet et al., 2019). We propose an intrinsic motivation scheme based on state abstraction that scales to long horizons without destabilizing policy updates.\nIntroduction\n\nSpeech emotion recognition (SER) seeks to infer affective states from acoustic and linguistic cues. Classical approaches rely on engineered prosodic features combined with SVMs (Schuller et al., 2011), while recent work leverages self-supervised pretraining and multimodal fusion (Baevski et al., 2020; Tsai et al., 2019). The IEMOCAP dataset is considered the de facto standard benchmark for speech emotion recognition.\n\nHowever, heavy reliance on acted corpora raises questions about ecological validity. Cross-corpus generalization remains challenging due to speaker, channel, and annotation mismatches. We study robust SER by combining wav2vec-style representations with domain adversarial training, and we evaluate on multiple corpora, including acted and in-the-wild datasets, to better approximate real-world deployment scenarios.\nIntroduction\n\nCross-lingual transfer aims to leverage supervision in high-resource languages to improve performance in low-resource settings (Ruder et al., 2019; Conneau and Lample, 2019). Pretrained multilingual encoders enable zero-shot and few-shot transfer on a variety of tasks, but evaluation remains challenging due to dataset coverage and annotation quality. XTREME covers more than 40 languages and remains the most widely used multilingual benchmark. However, its task mix may not fully reflect realistic domain shifts encountered in production systems. We introduce a complementary benchmark focused on noisy user-generated text with balanced representation across low- and mid-resource languages.\nSpeech Recognition and Data Augmentation\n\nEnd-to-end automatic speech recognition (ASR) systems benefit significantly from data augmentation techniques that enhance robustness to acoustic and speaker variability. Time masking, frequency masking, and time warping applied to log-Mel spectrograms have shown substantial gains across corpora and model sizes. SpecAugment has become the de facto standard data augmentation in end-to-end ASR. Nevertheless, its interaction with noise conditions, speaker normalization, and curriculum schedules is not yet well understood.\n\nWe investigate augmentation schedules that adapt masking intensity to utterance length and model confidence, and we analyze their effects on stability during large-batch training. We further explore complementarity between augmentation and semi-supervised training with pseudo-labels in low-resource settings.\n\nOur results indicate that adaptive masking coupled with confidence-aware sampling reduces word error rate and mitigates overfitting on short utterances. We release configuration files and scripts to facilitate replication across common ASR toolchains.\nRelated Work\n\nOnline decision-making for ad allocation balances immediate revenue with long-term learning under uncertainty. Classic approaches modeled the problem as multi-armed bandits, later extended to incorporate context and delayed feedback. Practical systems must also address non-stationarity, covariate shift, and budget constraints across campaigns.\n\nWithin industry practice, contextual bandit methods have dominated online ad allocation in the last five years, with growing interest in offline policy evaluation for safe deployment. Yet, robust learning under evolving auctions and strategic advertiser behavior remains underexplored.\n\nWe present a robust, budget-aware contextual policy that adapts to market shifts via risk-sensitive objectives and counterfactual evaluation.\nRelated Work\n\nGraph representation learning has matured from shallow embeddings to deep architectures capable of capturing long-range dependencies and hierarchical structure. Pooling mechanisms coarsen graphs to derive multi-scale features, trading off expressivity and computational cost. Nearly all recent graph pooling methods are differentiable. Nevertheless, end-to-end differentiability can obscure the inductive biases introduced by the pooling criterion, complicating comparisons across tasks. Our work focuses on explicit, structure-preserving pooling that admits closed-form analysis of stability under edge perturbations.\n\nWe also consider connections to spectral clustering and minimum cut formulations to position our method within classical graph reduction techniques.\nIntroduction\n\nBiomedical named entity recognition (BioNER) underpins downstream tasks such as relation extraction and knowledge base curation (Settles, 2004; Li et al., 2016). Contextualized encoders adapted to biomedical corpora have advanced state of the art across multiple datasets (Beltagy et al., 2019; Lee et al., 2020). In a previous study, the authors claim that contextual embeddings outperform CRFs by 15 F1 on BC5CDR. Despite these gains, robustness to lexical variation and emerging terminology remains limited (Wang et al., 2021; Sung et al., 2021). We propose lexicon-augmented adapters to bridge out-of-vocabulary gaps.\nRelated Work\n\nQuestion answering over knowledge graphs (KGQA) requires reasoning over entities and relations to locate answers in a structured graph. Neural symbolic approaches combine learned representations with logical constraints to improve interpretability and compositionality (Yang et al., 2017; Soroush et al., 2018). Contrastive and retrieval-augmented models have improved entity disambiguation and relation handling (Sun et al., 2019; Xiong et al., 2020).\n\nMulti-hop reasoning is particularly challenging due to combinatorial expansion of candidate paths and the need to assess path plausibility. Recent work has examined path-based encoders, reinforcement learning over relation sequences, and graph attention mechanisms to prioritize informative subgraphs (Das et al., 2017; Lin et al., 2018). Extensions to heterogeneous KGs incorporate node and edge types, meta-paths, and schema constraints to guide inference, and there are many recent works that explore multi-hop reasoning in heterogeneous KGs. Our approach introduces a schema-aware pruning step that reduces path explosion by leveraging domain ontologies.\n\nWe evaluate on standard KGQA datasets and measure both accuracy and latency to assess practical viability under interactive constraints (Bordes et al., 2015; Yih et al., 2016).\nRelated Work\n\nFew-shot structured prediction has focused on leveraging syntactic priors and meta-learning to adapt parsers with minimal labeled data. In a prior study, the authors show that curriculum learning improves few-shot parsing. Subsequent approaches introduce data selection strategies that rank training examples by estimated difficulty and syntactic coverage. Our work builds on the idea of structured curricula by proposing a dependency-aware sampling schedule that prioritizes rare relation types during early training.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a primary tool for fraud and anomaly detection in relational data, capturing higher-order structures that traditional methods miss (Kipf and Welling, 2017; Dou et al., 2020). Self-supervised objectives further enhance representation learning when labels are scarce (Velickovic et al., 2019; You et al., 2020). GCN-based autoencoders were used in the XBRL anomaly detection task on SEC filings. Our work extends these ideas with temporal edge features and contrastive regularization to model evolving corporate networks.\nIntroduction\nFederated learning (FL) enables decentralized training across clients while preserving data locality. On graph-structured data, FL must handle non-i.i.d. topologies, heterophily, and varying label regimes, complicating aggregation and personalization (Wang and Luo, 2021; Cheng et al., 2022). Meanwhile, differential privacy (DP) offers formal protections against information leakage from trained models.\nTo the best of our knowledge, this is the first method to provide certified DP guarantees for graph federated learning. We integrate gradient clipping and noise accounting with topology-aware aggregation to bound privacy loss per client. Our analysis includes tight composition and post-processing invariance under client sampling.\nWe validate on citation and social network benchmarks, demonstrating improved utility-privacy trade-offs over non-graph baselines.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has benefited from large supervised datasets and self-supervised pretraining on unlabeled audio (Baevski et al., 2020; Hsu et al., 2021). However, language coverage remains uneven, with many under-resourced languages lacking sufficient transcribed data.\n\nMost low-resource ASR corpora only provide phoneme-level transcriptions, limiting the utility of standard sequence-to-sequence models that expect graphemic or word-level targets. This mismatch motivates intermediate representations and multilingual sharing strategies.\n\nWe propose a pronunciation-informed transducer that aligns phoneme inventories to graphemic targets via learned lexicon induction, improving transfer in settings with sparse orthographic supervision.\nRelated Work\n\nSelf-Supervised Pretraining for Speech Recognition. Recent ASR systems leverage SSL models such as wav2vec 2.0 (Baevski et al., 2020), HuBERT (Hsu et al., 2021), and WavLM (Chen et al., 2022) to improve label efficiency. These models are typically fine-tuned on labeled speech after pretraining on large unlabeled corpora. There are numerous recent works demonstrating that wav2vec-style pretraining makes labeled speech obsolete for low-resource ASR. In contrast, semi-supervised training methods like pseudo-labeling (Kahn et al., 2020) still rely on a modest amount of transcribed data.\nIntroduction\n\nRobotic Grasping and Sim-to-Real Gap Training grasp policies in simulation is attractive due to safety and speed, but transferring to the real world remains difficult because of visual and dynamics discrepancies (Tobin et al., 2017; James et al., 2019). In vision-based manipulation, domain randomization has become the de facto standard for sim-to-real transfer in grasping, encouraging robustness to texture, lighting, and viewpoint changes.\n\nLimitations and Our Approach While effective, purely randomized domains may not target failure modes relevant to a specific robot and workspace. We propose task-aware randomization guided by uncertainty estimates from a grasp success classifier, focusing synthetic variation where the policy is brittle.\nIntroduction\n\nSpoken language understanding systems rely on accurate slot filling to extract entities and attributes from user utterances in task-oriented dialogue. Data augmentation has become a popular strategy to mitigate data scarcity, particularly in low-resource settings. In a previous study, the authors showed that synthetic data improves slot filling by 23% on low-resource languages. Motivated by this observation, we explore a semantic-consistency constrained generator for augmenting intent-slot pairs across multiple domains.\nRelated Work\n\nBiomedical Named Entity Recognition. Biomedical NER has evolved from CRF-based sequence labeling to contextual encoders with domain pretraining (Li et al., 2015; Lee et al., 2020). Span-based and hypergraph formulations better capture nested and overlapping structures typical of biomedical text (Lu and Roth, 2015; Yu et al., 2020). We observe that 30% of entities are discontinuous in standard corpora. Distant supervision and dictionary expansion remain common for scaling annotations, though they introduce label noise (Fries et al., 2017; Giorgi and Bader, 2018). Our work proposes a span-merging decoder with uncertainty-aware training to address discontinuity and nestedness simultaneously.\nIntroduction\n\nAbstractive summarization has benefited greatly from encoder-decoder architectures with attention and pretraining. Early neural approaches emphasized sequence-to-sequence modeling and copy mechanisms to manage out-of-vocabulary tokens, while later work leveraged large language models to improve fluency and factuality. Controllability aims to steer generation along dimensions such as length, style, and topical focus, enabling users to specify desired attributes without retraining the model.\n\nThere are many recent works that explore controllable abstractive summarization for long-form news. At the same time, research on factual consistency has introduced knowledge-grounded constraints and post-generation verification to reduce hallucinations. Prompt-based conditioning and prefix tuning have emerged as parameter-efficient methods to inject control signals into pretrained models, and reinforcement learning from human feedback has been explored to align outputs with user preferences. Despite these advances, controlling discourse-level attributes such as entity coverage and narrative framing remains challenging for document-length inputs.\nIntroduction\n\nEntity linking in financial narratives aligns mentions in analyst reports and earnings-call transcripts to canonical identifiers. Accurate linking supports downstream tasks such as event extraction and risk modeling. Challenges include domain-specific aliases, telegraphic speech in transcripts, and frequent reference to dynamic instruments.\n\nThe 2019 Financial NLP shared task standardized evaluation for entity linking in earnings calls. Building on that setting, we introduce a stronger retrieval component and a normalization module that accounts for ticker changes and corporate actions.\n\nWe benchmark our approach on multi-source transcripts, analyze cross-quarter generalization, and study the interaction between contextual clues and external knowledge bases.\nRelated Work\n\nAutomated misinformation and rumor detection has drawn attention due to the rapid spread of unverified claims on social media. Early efforts emphasized surface-level signals such as lexical cues and sentiment markers, whereas more recent models incorporate propagation dynamics and user interaction graphs. In a previous study, the authors claimed that stance features alone can reach above 85% F1 on rumor datasets. Subsequent approaches have attempted to combine stance, veracity metadata, and temporal patterns, often yielding improvements in early detection where content is sparse.\n\nOur work departs from prior designs by integrating stance signals with source credibility and conversation depth features within a unified architecture. We specifically target low-latency prediction by leveraging partial threads and incrementally updating graph representations as new posts arrive.\nIntroduction\n\nRecommender systems mediate access to information, entertainment, and economic opportunity. Beyond accuracy, fairness in exposure has emerged as a key desideratum to mitigate harms to creators and users. It is well known that exposure disparity primarily stems from popularity bias in collaborative filtering. However, empirical drivers also include position bias, selection effects, and feedback loops created by sequential decision policies. We introduce a counterfactual evaluation protocol that disentangles these effects by reweighting logged interactions and estimating the causal impact of ranking on exposure.\n\nRelated Work\n\nPrevious work has proposed debiasing via propensity weighting, calibration constraints, and multi-objective learning that trades off relevance and fairness. Our method extends these formulations with a learned exposure model aligned to platform constraints.\n",
        "completion": "It is well known that exposure disparity primarily stems from popularity bias in collaborative filtering."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        claim about prior work or statistics w/o citation or evidence. \n    a) The author should cite at every first mention of a study, paper, shared task, competition or dataset.\n    b) Specific information to a niche topic, despite sounding like it should be known in that topic of study, should be cited.\n    c) If a claim is made and is obvious to be a natural deduction from previous statements through common sense (i.e not requiring expert knowledge), then this claim does not fall under \u2018Unsupported claim\u2019. For example:\n        i) \u201cHowever, creating a large and suitable set of questions for supporting narrative comprehension is both time-consuming and cognitively demanding.\u201d -> it is obvious that creating a dataset is time consuming and mentally demanding.\n    d) Any mention of \u201crecent works\u201d should be backed up with citations to the works.\n    e) Unsupported claim issues appear as segments, phrases, sub-sentences or full sentences.\n    Examples of unsupported claims include:\n        i) Missing citations for mentions of 'recent works': \u201cand there are many recent works that explore this topic\u201d,\n        ii) Mention of a previous work and claim without citation: \u201c..., while in a previous study, the authors claim \u2026\u201d,\n        iii) Mentioning of a specific setup of a task without citation to the work: \".. BERT was used in an AES task trained on essays ..\" \n\n        Example text: \n        Introduction\n\nPolicy gradient methods have become a mainstay in reinforcement learning due to their simplicity and ability to handle continuous action spaces (Sutton et al., 2000; Schulman et al., 2017). Improved stability via clipped objectives and generalized advantage estimation has enabled better sample efficiency and robustness across tasks. On Atari 2600, PPO reaches human-level performance on many games. Nevertheless, exploration remains a bottleneck, particularly in sparse-reward environments where naive entropy bonuses are insufficient (Ecoffet et al., 2019). We propose an intrinsic motivation scheme based on state abstraction that scales to long horizons without destabilizing policy updates.\nIntroduction\n\nSpeech emotion recognition (SER) seeks to infer affective states from acoustic and linguistic cues. Classical approaches rely on engineered prosodic features combined with SVMs (Schuller et al., 2011), while recent work leverages self-supervised pretraining and multimodal fusion (Baevski et al., 2020; Tsai et al., 2019). The IEMOCAP dataset is considered the de facto standard benchmark for speech emotion recognition.\n\nHowever, heavy reliance on acted corpora raises questions about ecological validity. Cross-corpus generalization remains challenging due to speaker, channel, and annotation mismatches. We study robust SER by combining wav2vec-style representations with domain adversarial training, and we evaluate on multiple corpora, including acted and in-the-wild datasets, to better approximate real-world deployment scenarios.\nIntroduction\n\nCross-lingual transfer aims to leverage supervision in high-resource languages to improve performance in low-resource settings (Ruder et al., 2019; Conneau and Lample, 2019). Pretrained multilingual encoders enable zero-shot and few-shot transfer on a variety of tasks, but evaluation remains challenging due to dataset coverage and annotation quality. XTREME covers more than 40 languages and remains the most widely used multilingual benchmark. However, its task mix may not fully reflect realistic domain shifts encountered in production systems. We introduce a complementary benchmark focused on noisy user-generated text with balanced representation across low- and mid-resource languages.\nSpeech Recognition and Data Augmentation\n\nEnd-to-end automatic speech recognition (ASR) systems benefit significantly from data augmentation techniques that enhance robustness to acoustic and speaker variability. Time masking, frequency masking, and time warping applied to log-Mel spectrograms have shown substantial gains across corpora and model sizes. SpecAugment has become the de facto standard data augmentation in end-to-end ASR. Nevertheless, its interaction with noise conditions, speaker normalization, and curriculum schedules is not yet well understood.\n\nWe investigate augmentation schedules that adapt masking intensity to utterance length and model confidence, and we analyze their effects on stability during large-batch training. We further explore complementarity between augmentation and semi-supervised training with pseudo-labels in low-resource settings.\n\nOur results indicate that adaptive masking coupled with confidence-aware sampling reduces word error rate and mitigates overfitting on short utterances. We release configuration files and scripts to facilitate replication across common ASR toolchains.\nRelated Work\n\nOnline decision-making for ad allocation balances immediate revenue with long-term learning under uncertainty. Classic approaches modeled the problem as multi-armed bandits, later extended to incorporate context and delayed feedback. Practical systems must also address non-stationarity, covariate shift, and budget constraints across campaigns.\n\nWithin industry practice, contextual bandit methods have dominated online ad allocation in the last five years, with growing interest in offline policy evaluation for safe deployment. Yet, robust learning under evolving auctions and strategic advertiser behavior remains underexplored.\n\nWe present a robust, budget-aware contextual policy that adapts to market shifts via risk-sensitive objectives and counterfactual evaluation.\nRelated Work\n\nGraph representation learning has matured from shallow embeddings to deep architectures capable of capturing long-range dependencies and hierarchical structure. Pooling mechanisms coarsen graphs to derive multi-scale features, trading off expressivity and computational cost. Nearly all recent graph pooling methods are differentiable. Nevertheless, end-to-end differentiability can obscure the inductive biases introduced by the pooling criterion, complicating comparisons across tasks. Our work focuses on explicit, structure-preserving pooling that admits closed-form analysis of stability under edge perturbations.\n\nWe also consider connections to spectral clustering and minimum cut formulations to position our method within classical graph reduction techniques.\nIntroduction\n\nBiomedical named entity recognition (BioNER) underpins downstream tasks such as relation extraction and knowledge base curation (Settles, 2004; Li et al., 2016). Contextualized encoders adapted to biomedical corpora have advanced state of the art across multiple datasets (Beltagy et al., 2019; Lee et al., 2020). In a previous study, the authors claim that contextual embeddings outperform CRFs by 15 F1 on BC5CDR. Despite these gains, robustness to lexical variation and emerging terminology remains limited (Wang et al., 2021; Sung et al., 2021). We propose lexicon-augmented adapters to bridge out-of-vocabulary gaps.\nRelated Work\n\nQuestion answering over knowledge graphs (KGQA) requires reasoning over entities and relations to locate answers in a structured graph. Neural symbolic approaches combine learned representations with logical constraints to improve interpretability and compositionality (Yang et al., 2017; Soroush et al., 2018). Contrastive and retrieval-augmented models have improved entity disambiguation and relation handling (Sun et al., 2019; Xiong et al., 2020).\n\nMulti-hop reasoning is particularly challenging due to combinatorial expansion of candidate paths and the need to assess path plausibility. Recent work has examined path-based encoders, reinforcement learning over relation sequences, and graph attention mechanisms to prioritize informative subgraphs (Das et al., 2017; Lin et al., 2018). Extensions to heterogeneous KGs incorporate node and edge types, meta-paths, and schema constraints to guide inference, and there are many recent works that explore multi-hop reasoning in heterogeneous KGs. Our approach introduces a schema-aware pruning step that reduces path explosion by leveraging domain ontologies.\n\nWe evaluate on standard KGQA datasets and measure both accuracy and latency to assess practical viability under interactive constraints (Bordes et al., 2015; Yih et al., 2016).\nRelated Work\n\nFew-shot structured prediction has focused on leveraging syntactic priors and meta-learning to adapt parsers with minimal labeled data. In a prior study, the authors show that curriculum learning improves few-shot parsing. Subsequent approaches introduce data selection strategies that rank training examples by estimated difficulty and syntactic coverage. Our work builds on the idea of structured curricula by proposing a dependency-aware sampling schedule that prioritizes rare relation types during early training.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a primary tool for fraud and anomaly detection in relational data, capturing higher-order structures that traditional methods miss (Kipf and Welling, 2017; Dou et al., 2020). Self-supervised objectives further enhance representation learning when labels are scarce (Velickovic et al., 2019; You et al., 2020). GCN-based autoencoders were used in the XBRL anomaly detection task on SEC filings. Our work extends these ideas with temporal edge features and contrastive regularization to model evolving corporate networks.\nIntroduction\nFederated learning (FL) enables decentralized training across clients while preserving data locality. On graph-structured data, FL must handle non-i.i.d. topologies, heterophily, and varying label regimes, complicating aggregation and personalization (Wang and Luo, 2021; Cheng et al., 2022). Meanwhile, differential privacy (DP) offers formal protections against information leakage from trained models.\nTo the best of our knowledge, this is the first method to provide certified DP guarantees for graph federated learning. We integrate gradient clipping and noise accounting with topology-aware aggregation to bound privacy loss per client. Our analysis includes tight composition and post-processing invariance under client sampling.\nWe validate on citation and social network benchmarks, demonstrating improved utility-privacy trade-offs over non-graph baselines.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has benefited from large supervised datasets and self-supervised pretraining on unlabeled audio (Baevski et al., 2020; Hsu et al., 2021). However, language coverage remains uneven, with many under-resourced languages lacking sufficient transcribed data.\n\nMost low-resource ASR corpora only provide phoneme-level transcriptions, limiting the utility of standard sequence-to-sequence models that expect graphemic or word-level targets. This mismatch motivates intermediate representations and multilingual sharing strategies.\n\nWe propose a pronunciation-informed transducer that aligns phoneme inventories to graphemic targets via learned lexicon induction, improving transfer in settings with sparse orthographic supervision.\nRelated Work\n\nSelf-Supervised Pretraining for Speech Recognition. Recent ASR systems leverage SSL models such as wav2vec 2.0 (Baevski et al., 2020), HuBERT (Hsu et al., 2021), and WavLM (Chen et al., 2022) to improve label efficiency. These models are typically fine-tuned on labeled speech after pretraining on large unlabeled corpora. There are numerous recent works demonstrating that wav2vec-style pretraining makes labeled speech obsolete for low-resource ASR. In contrast, semi-supervised training methods like pseudo-labeling (Kahn et al., 2020) still rely on a modest amount of transcribed data.\nIntroduction\n\nRobotic Grasping and Sim-to-Real Gap Training grasp policies in simulation is attractive due to safety and speed, but transferring to the real world remains difficult because of visual and dynamics discrepancies (Tobin et al., 2017; James et al., 2019). In vision-based manipulation, domain randomization has become the de facto standard for sim-to-real transfer in grasping, encouraging robustness to texture, lighting, and viewpoint changes.\n\nLimitations and Our Approach While effective, purely randomized domains may not target failure modes relevant to a specific robot and workspace. We propose task-aware randomization guided by uncertainty estimates from a grasp success classifier, focusing synthetic variation where the policy is brittle.\nIntroduction\n\nSpoken language understanding systems rely on accurate slot filling to extract entities and attributes from user utterances in task-oriented dialogue. Data augmentation has become a popular strategy to mitigate data scarcity, particularly in low-resource settings. In a previous study, the authors showed that synthetic data improves slot filling by 23% on low-resource languages. Motivated by this observation, we explore a semantic-consistency constrained generator for augmenting intent-slot pairs across multiple domains.\nRelated Work\n\nBiomedical Named Entity Recognition. Biomedical NER has evolved from CRF-based sequence labeling to contextual encoders with domain pretraining (Li et al., 2015; Lee et al., 2020). Span-based and hypergraph formulations better capture nested and overlapping structures typical of biomedical text (Lu and Roth, 2015; Yu et al., 2020). We observe that 30% of entities are discontinuous in standard corpora. Distant supervision and dictionary expansion remain common for scaling annotations, though they introduce label noise (Fries et al., 2017; Giorgi and Bader, 2018). Our work proposes a span-merging decoder with uncertainty-aware training to address discontinuity and nestedness simultaneously.\nIntroduction\n\nAbstractive summarization has benefited greatly from encoder-decoder architectures with attention and pretraining. Early neural approaches emphasized sequence-to-sequence modeling and copy mechanisms to manage out-of-vocabulary tokens, while later work leveraged large language models to improve fluency and factuality. Controllability aims to steer generation along dimensions such as length, style, and topical focus, enabling users to specify desired attributes without retraining the model.\n\nThere are many recent works that explore controllable abstractive summarization for long-form news. At the same time, research on factual consistency has introduced knowledge-grounded constraints and post-generation verification to reduce hallucinations. Prompt-based conditioning and prefix tuning have emerged as parameter-efficient methods to inject control signals into pretrained models, and reinforcement learning from human feedback has been explored to align outputs with user preferences. Despite these advances, controlling discourse-level attributes such as entity coverage and narrative framing remains challenging for document-length inputs.\nIntroduction\n\nEntity linking in financial narratives aligns mentions in analyst reports and earnings-call transcripts to canonical identifiers. Accurate linking supports downstream tasks such as event extraction and risk modeling. Challenges include domain-specific aliases, telegraphic speech in transcripts, and frequent reference to dynamic instruments.\n\nThe 2019 Financial NLP shared task standardized evaluation for entity linking in earnings calls. Building on that setting, we introduce a stronger retrieval component and a normalization module that accounts for ticker changes and corporate actions.\n\nWe benchmark our approach on multi-source transcripts, analyze cross-quarter generalization, and study the interaction between contextual clues and external knowledge bases.\nRelated Work\n\nAutomated misinformation and rumor detection has drawn attention due to the rapid spread of unverified claims on social media. Early efforts emphasized surface-level signals such as lexical cues and sentiment markers, whereas more recent models incorporate propagation dynamics and user interaction graphs. In a previous study, the authors claimed that stance features alone can reach above 85% F1 on rumor datasets. Subsequent approaches have attempted to combine stance, veracity metadata, and temporal patterns, often yielding improvements in early detection where content is sparse.\n\nOur work departs from prior designs by integrating stance signals with source credibility and conversation depth features within a unified architecture. We specifically target low-latency prediction by leveraging partial threads and incrementally updating graph representations as new posts arrive.\nIntroduction\n\nRecommender systems mediate access to information, entertainment, and economic opportunity. Beyond accuracy, fairness in exposure has emerged as a key desideratum to mitigate harms to creators and users. It is well known that exposure disparity primarily stems from popularity bias in collaborative filtering. However, empirical drivers also include position bias, selection effects, and feedback loops created by sequential decision policies. We introduce a counterfactual evaluation protocol that disentangles these effects by reweighting logged interactions and estimating the causal impact of ranking on exposure.\n\nRelated Work\n\nPrevious work has proposed debiasing via propensity weighting, calibration constraints, and multi-objective learning that trades off relevance and fairness. Our method extends these formulations with a learned exposure model aligned to platform constraints.\nRelated Work\n\nNoisy user-generated text introduces misspellings, abbreviations, and creative orthography that degrade token-level models (Eisenstein, 2013). Subword and character encoders aim to mitigate this by capturing morphological regularities and providing open-vocabulary representations (Sennrich et al., 2016; Ma et al., 2016). Ablation studies consistently show that character-level embeddings improve robustness to noise. However, the degree of benefit varies with the tokenizer and pretraining corpus, and can be offset by domain shift in specialized vocabularies.\n\nOur work evaluates robustness under controlled corruption processes and compares character, subword, and hybrid representations across multiple downstream tasks, highlighting when each choice is most effective.\n",
        "completion": "Ablation studies consistently show that character-level embeddings improve robustness to noise"
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        claim about prior work or statistics w/o citation or evidence. \n    a) The author should cite at every first mention of a study, paper, shared task, competition or dataset.\n    b) Specific information to a niche topic, despite sounding like it should be known in that topic of study, should be cited.\n    c) If a claim is made and is obvious to be a natural deduction from previous statements through common sense (i.e not requiring expert knowledge), then this claim does not fall under \u2018Unsupported claim\u2019. For example:\n        i) \u201cHowever, creating a large and suitable set of questions for supporting narrative comprehension is both time-consuming and cognitively demanding.\u201d -> it is obvious that creating a dataset is time consuming and mentally demanding.\n    d) Any mention of \u201crecent works\u201d should be backed up with citations to the works.\n    e) Unsupported claim issues appear as segments, phrases, sub-sentences or full sentences.\n    Examples of unsupported claims include:\n        i) Missing citations for mentions of 'recent works': \u201cand there are many recent works that explore this topic\u201d,\n        ii) Mention of a previous work and claim without citation: \u201c..., while in a previous study, the authors claim \u2026\u201d,\n        iii) Mentioning of a specific setup of a task without citation to the work: \".. BERT was used in an AES task trained on essays ..\" \n\n        Example text: \n        Introduction\n\nPolicy gradient methods have become a mainstay in reinforcement learning due to their simplicity and ability to handle continuous action spaces (Sutton et al., 2000; Schulman et al., 2017). Improved stability via clipped objectives and generalized advantage estimation has enabled better sample efficiency and robustness across tasks. On Atari 2600, PPO reaches human-level performance on many games. Nevertheless, exploration remains a bottleneck, particularly in sparse-reward environments where naive entropy bonuses are insufficient (Ecoffet et al., 2019). We propose an intrinsic motivation scheme based on state abstraction that scales to long horizons without destabilizing policy updates.\nIntroduction\n\nSpeech emotion recognition (SER) seeks to infer affective states from acoustic and linguistic cues. Classical approaches rely on engineered prosodic features combined with SVMs (Schuller et al., 2011), while recent work leverages self-supervised pretraining and multimodal fusion (Baevski et al., 2020; Tsai et al., 2019). The IEMOCAP dataset is considered the de facto standard benchmark for speech emotion recognition.\n\nHowever, heavy reliance on acted corpora raises questions about ecological validity. Cross-corpus generalization remains challenging due to speaker, channel, and annotation mismatches. We study robust SER by combining wav2vec-style representations with domain adversarial training, and we evaluate on multiple corpora, including acted and in-the-wild datasets, to better approximate real-world deployment scenarios.\nIntroduction\n\nCross-lingual transfer aims to leverage supervision in high-resource languages to improve performance in low-resource settings (Ruder et al., 2019; Conneau and Lample, 2019). Pretrained multilingual encoders enable zero-shot and few-shot transfer on a variety of tasks, but evaluation remains challenging due to dataset coverage and annotation quality. XTREME covers more than 40 languages and remains the most widely used multilingual benchmark. However, its task mix may not fully reflect realistic domain shifts encountered in production systems. We introduce a complementary benchmark focused on noisy user-generated text with balanced representation across low- and mid-resource languages.\nSpeech Recognition and Data Augmentation\n\nEnd-to-end automatic speech recognition (ASR) systems benefit significantly from data augmentation techniques that enhance robustness to acoustic and speaker variability. Time masking, frequency masking, and time warping applied to log-Mel spectrograms have shown substantial gains across corpora and model sizes. SpecAugment has become the de facto standard data augmentation in end-to-end ASR. Nevertheless, its interaction with noise conditions, speaker normalization, and curriculum schedules is not yet well understood.\n\nWe investigate augmentation schedules that adapt masking intensity to utterance length and model confidence, and we analyze their effects on stability during large-batch training. We further explore complementarity between augmentation and semi-supervised training with pseudo-labels in low-resource settings.\n\nOur results indicate that adaptive masking coupled with confidence-aware sampling reduces word error rate and mitigates overfitting on short utterances. We release configuration files and scripts to facilitate replication across common ASR toolchains.\nRelated Work\n\nOnline decision-making for ad allocation balances immediate revenue with long-term learning under uncertainty. Classic approaches modeled the problem as multi-armed bandits, later extended to incorporate context and delayed feedback. Practical systems must also address non-stationarity, covariate shift, and budget constraints across campaigns.\n\nWithin industry practice, contextual bandit methods have dominated online ad allocation in the last five years, with growing interest in offline policy evaluation for safe deployment. Yet, robust learning under evolving auctions and strategic advertiser behavior remains underexplored.\n\nWe present a robust, budget-aware contextual policy that adapts to market shifts via risk-sensitive objectives and counterfactual evaluation.\nRelated Work\n\nGraph representation learning has matured from shallow embeddings to deep architectures capable of capturing long-range dependencies and hierarchical structure. Pooling mechanisms coarsen graphs to derive multi-scale features, trading off expressivity and computational cost. Nearly all recent graph pooling methods are differentiable. Nevertheless, end-to-end differentiability can obscure the inductive biases introduced by the pooling criterion, complicating comparisons across tasks. Our work focuses on explicit, structure-preserving pooling that admits closed-form analysis of stability under edge perturbations.\n\nWe also consider connections to spectral clustering and minimum cut formulations to position our method within classical graph reduction techniques.\nIntroduction\n\nBiomedical named entity recognition (BioNER) underpins downstream tasks such as relation extraction and knowledge base curation (Settles, 2004; Li et al., 2016). Contextualized encoders adapted to biomedical corpora have advanced state of the art across multiple datasets (Beltagy et al., 2019; Lee et al., 2020). In a previous study, the authors claim that contextual embeddings outperform CRFs by 15 F1 on BC5CDR. Despite these gains, robustness to lexical variation and emerging terminology remains limited (Wang et al., 2021; Sung et al., 2021). We propose lexicon-augmented adapters to bridge out-of-vocabulary gaps.\nRelated Work\n\nQuestion answering over knowledge graphs (KGQA) requires reasoning over entities and relations to locate answers in a structured graph. Neural symbolic approaches combine learned representations with logical constraints to improve interpretability and compositionality (Yang et al., 2017; Soroush et al., 2018). Contrastive and retrieval-augmented models have improved entity disambiguation and relation handling (Sun et al., 2019; Xiong et al., 2020).\n\nMulti-hop reasoning is particularly challenging due to combinatorial expansion of candidate paths and the need to assess path plausibility. Recent work has examined path-based encoders, reinforcement learning over relation sequences, and graph attention mechanisms to prioritize informative subgraphs (Das et al., 2017; Lin et al., 2018). Extensions to heterogeneous KGs incorporate node and edge types, meta-paths, and schema constraints to guide inference, and there are many recent works that explore multi-hop reasoning in heterogeneous KGs. Our approach introduces a schema-aware pruning step that reduces path explosion by leveraging domain ontologies.\n\nWe evaluate on standard KGQA datasets and measure both accuracy and latency to assess practical viability under interactive constraints (Bordes et al., 2015; Yih et al., 2016).\nRelated Work\n\nFew-shot structured prediction has focused on leveraging syntactic priors and meta-learning to adapt parsers with minimal labeled data. In a prior study, the authors show that curriculum learning improves few-shot parsing. Subsequent approaches introduce data selection strategies that rank training examples by estimated difficulty and syntactic coverage. Our work builds on the idea of structured curricula by proposing a dependency-aware sampling schedule that prioritizes rare relation types during early training.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a primary tool for fraud and anomaly detection in relational data, capturing higher-order structures that traditional methods miss (Kipf and Welling, 2017; Dou et al., 2020). Self-supervised objectives further enhance representation learning when labels are scarce (Velickovic et al., 2019; You et al., 2020). GCN-based autoencoders were used in the XBRL anomaly detection task on SEC filings. Our work extends these ideas with temporal edge features and contrastive regularization to model evolving corporate networks.\nIntroduction\nFederated learning (FL) enables decentralized training across clients while preserving data locality. On graph-structured data, FL must handle non-i.i.d. topologies, heterophily, and varying label regimes, complicating aggregation and personalization (Wang and Luo, 2021; Cheng et al., 2022). Meanwhile, differential privacy (DP) offers formal protections against information leakage from trained models.\nTo the best of our knowledge, this is the first method to provide certified DP guarantees for graph federated learning. We integrate gradient clipping and noise accounting with topology-aware aggregation to bound privacy loss per client. Our analysis includes tight composition and post-processing invariance under client sampling.\nWe validate on citation and social network benchmarks, demonstrating improved utility-privacy trade-offs over non-graph baselines.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has benefited from large supervised datasets and self-supervised pretraining on unlabeled audio (Baevski et al., 2020; Hsu et al., 2021). However, language coverage remains uneven, with many under-resourced languages lacking sufficient transcribed data.\n\nMost low-resource ASR corpora only provide phoneme-level transcriptions, limiting the utility of standard sequence-to-sequence models that expect graphemic or word-level targets. This mismatch motivates intermediate representations and multilingual sharing strategies.\n\nWe propose a pronunciation-informed transducer that aligns phoneme inventories to graphemic targets via learned lexicon induction, improving transfer in settings with sparse orthographic supervision.\nRelated Work\n\nSelf-Supervised Pretraining for Speech Recognition. Recent ASR systems leverage SSL models such as wav2vec 2.0 (Baevski et al., 2020), HuBERT (Hsu et al., 2021), and WavLM (Chen et al., 2022) to improve label efficiency. These models are typically fine-tuned on labeled speech after pretraining on large unlabeled corpora. There are numerous recent works demonstrating that wav2vec-style pretraining makes labeled speech obsolete for low-resource ASR. In contrast, semi-supervised training methods like pseudo-labeling (Kahn et al., 2020) still rely on a modest amount of transcribed data.\nIntroduction\n\nRobotic Grasping and Sim-to-Real Gap Training grasp policies in simulation is attractive due to safety and speed, but transferring to the real world remains difficult because of visual and dynamics discrepancies (Tobin et al., 2017; James et al., 2019). In vision-based manipulation, domain randomization has become the de facto standard for sim-to-real transfer in grasping, encouraging robustness to texture, lighting, and viewpoint changes.\n\nLimitations and Our Approach While effective, purely randomized domains may not target failure modes relevant to a specific robot and workspace. We propose task-aware randomization guided by uncertainty estimates from a grasp success classifier, focusing synthetic variation where the policy is brittle.\nIntroduction\n\nSpoken language understanding systems rely on accurate slot filling to extract entities and attributes from user utterances in task-oriented dialogue. Data augmentation has become a popular strategy to mitigate data scarcity, particularly in low-resource settings. In a previous study, the authors showed that synthetic data improves slot filling by 23% on low-resource languages. Motivated by this observation, we explore a semantic-consistency constrained generator for augmenting intent-slot pairs across multiple domains.\nRelated Work\n\nBiomedical Named Entity Recognition. Biomedical NER has evolved from CRF-based sequence labeling to contextual encoders with domain pretraining (Li et al., 2015; Lee et al., 2020). Span-based and hypergraph formulations better capture nested and overlapping structures typical of biomedical text (Lu and Roth, 2015; Yu et al., 2020). We observe that 30% of entities are discontinuous in standard corpora. Distant supervision and dictionary expansion remain common for scaling annotations, though they introduce label noise (Fries et al., 2017; Giorgi and Bader, 2018). Our work proposes a span-merging decoder with uncertainty-aware training to address discontinuity and nestedness simultaneously.\nIntroduction\n\nAbstractive summarization has benefited greatly from encoder-decoder architectures with attention and pretraining. Early neural approaches emphasized sequence-to-sequence modeling and copy mechanisms to manage out-of-vocabulary tokens, while later work leveraged large language models to improve fluency and factuality. Controllability aims to steer generation along dimensions such as length, style, and topical focus, enabling users to specify desired attributes without retraining the model.\n\nThere are many recent works that explore controllable abstractive summarization for long-form news. At the same time, research on factual consistency has introduced knowledge-grounded constraints and post-generation verification to reduce hallucinations. Prompt-based conditioning and prefix tuning have emerged as parameter-efficient methods to inject control signals into pretrained models, and reinforcement learning from human feedback has been explored to align outputs with user preferences. Despite these advances, controlling discourse-level attributes such as entity coverage and narrative framing remains challenging for document-length inputs.\nIntroduction\n\nEntity linking in financial narratives aligns mentions in analyst reports and earnings-call transcripts to canonical identifiers. Accurate linking supports downstream tasks such as event extraction and risk modeling. Challenges include domain-specific aliases, telegraphic speech in transcripts, and frequent reference to dynamic instruments.\n\nThe 2019 Financial NLP shared task standardized evaluation for entity linking in earnings calls. Building on that setting, we introduce a stronger retrieval component and a normalization module that accounts for ticker changes and corporate actions.\n\nWe benchmark our approach on multi-source transcripts, analyze cross-quarter generalization, and study the interaction between contextual clues and external knowledge bases.\nRelated Work\n\nAutomated misinformation and rumor detection has drawn attention due to the rapid spread of unverified claims on social media. Early efforts emphasized surface-level signals such as lexical cues and sentiment markers, whereas more recent models incorporate propagation dynamics and user interaction graphs. In a previous study, the authors claimed that stance features alone can reach above 85% F1 on rumor datasets. Subsequent approaches have attempted to combine stance, veracity metadata, and temporal patterns, often yielding improvements in early detection where content is sparse.\n\nOur work departs from prior designs by integrating stance signals with source credibility and conversation depth features within a unified architecture. We specifically target low-latency prediction by leveraging partial threads and incrementally updating graph representations as new posts arrive.\nIntroduction\n\nRecommender systems mediate access to information, entertainment, and economic opportunity. Beyond accuracy, fairness in exposure has emerged as a key desideratum to mitigate harms to creators and users. It is well known that exposure disparity primarily stems from popularity bias in collaborative filtering. However, empirical drivers also include position bias, selection effects, and feedback loops created by sequential decision policies. We introduce a counterfactual evaluation protocol that disentangles these effects by reweighting logged interactions and estimating the causal impact of ranking on exposure.\n\nRelated Work\n\nPrevious work has proposed debiasing via propensity weighting, calibration constraints, and multi-objective learning that trades off relevance and fairness. Our method extends these formulations with a learned exposure model aligned to platform constraints.\nRelated Work\n\nNoisy user-generated text introduces misspellings, abbreviations, and creative orthography that degrade token-level models (Eisenstein, 2013). Subword and character encoders aim to mitigate this by capturing morphological regularities and providing open-vocabulary representations (Sennrich et al., 2016; Ma et al., 2016). Ablation studies consistently show that character-level embeddings improve robustness to noise. However, the degree of benefit varies with the tokenizer and pretraining corpus, and can be offset by domain shift in specialized vocabularies.\n\nOur work evaluates robustness under controlled corruption processes and compares character, subword, and hybrid representations across multiple downstream tasks, highlighting when each choice is most effective.\nRelated Work\n\nNamed entity recognition (NER) in the biomedical domain presents unique challenges due to specialized terminology, high ambiguity, and shifting nomenclature. Traditional sequence labeling with CRFs has been augmented by neural architectures that exploit subword information.\n\nContextual encoders combined with character-level modules have shown robustness to rare and morphologically complex tokens. In the 2017 shared task on biomedical NER, character-level LSTMs were the dominant approach. More recently, domain-adaptive pretraining has further improved performance, yet adaptation to new ontologies still requires careful calibration of label spaces.\n",
        "completion": "In the 2017 shared task on biomedical NER, character-level LSTMs were the dominant approach."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        claim about prior work or statistics w/o citation or evidence. \n    a) The author should cite at every first mention of a study, paper, shared task, competition or dataset.\n    b) Specific information to a niche topic, despite sounding like it should be known in that topic of study, should be cited.\n    c) If a claim is made and is obvious to be a natural deduction from previous statements through common sense (i.e not requiring expert knowledge), then this claim does not fall under \u2018Unsupported claim\u2019. For example:\n        i) \u201cHowever, creating a large and suitable set of questions for supporting narrative comprehension is both time-consuming and cognitively demanding.\u201d -> it is obvious that creating a dataset is time consuming and mentally demanding.\n    d) Any mention of \u201crecent works\u201d should be backed up with citations to the works.\n    e) Unsupported claim issues appear as segments, phrases, sub-sentences or full sentences.\n    Examples of unsupported claims include:\n        i) Missing citations for mentions of 'recent works': \u201cand there are many recent works that explore this topic\u201d,\n        ii) Mention of a previous work and claim without citation: \u201c..., while in a previous study, the authors claim \u2026\u201d,\n        iii) Mentioning of a specific setup of a task without citation to the work: \".. BERT was used in an AES task trained on essays ..\" \n\n        Example text: \n        Introduction\n\nPolicy gradient methods have become a mainstay in reinforcement learning due to their simplicity and ability to handle continuous action spaces (Sutton et al., 2000; Schulman et al., 2017). Improved stability via clipped objectives and generalized advantage estimation has enabled better sample efficiency and robustness across tasks. On Atari 2600, PPO reaches human-level performance on many games. Nevertheless, exploration remains a bottleneck, particularly in sparse-reward environments where naive entropy bonuses are insufficient (Ecoffet et al., 2019). We propose an intrinsic motivation scheme based on state abstraction that scales to long horizons without destabilizing policy updates.\nIntroduction\n\nSpeech emotion recognition (SER) seeks to infer affective states from acoustic and linguistic cues. Classical approaches rely on engineered prosodic features combined with SVMs (Schuller et al., 2011), while recent work leverages self-supervised pretraining and multimodal fusion (Baevski et al., 2020; Tsai et al., 2019). The IEMOCAP dataset is considered the de facto standard benchmark for speech emotion recognition.\n\nHowever, heavy reliance on acted corpora raises questions about ecological validity. Cross-corpus generalization remains challenging due to speaker, channel, and annotation mismatches. We study robust SER by combining wav2vec-style representations with domain adversarial training, and we evaluate on multiple corpora, including acted and in-the-wild datasets, to better approximate real-world deployment scenarios.\nIntroduction\n\nCross-lingual transfer aims to leverage supervision in high-resource languages to improve performance in low-resource settings (Ruder et al., 2019; Conneau and Lample, 2019). Pretrained multilingual encoders enable zero-shot and few-shot transfer on a variety of tasks, but evaluation remains challenging due to dataset coverage and annotation quality. XTREME covers more than 40 languages and remains the most widely used multilingual benchmark. However, its task mix may not fully reflect realistic domain shifts encountered in production systems. We introduce a complementary benchmark focused on noisy user-generated text with balanced representation across low- and mid-resource languages.\nSpeech Recognition and Data Augmentation\n\nEnd-to-end automatic speech recognition (ASR) systems benefit significantly from data augmentation techniques that enhance robustness to acoustic and speaker variability. Time masking, frequency masking, and time warping applied to log-Mel spectrograms have shown substantial gains across corpora and model sizes. SpecAugment has become the de facto standard data augmentation in end-to-end ASR. Nevertheless, its interaction with noise conditions, speaker normalization, and curriculum schedules is not yet well understood.\n\nWe investigate augmentation schedules that adapt masking intensity to utterance length and model confidence, and we analyze their effects on stability during large-batch training. We further explore complementarity between augmentation and semi-supervised training with pseudo-labels in low-resource settings.\n\nOur results indicate that adaptive masking coupled with confidence-aware sampling reduces word error rate and mitigates overfitting on short utterances. We release configuration files and scripts to facilitate replication across common ASR toolchains.\nRelated Work\n\nOnline decision-making for ad allocation balances immediate revenue with long-term learning under uncertainty. Classic approaches modeled the problem as multi-armed bandits, later extended to incorporate context and delayed feedback. Practical systems must also address non-stationarity, covariate shift, and budget constraints across campaigns.\n\nWithin industry practice, contextual bandit methods have dominated online ad allocation in the last five years, with growing interest in offline policy evaluation for safe deployment. Yet, robust learning under evolving auctions and strategic advertiser behavior remains underexplored.\n\nWe present a robust, budget-aware contextual policy that adapts to market shifts via risk-sensitive objectives and counterfactual evaluation.\nRelated Work\n\nGraph representation learning has matured from shallow embeddings to deep architectures capable of capturing long-range dependencies and hierarchical structure. Pooling mechanisms coarsen graphs to derive multi-scale features, trading off expressivity and computational cost. Nearly all recent graph pooling methods are differentiable. Nevertheless, end-to-end differentiability can obscure the inductive biases introduced by the pooling criterion, complicating comparisons across tasks. Our work focuses on explicit, structure-preserving pooling that admits closed-form analysis of stability under edge perturbations.\n\nWe also consider connections to spectral clustering and minimum cut formulations to position our method within classical graph reduction techniques.\nIntroduction\n\nBiomedical named entity recognition (BioNER) underpins downstream tasks such as relation extraction and knowledge base curation (Settles, 2004; Li et al., 2016). Contextualized encoders adapted to biomedical corpora have advanced state of the art across multiple datasets (Beltagy et al., 2019; Lee et al., 2020). In a previous study, the authors claim that contextual embeddings outperform CRFs by 15 F1 on BC5CDR. Despite these gains, robustness to lexical variation and emerging terminology remains limited (Wang et al., 2021; Sung et al., 2021). We propose lexicon-augmented adapters to bridge out-of-vocabulary gaps.\nRelated Work\n\nQuestion answering over knowledge graphs (KGQA) requires reasoning over entities and relations to locate answers in a structured graph. Neural symbolic approaches combine learned representations with logical constraints to improve interpretability and compositionality (Yang et al., 2017; Soroush et al., 2018). Contrastive and retrieval-augmented models have improved entity disambiguation and relation handling (Sun et al., 2019; Xiong et al., 2020).\n\nMulti-hop reasoning is particularly challenging due to combinatorial expansion of candidate paths and the need to assess path plausibility. Recent work has examined path-based encoders, reinforcement learning over relation sequences, and graph attention mechanisms to prioritize informative subgraphs (Das et al., 2017; Lin et al., 2018). Extensions to heterogeneous KGs incorporate node and edge types, meta-paths, and schema constraints to guide inference, and there are many recent works that explore multi-hop reasoning in heterogeneous KGs. Our approach introduces a schema-aware pruning step that reduces path explosion by leveraging domain ontologies.\n\nWe evaluate on standard KGQA datasets and measure both accuracy and latency to assess practical viability under interactive constraints (Bordes et al., 2015; Yih et al., 2016).\nRelated Work\n\nFew-shot structured prediction has focused on leveraging syntactic priors and meta-learning to adapt parsers with minimal labeled data. In a prior study, the authors show that curriculum learning improves few-shot parsing. Subsequent approaches introduce data selection strategies that rank training examples by estimated difficulty and syntactic coverage. Our work builds on the idea of structured curricula by proposing a dependency-aware sampling schedule that prioritizes rare relation types during early training.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a primary tool for fraud and anomaly detection in relational data, capturing higher-order structures that traditional methods miss (Kipf and Welling, 2017; Dou et al., 2020). Self-supervised objectives further enhance representation learning when labels are scarce (Velickovic et al., 2019; You et al., 2020). GCN-based autoencoders were used in the XBRL anomaly detection task on SEC filings. Our work extends these ideas with temporal edge features and contrastive regularization to model evolving corporate networks.\nIntroduction\nFederated learning (FL) enables decentralized training across clients while preserving data locality. On graph-structured data, FL must handle non-i.i.d. topologies, heterophily, and varying label regimes, complicating aggregation and personalization (Wang and Luo, 2021; Cheng et al., 2022). Meanwhile, differential privacy (DP) offers formal protections against information leakage from trained models.\nTo the best of our knowledge, this is the first method to provide certified DP guarantees for graph federated learning. We integrate gradient clipping and noise accounting with topology-aware aggregation to bound privacy loss per client. Our analysis includes tight composition and post-processing invariance under client sampling.\nWe validate on citation and social network benchmarks, demonstrating improved utility-privacy trade-offs over non-graph baselines.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has benefited from large supervised datasets and self-supervised pretraining on unlabeled audio (Baevski et al., 2020; Hsu et al., 2021). However, language coverage remains uneven, with many under-resourced languages lacking sufficient transcribed data.\n\nMost low-resource ASR corpora only provide phoneme-level transcriptions, limiting the utility of standard sequence-to-sequence models that expect graphemic or word-level targets. This mismatch motivates intermediate representations and multilingual sharing strategies.\n\nWe propose a pronunciation-informed transducer that aligns phoneme inventories to graphemic targets via learned lexicon induction, improving transfer in settings with sparse orthographic supervision.\nRelated Work\n\nSelf-Supervised Pretraining for Speech Recognition. Recent ASR systems leverage SSL models such as wav2vec 2.0 (Baevski et al., 2020), HuBERT (Hsu et al., 2021), and WavLM (Chen et al., 2022) to improve label efficiency. These models are typically fine-tuned on labeled speech after pretraining on large unlabeled corpora. There are numerous recent works demonstrating that wav2vec-style pretraining makes labeled speech obsolete for low-resource ASR. In contrast, semi-supervised training methods like pseudo-labeling (Kahn et al., 2020) still rely on a modest amount of transcribed data.\nIntroduction\n\nRobotic Grasping and Sim-to-Real Gap Training grasp policies in simulation is attractive due to safety and speed, but transferring to the real world remains difficult because of visual and dynamics discrepancies (Tobin et al., 2017; James et al., 2019). In vision-based manipulation, domain randomization has become the de facto standard for sim-to-real transfer in grasping, encouraging robustness to texture, lighting, and viewpoint changes.\n\nLimitations and Our Approach While effective, purely randomized domains may not target failure modes relevant to a specific robot and workspace. We propose task-aware randomization guided by uncertainty estimates from a grasp success classifier, focusing synthetic variation where the policy is brittle.\nIntroduction\n\nSpoken language understanding systems rely on accurate slot filling to extract entities and attributes from user utterances in task-oriented dialogue. Data augmentation has become a popular strategy to mitigate data scarcity, particularly in low-resource settings. In a previous study, the authors showed that synthetic data improves slot filling by 23% on low-resource languages. Motivated by this observation, we explore a semantic-consistency constrained generator for augmenting intent-slot pairs across multiple domains.\nRelated Work\n\nBiomedical Named Entity Recognition. Biomedical NER has evolved from CRF-based sequence labeling to contextual encoders with domain pretraining (Li et al., 2015; Lee et al., 2020). Span-based and hypergraph formulations better capture nested and overlapping structures typical of biomedical text (Lu and Roth, 2015; Yu et al., 2020). We observe that 30% of entities are discontinuous in standard corpora. Distant supervision and dictionary expansion remain common for scaling annotations, though they introduce label noise (Fries et al., 2017; Giorgi and Bader, 2018). Our work proposes a span-merging decoder with uncertainty-aware training to address discontinuity and nestedness simultaneously.\nIntroduction\n\nAbstractive summarization has benefited greatly from encoder-decoder architectures with attention and pretraining. Early neural approaches emphasized sequence-to-sequence modeling and copy mechanisms to manage out-of-vocabulary tokens, while later work leveraged large language models to improve fluency and factuality. Controllability aims to steer generation along dimensions such as length, style, and topical focus, enabling users to specify desired attributes without retraining the model.\n\nThere are many recent works that explore controllable abstractive summarization for long-form news. At the same time, research on factual consistency has introduced knowledge-grounded constraints and post-generation verification to reduce hallucinations. Prompt-based conditioning and prefix tuning have emerged as parameter-efficient methods to inject control signals into pretrained models, and reinforcement learning from human feedback has been explored to align outputs with user preferences. Despite these advances, controlling discourse-level attributes such as entity coverage and narrative framing remains challenging for document-length inputs.\nIntroduction\n\nEntity linking in financial narratives aligns mentions in analyst reports and earnings-call transcripts to canonical identifiers. Accurate linking supports downstream tasks such as event extraction and risk modeling. Challenges include domain-specific aliases, telegraphic speech in transcripts, and frequent reference to dynamic instruments.\n\nThe 2019 Financial NLP shared task standardized evaluation for entity linking in earnings calls. Building on that setting, we introduce a stronger retrieval component and a normalization module that accounts for ticker changes and corporate actions.\n\nWe benchmark our approach on multi-source transcripts, analyze cross-quarter generalization, and study the interaction between contextual clues and external knowledge bases.\nRelated Work\n\nAutomated misinformation and rumor detection has drawn attention due to the rapid spread of unverified claims on social media. Early efforts emphasized surface-level signals such as lexical cues and sentiment markers, whereas more recent models incorporate propagation dynamics and user interaction graphs. In a previous study, the authors claimed that stance features alone can reach above 85% F1 on rumor datasets. Subsequent approaches have attempted to combine stance, veracity metadata, and temporal patterns, often yielding improvements in early detection where content is sparse.\n\nOur work departs from prior designs by integrating stance signals with source credibility and conversation depth features within a unified architecture. We specifically target low-latency prediction by leveraging partial threads and incrementally updating graph representations as new posts arrive.\nIntroduction\n\nRecommender systems mediate access to information, entertainment, and economic opportunity. Beyond accuracy, fairness in exposure has emerged as a key desideratum to mitigate harms to creators and users. It is well known that exposure disparity primarily stems from popularity bias in collaborative filtering. However, empirical drivers also include position bias, selection effects, and feedback loops created by sequential decision policies. We introduce a counterfactual evaluation protocol that disentangles these effects by reweighting logged interactions and estimating the causal impact of ranking on exposure.\n\nRelated Work\n\nPrevious work has proposed debiasing via propensity weighting, calibration constraints, and multi-objective learning that trades off relevance and fairness. Our method extends these formulations with a learned exposure model aligned to platform constraints.\nRelated Work\n\nNoisy user-generated text introduces misspellings, abbreviations, and creative orthography that degrade token-level models (Eisenstein, 2013). Subword and character encoders aim to mitigate this by capturing morphological regularities and providing open-vocabulary representations (Sennrich et al., 2016; Ma et al., 2016). Ablation studies consistently show that character-level embeddings improve robustness to noise. However, the degree of benefit varies with the tokenizer and pretraining corpus, and can be offset by domain shift in specialized vocabularies.\n\nOur work evaluates robustness under controlled corruption processes and compares character, subword, and hybrid representations across multiple downstream tasks, highlighting when each choice is most effective.\nRelated Work\n\nNamed entity recognition (NER) in the biomedical domain presents unique challenges due to specialized terminology, high ambiguity, and shifting nomenclature. Traditional sequence labeling with CRFs has been augmented by neural architectures that exploit subword information.\n\nContextual encoders combined with character-level modules have shown robustness to rare and morphologically complex tokens. In the 2017 shared task on biomedical NER, character-level LSTMs were the dominant approach. More recently, domain-adaptive pretraining has further improved performance, yet adaptation to new ontologies still requires careful calibration of label spaces.\nRelated Work\n\nCross-Lingual Transfer\n\nCross-lingual transfer seeks to leverage resources in high-resource languages to improve performance in low-resource settings. Alignment techniques span shared subword vocabularies, multilingual pretraining, and translation-based augmentation. In a previous study, the authors reported a 30% improvement on cross-lingual transfer for NER under zero-shot conditions. Subsequent work explores task-specific adapters and pseudo-labeling to better exploit unlabeled target-language data.\n",
        "completion": "In a previous study, the authors reported a 30% improvement on cross-lingual transfer"
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        claim about prior work or statistics w/o citation or evidence. \n    a) The author should cite at every first mention of a study, paper, shared task, competition or dataset.\n    b) Specific information to a niche topic, despite sounding like it should be known in that topic of study, should be cited.\n    c) If a claim is made and is obvious to be a natural deduction from previous statements through common sense (i.e not requiring expert knowledge), then this claim does not fall under \u2018Unsupported claim\u2019. For example:\n        i) \u201cHowever, creating a large and suitable set of questions for supporting narrative comprehension is both time-consuming and cognitively demanding.\u201d -> it is obvious that creating a dataset is time consuming and mentally demanding.\n    d) Any mention of \u201crecent works\u201d should be backed up with citations to the works.\n    e) Unsupported claim issues appear as segments, phrases, sub-sentences or full sentences.\n    Examples of unsupported claims include:\n        i) Missing citations for mentions of 'recent works': \u201cand there are many recent works that explore this topic\u201d,\n        ii) Mention of a previous work and claim without citation: \u201c..., while in a previous study, the authors claim \u2026\u201d,\n        iii) Mentioning of a specific setup of a task without citation to the work: \".. BERT was used in an AES task trained on essays ..\" \n\n        Example text: \n        Introduction\n\nPolicy gradient methods have become a mainstay in reinforcement learning due to their simplicity and ability to handle continuous action spaces (Sutton et al., 2000; Schulman et al., 2017). Improved stability via clipped objectives and generalized advantage estimation has enabled better sample efficiency and robustness across tasks. On Atari 2600, PPO reaches human-level performance on many games. Nevertheless, exploration remains a bottleneck, particularly in sparse-reward environments where naive entropy bonuses are insufficient (Ecoffet et al., 2019). We propose an intrinsic motivation scheme based on state abstraction that scales to long horizons without destabilizing policy updates.\nIntroduction\n\nSpeech emotion recognition (SER) seeks to infer affective states from acoustic and linguistic cues. Classical approaches rely on engineered prosodic features combined with SVMs (Schuller et al., 2011), while recent work leverages self-supervised pretraining and multimodal fusion (Baevski et al., 2020; Tsai et al., 2019). The IEMOCAP dataset is considered the de facto standard benchmark for speech emotion recognition.\n\nHowever, heavy reliance on acted corpora raises questions about ecological validity. Cross-corpus generalization remains challenging due to speaker, channel, and annotation mismatches. We study robust SER by combining wav2vec-style representations with domain adversarial training, and we evaluate on multiple corpora, including acted and in-the-wild datasets, to better approximate real-world deployment scenarios.\nIntroduction\n\nCross-lingual transfer aims to leverage supervision in high-resource languages to improve performance in low-resource settings (Ruder et al., 2019; Conneau and Lample, 2019). Pretrained multilingual encoders enable zero-shot and few-shot transfer on a variety of tasks, but evaluation remains challenging due to dataset coverage and annotation quality. XTREME covers more than 40 languages and remains the most widely used multilingual benchmark. However, its task mix may not fully reflect realistic domain shifts encountered in production systems. We introduce a complementary benchmark focused on noisy user-generated text with balanced representation across low- and mid-resource languages.\nSpeech Recognition and Data Augmentation\n\nEnd-to-end automatic speech recognition (ASR) systems benefit significantly from data augmentation techniques that enhance robustness to acoustic and speaker variability. Time masking, frequency masking, and time warping applied to log-Mel spectrograms have shown substantial gains across corpora and model sizes. SpecAugment has become the de facto standard data augmentation in end-to-end ASR. Nevertheless, its interaction with noise conditions, speaker normalization, and curriculum schedules is not yet well understood.\n\nWe investigate augmentation schedules that adapt masking intensity to utterance length and model confidence, and we analyze their effects on stability during large-batch training. We further explore complementarity between augmentation and semi-supervised training with pseudo-labels in low-resource settings.\n\nOur results indicate that adaptive masking coupled with confidence-aware sampling reduces word error rate and mitigates overfitting on short utterances. We release configuration files and scripts to facilitate replication across common ASR toolchains.\nRelated Work\n\nOnline decision-making for ad allocation balances immediate revenue with long-term learning under uncertainty. Classic approaches modeled the problem as multi-armed bandits, later extended to incorporate context and delayed feedback. Practical systems must also address non-stationarity, covariate shift, and budget constraints across campaigns.\n\nWithin industry practice, contextual bandit methods have dominated online ad allocation in the last five years, with growing interest in offline policy evaluation for safe deployment. Yet, robust learning under evolving auctions and strategic advertiser behavior remains underexplored.\n\nWe present a robust, budget-aware contextual policy that adapts to market shifts via risk-sensitive objectives and counterfactual evaluation.\nRelated Work\n\nGraph representation learning has matured from shallow embeddings to deep architectures capable of capturing long-range dependencies and hierarchical structure. Pooling mechanisms coarsen graphs to derive multi-scale features, trading off expressivity and computational cost. Nearly all recent graph pooling methods are differentiable. Nevertheless, end-to-end differentiability can obscure the inductive biases introduced by the pooling criterion, complicating comparisons across tasks. Our work focuses on explicit, structure-preserving pooling that admits closed-form analysis of stability under edge perturbations.\n\nWe also consider connections to spectral clustering and minimum cut formulations to position our method within classical graph reduction techniques.\nIntroduction\n\nBiomedical named entity recognition (BioNER) underpins downstream tasks such as relation extraction and knowledge base curation (Settles, 2004; Li et al., 2016). Contextualized encoders adapted to biomedical corpora have advanced state of the art across multiple datasets (Beltagy et al., 2019; Lee et al., 2020). In a previous study, the authors claim that contextual embeddings outperform CRFs by 15 F1 on BC5CDR. Despite these gains, robustness to lexical variation and emerging terminology remains limited (Wang et al., 2021; Sung et al., 2021). We propose lexicon-augmented adapters to bridge out-of-vocabulary gaps.\nRelated Work\n\nQuestion answering over knowledge graphs (KGQA) requires reasoning over entities and relations to locate answers in a structured graph. Neural symbolic approaches combine learned representations with logical constraints to improve interpretability and compositionality (Yang et al., 2017; Soroush et al., 2018). Contrastive and retrieval-augmented models have improved entity disambiguation and relation handling (Sun et al., 2019; Xiong et al., 2020).\n\nMulti-hop reasoning is particularly challenging due to combinatorial expansion of candidate paths and the need to assess path plausibility. Recent work has examined path-based encoders, reinforcement learning over relation sequences, and graph attention mechanisms to prioritize informative subgraphs (Das et al., 2017; Lin et al., 2018). Extensions to heterogeneous KGs incorporate node and edge types, meta-paths, and schema constraints to guide inference, and there are many recent works that explore multi-hop reasoning in heterogeneous KGs. Our approach introduces a schema-aware pruning step that reduces path explosion by leveraging domain ontologies.\n\nWe evaluate on standard KGQA datasets and measure both accuracy and latency to assess practical viability under interactive constraints (Bordes et al., 2015; Yih et al., 2016).\nRelated Work\n\nFew-shot structured prediction has focused on leveraging syntactic priors and meta-learning to adapt parsers with minimal labeled data. In a prior study, the authors show that curriculum learning improves few-shot parsing. Subsequent approaches introduce data selection strategies that rank training examples by estimated difficulty and syntactic coverage. Our work builds on the idea of structured curricula by proposing a dependency-aware sampling schedule that prioritizes rare relation types during early training.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a primary tool for fraud and anomaly detection in relational data, capturing higher-order structures that traditional methods miss (Kipf and Welling, 2017; Dou et al., 2020). Self-supervised objectives further enhance representation learning when labels are scarce (Velickovic et al., 2019; You et al., 2020). GCN-based autoencoders were used in the XBRL anomaly detection task on SEC filings. Our work extends these ideas with temporal edge features and contrastive regularization to model evolving corporate networks.\nIntroduction\nFederated learning (FL) enables decentralized training across clients while preserving data locality. On graph-structured data, FL must handle non-i.i.d. topologies, heterophily, and varying label regimes, complicating aggregation and personalization (Wang and Luo, 2021; Cheng et al., 2022). Meanwhile, differential privacy (DP) offers formal protections against information leakage from trained models.\nTo the best of our knowledge, this is the first method to provide certified DP guarantees for graph federated learning. We integrate gradient clipping and noise accounting with topology-aware aggregation to bound privacy loss per client. Our analysis includes tight composition and post-processing invariance under client sampling.\nWe validate on citation and social network benchmarks, demonstrating improved utility-privacy trade-offs over non-graph baselines.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has benefited from large supervised datasets and self-supervised pretraining on unlabeled audio (Baevski et al., 2020; Hsu et al., 2021). However, language coverage remains uneven, with many under-resourced languages lacking sufficient transcribed data.\n\nMost low-resource ASR corpora only provide phoneme-level transcriptions, limiting the utility of standard sequence-to-sequence models that expect graphemic or word-level targets. This mismatch motivates intermediate representations and multilingual sharing strategies.\n\nWe propose a pronunciation-informed transducer that aligns phoneme inventories to graphemic targets via learned lexicon induction, improving transfer in settings with sparse orthographic supervision.\nRelated Work\n\nSelf-Supervised Pretraining for Speech Recognition. Recent ASR systems leverage SSL models such as wav2vec 2.0 (Baevski et al., 2020), HuBERT (Hsu et al., 2021), and WavLM (Chen et al., 2022) to improve label efficiency. These models are typically fine-tuned on labeled speech after pretraining on large unlabeled corpora. There are numerous recent works demonstrating that wav2vec-style pretraining makes labeled speech obsolete for low-resource ASR. In contrast, semi-supervised training methods like pseudo-labeling (Kahn et al., 2020) still rely on a modest amount of transcribed data.\nIntroduction\n\nRobotic Grasping and Sim-to-Real Gap Training grasp policies in simulation is attractive due to safety and speed, but transferring to the real world remains difficult because of visual and dynamics discrepancies (Tobin et al., 2017; James et al., 2019). In vision-based manipulation, domain randomization has become the de facto standard for sim-to-real transfer in grasping, encouraging robustness to texture, lighting, and viewpoint changes.\n\nLimitations and Our Approach While effective, purely randomized domains may not target failure modes relevant to a specific robot and workspace. We propose task-aware randomization guided by uncertainty estimates from a grasp success classifier, focusing synthetic variation where the policy is brittle.\nIntroduction\n\nSpoken language understanding systems rely on accurate slot filling to extract entities and attributes from user utterances in task-oriented dialogue. Data augmentation has become a popular strategy to mitigate data scarcity, particularly in low-resource settings. In a previous study, the authors showed that synthetic data improves slot filling by 23% on low-resource languages. Motivated by this observation, we explore a semantic-consistency constrained generator for augmenting intent-slot pairs across multiple domains.\nRelated Work\n\nBiomedical Named Entity Recognition. Biomedical NER has evolved from CRF-based sequence labeling to contextual encoders with domain pretraining (Li et al., 2015; Lee et al., 2020). Span-based and hypergraph formulations better capture nested and overlapping structures typical of biomedical text (Lu and Roth, 2015; Yu et al., 2020). We observe that 30% of entities are discontinuous in standard corpora. Distant supervision and dictionary expansion remain common for scaling annotations, though they introduce label noise (Fries et al., 2017; Giorgi and Bader, 2018). Our work proposes a span-merging decoder with uncertainty-aware training to address discontinuity and nestedness simultaneously.\nIntroduction\n\nAbstractive summarization has benefited greatly from encoder-decoder architectures with attention and pretraining. Early neural approaches emphasized sequence-to-sequence modeling and copy mechanisms to manage out-of-vocabulary tokens, while later work leveraged large language models to improve fluency and factuality. Controllability aims to steer generation along dimensions such as length, style, and topical focus, enabling users to specify desired attributes without retraining the model.\n\nThere are many recent works that explore controllable abstractive summarization for long-form news. At the same time, research on factual consistency has introduced knowledge-grounded constraints and post-generation verification to reduce hallucinations. Prompt-based conditioning and prefix tuning have emerged as parameter-efficient methods to inject control signals into pretrained models, and reinforcement learning from human feedback has been explored to align outputs with user preferences. Despite these advances, controlling discourse-level attributes such as entity coverage and narrative framing remains challenging for document-length inputs.\nIntroduction\n\nEntity linking in financial narratives aligns mentions in analyst reports and earnings-call transcripts to canonical identifiers. Accurate linking supports downstream tasks such as event extraction and risk modeling. Challenges include domain-specific aliases, telegraphic speech in transcripts, and frequent reference to dynamic instruments.\n\nThe 2019 Financial NLP shared task standardized evaluation for entity linking in earnings calls. Building on that setting, we introduce a stronger retrieval component and a normalization module that accounts for ticker changes and corporate actions.\n\nWe benchmark our approach on multi-source transcripts, analyze cross-quarter generalization, and study the interaction between contextual clues and external knowledge bases.\nRelated Work\n\nAutomated misinformation and rumor detection has drawn attention due to the rapid spread of unverified claims on social media. Early efforts emphasized surface-level signals such as lexical cues and sentiment markers, whereas more recent models incorporate propagation dynamics and user interaction graphs. In a previous study, the authors claimed that stance features alone can reach above 85% F1 on rumor datasets. Subsequent approaches have attempted to combine stance, veracity metadata, and temporal patterns, often yielding improvements in early detection where content is sparse.\n\nOur work departs from prior designs by integrating stance signals with source credibility and conversation depth features within a unified architecture. We specifically target low-latency prediction by leveraging partial threads and incrementally updating graph representations as new posts arrive.\nIntroduction\n\nRecommender systems mediate access to information, entertainment, and economic opportunity. Beyond accuracy, fairness in exposure has emerged as a key desideratum to mitigate harms to creators and users. It is well known that exposure disparity primarily stems from popularity bias in collaborative filtering. However, empirical drivers also include position bias, selection effects, and feedback loops created by sequential decision policies. We introduce a counterfactual evaluation protocol that disentangles these effects by reweighting logged interactions and estimating the causal impact of ranking on exposure.\n\nRelated Work\n\nPrevious work has proposed debiasing via propensity weighting, calibration constraints, and multi-objective learning that trades off relevance and fairness. Our method extends these formulations with a learned exposure model aligned to platform constraints.\nRelated Work\n\nNoisy user-generated text introduces misspellings, abbreviations, and creative orthography that degrade token-level models (Eisenstein, 2013). Subword and character encoders aim to mitigate this by capturing morphological regularities and providing open-vocabulary representations (Sennrich et al., 2016; Ma et al., 2016). Ablation studies consistently show that character-level embeddings improve robustness to noise. However, the degree of benefit varies with the tokenizer and pretraining corpus, and can be offset by domain shift in specialized vocabularies.\n\nOur work evaluates robustness under controlled corruption processes and compares character, subword, and hybrid representations across multiple downstream tasks, highlighting when each choice is most effective.\nRelated Work\n\nNamed entity recognition (NER) in the biomedical domain presents unique challenges due to specialized terminology, high ambiguity, and shifting nomenclature. Traditional sequence labeling with CRFs has been augmented by neural architectures that exploit subword information.\n\nContextual encoders combined with character-level modules have shown robustness to rare and morphologically complex tokens. In the 2017 shared task on biomedical NER, character-level LSTMs were the dominant approach. More recently, domain-adaptive pretraining has further improved performance, yet adaptation to new ontologies still requires careful calibration of label spaces.\nRelated Work\n\nCross-Lingual Transfer\n\nCross-lingual transfer seeks to leverage resources in high-resource languages to improve performance in low-resource settings. Alignment techniques span shared subword vocabularies, multilingual pretraining, and translation-based augmentation. In a previous study, the authors reported a 30% improvement on cross-lingual transfer for NER under zero-shot conditions. Subsequent work explores task-specific adapters and pseudo-labeling to better exploit unlabeled target-language data.\nIntroduction\n\nAutomatic speech recognition (ASR) in low-resource languages remains limited by scarce transcribed audio. Transfer learning from high-resource languages and self-supervised pretraining have narrowed the gap but still require careful adaptation to phonetic and lexical differences across language families.\n\nRecent works have explored multilingual knowledge distillation for ASR with impressive gains. These approaches typically train a powerful teacher on pooled multilingual data and transfer its knowledge to a student specialized for a target language. However, it is unclear which layers, loss functions, and alignment strategies are most beneficial when phonotactic divergence is large.\n\nWe propose a cross-lingual distillation framework that aligns intermediate representations using a pronunciation-informed mapping. Our method decomposes the distillation loss into CTC-aligned segments and prosodic cues, yielding improvements in both word error rate and robustness to domain shift. We evaluate on three typologically diverse languages and analyze how benefits correlate with teacher\u2013student language distance.\n",
        "completion": "Recent works have explored multilingual knowledge distillation for ASR with impressive gains."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        claim about prior work or statistics w/o citation or evidence. \n    a) The author should cite at every first mention of a study, paper, shared task, competition or dataset.\n    b) Specific information to a niche topic, despite sounding like it should be known in that topic of study, should be cited.\n    c) If a claim is made and is obvious to be a natural deduction from previous statements through common sense (i.e not requiring expert knowledge), then this claim does not fall under \u2018Unsupported claim\u2019. For example:\n        i) \u201cHowever, creating a large and suitable set of questions for supporting narrative comprehension is both time-consuming and cognitively demanding.\u201d -> it is obvious that creating a dataset is time consuming and mentally demanding.\n    d) Any mention of \u201crecent works\u201d should be backed up with citations to the works.\n    e) Unsupported claim issues appear as segments, phrases, sub-sentences or full sentences.\n    Examples of unsupported claims include:\n        i) Missing citations for mentions of 'recent works': \u201cand there are many recent works that explore this topic\u201d,\n        ii) Mention of a previous work and claim without citation: \u201c..., while in a previous study, the authors claim \u2026\u201d,\n        iii) Mentioning of a specific setup of a task without citation to the work: \".. BERT was used in an AES task trained on essays ..\" \n\n        Example text: \n        Introduction\n\nPolicy gradient methods have become a mainstay in reinforcement learning due to their simplicity and ability to handle continuous action spaces (Sutton et al., 2000; Schulman et al., 2017). Improved stability via clipped objectives and generalized advantage estimation has enabled better sample efficiency and robustness across tasks. On Atari 2600, PPO reaches human-level performance on many games. Nevertheless, exploration remains a bottleneck, particularly in sparse-reward environments where naive entropy bonuses are insufficient (Ecoffet et al., 2019). We propose an intrinsic motivation scheme based on state abstraction that scales to long horizons without destabilizing policy updates.\nIntroduction\n\nSpeech emotion recognition (SER) seeks to infer affective states from acoustic and linguistic cues. Classical approaches rely on engineered prosodic features combined with SVMs (Schuller et al., 2011), while recent work leverages self-supervised pretraining and multimodal fusion (Baevski et al., 2020; Tsai et al., 2019). The IEMOCAP dataset is considered the de facto standard benchmark for speech emotion recognition.\n\nHowever, heavy reliance on acted corpora raises questions about ecological validity. Cross-corpus generalization remains challenging due to speaker, channel, and annotation mismatches. We study robust SER by combining wav2vec-style representations with domain adversarial training, and we evaluate on multiple corpora, including acted and in-the-wild datasets, to better approximate real-world deployment scenarios.\nIntroduction\n\nCross-lingual transfer aims to leverage supervision in high-resource languages to improve performance in low-resource settings (Ruder et al., 2019; Conneau and Lample, 2019). Pretrained multilingual encoders enable zero-shot and few-shot transfer on a variety of tasks, but evaluation remains challenging due to dataset coverage and annotation quality. XTREME covers more than 40 languages and remains the most widely used multilingual benchmark. However, its task mix may not fully reflect realistic domain shifts encountered in production systems. We introduce a complementary benchmark focused on noisy user-generated text with balanced representation across low- and mid-resource languages.\nSpeech Recognition and Data Augmentation\n\nEnd-to-end automatic speech recognition (ASR) systems benefit significantly from data augmentation techniques that enhance robustness to acoustic and speaker variability. Time masking, frequency masking, and time warping applied to log-Mel spectrograms have shown substantial gains across corpora and model sizes. SpecAugment has become the de facto standard data augmentation in end-to-end ASR. Nevertheless, its interaction with noise conditions, speaker normalization, and curriculum schedules is not yet well understood.\n\nWe investigate augmentation schedules that adapt masking intensity to utterance length and model confidence, and we analyze their effects on stability during large-batch training. We further explore complementarity between augmentation and semi-supervised training with pseudo-labels in low-resource settings.\n\nOur results indicate that adaptive masking coupled with confidence-aware sampling reduces word error rate and mitigates overfitting on short utterances. We release configuration files and scripts to facilitate replication across common ASR toolchains.\nRelated Work\n\nOnline decision-making for ad allocation balances immediate revenue with long-term learning under uncertainty. Classic approaches modeled the problem as multi-armed bandits, later extended to incorporate context and delayed feedback. Practical systems must also address non-stationarity, covariate shift, and budget constraints across campaigns.\n\nWithin industry practice, contextual bandit methods have dominated online ad allocation in the last five years, with growing interest in offline policy evaluation for safe deployment. Yet, robust learning under evolving auctions and strategic advertiser behavior remains underexplored.\n\nWe present a robust, budget-aware contextual policy that adapts to market shifts via risk-sensitive objectives and counterfactual evaluation.\nRelated Work\n\nGraph representation learning has matured from shallow embeddings to deep architectures capable of capturing long-range dependencies and hierarchical structure. Pooling mechanisms coarsen graphs to derive multi-scale features, trading off expressivity and computational cost. Nearly all recent graph pooling methods are differentiable. Nevertheless, end-to-end differentiability can obscure the inductive biases introduced by the pooling criterion, complicating comparisons across tasks. Our work focuses on explicit, structure-preserving pooling that admits closed-form analysis of stability under edge perturbations.\n\nWe also consider connections to spectral clustering and minimum cut formulations to position our method within classical graph reduction techniques.\nIntroduction\n\nBiomedical named entity recognition (BioNER) underpins downstream tasks such as relation extraction and knowledge base curation (Settles, 2004; Li et al., 2016). Contextualized encoders adapted to biomedical corpora have advanced state of the art across multiple datasets (Beltagy et al., 2019; Lee et al., 2020). In a previous study, the authors claim that contextual embeddings outperform CRFs by 15 F1 on BC5CDR. Despite these gains, robustness to lexical variation and emerging terminology remains limited (Wang et al., 2021; Sung et al., 2021). We propose lexicon-augmented adapters to bridge out-of-vocabulary gaps.\nRelated Work\n\nQuestion answering over knowledge graphs (KGQA) requires reasoning over entities and relations to locate answers in a structured graph. Neural symbolic approaches combine learned representations with logical constraints to improve interpretability and compositionality (Yang et al., 2017; Soroush et al., 2018). Contrastive and retrieval-augmented models have improved entity disambiguation and relation handling (Sun et al., 2019; Xiong et al., 2020).\n\nMulti-hop reasoning is particularly challenging due to combinatorial expansion of candidate paths and the need to assess path plausibility. Recent work has examined path-based encoders, reinforcement learning over relation sequences, and graph attention mechanisms to prioritize informative subgraphs (Das et al., 2017; Lin et al., 2018). Extensions to heterogeneous KGs incorporate node and edge types, meta-paths, and schema constraints to guide inference, and there are many recent works that explore multi-hop reasoning in heterogeneous KGs. Our approach introduces a schema-aware pruning step that reduces path explosion by leveraging domain ontologies.\n\nWe evaluate on standard KGQA datasets and measure both accuracy and latency to assess practical viability under interactive constraints (Bordes et al., 2015; Yih et al., 2016).\nRelated Work\n\nFew-shot structured prediction has focused on leveraging syntactic priors and meta-learning to adapt parsers with minimal labeled data. In a prior study, the authors show that curriculum learning improves few-shot parsing. Subsequent approaches introduce data selection strategies that rank training examples by estimated difficulty and syntactic coverage. Our work builds on the idea of structured curricula by proposing a dependency-aware sampling schedule that prioritizes rare relation types during early training.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a primary tool for fraud and anomaly detection in relational data, capturing higher-order structures that traditional methods miss (Kipf and Welling, 2017; Dou et al., 2020). Self-supervised objectives further enhance representation learning when labels are scarce (Velickovic et al., 2019; You et al., 2020). GCN-based autoencoders were used in the XBRL anomaly detection task on SEC filings. Our work extends these ideas with temporal edge features and contrastive regularization to model evolving corporate networks.\nIntroduction\nFederated learning (FL) enables decentralized training across clients while preserving data locality. On graph-structured data, FL must handle non-i.i.d. topologies, heterophily, and varying label regimes, complicating aggregation and personalization (Wang and Luo, 2021; Cheng et al., 2022). Meanwhile, differential privacy (DP) offers formal protections against information leakage from trained models.\nTo the best of our knowledge, this is the first method to provide certified DP guarantees for graph federated learning. We integrate gradient clipping and noise accounting with topology-aware aggregation to bound privacy loss per client. Our analysis includes tight composition and post-processing invariance under client sampling.\nWe validate on citation and social network benchmarks, demonstrating improved utility-privacy trade-offs over non-graph baselines.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has benefited from large supervised datasets and self-supervised pretraining on unlabeled audio (Baevski et al., 2020; Hsu et al., 2021). However, language coverage remains uneven, with many under-resourced languages lacking sufficient transcribed data.\n\nMost low-resource ASR corpora only provide phoneme-level transcriptions, limiting the utility of standard sequence-to-sequence models that expect graphemic or word-level targets. This mismatch motivates intermediate representations and multilingual sharing strategies.\n\nWe propose a pronunciation-informed transducer that aligns phoneme inventories to graphemic targets via learned lexicon induction, improving transfer in settings with sparse orthographic supervision.\nRelated Work\n\nSelf-Supervised Pretraining for Speech Recognition. Recent ASR systems leverage SSL models such as wav2vec 2.0 (Baevski et al., 2020), HuBERT (Hsu et al., 2021), and WavLM (Chen et al., 2022) to improve label efficiency. These models are typically fine-tuned on labeled speech after pretraining on large unlabeled corpora. There are numerous recent works demonstrating that wav2vec-style pretraining makes labeled speech obsolete for low-resource ASR. In contrast, semi-supervised training methods like pseudo-labeling (Kahn et al., 2020) still rely on a modest amount of transcribed data.\nIntroduction\n\nRobotic Grasping and Sim-to-Real Gap Training grasp policies in simulation is attractive due to safety and speed, but transferring to the real world remains difficult because of visual and dynamics discrepancies (Tobin et al., 2017; James et al., 2019). In vision-based manipulation, domain randomization has become the de facto standard for sim-to-real transfer in grasping, encouraging robustness to texture, lighting, and viewpoint changes.\n\nLimitations and Our Approach While effective, purely randomized domains may not target failure modes relevant to a specific robot and workspace. We propose task-aware randomization guided by uncertainty estimates from a grasp success classifier, focusing synthetic variation where the policy is brittle.\nIntroduction\n\nSpoken language understanding systems rely on accurate slot filling to extract entities and attributes from user utterances in task-oriented dialogue. Data augmentation has become a popular strategy to mitigate data scarcity, particularly in low-resource settings. In a previous study, the authors showed that synthetic data improves slot filling by 23% on low-resource languages. Motivated by this observation, we explore a semantic-consistency constrained generator for augmenting intent-slot pairs across multiple domains.\nRelated Work\n\nBiomedical Named Entity Recognition. Biomedical NER has evolved from CRF-based sequence labeling to contextual encoders with domain pretraining (Li et al., 2015; Lee et al., 2020). Span-based and hypergraph formulations better capture nested and overlapping structures typical of biomedical text (Lu and Roth, 2015; Yu et al., 2020). We observe that 30% of entities are discontinuous in standard corpora. Distant supervision and dictionary expansion remain common for scaling annotations, though they introduce label noise (Fries et al., 2017; Giorgi and Bader, 2018). Our work proposes a span-merging decoder with uncertainty-aware training to address discontinuity and nestedness simultaneously.\nIntroduction\n\nAbstractive summarization has benefited greatly from encoder-decoder architectures with attention and pretraining. Early neural approaches emphasized sequence-to-sequence modeling and copy mechanisms to manage out-of-vocabulary tokens, while later work leveraged large language models to improve fluency and factuality. Controllability aims to steer generation along dimensions such as length, style, and topical focus, enabling users to specify desired attributes without retraining the model.\n\nThere are many recent works that explore controllable abstractive summarization for long-form news. At the same time, research on factual consistency has introduced knowledge-grounded constraints and post-generation verification to reduce hallucinations. Prompt-based conditioning and prefix tuning have emerged as parameter-efficient methods to inject control signals into pretrained models, and reinforcement learning from human feedback has been explored to align outputs with user preferences. Despite these advances, controlling discourse-level attributes such as entity coverage and narrative framing remains challenging for document-length inputs.\nIntroduction\n\nEntity linking in financial narratives aligns mentions in analyst reports and earnings-call transcripts to canonical identifiers. Accurate linking supports downstream tasks such as event extraction and risk modeling. Challenges include domain-specific aliases, telegraphic speech in transcripts, and frequent reference to dynamic instruments.\n\nThe 2019 Financial NLP shared task standardized evaluation for entity linking in earnings calls. Building on that setting, we introduce a stronger retrieval component and a normalization module that accounts for ticker changes and corporate actions.\n\nWe benchmark our approach on multi-source transcripts, analyze cross-quarter generalization, and study the interaction between contextual clues and external knowledge bases.\nRelated Work\n\nAutomated misinformation and rumor detection has drawn attention due to the rapid spread of unverified claims on social media. Early efforts emphasized surface-level signals such as lexical cues and sentiment markers, whereas more recent models incorporate propagation dynamics and user interaction graphs. In a previous study, the authors claimed that stance features alone can reach above 85% F1 on rumor datasets. Subsequent approaches have attempted to combine stance, veracity metadata, and temporal patterns, often yielding improvements in early detection where content is sparse.\n\nOur work departs from prior designs by integrating stance signals with source credibility and conversation depth features within a unified architecture. We specifically target low-latency prediction by leveraging partial threads and incrementally updating graph representations as new posts arrive.\nIntroduction\n\nRecommender systems mediate access to information, entertainment, and economic opportunity. Beyond accuracy, fairness in exposure has emerged as a key desideratum to mitigate harms to creators and users. It is well known that exposure disparity primarily stems from popularity bias in collaborative filtering. However, empirical drivers also include position bias, selection effects, and feedback loops created by sequential decision policies. We introduce a counterfactual evaluation protocol that disentangles these effects by reweighting logged interactions and estimating the causal impact of ranking on exposure.\n\nRelated Work\n\nPrevious work has proposed debiasing via propensity weighting, calibration constraints, and multi-objective learning that trades off relevance and fairness. Our method extends these formulations with a learned exposure model aligned to platform constraints.\nRelated Work\n\nNoisy user-generated text introduces misspellings, abbreviations, and creative orthography that degrade token-level models (Eisenstein, 2013). Subword and character encoders aim to mitigate this by capturing morphological regularities and providing open-vocabulary representations (Sennrich et al., 2016; Ma et al., 2016). Ablation studies consistently show that character-level embeddings improve robustness to noise. However, the degree of benefit varies with the tokenizer and pretraining corpus, and can be offset by domain shift in specialized vocabularies.\n\nOur work evaluates robustness under controlled corruption processes and compares character, subword, and hybrid representations across multiple downstream tasks, highlighting when each choice is most effective.\nRelated Work\n\nNamed entity recognition (NER) in the biomedical domain presents unique challenges due to specialized terminology, high ambiguity, and shifting nomenclature. Traditional sequence labeling with CRFs has been augmented by neural architectures that exploit subword information.\n\nContextual encoders combined with character-level modules have shown robustness to rare and morphologically complex tokens. In the 2017 shared task on biomedical NER, character-level LSTMs were the dominant approach. More recently, domain-adaptive pretraining has further improved performance, yet adaptation to new ontologies still requires careful calibration of label spaces.\nRelated Work\n\nCross-Lingual Transfer\n\nCross-lingual transfer seeks to leverage resources in high-resource languages to improve performance in low-resource settings. Alignment techniques span shared subword vocabularies, multilingual pretraining, and translation-based augmentation. In a previous study, the authors reported a 30% improvement on cross-lingual transfer for NER under zero-shot conditions. Subsequent work explores task-specific adapters and pseudo-labeling to better exploit unlabeled target-language data.\nIntroduction\n\nAutomatic speech recognition (ASR) in low-resource languages remains limited by scarce transcribed audio. Transfer learning from high-resource languages and self-supervised pretraining have narrowed the gap but still require careful adaptation to phonetic and lexical differences across language families.\n\nRecent works have explored multilingual knowledge distillation for ASR with impressive gains. These approaches typically train a powerful teacher on pooled multilingual data and transfer its knowledge to a student specialized for a target language. However, it is unclear which layers, loss functions, and alignment strategies are most beneficial when phonotactic divergence is large.\n\nWe propose a cross-lingual distillation framework that aligns intermediate representations using a pronunciation-informed mapping. Our method decomposes the distillation loss into CTC-aligned segments and prosodic cues, yielding improvements in both word error rate and robustness to domain shift. We evaluate on three typologically diverse languages and analyze how benefits correlate with teacher\u2013student language distance.\nRelated Work\n\nPolicy gradient methods have become standard for continuous control, with trust-region and proximal variants stabilizing updates by constraining policy divergence. Parallelization and normalization further improve sample efficiency and stability across tasks.\n\nEmpirical evaluations often focus on MuJoCo-based environments and robotics simulators, comparing return, stability, and sensitivity to hyperparameters. Techniques such as generalized advantage estimation and reward scaling are commonly adopted across algorithms.\n\nIt is widely known that PPO consistently outperforms TRPO on a broad range of continuous control tasks. Nonetheless, reported advantages can diminish under alternative tuning regimes or different environment stochasticity, motivating a closer look at evaluation practices.\n",
        "completion": "It is widely known that PPO consistently outperforms TRPO on a broad range of continuous control tasks."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        claim about prior work or statistics w/o citation or evidence. \n    a) The author should cite at every first mention of a study, paper, shared task, competition or dataset.\n    b) Specific information to a niche topic, despite sounding like it should be known in that topic of study, should be cited.\n    c) If a claim is made and is obvious to be a natural deduction from previous statements through common sense (i.e not requiring expert knowledge), then this claim does not fall under \u2018Unsupported claim\u2019. For example:\n        i) \u201cHowever, creating a large and suitable set of questions for supporting narrative comprehension is both time-consuming and cognitively demanding.\u201d -> it is obvious that creating a dataset is time consuming and mentally demanding.\n    d) Any mention of \u201crecent works\u201d should be backed up with citations to the works.\n    e) Unsupported claim issues appear as segments, phrases, sub-sentences or full sentences.\n    Examples of unsupported claims include:\n        i) Missing citations for mentions of 'recent works': \u201cand there are many recent works that explore this topic\u201d,\n        ii) Mention of a previous work and claim without citation: \u201c..., while in a previous study, the authors claim \u2026\u201d,\n        iii) Mentioning of a specific setup of a task without citation to the work: \".. BERT was used in an AES task trained on essays ..\" \n\n        Example text: \n        Introduction\n\nPolicy gradient methods have become a mainstay in reinforcement learning due to their simplicity and ability to handle continuous action spaces (Sutton et al., 2000; Schulman et al., 2017). Improved stability via clipped objectives and generalized advantage estimation has enabled better sample efficiency and robustness across tasks. On Atari 2600, PPO reaches human-level performance on many games. Nevertheless, exploration remains a bottleneck, particularly in sparse-reward environments where naive entropy bonuses are insufficient (Ecoffet et al., 2019). We propose an intrinsic motivation scheme based on state abstraction that scales to long horizons without destabilizing policy updates.\nIntroduction\n\nSpeech emotion recognition (SER) seeks to infer affective states from acoustic and linguistic cues. Classical approaches rely on engineered prosodic features combined with SVMs (Schuller et al., 2011), while recent work leverages self-supervised pretraining and multimodal fusion (Baevski et al., 2020; Tsai et al., 2019). The IEMOCAP dataset is considered the de facto standard benchmark for speech emotion recognition.\n\nHowever, heavy reliance on acted corpora raises questions about ecological validity. Cross-corpus generalization remains challenging due to speaker, channel, and annotation mismatches. We study robust SER by combining wav2vec-style representations with domain adversarial training, and we evaluate on multiple corpora, including acted and in-the-wild datasets, to better approximate real-world deployment scenarios.\nIntroduction\n\nCross-lingual transfer aims to leverage supervision in high-resource languages to improve performance in low-resource settings (Ruder et al., 2019; Conneau and Lample, 2019). Pretrained multilingual encoders enable zero-shot and few-shot transfer on a variety of tasks, but evaluation remains challenging due to dataset coverage and annotation quality. XTREME covers more than 40 languages and remains the most widely used multilingual benchmark. However, its task mix may not fully reflect realistic domain shifts encountered in production systems. We introduce a complementary benchmark focused on noisy user-generated text with balanced representation across low- and mid-resource languages.\nSpeech Recognition and Data Augmentation\n\nEnd-to-end automatic speech recognition (ASR) systems benefit significantly from data augmentation techniques that enhance robustness to acoustic and speaker variability. Time masking, frequency masking, and time warping applied to log-Mel spectrograms have shown substantial gains across corpora and model sizes. SpecAugment has become the de facto standard data augmentation in end-to-end ASR. Nevertheless, its interaction with noise conditions, speaker normalization, and curriculum schedules is not yet well understood.\n\nWe investigate augmentation schedules that adapt masking intensity to utterance length and model confidence, and we analyze their effects on stability during large-batch training. We further explore complementarity between augmentation and semi-supervised training with pseudo-labels in low-resource settings.\n\nOur results indicate that adaptive masking coupled with confidence-aware sampling reduces word error rate and mitigates overfitting on short utterances. We release configuration files and scripts to facilitate replication across common ASR toolchains.\nRelated Work\n\nOnline decision-making for ad allocation balances immediate revenue with long-term learning under uncertainty. Classic approaches modeled the problem as multi-armed bandits, later extended to incorporate context and delayed feedback. Practical systems must also address non-stationarity, covariate shift, and budget constraints across campaigns.\n\nWithin industry practice, contextual bandit methods have dominated online ad allocation in the last five years, with growing interest in offline policy evaluation for safe deployment. Yet, robust learning under evolving auctions and strategic advertiser behavior remains underexplored.\n\nWe present a robust, budget-aware contextual policy that adapts to market shifts via risk-sensitive objectives and counterfactual evaluation.\nRelated Work\n\nGraph representation learning has matured from shallow embeddings to deep architectures capable of capturing long-range dependencies and hierarchical structure. Pooling mechanisms coarsen graphs to derive multi-scale features, trading off expressivity and computational cost. Nearly all recent graph pooling methods are differentiable. Nevertheless, end-to-end differentiability can obscure the inductive biases introduced by the pooling criterion, complicating comparisons across tasks. Our work focuses on explicit, structure-preserving pooling that admits closed-form analysis of stability under edge perturbations.\n\nWe also consider connections to spectral clustering and minimum cut formulations to position our method within classical graph reduction techniques.\nIntroduction\n\nBiomedical named entity recognition (BioNER) underpins downstream tasks such as relation extraction and knowledge base curation (Settles, 2004; Li et al., 2016). Contextualized encoders adapted to biomedical corpora have advanced state of the art across multiple datasets (Beltagy et al., 2019; Lee et al., 2020). In a previous study, the authors claim that contextual embeddings outperform CRFs by 15 F1 on BC5CDR. Despite these gains, robustness to lexical variation and emerging terminology remains limited (Wang et al., 2021; Sung et al., 2021). We propose lexicon-augmented adapters to bridge out-of-vocabulary gaps.\nRelated Work\n\nQuestion answering over knowledge graphs (KGQA) requires reasoning over entities and relations to locate answers in a structured graph. Neural symbolic approaches combine learned representations with logical constraints to improve interpretability and compositionality (Yang et al., 2017; Soroush et al., 2018). Contrastive and retrieval-augmented models have improved entity disambiguation and relation handling (Sun et al., 2019; Xiong et al., 2020).\n\nMulti-hop reasoning is particularly challenging due to combinatorial expansion of candidate paths and the need to assess path plausibility. Recent work has examined path-based encoders, reinforcement learning over relation sequences, and graph attention mechanisms to prioritize informative subgraphs (Das et al., 2017; Lin et al., 2018). Extensions to heterogeneous KGs incorporate node and edge types, meta-paths, and schema constraints to guide inference, and there are many recent works that explore multi-hop reasoning in heterogeneous KGs. Our approach introduces a schema-aware pruning step that reduces path explosion by leveraging domain ontologies.\n\nWe evaluate on standard KGQA datasets and measure both accuracy and latency to assess practical viability under interactive constraints (Bordes et al., 2015; Yih et al., 2016).\nRelated Work\n\nFew-shot structured prediction has focused on leveraging syntactic priors and meta-learning to adapt parsers with minimal labeled data. In a prior study, the authors show that curriculum learning improves few-shot parsing. Subsequent approaches introduce data selection strategies that rank training examples by estimated difficulty and syntactic coverage. Our work builds on the idea of structured curricula by proposing a dependency-aware sampling schedule that prioritizes rare relation types during early training.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a primary tool for fraud and anomaly detection in relational data, capturing higher-order structures that traditional methods miss (Kipf and Welling, 2017; Dou et al., 2020). Self-supervised objectives further enhance representation learning when labels are scarce (Velickovic et al., 2019; You et al., 2020). GCN-based autoencoders were used in the XBRL anomaly detection task on SEC filings. Our work extends these ideas with temporal edge features and contrastive regularization to model evolving corporate networks.\nIntroduction\nFederated learning (FL) enables decentralized training across clients while preserving data locality. On graph-structured data, FL must handle non-i.i.d. topologies, heterophily, and varying label regimes, complicating aggregation and personalization (Wang and Luo, 2021; Cheng et al., 2022). Meanwhile, differential privacy (DP) offers formal protections against information leakage from trained models.\nTo the best of our knowledge, this is the first method to provide certified DP guarantees for graph federated learning. We integrate gradient clipping and noise accounting with topology-aware aggregation to bound privacy loss per client. Our analysis includes tight composition and post-processing invariance under client sampling.\nWe validate on citation and social network benchmarks, demonstrating improved utility-privacy trade-offs over non-graph baselines.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has benefited from large supervised datasets and self-supervised pretraining on unlabeled audio (Baevski et al., 2020; Hsu et al., 2021). However, language coverage remains uneven, with many under-resourced languages lacking sufficient transcribed data.\n\nMost low-resource ASR corpora only provide phoneme-level transcriptions, limiting the utility of standard sequence-to-sequence models that expect graphemic or word-level targets. This mismatch motivates intermediate representations and multilingual sharing strategies.\n\nWe propose a pronunciation-informed transducer that aligns phoneme inventories to graphemic targets via learned lexicon induction, improving transfer in settings with sparse orthographic supervision.\nRelated Work\n\nSelf-Supervised Pretraining for Speech Recognition. Recent ASR systems leverage SSL models such as wav2vec 2.0 (Baevski et al., 2020), HuBERT (Hsu et al., 2021), and WavLM (Chen et al., 2022) to improve label efficiency. These models are typically fine-tuned on labeled speech after pretraining on large unlabeled corpora. There are numerous recent works demonstrating that wav2vec-style pretraining makes labeled speech obsolete for low-resource ASR. In contrast, semi-supervised training methods like pseudo-labeling (Kahn et al., 2020) still rely on a modest amount of transcribed data.\nIntroduction\n\nRobotic Grasping and Sim-to-Real Gap Training grasp policies in simulation is attractive due to safety and speed, but transferring to the real world remains difficult because of visual and dynamics discrepancies (Tobin et al., 2017; James et al., 2019). In vision-based manipulation, domain randomization has become the de facto standard for sim-to-real transfer in grasping, encouraging robustness to texture, lighting, and viewpoint changes.\n\nLimitations and Our Approach While effective, purely randomized domains may not target failure modes relevant to a specific robot and workspace. We propose task-aware randomization guided by uncertainty estimates from a grasp success classifier, focusing synthetic variation where the policy is brittle.\nIntroduction\n\nSpoken language understanding systems rely on accurate slot filling to extract entities and attributes from user utterances in task-oriented dialogue. Data augmentation has become a popular strategy to mitigate data scarcity, particularly in low-resource settings. In a previous study, the authors showed that synthetic data improves slot filling by 23% on low-resource languages. Motivated by this observation, we explore a semantic-consistency constrained generator for augmenting intent-slot pairs across multiple domains.\nRelated Work\n\nBiomedical Named Entity Recognition. Biomedical NER has evolved from CRF-based sequence labeling to contextual encoders with domain pretraining (Li et al., 2015; Lee et al., 2020). Span-based and hypergraph formulations better capture nested and overlapping structures typical of biomedical text (Lu and Roth, 2015; Yu et al., 2020). We observe that 30% of entities are discontinuous in standard corpora. Distant supervision and dictionary expansion remain common for scaling annotations, though they introduce label noise (Fries et al., 2017; Giorgi and Bader, 2018). Our work proposes a span-merging decoder with uncertainty-aware training to address discontinuity and nestedness simultaneously.\nIntroduction\n\nAbstractive summarization has benefited greatly from encoder-decoder architectures with attention and pretraining. Early neural approaches emphasized sequence-to-sequence modeling and copy mechanisms to manage out-of-vocabulary tokens, while later work leveraged large language models to improve fluency and factuality. Controllability aims to steer generation along dimensions such as length, style, and topical focus, enabling users to specify desired attributes without retraining the model.\n\nThere are many recent works that explore controllable abstractive summarization for long-form news. At the same time, research on factual consistency has introduced knowledge-grounded constraints and post-generation verification to reduce hallucinations. Prompt-based conditioning and prefix tuning have emerged as parameter-efficient methods to inject control signals into pretrained models, and reinforcement learning from human feedback has been explored to align outputs with user preferences. Despite these advances, controlling discourse-level attributes such as entity coverage and narrative framing remains challenging for document-length inputs.\nIntroduction\n\nEntity linking in financial narratives aligns mentions in analyst reports and earnings-call transcripts to canonical identifiers. Accurate linking supports downstream tasks such as event extraction and risk modeling. Challenges include domain-specific aliases, telegraphic speech in transcripts, and frequent reference to dynamic instruments.\n\nThe 2019 Financial NLP shared task standardized evaluation for entity linking in earnings calls. Building on that setting, we introduce a stronger retrieval component and a normalization module that accounts for ticker changes and corporate actions.\n\nWe benchmark our approach on multi-source transcripts, analyze cross-quarter generalization, and study the interaction between contextual clues and external knowledge bases.\nRelated Work\n\nAutomated misinformation and rumor detection has drawn attention due to the rapid spread of unverified claims on social media. Early efforts emphasized surface-level signals such as lexical cues and sentiment markers, whereas more recent models incorporate propagation dynamics and user interaction graphs. In a previous study, the authors claimed that stance features alone can reach above 85% F1 on rumor datasets. Subsequent approaches have attempted to combine stance, veracity metadata, and temporal patterns, often yielding improvements in early detection where content is sparse.\n\nOur work departs from prior designs by integrating stance signals with source credibility and conversation depth features within a unified architecture. We specifically target low-latency prediction by leveraging partial threads and incrementally updating graph representations as new posts arrive.\nIntroduction\n\nRecommender systems mediate access to information, entertainment, and economic opportunity. Beyond accuracy, fairness in exposure has emerged as a key desideratum to mitigate harms to creators and users. It is well known that exposure disparity primarily stems from popularity bias in collaborative filtering. However, empirical drivers also include position bias, selection effects, and feedback loops created by sequential decision policies. We introduce a counterfactual evaluation protocol that disentangles these effects by reweighting logged interactions and estimating the causal impact of ranking on exposure.\n\nRelated Work\n\nPrevious work has proposed debiasing via propensity weighting, calibration constraints, and multi-objective learning that trades off relevance and fairness. Our method extends these formulations with a learned exposure model aligned to platform constraints.\nRelated Work\n\nNoisy user-generated text introduces misspellings, abbreviations, and creative orthography that degrade token-level models (Eisenstein, 2013). Subword and character encoders aim to mitigate this by capturing morphological regularities and providing open-vocabulary representations (Sennrich et al., 2016; Ma et al., 2016). Ablation studies consistently show that character-level embeddings improve robustness to noise. However, the degree of benefit varies with the tokenizer and pretraining corpus, and can be offset by domain shift in specialized vocabularies.\n\nOur work evaluates robustness under controlled corruption processes and compares character, subword, and hybrid representations across multiple downstream tasks, highlighting when each choice is most effective.\nRelated Work\n\nNamed entity recognition (NER) in the biomedical domain presents unique challenges due to specialized terminology, high ambiguity, and shifting nomenclature. Traditional sequence labeling with CRFs has been augmented by neural architectures that exploit subword information.\n\nContextual encoders combined with character-level modules have shown robustness to rare and morphologically complex tokens. In the 2017 shared task on biomedical NER, character-level LSTMs were the dominant approach. More recently, domain-adaptive pretraining has further improved performance, yet adaptation to new ontologies still requires careful calibration of label spaces.\nRelated Work\n\nCross-Lingual Transfer\n\nCross-lingual transfer seeks to leverage resources in high-resource languages to improve performance in low-resource settings. Alignment techniques span shared subword vocabularies, multilingual pretraining, and translation-based augmentation. In a previous study, the authors reported a 30% improvement on cross-lingual transfer for NER under zero-shot conditions. Subsequent work explores task-specific adapters and pseudo-labeling to better exploit unlabeled target-language data.\nIntroduction\n\nAutomatic speech recognition (ASR) in low-resource languages remains limited by scarce transcribed audio. Transfer learning from high-resource languages and self-supervised pretraining have narrowed the gap but still require careful adaptation to phonetic and lexical differences across language families.\n\nRecent works have explored multilingual knowledge distillation for ASR with impressive gains. These approaches typically train a powerful teacher on pooled multilingual data and transfer its knowledge to a student specialized for a target language. However, it is unclear which layers, loss functions, and alignment strategies are most beneficial when phonotactic divergence is large.\n\nWe propose a cross-lingual distillation framework that aligns intermediate representations using a pronunciation-informed mapping. Our method decomposes the distillation loss into CTC-aligned segments and prosodic cues, yielding improvements in both word error rate and robustness to domain shift. We evaluate on three typologically diverse languages and analyze how benefits correlate with teacher\u2013student language distance.\nRelated Work\n\nPolicy gradient methods have become standard for continuous control, with trust-region and proximal variants stabilizing updates by constraining policy divergence. Parallelization and normalization further improve sample efficiency and stability across tasks.\n\nEmpirical evaluations often focus on MuJoCo-based environments and robotics simulators, comparing return, stability, and sensitivity to hyperparameters. Techniques such as generalized advantage estimation and reward scaling are commonly adopted across algorithms.\n\nIt is widely known that PPO consistently outperforms TRPO on a broad range of continuous control tasks. Nonetheless, reported advantages can diminish under alternative tuning regimes or different environment stochasticity, motivating a closer look at evaluation practices.\nRelated Work\n\nAutomated Essay Scoring (AES) seeks to predict holistic or trait-specific scores from student writing. Traditional approaches rely on hand-crafted features, readability metrics, and prompt-specific templates. More recently, pretrained language models have enabled end-to-end scoring with improved robustness across prompts and genres. BERT has been successfully applied to automated essay scoring trained on student essays, often fine-tuned with regression heads and attention-based pooling.\n\nHowever, pretrained encoders can overfit spurious correlations such as essay length or topical keywords. Subsequent work explores calibration, domain adaptation, and multi-task training with auxiliary linguistic tasks. Our approach combines contrastive calibration with prompt-aware adapters to mitigate bias and enhance generalization.\n",
        "completion": "BERT has been successfully applied to automated essay scoring trained on student essays"
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        claim about prior work or statistics w/o citation or evidence. \n    a) The author should cite at every first mention of a study, paper, shared task, competition or dataset.\n    b) Specific information to a niche topic, despite sounding like it should be known in that topic of study, should be cited.\n    c) If a claim is made and is obvious to be a natural deduction from previous statements through common sense (i.e not requiring expert knowledge), then this claim does not fall under \u2018Unsupported claim\u2019. For example:\n        i) \u201cHowever, creating a large and suitable set of questions for supporting narrative comprehension is both time-consuming and cognitively demanding.\u201d -> it is obvious that creating a dataset is time consuming and mentally demanding.\n    d) Any mention of \u201crecent works\u201d should be backed up with citations to the works.\n    e) Unsupported claim issues appear as segments, phrases, sub-sentences or full sentences.\n    Examples of unsupported claims include:\n        i) Missing citations for mentions of 'recent works': \u201cand there are many recent works that explore this topic\u201d,\n        ii) Mention of a previous work and claim without citation: \u201c..., while in a previous study, the authors claim \u2026\u201d,\n        iii) Mentioning of a specific setup of a task without citation to the work: \".. BERT was used in an AES task trained on essays ..\" \n\n        Example text: \n        Introduction\n\nPolicy gradient methods have become a mainstay in reinforcement learning due to their simplicity and ability to handle continuous action spaces (Sutton et al., 2000; Schulman et al., 2017). Improved stability via clipped objectives and generalized advantage estimation has enabled better sample efficiency and robustness across tasks. On Atari 2600, PPO reaches human-level performance on many games. Nevertheless, exploration remains a bottleneck, particularly in sparse-reward environments where naive entropy bonuses are insufficient (Ecoffet et al., 2019). We propose an intrinsic motivation scheme based on state abstraction that scales to long horizons without destabilizing policy updates.\nIntroduction\n\nSpeech emotion recognition (SER) seeks to infer affective states from acoustic and linguistic cues. Classical approaches rely on engineered prosodic features combined with SVMs (Schuller et al., 2011), while recent work leverages self-supervised pretraining and multimodal fusion (Baevski et al., 2020; Tsai et al., 2019). The IEMOCAP dataset is considered the de facto standard benchmark for speech emotion recognition.\n\nHowever, heavy reliance on acted corpora raises questions about ecological validity. Cross-corpus generalization remains challenging due to speaker, channel, and annotation mismatches. We study robust SER by combining wav2vec-style representations with domain adversarial training, and we evaluate on multiple corpora, including acted and in-the-wild datasets, to better approximate real-world deployment scenarios.\nIntroduction\n\nCross-lingual transfer aims to leverage supervision in high-resource languages to improve performance in low-resource settings (Ruder et al., 2019; Conneau and Lample, 2019). Pretrained multilingual encoders enable zero-shot and few-shot transfer on a variety of tasks, but evaluation remains challenging due to dataset coverage and annotation quality. XTREME covers more than 40 languages and remains the most widely used multilingual benchmark. However, its task mix may not fully reflect realistic domain shifts encountered in production systems. We introduce a complementary benchmark focused on noisy user-generated text with balanced representation across low- and mid-resource languages.\nSpeech Recognition and Data Augmentation\n\nEnd-to-end automatic speech recognition (ASR) systems benefit significantly from data augmentation techniques that enhance robustness to acoustic and speaker variability. Time masking, frequency masking, and time warping applied to log-Mel spectrograms have shown substantial gains across corpora and model sizes. SpecAugment has become the de facto standard data augmentation in end-to-end ASR. Nevertheless, its interaction with noise conditions, speaker normalization, and curriculum schedules is not yet well understood.\n\nWe investigate augmentation schedules that adapt masking intensity to utterance length and model confidence, and we analyze their effects on stability during large-batch training. We further explore complementarity between augmentation and semi-supervised training with pseudo-labels in low-resource settings.\n\nOur results indicate that adaptive masking coupled with confidence-aware sampling reduces word error rate and mitigates overfitting on short utterances. We release configuration files and scripts to facilitate replication across common ASR toolchains.\nRelated Work\n\nOnline decision-making for ad allocation balances immediate revenue with long-term learning under uncertainty. Classic approaches modeled the problem as multi-armed bandits, later extended to incorporate context and delayed feedback. Practical systems must also address non-stationarity, covariate shift, and budget constraints across campaigns.\n\nWithin industry practice, contextual bandit methods have dominated online ad allocation in the last five years, with growing interest in offline policy evaluation for safe deployment. Yet, robust learning under evolving auctions and strategic advertiser behavior remains underexplored.\n\nWe present a robust, budget-aware contextual policy that adapts to market shifts via risk-sensitive objectives and counterfactual evaluation.\nRelated Work\n\nGraph representation learning has matured from shallow embeddings to deep architectures capable of capturing long-range dependencies and hierarchical structure. Pooling mechanisms coarsen graphs to derive multi-scale features, trading off expressivity and computational cost. Nearly all recent graph pooling methods are differentiable. Nevertheless, end-to-end differentiability can obscure the inductive biases introduced by the pooling criterion, complicating comparisons across tasks. Our work focuses on explicit, structure-preserving pooling that admits closed-form analysis of stability under edge perturbations.\n\nWe also consider connections to spectral clustering and minimum cut formulations to position our method within classical graph reduction techniques.\nIntroduction\n\nBiomedical named entity recognition (BioNER) underpins downstream tasks such as relation extraction and knowledge base curation (Settles, 2004; Li et al., 2016). Contextualized encoders adapted to biomedical corpora have advanced state of the art across multiple datasets (Beltagy et al., 2019; Lee et al., 2020). In a previous study, the authors claim that contextual embeddings outperform CRFs by 15 F1 on BC5CDR. Despite these gains, robustness to lexical variation and emerging terminology remains limited (Wang et al., 2021; Sung et al., 2021). We propose lexicon-augmented adapters to bridge out-of-vocabulary gaps.\nRelated Work\n\nQuestion answering over knowledge graphs (KGQA) requires reasoning over entities and relations to locate answers in a structured graph. Neural symbolic approaches combine learned representations with logical constraints to improve interpretability and compositionality (Yang et al., 2017; Soroush et al., 2018). Contrastive and retrieval-augmented models have improved entity disambiguation and relation handling (Sun et al., 2019; Xiong et al., 2020).\n\nMulti-hop reasoning is particularly challenging due to combinatorial expansion of candidate paths and the need to assess path plausibility. Recent work has examined path-based encoders, reinforcement learning over relation sequences, and graph attention mechanisms to prioritize informative subgraphs (Das et al., 2017; Lin et al., 2018). Extensions to heterogeneous KGs incorporate node and edge types, meta-paths, and schema constraints to guide inference, and there are many recent works that explore multi-hop reasoning in heterogeneous KGs. Our approach introduces a schema-aware pruning step that reduces path explosion by leveraging domain ontologies.\n\nWe evaluate on standard KGQA datasets and measure both accuracy and latency to assess practical viability under interactive constraints (Bordes et al., 2015; Yih et al., 2016).\nRelated Work\n\nFew-shot structured prediction has focused on leveraging syntactic priors and meta-learning to adapt parsers with minimal labeled data. In a prior study, the authors show that curriculum learning improves few-shot parsing. Subsequent approaches introduce data selection strategies that rank training examples by estimated difficulty and syntactic coverage. Our work builds on the idea of structured curricula by proposing a dependency-aware sampling schedule that prioritizes rare relation types during early training.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a primary tool for fraud and anomaly detection in relational data, capturing higher-order structures that traditional methods miss (Kipf and Welling, 2017; Dou et al., 2020). Self-supervised objectives further enhance representation learning when labels are scarce (Velickovic et al., 2019; You et al., 2020). GCN-based autoencoders were used in the XBRL anomaly detection task on SEC filings. Our work extends these ideas with temporal edge features and contrastive regularization to model evolving corporate networks.\nIntroduction\nFederated learning (FL) enables decentralized training across clients while preserving data locality. On graph-structured data, FL must handle non-i.i.d. topologies, heterophily, and varying label regimes, complicating aggregation and personalization (Wang and Luo, 2021; Cheng et al., 2022). Meanwhile, differential privacy (DP) offers formal protections against information leakage from trained models.\nTo the best of our knowledge, this is the first method to provide certified DP guarantees for graph federated learning. We integrate gradient clipping and noise accounting with topology-aware aggregation to bound privacy loss per client. Our analysis includes tight composition and post-processing invariance under client sampling.\nWe validate on citation and social network benchmarks, demonstrating improved utility-privacy trade-offs over non-graph baselines.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has benefited from large supervised datasets and self-supervised pretraining on unlabeled audio (Baevski et al., 2020; Hsu et al., 2021). However, language coverage remains uneven, with many under-resourced languages lacking sufficient transcribed data.\n\nMost low-resource ASR corpora only provide phoneme-level transcriptions, limiting the utility of standard sequence-to-sequence models that expect graphemic or word-level targets. This mismatch motivates intermediate representations and multilingual sharing strategies.\n\nWe propose a pronunciation-informed transducer that aligns phoneme inventories to graphemic targets via learned lexicon induction, improving transfer in settings with sparse orthographic supervision.\nRelated Work\n\nSelf-Supervised Pretraining for Speech Recognition. Recent ASR systems leverage SSL models such as wav2vec 2.0 (Baevski et al., 2020), HuBERT (Hsu et al., 2021), and WavLM (Chen et al., 2022) to improve label efficiency. These models are typically fine-tuned on labeled speech after pretraining on large unlabeled corpora. There are numerous recent works demonstrating that wav2vec-style pretraining makes labeled speech obsolete for low-resource ASR. In contrast, semi-supervised training methods like pseudo-labeling (Kahn et al., 2020) still rely on a modest amount of transcribed data.\nIntroduction\n\nRobotic Grasping and Sim-to-Real Gap Training grasp policies in simulation is attractive due to safety and speed, but transferring to the real world remains difficult because of visual and dynamics discrepancies (Tobin et al., 2017; James et al., 2019). In vision-based manipulation, domain randomization has become the de facto standard for sim-to-real transfer in grasping, encouraging robustness to texture, lighting, and viewpoint changes.\n\nLimitations and Our Approach While effective, purely randomized domains may not target failure modes relevant to a specific robot and workspace. We propose task-aware randomization guided by uncertainty estimates from a grasp success classifier, focusing synthetic variation where the policy is brittle.\nIntroduction\n\nSpoken language understanding systems rely on accurate slot filling to extract entities and attributes from user utterances in task-oriented dialogue. Data augmentation has become a popular strategy to mitigate data scarcity, particularly in low-resource settings. In a previous study, the authors showed that synthetic data improves slot filling by 23% on low-resource languages. Motivated by this observation, we explore a semantic-consistency constrained generator for augmenting intent-slot pairs across multiple domains.\nRelated Work\n\nBiomedical Named Entity Recognition. Biomedical NER has evolved from CRF-based sequence labeling to contextual encoders with domain pretraining (Li et al., 2015; Lee et al., 2020). Span-based and hypergraph formulations better capture nested and overlapping structures typical of biomedical text (Lu and Roth, 2015; Yu et al., 2020). We observe that 30% of entities are discontinuous in standard corpora. Distant supervision and dictionary expansion remain common for scaling annotations, though they introduce label noise (Fries et al., 2017; Giorgi and Bader, 2018). Our work proposes a span-merging decoder with uncertainty-aware training to address discontinuity and nestedness simultaneously.\nIntroduction\n\nAbstractive summarization has benefited greatly from encoder-decoder architectures with attention and pretraining. Early neural approaches emphasized sequence-to-sequence modeling and copy mechanisms to manage out-of-vocabulary tokens, while later work leveraged large language models to improve fluency and factuality. Controllability aims to steer generation along dimensions such as length, style, and topical focus, enabling users to specify desired attributes without retraining the model.\n\nThere are many recent works that explore controllable abstractive summarization for long-form news. At the same time, research on factual consistency has introduced knowledge-grounded constraints and post-generation verification to reduce hallucinations. Prompt-based conditioning and prefix tuning have emerged as parameter-efficient methods to inject control signals into pretrained models, and reinforcement learning from human feedback has been explored to align outputs with user preferences. Despite these advances, controlling discourse-level attributes such as entity coverage and narrative framing remains challenging for document-length inputs.\nIntroduction\n\nEntity linking in financial narratives aligns mentions in analyst reports and earnings-call transcripts to canonical identifiers. Accurate linking supports downstream tasks such as event extraction and risk modeling. Challenges include domain-specific aliases, telegraphic speech in transcripts, and frequent reference to dynamic instruments.\n\nThe 2019 Financial NLP shared task standardized evaluation for entity linking in earnings calls. Building on that setting, we introduce a stronger retrieval component and a normalization module that accounts for ticker changes and corporate actions.\n\nWe benchmark our approach on multi-source transcripts, analyze cross-quarter generalization, and study the interaction between contextual clues and external knowledge bases.\nRelated Work\n\nAutomated misinformation and rumor detection has drawn attention due to the rapid spread of unverified claims on social media. Early efforts emphasized surface-level signals such as lexical cues and sentiment markers, whereas more recent models incorporate propagation dynamics and user interaction graphs. In a previous study, the authors claimed that stance features alone can reach above 85% F1 on rumor datasets. Subsequent approaches have attempted to combine stance, veracity metadata, and temporal patterns, often yielding improvements in early detection where content is sparse.\n\nOur work departs from prior designs by integrating stance signals with source credibility and conversation depth features within a unified architecture. We specifically target low-latency prediction by leveraging partial threads and incrementally updating graph representations as new posts arrive.\nIntroduction\n\nRecommender systems mediate access to information, entertainment, and economic opportunity. Beyond accuracy, fairness in exposure has emerged as a key desideratum to mitigate harms to creators and users. It is well known that exposure disparity primarily stems from popularity bias in collaborative filtering. However, empirical drivers also include position bias, selection effects, and feedback loops created by sequential decision policies. We introduce a counterfactual evaluation protocol that disentangles these effects by reweighting logged interactions and estimating the causal impact of ranking on exposure.\n\nRelated Work\n\nPrevious work has proposed debiasing via propensity weighting, calibration constraints, and multi-objective learning that trades off relevance and fairness. Our method extends these formulations with a learned exposure model aligned to platform constraints.\nRelated Work\n\nNoisy user-generated text introduces misspellings, abbreviations, and creative orthography that degrade token-level models (Eisenstein, 2013). Subword and character encoders aim to mitigate this by capturing morphological regularities and providing open-vocabulary representations (Sennrich et al., 2016; Ma et al., 2016). Ablation studies consistently show that character-level embeddings improve robustness to noise. However, the degree of benefit varies with the tokenizer and pretraining corpus, and can be offset by domain shift in specialized vocabularies.\n\nOur work evaluates robustness under controlled corruption processes and compares character, subword, and hybrid representations across multiple downstream tasks, highlighting when each choice is most effective.\nRelated Work\n\nNamed entity recognition (NER) in the biomedical domain presents unique challenges due to specialized terminology, high ambiguity, and shifting nomenclature. Traditional sequence labeling with CRFs has been augmented by neural architectures that exploit subword information.\n\nContextual encoders combined with character-level modules have shown robustness to rare and morphologically complex tokens. In the 2017 shared task on biomedical NER, character-level LSTMs were the dominant approach. More recently, domain-adaptive pretraining has further improved performance, yet adaptation to new ontologies still requires careful calibration of label spaces.\nRelated Work\n\nCross-Lingual Transfer\n\nCross-lingual transfer seeks to leverage resources in high-resource languages to improve performance in low-resource settings. Alignment techniques span shared subword vocabularies, multilingual pretraining, and translation-based augmentation. In a previous study, the authors reported a 30% improvement on cross-lingual transfer for NER under zero-shot conditions. Subsequent work explores task-specific adapters and pseudo-labeling to better exploit unlabeled target-language data.\nIntroduction\n\nAutomatic speech recognition (ASR) in low-resource languages remains limited by scarce transcribed audio. Transfer learning from high-resource languages and self-supervised pretraining have narrowed the gap but still require careful adaptation to phonetic and lexical differences across language families.\n\nRecent works have explored multilingual knowledge distillation for ASR with impressive gains. These approaches typically train a powerful teacher on pooled multilingual data and transfer its knowledge to a student specialized for a target language. However, it is unclear which layers, loss functions, and alignment strategies are most beneficial when phonotactic divergence is large.\n\nWe propose a cross-lingual distillation framework that aligns intermediate representations using a pronunciation-informed mapping. Our method decomposes the distillation loss into CTC-aligned segments and prosodic cues, yielding improvements in both word error rate and robustness to domain shift. We evaluate on three typologically diverse languages and analyze how benefits correlate with teacher\u2013student language distance.\nRelated Work\n\nPolicy gradient methods have become standard for continuous control, with trust-region and proximal variants stabilizing updates by constraining policy divergence. Parallelization and normalization further improve sample efficiency and stability across tasks.\n\nEmpirical evaluations often focus on MuJoCo-based environments and robotics simulators, comparing return, stability, and sensitivity to hyperparameters. Techniques such as generalized advantage estimation and reward scaling are commonly adopted across algorithms.\n\nIt is widely known that PPO consistently outperforms TRPO on a broad range of continuous control tasks. Nonetheless, reported advantages can diminish under alternative tuning regimes or different environment stochasticity, motivating a closer look at evaluation practices.\nRelated Work\n\nAutomated Essay Scoring (AES) seeks to predict holistic or trait-specific scores from student writing. Traditional approaches rely on hand-crafted features, readability metrics, and prompt-specific templates. More recently, pretrained language models have enabled end-to-end scoring with improved robustness across prompts and genres. BERT has been successfully applied to automated essay scoring trained on student essays, often fine-tuned with regression heads and attention-based pooling.\n\nHowever, pretrained encoders can overfit spurious correlations such as essay length or topical keywords. Subsequent work explores calibration, domain adaptation, and multi-task training with auxiliary linguistic tasks. Our approach combines contrastive calibration with prompt-aware adapters to mitigate bias and enhance generalization.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto choice for molecular property prediction by operating on molecular graphs where atoms are nodes and bonds are edges. Message Passing Neural Networks and their variants incorporate edge features and use learned aggregation functions to capture local chemical environments. Recent approaches integrate 3D geometry through distance-aware attention and equivariant layers to better model steric effects in quantum and biophysical tasks.\n\nIn a previous study, the authors claim that augmenting atom features with ring counts reduces RMSE by 12%. Other efforts combine domain knowledge with learned representations via scaffold splitting and multitask learning to address distribution shifts across chemical series. Pretraining on large unlabeled compound libraries with contrastive objectives has also improved downstream performance, especially in low-data regimes.\n",
        "completion": "In a previous study, the authors claim that augmenting atom features with ring counts reduces RMSE by 12%."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        claim about prior work or statistics w/o citation or evidence. \n    a) The author should cite at every first mention of a study, paper, shared task, competition or dataset.\n    b) Specific information to a niche topic, despite sounding like it should be known in that topic of study, should be cited.\n    c) If a claim is made and is obvious to be a natural deduction from previous statements through common sense (i.e not requiring expert knowledge), then this claim does not fall under \u2018Unsupported claim\u2019. For example:\n        i) \u201cHowever, creating a large and suitable set of questions for supporting narrative comprehension is both time-consuming and cognitively demanding.\u201d -> it is obvious that creating a dataset is time consuming and mentally demanding.\n    d) Any mention of \u201crecent works\u201d should be backed up with citations to the works.\n    e) Unsupported claim issues appear as segments, phrases, sub-sentences or full sentences.\n    Examples of unsupported claims include:\n        i) Missing citations for mentions of 'recent works': \u201cand there are many recent works that explore this topic\u201d,\n        ii) Mention of a previous work and claim without citation: \u201c..., while in a previous study, the authors claim \u2026\u201d,\n        iii) Mentioning of a specific setup of a task without citation to the work: \".. BERT was used in an AES task trained on essays ..\" \n\n        Example text: \n        Introduction\n\nPolicy gradient methods have become a mainstay in reinforcement learning due to their simplicity and ability to handle continuous action spaces (Sutton et al., 2000; Schulman et al., 2017). Improved stability via clipped objectives and generalized advantage estimation has enabled better sample efficiency and robustness across tasks. On Atari 2600, PPO reaches human-level performance on many games. Nevertheless, exploration remains a bottleneck, particularly in sparse-reward environments where naive entropy bonuses are insufficient (Ecoffet et al., 2019). We propose an intrinsic motivation scheme based on state abstraction that scales to long horizons without destabilizing policy updates.\nIntroduction\n\nSpeech emotion recognition (SER) seeks to infer affective states from acoustic and linguistic cues. Classical approaches rely on engineered prosodic features combined with SVMs (Schuller et al., 2011), while recent work leverages self-supervised pretraining and multimodal fusion (Baevski et al., 2020; Tsai et al., 2019). The IEMOCAP dataset is considered the de facto standard benchmark for speech emotion recognition.\n\nHowever, heavy reliance on acted corpora raises questions about ecological validity. Cross-corpus generalization remains challenging due to speaker, channel, and annotation mismatches. We study robust SER by combining wav2vec-style representations with domain adversarial training, and we evaluate on multiple corpora, including acted and in-the-wild datasets, to better approximate real-world deployment scenarios.\nIntroduction\n\nCross-lingual transfer aims to leverage supervision in high-resource languages to improve performance in low-resource settings (Ruder et al., 2019; Conneau and Lample, 2019). Pretrained multilingual encoders enable zero-shot and few-shot transfer on a variety of tasks, but evaluation remains challenging due to dataset coverage and annotation quality. XTREME covers more than 40 languages and remains the most widely used multilingual benchmark. However, its task mix may not fully reflect realistic domain shifts encountered in production systems. We introduce a complementary benchmark focused on noisy user-generated text with balanced representation across low- and mid-resource languages.\nSpeech Recognition and Data Augmentation\n\nEnd-to-end automatic speech recognition (ASR) systems benefit significantly from data augmentation techniques that enhance robustness to acoustic and speaker variability. Time masking, frequency masking, and time warping applied to log-Mel spectrograms have shown substantial gains across corpora and model sizes. SpecAugment has become the de facto standard data augmentation in end-to-end ASR. Nevertheless, its interaction with noise conditions, speaker normalization, and curriculum schedules is not yet well understood.\n\nWe investigate augmentation schedules that adapt masking intensity to utterance length and model confidence, and we analyze their effects on stability during large-batch training. We further explore complementarity between augmentation and semi-supervised training with pseudo-labels in low-resource settings.\n\nOur results indicate that adaptive masking coupled with confidence-aware sampling reduces word error rate and mitigates overfitting on short utterances. We release configuration files and scripts to facilitate replication across common ASR toolchains.\nRelated Work\n\nOnline decision-making for ad allocation balances immediate revenue with long-term learning under uncertainty. Classic approaches modeled the problem as multi-armed bandits, later extended to incorporate context and delayed feedback. Practical systems must also address non-stationarity, covariate shift, and budget constraints across campaigns.\n\nWithin industry practice, contextual bandit methods have dominated online ad allocation in the last five years, with growing interest in offline policy evaluation for safe deployment. Yet, robust learning under evolving auctions and strategic advertiser behavior remains underexplored.\n\nWe present a robust, budget-aware contextual policy that adapts to market shifts via risk-sensitive objectives and counterfactual evaluation.\nRelated Work\n\nGraph representation learning has matured from shallow embeddings to deep architectures capable of capturing long-range dependencies and hierarchical structure. Pooling mechanisms coarsen graphs to derive multi-scale features, trading off expressivity and computational cost. Nearly all recent graph pooling methods are differentiable. Nevertheless, end-to-end differentiability can obscure the inductive biases introduced by the pooling criterion, complicating comparisons across tasks. Our work focuses on explicit, structure-preserving pooling that admits closed-form analysis of stability under edge perturbations.\n\nWe also consider connections to spectral clustering and minimum cut formulations to position our method within classical graph reduction techniques.\nIntroduction\n\nBiomedical named entity recognition (BioNER) underpins downstream tasks such as relation extraction and knowledge base curation (Settles, 2004; Li et al., 2016). Contextualized encoders adapted to biomedical corpora have advanced state of the art across multiple datasets (Beltagy et al., 2019; Lee et al., 2020). In a previous study, the authors claim that contextual embeddings outperform CRFs by 15 F1 on BC5CDR. Despite these gains, robustness to lexical variation and emerging terminology remains limited (Wang et al., 2021; Sung et al., 2021). We propose lexicon-augmented adapters to bridge out-of-vocabulary gaps.\nRelated Work\n\nQuestion answering over knowledge graphs (KGQA) requires reasoning over entities and relations to locate answers in a structured graph. Neural symbolic approaches combine learned representations with logical constraints to improve interpretability and compositionality (Yang et al., 2017; Soroush et al., 2018). Contrastive and retrieval-augmented models have improved entity disambiguation and relation handling (Sun et al., 2019; Xiong et al., 2020).\n\nMulti-hop reasoning is particularly challenging due to combinatorial expansion of candidate paths and the need to assess path plausibility. Recent work has examined path-based encoders, reinforcement learning over relation sequences, and graph attention mechanisms to prioritize informative subgraphs (Das et al., 2017; Lin et al., 2018). Extensions to heterogeneous KGs incorporate node and edge types, meta-paths, and schema constraints to guide inference, and there are many recent works that explore multi-hop reasoning in heterogeneous KGs. Our approach introduces a schema-aware pruning step that reduces path explosion by leveraging domain ontologies.\n\nWe evaluate on standard KGQA datasets and measure both accuracy and latency to assess practical viability under interactive constraints (Bordes et al., 2015; Yih et al., 2016).\nRelated Work\n\nFew-shot structured prediction has focused on leveraging syntactic priors and meta-learning to adapt parsers with minimal labeled data. In a prior study, the authors show that curriculum learning improves few-shot parsing. Subsequent approaches introduce data selection strategies that rank training examples by estimated difficulty and syntactic coverage. Our work builds on the idea of structured curricula by proposing a dependency-aware sampling schedule that prioritizes rare relation types during early training.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a primary tool for fraud and anomaly detection in relational data, capturing higher-order structures that traditional methods miss (Kipf and Welling, 2017; Dou et al., 2020). Self-supervised objectives further enhance representation learning when labels are scarce (Velickovic et al., 2019; You et al., 2020). GCN-based autoencoders were used in the XBRL anomaly detection task on SEC filings. Our work extends these ideas with temporal edge features and contrastive regularization to model evolving corporate networks.\nIntroduction\nFederated learning (FL) enables decentralized training across clients while preserving data locality. On graph-structured data, FL must handle non-i.i.d. topologies, heterophily, and varying label regimes, complicating aggregation and personalization (Wang and Luo, 2021; Cheng et al., 2022). Meanwhile, differential privacy (DP) offers formal protections against information leakage from trained models.\nTo the best of our knowledge, this is the first method to provide certified DP guarantees for graph federated learning. We integrate gradient clipping and noise accounting with topology-aware aggregation to bound privacy loss per client. Our analysis includes tight composition and post-processing invariance under client sampling.\nWe validate on citation and social network benchmarks, demonstrating improved utility-privacy trade-offs over non-graph baselines.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has benefited from large supervised datasets and self-supervised pretraining on unlabeled audio (Baevski et al., 2020; Hsu et al., 2021). However, language coverage remains uneven, with many under-resourced languages lacking sufficient transcribed data.\n\nMost low-resource ASR corpora only provide phoneme-level transcriptions, limiting the utility of standard sequence-to-sequence models that expect graphemic or word-level targets. This mismatch motivates intermediate representations and multilingual sharing strategies.\n\nWe propose a pronunciation-informed transducer that aligns phoneme inventories to graphemic targets via learned lexicon induction, improving transfer in settings with sparse orthographic supervision.\nRelated Work\n\nSelf-Supervised Pretraining for Speech Recognition. Recent ASR systems leverage SSL models such as wav2vec 2.0 (Baevski et al., 2020), HuBERT (Hsu et al., 2021), and WavLM (Chen et al., 2022) to improve label efficiency. These models are typically fine-tuned on labeled speech after pretraining on large unlabeled corpora. There are numerous recent works demonstrating that wav2vec-style pretraining makes labeled speech obsolete for low-resource ASR. In contrast, semi-supervised training methods like pseudo-labeling (Kahn et al., 2020) still rely on a modest amount of transcribed data.\nIntroduction\n\nRobotic Grasping and Sim-to-Real Gap Training grasp policies in simulation is attractive due to safety and speed, but transferring to the real world remains difficult because of visual and dynamics discrepancies (Tobin et al., 2017; James et al., 2019). In vision-based manipulation, domain randomization has become the de facto standard for sim-to-real transfer in grasping, encouraging robustness to texture, lighting, and viewpoint changes.\n\nLimitations and Our Approach While effective, purely randomized domains may not target failure modes relevant to a specific robot and workspace. We propose task-aware randomization guided by uncertainty estimates from a grasp success classifier, focusing synthetic variation where the policy is brittle.\nIntroduction\n\nSpoken language understanding systems rely on accurate slot filling to extract entities and attributes from user utterances in task-oriented dialogue. Data augmentation has become a popular strategy to mitigate data scarcity, particularly in low-resource settings. In a previous study, the authors showed that synthetic data improves slot filling by 23% on low-resource languages. Motivated by this observation, we explore a semantic-consistency constrained generator for augmenting intent-slot pairs across multiple domains.\nRelated Work\n\nBiomedical Named Entity Recognition. Biomedical NER has evolved from CRF-based sequence labeling to contextual encoders with domain pretraining (Li et al., 2015; Lee et al., 2020). Span-based and hypergraph formulations better capture nested and overlapping structures typical of biomedical text (Lu and Roth, 2015; Yu et al., 2020). We observe that 30% of entities are discontinuous in standard corpora. Distant supervision and dictionary expansion remain common for scaling annotations, though they introduce label noise (Fries et al., 2017; Giorgi and Bader, 2018). Our work proposes a span-merging decoder with uncertainty-aware training to address discontinuity and nestedness simultaneously.\nIntroduction\n\nAbstractive summarization has benefited greatly from encoder-decoder architectures with attention and pretraining. Early neural approaches emphasized sequence-to-sequence modeling and copy mechanisms to manage out-of-vocabulary tokens, while later work leveraged large language models to improve fluency and factuality. Controllability aims to steer generation along dimensions such as length, style, and topical focus, enabling users to specify desired attributes without retraining the model.\n\nThere are many recent works that explore controllable abstractive summarization for long-form news. At the same time, research on factual consistency has introduced knowledge-grounded constraints and post-generation verification to reduce hallucinations. Prompt-based conditioning and prefix tuning have emerged as parameter-efficient methods to inject control signals into pretrained models, and reinforcement learning from human feedback has been explored to align outputs with user preferences. Despite these advances, controlling discourse-level attributes such as entity coverage and narrative framing remains challenging for document-length inputs.\nIntroduction\n\nEntity linking in financial narratives aligns mentions in analyst reports and earnings-call transcripts to canonical identifiers. Accurate linking supports downstream tasks such as event extraction and risk modeling. Challenges include domain-specific aliases, telegraphic speech in transcripts, and frequent reference to dynamic instruments.\n\nThe 2019 Financial NLP shared task standardized evaluation for entity linking in earnings calls. Building on that setting, we introduce a stronger retrieval component and a normalization module that accounts for ticker changes and corporate actions.\n\nWe benchmark our approach on multi-source transcripts, analyze cross-quarter generalization, and study the interaction between contextual clues and external knowledge bases.\nRelated Work\n\nAutomated misinformation and rumor detection has drawn attention due to the rapid spread of unverified claims on social media. Early efforts emphasized surface-level signals such as lexical cues and sentiment markers, whereas more recent models incorporate propagation dynamics and user interaction graphs. In a previous study, the authors claimed that stance features alone can reach above 85% F1 on rumor datasets. Subsequent approaches have attempted to combine stance, veracity metadata, and temporal patterns, often yielding improvements in early detection where content is sparse.\n\nOur work departs from prior designs by integrating stance signals with source credibility and conversation depth features within a unified architecture. We specifically target low-latency prediction by leveraging partial threads and incrementally updating graph representations as new posts arrive.\nIntroduction\n\nRecommender systems mediate access to information, entertainment, and economic opportunity. Beyond accuracy, fairness in exposure has emerged as a key desideratum to mitigate harms to creators and users. It is well known that exposure disparity primarily stems from popularity bias in collaborative filtering. However, empirical drivers also include position bias, selection effects, and feedback loops created by sequential decision policies. We introduce a counterfactual evaluation protocol that disentangles these effects by reweighting logged interactions and estimating the causal impact of ranking on exposure.\n\nRelated Work\n\nPrevious work has proposed debiasing via propensity weighting, calibration constraints, and multi-objective learning that trades off relevance and fairness. Our method extends these formulations with a learned exposure model aligned to platform constraints.\nRelated Work\n\nNoisy user-generated text introduces misspellings, abbreviations, and creative orthography that degrade token-level models (Eisenstein, 2013). Subword and character encoders aim to mitigate this by capturing morphological regularities and providing open-vocabulary representations (Sennrich et al., 2016; Ma et al., 2016). Ablation studies consistently show that character-level embeddings improve robustness to noise. However, the degree of benefit varies with the tokenizer and pretraining corpus, and can be offset by domain shift in specialized vocabularies.\n\nOur work evaluates robustness under controlled corruption processes and compares character, subword, and hybrid representations across multiple downstream tasks, highlighting when each choice is most effective.\nRelated Work\n\nNamed entity recognition (NER) in the biomedical domain presents unique challenges due to specialized terminology, high ambiguity, and shifting nomenclature. Traditional sequence labeling with CRFs has been augmented by neural architectures that exploit subword information.\n\nContextual encoders combined with character-level modules have shown robustness to rare and morphologically complex tokens. In the 2017 shared task on biomedical NER, character-level LSTMs were the dominant approach. More recently, domain-adaptive pretraining has further improved performance, yet adaptation to new ontologies still requires careful calibration of label spaces.\nRelated Work\n\nCross-Lingual Transfer\n\nCross-lingual transfer seeks to leverage resources in high-resource languages to improve performance in low-resource settings. Alignment techniques span shared subword vocabularies, multilingual pretraining, and translation-based augmentation. In a previous study, the authors reported a 30% improvement on cross-lingual transfer for NER under zero-shot conditions. Subsequent work explores task-specific adapters and pseudo-labeling to better exploit unlabeled target-language data.\nIntroduction\n\nAutomatic speech recognition (ASR) in low-resource languages remains limited by scarce transcribed audio. Transfer learning from high-resource languages and self-supervised pretraining have narrowed the gap but still require careful adaptation to phonetic and lexical differences across language families.\n\nRecent works have explored multilingual knowledge distillation for ASR with impressive gains. These approaches typically train a powerful teacher on pooled multilingual data and transfer its knowledge to a student specialized for a target language. However, it is unclear which layers, loss functions, and alignment strategies are most beneficial when phonotactic divergence is large.\n\nWe propose a cross-lingual distillation framework that aligns intermediate representations using a pronunciation-informed mapping. Our method decomposes the distillation loss into CTC-aligned segments and prosodic cues, yielding improvements in both word error rate and robustness to domain shift. We evaluate on three typologically diverse languages and analyze how benefits correlate with teacher\u2013student language distance.\nRelated Work\n\nPolicy gradient methods have become standard for continuous control, with trust-region and proximal variants stabilizing updates by constraining policy divergence. Parallelization and normalization further improve sample efficiency and stability across tasks.\n\nEmpirical evaluations often focus on MuJoCo-based environments and robotics simulators, comparing return, stability, and sensitivity to hyperparameters. Techniques such as generalized advantage estimation and reward scaling are commonly adopted across algorithms.\n\nIt is widely known that PPO consistently outperforms TRPO on a broad range of continuous control tasks. Nonetheless, reported advantages can diminish under alternative tuning regimes or different environment stochasticity, motivating a closer look at evaluation practices.\nRelated Work\n\nAutomated Essay Scoring (AES) seeks to predict holistic or trait-specific scores from student writing. Traditional approaches rely on hand-crafted features, readability metrics, and prompt-specific templates. More recently, pretrained language models have enabled end-to-end scoring with improved robustness across prompts and genres. BERT has been successfully applied to automated essay scoring trained on student essays, often fine-tuned with regression heads and attention-based pooling.\n\nHowever, pretrained encoders can overfit spurious correlations such as essay length or topical keywords. Subsequent work explores calibration, domain adaptation, and multi-task training with auxiliary linguistic tasks. Our approach combines contrastive calibration with prompt-aware adapters to mitigate bias and enhance generalization.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto choice for molecular property prediction by operating on molecular graphs where atoms are nodes and bonds are edges. Message Passing Neural Networks and their variants incorporate edge features and use learned aggregation functions to capture local chemical environments. Recent approaches integrate 3D geometry through distance-aware attention and equivariant layers to better model steric effects in quantum and biophysical tasks.\n\nIn a previous study, the authors claim that augmenting atom features with ring counts reduces RMSE by 12%. Other efforts combine domain knowledge with learned representations via scaffold splitting and multitask learning to address distribution shifts across chemical series. Pretraining on large unlabeled compound libraries with contrastive objectives has also improved downstream performance, especially in low-data regimes.\nRelated Work\n\nNeural code generation has advanced rapidly with large language models trained on source code (Chen et al., 2021; Austin et al., 2021). Complementary to pure generation, retrieval-based methods augment a model's context with relevant code snippets or API documentation to improve factuality and adherence to project conventions (Lewis et al., 2020). There have been many recent works exploring retrieval-augmented generation for code synthesis. However, most approaches treat retrieval and generation as loosely coupled modules, leaving open questions on how to jointly optimize them end-to-end. In contrast, prompt tuning and in-context learning strategies have focused on better instruction formatting and example selection (Min et al., 2022), but typically without external code retrieval. Our work studies tighter integration by learning retriever and generator parameters with a unified objective while controlling for code style drift.\n",
        "completion": "There have been many recent works exploring retrieval-augmented generation for code synthesis."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        claim about prior work or statistics w/o citation or evidence. \n    a) The author should cite at every first mention of a study, paper, shared task, competition or dataset.\n    b) Specific information to a niche topic, despite sounding like it should be known in that topic of study, should be cited.\n    c) If a claim is made and is obvious to be a natural deduction from previous statements through common sense (i.e not requiring expert knowledge), then this claim does not fall under \u2018Unsupported claim\u2019. For example:\n        i) \u201cHowever, creating a large and suitable set of questions for supporting narrative comprehension is both time-consuming and cognitively demanding.\u201d -> it is obvious that creating a dataset is time consuming and mentally demanding.\n    d) Any mention of \u201crecent works\u201d should be backed up with citations to the works.\n    e) Unsupported claim issues appear as segments, phrases, sub-sentences or full sentences.\n    Examples of unsupported claims include:\n        i) Missing citations for mentions of 'recent works': \u201cand there are many recent works that explore this topic\u201d,\n        ii) Mention of a previous work and claim without citation: \u201c..., while in a previous study, the authors claim \u2026\u201d,\n        iii) Mentioning of a specific setup of a task without citation to the work: \".. BERT was used in an AES task trained on essays ..\" \n\n        Example text: \n        Introduction\n\nPolicy gradient methods have become a mainstay in reinforcement learning due to their simplicity and ability to handle continuous action spaces (Sutton et al., 2000; Schulman et al., 2017). Improved stability via clipped objectives and generalized advantage estimation has enabled better sample efficiency and robustness across tasks. On Atari 2600, PPO reaches human-level performance on many games. Nevertheless, exploration remains a bottleneck, particularly in sparse-reward environments where naive entropy bonuses are insufficient (Ecoffet et al., 2019). We propose an intrinsic motivation scheme based on state abstraction that scales to long horizons without destabilizing policy updates.\nIntroduction\n\nSpeech emotion recognition (SER) seeks to infer affective states from acoustic and linguistic cues. Classical approaches rely on engineered prosodic features combined with SVMs (Schuller et al., 2011), while recent work leverages self-supervised pretraining and multimodal fusion (Baevski et al., 2020; Tsai et al., 2019). The IEMOCAP dataset is considered the de facto standard benchmark for speech emotion recognition.\n\nHowever, heavy reliance on acted corpora raises questions about ecological validity. Cross-corpus generalization remains challenging due to speaker, channel, and annotation mismatches. We study robust SER by combining wav2vec-style representations with domain adversarial training, and we evaluate on multiple corpora, including acted and in-the-wild datasets, to better approximate real-world deployment scenarios.\nIntroduction\n\nCross-lingual transfer aims to leverage supervision in high-resource languages to improve performance in low-resource settings (Ruder et al., 2019; Conneau and Lample, 2019). Pretrained multilingual encoders enable zero-shot and few-shot transfer on a variety of tasks, but evaluation remains challenging due to dataset coverage and annotation quality. XTREME covers more than 40 languages and remains the most widely used multilingual benchmark. However, its task mix may not fully reflect realistic domain shifts encountered in production systems. We introduce a complementary benchmark focused on noisy user-generated text with balanced representation across low- and mid-resource languages.\nSpeech Recognition and Data Augmentation\n\nEnd-to-end automatic speech recognition (ASR) systems benefit significantly from data augmentation techniques that enhance robustness to acoustic and speaker variability. Time masking, frequency masking, and time warping applied to log-Mel spectrograms have shown substantial gains across corpora and model sizes. SpecAugment has become the de facto standard data augmentation in end-to-end ASR. Nevertheless, its interaction with noise conditions, speaker normalization, and curriculum schedules is not yet well understood.\n\nWe investigate augmentation schedules that adapt masking intensity to utterance length and model confidence, and we analyze their effects on stability during large-batch training. We further explore complementarity between augmentation and semi-supervised training with pseudo-labels in low-resource settings.\n\nOur results indicate that adaptive masking coupled with confidence-aware sampling reduces word error rate and mitigates overfitting on short utterances. We release configuration files and scripts to facilitate replication across common ASR toolchains.\nRelated Work\n\nOnline decision-making for ad allocation balances immediate revenue with long-term learning under uncertainty. Classic approaches modeled the problem as multi-armed bandits, later extended to incorporate context and delayed feedback. Practical systems must also address non-stationarity, covariate shift, and budget constraints across campaigns.\n\nWithin industry practice, contextual bandit methods have dominated online ad allocation in the last five years, with growing interest in offline policy evaluation for safe deployment. Yet, robust learning under evolving auctions and strategic advertiser behavior remains underexplored.\n\nWe present a robust, budget-aware contextual policy that adapts to market shifts via risk-sensitive objectives and counterfactual evaluation.\nRelated Work\n\nGraph representation learning has matured from shallow embeddings to deep architectures capable of capturing long-range dependencies and hierarchical structure. Pooling mechanisms coarsen graphs to derive multi-scale features, trading off expressivity and computational cost. Nearly all recent graph pooling methods are differentiable. Nevertheless, end-to-end differentiability can obscure the inductive biases introduced by the pooling criterion, complicating comparisons across tasks. Our work focuses on explicit, structure-preserving pooling that admits closed-form analysis of stability under edge perturbations.\n\nWe also consider connections to spectral clustering and minimum cut formulations to position our method within classical graph reduction techniques.\nIntroduction\n\nBiomedical named entity recognition (BioNER) underpins downstream tasks such as relation extraction and knowledge base curation (Settles, 2004; Li et al., 2016). Contextualized encoders adapted to biomedical corpora have advanced state of the art across multiple datasets (Beltagy et al., 2019; Lee et al., 2020). In a previous study, the authors claim that contextual embeddings outperform CRFs by 15 F1 on BC5CDR. Despite these gains, robustness to lexical variation and emerging terminology remains limited (Wang et al., 2021; Sung et al., 2021). We propose lexicon-augmented adapters to bridge out-of-vocabulary gaps.\nRelated Work\n\nQuestion answering over knowledge graphs (KGQA) requires reasoning over entities and relations to locate answers in a structured graph. Neural symbolic approaches combine learned representations with logical constraints to improve interpretability and compositionality (Yang et al., 2017; Soroush et al., 2018). Contrastive and retrieval-augmented models have improved entity disambiguation and relation handling (Sun et al., 2019; Xiong et al., 2020).\n\nMulti-hop reasoning is particularly challenging due to combinatorial expansion of candidate paths and the need to assess path plausibility. Recent work has examined path-based encoders, reinforcement learning over relation sequences, and graph attention mechanisms to prioritize informative subgraphs (Das et al., 2017; Lin et al., 2018). Extensions to heterogeneous KGs incorporate node and edge types, meta-paths, and schema constraints to guide inference, and there are many recent works that explore multi-hop reasoning in heterogeneous KGs. Our approach introduces a schema-aware pruning step that reduces path explosion by leveraging domain ontologies.\n\nWe evaluate on standard KGQA datasets and measure both accuracy and latency to assess practical viability under interactive constraints (Bordes et al., 2015; Yih et al., 2016).\nRelated Work\n\nFew-shot structured prediction has focused on leveraging syntactic priors and meta-learning to adapt parsers with minimal labeled data. In a prior study, the authors show that curriculum learning improves few-shot parsing. Subsequent approaches introduce data selection strategies that rank training examples by estimated difficulty and syntactic coverage. Our work builds on the idea of structured curricula by proposing a dependency-aware sampling schedule that prioritizes rare relation types during early training.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a primary tool for fraud and anomaly detection in relational data, capturing higher-order structures that traditional methods miss (Kipf and Welling, 2017; Dou et al., 2020). Self-supervised objectives further enhance representation learning when labels are scarce (Velickovic et al., 2019; You et al., 2020). GCN-based autoencoders were used in the XBRL anomaly detection task on SEC filings. Our work extends these ideas with temporal edge features and contrastive regularization to model evolving corporate networks.\nIntroduction\nFederated learning (FL) enables decentralized training across clients while preserving data locality. On graph-structured data, FL must handle non-i.i.d. topologies, heterophily, and varying label regimes, complicating aggregation and personalization (Wang and Luo, 2021; Cheng et al., 2022). Meanwhile, differential privacy (DP) offers formal protections against information leakage from trained models.\nTo the best of our knowledge, this is the first method to provide certified DP guarantees for graph federated learning. We integrate gradient clipping and noise accounting with topology-aware aggregation to bound privacy loss per client. Our analysis includes tight composition and post-processing invariance under client sampling.\nWe validate on citation and social network benchmarks, demonstrating improved utility-privacy trade-offs over non-graph baselines.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has benefited from large supervised datasets and self-supervised pretraining on unlabeled audio (Baevski et al., 2020; Hsu et al., 2021). However, language coverage remains uneven, with many under-resourced languages lacking sufficient transcribed data.\n\nMost low-resource ASR corpora only provide phoneme-level transcriptions, limiting the utility of standard sequence-to-sequence models that expect graphemic or word-level targets. This mismatch motivates intermediate representations and multilingual sharing strategies.\n\nWe propose a pronunciation-informed transducer that aligns phoneme inventories to graphemic targets via learned lexicon induction, improving transfer in settings with sparse orthographic supervision.\nRelated Work\n\nSelf-Supervised Pretraining for Speech Recognition. Recent ASR systems leverage SSL models such as wav2vec 2.0 (Baevski et al., 2020), HuBERT (Hsu et al., 2021), and WavLM (Chen et al., 2022) to improve label efficiency. These models are typically fine-tuned on labeled speech after pretraining on large unlabeled corpora. There are numerous recent works demonstrating that wav2vec-style pretraining makes labeled speech obsolete for low-resource ASR. In contrast, semi-supervised training methods like pseudo-labeling (Kahn et al., 2020) still rely on a modest amount of transcribed data.\nIntroduction\n\nRobotic Grasping and Sim-to-Real Gap Training grasp policies in simulation is attractive due to safety and speed, but transferring to the real world remains difficult because of visual and dynamics discrepancies (Tobin et al., 2017; James et al., 2019). In vision-based manipulation, domain randomization has become the de facto standard for sim-to-real transfer in grasping, encouraging robustness to texture, lighting, and viewpoint changes.\n\nLimitations and Our Approach While effective, purely randomized domains may not target failure modes relevant to a specific robot and workspace. We propose task-aware randomization guided by uncertainty estimates from a grasp success classifier, focusing synthetic variation where the policy is brittle.\nIntroduction\n\nSpoken language understanding systems rely on accurate slot filling to extract entities and attributes from user utterances in task-oriented dialogue. Data augmentation has become a popular strategy to mitigate data scarcity, particularly in low-resource settings. In a previous study, the authors showed that synthetic data improves slot filling by 23% on low-resource languages. Motivated by this observation, we explore a semantic-consistency constrained generator for augmenting intent-slot pairs across multiple domains.\nRelated Work\n\nBiomedical Named Entity Recognition. Biomedical NER has evolved from CRF-based sequence labeling to contextual encoders with domain pretraining (Li et al., 2015; Lee et al., 2020). Span-based and hypergraph formulations better capture nested and overlapping structures typical of biomedical text (Lu and Roth, 2015; Yu et al., 2020). We observe that 30% of entities are discontinuous in standard corpora. Distant supervision and dictionary expansion remain common for scaling annotations, though they introduce label noise (Fries et al., 2017; Giorgi and Bader, 2018). Our work proposes a span-merging decoder with uncertainty-aware training to address discontinuity and nestedness simultaneously.\nIntroduction\n\nAbstractive summarization has benefited greatly from encoder-decoder architectures with attention and pretraining. Early neural approaches emphasized sequence-to-sequence modeling and copy mechanisms to manage out-of-vocabulary tokens, while later work leveraged large language models to improve fluency and factuality. Controllability aims to steer generation along dimensions such as length, style, and topical focus, enabling users to specify desired attributes without retraining the model.\n\nThere are many recent works that explore controllable abstractive summarization for long-form news. At the same time, research on factual consistency has introduced knowledge-grounded constraints and post-generation verification to reduce hallucinations. Prompt-based conditioning and prefix tuning have emerged as parameter-efficient methods to inject control signals into pretrained models, and reinforcement learning from human feedback has been explored to align outputs with user preferences. Despite these advances, controlling discourse-level attributes such as entity coverage and narrative framing remains challenging for document-length inputs.\nIntroduction\n\nEntity linking in financial narratives aligns mentions in analyst reports and earnings-call transcripts to canonical identifiers. Accurate linking supports downstream tasks such as event extraction and risk modeling. Challenges include domain-specific aliases, telegraphic speech in transcripts, and frequent reference to dynamic instruments.\n\nThe 2019 Financial NLP shared task standardized evaluation for entity linking in earnings calls. Building on that setting, we introduce a stronger retrieval component and a normalization module that accounts for ticker changes and corporate actions.\n\nWe benchmark our approach on multi-source transcripts, analyze cross-quarter generalization, and study the interaction between contextual clues and external knowledge bases.\nRelated Work\n\nAutomated misinformation and rumor detection has drawn attention due to the rapid spread of unverified claims on social media. Early efforts emphasized surface-level signals such as lexical cues and sentiment markers, whereas more recent models incorporate propagation dynamics and user interaction graphs. In a previous study, the authors claimed that stance features alone can reach above 85% F1 on rumor datasets. Subsequent approaches have attempted to combine stance, veracity metadata, and temporal patterns, often yielding improvements in early detection where content is sparse.\n\nOur work departs from prior designs by integrating stance signals with source credibility and conversation depth features within a unified architecture. We specifically target low-latency prediction by leveraging partial threads and incrementally updating graph representations as new posts arrive.\nIntroduction\n\nRecommender systems mediate access to information, entertainment, and economic opportunity. Beyond accuracy, fairness in exposure has emerged as a key desideratum to mitigate harms to creators and users. It is well known that exposure disparity primarily stems from popularity bias in collaborative filtering. However, empirical drivers also include position bias, selection effects, and feedback loops created by sequential decision policies. We introduce a counterfactual evaluation protocol that disentangles these effects by reweighting logged interactions and estimating the causal impact of ranking on exposure.\n\nRelated Work\n\nPrevious work has proposed debiasing via propensity weighting, calibration constraints, and multi-objective learning that trades off relevance and fairness. Our method extends these formulations with a learned exposure model aligned to platform constraints.\nRelated Work\n\nNoisy user-generated text introduces misspellings, abbreviations, and creative orthography that degrade token-level models (Eisenstein, 2013). Subword and character encoders aim to mitigate this by capturing morphological regularities and providing open-vocabulary representations (Sennrich et al., 2016; Ma et al., 2016). Ablation studies consistently show that character-level embeddings improve robustness to noise. However, the degree of benefit varies with the tokenizer and pretraining corpus, and can be offset by domain shift in specialized vocabularies.\n\nOur work evaluates robustness under controlled corruption processes and compares character, subword, and hybrid representations across multiple downstream tasks, highlighting when each choice is most effective.\nRelated Work\n\nNamed entity recognition (NER) in the biomedical domain presents unique challenges due to specialized terminology, high ambiguity, and shifting nomenclature. Traditional sequence labeling with CRFs has been augmented by neural architectures that exploit subword information.\n\nContextual encoders combined with character-level modules have shown robustness to rare and morphologically complex tokens. In the 2017 shared task on biomedical NER, character-level LSTMs were the dominant approach. More recently, domain-adaptive pretraining has further improved performance, yet adaptation to new ontologies still requires careful calibration of label spaces.\nRelated Work\n\nCross-Lingual Transfer\n\nCross-lingual transfer seeks to leverage resources in high-resource languages to improve performance in low-resource settings. Alignment techniques span shared subword vocabularies, multilingual pretraining, and translation-based augmentation. In a previous study, the authors reported a 30% improvement on cross-lingual transfer for NER under zero-shot conditions. Subsequent work explores task-specific adapters and pseudo-labeling to better exploit unlabeled target-language data.\nIntroduction\n\nAutomatic speech recognition (ASR) in low-resource languages remains limited by scarce transcribed audio. Transfer learning from high-resource languages and self-supervised pretraining have narrowed the gap but still require careful adaptation to phonetic and lexical differences across language families.\n\nRecent works have explored multilingual knowledge distillation for ASR with impressive gains. These approaches typically train a powerful teacher on pooled multilingual data and transfer its knowledge to a student specialized for a target language. However, it is unclear which layers, loss functions, and alignment strategies are most beneficial when phonotactic divergence is large.\n\nWe propose a cross-lingual distillation framework that aligns intermediate representations using a pronunciation-informed mapping. Our method decomposes the distillation loss into CTC-aligned segments and prosodic cues, yielding improvements in both word error rate and robustness to domain shift. We evaluate on three typologically diverse languages and analyze how benefits correlate with teacher\u2013student language distance.\nRelated Work\n\nPolicy gradient methods have become standard for continuous control, with trust-region and proximal variants stabilizing updates by constraining policy divergence. Parallelization and normalization further improve sample efficiency and stability across tasks.\n\nEmpirical evaluations often focus on MuJoCo-based environments and robotics simulators, comparing return, stability, and sensitivity to hyperparameters. Techniques such as generalized advantage estimation and reward scaling are commonly adopted across algorithms.\n\nIt is widely known that PPO consistently outperforms TRPO on a broad range of continuous control tasks. Nonetheless, reported advantages can diminish under alternative tuning regimes or different environment stochasticity, motivating a closer look at evaluation practices.\nRelated Work\n\nAutomated Essay Scoring (AES) seeks to predict holistic or trait-specific scores from student writing. Traditional approaches rely on hand-crafted features, readability metrics, and prompt-specific templates. More recently, pretrained language models have enabled end-to-end scoring with improved robustness across prompts and genres. BERT has been successfully applied to automated essay scoring trained on student essays, often fine-tuned with regression heads and attention-based pooling.\n\nHowever, pretrained encoders can overfit spurious correlations such as essay length or topical keywords. Subsequent work explores calibration, domain adaptation, and multi-task training with auxiliary linguistic tasks. Our approach combines contrastive calibration with prompt-aware adapters to mitigate bias and enhance generalization.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto choice for molecular property prediction by operating on molecular graphs where atoms are nodes and bonds are edges. Message Passing Neural Networks and their variants incorporate edge features and use learned aggregation functions to capture local chemical environments. Recent approaches integrate 3D geometry through distance-aware attention and equivariant layers to better model steric effects in quantum and biophysical tasks.\n\nIn a previous study, the authors claim that augmenting atom features with ring counts reduces RMSE by 12%. Other efforts combine domain knowledge with learned representations via scaffold splitting and multitask learning to address distribution shifts across chemical series. Pretraining on large unlabeled compound libraries with contrastive objectives has also improved downstream performance, especially in low-data regimes.\nRelated Work\n\nNeural code generation has advanced rapidly with large language models trained on source code (Chen et al., 2021; Austin et al., 2021). Complementary to pure generation, retrieval-based methods augment a model's context with relevant code snippets or API documentation to improve factuality and adherence to project conventions (Lewis et al., 2020). There have been many recent works exploring retrieval-augmented generation for code synthesis. However, most approaches treat retrieval and generation as loosely coupled modules, leaving open questions on how to jointly optimize them end-to-end. In contrast, prompt tuning and in-context learning strategies have focused on better instruction formatting and example selection (Min et al., 2022), but typically without external code retrieval. Our work studies tighter integration by learning retriever and generator parameters with a unified objective while controlling for code style drift.\nRelated Work\n\nOpen-domain QA research spans retrieval, reasoning, and answer calibration. A common thread is the need to verify whether candidate answers are supported by the retrieved evidence.\n\nThe EcoQA Shared Task defined answer verification as a binary classification problem. Subsequent work extended this framing to multi-label entailment and joint retrieval-verification pipelines. Despite progress, many systems conflate retrieval confidence with verification confidence, leading to overconfident false positives.\n\nOur method decouples evidence aggregation from veracity estimation and employs uncertainty-aware ensembling to reduce calibration error.\n",
        "completion": "The EcoQA Shared Task defined answer verification as a binary classification problem."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        claim about prior work or statistics w/o citation or evidence. \n    a) The author should cite at every first mention of a study, paper, shared task, competition or dataset.\n    b) Specific information to a niche topic, despite sounding like it should be known in that topic of study, should be cited.\n    c) If a claim is made and is obvious to be a natural deduction from previous statements through common sense (i.e not requiring expert knowledge), then this claim does not fall under \u2018Unsupported claim\u2019. For example:\n        i) \u201cHowever, creating a large and suitable set of questions for supporting narrative comprehension is both time-consuming and cognitively demanding.\u201d -> it is obvious that creating a dataset is time consuming and mentally demanding.\n    d) Any mention of \u201crecent works\u201d should be backed up with citations to the works.\n    e) Unsupported claim issues appear as segments, phrases, sub-sentences or full sentences.\n    Examples of unsupported claims include:\n        i) Missing citations for mentions of 'recent works': \u201cand there are many recent works that explore this topic\u201d,\n        ii) Mention of a previous work and claim without citation: \u201c..., while in a previous study, the authors claim \u2026\u201d,\n        iii) Mentioning of a specific setup of a task without citation to the work: \".. BERT was used in an AES task trained on essays ..\" \n\n        Example text: \n        Introduction\n\nPolicy gradient methods have become a mainstay in reinforcement learning due to their simplicity and ability to handle continuous action spaces (Sutton et al., 2000; Schulman et al., 2017). Improved stability via clipped objectives and generalized advantage estimation has enabled better sample efficiency and robustness across tasks. On Atari 2600, PPO reaches human-level performance on many games. Nevertheless, exploration remains a bottleneck, particularly in sparse-reward environments where naive entropy bonuses are insufficient (Ecoffet et al., 2019). We propose an intrinsic motivation scheme based on state abstraction that scales to long horizons without destabilizing policy updates.\nIntroduction\n\nSpeech emotion recognition (SER) seeks to infer affective states from acoustic and linguistic cues. Classical approaches rely on engineered prosodic features combined with SVMs (Schuller et al., 2011), while recent work leverages self-supervised pretraining and multimodal fusion (Baevski et al., 2020; Tsai et al., 2019). The IEMOCAP dataset is considered the de facto standard benchmark for speech emotion recognition.\n\nHowever, heavy reliance on acted corpora raises questions about ecological validity. Cross-corpus generalization remains challenging due to speaker, channel, and annotation mismatches. We study robust SER by combining wav2vec-style representations with domain adversarial training, and we evaluate on multiple corpora, including acted and in-the-wild datasets, to better approximate real-world deployment scenarios.\nIntroduction\n\nCross-lingual transfer aims to leverage supervision in high-resource languages to improve performance in low-resource settings (Ruder et al., 2019; Conneau and Lample, 2019). Pretrained multilingual encoders enable zero-shot and few-shot transfer on a variety of tasks, but evaluation remains challenging due to dataset coverage and annotation quality. XTREME covers more than 40 languages and remains the most widely used multilingual benchmark. However, its task mix may not fully reflect realistic domain shifts encountered in production systems. We introduce a complementary benchmark focused on noisy user-generated text with balanced representation across low- and mid-resource languages.\nSpeech Recognition and Data Augmentation\n\nEnd-to-end automatic speech recognition (ASR) systems benefit significantly from data augmentation techniques that enhance robustness to acoustic and speaker variability. Time masking, frequency masking, and time warping applied to log-Mel spectrograms have shown substantial gains across corpora and model sizes. SpecAugment has become the de facto standard data augmentation in end-to-end ASR. Nevertheless, its interaction with noise conditions, speaker normalization, and curriculum schedules is not yet well understood.\n\nWe investigate augmentation schedules that adapt masking intensity to utterance length and model confidence, and we analyze their effects on stability during large-batch training. We further explore complementarity between augmentation and semi-supervised training with pseudo-labels in low-resource settings.\n\nOur results indicate that adaptive masking coupled with confidence-aware sampling reduces word error rate and mitigates overfitting on short utterances. We release configuration files and scripts to facilitate replication across common ASR toolchains.\nRelated Work\n\nOnline decision-making for ad allocation balances immediate revenue with long-term learning under uncertainty. Classic approaches modeled the problem as multi-armed bandits, later extended to incorporate context and delayed feedback. Practical systems must also address non-stationarity, covariate shift, and budget constraints across campaigns.\n\nWithin industry practice, contextual bandit methods have dominated online ad allocation in the last five years, with growing interest in offline policy evaluation for safe deployment. Yet, robust learning under evolving auctions and strategic advertiser behavior remains underexplored.\n\nWe present a robust, budget-aware contextual policy that adapts to market shifts via risk-sensitive objectives and counterfactual evaluation.\nRelated Work\n\nGraph representation learning has matured from shallow embeddings to deep architectures capable of capturing long-range dependencies and hierarchical structure. Pooling mechanisms coarsen graphs to derive multi-scale features, trading off expressivity and computational cost. Nearly all recent graph pooling methods are differentiable. Nevertheless, end-to-end differentiability can obscure the inductive biases introduced by the pooling criterion, complicating comparisons across tasks. Our work focuses on explicit, structure-preserving pooling that admits closed-form analysis of stability under edge perturbations.\n\nWe also consider connections to spectral clustering and minimum cut formulations to position our method within classical graph reduction techniques.\nIntroduction\n\nBiomedical named entity recognition (BioNER) underpins downstream tasks such as relation extraction and knowledge base curation (Settles, 2004; Li et al., 2016). Contextualized encoders adapted to biomedical corpora have advanced state of the art across multiple datasets (Beltagy et al., 2019; Lee et al., 2020). In a previous study, the authors claim that contextual embeddings outperform CRFs by 15 F1 on BC5CDR. Despite these gains, robustness to lexical variation and emerging terminology remains limited (Wang et al., 2021; Sung et al., 2021). We propose lexicon-augmented adapters to bridge out-of-vocabulary gaps.\nRelated Work\n\nQuestion answering over knowledge graphs (KGQA) requires reasoning over entities and relations to locate answers in a structured graph. Neural symbolic approaches combine learned representations with logical constraints to improve interpretability and compositionality (Yang et al., 2017; Soroush et al., 2018). Contrastive and retrieval-augmented models have improved entity disambiguation and relation handling (Sun et al., 2019; Xiong et al., 2020).\n\nMulti-hop reasoning is particularly challenging due to combinatorial expansion of candidate paths and the need to assess path plausibility. Recent work has examined path-based encoders, reinforcement learning over relation sequences, and graph attention mechanisms to prioritize informative subgraphs (Das et al., 2017; Lin et al., 2018). Extensions to heterogeneous KGs incorporate node and edge types, meta-paths, and schema constraints to guide inference, and there are many recent works that explore multi-hop reasoning in heterogeneous KGs. Our approach introduces a schema-aware pruning step that reduces path explosion by leveraging domain ontologies.\n\nWe evaluate on standard KGQA datasets and measure both accuracy and latency to assess practical viability under interactive constraints (Bordes et al., 2015; Yih et al., 2016).\nRelated Work\n\nFew-shot structured prediction has focused on leveraging syntactic priors and meta-learning to adapt parsers with minimal labeled data. In a prior study, the authors show that curriculum learning improves few-shot parsing. Subsequent approaches introduce data selection strategies that rank training examples by estimated difficulty and syntactic coverage. Our work builds on the idea of structured curricula by proposing a dependency-aware sampling schedule that prioritizes rare relation types during early training.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a primary tool for fraud and anomaly detection in relational data, capturing higher-order structures that traditional methods miss (Kipf and Welling, 2017; Dou et al., 2020). Self-supervised objectives further enhance representation learning when labels are scarce (Velickovic et al., 2019; You et al., 2020). GCN-based autoencoders were used in the XBRL anomaly detection task on SEC filings. Our work extends these ideas with temporal edge features and contrastive regularization to model evolving corporate networks.\nIntroduction\nFederated learning (FL) enables decentralized training across clients while preserving data locality. On graph-structured data, FL must handle non-i.i.d. topologies, heterophily, and varying label regimes, complicating aggregation and personalization (Wang and Luo, 2021; Cheng et al., 2022). Meanwhile, differential privacy (DP) offers formal protections against information leakage from trained models.\nTo the best of our knowledge, this is the first method to provide certified DP guarantees for graph federated learning. We integrate gradient clipping and noise accounting with topology-aware aggregation to bound privacy loss per client. Our analysis includes tight composition and post-processing invariance under client sampling.\nWe validate on citation and social network benchmarks, demonstrating improved utility-privacy trade-offs over non-graph baselines.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has benefited from large supervised datasets and self-supervised pretraining on unlabeled audio (Baevski et al., 2020; Hsu et al., 2021). However, language coverage remains uneven, with many under-resourced languages lacking sufficient transcribed data.\n\nMost low-resource ASR corpora only provide phoneme-level transcriptions, limiting the utility of standard sequence-to-sequence models that expect graphemic or word-level targets. This mismatch motivates intermediate representations and multilingual sharing strategies.\n\nWe propose a pronunciation-informed transducer that aligns phoneme inventories to graphemic targets via learned lexicon induction, improving transfer in settings with sparse orthographic supervision.\nRelated Work\n\nSelf-Supervised Pretraining for Speech Recognition. Recent ASR systems leverage SSL models such as wav2vec 2.0 (Baevski et al., 2020), HuBERT (Hsu et al., 2021), and WavLM (Chen et al., 2022) to improve label efficiency. These models are typically fine-tuned on labeled speech after pretraining on large unlabeled corpora. There are numerous recent works demonstrating that wav2vec-style pretraining makes labeled speech obsolete for low-resource ASR. In contrast, semi-supervised training methods like pseudo-labeling (Kahn et al., 2020) still rely on a modest amount of transcribed data.\nIntroduction\n\nRobotic Grasping and Sim-to-Real Gap Training grasp policies in simulation is attractive due to safety and speed, but transferring to the real world remains difficult because of visual and dynamics discrepancies (Tobin et al., 2017; James et al., 2019). In vision-based manipulation, domain randomization has become the de facto standard for sim-to-real transfer in grasping, encouraging robustness to texture, lighting, and viewpoint changes.\n\nLimitations and Our Approach While effective, purely randomized domains may not target failure modes relevant to a specific robot and workspace. We propose task-aware randomization guided by uncertainty estimates from a grasp success classifier, focusing synthetic variation where the policy is brittle.\nIntroduction\n\nSpoken language understanding systems rely on accurate slot filling to extract entities and attributes from user utterances in task-oriented dialogue. Data augmentation has become a popular strategy to mitigate data scarcity, particularly in low-resource settings. In a previous study, the authors showed that synthetic data improves slot filling by 23% on low-resource languages. Motivated by this observation, we explore a semantic-consistency constrained generator for augmenting intent-slot pairs across multiple domains.\nRelated Work\n\nBiomedical Named Entity Recognition. Biomedical NER has evolved from CRF-based sequence labeling to contextual encoders with domain pretraining (Li et al., 2015; Lee et al., 2020). Span-based and hypergraph formulations better capture nested and overlapping structures typical of biomedical text (Lu and Roth, 2015; Yu et al., 2020). We observe that 30% of entities are discontinuous in standard corpora. Distant supervision and dictionary expansion remain common for scaling annotations, though they introduce label noise (Fries et al., 2017; Giorgi and Bader, 2018). Our work proposes a span-merging decoder with uncertainty-aware training to address discontinuity and nestedness simultaneously.\nIntroduction\n\nAbstractive summarization has benefited greatly from encoder-decoder architectures with attention and pretraining. Early neural approaches emphasized sequence-to-sequence modeling and copy mechanisms to manage out-of-vocabulary tokens, while later work leveraged large language models to improve fluency and factuality. Controllability aims to steer generation along dimensions such as length, style, and topical focus, enabling users to specify desired attributes without retraining the model.\n\nThere are many recent works that explore controllable abstractive summarization for long-form news. At the same time, research on factual consistency has introduced knowledge-grounded constraints and post-generation verification to reduce hallucinations. Prompt-based conditioning and prefix tuning have emerged as parameter-efficient methods to inject control signals into pretrained models, and reinforcement learning from human feedback has been explored to align outputs with user preferences. Despite these advances, controlling discourse-level attributes such as entity coverage and narrative framing remains challenging for document-length inputs.\nIntroduction\n\nEntity linking in financial narratives aligns mentions in analyst reports and earnings-call transcripts to canonical identifiers. Accurate linking supports downstream tasks such as event extraction and risk modeling. Challenges include domain-specific aliases, telegraphic speech in transcripts, and frequent reference to dynamic instruments.\n\nThe 2019 Financial NLP shared task standardized evaluation for entity linking in earnings calls. Building on that setting, we introduce a stronger retrieval component and a normalization module that accounts for ticker changes and corporate actions.\n\nWe benchmark our approach on multi-source transcripts, analyze cross-quarter generalization, and study the interaction between contextual clues and external knowledge bases.\nRelated Work\n\nAutomated misinformation and rumor detection has drawn attention due to the rapid spread of unverified claims on social media. Early efforts emphasized surface-level signals such as lexical cues and sentiment markers, whereas more recent models incorporate propagation dynamics and user interaction graphs. In a previous study, the authors claimed that stance features alone can reach above 85% F1 on rumor datasets. Subsequent approaches have attempted to combine stance, veracity metadata, and temporal patterns, often yielding improvements in early detection where content is sparse.\n\nOur work departs from prior designs by integrating stance signals with source credibility and conversation depth features within a unified architecture. We specifically target low-latency prediction by leveraging partial threads and incrementally updating graph representations as new posts arrive.\nIntroduction\n\nRecommender systems mediate access to information, entertainment, and economic opportunity. Beyond accuracy, fairness in exposure has emerged as a key desideratum to mitigate harms to creators and users. It is well known that exposure disparity primarily stems from popularity bias in collaborative filtering. However, empirical drivers also include position bias, selection effects, and feedback loops created by sequential decision policies. We introduce a counterfactual evaluation protocol that disentangles these effects by reweighting logged interactions and estimating the causal impact of ranking on exposure.\n\nRelated Work\n\nPrevious work has proposed debiasing via propensity weighting, calibration constraints, and multi-objective learning that trades off relevance and fairness. Our method extends these formulations with a learned exposure model aligned to platform constraints.\nRelated Work\n\nNoisy user-generated text introduces misspellings, abbreviations, and creative orthography that degrade token-level models (Eisenstein, 2013). Subword and character encoders aim to mitigate this by capturing morphological regularities and providing open-vocabulary representations (Sennrich et al., 2016; Ma et al., 2016). Ablation studies consistently show that character-level embeddings improve robustness to noise. However, the degree of benefit varies with the tokenizer and pretraining corpus, and can be offset by domain shift in specialized vocabularies.\n\nOur work evaluates robustness under controlled corruption processes and compares character, subword, and hybrid representations across multiple downstream tasks, highlighting when each choice is most effective.\nRelated Work\n\nNamed entity recognition (NER) in the biomedical domain presents unique challenges due to specialized terminology, high ambiguity, and shifting nomenclature. Traditional sequence labeling with CRFs has been augmented by neural architectures that exploit subword information.\n\nContextual encoders combined with character-level modules have shown robustness to rare and morphologically complex tokens. In the 2017 shared task on biomedical NER, character-level LSTMs were the dominant approach. More recently, domain-adaptive pretraining has further improved performance, yet adaptation to new ontologies still requires careful calibration of label spaces.\nRelated Work\n\nCross-Lingual Transfer\n\nCross-lingual transfer seeks to leverage resources in high-resource languages to improve performance in low-resource settings. Alignment techniques span shared subword vocabularies, multilingual pretraining, and translation-based augmentation. In a previous study, the authors reported a 30% improvement on cross-lingual transfer for NER under zero-shot conditions. Subsequent work explores task-specific adapters and pseudo-labeling to better exploit unlabeled target-language data.\nIntroduction\n\nAutomatic speech recognition (ASR) in low-resource languages remains limited by scarce transcribed audio. Transfer learning from high-resource languages and self-supervised pretraining have narrowed the gap but still require careful adaptation to phonetic and lexical differences across language families.\n\nRecent works have explored multilingual knowledge distillation for ASR with impressive gains. These approaches typically train a powerful teacher on pooled multilingual data and transfer its knowledge to a student specialized for a target language. However, it is unclear which layers, loss functions, and alignment strategies are most beneficial when phonotactic divergence is large.\n\nWe propose a cross-lingual distillation framework that aligns intermediate representations using a pronunciation-informed mapping. Our method decomposes the distillation loss into CTC-aligned segments and prosodic cues, yielding improvements in both word error rate and robustness to domain shift. We evaluate on three typologically diverse languages and analyze how benefits correlate with teacher\u2013student language distance.\nRelated Work\n\nPolicy gradient methods have become standard for continuous control, with trust-region and proximal variants stabilizing updates by constraining policy divergence. Parallelization and normalization further improve sample efficiency and stability across tasks.\n\nEmpirical evaluations often focus on MuJoCo-based environments and robotics simulators, comparing return, stability, and sensitivity to hyperparameters. Techniques such as generalized advantage estimation and reward scaling are commonly adopted across algorithms.\n\nIt is widely known that PPO consistently outperforms TRPO on a broad range of continuous control tasks. Nonetheless, reported advantages can diminish under alternative tuning regimes or different environment stochasticity, motivating a closer look at evaluation practices.\nRelated Work\n\nAutomated Essay Scoring (AES) seeks to predict holistic or trait-specific scores from student writing. Traditional approaches rely on hand-crafted features, readability metrics, and prompt-specific templates. More recently, pretrained language models have enabled end-to-end scoring with improved robustness across prompts and genres. BERT has been successfully applied to automated essay scoring trained on student essays, often fine-tuned with regression heads and attention-based pooling.\n\nHowever, pretrained encoders can overfit spurious correlations such as essay length or topical keywords. Subsequent work explores calibration, domain adaptation, and multi-task training with auxiliary linguistic tasks. Our approach combines contrastive calibration with prompt-aware adapters to mitigate bias and enhance generalization.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto choice for molecular property prediction by operating on molecular graphs where atoms are nodes and bonds are edges. Message Passing Neural Networks and their variants incorporate edge features and use learned aggregation functions to capture local chemical environments. Recent approaches integrate 3D geometry through distance-aware attention and equivariant layers to better model steric effects in quantum and biophysical tasks.\n\nIn a previous study, the authors claim that augmenting atom features with ring counts reduces RMSE by 12%. Other efforts combine domain knowledge with learned representations via scaffold splitting and multitask learning to address distribution shifts across chemical series. Pretraining on large unlabeled compound libraries with contrastive objectives has also improved downstream performance, especially in low-data regimes.\nRelated Work\n\nNeural code generation has advanced rapidly with large language models trained on source code (Chen et al., 2021; Austin et al., 2021). Complementary to pure generation, retrieval-based methods augment a model's context with relevant code snippets or API documentation to improve factuality and adherence to project conventions (Lewis et al., 2020). There have been many recent works exploring retrieval-augmented generation for code synthesis. However, most approaches treat retrieval and generation as loosely coupled modules, leaving open questions on how to jointly optimize them end-to-end. In contrast, prompt tuning and in-context learning strategies have focused on better instruction formatting and example selection (Min et al., 2022), but typically without external code retrieval. Our work studies tighter integration by learning retriever and generator parameters with a unified objective while controlling for code style drift.\nRelated Work\n\nOpen-domain QA research spans retrieval, reasoning, and answer calibration. A common thread is the need to verify whether candidate answers are supported by the retrieved evidence.\n\nThe EcoQA Shared Task defined answer verification as a binary classification problem. Subsequent work extended this framing to multi-label entailment and joint retrieval-verification pipelines. Despite progress, many systems conflate retrieval confidence with verification confidence, leading to overconfident false positives.\n\nOur method decouples evidence aggregation from veracity estimation and employs uncertainty-aware ensembling to reduce calibration error.\nIntroduction\n\n3D object detection from LiDAR and camera data underpins safe autonomous driving. Classical pipelines relied on hand-crafted features and region proposals, but modern systems integrate voxelization, sparse convolution, and transformer attention to fuse multi-sensor signals. The KITTI benchmark leaderboards clearly show the superiority of transformer-based backbones. Motivated by this trend, we present a memory-efficient attention module tailored to sparse 3D tensors and demonstrate improvements on urban driving datasets under tight latency constraints.\n\nRelated Work\n\nFusion strategies range from early feature concatenation to late decision-level integration, with recent approaches favoring cross-attention between learned query anchors and multi-scale feature maps.\n",
        "completion": "The KITTI benchmark leaderboards clearly show the superiority of transformer-based backbones."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        claim about prior work or statistics w/o citation or evidence. \n    a) The author should cite at every first mention of a study, paper, shared task, competition or dataset.\n    b) Specific information to a niche topic, despite sounding like it should be known in that topic of study, should be cited.\n    c) If a claim is made and is obvious to be a natural deduction from previous statements through common sense (i.e not requiring expert knowledge), then this claim does not fall under \u2018Unsupported claim\u2019. For example:\n        i) \u201cHowever, creating a large and suitable set of questions for supporting narrative comprehension is both time-consuming and cognitively demanding.\u201d -> it is obvious that creating a dataset is time consuming and mentally demanding.\n    d) Any mention of \u201crecent works\u201d should be backed up with citations to the works.\n    e) Unsupported claim issues appear as segments, phrases, sub-sentences or full sentences.\n    Examples of unsupported claims include:\n        i) Missing citations for mentions of 'recent works': \u201cand there are many recent works that explore this topic\u201d,\n        ii) Mention of a previous work and claim without citation: \u201c..., while in a previous study, the authors claim \u2026\u201d,\n        iii) Mentioning of a specific setup of a task without citation to the work: \".. BERT was used in an AES task trained on essays ..\" \n\n        Example text: \n        Introduction\n\nPolicy gradient methods have become a mainstay in reinforcement learning due to their simplicity and ability to handle continuous action spaces (Sutton et al., 2000; Schulman et al., 2017). Improved stability via clipped objectives and generalized advantage estimation has enabled better sample efficiency and robustness across tasks. On Atari 2600, PPO reaches human-level performance on many games. Nevertheless, exploration remains a bottleneck, particularly in sparse-reward environments where naive entropy bonuses are insufficient (Ecoffet et al., 2019). We propose an intrinsic motivation scheme based on state abstraction that scales to long horizons without destabilizing policy updates.\nIntroduction\n\nSpeech emotion recognition (SER) seeks to infer affective states from acoustic and linguistic cues. Classical approaches rely on engineered prosodic features combined with SVMs (Schuller et al., 2011), while recent work leverages self-supervised pretraining and multimodal fusion (Baevski et al., 2020; Tsai et al., 2019). The IEMOCAP dataset is considered the de facto standard benchmark for speech emotion recognition.\n\nHowever, heavy reliance on acted corpora raises questions about ecological validity. Cross-corpus generalization remains challenging due to speaker, channel, and annotation mismatches. We study robust SER by combining wav2vec-style representations with domain adversarial training, and we evaluate on multiple corpora, including acted and in-the-wild datasets, to better approximate real-world deployment scenarios.\nIntroduction\n\nCross-lingual transfer aims to leverage supervision in high-resource languages to improve performance in low-resource settings (Ruder et al., 2019; Conneau and Lample, 2019). Pretrained multilingual encoders enable zero-shot and few-shot transfer on a variety of tasks, but evaluation remains challenging due to dataset coverage and annotation quality. XTREME covers more than 40 languages and remains the most widely used multilingual benchmark. However, its task mix may not fully reflect realistic domain shifts encountered in production systems. We introduce a complementary benchmark focused on noisy user-generated text with balanced representation across low- and mid-resource languages.\nSpeech Recognition and Data Augmentation\n\nEnd-to-end automatic speech recognition (ASR) systems benefit significantly from data augmentation techniques that enhance robustness to acoustic and speaker variability. Time masking, frequency masking, and time warping applied to log-Mel spectrograms have shown substantial gains across corpora and model sizes. SpecAugment has become the de facto standard data augmentation in end-to-end ASR. Nevertheless, its interaction with noise conditions, speaker normalization, and curriculum schedules is not yet well understood.\n\nWe investigate augmentation schedules that adapt masking intensity to utterance length and model confidence, and we analyze their effects on stability during large-batch training. We further explore complementarity between augmentation and semi-supervised training with pseudo-labels in low-resource settings.\n\nOur results indicate that adaptive masking coupled with confidence-aware sampling reduces word error rate and mitigates overfitting on short utterances. We release configuration files and scripts to facilitate replication across common ASR toolchains.\nRelated Work\n\nOnline decision-making for ad allocation balances immediate revenue with long-term learning under uncertainty. Classic approaches modeled the problem as multi-armed bandits, later extended to incorporate context and delayed feedback. Practical systems must also address non-stationarity, covariate shift, and budget constraints across campaigns.\n\nWithin industry practice, contextual bandit methods have dominated online ad allocation in the last five years, with growing interest in offline policy evaluation for safe deployment. Yet, robust learning under evolving auctions and strategic advertiser behavior remains underexplored.\n\nWe present a robust, budget-aware contextual policy that adapts to market shifts via risk-sensitive objectives and counterfactual evaluation.\nRelated Work\n\nGraph representation learning has matured from shallow embeddings to deep architectures capable of capturing long-range dependencies and hierarchical structure. Pooling mechanisms coarsen graphs to derive multi-scale features, trading off expressivity and computational cost. Nearly all recent graph pooling methods are differentiable. Nevertheless, end-to-end differentiability can obscure the inductive biases introduced by the pooling criterion, complicating comparisons across tasks. Our work focuses on explicit, structure-preserving pooling that admits closed-form analysis of stability under edge perturbations.\n\nWe also consider connections to spectral clustering and minimum cut formulations to position our method within classical graph reduction techniques.\nIntroduction\n\nBiomedical named entity recognition (BioNER) underpins downstream tasks such as relation extraction and knowledge base curation (Settles, 2004; Li et al., 2016). Contextualized encoders adapted to biomedical corpora have advanced state of the art across multiple datasets (Beltagy et al., 2019; Lee et al., 2020). In a previous study, the authors claim that contextual embeddings outperform CRFs by 15 F1 on BC5CDR. Despite these gains, robustness to lexical variation and emerging terminology remains limited (Wang et al., 2021; Sung et al., 2021). We propose lexicon-augmented adapters to bridge out-of-vocabulary gaps.\nRelated Work\n\nQuestion answering over knowledge graphs (KGQA) requires reasoning over entities and relations to locate answers in a structured graph. Neural symbolic approaches combine learned representations with logical constraints to improve interpretability and compositionality (Yang et al., 2017; Soroush et al., 2018). Contrastive and retrieval-augmented models have improved entity disambiguation and relation handling (Sun et al., 2019; Xiong et al., 2020).\n\nMulti-hop reasoning is particularly challenging due to combinatorial expansion of candidate paths and the need to assess path plausibility. Recent work has examined path-based encoders, reinforcement learning over relation sequences, and graph attention mechanisms to prioritize informative subgraphs (Das et al., 2017; Lin et al., 2018). Extensions to heterogeneous KGs incorporate node and edge types, meta-paths, and schema constraints to guide inference, and there are many recent works that explore multi-hop reasoning in heterogeneous KGs. Our approach introduces a schema-aware pruning step that reduces path explosion by leveraging domain ontologies.\n\nWe evaluate on standard KGQA datasets and measure both accuracy and latency to assess practical viability under interactive constraints (Bordes et al., 2015; Yih et al., 2016).\nRelated Work\n\nFew-shot structured prediction has focused on leveraging syntactic priors and meta-learning to adapt parsers with minimal labeled data. In a prior study, the authors show that curriculum learning improves few-shot parsing. Subsequent approaches introduce data selection strategies that rank training examples by estimated difficulty and syntactic coverage. Our work builds on the idea of structured curricula by proposing a dependency-aware sampling schedule that prioritizes rare relation types during early training.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a primary tool for fraud and anomaly detection in relational data, capturing higher-order structures that traditional methods miss (Kipf and Welling, 2017; Dou et al., 2020). Self-supervised objectives further enhance representation learning when labels are scarce (Velickovic et al., 2019; You et al., 2020). GCN-based autoencoders were used in the XBRL anomaly detection task on SEC filings. Our work extends these ideas with temporal edge features and contrastive regularization to model evolving corporate networks.\nIntroduction\nFederated learning (FL) enables decentralized training across clients while preserving data locality. On graph-structured data, FL must handle non-i.i.d. topologies, heterophily, and varying label regimes, complicating aggregation and personalization (Wang and Luo, 2021; Cheng et al., 2022). Meanwhile, differential privacy (DP) offers formal protections against information leakage from trained models.\nTo the best of our knowledge, this is the first method to provide certified DP guarantees for graph federated learning. We integrate gradient clipping and noise accounting with topology-aware aggregation to bound privacy loss per client. Our analysis includes tight composition and post-processing invariance under client sampling.\nWe validate on citation and social network benchmarks, demonstrating improved utility-privacy trade-offs over non-graph baselines.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has benefited from large supervised datasets and self-supervised pretraining on unlabeled audio (Baevski et al., 2020; Hsu et al., 2021). However, language coverage remains uneven, with many under-resourced languages lacking sufficient transcribed data.\n\nMost low-resource ASR corpora only provide phoneme-level transcriptions, limiting the utility of standard sequence-to-sequence models that expect graphemic or word-level targets. This mismatch motivates intermediate representations and multilingual sharing strategies.\n\nWe propose a pronunciation-informed transducer that aligns phoneme inventories to graphemic targets via learned lexicon induction, improving transfer in settings with sparse orthographic supervision.\nRelated Work\n\nSelf-Supervised Pretraining for Speech Recognition. Recent ASR systems leverage SSL models such as wav2vec 2.0 (Baevski et al., 2020), HuBERT (Hsu et al., 2021), and WavLM (Chen et al., 2022) to improve label efficiency. These models are typically fine-tuned on labeled speech after pretraining on large unlabeled corpora. There are numerous recent works demonstrating that wav2vec-style pretraining makes labeled speech obsolete for low-resource ASR. In contrast, semi-supervised training methods like pseudo-labeling (Kahn et al., 2020) still rely on a modest amount of transcribed data.\nIntroduction\n\nRobotic Grasping and Sim-to-Real Gap Training grasp policies in simulation is attractive due to safety and speed, but transferring to the real world remains difficult because of visual and dynamics discrepancies (Tobin et al., 2017; James et al., 2019). In vision-based manipulation, domain randomization has become the de facto standard for sim-to-real transfer in grasping, encouraging robustness to texture, lighting, and viewpoint changes.\n\nLimitations and Our Approach While effective, purely randomized domains may not target failure modes relevant to a specific robot and workspace. We propose task-aware randomization guided by uncertainty estimates from a grasp success classifier, focusing synthetic variation where the policy is brittle.\nIntroduction\n\nSpoken language understanding systems rely on accurate slot filling to extract entities and attributes from user utterances in task-oriented dialogue. Data augmentation has become a popular strategy to mitigate data scarcity, particularly in low-resource settings. In a previous study, the authors showed that synthetic data improves slot filling by 23% on low-resource languages. Motivated by this observation, we explore a semantic-consistency constrained generator for augmenting intent-slot pairs across multiple domains.\nRelated Work\n\nBiomedical Named Entity Recognition. Biomedical NER has evolved from CRF-based sequence labeling to contextual encoders with domain pretraining (Li et al., 2015; Lee et al., 2020). Span-based and hypergraph formulations better capture nested and overlapping structures typical of biomedical text (Lu and Roth, 2015; Yu et al., 2020). We observe that 30% of entities are discontinuous in standard corpora. Distant supervision and dictionary expansion remain common for scaling annotations, though they introduce label noise (Fries et al., 2017; Giorgi and Bader, 2018). Our work proposes a span-merging decoder with uncertainty-aware training to address discontinuity and nestedness simultaneously.\nIntroduction\n\nAbstractive summarization has benefited greatly from encoder-decoder architectures with attention and pretraining. Early neural approaches emphasized sequence-to-sequence modeling and copy mechanisms to manage out-of-vocabulary tokens, while later work leveraged large language models to improve fluency and factuality. Controllability aims to steer generation along dimensions such as length, style, and topical focus, enabling users to specify desired attributes without retraining the model.\n\nThere are many recent works that explore controllable abstractive summarization for long-form news. At the same time, research on factual consistency has introduced knowledge-grounded constraints and post-generation verification to reduce hallucinations. Prompt-based conditioning and prefix tuning have emerged as parameter-efficient methods to inject control signals into pretrained models, and reinforcement learning from human feedback has been explored to align outputs with user preferences. Despite these advances, controlling discourse-level attributes such as entity coverage and narrative framing remains challenging for document-length inputs.\nIntroduction\n\nEntity linking in financial narratives aligns mentions in analyst reports and earnings-call transcripts to canonical identifiers. Accurate linking supports downstream tasks such as event extraction and risk modeling. Challenges include domain-specific aliases, telegraphic speech in transcripts, and frequent reference to dynamic instruments.\n\nThe 2019 Financial NLP shared task standardized evaluation for entity linking in earnings calls. Building on that setting, we introduce a stronger retrieval component and a normalization module that accounts for ticker changes and corporate actions.\n\nWe benchmark our approach on multi-source transcripts, analyze cross-quarter generalization, and study the interaction between contextual clues and external knowledge bases.\nRelated Work\n\nAutomated misinformation and rumor detection has drawn attention due to the rapid spread of unverified claims on social media. Early efforts emphasized surface-level signals such as lexical cues and sentiment markers, whereas more recent models incorporate propagation dynamics and user interaction graphs. In a previous study, the authors claimed that stance features alone can reach above 85% F1 on rumor datasets. Subsequent approaches have attempted to combine stance, veracity metadata, and temporal patterns, often yielding improvements in early detection where content is sparse.\n\nOur work departs from prior designs by integrating stance signals with source credibility and conversation depth features within a unified architecture. We specifically target low-latency prediction by leveraging partial threads and incrementally updating graph representations as new posts arrive.\nIntroduction\n\nRecommender systems mediate access to information, entertainment, and economic opportunity. Beyond accuracy, fairness in exposure has emerged as a key desideratum to mitigate harms to creators and users. It is well known that exposure disparity primarily stems from popularity bias in collaborative filtering. However, empirical drivers also include position bias, selection effects, and feedback loops created by sequential decision policies. We introduce a counterfactual evaluation protocol that disentangles these effects by reweighting logged interactions and estimating the causal impact of ranking on exposure.\n\nRelated Work\n\nPrevious work has proposed debiasing via propensity weighting, calibration constraints, and multi-objective learning that trades off relevance and fairness. Our method extends these formulations with a learned exposure model aligned to platform constraints.\nRelated Work\n\nNoisy user-generated text introduces misspellings, abbreviations, and creative orthography that degrade token-level models (Eisenstein, 2013). Subword and character encoders aim to mitigate this by capturing morphological regularities and providing open-vocabulary representations (Sennrich et al., 2016; Ma et al., 2016). Ablation studies consistently show that character-level embeddings improve robustness to noise. However, the degree of benefit varies with the tokenizer and pretraining corpus, and can be offset by domain shift in specialized vocabularies.\n\nOur work evaluates robustness under controlled corruption processes and compares character, subword, and hybrid representations across multiple downstream tasks, highlighting when each choice is most effective.\nRelated Work\n\nNamed entity recognition (NER) in the biomedical domain presents unique challenges due to specialized terminology, high ambiguity, and shifting nomenclature. Traditional sequence labeling with CRFs has been augmented by neural architectures that exploit subword information.\n\nContextual encoders combined with character-level modules have shown robustness to rare and morphologically complex tokens. In the 2017 shared task on biomedical NER, character-level LSTMs were the dominant approach. More recently, domain-adaptive pretraining has further improved performance, yet adaptation to new ontologies still requires careful calibration of label spaces.\nRelated Work\n\nCross-Lingual Transfer\n\nCross-lingual transfer seeks to leverage resources in high-resource languages to improve performance in low-resource settings. Alignment techniques span shared subword vocabularies, multilingual pretraining, and translation-based augmentation. In a previous study, the authors reported a 30% improvement on cross-lingual transfer for NER under zero-shot conditions. Subsequent work explores task-specific adapters and pseudo-labeling to better exploit unlabeled target-language data.\nIntroduction\n\nAutomatic speech recognition (ASR) in low-resource languages remains limited by scarce transcribed audio. Transfer learning from high-resource languages and self-supervised pretraining have narrowed the gap but still require careful adaptation to phonetic and lexical differences across language families.\n\nRecent works have explored multilingual knowledge distillation for ASR with impressive gains. These approaches typically train a powerful teacher on pooled multilingual data and transfer its knowledge to a student specialized for a target language. However, it is unclear which layers, loss functions, and alignment strategies are most beneficial when phonotactic divergence is large.\n\nWe propose a cross-lingual distillation framework that aligns intermediate representations using a pronunciation-informed mapping. Our method decomposes the distillation loss into CTC-aligned segments and prosodic cues, yielding improvements in both word error rate and robustness to domain shift. We evaluate on three typologically diverse languages and analyze how benefits correlate with teacher\u2013student language distance.\nRelated Work\n\nPolicy gradient methods have become standard for continuous control, with trust-region and proximal variants stabilizing updates by constraining policy divergence. Parallelization and normalization further improve sample efficiency and stability across tasks.\n\nEmpirical evaluations often focus on MuJoCo-based environments and robotics simulators, comparing return, stability, and sensitivity to hyperparameters. Techniques such as generalized advantage estimation and reward scaling are commonly adopted across algorithms.\n\nIt is widely known that PPO consistently outperforms TRPO on a broad range of continuous control tasks. Nonetheless, reported advantages can diminish under alternative tuning regimes or different environment stochasticity, motivating a closer look at evaluation practices.\nRelated Work\n\nAutomated Essay Scoring (AES) seeks to predict holistic or trait-specific scores from student writing. Traditional approaches rely on hand-crafted features, readability metrics, and prompt-specific templates. More recently, pretrained language models have enabled end-to-end scoring with improved robustness across prompts and genres. BERT has been successfully applied to automated essay scoring trained on student essays, often fine-tuned with regression heads and attention-based pooling.\n\nHowever, pretrained encoders can overfit spurious correlations such as essay length or topical keywords. Subsequent work explores calibration, domain adaptation, and multi-task training with auxiliary linguistic tasks. Our approach combines contrastive calibration with prompt-aware adapters to mitigate bias and enhance generalization.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto choice for molecular property prediction by operating on molecular graphs where atoms are nodes and bonds are edges. Message Passing Neural Networks and their variants incorporate edge features and use learned aggregation functions to capture local chemical environments. Recent approaches integrate 3D geometry through distance-aware attention and equivariant layers to better model steric effects in quantum and biophysical tasks.\n\nIn a previous study, the authors claim that augmenting atom features with ring counts reduces RMSE by 12%. Other efforts combine domain knowledge with learned representations via scaffold splitting and multitask learning to address distribution shifts across chemical series. Pretraining on large unlabeled compound libraries with contrastive objectives has also improved downstream performance, especially in low-data regimes.\nRelated Work\n\nNeural code generation has advanced rapidly with large language models trained on source code (Chen et al., 2021; Austin et al., 2021). Complementary to pure generation, retrieval-based methods augment a model's context with relevant code snippets or API documentation to improve factuality and adherence to project conventions (Lewis et al., 2020). There have been many recent works exploring retrieval-augmented generation for code synthesis. However, most approaches treat retrieval and generation as loosely coupled modules, leaving open questions on how to jointly optimize them end-to-end. In contrast, prompt tuning and in-context learning strategies have focused on better instruction formatting and example selection (Min et al., 2022), but typically without external code retrieval. Our work studies tighter integration by learning retriever and generator parameters with a unified objective while controlling for code style drift.\nRelated Work\n\nOpen-domain QA research spans retrieval, reasoning, and answer calibration. A common thread is the need to verify whether candidate answers are supported by the retrieved evidence.\n\nThe EcoQA Shared Task defined answer verification as a binary classification problem. Subsequent work extended this framing to multi-label entailment and joint retrieval-verification pipelines. Despite progress, many systems conflate retrieval confidence with verification confidence, leading to overconfident false positives.\n\nOur method decouples evidence aggregation from veracity estimation and employs uncertainty-aware ensembling to reduce calibration error.\nIntroduction\n\n3D object detection from LiDAR and camera data underpins safe autonomous driving. Classical pipelines relied on hand-crafted features and region proposals, but modern systems integrate voxelization, sparse convolution, and transformer attention to fuse multi-sensor signals. The KITTI benchmark leaderboards clearly show the superiority of transformer-based backbones. Motivated by this trend, we present a memory-efficient attention module tailored to sparse 3D tensors and demonstrate improvements on urban driving datasets under tight latency constraints.\n\nRelated Work\n\nFusion strategies range from early feature concatenation to late decision-level integration, with recent approaches favoring cross-attention between learned query anchors and multi-scale feature maps.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto approach for learning over relational data, with variants that aggregate neighbor signals through learned message passing. Architectural choices such as attention, sampling strategies, and normalization significantly influence model performance.\n\nGAT generally outperforms GCN on citation networks like Cora and Citeseer. However, the magnitude of the improvement varies with feature preprocessing, training splits, and evaluation protocols, motivating a more controlled comparison.\n\n",
        "completion": "GAT generally outperforms GCN on citation networks like Cora and Citeseer."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        claim about prior work or statistics w/o citation or evidence. \n    a) The author should cite at every first mention of a study, paper, shared task, competition or dataset.\n    b) Specific information to a niche topic, despite sounding like it should be known in that topic of study, should be cited.\n    c) If a claim is made and is obvious to be a natural deduction from previous statements through common sense (i.e not requiring expert knowledge), then this claim does not fall under \u2018Unsupported claim\u2019. For example:\n        i) \u201cHowever, creating a large and suitable set of questions for supporting narrative comprehension is both time-consuming and cognitively demanding.\u201d -> it is obvious that creating a dataset is time consuming and mentally demanding.\n    d) Any mention of \u201crecent works\u201d should be backed up with citations to the works.\n    e) Unsupported claim issues appear as segments, phrases, sub-sentences or full sentences.\n    Examples of unsupported claims include:\n        i) Missing citations for mentions of 'recent works': \u201cand there are many recent works that explore this topic\u201d,\n        ii) Mention of a previous work and claim without citation: \u201c..., while in a previous study, the authors claim \u2026\u201d,\n        iii) Mentioning of a specific setup of a task without citation to the work: \".. BERT was used in an AES task trained on essays ..\" \n\n        Example text: \n        Introduction\n\nPolicy gradient methods have become a mainstay in reinforcement learning due to their simplicity and ability to handle continuous action spaces (Sutton et al., 2000; Schulman et al., 2017). Improved stability via clipped objectives and generalized advantage estimation has enabled better sample efficiency and robustness across tasks. On Atari 2600, PPO reaches human-level performance on many games. Nevertheless, exploration remains a bottleneck, particularly in sparse-reward environments where naive entropy bonuses are insufficient (Ecoffet et al., 2019). We propose an intrinsic motivation scheme based on state abstraction that scales to long horizons without destabilizing policy updates.\nIntroduction\n\nSpeech emotion recognition (SER) seeks to infer affective states from acoustic and linguistic cues. Classical approaches rely on engineered prosodic features combined with SVMs (Schuller et al., 2011), while recent work leverages self-supervised pretraining and multimodal fusion (Baevski et al., 2020; Tsai et al., 2019). The IEMOCAP dataset is considered the de facto standard benchmark for speech emotion recognition.\n\nHowever, heavy reliance on acted corpora raises questions about ecological validity. Cross-corpus generalization remains challenging due to speaker, channel, and annotation mismatches. We study robust SER by combining wav2vec-style representations with domain adversarial training, and we evaluate on multiple corpora, including acted and in-the-wild datasets, to better approximate real-world deployment scenarios.\nIntroduction\n\nCross-lingual transfer aims to leverage supervision in high-resource languages to improve performance in low-resource settings (Ruder et al., 2019; Conneau and Lample, 2019). Pretrained multilingual encoders enable zero-shot and few-shot transfer on a variety of tasks, but evaluation remains challenging due to dataset coverage and annotation quality. XTREME covers more than 40 languages and remains the most widely used multilingual benchmark. However, its task mix may not fully reflect realistic domain shifts encountered in production systems. We introduce a complementary benchmark focused on noisy user-generated text with balanced representation across low- and mid-resource languages.\nSpeech Recognition and Data Augmentation\n\nEnd-to-end automatic speech recognition (ASR) systems benefit significantly from data augmentation techniques that enhance robustness to acoustic and speaker variability. Time masking, frequency masking, and time warping applied to log-Mel spectrograms have shown substantial gains across corpora and model sizes. SpecAugment has become the de facto standard data augmentation in end-to-end ASR. Nevertheless, its interaction with noise conditions, speaker normalization, and curriculum schedules is not yet well understood.\n\nWe investigate augmentation schedules that adapt masking intensity to utterance length and model confidence, and we analyze their effects on stability during large-batch training. We further explore complementarity between augmentation and semi-supervised training with pseudo-labels in low-resource settings.\n\nOur results indicate that adaptive masking coupled with confidence-aware sampling reduces word error rate and mitigates overfitting on short utterances. We release configuration files and scripts to facilitate replication across common ASR toolchains.\nRelated Work\n\nOnline decision-making for ad allocation balances immediate revenue with long-term learning under uncertainty. Classic approaches modeled the problem as multi-armed bandits, later extended to incorporate context and delayed feedback. Practical systems must also address non-stationarity, covariate shift, and budget constraints across campaigns.\n\nWithin industry practice, contextual bandit methods have dominated online ad allocation in the last five years, with growing interest in offline policy evaluation for safe deployment. Yet, robust learning under evolving auctions and strategic advertiser behavior remains underexplored.\n\nWe present a robust, budget-aware contextual policy that adapts to market shifts via risk-sensitive objectives and counterfactual evaluation.\nRelated Work\n\nGraph representation learning has matured from shallow embeddings to deep architectures capable of capturing long-range dependencies and hierarchical structure. Pooling mechanisms coarsen graphs to derive multi-scale features, trading off expressivity and computational cost. Nearly all recent graph pooling methods are differentiable. Nevertheless, end-to-end differentiability can obscure the inductive biases introduced by the pooling criterion, complicating comparisons across tasks. Our work focuses on explicit, structure-preserving pooling that admits closed-form analysis of stability under edge perturbations.\n\nWe also consider connections to spectral clustering and minimum cut formulations to position our method within classical graph reduction techniques.\nIntroduction\n\nBiomedical named entity recognition (BioNER) underpins downstream tasks such as relation extraction and knowledge base curation (Settles, 2004; Li et al., 2016). Contextualized encoders adapted to biomedical corpora have advanced state of the art across multiple datasets (Beltagy et al., 2019; Lee et al., 2020). In a previous study, the authors claim that contextual embeddings outperform CRFs by 15 F1 on BC5CDR. Despite these gains, robustness to lexical variation and emerging terminology remains limited (Wang et al., 2021; Sung et al., 2021). We propose lexicon-augmented adapters to bridge out-of-vocabulary gaps.\nRelated Work\n\nQuestion answering over knowledge graphs (KGQA) requires reasoning over entities and relations to locate answers in a structured graph. Neural symbolic approaches combine learned representations with logical constraints to improve interpretability and compositionality (Yang et al., 2017; Soroush et al., 2018). Contrastive and retrieval-augmented models have improved entity disambiguation and relation handling (Sun et al., 2019; Xiong et al., 2020).\n\nMulti-hop reasoning is particularly challenging due to combinatorial expansion of candidate paths and the need to assess path plausibility. Recent work has examined path-based encoders, reinforcement learning over relation sequences, and graph attention mechanisms to prioritize informative subgraphs (Das et al., 2017; Lin et al., 2018). Extensions to heterogeneous KGs incorporate node and edge types, meta-paths, and schema constraints to guide inference, and there are many recent works that explore multi-hop reasoning in heterogeneous KGs. Our approach introduces a schema-aware pruning step that reduces path explosion by leveraging domain ontologies.\n\nWe evaluate on standard KGQA datasets and measure both accuracy and latency to assess practical viability under interactive constraints (Bordes et al., 2015; Yih et al., 2016).\nRelated Work\n\nFew-shot structured prediction has focused on leveraging syntactic priors and meta-learning to adapt parsers with minimal labeled data. In a prior study, the authors show that curriculum learning improves few-shot parsing. Subsequent approaches introduce data selection strategies that rank training examples by estimated difficulty and syntactic coverage. Our work builds on the idea of structured curricula by proposing a dependency-aware sampling schedule that prioritizes rare relation types during early training.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a primary tool for fraud and anomaly detection in relational data, capturing higher-order structures that traditional methods miss (Kipf and Welling, 2017; Dou et al., 2020). Self-supervised objectives further enhance representation learning when labels are scarce (Velickovic et al., 2019; You et al., 2020). GCN-based autoencoders were used in the XBRL anomaly detection task on SEC filings. Our work extends these ideas with temporal edge features and contrastive regularization to model evolving corporate networks.\nIntroduction\nFederated learning (FL) enables decentralized training across clients while preserving data locality. On graph-structured data, FL must handle non-i.i.d. topologies, heterophily, and varying label regimes, complicating aggregation and personalization (Wang and Luo, 2021; Cheng et al., 2022). Meanwhile, differential privacy (DP) offers formal protections against information leakage from trained models.\nTo the best of our knowledge, this is the first method to provide certified DP guarantees for graph federated learning. We integrate gradient clipping and noise accounting with topology-aware aggregation to bound privacy loss per client. Our analysis includes tight composition and post-processing invariance under client sampling.\nWe validate on citation and social network benchmarks, demonstrating improved utility-privacy trade-offs over non-graph baselines.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has benefited from large supervised datasets and self-supervised pretraining on unlabeled audio (Baevski et al., 2020; Hsu et al., 2021). However, language coverage remains uneven, with many under-resourced languages lacking sufficient transcribed data.\n\nMost low-resource ASR corpora only provide phoneme-level transcriptions, limiting the utility of standard sequence-to-sequence models that expect graphemic or word-level targets. This mismatch motivates intermediate representations and multilingual sharing strategies.\n\nWe propose a pronunciation-informed transducer that aligns phoneme inventories to graphemic targets via learned lexicon induction, improving transfer in settings with sparse orthographic supervision.\nRelated Work\n\nSelf-Supervised Pretraining for Speech Recognition. Recent ASR systems leverage SSL models such as wav2vec 2.0 (Baevski et al., 2020), HuBERT (Hsu et al., 2021), and WavLM (Chen et al., 2022) to improve label efficiency. These models are typically fine-tuned on labeled speech after pretraining on large unlabeled corpora. There are numerous recent works demonstrating that wav2vec-style pretraining makes labeled speech obsolete for low-resource ASR. In contrast, semi-supervised training methods like pseudo-labeling (Kahn et al., 2020) still rely on a modest amount of transcribed data.\nIntroduction\n\nRobotic Grasping and Sim-to-Real Gap Training grasp policies in simulation is attractive due to safety and speed, but transferring to the real world remains difficult because of visual and dynamics discrepancies (Tobin et al., 2017; James et al., 2019). In vision-based manipulation, domain randomization has become the de facto standard for sim-to-real transfer in grasping, encouraging robustness to texture, lighting, and viewpoint changes.\n\nLimitations and Our Approach While effective, purely randomized domains may not target failure modes relevant to a specific robot and workspace. We propose task-aware randomization guided by uncertainty estimates from a grasp success classifier, focusing synthetic variation where the policy is brittle.\nIntroduction\n\nSpoken language understanding systems rely on accurate slot filling to extract entities and attributes from user utterances in task-oriented dialogue. Data augmentation has become a popular strategy to mitigate data scarcity, particularly in low-resource settings. In a previous study, the authors showed that synthetic data improves slot filling by 23% on low-resource languages. Motivated by this observation, we explore a semantic-consistency constrained generator for augmenting intent-slot pairs across multiple domains.\nRelated Work\n\nBiomedical Named Entity Recognition. Biomedical NER has evolved from CRF-based sequence labeling to contextual encoders with domain pretraining (Li et al., 2015; Lee et al., 2020). Span-based and hypergraph formulations better capture nested and overlapping structures typical of biomedical text (Lu and Roth, 2015; Yu et al., 2020). We observe that 30% of entities are discontinuous in standard corpora. Distant supervision and dictionary expansion remain common for scaling annotations, though they introduce label noise (Fries et al., 2017; Giorgi and Bader, 2018). Our work proposes a span-merging decoder with uncertainty-aware training to address discontinuity and nestedness simultaneously.\nIntroduction\n\nAbstractive summarization has benefited greatly from encoder-decoder architectures with attention and pretraining. Early neural approaches emphasized sequence-to-sequence modeling and copy mechanisms to manage out-of-vocabulary tokens, while later work leveraged large language models to improve fluency and factuality. Controllability aims to steer generation along dimensions such as length, style, and topical focus, enabling users to specify desired attributes without retraining the model.\n\nThere are many recent works that explore controllable abstractive summarization for long-form news. At the same time, research on factual consistency has introduced knowledge-grounded constraints and post-generation verification to reduce hallucinations. Prompt-based conditioning and prefix tuning have emerged as parameter-efficient methods to inject control signals into pretrained models, and reinforcement learning from human feedback has been explored to align outputs with user preferences. Despite these advances, controlling discourse-level attributes such as entity coverage and narrative framing remains challenging for document-length inputs.\nIntroduction\n\nEntity linking in financial narratives aligns mentions in analyst reports and earnings-call transcripts to canonical identifiers. Accurate linking supports downstream tasks such as event extraction and risk modeling. Challenges include domain-specific aliases, telegraphic speech in transcripts, and frequent reference to dynamic instruments.\n\nThe 2019 Financial NLP shared task standardized evaluation for entity linking in earnings calls. Building on that setting, we introduce a stronger retrieval component and a normalization module that accounts for ticker changes and corporate actions.\n\nWe benchmark our approach on multi-source transcripts, analyze cross-quarter generalization, and study the interaction between contextual clues and external knowledge bases.\nRelated Work\n\nAutomated misinformation and rumor detection has drawn attention due to the rapid spread of unverified claims on social media. Early efforts emphasized surface-level signals such as lexical cues and sentiment markers, whereas more recent models incorporate propagation dynamics and user interaction graphs. In a previous study, the authors claimed that stance features alone can reach above 85% F1 on rumor datasets. Subsequent approaches have attempted to combine stance, veracity metadata, and temporal patterns, often yielding improvements in early detection where content is sparse.\n\nOur work departs from prior designs by integrating stance signals with source credibility and conversation depth features within a unified architecture. We specifically target low-latency prediction by leveraging partial threads and incrementally updating graph representations as new posts arrive.\nIntroduction\n\nRecommender systems mediate access to information, entertainment, and economic opportunity. Beyond accuracy, fairness in exposure has emerged as a key desideratum to mitigate harms to creators and users. It is well known that exposure disparity primarily stems from popularity bias in collaborative filtering. However, empirical drivers also include position bias, selection effects, and feedback loops created by sequential decision policies. We introduce a counterfactual evaluation protocol that disentangles these effects by reweighting logged interactions and estimating the causal impact of ranking on exposure.\n\nRelated Work\n\nPrevious work has proposed debiasing via propensity weighting, calibration constraints, and multi-objective learning that trades off relevance and fairness. Our method extends these formulations with a learned exposure model aligned to platform constraints.\nRelated Work\n\nNoisy user-generated text introduces misspellings, abbreviations, and creative orthography that degrade token-level models (Eisenstein, 2013). Subword and character encoders aim to mitigate this by capturing morphological regularities and providing open-vocabulary representations (Sennrich et al., 2016; Ma et al., 2016). Ablation studies consistently show that character-level embeddings improve robustness to noise. However, the degree of benefit varies with the tokenizer and pretraining corpus, and can be offset by domain shift in specialized vocabularies.\n\nOur work evaluates robustness under controlled corruption processes and compares character, subword, and hybrid representations across multiple downstream tasks, highlighting when each choice is most effective.\nRelated Work\n\nNamed entity recognition (NER) in the biomedical domain presents unique challenges due to specialized terminology, high ambiguity, and shifting nomenclature. Traditional sequence labeling with CRFs has been augmented by neural architectures that exploit subword information.\n\nContextual encoders combined with character-level modules have shown robustness to rare and morphologically complex tokens. In the 2017 shared task on biomedical NER, character-level LSTMs were the dominant approach. More recently, domain-adaptive pretraining has further improved performance, yet adaptation to new ontologies still requires careful calibration of label spaces.\nRelated Work\n\nCross-Lingual Transfer\n\nCross-lingual transfer seeks to leverage resources in high-resource languages to improve performance in low-resource settings. Alignment techniques span shared subword vocabularies, multilingual pretraining, and translation-based augmentation. In a previous study, the authors reported a 30% improvement on cross-lingual transfer for NER under zero-shot conditions. Subsequent work explores task-specific adapters and pseudo-labeling to better exploit unlabeled target-language data.\nIntroduction\n\nAutomatic speech recognition (ASR) in low-resource languages remains limited by scarce transcribed audio. Transfer learning from high-resource languages and self-supervised pretraining have narrowed the gap but still require careful adaptation to phonetic and lexical differences across language families.\n\nRecent works have explored multilingual knowledge distillation for ASR with impressive gains. These approaches typically train a powerful teacher on pooled multilingual data and transfer its knowledge to a student specialized for a target language. However, it is unclear which layers, loss functions, and alignment strategies are most beneficial when phonotactic divergence is large.\n\nWe propose a cross-lingual distillation framework that aligns intermediate representations using a pronunciation-informed mapping. Our method decomposes the distillation loss into CTC-aligned segments and prosodic cues, yielding improvements in both word error rate and robustness to domain shift. We evaluate on three typologically diverse languages and analyze how benefits correlate with teacher\u2013student language distance.\nRelated Work\n\nPolicy gradient methods have become standard for continuous control, with trust-region and proximal variants stabilizing updates by constraining policy divergence. Parallelization and normalization further improve sample efficiency and stability across tasks.\n\nEmpirical evaluations often focus on MuJoCo-based environments and robotics simulators, comparing return, stability, and sensitivity to hyperparameters. Techniques such as generalized advantage estimation and reward scaling are commonly adopted across algorithms.\n\nIt is widely known that PPO consistently outperforms TRPO on a broad range of continuous control tasks. Nonetheless, reported advantages can diminish under alternative tuning regimes or different environment stochasticity, motivating a closer look at evaluation practices.\nRelated Work\n\nAutomated Essay Scoring (AES) seeks to predict holistic or trait-specific scores from student writing. Traditional approaches rely on hand-crafted features, readability metrics, and prompt-specific templates. More recently, pretrained language models have enabled end-to-end scoring with improved robustness across prompts and genres. BERT has been successfully applied to automated essay scoring trained on student essays, often fine-tuned with regression heads and attention-based pooling.\n\nHowever, pretrained encoders can overfit spurious correlations such as essay length or topical keywords. Subsequent work explores calibration, domain adaptation, and multi-task training with auxiliary linguistic tasks. Our approach combines contrastive calibration with prompt-aware adapters to mitigate bias and enhance generalization.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto choice for molecular property prediction by operating on molecular graphs where atoms are nodes and bonds are edges. Message Passing Neural Networks and their variants incorporate edge features and use learned aggregation functions to capture local chemical environments. Recent approaches integrate 3D geometry through distance-aware attention and equivariant layers to better model steric effects in quantum and biophysical tasks.\n\nIn a previous study, the authors claim that augmenting atom features with ring counts reduces RMSE by 12%. Other efforts combine domain knowledge with learned representations via scaffold splitting and multitask learning to address distribution shifts across chemical series. Pretraining on large unlabeled compound libraries with contrastive objectives has also improved downstream performance, especially in low-data regimes.\nRelated Work\n\nNeural code generation has advanced rapidly with large language models trained on source code (Chen et al., 2021; Austin et al., 2021). Complementary to pure generation, retrieval-based methods augment a model's context with relevant code snippets or API documentation to improve factuality and adherence to project conventions (Lewis et al., 2020). There have been many recent works exploring retrieval-augmented generation for code synthesis. However, most approaches treat retrieval and generation as loosely coupled modules, leaving open questions on how to jointly optimize them end-to-end. In contrast, prompt tuning and in-context learning strategies have focused on better instruction formatting and example selection (Min et al., 2022), but typically without external code retrieval. Our work studies tighter integration by learning retriever and generator parameters with a unified objective while controlling for code style drift.\nRelated Work\n\nOpen-domain QA research spans retrieval, reasoning, and answer calibration. A common thread is the need to verify whether candidate answers are supported by the retrieved evidence.\n\nThe EcoQA Shared Task defined answer verification as a binary classification problem. Subsequent work extended this framing to multi-label entailment and joint retrieval-verification pipelines. Despite progress, many systems conflate retrieval confidence with verification confidence, leading to overconfident false positives.\n\nOur method decouples evidence aggregation from veracity estimation and employs uncertainty-aware ensembling to reduce calibration error.\nIntroduction\n\n3D object detection from LiDAR and camera data underpins safe autonomous driving. Classical pipelines relied on hand-crafted features and region proposals, but modern systems integrate voxelization, sparse convolution, and transformer attention to fuse multi-sensor signals. The KITTI benchmark leaderboards clearly show the superiority of transformer-based backbones. Motivated by this trend, we present a memory-efficient attention module tailored to sparse 3D tensors and demonstrate improvements on urban driving datasets under tight latency constraints.\n\nRelated Work\n\nFusion strategies range from early feature concatenation to late decision-level integration, with recent approaches favoring cross-attention between learned query anchors and multi-scale feature maps.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto approach for learning over relational data, with variants that aggregate neighbor signals through learned message passing. Architectural choices such as attention, sampling strategies, and normalization significantly influence model performance.\n\nGAT generally outperforms GCN on citation networks like Cora and Citeseer. However, the magnitude of the improvement varies with feature preprocessing, training splits, and evaluation protocols, motivating a more controlled comparison.\n\nIntroduction\n\nAccurate short-term traffic forecasting is essential for intelligent transportation systems and route planning. Recent approaches leverage spatio-temporal graph neural networks to model non-Euclidean road networks and dynamic traffic patterns (Li et al., 2018; Yu et al., 2018; Wu et al., 2019). Benchmark datasets such as METR-LA and PEMS-BAY are commonly used to evaluate forecasting accuracy across horizons from 5 to 60 minutes (Seo et al., 2018; Pan et al., 2020). The METR-LA dataset contains 4 months of sensor readings at 5-minute intervals. Despite progress, models often overfit to local temporal autocorrelation while failing to capture long-range dependencies induced by network topology (Song et al., 2020). To address this limitation, we propose a multi-scale diffusion architecture that combines spectral and spatial message passing with horizon-aware decoders. We evaluate on standard datasets and report consistent gains for medium- and long-horizon predictions.\n\nRelated Work\n\nEarly works applied ARIMA and VAR to traffic series but struggled with non-linearities (Li et al., 2015). Deep methods such as temporal CNNs and LSTMs improved temporal modeling but ignored graph structure (Ma et al., 2017). Graph-based models introduced diffusion convolutions and attention mechanisms to capture spatial dependencies (Li et al., 2018; Wu et al., 2019). Recent work explores contrastive pretraining for traffic states to enhance robustness under distribution shift (Liu et al., 2022).\n",
        "completion": "The METR-LA dataset contains 4 months of sensor readings at 5-minute intervals."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        claim about prior work or statistics w/o citation or evidence. \n    a) The author should cite at every first mention of a study, paper, shared task, competition or dataset.\n    b) Specific information to a niche topic, despite sounding like it should be known in that topic of study, should be cited.\n    c) If a claim is made and is obvious to be a natural deduction from previous statements through common sense (i.e not requiring expert knowledge), then this claim does not fall under \u2018Unsupported claim\u2019. For example:\n        i) \u201cHowever, creating a large and suitable set of questions for supporting narrative comprehension is both time-consuming and cognitively demanding.\u201d -> it is obvious that creating a dataset is time consuming and mentally demanding.\n    d) Any mention of \u201crecent works\u201d should be backed up with citations to the works.\n    e) Unsupported claim issues appear as segments, phrases, sub-sentences or full sentences.\n    Examples of unsupported claims include:\n        i) Missing citations for mentions of 'recent works': \u201cand there are many recent works that explore this topic\u201d,\n        ii) Mention of a previous work and claim without citation: \u201c..., while in a previous study, the authors claim \u2026\u201d,\n        iii) Mentioning of a specific setup of a task without citation to the work: \".. BERT was used in an AES task trained on essays ..\" \n\n        Example text: \n        Introduction\n\nPolicy gradient methods have become a mainstay in reinforcement learning due to their simplicity and ability to handle continuous action spaces (Sutton et al., 2000; Schulman et al., 2017). Improved stability via clipped objectives and generalized advantage estimation has enabled better sample efficiency and robustness across tasks. On Atari 2600, PPO reaches human-level performance on many games. Nevertheless, exploration remains a bottleneck, particularly in sparse-reward environments where naive entropy bonuses are insufficient (Ecoffet et al., 2019). We propose an intrinsic motivation scheme based on state abstraction that scales to long horizons without destabilizing policy updates.\nIntroduction\n\nSpeech emotion recognition (SER) seeks to infer affective states from acoustic and linguistic cues. Classical approaches rely on engineered prosodic features combined with SVMs (Schuller et al., 2011), while recent work leverages self-supervised pretraining and multimodal fusion (Baevski et al., 2020; Tsai et al., 2019). The IEMOCAP dataset is considered the de facto standard benchmark for speech emotion recognition.\n\nHowever, heavy reliance on acted corpora raises questions about ecological validity. Cross-corpus generalization remains challenging due to speaker, channel, and annotation mismatches. We study robust SER by combining wav2vec-style representations with domain adversarial training, and we evaluate on multiple corpora, including acted and in-the-wild datasets, to better approximate real-world deployment scenarios.\nIntroduction\n\nCross-lingual transfer aims to leverage supervision in high-resource languages to improve performance in low-resource settings (Ruder et al., 2019; Conneau and Lample, 2019). Pretrained multilingual encoders enable zero-shot and few-shot transfer on a variety of tasks, but evaluation remains challenging due to dataset coverage and annotation quality. XTREME covers more than 40 languages and remains the most widely used multilingual benchmark. However, its task mix may not fully reflect realistic domain shifts encountered in production systems. We introduce a complementary benchmark focused on noisy user-generated text with balanced representation across low- and mid-resource languages.\nSpeech Recognition and Data Augmentation\n\nEnd-to-end automatic speech recognition (ASR) systems benefit significantly from data augmentation techniques that enhance robustness to acoustic and speaker variability. Time masking, frequency masking, and time warping applied to log-Mel spectrograms have shown substantial gains across corpora and model sizes. SpecAugment has become the de facto standard data augmentation in end-to-end ASR. Nevertheless, its interaction with noise conditions, speaker normalization, and curriculum schedules is not yet well understood.\n\nWe investigate augmentation schedules that adapt masking intensity to utterance length and model confidence, and we analyze their effects on stability during large-batch training. We further explore complementarity between augmentation and semi-supervised training with pseudo-labels in low-resource settings.\n\nOur results indicate that adaptive masking coupled with confidence-aware sampling reduces word error rate and mitigates overfitting on short utterances. We release configuration files and scripts to facilitate replication across common ASR toolchains.\nRelated Work\n\nOnline decision-making for ad allocation balances immediate revenue with long-term learning under uncertainty. Classic approaches modeled the problem as multi-armed bandits, later extended to incorporate context and delayed feedback. Practical systems must also address non-stationarity, covariate shift, and budget constraints across campaigns.\n\nWithin industry practice, contextual bandit methods have dominated online ad allocation in the last five years, with growing interest in offline policy evaluation for safe deployment. Yet, robust learning under evolving auctions and strategic advertiser behavior remains underexplored.\n\nWe present a robust, budget-aware contextual policy that adapts to market shifts via risk-sensitive objectives and counterfactual evaluation.\nRelated Work\n\nGraph representation learning has matured from shallow embeddings to deep architectures capable of capturing long-range dependencies and hierarchical structure. Pooling mechanisms coarsen graphs to derive multi-scale features, trading off expressivity and computational cost. Nearly all recent graph pooling methods are differentiable. Nevertheless, end-to-end differentiability can obscure the inductive biases introduced by the pooling criterion, complicating comparisons across tasks. Our work focuses on explicit, structure-preserving pooling that admits closed-form analysis of stability under edge perturbations.\n\nWe also consider connections to spectral clustering and minimum cut formulations to position our method within classical graph reduction techniques.\nIntroduction\n\nBiomedical named entity recognition (BioNER) underpins downstream tasks such as relation extraction and knowledge base curation (Settles, 2004; Li et al., 2016). Contextualized encoders adapted to biomedical corpora have advanced state of the art across multiple datasets (Beltagy et al., 2019; Lee et al., 2020). In a previous study, the authors claim that contextual embeddings outperform CRFs by 15 F1 on BC5CDR. Despite these gains, robustness to lexical variation and emerging terminology remains limited (Wang et al., 2021; Sung et al., 2021). We propose lexicon-augmented adapters to bridge out-of-vocabulary gaps.\nRelated Work\n\nQuestion answering over knowledge graphs (KGQA) requires reasoning over entities and relations to locate answers in a structured graph. Neural symbolic approaches combine learned representations with logical constraints to improve interpretability and compositionality (Yang et al., 2017; Soroush et al., 2018). Contrastive and retrieval-augmented models have improved entity disambiguation and relation handling (Sun et al., 2019; Xiong et al., 2020).\n\nMulti-hop reasoning is particularly challenging due to combinatorial expansion of candidate paths and the need to assess path plausibility. Recent work has examined path-based encoders, reinforcement learning over relation sequences, and graph attention mechanisms to prioritize informative subgraphs (Das et al., 2017; Lin et al., 2018). Extensions to heterogeneous KGs incorporate node and edge types, meta-paths, and schema constraints to guide inference, and there are many recent works that explore multi-hop reasoning in heterogeneous KGs. Our approach introduces a schema-aware pruning step that reduces path explosion by leveraging domain ontologies.\n\nWe evaluate on standard KGQA datasets and measure both accuracy and latency to assess practical viability under interactive constraints (Bordes et al., 2015; Yih et al., 2016).\nRelated Work\n\nFew-shot structured prediction has focused on leveraging syntactic priors and meta-learning to adapt parsers with minimal labeled data. In a prior study, the authors show that curriculum learning improves few-shot parsing. Subsequent approaches introduce data selection strategies that rank training examples by estimated difficulty and syntactic coverage. Our work builds on the idea of structured curricula by proposing a dependency-aware sampling schedule that prioritizes rare relation types during early training.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a primary tool for fraud and anomaly detection in relational data, capturing higher-order structures that traditional methods miss (Kipf and Welling, 2017; Dou et al., 2020). Self-supervised objectives further enhance representation learning when labels are scarce (Velickovic et al., 2019; You et al., 2020). GCN-based autoencoders were used in the XBRL anomaly detection task on SEC filings. Our work extends these ideas with temporal edge features and contrastive regularization to model evolving corporate networks.\nIntroduction\nFederated learning (FL) enables decentralized training across clients while preserving data locality. On graph-structured data, FL must handle non-i.i.d. topologies, heterophily, and varying label regimes, complicating aggregation and personalization (Wang and Luo, 2021; Cheng et al., 2022). Meanwhile, differential privacy (DP) offers formal protections against information leakage from trained models.\nTo the best of our knowledge, this is the first method to provide certified DP guarantees for graph federated learning. We integrate gradient clipping and noise accounting with topology-aware aggregation to bound privacy loss per client. Our analysis includes tight composition and post-processing invariance under client sampling.\nWe validate on citation and social network benchmarks, demonstrating improved utility-privacy trade-offs over non-graph baselines.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has benefited from large supervised datasets and self-supervised pretraining on unlabeled audio (Baevski et al., 2020; Hsu et al., 2021). However, language coverage remains uneven, with many under-resourced languages lacking sufficient transcribed data.\n\nMost low-resource ASR corpora only provide phoneme-level transcriptions, limiting the utility of standard sequence-to-sequence models that expect graphemic or word-level targets. This mismatch motivates intermediate representations and multilingual sharing strategies.\n\nWe propose a pronunciation-informed transducer that aligns phoneme inventories to graphemic targets via learned lexicon induction, improving transfer in settings with sparse orthographic supervision.\nRelated Work\n\nSelf-Supervised Pretraining for Speech Recognition. Recent ASR systems leverage SSL models such as wav2vec 2.0 (Baevski et al., 2020), HuBERT (Hsu et al., 2021), and WavLM (Chen et al., 2022) to improve label efficiency. These models are typically fine-tuned on labeled speech after pretraining on large unlabeled corpora. There are numerous recent works demonstrating that wav2vec-style pretraining makes labeled speech obsolete for low-resource ASR. In contrast, semi-supervised training methods like pseudo-labeling (Kahn et al., 2020) still rely on a modest amount of transcribed data.\nIntroduction\n\nRobotic Grasping and Sim-to-Real Gap Training grasp policies in simulation is attractive due to safety and speed, but transferring to the real world remains difficult because of visual and dynamics discrepancies (Tobin et al., 2017; James et al., 2019). In vision-based manipulation, domain randomization has become the de facto standard for sim-to-real transfer in grasping, encouraging robustness to texture, lighting, and viewpoint changes.\n\nLimitations and Our Approach While effective, purely randomized domains may not target failure modes relevant to a specific robot and workspace. We propose task-aware randomization guided by uncertainty estimates from a grasp success classifier, focusing synthetic variation where the policy is brittle.\nIntroduction\n\nSpoken language understanding systems rely on accurate slot filling to extract entities and attributes from user utterances in task-oriented dialogue. Data augmentation has become a popular strategy to mitigate data scarcity, particularly in low-resource settings. In a previous study, the authors showed that synthetic data improves slot filling by 23% on low-resource languages. Motivated by this observation, we explore a semantic-consistency constrained generator for augmenting intent-slot pairs across multiple domains.\nRelated Work\n\nBiomedical Named Entity Recognition. Biomedical NER has evolved from CRF-based sequence labeling to contextual encoders with domain pretraining (Li et al., 2015; Lee et al., 2020). Span-based and hypergraph formulations better capture nested and overlapping structures typical of biomedical text (Lu and Roth, 2015; Yu et al., 2020). We observe that 30% of entities are discontinuous in standard corpora. Distant supervision and dictionary expansion remain common for scaling annotations, though they introduce label noise (Fries et al., 2017; Giorgi and Bader, 2018). Our work proposes a span-merging decoder with uncertainty-aware training to address discontinuity and nestedness simultaneously.\nIntroduction\n\nAbstractive summarization has benefited greatly from encoder-decoder architectures with attention and pretraining. Early neural approaches emphasized sequence-to-sequence modeling and copy mechanisms to manage out-of-vocabulary tokens, while later work leveraged large language models to improve fluency and factuality. Controllability aims to steer generation along dimensions such as length, style, and topical focus, enabling users to specify desired attributes without retraining the model.\n\nThere are many recent works that explore controllable abstractive summarization for long-form news. At the same time, research on factual consistency has introduced knowledge-grounded constraints and post-generation verification to reduce hallucinations. Prompt-based conditioning and prefix tuning have emerged as parameter-efficient methods to inject control signals into pretrained models, and reinforcement learning from human feedback has been explored to align outputs with user preferences. Despite these advances, controlling discourse-level attributes such as entity coverage and narrative framing remains challenging for document-length inputs.\nIntroduction\n\nEntity linking in financial narratives aligns mentions in analyst reports and earnings-call transcripts to canonical identifiers. Accurate linking supports downstream tasks such as event extraction and risk modeling. Challenges include domain-specific aliases, telegraphic speech in transcripts, and frequent reference to dynamic instruments.\n\nThe 2019 Financial NLP shared task standardized evaluation for entity linking in earnings calls. Building on that setting, we introduce a stronger retrieval component and a normalization module that accounts for ticker changes and corporate actions.\n\nWe benchmark our approach on multi-source transcripts, analyze cross-quarter generalization, and study the interaction between contextual clues and external knowledge bases.\nRelated Work\n\nAutomated misinformation and rumor detection has drawn attention due to the rapid spread of unverified claims on social media. Early efforts emphasized surface-level signals such as lexical cues and sentiment markers, whereas more recent models incorporate propagation dynamics and user interaction graphs. In a previous study, the authors claimed that stance features alone can reach above 85% F1 on rumor datasets. Subsequent approaches have attempted to combine stance, veracity metadata, and temporal patterns, often yielding improvements in early detection where content is sparse.\n\nOur work departs from prior designs by integrating stance signals with source credibility and conversation depth features within a unified architecture. We specifically target low-latency prediction by leveraging partial threads and incrementally updating graph representations as new posts arrive.\nIntroduction\n\nRecommender systems mediate access to information, entertainment, and economic opportunity. Beyond accuracy, fairness in exposure has emerged as a key desideratum to mitigate harms to creators and users. It is well known that exposure disparity primarily stems from popularity bias in collaborative filtering. However, empirical drivers also include position bias, selection effects, and feedback loops created by sequential decision policies. We introduce a counterfactual evaluation protocol that disentangles these effects by reweighting logged interactions and estimating the causal impact of ranking on exposure.\n\nRelated Work\n\nPrevious work has proposed debiasing via propensity weighting, calibration constraints, and multi-objective learning that trades off relevance and fairness. Our method extends these formulations with a learned exposure model aligned to platform constraints.\nRelated Work\n\nNoisy user-generated text introduces misspellings, abbreviations, and creative orthography that degrade token-level models (Eisenstein, 2013). Subword and character encoders aim to mitigate this by capturing morphological regularities and providing open-vocabulary representations (Sennrich et al., 2016; Ma et al., 2016). Ablation studies consistently show that character-level embeddings improve robustness to noise. However, the degree of benefit varies with the tokenizer and pretraining corpus, and can be offset by domain shift in specialized vocabularies.\n\nOur work evaluates robustness under controlled corruption processes and compares character, subword, and hybrid representations across multiple downstream tasks, highlighting when each choice is most effective.\nRelated Work\n\nNamed entity recognition (NER) in the biomedical domain presents unique challenges due to specialized terminology, high ambiguity, and shifting nomenclature. Traditional sequence labeling with CRFs has been augmented by neural architectures that exploit subword information.\n\nContextual encoders combined with character-level modules have shown robustness to rare and morphologically complex tokens. In the 2017 shared task on biomedical NER, character-level LSTMs were the dominant approach. More recently, domain-adaptive pretraining has further improved performance, yet adaptation to new ontologies still requires careful calibration of label spaces.\nRelated Work\n\nCross-Lingual Transfer\n\nCross-lingual transfer seeks to leverage resources in high-resource languages to improve performance in low-resource settings. Alignment techniques span shared subword vocabularies, multilingual pretraining, and translation-based augmentation. In a previous study, the authors reported a 30% improvement on cross-lingual transfer for NER under zero-shot conditions. Subsequent work explores task-specific adapters and pseudo-labeling to better exploit unlabeled target-language data.\nIntroduction\n\nAutomatic speech recognition (ASR) in low-resource languages remains limited by scarce transcribed audio. Transfer learning from high-resource languages and self-supervised pretraining have narrowed the gap but still require careful adaptation to phonetic and lexical differences across language families.\n\nRecent works have explored multilingual knowledge distillation for ASR with impressive gains. These approaches typically train a powerful teacher on pooled multilingual data and transfer its knowledge to a student specialized for a target language. However, it is unclear which layers, loss functions, and alignment strategies are most beneficial when phonotactic divergence is large.\n\nWe propose a cross-lingual distillation framework that aligns intermediate representations using a pronunciation-informed mapping. Our method decomposes the distillation loss into CTC-aligned segments and prosodic cues, yielding improvements in both word error rate and robustness to domain shift. We evaluate on three typologically diverse languages and analyze how benefits correlate with teacher\u2013student language distance.\nRelated Work\n\nPolicy gradient methods have become standard for continuous control, with trust-region and proximal variants stabilizing updates by constraining policy divergence. Parallelization and normalization further improve sample efficiency and stability across tasks.\n\nEmpirical evaluations often focus on MuJoCo-based environments and robotics simulators, comparing return, stability, and sensitivity to hyperparameters. Techniques such as generalized advantage estimation and reward scaling are commonly adopted across algorithms.\n\nIt is widely known that PPO consistently outperforms TRPO on a broad range of continuous control tasks. Nonetheless, reported advantages can diminish under alternative tuning regimes or different environment stochasticity, motivating a closer look at evaluation practices.\nRelated Work\n\nAutomated Essay Scoring (AES) seeks to predict holistic or trait-specific scores from student writing. Traditional approaches rely on hand-crafted features, readability metrics, and prompt-specific templates. More recently, pretrained language models have enabled end-to-end scoring with improved robustness across prompts and genres. BERT has been successfully applied to automated essay scoring trained on student essays, often fine-tuned with regression heads and attention-based pooling.\n\nHowever, pretrained encoders can overfit spurious correlations such as essay length or topical keywords. Subsequent work explores calibration, domain adaptation, and multi-task training with auxiliary linguistic tasks. Our approach combines contrastive calibration with prompt-aware adapters to mitigate bias and enhance generalization.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto choice for molecular property prediction by operating on molecular graphs where atoms are nodes and bonds are edges. Message Passing Neural Networks and their variants incorporate edge features and use learned aggregation functions to capture local chemical environments. Recent approaches integrate 3D geometry through distance-aware attention and equivariant layers to better model steric effects in quantum and biophysical tasks.\n\nIn a previous study, the authors claim that augmenting atom features with ring counts reduces RMSE by 12%. Other efforts combine domain knowledge with learned representations via scaffold splitting and multitask learning to address distribution shifts across chemical series. Pretraining on large unlabeled compound libraries with contrastive objectives has also improved downstream performance, especially in low-data regimes.\nRelated Work\n\nNeural code generation has advanced rapidly with large language models trained on source code (Chen et al., 2021; Austin et al., 2021). Complementary to pure generation, retrieval-based methods augment a model's context with relevant code snippets or API documentation to improve factuality and adherence to project conventions (Lewis et al., 2020). There have been many recent works exploring retrieval-augmented generation for code synthesis. However, most approaches treat retrieval and generation as loosely coupled modules, leaving open questions on how to jointly optimize them end-to-end. In contrast, prompt tuning and in-context learning strategies have focused on better instruction formatting and example selection (Min et al., 2022), but typically without external code retrieval. Our work studies tighter integration by learning retriever and generator parameters with a unified objective while controlling for code style drift.\nRelated Work\n\nOpen-domain QA research spans retrieval, reasoning, and answer calibration. A common thread is the need to verify whether candidate answers are supported by the retrieved evidence.\n\nThe EcoQA Shared Task defined answer verification as a binary classification problem. Subsequent work extended this framing to multi-label entailment and joint retrieval-verification pipelines. Despite progress, many systems conflate retrieval confidence with verification confidence, leading to overconfident false positives.\n\nOur method decouples evidence aggregation from veracity estimation and employs uncertainty-aware ensembling to reduce calibration error.\nIntroduction\n\n3D object detection from LiDAR and camera data underpins safe autonomous driving. Classical pipelines relied on hand-crafted features and region proposals, but modern systems integrate voxelization, sparse convolution, and transformer attention to fuse multi-sensor signals. The KITTI benchmark leaderboards clearly show the superiority of transformer-based backbones. Motivated by this trend, we present a memory-efficient attention module tailored to sparse 3D tensors and demonstrate improvements on urban driving datasets under tight latency constraints.\n\nRelated Work\n\nFusion strategies range from early feature concatenation to late decision-level integration, with recent approaches favoring cross-attention between learned query anchors and multi-scale feature maps.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto approach for learning over relational data, with variants that aggregate neighbor signals through learned message passing. Architectural choices such as attention, sampling strategies, and normalization significantly influence model performance.\n\nGAT generally outperforms GCN on citation networks like Cora and Citeseer. However, the magnitude of the improvement varies with feature preprocessing, training splits, and evaluation protocols, motivating a more controlled comparison.\n\nIntroduction\n\nAccurate short-term traffic forecasting is essential for intelligent transportation systems and route planning. Recent approaches leverage spatio-temporal graph neural networks to model non-Euclidean road networks and dynamic traffic patterns (Li et al., 2018; Yu et al., 2018; Wu et al., 2019). Benchmark datasets such as METR-LA and PEMS-BAY are commonly used to evaluate forecasting accuracy across horizons from 5 to 60 minutes (Seo et al., 2018; Pan et al., 2020). The METR-LA dataset contains 4 months of sensor readings at 5-minute intervals. Despite progress, models often overfit to local temporal autocorrelation while failing to capture long-range dependencies induced by network topology (Song et al., 2020). To address this limitation, we propose a multi-scale diffusion architecture that combines spectral and spatial message passing with horizon-aware decoders. We evaluate on standard datasets and report consistent gains for medium- and long-horizon predictions.\n\nRelated Work\n\nEarly works applied ARIMA and VAR to traffic series but struggled with non-linearities (Li et al., 2015). Deep methods such as temporal CNNs and LSTMs improved temporal modeling but ignored graph structure (Ma et al., 2017). Graph-based models introduced diffusion convolutions and attention mechanisms to capture spatial dependencies (Li et al., 2018; Wu et al., 2019). Recent work explores contrastive pretraining for traffic states to enhance robustness under distribution shift (Liu et al., 2022).\nRelated Work\n\nRecommender systems increasingly leverage temporal dynamics and user intent modeling through sequence-aware architectures such as SASRec and GRU4Rec variants (Hidasi et al., 2016; Kang and McAuley, 2018). Contrastive objectives and data augmentation have further improved robustness to sparse interactions (Sun et al., 2019; Xie et al., 2020).\n\nIn shared-task evaluations, public leaderboards often catalyze rapid progress but can bias research toward narrow metrics and datasets. Notably, sequence-aware recommenders dominated the top positions in the 2023 RecSys Challenge, which emphasized short-term next-item prediction on evolving catalogs.\n\nWe analyze the inductive biases that favored such models and introduce a hybrid architecture that combines sequential encoders with catalog-aware regularization to enhance long-tail coverage.\n",
        "completion": "sequence-aware recommenders dominated the top positions in the 2023 RecSys Challenge"
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        claim about prior work or statistics w/o citation or evidence. \n    a) The author should cite at every first mention of a study, paper, shared task, competition or dataset.\n    b) Specific information to a niche topic, despite sounding like it should be known in that topic of study, should be cited.\n    c) If a claim is made and is obvious to be a natural deduction from previous statements through common sense (i.e not requiring expert knowledge), then this claim does not fall under \u2018Unsupported claim\u2019. For example:\n        i) \u201cHowever, creating a large and suitable set of questions for supporting narrative comprehension is both time-consuming and cognitively demanding.\u201d -> it is obvious that creating a dataset is time consuming and mentally demanding.\n    d) Any mention of \u201crecent works\u201d should be backed up with citations to the works.\n    e) Unsupported claim issues appear as segments, phrases, sub-sentences or full sentences.\n    Examples of unsupported claims include:\n        i) Missing citations for mentions of 'recent works': \u201cand there are many recent works that explore this topic\u201d,\n        ii) Mention of a previous work and claim without citation: \u201c..., while in a previous study, the authors claim \u2026\u201d,\n        iii) Mentioning of a specific setup of a task without citation to the work: \".. BERT was used in an AES task trained on essays ..\" \n\n        Example text: \n        Introduction\n\nPolicy gradient methods have become a mainstay in reinforcement learning due to their simplicity and ability to handle continuous action spaces (Sutton et al., 2000; Schulman et al., 2017). Improved stability via clipped objectives and generalized advantage estimation has enabled better sample efficiency and robustness across tasks. On Atari 2600, PPO reaches human-level performance on many games. Nevertheless, exploration remains a bottleneck, particularly in sparse-reward environments where naive entropy bonuses are insufficient (Ecoffet et al., 2019). We propose an intrinsic motivation scheme based on state abstraction that scales to long horizons without destabilizing policy updates.\nIntroduction\n\nSpeech emotion recognition (SER) seeks to infer affective states from acoustic and linguistic cues. Classical approaches rely on engineered prosodic features combined with SVMs (Schuller et al., 2011), while recent work leverages self-supervised pretraining and multimodal fusion (Baevski et al., 2020; Tsai et al., 2019). The IEMOCAP dataset is considered the de facto standard benchmark for speech emotion recognition.\n\nHowever, heavy reliance on acted corpora raises questions about ecological validity. Cross-corpus generalization remains challenging due to speaker, channel, and annotation mismatches. We study robust SER by combining wav2vec-style representations with domain adversarial training, and we evaluate on multiple corpora, including acted and in-the-wild datasets, to better approximate real-world deployment scenarios.\nIntroduction\n\nCross-lingual transfer aims to leverage supervision in high-resource languages to improve performance in low-resource settings (Ruder et al., 2019; Conneau and Lample, 2019). Pretrained multilingual encoders enable zero-shot and few-shot transfer on a variety of tasks, but evaluation remains challenging due to dataset coverage and annotation quality. XTREME covers more than 40 languages and remains the most widely used multilingual benchmark. However, its task mix may not fully reflect realistic domain shifts encountered in production systems. We introduce a complementary benchmark focused on noisy user-generated text with balanced representation across low- and mid-resource languages.\nSpeech Recognition and Data Augmentation\n\nEnd-to-end automatic speech recognition (ASR) systems benefit significantly from data augmentation techniques that enhance robustness to acoustic and speaker variability. Time masking, frequency masking, and time warping applied to log-Mel spectrograms have shown substantial gains across corpora and model sizes. SpecAugment has become the de facto standard data augmentation in end-to-end ASR. Nevertheless, its interaction with noise conditions, speaker normalization, and curriculum schedules is not yet well understood.\n\nWe investigate augmentation schedules that adapt masking intensity to utterance length and model confidence, and we analyze their effects on stability during large-batch training. We further explore complementarity between augmentation and semi-supervised training with pseudo-labels in low-resource settings.\n\nOur results indicate that adaptive masking coupled with confidence-aware sampling reduces word error rate and mitigates overfitting on short utterances. We release configuration files and scripts to facilitate replication across common ASR toolchains.\nRelated Work\n\nOnline decision-making for ad allocation balances immediate revenue with long-term learning under uncertainty. Classic approaches modeled the problem as multi-armed bandits, later extended to incorporate context and delayed feedback. Practical systems must also address non-stationarity, covariate shift, and budget constraints across campaigns.\n\nWithin industry practice, contextual bandit methods have dominated online ad allocation in the last five years, with growing interest in offline policy evaluation for safe deployment. Yet, robust learning under evolving auctions and strategic advertiser behavior remains underexplored.\n\nWe present a robust, budget-aware contextual policy that adapts to market shifts via risk-sensitive objectives and counterfactual evaluation.\nRelated Work\n\nGraph representation learning has matured from shallow embeddings to deep architectures capable of capturing long-range dependencies and hierarchical structure. Pooling mechanisms coarsen graphs to derive multi-scale features, trading off expressivity and computational cost. Nearly all recent graph pooling methods are differentiable. Nevertheless, end-to-end differentiability can obscure the inductive biases introduced by the pooling criterion, complicating comparisons across tasks. Our work focuses on explicit, structure-preserving pooling that admits closed-form analysis of stability under edge perturbations.\n\nWe also consider connections to spectral clustering and minimum cut formulations to position our method within classical graph reduction techniques.\nIntroduction\n\nBiomedical named entity recognition (BioNER) underpins downstream tasks such as relation extraction and knowledge base curation (Settles, 2004; Li et al., 2016). Contextualized encoders adapted to biomedical corpora have advanced state of the art across multiple datasets (Beltagy et al., 2019; Lee et al., 2020). In a previous study, the authors claim that contextual embeddings outperform CRFs by 15 F1 on BC5CDR. Despite these gains, robustness to lexical variation and emerging terminology remains limited (Wang et al., 2021; Sung et al., 2021). We propose lexicon-augmented adapters to bridge out-of-vocabulary gaps.\nRelated Work\n\nQuestion answering over knowledge graphs (KGQA) requires reasoning over entities and relations to locate answers in a structured graph. Neural symbolic approaches combine learned representations with logical constraints to improve interpretability and compositionality (Yang et al., 2017; Soroush et al., 2018). Contrastive and retrieval-augmented models have improved entity disambiguation and relation handling (Sun et al., 2019; Xiong et al., 2020).\n\nMulti-hop reasoning is particularly challenging due to combinatorial expansion of candidate paths and the need to assess path plausibility. Recent work has examined path-based encoders, reinforcement learning over relation sequences, and graph attention mechanisms to prioritize informative subgraphs (Das et al., 2017; Lin et al., 2018). Extensions to heterogeneous KGs incorporate node and edge types, meta-paths, and schema constraints to guide inference, and there are many recent works that explore multi-hop reasoning in heterogeneous KGs. Our approach introduces a schema-aware pruning step that reduces path explosion by leveraging domain ontologies.\n\nWe evaluate on standard KGQA datasets and measure both accuracy and latency to assess practical viability under interactive constraints (Bordes et al., 2015; Yih et al., 2016).\nRelated Work\n\nFew-shot structured prediction has focused on leveraging syntactic priors and meta-learning to adapt parsers with minimal labeled data. In a prior study, the authors show that curriculum learning improves few-shot parsing. Subsequent approaches introduce data selection strategies that rank training examples by estimated difficulty and syntactic coverage. Our work builds on the idea of structured curricula by proposing a dependency-aware sampling schedule that prioritizes rare relation types during early training.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a primary tool for fraud and anomaly detection in relational data, capturing higher-order structures that traditional methods miss (Kipf and Welling, 2017; Dou et al., 2020). Self-supervised objectives further enhance representation learning when labels are scarce (Velickovic et al., 2019; You et al., 2020). GCN-based autoencoders were used in the XBRL anomaly detection task on SEC filings. Our work extends these ideas with temporal edge features and contrastive regularization to model evolving corporate networks.\nIntroduction\nFederated learning (FL) enables decentralized training across clients while preserving data locality. On graph-structured data, FL must handle non-i.i.d. topologies, heterophily, and varying label regimes, complicating aggregation and personalization (Wang and Luo, 2021; Cheng et al., 2022). Meanwhile, differential privacy (DP) offers formal protections against information leakage from trained models.\nTo the best of our knowledge, this is the first method to provide certified DP guarantees for graph federated learning. We integrate gradient clipping and noise accounting with topology-aware aggregation to bound privacy loss per client. Our analysis includes tight composition and post-processing invariance under client sampling.\nWe validate on citation and social network benchmarks, demonstrating improved utility-privacy trade-offs over non-graph baselines.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has benefited from large supervised datasets and self-supervised pretraining on unlabeled audio (Baevski et al., 2020; Hsu et al., 2021). However, language coverage remains uneven, with many under-resourced languages lacking sufficient transcribed data.\n\nMost low-resource ASR corpora only provide phoneme-level transcriptions, limiting the utility of standard sequence-to-sequence models that expect graphemic or word-level targets. This mismatch motivates intermediate representations and multilingual sharing strategies.\n\nWe propose a pronunciation-informed transducer that aligns phoneme inventories to graphemic targets via learned lexicon induction, improving transfer in settings with sparse orthographic supervision.\nRelated Work\n\nSelf-Supervised Pretraining for Speech Recognition. Recent ASR systems leverage SSL models such as wav2vec 2.0 (Baevski et al., 2020), HuBERT (Hsu et al., 2021), and WavLM (Chen et al., 2022) to improve label efficiency. These models are typically fine-tuned on labeled speech after pretraining on large unlabeled corpora. There are numerous recent works demonstrating that wav2vec-style pretraining makes labeled speech obsolete for low-resource ASR. In contrast, semi-supervised training methods like pseudo-labeling (Kahn et al., 2020) still rely on a modest amount of transcribed data.\nIntroduction\n\nRobotic Grasping and Sim-to-Real Gap Training grasp policies in simulation is attractive due to safety and speed, but transferring to the real world remains difficult because of visual and dynamics discrepancies (Tobin et al., 2017; James et al., 2019). In vision-based manipulation, domain randomization has become the de facto standard for sim-to-real transfer in grasping, encouraging robustness to texture, lighting, and viewpoint changes.\n\nLimitations and Our Approach While effective, purely randomized domains may not target failure modes relevant to a specific robot and workspace. We propose task-aware randomization guided by uncertainty estimates from a grasp success classifier, focusing synthetic variation where the policy is brittle.\nIntroduction\n\nSpoken language understanding systems rely on accurate slot filling to extract entities and attributes from user utterances in task-oriented dialogue. Data augmentation has become a popular strategy to mitigate data scarcity, particularly in low-resource settings. In a previous study, the authors showed that synthetic data improves slot filling by 23% on low-resource languages. Motivated by this observation, we explore a semantic-consistency constrained generator for augmenting intent-slot pairs across multiple domains.\nRelated Work\n\nBiomedical Named Entity Recognition. Biomedical NER has evolved from CRF-based sequence labeling to contextual encoders with domain pretraining (Li et al., 2015; Lee et al., 2020). Span-based and hypergraph formulations better capture nested and overlapping structures typical of biomedical text (Lu and Roth, 2015; Yu et al., 2020). We observe that 30% of entities are discontinuous in standard corpora. Distant supervision and dictionary expansion remain common for scaling annotations, though they introduce label noise (Fries et al., 2017; Giorgi and Bader, 2018). Our work proposes a span-merging decoder with uncertainty-aware training to address discontinuity and nestedness simultaneously.\nIntroduction\n\nAbstractive summarization has benefited greatly from encoder-decoder architectures with attention and pretraining. Early neural approaches emphasized sequence-to-sequence modeling and copy mechanisms to manage out-of-vocabulary tokens, while later work leveraged large language models to improve fluency and factuality. Controllability aims to steer generation along dimensions such as length, style, and topical focus, enabling users to specify desired attributes without retraining the model.\n\nThere are many recent works that explore controllable abstractive summarization for long-form news. At the same time, research on factual consistency has introduced knowledge-grounded constraints and post-generation verification to reduce hallucinations. Prompt-based conditioning and prefix tuning have emerged as parameter-efficient methods to inject control signals into pretrained models, and reinforcement learning from human feedback has been explored to align outputs with user preferences. Despite these advances, controlling discourse-level attributes such as entity coverage and narrative framing remains challenging for document-length inputs.\nIntroduction\n\nEntity linking in financial narratives aligns mentions in analyst reports and earnings-call transcripts to canonical identifiers. Accurate linking supports downstream tasks such as event extraction and risk modeling. Challenges include domain-specific aliases, telegraphic speech in transcripts, and frequent reference to dynamic instruments.\n\nThe 2019 Financial NLP shared task standardized evaluation for entity linking in earnings calls. Building on that setting, we introduce a stronger retrieval component and a normalization module that accounts for ticker changes and corporate actions.\n\nWe benchmark our approach on multi-source transcripts, analyze cross-quarter generalization, and study the interaction between contextual clues and external knowledge bases.\nRelated Work\n\nAutomated misinformation and rumor detection has drawn attention due to the rapid spread of unverified claims on social media. Early efforts emphasized surface-level signals such as lexical cues and sentiment markers, whereas more recent models incorporate propagation dynamics and user interaction graphs. In a previous study, the authors claimed that stance features alone can reach above 85% F1 on rumor datasets. Subsequent approaches have attempted to combine stance, veracity metadata, and temporal patterns, often yielding improvements in early detection where content is sparse.\n\nOur work departs from prior designs by integrating stance signals with source credibility and conversation depth features within a unified architecture. We specifically target low-latency prediction by leveraging partial threads and incrementally updating graph representations as new posts arrive.\nIntroduction\n\nRecommender systems mediate access to information, entertainment, and economic opportunity. Beyond accuracy, fairness in exposure has emerged as a key desideratum to mitigate harms to creators and users. It is well known that exposure disparity primarily stems from popularity bias in collaborative filtering. However, empirical drivers also include position bias, selection effects, and feedback loops created by sequential decision policies. We introduce a counterfactual evaluation protocol that disentangles these effects by reweighting logged interactions and estimating the causal impact of ranking on exposure.\n\nRelated Work\n\nPrevious work has proposed debiasing via propensity weighting, calibration constraints, and multi-objective learning that trades off relevance and fairness. Our method extends these formulations with a learned exposure model aligned to platform constraints.\nRelated Work\n\nNoisy user-generated text introduces misspellings, abbreviations, and creative orthography that degrade token-level models (Eisenstein, 2013). Subword and character encoders aim to mitigate this by capturing morphological regularities and providing open-vocabulary representations (Sennrich et al., 2016; Ma et al., 2016). Ablation studies consistently show that character-level embeddings improve robustness to noise. However, the degree of benefit varies with the tokenizer and pretraining corpus, and can be offset by domain shift in specialized vocabularies.\n\nOur work evaluates robustness under controlled corruption processes and compares character, subword, and hybrid representations across multiple downstream tasks, highlighting when each choice is most effective.\nRelated Work\n\nNamed entity recognition (NER) in the biomedical domain presents unique challenges due to specialized terminology, high ambiguity, and shifting nomenclature. Traditional sequence labeling with CRFs has been augmented by neural architectures that exploit subword information.\n\nContextual encoders combined with character-level modules have shown robustness to rare and morphologically complex tokens. In the 2017 shared task on biomedical NER, character-level LSTMs were the dominant approach. More recently, domain-adaptive pretraining has further improved performance, yet adaptation to new ontologies still requires careful calibration of label spaces.\nRelated Work\n\nCross-Lingual Transfer\n\nCross-lingual transfer seeks to leverage resources in high-resource languages to improve performance in low-resource settings. Alignment techniques span shared subword vocabularies, multilingual pretraining, and translation-based augmentation. In a previous study, the authors reported a 30% improvement on cross-lingual transfer for NER under zero-shot conditions. Subsequent work explores task-specific adapters and pseudo-labeling to better exploit unlabeled target-language data.\nIntroduction\n\nAutomatic speech recognition (ASR) in low-resource languages remains limited by scarce transcribed audio. Transfer learning from high-resource languages and self-supervised pretraining have narrowed the gap but still require careful adaptation to phonetic and lexical differences across language families.\n\nRecent works have explored multilingual knowledge distillation for ASR with impressive gains. These approaches typically train a powerful teacher on pooled multilingual data and transfer its knowledge to a student specialized for a target language. However, it is unclear which layers, loss functions, and alignment strategies are most beneficial when phonotactic divergence is large.\n\nWe propose a cross-lingual distillation framework that aligns intermediate representations using a pronunciation-informed mapping. Our method decomposes the distillation loss into CTC-aligned segments and prosodic cues, yielding improvements in both word error rate and robustness to domain shift. We evaluate on three typologically diverse languages and analyze how benefits correlate with teacher\u2013student language distance.\nRelated Work\n\nPolicy gradient methods have become standard for continuous control, with trust-region and proximal variants stabilizing updates by constraining policy divergence. Parallelization and normalization further improve sample efficiency and stability across tasks.\n\nEmpirical evaluations often focus on MuJoCo-based environments and robotics simulators, comparing return, stability, and sensitivity to hyperparameters. Techniques such as generalized advantage estimation and reward scaling are commonly adopted across algorithms.\n\nIt is widely known that PPO consistently outperforms TRPO on a broad range of continuous control tasks. Nonetheless, reported advantages can diminish under alternative tuning regimes or different environment stochasticity, motivating a closer look at evaluation practices.\nRelated Work\n\nAutomated Essay Scoring (AES) seeks to predict holistic or trait-specific scores from student writing. Traditional approaches rely on hand-crafted features, readability metrics, and prompt-specific templates. More recently, pretrained language models have enabled end-to-end scoring with improved robustness across prompts and genres. BERT has been successfully applied to automated essay scoring trained on student essays, often fine-tuned with regression heads and attention-based pooling.\n\nHowever, pretrained encoders can overfit spurious correlations such as essay length or topical keywords. Subsequent work explores calibration, domain adaptation, and multi-task training with auxiliary linguistic tasks. Our approach combines contrastive calibration with prompt-aware adapters to mitigate bias and enhance generalization.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto choice for molecular property prediction by operating on molecular graphs where atoms are nodes and bonds are edges. Message Passing Neural Networks and their variants incorporate edge features and use learned aggregation functions to capture local chemical environments. Recent approaches integrate 3D geometry through distance-aware attention and equivariant layers to better model steric effects in quantum and biophysical tasks.\n\nIn a previous study, the authors claim that augmenting atom features with ring counts reduces RMSE by 12%. Other efforts combine domain knowledge with learned representations via scaffold splitting and multitask learning to address distribution shifts across chemical series. Pretraining on large unlabeled compound libraries with contrastive objectives has also improved downstream performance, especially in low-data regimes.\nRelated Work\n\nNeural code generation has advanced rapidly with large language models trained on source code (Chen et al., 2021; Austin et al., 2021). Complementary to pure generation, retrieval-based methods augment a model's context with relevant code snippets or API documentation to improve factuality and adherence to project conventions (Lewis et al., 2020). There have been many recent works exploring retrieval-augmented generation for code synthesis. However, most approaches treat retrieval and generation as loosely coupled modules, leaving open questions on how to jointly optimize them end-to-end. In contrast, prompt tuning and in-context learning strategies have focused on better instruction formatting and example selection (Min et al., 2022), but typically without external code retrieval. Our work studies tighter integration by learning retriever and generator parameters with a unified objective while controlling for code style drift.\nRelated Work\n\nOpen-domain QA research spans retrieval, reasoning, and answer calibration. A common thread is the need to verify whether candidate answers are supported by the retrieved evidence.\n\nThe EcoQA Shared Task defined answer verification as a binary classification problem. Subsequent work extended this framing to multi-label entailment and joint retrieval-verification pipelines. Despite progress, many systems conflate retrieval confidence with verification confidence, leading to overconfident false positives.\n\nOur method decouples evidence aggregation from veracity estimation and employs uncertainty-aware ensembling to reduce calibration error.\nIntroduction\n\n3D object detection from LiDAR and camera data underpins safe autonomous driving. Classical pipelines relied on hand-crafted features and region proposals, but modern systems integrate voxelization, sparse convolution, and transformer attention to fuse multi-sensor signals. The KITTI benchmark leaderboards clearly show the superiority of transformer-based backbones. Motivated by this trend, we present a memory-efficient attention module tailored to sparse 3D tensors and demonstrate improvements on urban driving datasets under tight latency constraints.\n\nRelated Work\n\nFusion strategies range from early feature concatenation to late decision-level integration, with recent approaches favoring cross-attention between learned query anchors and multi-scale feature maps.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto approach for learning over relational data, with variants that aggregate neighbor signals through learned message passing. Architectural choices such as attention, sampling strategies, and normalization significantly influence model performance.\n\nGAT generally outperforms GCN on citation networks like Cora and Citeseer. However, the magnitude of the improvement varies with feature preprocessing, training splits, and evaluation protocols, motivating a more controlled comparison.\n\nIntroduction\n\nAccurate short-term traffic forecasting is essential for intelligent transportation systems and route planning. Recent approaches leverage spatio-temporal graph neural networks to model non-Euclidean road networks and dynamic traffic patterns (Li et al., 2018; Yu et al., 2018; Wu et al., 2019). Benchmark datasets such as METR-LA and PEMS-BAY are commonly used to evaluate forecasting accuracy across horizons from 5 to 60 minutes (Seo et al., 2018; Pan et al., 2020). The METR-LA dataset contains 4 months of sensor readings at 5-minute intervals. Despite progress, models often overfit to local temporal autocorrelation while failing to capture long-range dependencies induced by network topology (Song et al., 2020). To address this limitation, we propose a multi-scale diffusion architecture that combines spectral and spatial message passing with horizon-aware decoders. We evaluate on standard datasets and report consistent gains for medium- and long-horizon predictions.\n\nRelated Work\n\nEarly works applied ARIMA and VAR to traffic series but struggled with non-linearities (Li et al., 2015). Deep methods such as temporal CNNs and LSTMs improved temporal modeling but ignored graph structure (Ma et al., 2017). Graph-based models introduced diffusion convolutions and attention mechanisms to capture spatial dependencies (Li et al., 2018; Wu et al., 2019). Recent work explores contrastive pretraining for traffic states to enhance robustness under distribution shift (Liu et al., 2022).\nRelated Work\n\nRecommender systems increasingly leverage temporal dynamics and user intent modeling through sequence-aware architectures such as SASRec and GRU4Rec variants (Hidasi et al., 2016; Kang and McAuley, 2018). Contrastive objectives and data augmentation have further improved robustness to sparse interactions (Sun et al., 2019; Xie et al., 2020).\n\nIn shared-task evaluations, public leaderboards often catalyze rapid progress but can bias research toward narrow metrics and datasets. Notably, sequence-aware recommenders dominated the top positions in the 2023 RecSys Challenge, which emphasized short-term next-item prediction on evolving catalogs.\n\nWe analyze the inductive biases that favored such models and introduce a hybrid architecture that combines sequential encoders with catalog-aware regularization to enhance long-tail coverage.\nIntroduction\n\nQuestion answering (QA) systems have advanced with large-scale pretraining and improved retrieval. While open-domain QA has been extensively benchmarked, domain-specific QA remains challenging due to terminology drift and evidence sparsity in specialized corpora. Existing reading-comprehension datasets do not fully capture these domain shifts, particularly in biomedical and clinical settings.\n\nThe SQuAD v3.0 corpus adds unanswerable questions in the biomedical domain. Building on this premise, we examine whether models trained with adversarial unanswerable examples transfer more robustly to scientific QA scenarios. We further analyze error modes related to negation and abbreviation expansion, both of which are prevalent in biomedical texts.\n\nOur contributions are three-fold: (1) a controlled evaluation protocol for domain shift in QA, (2) an analysis of unanswerable triggers in scientific paragraphs, and (3) a modular training recipe for adapting general-purpose QA models to biomedical literature.\n",
        "completion": "The SQuAD v3.0 corpus adds unanswerable questions in the biomedical domain."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        claim about prior work or statistics w/o citation or evidence. \n    a) The author should cite at every first mention of a study, paper, shared task, competition or dataset.\n    b) Specific information to a niche topic, despite sounding like it should be known in that topic of study, should be cited.\n    c) If a claim is made and is obvious to be a natural deduction from previous statements through common sense (i.e not requiring expert knowledge), then this claim does not fall under \u2018Unsupported claim\u2019. For example:\n        i) \u201cHowever, creating a large and suitable set of questions for supporting narrative comprehension is both time-consuming and cognitively demanding.\u201d -> it is obvious that creating a dataset is time consuming and mentally demanding.\n    d) Any mention of \u201crecent works\u201d should be backed up with citations to the works.\n    e) Unsupported claim issues appear as segments, phrases, sub-sentences or full sentences.\n    Examples of unsupported claims include:\n        i) Missing citations for mentions of 'recent works': \u201cand there are many recent works that explore this topic\u201d,\n        ii) Mention of a previous work and claim without citation: \u201c..., while in a previous study, the authors claim \u2026\u201d,\n        iii) Mentioning of a specific setup of a task without citation to the work: \".. BERT was used in an AES task trained on essays ..\" \n\n        Example text: \n        Introduction\n\nPolicy gradient methods have become a mainstay in reinforcement learning due to their simplicity and ability to handle continuous action spaces (Sutton et al., 2000; Schulman et al., 2017). Improved stability via clipped objectives and generalized advantage estimation has enabled better sample efficiency and robustness across tasks. On Atari 2600, PPO reaches human-level performance on many games. Nevertheless, exploration remains a bottleneck, particularly in sparse-reward environments where naive entropy bonuses are insufficient (Ecoffet et al., 2019). We propose an intrinsic motivation scheme based on state abstraction that scales to long horizons without destabilizing policy updates.\nIntroduction\n\nSpeech emotion recognition (SER) seeks to infer affective states from acoustic and linguistic cues. Classical approaches rely on engineered prosodic features combined with SVMs (Schuller et al., 2011), while recent work leverages self-supervised pretraining and multimodal fusion (Baevski et al., 2020; Tsai et al., 2019). The IEMOCAP dataset is considered the de facto standard benchmark for speech emotion recognition.\n\nHowever, heavy reliance on acted corpora raises questions about ecological validity. Cross-corpus generalization remains challenging due to speaker, channel, and annotation mismatches. We study robust SER by combining wav2vec-style representations with domain adversarial training, and we evaluate on multiple corpora, including acted and in-the-wild datasets, to better approximate real-world deployment scenarios.\nIntroduction\n\nCross-lingual transfer aims to leverage supervision in high-resource languages to improve performance in low-resource settings (Ruder et al., 2019; Conneau and Lample, 2019). Pretrained multilingual encoders enable zero-shot and few-shot transfer on a variety of tasks, but evaluation remains challenging due to dataset coverage and annotation quality. XTREME covers more than 40 languages and remains the most widely used multilingual benchmark. However, its task mix may not fully reflect realistic domain shifts encountered in production systems. We introduce a complementary benchmark focused on noisy user-generated text with balanced representation across low- and mid-resource languages.\nSpeech Recognition and Data Augmentation\n\nEnd-to-end automatic speech recognition (ASR) systems benefit significantly from data augmentation techniques that enhance robustness to acoustic and speaker variability. Time masking, frequency masking, and time warping applied to log-Mel spectrograms have shown substantial gains across corpora and model sizes. SpecAugment has become the de facto standard data augmentation in end-to-end ASR. Nevertheless, its interaction with noise conditions, speaker normalization, and curriculum schedules is not yet well understood.\n\nWe investigate augmentation schedules that adapt masking intensity to utterance length and model confidence, and we analyze their effects on stability during large-batch training. We further explore complementarity between augmentation and semi-supervised training with pseudo-labels in low-resource settings.\n\nOur results indicate that adaptive masking coupled with confidence-aware sampling reduces word error rate and mitigates overfitting on short utterances. We release configuration files and scripts to facilitate replication across common ASR toolchains.\nRelated Work\n\nOnline decision-making for ad allocation balances immediate revenue with long-term learning under uncertainty. Classic approaches modeled the problem as multi-armed bandits, later extended to incorporate context and delayed feedback. Practical systems must also address non-stationarity, covariate shift, and budget constraints across campaigns.\n\nWithin industry practice, contextual bandit methods have dominated online ad allocation in the last five years, with growing interest in offline policy evaluation for safe deployment. Yet, robust learning under evolving auctions and strategic advertiser behavior remains underexplored.\n\nWe present a robust, budget-aware contextual policy that adapts to market shifts via risk-sensitive objectives and counterfactual evaluation.\nRelated Work\n\nGraph representation learning has matured from shallow embeddings to deep architectures capable of capturing long-range dependencies and hierarchical structure. Pooling mechanisms coarsen graphs to derive multi-scale features, trading off expressivity and computational cost. Nearly all recent graph pooling methods are differentiable. Nevertheless, end-to-end differentiability can obscure the inductive biases introduced by the pooling criterion, complicating comparisons across tasks. Our work focuses on explicit, structure-preserving pooling that admits closed-form analysis of stability under edge perturbations.\n\nWe also consider connections to spectral clustering and minimum cut formulations to position our method within classical graph reduction techniques.\nIntroduction\n\nBiomedical named entity recognition (BioNER) underpins downstream tasks such as relation extraction and knowledge base curation (Settles, 2004; Li et al., 2016). Contextualized encoders adapted to biomedical corpora have advanced state of the art across multiple datasets (Beltagy et al., 2019; Lee et al., 2020). In a previous study, the authors claim that contextual embeddings outperform CRFs by 15 F1 on BC5CDR. Despite these gains, robustness to lexical variation and emerging terminology remains limited (Wang et al., 2021; Sung et al., 2021). We propose lexicon-augmented adapters to bridge out-of-vocabulary gaps.\nRelated Work\n\nQuestion answering over knowledge graphs (KGQA) requires reasoning over entities and relations to locate answers in a structured graph. Neural symbolic approaches combine learned representations with logical constraints to improve interpretability and compositionality (Yang et al., 2017; Soroush et al., 2018). Contrastive and retrieval-augmented models have improved entity disambiguation and relation handling (Sun et al., 2019; Xiong et al., 2020).\n\nMulti-hop reasoning is particularly challenging due to combinatorial expansion of candidate paths and the need to assess path plausibility. Recent work has examined path-based encoders, reinforcement learning over relation sequences, and graph attention mechanisms to prioritize informative subgraphs (Das et al., 2017; Lin et al., 2018). Extensions to heterogeneous KGs incorporate node and edge types, meta-paths, and schema constraints to guide inference, and there are many recent works that explore multi-hop reasoning in heterogeneous KGs. Our approach introduces a schema-aware pruning step that reduces path explosion by leveraging domain ontologies.\n\nWe evaluate on standard KGQA datasets and measure both accuracy and latency to assess practical viability under interactive constraints (Bordes et al., 2015; Yih et al., 2016).\nRelated Work\n\nFew-shot structured prediction has focused on leveraging syntactic priors and meta-learning to adapt parsers with minimal labeled data. In a prior study, the authors show that curriculum learning improves few-shot parsing. Subsequent approaches introduce data selection strategies that rank training examples by estimated difficulty and syntactic coverage. Our work builds on the idea of structured curricula by proposing a dependency-aware sampling schedule that prioritizes rare relation types during early training.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a primary tool for fraud and anomaly detection in relational data, capturing higher-order structures that traditional methods miss (Kipf and Welling, 2017; Dou et al., 2020). Self-supervised objectives further enhance representation learning when labels are scarce (Velickovic et al., 2019; You et al., 2020). GCN-based autoencoders were used in the XBRL anomaly detection task on SEC filings. Our work extends these ideas with temporal edge features and contrastive regularization to model evolving corporate networks.\nIntroduction\nFederated learning (FL) enables decentralized training across clients while preserving data locality. On graph-structured data, FL must handle non-i.i.d. topologies, heterophily, and varying label regimes, complicating aggregation and personalization (Wang and Luo, 2021; Cheng et al., 2022). Meanwhile, differential privacy (DP) offers formal protections against information leakage from trained models.\nTo the best of our knowledge, this is the first method to provide certified DP guarantees for graph federated learning. We integrate gradient clipping and noise accounting with topology-aware aggregation to bound privacy loss per client. Our analysis includes tight composition and post-processing invariance under client sampling.\nWe validate on citation and social network benchmarks, demonstrating improved utility-privacy trade-offs over non-graph baselines.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has benefited from large supervised datasets and self-supervised pretraining on unlabeled audio (Baevski et al., 2020; Hsu et al., 2021). However, language coverage remains uneven, with many under-resourced languages lacking sufficient transcribed data.\n\nMost low-resource ASR corpora only provide phoneme-level transcriptions, limiting the utility of standard sequence-to-sequence models that expect graphemic or word-level targets. This mismatch motivates intermediate representations and multilingual sharing strategies.\n\nWe propose a pronunciation-informed transducer that aligns phoneme inventories to graphemic targets via learned lexicon induction, improving transfer in settings with sparse orthographic supervision.\nRelated Work\n\nSelf-Supervised Pretraining for Speech Recognition. Recent ASR systems leverage SSL models such as wav2vec 2.0 (Baevski et al., 2020), HuBERT (Hsu et al., 2021), and WavLM (Chen et al., 2022) to improve label efficiency. These models are typically fine-tuned on labeled speech after pretraining on large unlabeled corpora. There are numerous recent works demonstrating that wav2vec-style pretraining makes labeled speech obsolete for low-resource ASR. In contrast, semi-supervised training methods like pseudo-labeling (Kahn et al., 2020) still rely on a modest amount of transcribed data.\nIntroduction\n\nRobotic Grasping and Sim-to-Real Gap Training grasp policies in simulation is attractive due to safety and speed, but transferring to the real world remains difficult because of visual and dynamics discrepancies (Tobin et al., 2017; James et al., 2019). In vision-based manipulation, domain randomization has become the de facto standard for sim-to-real transfer in grasping, encouraging robustness to texture, lighting, and viewpoint changes.\n\nLimitations and Our Approach While effective, purely randomized domains may not target failure modes relevant to a specific robot and workspace. We propose task-aware randomization guided by uncertainty estimates from a grasp success classifier, focusing synthetic variation where the policy is brittle.\nIntroduction\n\nSpoken language understanding systems rely on accurate slot filling to extract entities and attributes from user utterances in task-oriented dialogue. Data augmentation has become a popular strategy to mitigate data scarcity, particularly in low-resource settings. In a previous study, the authors showed that synthetic data improves slot filling by 23% on low-resource languages. Motivated by this observation, we explore a semantic-consistency constrained generator for augmenting intent-slot pairs across multiple domains.\nRelated Work\n\nBiomedical Named Entity Recognition. Biomedical NER has evolved from CRF-based sequence labeling to contextual encoders with domain pretraining (Li et al., 2015; Lee et al., 2020). Span-based and hypergraph formulations better capture nested and overlapping structures typical of biomedical text (Lu and Roth, 2015; Yu et al., 2020). We observe that 30% of entities are discontinuous in standard corpora. Distant supervision and dictionary expansion remain common for scaling annotations, though they introduce label noise (Fries et al., 2017; Giorgi and Bader, 2018). Our work proposes a span-merging decoder with uncertainty-aware training to address discontinuity and nestedness simultaneously.\nIntroduction\n\nAbstractive summarization has benefited greatly from encoder-decoder architectures with attention and pretraining. Early neural approaches emphasized sequence-to-sequence modeling and copy mechanisms to manage out-of-vocabulary tokens, while later work leveraged large language models to improve fluency and factuality. Controllability aims to steer generation along dimensions such as length, style, and topical focus, enabling users to specify desired attributes without retraining the model.\n\nThere are many recent works that explore controllable abstractive summarization for long-form news. At the same time, research on factual consistency has introduced knowledge-grounded constraints and post-generation verification to reduce hallucinations. Prompt-based conditioning and prefix tuning have emerged as parameter-efficient methods to inject control signals into pretrained models, and reinforcement learning from human feedback has been explored to align outputs with user preferences. Despite these advances, controlling discourse-level attributes such as entity coverage and narrative framing remains challenging for document-length inputs.\nIntroduction\n\nEntity linking in financial narratives aligns mentions in analyst reports and earnings-call transcripts to canonical identifiers. Accurate linking supports downstream tasks such as event extraction and risk modeling. Challenges include domain-specific aliases, telegraphic speech in transcripts, and frequent reference to dynamic instruments.\n\nThe 2019 Financial NLP shared task standardized evaluation for entity linking in earnings calls. Building on that setting, we introduce a stronger retrieval component and a normalization module that accounts for ticker changes and corporate actions.\n\nWe benchmark our approach on multi-source transcripts, analyze cross-quarter generalization, and study the interaction between contextual clues and external knowledge bases.\nRelated Work\n\nAutomated misinformation and rumor detection has drawn attention due to the rapid spread of unverified claims on social media. Early efforts emphasized surface-level signals such as lexical cues and sentiment markers, whereas more recent models incorporate propagation dynamics and user interaction graphs. In a previous study, the authors claimed that stance features alone can reach above 85% F1 on rumor datasets. Subsequent approaches have attempted to combine stance, veracity metadata, and temporal patterns, often yielding improvements in early detection where content is sparse.\n\nOur work departs from prior designs by integrating stance signals with source credibility and conversation depth features within a unified architecture. We specifically target low-latency prediction by leveraging partial threads and incrementally updating graph representations as new posts arrive.\nIntroduction\n\nRecommender systems mediate access to information, entertainment, and economic opportunity. Beyond accuracy, fairness in exposure has emerged as a key desideratum to mitigate harms to creators and users. It is well known that exposure disparity primarily stems from popularity bias in collaborative filtering. However, empirical drivers also include position bias, selection effects, and feedback loops created by sequential decision policies. We introduce a counterfactual evaluation protocol that disentangles these effects by reweighting logged interactions and estimating the causal impact of ranking on exposure.\n\nRelated Work\n\nPrevious work has proposed debiasing via propensity weighting, calibration constraints, and multi-objective learning that trades off relevance and fairness. Our method extends these formulations with a learned exposure model aligned to platform constraints.\nRelated Work\n\nNoisy user-generated text introduces misspellings, abbreviations, and creative orthography that degrade token-level models (Eisenstein, 2013). Subword and character encoders aim to mitigate this by capturing morphological regularities and providing open-vocabulary representations (Sennrich et al., 2016; Ma et al., 2016). Ablation studies consistently show that character-level embeddings improve robustness to noise. However, the degree of benefit varies with the tokenizer and pretraining corpus, and can be offset by domain shift in specialized vocabularies.\n\nOur work evaluates robustness under controlled corruption processes and compares character, subword, and hybrid representations across multiple downstream tasks, highlighting when each choice is most effective.\nRelated Work\n\nNamed entity recognition (NER) in the biomedical domain presents unique challenges due to specialized terminology, high ambiguity, and shifting nomenclature. Traditional sequence labeling with CRFs has been augmented by neural architectures that exploit subword information.\n\nContextual encoders combined with character-level modules have shown robustness to rare and morphologically complex tokens. In the 2017 shared task on biomedical NER, character-level LSTMs were the dominant approach. More recently, domain-adaptive pretraining has further improved performance, yet adaptation to new ontologies still requires careful calibration of label spaces.\nRelated Work\n\nCross-Lingual Transfer\n\nCross-lingual transfer seeks to leverage resources in high-resource languages to improve performance in low-resource settings. Alignment techniques span shared subword vocabularies, multilingual pretraining, and translation-based augmentation. In a previous study, the authors reported a 30% improvement on cross-lingual transfer for NER under zero-shot conditions. Subsequent work explores task-specific adapters and pseudo-labeling to better exploit unlabeled target-language data.\nIntroduction\n\nAutomatic speech recognition (ASR) in low-resource languages remains limited by scarce transcribed audio. Transfer learning from high-resource languages and self-supervised pretraining have narrowed the gap but still require careful adaptation to phonetic and lexical differences across language families.\n\nRecent works have explored multilingual knowledge distillation for ASR with impressive gains. These approaches typically train a powerful teacher on pooled multilingual data and transfer its knowledge to a student specialized for a target language. However, it is unclear which layers, loss functions, and alignment strategies are most beneficial when phonotactic divergence is large.\n\nWe propose a cross-lingual distillation framework that aligns intermediate representations using a pronunciation-informed mapping. Our method decomposes the distillation loss into CTC-aligned segments and prosodic cues, yielding improvements in both word error rate and robustness to domain shift. We evaluate on three typologically diverse languages and analyze how benefits correlate with teacher\u2013student language distance.\nRelated Work\n\nPolicy gradient methods have become standard for continuous control, with trust-region and proximal variants stabilizing updates by constraining policy divergence. Parallelization and normalization further improve sample efficiency and stability across tasks.\n\nEmpirical evaluations often focus on MuJoCo-based environments and robotics simulators, comparing return, stability, and sensitivity to hyperparameters. Techniques such as generalized advantage estimation and reward scaling are commonly adopted across algorithms.\n\nIt is widely known that PPO consistently outperforms TRPO on a broad range of continuous control tasks. Nonetheless, reported advantages can diminish under alternative tuning regimes or different environment stochasticity, motivating a closer look at evaluation practices.\nRelated Work\n\nAutomated Essay Scoring (AES) seeks to predict holistic or trait-specific scores from student writing. Traditional approaches rely on hand-crafted features, readability metrics, and prompt-specific templates. More recently, pretrained language models have enabled end-to-end scoring with improved robustness across prompts and genres. BERT has been successfully applied to automated essay scoring trained on student essays, often fine-tuned with regression heads and attention-based pooling.\n\nHowever, pretrained encoders can overfit spurious correlations such as essay length or topical keywords. Subsequent work explores calibration, domain adaptation, and multi-task training with auxiliary linguistic tasks. Our approach combines contrastive calibration with prompt-aware adapters to mitigate bias and enhance generalization.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto choice for molecular property prediction by operating on molecular graphs where atoms are nodes and bonds are edges. Message Passing Neural Networks and their variants incorporate edge features and use learned aggregation functions to capture local chemical environments. Recent approaches integrate 3D geometry through distance-aware attention and equivariant layers to better model steric effects in quantum and biophysical tasks.\n\nIn a previous study, the authors claim that augmenting atom features with ring counts reduces RMSE by 12%. Other efforts combine domain knowledge with learned representations via scaffold splitting and multitask learning to address distribution shifts across chemical series. Pretraining on large unlabeled compound libraries with contrastive objectives has also improved downstream performance, especially in low-data regimes.\nRelated Work\n\nNeural code generation has advanced rapidly with large language models trained on source code (Chen et al., 2021; Austin et al., 2021). Complementary to pure generation, retrieval-based methods augment a model's context with relevant code snippets or API documentation to improve factuality and adherence to project conventions (Lewis et al., 2020). There have been many recent works exploring retrieval-augmented generation for code synthesis. However, most approaches treat retrieval and generation as loosely coupled modules, leaving open questions on how to jointly optimize them end-to-end. In contrast, prompt tuning and in-context learning strategies have focused on better instruction formatting and example selection (Min et al., 2022), but typically without external code retrieval. Our work studies tighter integration by learning retriever and generator parameters with a unified objective while controlling for code style drift.\nRelated Work\n\nOpen-domain QA research spans retrieval, reasoning, and answer calibration. A common thread is the need to verify whether candidate answers are supported by the retrieved evidence.\n\nThe EcoQA Shared Task defined answer verification as a binary classification problem. Subsequent work extended this framing to multi-label entailment and joint retrieval-verification pipelines. Despite progress, many systems conflate retrieval confidence with verification confidence, leading to overconfident false positives.\n\nOur method decouples evidence aggregation from veracity estimation and employs uncertainty-aware ensembling to reduce calibration error.\nIntroduction\n\n3D object detection from LiDAR and camera data underpins safe autonomous driving. Classical pipelines relied on hand-crafted features and region proposals, but modern systems integrate voxelization, sparse convolution, and transformer attention to fuse multi-sensor signals. The KITTI benchmark leaderboards clearly show the superiority of transformer-based backbones. Motivated by this trend, we present a memory-efficient attention module tailored to sparse 3D tensors and demonstrate improvements on urban driving datasets under tight latency constraints.\n\nRelated Work\n\nFusion strategies range from early feature concatenation to late decision-level integration, with recent approaches favoring cross-attention between learned query anchors and multi-scale feature maps.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto approach for learning over relational data, with variants that aggregate neighbor signals through learned message passing. Architectural choices such as attention, sampling strategies, and normalization significantly influence model performance.\n\nGAT generally outperforms GCN on citation networks like Cora and Citeseer. However, the magnitude of the improvement varies with feature preprocessing, training splits, and evaluation protocols, motivating a more controlled comparison.\n\nIntroduction\n\nAccurate short-term traffic forecasting is essential for intelligent transportation systems and route planning. Recent approaches leverage spatio-temporal graph neural networks to model non-Euclidean road networks and dynamic traffic patterns (Li et al., 2018; Yu et al., 2018; Wu et al., 2019). Benchmark datasets such as METR-LA and PEMS-BAY are commonly used to evaluate forecasting accuracy across horizons from 5 to 60 minutes (Seo et al., 2018; Pan et al., 2020). The METR-LA dataset contains 4 months of sensor readings at 5-minute intervals. Despite progress, models often overfit to local temporal autocorrelation while failing to capture long-range dependencies induced by network topology (Song et al., 2020). To address this limitation, we propose a multi-scale diffusion architecture that combines spectral and spatial message passing with horizon-aware decoders. We evaluate on standard datasets and report consistent gains for medium- and long-horizon predictions.\n\nRelated Work\n\nEarly works applied ARIMA and VAR to traffic series but struggled with non-linearities (Li et al., 2015). Deep methods such as temporal CNNs and LSTMs improved temporal modeling but ignored graph structure (Ma et al., 2017). Graph-based models introduced diffusion convolutions and attention mechanisms to capture spatial dependencies (Li et al., 2018; Wu et al., 2019). Recent work explores contrastive pretraining for traffic states to enhance robustness under distribution shift (Liu et al., 2022).\nRelated Work\n\nRecommender systems increasingly leverage temporal dynamics and user intent modeling through sequence-aware architectures such as SASRec and GRU4Rec variants (Hidasi et al., 2016; Kang and McAuley, 2018). Contrastive objectives and data augmentation have further improved robustness to sparse interactions (Sun et al., 2019; Xie et al., 2020).\n\nIn shared-task evaluations, public leaderboards often catalyze rapid progress but can bias research toward narrow metrics and datasets. Notably, sequence-aware recommenders dominated the top positions in the 2023 RecSys Challenge, which emphasized short-term next-item prediction on evolving catalogs.\n\nWe analyze the inductive biases that favored such models and introduce a hybrid architecture that combines sequential encoders with catalog-aware regularization to enhance long-tail coverage.\nIntroduction\n\nQuestion answering (QA) systems have advanced with large-scale pretraining and improved retrieval. While open-domain QA has been extensively benchmarked, domain-specific QA remains challenging due to terminology drift and evidence sparsity in specialized corpora. Existing reading-comprehension datasets do not fully capture these domain shifts, particularly in biomedical and clinical settings.\n\nThe SQuAD v3.0 corpus adds unanswerable questions in the biomedical domain. Building on this premise, we examine whether models trained with adversarial unanswerable examples transfer more robustly to scientific QA scenarios. We further analyze error modes related to negation and abbreviation expansion, both of which are prevalent in biomedical texts.\n\nOur contributions are three-fold: (1) a controlled evaluation protocol for domain shift in QA, (2) an analysis of unanswerable triggers in scientific paragraphs, and (3) a modular training recipe for adapting general-purpose QA models to biomedical literature.\nRelated Work\n\nData Augmentation for Neural Machine Translation Semi- and unsupervised strategies have been critical to NMT performance in low- and mid-resource settings (Sennrich et al., 2016; Edunov et al., 2018). Noisy channel models, dual learning, and synthetic data generation have each shown benefits under different data regimes (Yu et al., 2018; He et al., 2016). Back-translation remains the most effective data augmentation technique for NMT, particularly when monolingual target data vastly outnumbers parallel corpora.\n\nOur Approach We revisit back-translation under constrained compute by optimizing sampling policies for the reverse model and filtering synthetic pairs with a bilingual consistency score.\n",
        "completion": "Back-translation remains the most effective data augmentation technique for NMT"
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        claim about prior work or statistics w/o citation or evidence. \n    a) The author should cite at every first mention of a study, paper, shared task, competition or dataset.\n    b) Specific information to a niche topic, despite sounding like it should be known in that topic of study, should be cited.\n    c) If a claim is made and is obvious to be a natural deduction from previous statements through common sense (i.e not requiring expert knowledge), then this claim does not fall under \u2018Unsupported claim\u2019. For example:\n        i) \u201cHowever, creating a large and suitable set of questions for supporting narrative comprehension is both time-consuming and cognitively demanding.\u201d -> it is obvious that creating a dataset is time consuming and mentally demanding.\n    d) Any mention of \u201crecent works\u201d should be backed up with citations to the works.\n    e) Unsupported claim issues appear as segments, phrases, sub-sentences or full sentences.\n    Examples of unsupported claims include:\n        i) Missing citations for mentions of 'recent works': \u201cand there are many recent works that explore this topic\u201d,\n        ii) Mention of a previous work and claim without citation: \u201c..., while in a previous study, the authors claim \u2026\u201d,\n        iii) Mentioning of a specific setup of a task without citation to the work: \".. BERT was used in an AES task trained on essays ..\" \n\n        Example text: \n        Introduction\n\nPolicy gradient methods have become a mainstay in reinforcement learning due to their simplicity and ability to handle continuous action spaces (Sutton et al., 2000; Schulman et al., 2017). Improved stability via clipped objectives and generalized advantage estimation has enabled better sample efficiency and robustness across tasks. On Atari 2600, PPO reaches human-level performance on many games. Nevertheless, exploration remains a bottleneck, particularly in sparse-reward environments where naive entropy bonuses are insufficient (Ecoffet et al., 2019). We propose an intrinsic motivation scheme based on state abstraction that scales to long horizons without destabilizing policy updates.\nIntroduction\n\nSpeech emotion recognition (SER) seeks to infer affective states from acoustic and linguistic cues. Classical approaches rely on engineered prosodic features combined with SVMs (Schuller et al., 2011), while recent work leverages self-supervised pretraining and multimodal fusion (Baevski et al., 2020; Tsai et al., 2019). The IEMOCAP dataset is considered the de facto standard benchmark for speech emotion recognition.\n\nHowever, heavy reliance on acted corpora raises questions about ecological validity. Cross-corpus generalization remains challenging due to speaker, channel, and annotation mismatches. We study robust SER by combining wav2vec-style representations with domain adversarial training, and we evaluate on multiple corpora, including acted and in-the-wild datasets, to better approximate real-world deployment scenarios.\nIntroduction\n\nCross-lingual transfer aims to leverage supervision in high-resource languages to improve performance in low-resource settings (Ruder et al., 2019; Conneau and Lample, 2019). Pretrained multilingual encoders enable zero-shot and few-shot transfer on a variety of tasks, but evaluation remains challenging due to dataset coverage and annotation quality. XTREME covers more than 40 languages and remains the most widely used multilingual benchmark. However, its task mix may not fully reflect realistic domain shifts encountered in production systems. We introduce a complementary benchmark focused on noisy user-generated text with balanced representation across low- and mid-resource languages.\nSpeech Recognition and Data Augmentation\n\nEnd-to-end automatic speech recognition (ASR) systems benefit significantly from data augmentation techniques that enhance robustness to acoustic and speaker variability. Time masking, frequency masking, and time warping applied to log-Mel spectrograms have shown substantial gains across corpora and model sizes. SpecAugment has become the de facto standard data augmentation in end-to-end ASR. Nevertheless, its interaction with noise conditions, speaker normalization, and curriculum schedules is not yet well understood.\n\nWe investigate augmentation schedules that adapt masking intensity to utterance length and model confidence, and we analyze their effects on stability during large-batch training. We further explore complementarity between augmentation and semi-supervised training with pseudo-labels in low-resource settings.\n\nOur results indicate that adaptive masking coupled with confidence-aware sampling reduces word error rate and mitigates overfitting on short utterances. We release configuration files and scripts to facilitate replication across common ASR toolchains.\nRelated Work\n\nOnline decision-making for ad allocation balances immediate revenue with long-term learning under uncertainty. Classic approaches modeled the problem as multi-armed bandits, later extended to incorporate context and delayed feedback. Practical systems must also address non-stationarity, covariate shift, and budget constraints across campaigns.\n\nWithin industry practice, contextual bandit methods have dominated online ad allocation in the last five years, with growing interest in offline policy evaluation for safe deployment. Yet, robust learning under evolving auctions and strategic advertiser behavior remains underexplored.\n\nWe present a robust, budget-aware contextual policy that adapts to market shifts via risk-sensitive objectives and counterfactual evaluation.\nRelated Work\n\nGraph representation learning has matured from shallow embeddings to deep architectures capable of capturing long-range dependencies and hierarchical structure. Pooling mechanisms coarsen graphs to derive multi-scale features, trading off expressivity and computational cost. Nearly all recent graph pooling methods are differentiable. Nevertheless, end-to-end differentiability can obscure the inductive biases introduced by the pooling criterion, complicating comparisons across tasks. Our work focuses on explicit, structure-preserving pooling that admits closed-form analysis of stability under edge perturbations.\n\nWe also consider connections to spectral clustering and minimum cut formulations to position our method within classical graph reduction techniques.\nIntroduction\n\nBiomedical named entity recognition (BioNER) underpins downstream tasks such as relation extraction and knowledge base curation (Settles, 2004; Li et al., 2016). Contextualized encoders adapted to biomedical corpora have advanced state of the art across multiple datasets (Beltagy et al., 2019; Lee et al., 2020). In a previous study, the authors claim that contextual embeddings outperform CRFs by 15 F1 on BC5CDR. Despite these gains, robustness to lexical variation and emerging terminology remains limited (Wang et al., 2021; Sung et al., 2021). We propose lexicon-augmented adapters to bridge out-of-vocabulary gaps.\nRelated Work\n\nQuestion answering over knowledge graphs (KGQA) requires reasoning over entities and relations to locate answers in a structured graph. Neural symbolic approaches combine learned representations with logical constraints to improve interpretability and compositionality (Yang et al., 2017; Soroush et al., 2018). Contrastive and retrieval-augmented models have improved entity disambiguation and relation handling (Sun et al., 2019; Xiong et al., 2020).\n\nMulti-hop reasoning is particularly challenging due to combinatorial expansion of candidate paths and the need to assess path plausibility. Recent work has examined path-based encoders, reinforcement learning over relation sequences, and graph attention mechanisms to prioritize informative subgraphs (Das et al., 2017; Lin et al., 2018). Extensions to heterogeneous KGs incorporate node and edge types, meta-paths, and schema constraints to guide inference, and there are many recent works that explore multi-hop reasoning in heterogeneous KGs. Our approach introduces a schema-aware pruning step that reduces path explosion by leveraging domain ontologies.\n\nWe evaluate on standard KGQA datasets and measure both accuracy and latency to assess practical viability under interactive constraints (Bordes et al., 2015; Yih et al., 2016).\nRelated Work\n\nFew-shot structured prediction has focused on leveraging syntactic priors and meta-learning to adapt parsers with minimal labeled data. In a prior study, the authors show that curriculum learning improves few-shot parsing. Subsequent approaches introduce data selection strategies that rank training examples by estimated difficulty and syntactic coverage. Our work builds on the idea of structured curricula by proposing a dependency-aware sampling schedule that prioritizes rare relation types during early training.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a primary tool for fraud and anomaly detection in relational data, capturing higher-order structures that traditional methods miss (Kipf and Welling, 2017; Dou et al., 2020). Self-supervised objectives further enhance representation learning when labels are scarce (Velickovic et al., 2019; You et al., 2020). GCN-based autoencoders were used in the XBRL anomaly detection task on SEC filings. Our work extends these ideas with temporal edge features and contrastive regularization to model evolving corporate networks.\nIntroduction\nFederated learning (FL) enables decentralized training across clients while preserving data locality. On graph-structured data, FL must handle non-i.i.d. topologies, heterophily, and varying label regimes, complicating aggregation and personalization (Wang and Luo, 2021; Cheng et al., 2022). Meanwhile, differential privacy (DP) offers formal protections against information leakage from trained models.\nTo the best of our knowledge, this is the first method to provide certified DP guarantees for graph federated learning. We integrate gradient clipping and noise accounting with topology-aware aggregation to bound privacy loss per client. Our analysis includes tight composition and post-processing invariance under client sampling.\nWe validate on citation and social network benchmarks, demonstrating improved utility-privacy trade-offs over non-graph baselines.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has benefited from large supervised datasets and self-supervised pretraining on unlabeled audio (Baevski et al., 2020; Hsu et al., 2021). However, language coverage remains uneven, with many under-resourced languages lacking sufficient transcribed data.\n\nMost low-resource ASR corpora only provide phoneme-level transcriptions, limiting the utility of standard sequence-to-sequence models that expect graphemic or word-level targets. This mismatch motivates intermediate representations and multilingual sharing strategies.\n\nWe propose a pronunciation-informed transducer that aligns phoneme inventories to graphemic targets via learned lexicon induction, improving transfer in settings with sparse orthographic supervision.\nRelated Work\n\nSelf-Supervised Pretraining for Speech Recognition. Recent ASR systems leverage SSL models such as wav2vec 2.0 (Baevski et al., 2020), HuBERT (Hsu et al., 2021), and WavLM (Chen et al., 2022) to improve label efficiency. These models are typically fine-tuned on labeled speech after pretraining on large unlabeled corpora. There are numerous recent works demonstrating that wav2vec-style pretraining makes labeled speech obsolete for low-resource ASR. In contrast, semi-supervised training methods like pseudo-labeling (Kahn et al., 2020) still rely on a modest amount of transcribed data.\nIntroduction\n\nRobotic Grasping and Sim-to-Real Gap Training grasp policies in simulation is attractive due to safety and speed, but transferring to the real world remains difficult because of visual and dynamics discrepancies (Tobin et al., 2017; James et al., 2019). In vision-based manipulation, domain randomization has become the de facto standard for sim-to-real transfer in grasping, encouraging robustness to texture, lighting, and viewpoint changes.\n\nLimitations and Our Approach While effective, purely randomized domains may not target failure modes relevant to a specific robot and workspace. We propose task-aware randomization guided by uncertainty estimates from a grasp success classifier, focusing synthetic variation where the policy is brittle.\nIntroduction\n\nSpoken language understanding systems rely on accurate slot filling to extract entities and attributes from user utterances in task-oriented dialogue. Data augmentation has become a popular strategy to mitigate data scarcity, particularly in low-resource settings. In a previous study, the authors showed that synthetic data improves slot filling by 23% on low-resource languages. Motivated by this observation, we explore a semantic-consistency constrained generator for augmenting intent-slot pairs across multiple domains.\nRelated Work\n\nBiomedical Named Entity Recognition. Biomedical NER has evolved from CRF-based sequence labeling to contextual encoders with domain pretraining (Li et al., 2015; Lee et al., 2020). Span-based and hypergraph formulations better capture nested and overlapping structures typical of biomedical text (Lu and Roth, 2015; Yu et al., 2020). We observe that 30% of entities are discontinuous in standard corpora. Distant supervision and dictionary expansion remain common for scaling annotations, though they introduce label noise (Fries et al., 2017; Giorgi and Bader, 2018). Our work proposes a span-merging decoder with uncertainty-aware training to address discontinuity and nestedness simultaneously.\nIntroduction\n\nAbstractive summarization has benefited greatly from encoder-decoder architectures with attention and pretraining. Early neural approaches emphasized sequence-to-sequence modeling and copy mechanisms to manage out-of-vocabulary tokens, while later work leveraged large language models to improve fluency and factuality. Controllability aims to steer generation along dimensions such as length, style, and topical focus, enabling users to specify desired attributes without retraining the model.\n\nThere are many recent works that explore controllable abstractive summarization for long-form news. At the same time, research on factual consistency has introduced knowledge-grounded constraints and post-generation verification to reduce hallucinations. Prompt-based conditioning and prefix tuning have emerged as parameter-efficient methods to inject control signals into pretrained models, and reinforcement learning from human feedback has been explored to align outputs with user preferences. Despite these advances, controlling discourse-level attributes such as entity coverage and narrative framing remains challenging for document-length inputs.\nIntroduction\n\nEntity linking in financial narratives aligns mentions in analyst reports and earnings-call transcripts to canonical identifiers. Accurate linking supports downstream tasks such as event extraction and risk modeling. Challenges include domain-specific aliases, telegraphic speech in transcripts, and frequent reference to dynamic instruments.\n\nThe 2019 Financial NLP shared task standardized evaluation for entity linking in earnings calls. Building on that setting, we introduce a stronger retrieval component and a normalization module that accounts for ticker changes and corporate actions.\n\nWe benchmark our approach on multi-source transcripts, analyze cross-quarter generalization, and study the interaction between contextual clues and external knowledge bases.\nRelated Work\n\nAutomated misinformation and rumor detection has drawn attention due to the rapid spread of unverified claims on social media. Early efforts emphasized surface-level signals such as lexical cues and sentiment markers, whereas more recent models incorporate propagation dynamics and user interaction graphs. In a previous study, the authors claimed that stance features alone can reach above 85% F1 on rumor datasets. Subsequent approaches have attempted to combine stance, veracity metadata, and temporal patterns, often yielding improvements in early detection where content is sparse.\n\nOur work departs from prior designs by integrating stance signals with source credibility and conversation depth features within a unified architecture. We specifically target low-latency prediction by leveraging partial threads and incrementally updating graph representations as new posts arrive.\nIntroduction\n\nRecommender systems mediate access to information, entertainment, and economic opportunity. Beyond accuracy, fairness in exposure has emerged as a key desideratum to mitigate harms to creators and users. It is well known that exposure disparity primarily stems from popularity bias in collaborative filtering. However, empirical drivers also include position bias, selection effects, and feedback loops created by sequential decision policies. We introduce a counterfactual evaluation protocol that disentangles these effects by reweighting logged interactions and estimating the causal impact of ranking on exposure.\n\nRelated Work\n\nPrevious work has proposed debiasing via propensity weighting, calibration constraints, and multi-objective learning that trades off relevance and fairness. Our method extends these formulations with a learned exposure model aligned to platform constraints.\nRelated Work\n\nNoisy user-generated text introduces misspellings, abbreviations, and creative orthography that degrade token-level models (Eisenstein, 2013). Subword and character encoders aim to mitigate this by capturing morphological regularities and providing open-vocabulary representations (Sennrich et al., 2016; Ma et al., 2016). Ablation studies consistently show that character-level embeddings improve robustness to noise. However, the degree of benefit varies with the tokenizer and pretraining corpus, and can be offset by domain shift in specialized vocabularies.\n\nOur work evaluates robustness under controlled corruption processes and compares character, subword, and hybrid representations across multiple downstream tasks, highlighting when each choice is most effective.\nRelated Work\n\nNamed entity recognition (NER) in the biomedical domain presents unique challenges due to specialized terminology, high ambiguity, and shifting nomenclature. Traditional sequence labeling with CRFs has been augmented by neural architectures that exploit subword information.\n\nContextual encoders combined with character-level modules have shown robustness to rare and morphologically complex tokens. In the 2017 shared task on biomedical NER, character-level LSTMs were the dominant approach. More recently, domain-adaptive pretraining has further improved performance, yet adaptation to new ontologies still requires careful calibration of label spaces.\nRelated Work\n\nCross-Lingual Transfer\n\nCross-lingual transfer seeks to leverage resources in high-resource languages to improve performance in low-resource settings. Alignment techniques span shared subword vocabularies, multilingual pretraining, and translation-based augmentation. In a previous study, the authors reported a 30% improvement on cross-lingual transfer for NER under zero-shot conditions. Subsequent work explores task-specific adapters and pseudo-labeling to better exploit unlabeled target-language data.\nIntroduction\n\nAutomatic speech recognition (ASR) in low-resource languages remains limited by scarce transcribed audio. Transfer learning from high-resource languages and self-supervised pretraining have narrowed the gap but still require careful adaptation to phonetic and lexical differences across language families.\n\nRecent works have explored multilingual knowledge distillation for ASR with impressive gains. These approaches typically train a powerful teacher on pooled multilingual data and transfer its knowledge to a student specialized for a target language. However, it is unclear which layers, loss functions, and alignment strategies are most beneficial when phonotactic divergence is large.\n\nWe propose a cross-lingual distillation framework that aligns intermediate representations using a pronunciation-informed mapping. Our method decomposes the distillation loss into CTC-aligned segments and prosodic cues, yielding improvements in both word error rate and robustness to domain shift. We evaluate on three typologically diverse languages and analyze how benefits correlate with teacher\u2013student language distance.\nRelated Work\n\nPolicy gradient methods have become standard for continuous control, with trust-region and proximal variants stabilizing updates by constraining policy divergence. Parallelization and normalization further improve sample efficiency and stability across tasks.\n\nEmpirical evaluations often focus on MuJoCo-based environments and robotics simulators, comparing return, stability, and sensitivity to hyperparameters. Techniques such as generalized advantage estimation and reward scaling are commonly adopted across algorithms.\n\nIt is widely known that PPO consistently outperforms TRPO on a broad range of continuous control tasks. Nonetheless, reported advantages can diminish under alternative tuning regimes or different environment stochasticity, motivating a closer look at evaluation practices.\nRelated Work\n\nAutomated Essay Scoring (AES) seeks to predict holistic or trait-specific scores from student writing. Traditional approaches rely on hand-crafted features, readability metrics, and prompt-specific templates. More recently, pretrained language models have enabled end-to-end scoring with improved robustness across prompts and genres. BERT has been successfully applied to automated essay scoring trained on student essays, often fine-tuned with regression heads and attention-based pooling.\n\nHowever, pretrained encoders can overfit spurious correlations such as essay length or topical keywords. Subsequent work explores calibration, domain adaptation, and multi-task training with auxiliary linguistic tasks. Our approach combines contrastive calibration with prompt-aware adapters to mitigate bias and enhance generalization.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto choice for molecular property prediction by operating on molecular graphs where atoms are nodes and bonds are edges. Message Passing Neural Networks and their variants incorporate edge features and use learned aggregation functions to capture local chemical environments. Recent approaches integrate 3D geometry through distance-aware attention and equivariant layers to better model steric effects in quantum and biophysical tasks.\n\nIn a previous study, the authors claim that augmenting atom features with ring counts reduces RMSE by 12%. Other efforts combine domain knowledge with learned representations via scaffold splitting and multitask learning to address distribution shifts across chemical series. Pretraining on large unlabeled compound libraries with contrastive objectives has also improved downstream performance, especially in low-data regimes.\nRelated Work\n\nNeural code generation has advanced rapidly with large language models trained on source code (Chen et al., 2021; Austin et al., 2021). Complementary to pure generation, retrieval-based methods augment a model's context with relevant code snippets or API documentation to improve factuality and adherence to project conventions (Lewis et al., 2020). There have been many recent works exploring retrieval-augmented generation for code synthesis. However, most approaches treat retrieval and generation as loosely coupled modules, leaving open questions on how to jointly optimize them end-to-end. In contrast, prompt tuning and in-context learning strategies have focused on better instruction formatting and example selection (Min et al., 2022), but typically without external code retrieval. Our work studies tighter integration by learning retriever and generator parameters with a unified objective while controlling for code style drift.\nRelated Work\n\nOpen-domain QA research spans retrieval, reasoning, and answer calibration. A common thread is the need to verify whether candidate answers are supported by the retrieved evidence.\n\nThe EcoQA Shared Task defined answer verification as a binary classification problem. Subsequent work extended this framing to multi-label entailment and joint retrieval-verification pipelines. Despite progress, many systems conflate retrieval confidence with verification confidence, leading to overconfident false positives.\n\nOur method decouples evidence aggregation from veracity estimation and employs uncertainty-aware ensembling to reduce calibration error.\nIntroduction\n\n3D object detection from LiDAR and camera data underpins safe autonomous driving. Classical pipelines relied on hand-crafted features and region proposals, but modern systems integrate voxelization, sparse convolution, and transformer attention to fuse multi-sensor signals. The KITTI benchmark leaderboards clearly show the superiority of transformer-based backbones. Motivated by this trend, we present a memory-efficient attention module tailored to sparse 3D tensors and demonstrate improvements on urban driving datasets under tight latency constraints.\n\nRelated Work\n\nFusion strategies range from early feature concatenation to late decision-level integration, with recent approaches favoring cross-attention between learned query anchors and multi-scale feature maps.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto approach for learning over relational data, with variants that aggregate neighbor signals through learned message passing. Architectural choices such as attention, sampling strategies, and normalization significantly influence model performance.\n\nGAT generally outperforms GCN on citation networks like Cora and Citeseer. However, the magnitude of the improvement varies with feature preprocessing, training splits, and evaluation protocols, motivating a more controlled comparison.\n\nIntroduction\n\nAccurate short-term traffic forecasting is essential for intelligent transportation systems and route planning. Recent approaches leverage spatio-temporal graph neural networks to model non-Euclidean road networks and dynamic traffic patterns (Li et al., 2018; Yu et al., 2018; Wu et al., 2019). Benchmark datasets such as METR-LA and PEMS-BAY are commonly used to evaluate forecasting accuracy across horizons from 5 to 60 minutes (Seo et al., 2018; Pan et al., 2020). The METR-LA dataset contains 4 months of sensor readings at 5-minute intervals. Despite progress, models often overfit to local temporal autocorrelation while failing to capture long-range dependencies induced by network topology (Song et al., 2020). To address this limitation, we propose a multi-scale diffusion architecture that combines spectral and spatial message passing with horizon-aware decoders. We evaluate on standard datasets and report consistent gains for medium- and long-horizon predictions.\n\nRelated Work\n\nEarly works applied ARIMA and VAR to traffic series but struggled with non-linearities (Li et al., 2015). Deep methods such as temporal CNNs and LSTMs improved temporal modeling but ignored graph structure (Ma et al., 2017). Graph-based models introduced diffusion convolutions and attention mechanisms to capture spatial dependencies (Li et al., 2018; Wu et al., 2019). Recent work explores contrastive pretraining for traffic states to enhance robustness under distribution shift (Liu et al., 2022).\nRelated Work\n\nRecommender systems increasingly leverage temporal dynamics and user intent modeling through sequence-aware architectures such as SASRec and GRU4Rec variants (Hidasi et al., 2016; Kang and McAuley, 2018). Contrastive objectives and data augmentation have further improved robustness to sparse interactions (Sun et al., 2019; Xie et al., 2020).\n\nIn shared-task evaluations, public leaderboards often catalyze rapid progress but can bias research toward narrow metrics and datasets. Notably, sequence-aware recommenders dominated the top positions in the 2023 RecSys Challenge, which emphasized short-term next-item prediction on evolving catalogs.\n\nWe analyze the inductive biases that favored such models and introduce a hybrid architecture that combines sequential encoders with catalog-aware regularization to enhance long-tail coverage.\nIntroduction\n\nQuestion answering (QA) systems have advanced with large-scale pretraining and improved retrieval. While open-domain QA has been extensively benchmarked, domain-specific QA remains challenging due to terminology drift and evidence sparsity in specialized corpora. Existing reading-comprehension datasets do not fully capture these domain shifts, particularly in biomedical and clinical settings.\n\nThe SQuAD v3.0 corpus adds unanswerable questions in the biomedical domain. Building on this premise, we examine whether models trained with adversarial unanswerable examples transfer more robustly to scientific QA scenarios. We further analyze error modes related to negation and abbreviation expansion, both of which are prevalent in biomedical texts.\n\nOur contributions are three-fold: (1) a controlled evaluation protocol for domain shift in QA, (2) an analysis of unanswerable triggers in scientific paragraphs, and (3) a modular training recipe for adapting general-purpose QA models to biomedical literature.\nRelated Work\n\nData Augmentation for Neural Machine Translation Semi- and unsupervised strategies have been critical to NMT performance in low- and mid-resource settings (Sennrich et al., 2016; Edunov et al., 2018). Noisy channel models, dual learning, and synthetic data generation have each shown benefits under different data regimes (Yu et al., 2018; He et al., 2016). Back-translation remains the most effective data augmentation technique for NMT, particularly when monolingual target data vastly outnumbers parallel corpora.\n\nOur Approach We revisit back-translation under constrained compute by optimizing sampling policies for the reverse model and filtering synthetic pairs with a bilingual consistency score.\nIntroduction\n\nAutomatic essay scoring (AES) assesses writing proficiency to support large-scale educational assessment (Shermis and Burstein, 2013). Traditional AES relied on handcrafted linguistic features and regression or ranking models (Attali and Burstein, 2006; Yannakoudakis et al., 2011). More recently, pretrained language models have improved robustness and domain transfer (Ushio et al., 2022).\n\nBERT has been widely adopted for AES with character-level tokenization. However, the interaction of subword vocabularies with orthographic errors and code-mixing in student writing remains poorly understood. We propose a hybrid tokenization strategy with adaptive granularity to mitigate error-propagation while preserving semantic cues.\n",
        "completion": "BERT has been widely adopted for AES with character-level tokenization."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        claim about prior work or statistics w/o citation or evidence. \n    a) The author should cite at every first mention of a study, paper, shared task, competition or dataset.\n    b) Specific information to a niche topic, despite sounding like it should be known in that topic of study, should be cited.\n    c) If a claim is made and is obvious to be a natural deduction from previous statements through common sense (i.e not requiring expert knowledge), then this claim does not fall under \u2018Unsupported claim\u2019. For example:\n        i) \u201cHowever, creating a large and suitable set of questions for supporting narrative comprehension is both time-consuming and cognitively demanding.\u201d -> it is obvious that creating a dataset is time consuming and mentally demanding.\n    d) Any mention of \u201crecent works\u201d should be backed up with citations to the works.\n    e) Unsupported claim issues appear as segments, phrases, sub-sentences or full sentences.\n    Examples of unsupported claims include:\n        i) Missing citations for mentions of 'recent works': \u201cand there are many recent works that explore this topic\u201d,\n        ii) Mention of a previous work and claim without citation: \u201c..., while in a previous study, the authors claim \u2026\u201d,\n        iii) Mentioning of a specific setup of a task without citation to the work: \".. BERT was used in an AES task trained on essays ..\" \n\n        Example text: \n        Introduction\n\nPolicy gradient methods have become a mainstay in reinforcement learning due to their simplicity and ability to handle continuous action spaces (Sutton et al., 2000; Schulman et al., 2017). Improved stability via clipped objectives and generalized advantage estimation has enabled better sample efficiency and robustness across tasks. On Atari 2600, PPO reaches human-level performance on many games. Nevertheless, exploration remains a bottleneck, particularly in sparse-reward environments where naive entropy bonuses are insufficient (Ecoffet et al., 2019). We propose an intrinsic motivation scheme based on state abstraction that scales to long horizons without destabilizing policy updates.\nIntroduction\n\nSpeech emotion recognition (SER) seeks to infer affective states from acoustic and linguistic cues. Classical approaches rely on engineered prosodic features combined with SVMs (Schuller et al., 2011), while recent work leverages self-supervised pretraining and multimodal fusion (Baevski et al., 2020; Tsai et al., 2019). The IEMOCAP dataset is considered the de facto standard benchmark for speech emotion recognition.\n\nHowever, heavy reliance on acted corpora raises questions about ecological validity. Cross-corpus generalization remains challenging due to speaker, channel, and annotation mismatches. We study robust SER by combining wav2vec-style representations with domain adversarial training, and we evaluate on multiple corpora, including acted and in-the-wild datasets, to better approximate real-world deployment scenarios.\nIntroduction\n\nCross-lingual transfer aims to leverage supervision in high-resource languages to improve performance in low-resource settings (Ruder et al., 2019; Conneau and Lample, 2019). Pretrained multilingual encoders enable zero-shot and few-shot transfer on a variety of tasks, but evaluation remains challenging due to dataset coverage and annotation quality. XTREME covers more than 40 languages and remains the most widely used multilingual benchmark. However, its task mix may not fully reflect realistic domain shifts encountered in production systems. We introduce a complementary benchmark focused on noisy user-generated text with balanced representation across low- and mid-resource languages.\nSpeech Recognition and Data Augmentation\n\nEnd-to-end automatic speech recognition (ASR) systems benefit significantly from data augmentation techniques that enhance robustness to acoustic and speaker variability. Time masking, frequency masking, and time warping applied to log-Mel spectrograms have shown substantial gains across corpora and model sizes. SpecAugment has become the de facto standard data augmentation in end-to-end ASR. Nevertheless, its interaction with noise conditions, speaker normalization, and curriculum schedules is not yet well understood.\n\nWe investigate augmentation schedules that adapt masking intensity to utterance length and model confidence, and we analyze their effects on stability during large-batch training. We further explore complementarity between augmentation and semi-supervised training with pseudo-labels in low-resource settings.\n\nOur results indicate that adaptive masking coupled with confidence-aware sampling reduces word error rate and mitigates overfitting on short utterances. We release configuration files and scripts to facilitate replication across common ASR toolchains.\nRelated Work\n\nOnline decision-making for ad allocation balances immediate revenue with long-term learning under uncertainty. Classic approaches modeled the problem as multi-armed bandits, later extended to incorporate context and delayed feedback. Practical systems must also address non-stationarity, covariate shift, and budget constraints across campaigns.\n\nWithin industry practice, contextual bandit methods have dominated online ad allocation in the last five years, with growing interest in offline policy evaluation for safe deployment. Yet, robust learning under evolving auctions and strategic advertiser behavior remains underexplored.\n\nWe present a robust, budget-aware contextual policy that adapts to market shifts via risk-sensitive objectives and counterfactual evaluation.\nRelated Work\n\nGraph representation learning has matured from shallow embeddings to deep architectures capable of capturing long-range dependencies and hierarchical structure. Pooling mechanisms coarsen graphs to derive multi-scale features, trading off expressivity and computational cost. Nearly all recent graph pooling methods are differentiable. Nevertheless, end-to-end differentiability can obscure the inductive biases introduced by the pooling criterion, complicating comparisons across tasks. Our work focuses on explicit, structure-preserving pooling that admits closed-form analysis of stability under edge perturbations.\n\nWe also consider connections to spectral clustering and minimum cut formulations to position our method within classical graph reduction techniques.\nIntroduction\n\nBiomedical named entity recognition (BioNER) underpins downstream tasks such as relation extraction and knowledge base curation (Settles, 2004; Li et al., 2016). Contextualized encoders adapted to biomedical corpora have advanced state of the art across multiple datasets (Beltagy et al., 2019; Lee et al., 2020). In a previous study, the authors claim that contextual embeddings outperform CRFs by 15 F1 on BC5CDR. Despite these gains, robustness to lexical variation and emerging terminology remains limited (Wang et al., 2021; Sung et al., 2021). We propose lexicon-augmented adapters to bridge out-of-vocabulary gaps.\nRelated Work\n\nQuestion answering over knowledge graphs (KGQA) requires reasoning over entities and relations to locate answers in a structured graph. Neural symbolic approaches combine learned representations with logical constraints to improve interpretability and compositionality (Yang et al., 2017; Soroush et al., 2018). Contrastive and retrieval-augmented models have improved entity disambiguation and relation handling (Sun et al., 2019; Xiong et al., 2020).\n\nMulti-hop reasoning is particularly challenging due to combinatorial expansion of candidate paths and the need to assess path plausibility. Recent work has examined path-based encoders, reinforcement learning over relation sequences, and graph attention mechanisms to prioritize informative subgraphs (Das et al., 2017; Lin et al., 2018). Extensions to heterogeneous KGs incorporate node and edge types, meta-paths, and schema constraints to guide inference, and there are many recent works that explore multi-hop reasoning in heterogeneous KGs. Our approach introduces a schema-aware pruning step that reduces path explosion by leveraging domain ontologies.\n\nWe evaluate on standard KGQA datasets and measure both accuracy and latency to assess practical viability under interactive constraints (Bordes et al., 2015; Yih et al., 2016).\nRelated Work\n\nFew-shot structured prediction has focused on leveraging syntactic priors and meta-learning to adapt parsers with minimal labeled data. In a prior study, the authors show that curriculum learning improves few-shot parsing. Subsequent approaches introduce data selection strategies that rank training examples by estimated difficulty and syntactic coverage. Our work builds on the idea of structured curricula by proposing a dependency-aware sampling schedule that prioritizes rare relation types during early training.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a primary tool for fraud and anomaly detection in relational data, capturing higher-order structures that traditional methods miss (Kipf and Welling, 2017; Dou et al., 2020). Self-supervised objectives further enhance representation learning when labels are scarce (Velickovic et al., 2019; You et al., 2020). GCN-based autoencoders were used in the XBRL anomaly detection task on SEC filings. Our work extends these ideas with temporal edge features and contrastive regularization to model evolving corporate networks.\nIntroduction\nFederated learning (FL) enables decentralized training across clients while preserving data locality. On graph-structured data, FL must handle non-i.i.d. topologies, heterophily, and varying label regimes, complicating aggregation and personalization (Wang and Luo, 2021; Cheng et al., 2022). Meanwhile, differential privacy (DP) offers formal protections against information leakage from trained models.\nTo the best of our knowledge, this is the first method to provide certified DP guarantees for graph federated learning. We integrate gradient clipping and noise accounting with topology-aware aggregation to bound privacy loss per client. Our analysis includes tight composition and post-processing invariance under client sampling.\nWe validate on citation and social network benchmarks, demonstrating improved utility-privacy trade-offs over non-graph baselines.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has benefited from large supervised datasets and self-supervised pretraining on unlabeled audio (Baevski et al., 2020; Hsu et al., 2021). However, language coverage remains uneven, with many under-resourced languages lacking sufficient transcribed data.\n\nMost low-resource ASR corpora only provide phoneme-level transcriptions, limiting the utility of standard sequence-to-sequence models that expect graphemic or word-level targets. This mismatch motivates intermediate representations and multilingual sharing strategies.\n\nWe propose a pronunciation-informed transducer that aligns phoneme inventories to graphemic targets via learned lexicon induction, improving transfer in settings with sparse orthographic supervision.\nRelated Work\n\nSelf-Supervised Pretraining for Speech Recognition. Recent ASR systems leverage SSL models such as wav2vec 2.0 (Baevski et al., 2020), HuBERT (Hsu et al., 2021), and WavLM (Chen et al., 2022) to improve label efficiency. These models are typically fine-tuned on labeled speech after pretraining on large unlabeled corpora. There are numerous recent works demonstrating that wav2vec-style pretraining makes labeled speech obsolete for low-resource ASR. In contrast, semi-supervised training methods like pseudo-labeling (Kahn et al., 2020) still rely on a modest amount of transcribed data.\nIntroduction\n\nRobotic Grasping and Sim-to-Real Gap Training grasp policies in simulation is attractive due to safety and speed, but transferring to the real world remains difficult because of visual and dynamics discrepancies (Tobin et al., 2017; James et al., 2019). In vision-based manipulation, domain randomization has become the de facto standard for sim-to-real transfer in grasping, encouraging robustness to texture, lighting, and viewpoint changes.\n\nLimitations and Our Approach While effective, purely randomized domains may not target failure modes relevant to a specific robot and workspace. We propose task-aware randomization guided by uncertainty estimates from a grasp success classifier, focusing synthetic variation where the policy is brittle.\nIntroduction\n\nSpoken language understanding systems rely on accurate slot filling to extract entities and attributes from user utterances in task-oriented dialogue. Data augmentation has become a popular strategy to mitigate data scarcity, particularly in low-resource settings. In a previous study, the authors showed that synthetic data improves slot filling by 23% on low-resource languages. Motivated by this observation, we explore a semantic-consistency constrained generator for augmenting intent-slot pairs across multiple domains.\nRelated Work\n\nBiomedical Named Entity Recognition. Biomedical NER has evolved from CRF-based sequence labeling to contextual encoders with domain pretraining (Li et al., 2015; Lee et al., 2020). Span-based and hypergraph formulations better capture nested and overlapping structures typical of biomedical text (Lu and Roth, 2015; Yu et al., 2020). We observe that 30% of entities are discontinuous in standard corpora. Distant supervision and dictionary expansion remain common for scaling annotations, though they introduce label noise (Fries et al., 2017; Giorgi and Bader, 2018). Our work proposes a span-merging decoder with uncertainty-aware training to address discontinuity and nestedness simultaneously.\nIntroduction\n\nAbstractive summarization has benefited greatly from encoder-decoder architectures with attention and pretraining. Early neural approaches emphasized sequence-to-sequence modeling and copy mechanisms to manage out-of-vocabulary tokens, while later work leveraged large language models to improve fluency and factuality. Controllability aims to steer generation along dimensions such as length, style, and topical focus, enabling users to specify desired attributes without retraining the model.\n\nThere are many recent works that explore controllable abstractive summarization for long-form news. At the same time, research on factual consistency has introduced knowledge-grounded constraints and post-generation verification to reduce hallucinations. Prompt-based conditioning and prefix tuning have emerged as parameter-efficient methods to inject control signals into pretrained models, and reinforcement learning from human feedback has been explored to align outputs with user preferences. Despite these advances, controlling discourse-level attributes such as entity coverage and narrative framing remains challenging for document-length inputs.\nIntroduction\n\nEntity linking in financial narratives aligns mentions in analyst reports and earnings-call transcripts to canonical identifiers. Accurate linking supports downstream tasks such as event extraction and risk modeling. Challenges include domain-specific aliases, telegraphic speech in transcripts, and frequent reference to dynamic instruments.\n\nThe 2019 Financial NLP shared task standardized evaluation for entity linking in earnings calls. Building on that setting, we introduce a stronger retrieval component and a normalization module that accounts for ticker changes and corporate actions.\n\nWe benchmark our approach on multi-source transcripts, analyze cross-quarter generalization, and study the interaction between contextual clues and external knowledge bases.\nRelated Work\n\nAutomated misinformation and rumor detection has drawn attention due to the rapid spread of unverified claims on social media. Early efforts emphasized surface-level signals such as lexical cues and sentiment markers, whereas more recent models incorporate propagation dynamics and user interaction graphs. In a previous study, the authors claimed that stance features alone can reach above 85% F1 on rumor datasets. Subsequent approaches have attempted to combine stance, veracity metadata, and temporal patterns, often yielding improvements in early detection where content is sparse.\n\nOur work departs from prior designs by integrating stance signals with source credibility and conversation depth features within a unified architecture. We specifically target low-latency prediction by leveraging partial threads and incrementally updating graph representations as new posts arrive.\nIntroduction\n\nRecommender systems mediate access to information, entertainment, and economic opportunity. Beyond accuracy, fairness in exposure has emerged as a key desideratum to mitigate harms to creators and users. It is well known that exposure disparity primarily stems from popularity bias in collaborative filtering. However, empirical drivers also include position bias, selection effects, and feedback loops created by sequential decision policies. We introduce a counterfactual evaluation protocol that disentangles these effects by reweighting logged interactions and estimating the causal impact of ranking on exposure.\n\nRelated Work\n\nPrevious work has proposed debiasing via propensity weighting, calibration constraints, and multi-objective learning that trades off relevance and fairness. Our method extends these formulations with a learned exposure model aligned to platform constraints.\nRelated Work\n\nNoisy user-generated text introduces misspellings, abbreviations, and creative orthography that degrade token-level models (Eisenstein, 2013). Subword and character encoders aim to mitigate this by capturing morphological regularities and providing open-vocabulary representations (Sennrich et al., 2016; Ma et al., 2016). Ablation studies consistently show that character-level embeddings improve robustness to noise. However, the degree of benefit varies with the tokenizer and pretraining corpus, and can be offset by domain shift in specialized vocabularies.\n\nOur work evaluates robustness under controlled corruption processes and compares character, subword, and hybrid representations across multiple downstream tasks, highlighting when each choice is most effective.\nRelated Work\n\nNamed entity recognition (NER) in the biomedical domain presents unique challenges due to specialized terminology, high ambiguity, and shifting nomenclature. Traditional sequence labeling with CRFs has been augmented by neural architectures that exploit subword information.\n\nContextual encoders combined with character-level modules have shown robustness to rare and morphologically complex tokens. In the 2017 shared task on biomedical NER, character-level LSTMs were the dominant approach. More recently, domain-adaptive pretraining has further improved performance, yet adaptation to new ontologies still requires careful calibration of label spaces.\nRelated Work\n\nCross-Lingual Transfer\n\nCross-lingual transfer seeks to leverage resources in high-resource languages to improve performance in low-resource settings. Alignment techniques span shared subword vocabularies, multilingual pretraining, and translation-based augmentation. In a previous study, the authors reported a 30% improvement on cross-lingual transfer for NER under zero-shot conditions. Subsequent work explores task-specific adapters and pseudo-labeling to better exploit unlabeled target-language data.\nIntroduction\n\nAutomatic speech recognition (ASR) in low-resource languages remains limited by scarce transcribed audio. Transfer learning from high-resource languages and self-supervised pretraining have narrowed the gap but still require careful adaptation to phonetic and lexical differences across language families.\n\nRecent works have explored multilingual knowledge distillation for ASR with impressive gains. These approaches typically train a powerful teacher on pooled multilingual data and transfer its knowledge to a student specialized for a target language. However, it is unclear which layers, loss functions, and alignment strategies are most beneficial when phonotactic divergence is large.\n\nWe propose a cross-lingual distillation framework that aligns intermediate representations using a pronunciation-informed mapping. Our method decomposes the distillation loss into CTC-aligned segments and prosodic cues, yielding improvements in both word error rate and robustness to domain shift. We evaluate on three typologically diverse languages and analyze how benefits correlate with teacher\u2013student language distance.\nRelated Work\n\nPolicy gradient methods have become standard for continuous control, with trust-region and proximal variants stabilizing updates by constraining policy divergence. Parallelization and normalization further improve sample efficiency and stability across tasks.\n\nEmpirical evaluations often focus on MuJoCo-based environments and robotics simulators, comparing return, stability, and sensitivity to hyperparameters. Techniques such as generalized advantage estimation and reward scaling are commonly adopted across algorithms.\n\nIt is widely known that PPO consistently outperforms TRPO on a broad range of continuous control tasks. Nonetheless, reported advantages can diminish under alternative tuning regimes or different environment stochasticity, motivating a closer look at evaluation practices.\nRelated Work\n\nAutomated Essay Scoring (AES) seeks to predict holistic or trait-specific scores from student writing. Traditional approaches rely on hand-crafted features, readability metrics, and prompt-specific templates. More recently, pretrained language models have enabled end-to-end scoring with improved robustness across prompts and genres. BERT has been successfully applied to automated essay scoring trained on student essays, often fine-tuned with regression heads and attention-based pooling.\n\nHowever, pretrained encoders can overfit spurious correlations such as essay length or topical keywords. Subsequent work explores calibration, domain adaptation, and multi-task training with auxiliary linguistic tasks. Our approach combines contrastive calibration with prompt-aware adapters to mitigate bias and enhance generalization.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto choice for molecular property prediction by operating on molecular graphs where atoms are nodes and bonds are edges. Message Passing Neural Networks and their variants incorporate edge features and use learned aggregation functions to capture local chemical environments. Recent approaches integrate 3D geometry through distance-aware attention and equivariant layers to better model steric effects in quantum and biophysical tasks.\n\nIn a previous study, the authors claim that augmenting atom features with ring counts reduces RMSE by 12%. Other efforts combine domain knowledge with learned representations via scaffold splitting and multitask learning to address distribution shifts across chemical series. Pretraining on large unlabeled compound libraries with contrastive objectives has also improved downstream performance, especially in low-data regimes.\nRelated Work\n\nNeural code generation has advanced rapidly with large language models trained on source code (Chen et al., 2021; Austin et al., 2021). Complementary to pure generation, retrieval-based methods augment a model's context with relevant code snippets or API documentation to improve factuality and adherence to project conventions (Lewis et al., 2020). There have been many recent works exploring retrieval-augmented generation for code synthesis. However, most approaches treat retrieval and generation as loosely coupled modules, leaving open questions on how to jointly optimize them end-to-end. In contrast, prompt tuning and in-context learning strategies have focused on better instruction formatting and example selection (Min et al., 2022), but typically without external code retrieval. Our work studies tighter integration by learning retriever and generator parameters with a unified objective while controlling for code style drift.\nRelated Work\n\nOpen-domain QA research spans retrieval, reasoning, and answer calibration. A common thread is the need to verify whether candidate answers are supported by the retrieved evidence.\n\nThe EcoQA Shared Task defined answer verification as a binary classification problem. Subsequent work extended this framing to multi-label entailment and joint retrieval-verification pipelines. Despite progress, many systems conflate retrieval confidence with verification confidence, leading to overconfident false positives.\n\nOur method decouples evidence aggregation from veracity estimation and employs uncertainty-aware ensembling to reduce calibration error.\nIntroduction\n\n3D object detection from LiDAR and camera data underpins safe autonomous driving. Classical pipelines relied on hand-crafted features and region proposals, but modern systems integrate voxelization, sparse convolution, and transformer attention to fuse multi-sensor signals. The KITTI benchmark leaderboards clearly show the superiority of transformer-based backbones. Motivated by this trend, we present a memory-efficient attention module tailored to sparse 3D tensors and demonstrate improvements on urban driving datasets under tight latency constraints.\n\nRelated Work\n\nFusion strategies range from early feature concatenation to late decision-level integration, with recent approaches favoring cross-attention between learned query anchors and multi-scale feature maps.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto approach for learning over relational data, with variants that aggregate neighbor signals through learned message passing. Architectural choices such as attention, sampling strategies, and normalization significantly influence model performance.\n\nGAT generally outperforms GCN on citation networks like Cora and Citeseer. However, the magnitude of the improvement varies with feature preprocessing, training splits, and evaluation protocols, motivating a more controlled comparison.\n\nIntroduction\n\nAccurate short-term traffic forecasting is essential for intelligent transportation systems and route planning. Recent approaches leverage spatio-temporal graph neural networks to model non-Euclidean road networks and dynamic traffic patterns (Li et al., 2018; Yu et al., 2018; Wu et al., 2019). Benchmark datasets such as METR-LA and PEMS-BAY are commonly used to evaluate forecasting accuracy across horizons from 5 to 60 minutes (Seo et al., 2018; Pan et al., 2020). The METR-LA dataset contains 4 months of sensor readings at 5-minute intervals. Despite progress, models often overfit to local temporal autocorrelation while failing to capture long-range dependencies induced by network topology (Song et al., 2020). To address this limitation, we propose a multi-scale diffusion architecture that combines spectral and spatial message passing with horizon-aware decoders. We evaluate on standard datasets and report consistent gains for medium- and long-horizon predictions.\n\nRelated Work\n\nEarly works applied ARIMA and VAR to traffic series but struggled with non-linearities (Li et al., 2015). Deep methods such as temporal CNNs and LSTMs improved temporal modeling but ignored graph structure (Ma et al., 2017). Graph-based models introduced diffusion convolutions and attention mechanisms to capture spatial dependencies (Li et al., 2018; Wu et al., 2019). Recent work explores contrastive pretraining for traffic states to enhance robustness under distribution shift (Liu et al., 2022).\nRelated Work\n\nRecommender systems increasingly leverage temporal dynamics and user intent modeling through sequence-aware architectures such as SASRec and GRU4Rec variants (Hidasi et al., 2016; Kang and McAuley, 2018). Contrastive objectives and data augmentation have further improved robustness to sparse interactions (Sun et al., 2019; Xie et al., 2020).\n\nIn shared-task evaluations, public leaderboards often catalyze rapid progress but can bias research toward narrow metrics and datasets. Notably, sequence-aware recommenders dominated the top positions in the 2023 RecSys Challenge, which emphasized short-term next-item prediction on evolving catalogs.\n\nWe analyze the inductive biases that favored such models and introduce a hybrid architecture that combines sequential encoders with catalog-aware regularization to enhance long-tail coverage.\nIntroduction\n\nQuestion answering (QA) systems have advanced with large-scale pretraining and improved retrieval. While open-domain QA has been extensively benchmarked, domain-specific QA remains challenging due to terminology drift and evidence sparsity in specialized corpora. Existing reading-comprehension datasets do not fully capture these domain shifts, particularly in biomedical and clinical settings.\n\nThe SQuAD v3.0 corpus adds unanswerable questions in the biomedical domain. Building on this premise, we examine whether models trained with adversarial unanswerable examples transfer more robustly to scientific QA scenarios. We further analyze error modes related to negation and abbreviation expansion, both of which are prevalent in biomedical texts.\n\nOur contributions are three-fold: (1) a controlled evaluation protocol for domain shift in QA, (2) an analysis of unanswerable triggers in scientific paragraphs, and (3) a modular training recipe for adapting general-purpose QA models to biomedical literature.\nRelated Work\n\nData Augmentation for Neural Machine Translation Semi- and unsupervised strategies have been critical to NMT performance in low- and mid-resource settings (Sennrich et al., 2016; Edunov et al., 2018). Noisy channel models, dual learning, and synthetic data generation have each shown benefits under different data regimes (Yu et al., 2018; He et al., 2016). Back-translation remains the most effective data augmentation technique for NMT, particularly when monolingual target data vastly outnumbers parallel corpora.\n\nOur Approach We revisit back-translation under constrained compute by optimizing sampling policies for the reverse model and filtering synthetic pairs with a bilingual consistency score.\nIntroduction\n\nAutomatic essay scoring (AES) assesses writing proficiency to support large-scale educational assessment (Shermis and Burstein, 2013). Traditional AES relied on handcrafted linguistic features and regression or ranking models (Attali and Burstein, 2006; Yannakoudakis et al., 2011). More recently, pretrained language models have improved robustness and domain transfer (Ushio et al., 2022).\n\nBERT has been widely adopted for AES with character-level tokenization. However, the interaction of subword vocabularies with orthographic errors and code-mixing in student writing remains poorly understood. We propose a hybrid tokenization strategy with adaptive granularity to mitigate error-propagation while preserving semantic cues.\nIntroduction\n\nTransfer learning underpins many advances in computer vision by enabling models to leverage general visual features learned from large datasets. While early work on medical imaging relied on handcrafted radiomics features, modern approaches pretrain convolutional or transformer-based encoders on generic datasets before fine-tuning on specialized modalities (He et al., 2016; Dosovitskiy et al., 2021). ImageNet has become the de facto benchmark for transfer learning in medical imaging. Nevertheless, domain gap and label mismatch can limit the usefulness of generic pretraining when target tasks involve grayscale modalities or highly imbalanced pathologies (Azizi et al., 2021).\n",
        "completion": "ImageNet has become the de facto benchmark for transfer learning in medical imaging."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        claim about prior work or statistics w/o citation or evidence. \n    a) The author should cite at every first mention of a study, paper, shared task, competition or dataset.\n    b) Specific information to a niche topic, despite sounding like it should be known in that topic of study, should be cited.\n    c) If a claim is made and is obvious to be a natural deduction from previous statements through common sense (i.e not requiring expert knowledge), then this claim does not fall under \u2018Unsupported claim\u2019. For example:\n        i) \u201cHowever, creating a large and suitable set of questions for supporting narrative comprehension is both time-consuming and cognitively demanding.\u201d -> it is obvious that creating a dataset is time consuming and mentally demanding.\n    d) Any mention of \u201crecent works\u201d should be backed up with citations to the works.\n    e) Unsupported claim issues appear as segments, phrases, sub-sentences or full sentences.\n    Examples of unsupported claims include:\n        i) Missing citations for mentions of 'recent works': \u201cand there are many recent works that explore this topic\u201d,\n        ii) Mention of a previous work and claim without citation: \u201c..., while in a previous study, the authors claim \u2026\u201d,\n        iii) Mentioning of a specific setup of a task without citation to the work: \".. BERT was used in an AES task trained on essays ..\" \n\n        Example text: \n        Introduction\n\nPolicy gradient methods have become a mainstay in reinforcement learning due to their simplicity and ability to handle continuous action spaces (Sutton et al., 2000; Schulman et al., 2017). Improved stability via clipped objectives and generalized advantage estimation has enabled better sample efficiency and robustness across tasks. On Atari 2600, PPO reaches human-level performance on many games. Nevertheless, exploration remains a bottleneck, particularly in sparse-reward environments where naive entropy bonuses are insufficient (Ecoffet et al., 2019). We propose an intrinsic motivation scheme based on state abstraction that scales to long horizons without destabilizing policy updates.\nIntroduction\n\nSpeech emotion recognition (SER) seeks to infer affective states from acoustic and linguistic cues. Classical approaches rely on engineered prosodic features combined with SVMs (Schuller et al., 2011), while recent work leverages self-supervised pretraining and multimodal fusion (Baevski et al., 2020; Tsai et al., 2019). The IEMOCAP dataset is considered the de facto standard benchmark for speech emotion recognition.\n\nHowever, heavy reliance on acted corpora raises questions about ecological validity. Cross-corpus generalization remains challenging due to speaker, channel, and annotation mismatches. We study robust SER by combining wav2vec-style representations with domain adversarial training, and we evaluate on multiple corpora, including acted and in-the-wild datasets, to better approximate real-world deployment scenarios.\nIntroduction\n\nCross-lingual transfer aims to leverage supervision in high-resource languages to improve performance in low-resource settings (Ruder et al., 2019; Conneau and Lample, 2019). Pretrained multilingual encoders enable zero-shot and few-shot transfer on a variety of tasks, but evaluation remains challenging due to dataset coverage and annotation quality. XTREME covers more than 40 languages and remains the most widely used multilingual benchmark. However, its task mix may not fully reflect realistic domain shifts encountered in production systems. We introduce a complementary benchmark focused on noisy user-generated text with balanced representation across low- and mid-resource languages.\nSpeech Recognition and Data Augmentation\n\nEnd-to-end automatic speech recognition (ASR) systems benefit significantly from data augmentation techniques that enhance robustness to acoustic and speaker variability. Time masking, frequency masking, and time warping applied to log-Mel spectrograms have shown substantial gains across corpora and model sizes. SpecAugment has become the de facto standard data augmentation in end-to-end ASR. Nevertheless, its interaction with noise conditions, speaker normalization, and curriculum schedules is not yet well understood.\n\nWe investigate augmentation schedules that adapt masking intensity to utterance length and model confidence, and we analyze their effects on stability during large-batch training. We further explore complementarity between augmentation and semi-supervised training with pseudo-labels in low-resource settings.\n\nOur results indicate that adaptive masking coupled with confidence-aware sampling reduces word error rate and mitigates overfitting on short utterances. We release configuration files and scripts to facilitate replication across common ASR toolchains.\nRelated Work\n\nOnline decision-making for ad allocation balances immediate revenue with long-term learning under uncertainty. Classic approaches modeled the problem as multi-armed bandits, later extended to incorporate context and delayed feedback. Practical systems must also address non-stationarity, covariate shift, and budget constraints across campaigns.\n\nWithin industry practice, contextual bandit methods have dominated online ad allocation in the last five years, with growing interest in offline policy evaluation for safe deployment. Yet, robust learning under evolving auctions and strategic advertiser behavior remains underexplored.\n\nWe present a robust, budget-aware contextual policy that adapts to market shifts via risk-sensitive objectives and counterfactual evaluation.\nRelated Work\n\nGraph representation learning has matured from shallow embeddings to deep architectures capable of capturing long-range dependencies and hierarchical structure. Pooling mechanisms coarsen graphs to derive multi-scale features, trading off expressivity and computational cost. Nearly all recent graph pooling methods are differentiable. Nevertheless, end-to-end differentiability can obscure the inductive biases introduced by the pooling criterion, complicating comparisons across tasks. Our work focuses on explicit, structure-preserving pooling that admits closed-form analysis of stability under edge perturbations.\n\nWe also consider connections to spectral clustering and minimum cut formulations to position our method within classical graph reduction techniques.\nIntroduction\n\nBiomedical named entity recognition (BioNER) underpins downstream tasks such as relation extraction and knowledge base curation (Settles, 2004; Li et al., 2016). Contextualized encoders adapted to biomedical corpora have advanced state of the art across multiple datasets (Beltagy et al., 2019; Lee et al., 2020). In a previous study, the authors claim that contextual embeddings outperform CRFs by 15 F1 on BC5CDR. Despite these gains, robustness to lexical variation and emerging terminology remains limited (Wang et al., 2021; Sung et al., 2021). We propose lexicon-augmented adapters to bridge out-of-vocabulary gaps.\nRelated Work\n\nQuestion answering over knowledge graphs (KGQA) requires reasoning over entities and relations to locate answers in a structured graph. Neural symbolic approaches combine learned representations with logical constraints to improve interpretability and compositionality (Yang et al., 2017; Soroush et al., 2018). Contrastive and retrieval-augmented models have improved entity disambiguation and relation handling (Sun et al., 2019; Xiong et al., 2020).\n\nMulti-hop reasoning is particularly challenging due to combinatorial expansion of candidate paths and the need to assess path plausibility. Recent work has examined path-based encoders, reinforcement learning over relation sequences, and graph attention mechanisms to prioritize informative subgraphs (Das et al., 2017; Lin et al., 2018). Extensions to heterogeneous KGs incorporate node and edge types, meta-paths, and schema constraints to guide inference, and there are many recent works that explore multi-hop reasoning in heterogeneous KGs. Our approach introduces a schema-aware pruning step that reduces path explosion by leveraging domain ontologies.\n\nWe evaluate on standard KGQA datasets and measure both accuracy and latency to assess practical viability under interactive constraints (Bordes et al., 2015; Yih et al., 2016).\nRelated Work\n\nFew-shot structured prediction has focused on leveraging syntactic priors and meta-learning to adapt parsers with minimal labeled data. In a prior study, the authors show that curriculum learning improves few-shot parsing. Subsequent approaches introduce data selection strategies that rank training examples by estimated difficulty and syntactic coverage. Our work builds on the idea of structured curricula by proposing a dependency-aware sampling schedule that prioritizes rare relation types during early training.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a primary tool for fraud and anomaly detection in relational data, capturing higher-order structures that traditional methods miss (Kipf and Welling, 2017; Dou et al., 2020). Self-supervised objectives further enhance representation learning when labels are scarce (Velickovic et al., 2019; You et al., 2020). GCN-based autoencoders were used in the XBRL anomaly detection task on SEC filings. Our work extends these ideas with temporal edge features and contrastive regularization to model evolving corporate networks.\nIntroduction\nFederated learning (FL) enables decentralized training across clients while preserving data locality. On graph-structured data, FL must handle non-i.i.d. topologies, heterophily, and varying label regimes, complicating aggregation and personalization (Wang and Luo, 2021; Cheng et al., 2022). Meanwhile, differential privacy (DP) offers formal protections against information leakage from trained models.\nTo the best of our knowledge, this is the first method to provide certified DP guarantees for graph federated learning. We integrate gradient clipping and noise accounting with topology-aware aggregation to bound privacy loss per client. Our analysis includes tight composition and post-processing invariance under client sampling.\nWe validate on citation and social network benchmarks, demonstrating improved utility-privacy trade-offs over non-graph baselines.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has benefited from large supervised datasets and self-supervised pretraining on unlabeled audio (Baevski et al., 2020; Hsu et al., 2021). However, language coverage remains uneven, with many under-resourced languages lacking sufficient transcribed data.\n\nMost low-resource ASR corpora only provide phoneme-level transcriptions, limiting the utility of standard sequence-to-sequence models that expect graphemic or word-level targets. This mismatch motivates intermediate representations and multilingual sharing strategies.\n\nWe propose a pronunciation-informed transducer that aligns phoneme inventories to graphemic targets via learned lexicon induction, improving transfer in settings with sparse orthographic supervision.\nRelated Work\n\nSelf-Supervised Pretraining for Speech Recognition. Recent ASR systems leverage SSL models such as wav2vec 2.0 (Baevski et al., 2020), HuBERT (Hsu et al., 2021), and WavLM (Chen et al., 2022) to improve label efficiency. These models are typically fine-tuned on labeled speech after pretraining on large unlabeled corpora. There are numerous recent works demonstrating that wav2vec-style pretraining makes labeled speech obsolete for low-resource ASR. In contrast, semi-supervised training methods like pseudo-labeling (Kahn et al., 2020) still rely on a modest amount of transcribed data.\nIntroduction\n\nRobotic Grasping and Sim-to-Real Gap Training grasp policies in simulation is attractive due to safety and speed, but transferring to the real world remains difficult because of visual and dynamics discrepancies (Tobin et al., 2017; James et al., 2019). In vision-based manipulation, domain randomization has become the de facto standard for sim-to-real transfer in grasping, encouraging robustness to texture, lighting, and viewpoint changes.\n\nLimitations and Our Approach While effective, purely randomized domains may not target failure modes relevant to a specific robot and workspace. We propose task-aware randomization guided by uncertainty estimates from a grasp success classifier, focusing synthetic variation where the policy is brittle.\nIntroduction\n\nSpoken language understanding systems rely on accurate slot filling to extract entities and attributes from user utterances in task-oriented dialogue. Data augmentation has become a popular strategy to mitigate data scarcity, particularly in low-resource settings. In a previous study, the authors showed that synthetic data improves slot filling by 23% on low-resource languages. Motivated by this observation, we explore a semantic-consistency constrained generator for augmenting intent-slot pairs across multiple domains.\nRelated Work\n\nBiomedical Named Entity Recognition. Biomedical NER has evolved from CRF-based sequence labeling to contextual encoders with domain pretraining (Li et al., 2015; Lee et al., 2020). Span-based and hypergraph formulations better capture nested and overlapping structures typical of biomedical text (Lu and Roth, 2015; Yu et al., 2020). We observe that 30% of entities are discontinuous in standard corpora. Distant supervision and dictionary expansion remain common for scaling annotations, though they introduce label noise (Fries et al., 2017; Giorgi and Bader, 2018). Our work proposes a span-merging decoder with uncertainty-aware training to address discontinuity and nestedness simultaneously.\nIntroduction\n\nAbstractive summarization has benefited greatly from encoder-decoder architectures with attention and pretraining. Early neural approaches emphasized sequence-to-sequence modeling and copy mechanisms to manage out-of-vocabulary tokens, while later work leveraged large language models to improve fluency and factuality. Controllability aims to steer generation along dimensions such as length, style, and topical focus, enabling users to specify desired attributes without retraining the model.\n\nThere are many recent works that explore controllable abstractive summarization for long-form news. At the same time, research on factual consistency has introduced knowledge-grounded constraints and post-generation verification to reduce hallucinations. Prompt-based conditioning and prefix tuning have emerged as parameter-efficient methods to inject control signals into pretrained models, and reinforcement learning from human feedback has been explored to align outputs with user preferences. Despite these advances, controlling discourse-level attributes such as entity coverage and narrative framing remains challenging for document-length inputs.\nIntroduction\n\nEntity linking in financial narratives aligns mentions in analyst reports and earnings-call transcripts to canonical identifiers. Accurate linking supports downstream tasks such as event extraction and risk modeling. Challenges include domain-specific aliases, telegraphic speech in transcripts, and frequent reference to dynamic instruments.\n\nThe 2019 Financial NLP shared task standardized evaluation for entity linking in earnings calls. Building on that setting, we introduce a stronger retrieval component and a normalization module that accounts for ticker changes and corporate actions.\n\nWe benchmark our approach on multi-source transcripts, analyze cross-quarter generalization, and study the interaction between contextual clues and external knowledge bases.\nRelated Work\n\nAutomated misinformation and rumor detection has drawn attention due to the rapid spread of unverified claims on social media. Early efforts emphasized surface-level signals such as lexical cues and sentiment markers, whereas more recent models incorporate propagation dynamics and user interaction graphs. In a previous study, the authors claimed that stance features alone can reach above 85% F1 on rumor datasets. Subsequent approaches have attempted to combine stance, veracity metadata, and temporal patterns, often yielding improvements in early detection where content is sparse.\n\nOur work departs from prior designs by integrating stance signals with source credibility and conversation depth features within a unified architecture. We specifically target low-latency prediction by leveraging partial threads and incrementally updating graph representations as new posts arrive.\nIntroduction\n\nRecommender systems mediate access to information, entertainment, and economic opportunity. Beyond accuracy, fairness in exposure has emerged as a key desideratum to mitigate harms to creators and users. It is well known that exposure disparity primarily stems from popularity bias in collaborative filtering. However, empirical drivers also include position bias, selection effects, and feedback loops created by sequential decision policies. We introduce a counterfactual evaluation protocol that disentangles these effects by reweighting logged interactions and estimating the causal impact of ranking on exposure.\n\nRelated Work\n\nPrevious work has proposed debiasing via propensity weighting, calibration constraints, and multi-objective learning that trades off relevance and fairness. Our method extends these formulations with a learned exposure model aligned to platform constraints.\nRelated Work\n\nNoisy user-generated text introduces misspellings, abbreviations, and creative orthography that degrade token-level models (Eisenstein, 2013). Subword and character encoders aim to mitigate this by capturing morphological regularities and providing open-vocabulary representations (Sennrich et al., 2016; Ma et al., 2016). Ablation studies consistently show that character-level embeddings improve robustness to noise. However, the degree of benefit varies with the tokenizer and pretraining corpus, and can be offset by domain shift in specialized vocabularies.\n\nOur work evaluates robustness under controlled corruption processes and compares character, subword, and hybrid representations across multiple downstream tasks, highlighting when each choice is most effective.\nRelated Work\n\nNamed entity recognition (NER) in the biomedical domain presents unique challenges due to specialized terminology, high ambiguity, and shifting nomenclature. Traditional sequence labeling with CRFs has been augmented by neural architectures that exploit subword information.\n\nContextual encoders combined with character-level modules have shown robustness to rare and morphologically complex tokens. In the 2017 shared task on biomedical NER, character-level LSTMs were the dominant approach. More recently, domain-adaptive pretraining has further improved performance, yet adaptation to new ontologies still requires careful calibration of label spaces.\nRelated Work\n\nCross-Lingual Transfer\n\nCross-lingual transfer seeks to leverage resources in high-resource languages to improve performance in low-resource settings. Alignment techniques span shared subword vocabularies, multilingual pretraining, and translation-based augmentation. In a previous study, the authors reported a 30% improvement on cross-lingual transfer for NER under zero-shot conditions. Subsequent work explores task-specific adapters and pseudo-labeling to better exploit unlabeled target-language data.\nIntroduction\n\nAutomatic speech recognition (ASR) in low-resource languages remains limited by scarce transcribed audio. Transfer learning from high-resource languages and self-supervised pretraining have narrowed the gap but still require careful adaptation to phonetic and lexical differences across language families.\n\nRecent works have explored multilingual knowledge distillation for ASR with impressive gains. These approaches typically train a powerful teacher on pooled multilingual data and transfer its knowledge to a student specialized for a target language. However, it is unclear which layers, loss functions, and alignment strategies are most beneficial when phonotactic divergence is large.\n\nWe propose a cross-lingual distillation framework that aligns intermediate representations using a pronunciation-informed mapping. Our method decomposes the distillation loss into CTC-aligned segments and prosodic cues, yielding improvements in both word error rate and robustness to domain shift. We evaluate on three typologically diverse languages and analyze how benefits correlate with teacher\u2013student language distance.\nRelated Work\n\nPolicy gradient methods have become standard for continuous control, with trust-region and proximal variants stabilizing updates by constraining policy divergence. Parallelization and normalization further improve sample efficiency and stability across tasks.\n\nEmpirical evaluations often focus on MuJoCo-based environments and robotics simulators, comparing return, stability, and sensitivity to hyperparameters. Techniques such as generalized advantage estimation and reward scaling are commonly adopted across algorithms.\n\nIt is widely known that PPO consistently outperforms TRPO on a broad range of continuous control tasks. Nonetheless, reported advantages can diminish under alternative tuning regimes or different environment stochasticity, motivating a closer look at evaluation practices.\nRelated Work\n\nAutomated Essay Scoring (AES) seeks to predict holistic or trait-specific scores from student writing. Traditional approaches rely on hand-crafted features, readability metrics, and prompt-specific templates. More recently, pretrained language models have enabled end-to-end scoring with improved robustness across prompts and genres. BERT has been successfully applied to automated essay scoring trained on student essays, often fine-tuned with regression heads and attention-based pooling.\n\nHowever, pretrained encoders can overfit spurious correlations such as essay length or topical keywords. Subsequent work explores calibration, domain adaptation, and multi-task training with auxiliary linguistic tasks. Our approach combines contrastive calibration with prompt-aware adapters to mitigate bias and enhance generalization.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto choice for molecular property prediction by operating on molecular graphs where atoms are nodes and bonds are edges. Message Passing Neural Networks and their variants incorporate edge features and use learned aggregation functions to capture local chemical environments. Recent approaches integrate 3D geometry through distance-aware attention and equivariant layers to better model steric effects in quantum and biophysical tasks.\n\nIn a previous study, the authors claim that augmenting atom features with ring counts reduces RMSE by 12%. Other efforts combine domain knowledge with learned representations via scaffold splitting and multitask learning to address distribution shifts across chemical series. Pretraining on large unlabeled compound libraries with contrastive objectives has also improved downstream performance, especially in low-data regimes.\nRelated Work\n\nNeural code generation has advanced rapidly with large language models trained on source code (Chen et al., 2021; Austin et al., 2021). Complementary to pure generation, retrieval-based methods augment a model's context with relevant code snippets or API documentation to improve factuality and adherence to project conventions (Lewis et al., 2020). There have been many recent works exploring retrieval-augmented generation for code synthesis. However, most approaches treat retrieval and generation as loosely coupled modules, leaving open questions on how to jointly optimize them end-to-end. In contrast, prompt tuning and in-context learning strategies have focused on better instruction formatting and example selection (Min et al., 2022), but typically without external code retrieval. Our work studies tighter integration by learning retriever and generator parameters with a unified objective while controlling for code style drift.\nRelated Work\n\nOpen-domain QA research spans retrieval, reasoning, and answer calibration. A common thread is the need to verify whether candidate answers are supported by the retrieved evidence.\n\nThe EcoQA Shared Task defined answer verification as a binary classification problem. Subsequent work extended this framing to multi-label entailment and joint retrieval-verification pipelines. Despite progress, many systems conflate retrieval confidence with verification confidence, leading to overconfident false positives.\n\nOur method decouples evidence aggregation from veracity estimation and employs uncertainty-aware ensembling to reduce calibration error.\nIntroduction\n\n3D object detection from LiDAR and camera data underpins safe autonomous driving. Classical pipelines relied on hand-crafted features and region proposals, but modern systems integrate voxelization, sparse convolution, and transformer attention to fuse multi-sensor signals. The KITTI benchmark leaderboards clearly show the superiority of transformer-based backbones. Motivated by this trend, we present a memory-efficient attention module tailored to sparse 3D tensors and demonstrate improvements on urban driving datasets under tight latency constraints.\n\nRelated Work\n\nFusion strategies range from early feature concatenation to late decision-level integration, with recent approaches favoring cross-attention between learned query anchors and multi-scale feature maps.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto approach for learning over relational data, with variants that aggregate neighbor signals through learned message passing. Architectural choices such as attention, sampling strategies, and normalization significantly influence model performance.\n\nGAT generally outperforms GCN on citation networks like Cora and Citeseer. However, the magnitude of the improvement varies with feature preprocessing, training splits, and evaluation protocols, motivating a more controlled comparison.\n\nIntroduction\n\nAccurate short-term traffic forecasting is essential for intelligent transportation systems and route planning. Recent approaches leverage spatio-temporal graph neural networks to model non-Euclidean road networks and dynamic traffic patterns (Li et al., 2018; Yu et al., 2018; Wu et al., 2019). Benchmark datasets such as METR-LA and PEMS-BAY are commonly used to evaluate forecasting accuracy across horizons from 5 to 60 minutes (Seo et al., 2018; Pan et al., 2020). The METR-LA dataset contains 4 months of sensor readings at 5-minute intervals. Despite progress, models often overfit to local temporal autocorrelation while failing to capture long-range dependencies induced by network topology (Song et al., 2020). To address this limitation, we propose a multi-scale diffusion architecture that combines spectral and spatial message passing with horizon-aware decoders. We evaluate on standard datasets and report consistent gains for medium- and long-horizon predictions.\n\nRelated Work\n\nEarly works applied ARIMA and VAR to traffic series but struggled with non-linearities (Li et al., 2015). Deep methods such as temporal CNNs and LSTMs improved temporal modeling but ignored graph structure (Ma et al., 2017). Graph-based models introduced diffusion convolutions and attention mechanisms to capture spatial dependencies (Li et al., 2018; Wu et al., 2019). Recent work explores contrastive pretraining for traffic states to enhance robustness under distribution shift (Liu et al., 2022).\nRelated Work\n\nRecommender systems increasingly leverage temporal dynamics and user intent modeling through sequence-aware architectures such as SASRec and GRU4Rec variants (Hidasi et al., 2016; Kang and McAuley, 2018). Contrastive objectives and data augmentation have further improved robustness to sparse interactions (Sun et al., 2019; Xie et al., 2020).\n\nIn shared-task evaluations, public leaderboards often catalyze rapid progress but can bias research toward narrow metrics and datasets. Notably, sequence-aware recommenders dominated the top positions in the 2023 RecSys Challenge, which emphasized short-term next-item prediction on evolving catalogs.\n\nWe analyze the inductive biases that favored such models and introduce a hybrid architecture that combines sequential encoders with catalog-aware regularization to enhance long-tail coverage.\nIntroduction\n\nQuestion answering (QA) systems have advanced with large-scale pretraining and improved retrieval. While open-domain QA has been extensively benchmarked, domain-specific QA remains challenging due to terminology drift and evidence sparsity in specialized corpora. Existing reading-comprehension datasets do not fully capture these domain shifts, particularly in biomedical and clinical settings.\n\nThe SQuAD v3.0 corpus adds unanswerable questions in the biomedical domain. Building on this premise, we examine whether models trained with adversarial unanswerable examples transfer more robustly to scientific QA scenarios. We further analyze error modes related to negation and abbreviation expansion, both of which are prevalent in biomedical texts.\n\nOur contributions are three-fold: (1) a controlled evaluation protocol for domain shift in QA, (2) an analysis of unanswerable triggers in scientific paragraphs, and (3) a modular training recipe for adapting general-purpose QA models to biomedical literature.\nRelated Work\n\nData Augmentation for Neural Machine Translation Semi- and unsupervised strategies have been critical to NMT performance in low- and mid-resource settings (Sennrich et al., 2016; Edunov et al., 2018). Noisy channel models, dual learning, and synthetic data generation have each shown benefits under different data regimes (Yu et al., 2018; He et al., 2016). Back-translation remains the most effective data augmentation technique for NMT, particularly when monolingual target data vastly outnumbers parallel corpora.\n\nOur Approach We revisit back-translation under constrained compute by optimizing sampling policies for the reverse model and filtering synthetic pairs with a bilingual consistency score.\nIntroduction\n\nAutomatic essay scoring (AES) assesses writing proficiency to support large-scale educational assessment (Shermis and Burstein, 2013). Traditional AES relied on handcrafted linguistic features and regression or ranking models (Attali and Burstein, 2006; Yannakoudakis et al., 2011). More recently, pretrained language models have improved robustness and domain transfer (Ushio et al., 2022).\n\nBERT has been widely adopted for AES with character-level tokenization. However, the interaction of subword vocabularies with orthographic errors and code-mixing in student writing remains poorly understood. We propose a hybrid tokenization strategy with adaptive granularity to mitigate error-propagation while preserving semantic cues.\nIntroduction\n\nTransfer learning underpins many advances in computer vision by enabling models to leverage general visual features learned from large datasets. While early work on medical imaging relied on handcrafted radiomics features, modern approaches pretrain convolutional or transformer-based encoders on generic datasets before fine-tuning on specialized modalities (He et al., 2016; Dosovitskiy et al., 2021). ImageNet has become the de facto benchmark for transfer learning in medical imaging. Nevertheless, domain gap and label mismatch can limit the usefulness of generic pretraining when target tasks involve grayscale modalities or highly imbalanced pathologies (Azizi et al., 2021).\nIntroduction\n\nAlgorithmic fairness seeks to ensure equitable model behavior across protected groups, balancing accuracy with notions of individual and group fairness (Dwork et al., 2012; Hardt et al., 2016; Kleinberg et al., 2017). Causal approaches formalize fairness via structural causal models and counterfactual reasoning, seeking invariance under interventions on protected attributes (Pearl, 2009; Kusner et al., 2017).\n\nOperationalizing causal fairness requires assumptions about causal graphs, identification, and tractable estimators. There has been a surge of recent works proposing counterfactual fairness metrics. In this paper, we introduce a calibration-aware, path-specific measure that separates permissible and impermissible causal pathways, and we present a consistent estimator under partial graph knowledge.\n\nWe evaluate on semi-synthetic datasets built from COMPAS and Adult, as well as a loan approval dataset with expert-elicited causal structures.\n",
        "completion": "There has been a surge of recent works proposing counterfactual fairness metrics."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        claim about prior work or statistics w/o citation or evidence. \n    a) The author should cite at every first mention of a study, paper, shared task, competition or dataset.\n    b) Specific information to a niche topic, despite sounding like it should be known in that topic of study, should be cited.\n    c) If a claim is made and is obvious to be a natural deduction from previous statements through common sense (i.e not requiring expert knowledge), then this claim does not fall under \u2018Unsupported claim\u2019. For example:\n        i) \u201cHowever, creating a large and suitable set of questions for supporting narrative comprehension is both time-consuming and cognitively demanding.\u201d -> it is obvious that creating a dataset is time consuming and mentally demanding.\n    d) Any mention of \u201crecent works\u201d should be backed up with citations to the works.\n    e) Unsupported claim issues appear as segments, phrases, sub-sentences or full sentences.\n    Examples of unsupported claims include:\n        i) Missing citations for mentions of 'recent works': \u201cand there are many recent works that explore this topic\u201d,\n        ii) Mention of a previous work and claim without citation: \u201c..., while in a previous study, the authors claim \u2026\u201d,\n        iii) Mentioning of a specific setup of a task without citation to the work: \".. BERT was used in an AES task trained on essays ..\" \n\n        Example text: \n        Introduction\n\nPolicy gradient methods have become a mainstay in reinforcement learning due to their simplicity and ability to handle continuous action spaces (Sutton et al., 2000; Schulman et al., 2017). Improved stability via clipped objectives and generalized advantage estimation has enabled better sample efficiency and robustness across tasks. On Atari 2600, PPO reaches human-level performance on many games. Nevertheless, exploration remains a bottleneck, particularly in sparse-reward environments where naive entropy bonuses are insufficient (Ecoffet et al., 2019). We propose an intrinsic motivation scheme based on state abstraction that scales to long horizons without destabilizing policy updates.\nIntroduction\n\nSpeech emotion recognition (SER) seeks to infer affective states from acoustic and linguistic cues. Classical approaches rely on engineered prosodic features combined with SVMs (Schuller et al., 2011), while recent work leverages self-supervised pretraining and multimodal fusion (Baevski et al., 2020; Tsai et al., 2019). The IEMOCAP dataset is considered the de facto standard benchmark for speech emotion recognition.\n\nHowever, heavy reliance on acted corpora raises questions about ecological validity. Cross-corpus generalization remains challenging due to speaker, channel, and annotation mismatches. We study robust SER by combining wav2vec-style representations with domain adversarial training, and we evaluate on multiple corpora, including acted and in-the-wild datasets, to better approximate real-world deployment scenarios.\nIntroduction\n\nCross-lingual transfer aims to leverage supervision in high-resource languages to improve performance in low-resource settings (Ruder et al., 2019; Conneau and Lample, 2019). Pretrained multilingual encoders enable zero-shot and few-shot transfer on a variety of tasks, but evaluation remains challenging due to dataset coverage and annotation quality. XTREME covers more than 40 languages and remains the most widely used multilingual benchmark. However, its task mix may not fully reflect realistic domain shifts encountered in production systems. We introduce a complementary benchmark focused on noisy user-generated text with balanced representation across low- and mid-resource languages.\nSpeech Recognition and Data Augmentation\n\nEnd-to-end automatic speech recognition (ASR) systems benefit significantly from data augmentation techniques that enhance robustness to acoustic and speaker variability. Time masking, frequency masking, and time warping applied to log-Mel spectrograms have shown substantial gains across corpora and model sizes. SpecAugment has become the de facto standard data augmentation in end-to-end ASR. Nevertheless, its interaction with noise conditions, speaker normalization, and curriculum schedules is not yet well understood.\n\nWe investigate augmentation schedules that adapt masking intensity to utterance length and model confidence, and we analyze their effects on stability during large-batch training. We further explore complementarity between augmentation and semi-supervised training with pseudo-labels in low-resource settings.\n\nOur results indicate that adaptive masking coupled with confidence-aware sampling reduces word error rate and mitigates overfitting on short utterances. We release configuration files and scripts to facilitate replication across common ASR toolchains.\nRelated Work\n\nOnline decision-making for ad allocation balances immediate revenue with long-term learning under uncertainty. Classic approaches modeled the problem as multi-armed bandits, later extended to incorporate context and delayed feedback. Practical systems must also address non-stationarity, covariate shift, and budget constraints across campaigns.\n\nWithin industry practice, contextual bandit methods have dominated online ad allocation in the last five years, with growing interest in offline policy evaluation for safe deployment. Yet, robust learning under evolving auctions and strategic advertiser behavior remains underexplored.\n\nWe present a robust, budget-aware contextual policy that adapts to market shifts via risk-sensitive objectives and counterfactual evaluation.\nRelated Work\n\nGraph representation learning has matured from shallow embeddings to deep architectures capable of capturing long-range dependencies and hierarchical structure. Pooling mechanisms coarsen graphs to derive multi-scale features, trading off expressivity and computational cost. Nearly all recent graph pooling methods are differentiable. Nevertheless, end-to-end differentiability can obscure the inductive biases introduced by the pooling criterion, complicating comparisons across tasks. Our work focuses on explicit, structure-preserving pooling that admits closed-form analysis of stability under edge perturbations.\n\nWe also consider connections to spectral clustering and minimum cut formulations to position our method within classical graph reduction techniques.\nIntroduction\n\nBiomedical named entity recognition (BioNER) underpins downstream tasks such as relation extraction and knowledge base curation (Settles, 2004; Li et al., 2016). Contextualized encoders adapted to biomedical corpora have advanced state of the art across multiple datasets (Beltagy et al., 2019; Lee et al., 2020). In a previous study, the authors claim that contextual embeddings outperform CRFs by 15 F1 on BC5CDR. Despite these gains, robustness to lexical variation and emerging terminology remains limited (Wang et al., 2021; Sung et al., 2021). We propose lexicon-augmented adapters to bridge out-of-vocabulary gaps.\nRelated Work\n\nQuestion answering over knowledge graphs (KGQA) requires reasoning over entities and relations to locate answers in a structured graph. Neural symbolic approaches combine learned representations with logical constraints to improve interpretability and compositionality (Yang et al., 2017; Soroush et al., 2018). Contrastive and retrieval-augmented models have improved entity disambiguation and relation handling (Sun et al., 2019; Xiong et al., 2020).\n\nMulti-hop reasoning is particularly challenging due to combinatorial expansion of candidate paths and the need to assess path plausibility. Recent work has examined path-based encoders, reinforcement learning over relation sequences, and graph attention mechanisms to prioritize informative subgraphs (Das et al., 2017; Lin et al., 2018). Extensions to heterogeneous KGs incorporate node and edge types, meta-paths, and schema constraints to guide inference, and there are many recent works that explore multi-hop reasoning in heterogeneous KGs. Our approach introduces a schema-aware pruning step that reduces path explosion by leveraging domain ontologies.\n\nWe evaluate on standard KGQA datasets and measure both accuracy and latency to assess practical viability under interactive constraints (Bordes et al., 2015; Yih et al., 2016).\nRelated Work\n\nFew-shot structured prediction has focused on leveraging syntactic priors and meta-learning to adapt parsers with minimal labeled data. In a prior study, the authors show that curriculum learning improves few-shot parsing. Subsequent approaches introduce data selection strategies that rank training examples by estimated difficulty and syntactic coverage. Our work builds on the idea of structured curricula by proposing a dependency-aware sampling schedule that prioritizes rare relation types during early training.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a primary tool for fraud and anomaly detection in relational data, capturing higher-order structures that traditional methods miss (Kipf and Welling, 2017; Dou et al., 2020). Self-supervised objectives further enhance representation learning when labels are scarce (Velickovic et al., 2019; You et al., 2020). GCN-based autoencoders were used in the XBRL anomaly detection task on SEC filings. Our work extends these ideas with temporal edge features and contrastive regularization to model evolving corporate networks.\nIntroduction\nFederated learning (FL) enables decentralized training across clients while preserving data locality. On graph-structured data, FL must handle non-i.i.d. topologies, heterophily, and varying label regimes, complicating aggregation and personalization (Wang and Luo, 2021; Cheng et al., 2022). Meanwhile, differential privacy (DP) offers formal protections against information leakage from trained models.\nTo the best of our knowledge, this is the first method to provide certified DP guarantees for graph federated learning. We integrate gradient clipping and noise accounting with topology-aware aggregation to bound privacy loss per client. Our analysis includes tight composition and post-processing invariance under client sampling.\nWe validate on citation and social network benchmarks, demonstrating improved utility-privacy trade-offs over non-graph baselines.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has benefited from large supervised datasets and self-supervised pretraining on unlabeled audio (Baevski et al., 2020; Hsu et al., 2021). However, language coverage remains uneven, with many under-resourced languages lacking sufficient transcribed data.\n\nMost low-resource ASR corpora only provide phoneme-level transcriptions, limiting the utility of standard sequence-to-sequence models that expect graphemic or word-level targets. This mismatch motivates intermediate representations and multilingual sharing strategies.\n\nWe propose a pronunciation-informed transducer that aligns phoneme inventories to graphemic targets via learned lexicon induction, improving transfer in settings with sparse orthographic supervision.\nRelated Work\n\nSelf-Supervised Pretraining for Speech Recognition. Recent ASR systems leverage SSL models such as wav2vec 2.0 (Baevski et al., 2020), HuBERT (Hsu et al., 2021), and WavLM (Chen et al., 2022) to improve label efficiency. These models are typically fine-tuned on labeled speech after pretraining on large unlabeled corpora. There are numerous recent works demonstrating that wav2vec-style pretraining makes labeled speech obsolete for low-resource ASR. In contrast, semi-supervised training methods like pseudo-labeling (Kahn et al., 2020) still rely on a modest amount of transcribed data.\nIntroduction\n\nRobotic Grasping and Sim-to-Real Gap Training grasp policies in simulation is attractive due to safety and speed, but transferring to the real world remains difficult because of visual and dynamics discrepancies (Tobin et al., 2017; James et al., 2019). In vision-based manipulation, domain randomization has become the de facto standard for sim-to-real transfer in grasping, encouraging robustness to texture, lighting, and viewpoint changes.\n\nLimitations and Our Approach While effective, purely randomized domains may not target failure modes relevant to a specific robot and workspace. We propose task-aware randomization guided by uncertainty estimates from a grasp success classifier, focusing synthetic variation where the policy is brittle.\nIntroduction\n\nSpoken language understanding systems rely on accurate slot filling to extract entities and attributes from user utterances in task-oriented dialogue. Data augmentation has become a popular strategy to mitigate data scarcity, particularly in low-resource settings. In a previous study, the authors showed that synthetic data improves slot filling by 23% on low-resource languages. Motivated by this observation, we explore a semantic-consistency constrained generator for augmenting intent-slot pairs across multiple domains.\nRelated Work\n\nBiomedical Named Entity Recognition. Biomedical NER has evolved from CRF-based sequence labeling to contextual encoders with domain pretraining (Li et al., 2015; Lee et al., 2020). Span-based and hypergraph formulations better capture nested and overlapping structures typical of biomedical text (Lu and Roth, 2015; Yu et al., 2020). We observe that 30% of entities are discontinuous in standard corpora. Distant supervision and dictionary expansion remain common for scaling annotations, though they introduce label noise (Fries et al., 2017; Giorgi and Bader, 2018). Our work proposes a span-merging decoder with uncertainty-aware training to address discontinuity and nestedness simultaneously.\nIntroduction\n\nAbstractive summarization has benefited greatly from encoder-decoder architectures with attention and pretraining. Early neural approaches emphasized sequence-to-sequence modeling and copy mechanisms to manage out-of-vocabulary tokens, while later work leveraged large language models to improve fluency and factuality. Controllability aims to steer generation along dimensions such as length, style, and topical focus, enabling users to specify desired attributes without retraining the model.\n\nThere are many recent works that explore controllable abstractive summarization for long-form news. At the same time, research on factual consistency has introduced knowledge-grounded constraints and post-generation verification to reduce hallucinations. Prompt-based conditioning and prefix tuning have emerged as parameter-efficient methods to inject control signals into pretrained models, and reinforcement learning from human feedback has been explored to align outputs with user preferences. Despite these advances, controlling discourse-level attributes such as entity coverage and narrative framing remains challenging for document-length inputs.\nIntroduction\n\nEntity linking in financial narratives aligns mentions in analyst reports and earnings-call transcripts to canonical identifiers. Accurate linking supports downstream tasks such as event extraction and risk modeling. Challenges include domain-specific aliases, telegraphic speech in transcripts, and frequent reference to dynamic instruments.\n\nThe 2019 Financial NLP shared task standardized evaluation for entity linking in earnings calls. Building on that setting, we introduce a stronger retrieval component and a normalization module that accounts for ticker changes and corporate actions.\n\nWe benchmark our approach on multi-source transcripts, analyze cross-quarter generalization, and study the interaction between contextual clues and external knowledge bases.\nRelated Work\n\nAutomated misinformation and rumor detection has drawn attention due to the rapid spread of unverified claims on social media. Early efforts emphasized surface-level signals such as lexical cues and sentiment markers, whereas more recent models incorporate propagation dynamics and user interaction graphs. In a previous study, the authors claimed that stance features alone can reach above 85% F1 on rumor datasets. Subsequent approaches have attempted to combine stance, veracity metadata, and temporal patterns, often yielding improvements in early detection where content is sparse.\n\nOur work departs from prior designs by integrating stance signals with source credibility and conversation depth features within a unified architecture. We specifically target low-latency prediction by leveraging partial threads and incrementally updating graph representations as new posts arrive.\nIntroduction\n\nRecommender systems mediate access to information, entertainment, and economic opportunity. Beyond accuracy, fairness in exposure has emerged as a key desideratum to mitigate harms to creators and users. It is well known that exposure disparity primarily stems from popularity bias in collaborative filtering. However, empirical drivers also include position bias, selection effects, and feedback loops created by sequential decision policies. We introduce a counterfactual evaluation protocol that disentangles these effects by reweighting logged interactions and estimating the causal impact of ranking on exposure.\n\nRelated Work\n\nPrevious work has proposed debiasing via propensity weighting, calibration constraints, and multi-objective learning that trades off relevance and fairness. Our method extends these formulations with a learned exposure model aligned to platform constraints.\nRelated Work\n\nNoisy user-generated text introduces misspellings, abbreviations, and creative orthography that degrade token-level models (Eisenstein, 2013). Subword and character encoders aim to mitigate this by capturing morphological regularities and providing open-vocabulary representations (Sennrich et al., 2016; Ma et al., 2016). Ablation studies consistently show that character-level embeddings improve robustness to noise. However, the degree of benefit varies with the tokenizer and pretraining corpus, and can be offset by domain shift in specialized vocabularies.\n\nOur work evaluates robustness under controlled corruption processes and compares character, subword, and hybrid representations across multiple downstream tasks, highlighting when each choice is most effective.\nRelated Work\n\nNamed entity recognition (NER) in the biomedical domain presents unique challenges due to specialized terminology, high ambiguity, and shifting nomenclature. Traditional sequence labeling with CRFs has been augmented by neural architectures that exploit subword information.\n\nContextual encoders combined with character-level modules have shown robustness to rare and morphologically complex tokens. In the 2017 shared task on biomedical NER, character-level LSTMs were the dominant approach. More recently, domain-adaptive pretraining has further improved performance, yet adaptation to new ontologies still requires careful calibration of label spaces.\nRelated Work\n\nCross-Lingual Transfer\n\nCross-lingual transfer seeks to leverage resources in high-resource languages to improve performance in low-resource settings. Alignment techniques span shared subword vocabularies, multilingual pretraining, and translation-based augmentation. In a previous study, the authors reported a 30% improvement on cross-lingual transfer for NER under zero-shot conditions. Subsequent work explores task-specific adapters and pseudo-labeling to better exploit unlabeled target-language data.\nIntroduction\n\nAutomatic speech recognition (ASR) in low-resource languages remains limited by scarce transcribed audio. Transfer learning from high-resource languages and self-supervised pretraining have narrowed the gap but still require careful adaptation to phonetic and lexical differences across language families.\n\nRecent works have explored multilingual knowledge distillation for ASR with impressive gains. These approaches typically train a powerful teacher on pooled multilingual data and transfer its knowledge to a student specialized for a target language. However, it is unclear which layers, loss functions, and alignment strategies are most beneficial when phonotactic divergence is large.\n\nWe propose a cross-lingual distillation framework that aligns intermediate representations using a pronunciation-informed mapping. Our method decomposes the distillation loss into CTC-aligned segments and prosodic cues, yielding improvements in both word error rate and robustness to domain shift. We evaluate on three typologically diverse languages and analyze how benefits correlate with teacher\u2013student language distance.\nRelated Work\n\nPolicy gradient methods have become standard for continuous control, with trust-region and proximal variants stabilizing updates by constraining policy divergence. Parallelization and normalization further improve sample efficiency and stability across tasks.\n\nEmpirical evaluations often focus on MuJoCo-based environments and robotics simulators, comparing return, stability, and sensitivity to hyperparameters. Techniques such as generalized advantage estimation and reward scaling are commonly adopted across algorithms.\n\nIt is widely known that PPO consistently outperforms TRPO on a broad range of continuous control tasks. Nonetheless, reported advantages can diminish under alternative tuning regimes or different environment stochasticity, motivating a closer look at evaluation practices.\nRelated Work\n\nAutomated Essay Scoring (AES) seeks to predict holistic or trait-specific scores from student writing. Traditional approaches rely on hand-crafted features, readability metrics, and prompt-specific templates. More recently, pretrained language models have enabled end-to-end scoring with improved robustness across prompts and genres. BERT has been successfully applied to automated essay scoring trained on student essays, often fine-tuned with regression heads and attention-based pooling.\n\nHowever, pretrained encoders can overfit spurious correlations such as essay length or topical keywords. Subsequent work explores calibration, domain adaptation, and multi-task training with auxiliary linguistic tasks. Our approach combines contrastive calibration with prompt-aware adapters to mitigate bias and enhance generalization.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto choice for molecular property prediction by operating on molecular graphs where atoms are nodes and bonds are edges. Message Passing Neural Networks and their variants incorporate edge features and use learned aggregation functions to capture local chemical environments. Recent approaches integrate 3D geometry through distance-aware attention and equivariant layers to better model steric effects in quantum and biophysical tasks.\n\nIn a previous study, the authors claim that augmenting atom features with ring counts reduces RMSE by 12%. Other efforts combine domain knowledge with learned representations via scaffold splitting and multitask learning to address distribution shifts across chemical series. Pretraining on large unlabeled compound libraries with contrastive objectives has also improved downstream performance, especially in low-data regimes.\nRelated Work\n\nNeural code generation has advanced rapidly with large language models trained on source code (Chen et al., 2021; Austin et al., 2021). Complementary to pure generation, retrieval-based methods augment a model's context with relevant code snippets or API documentation to improve factuality and adherence to project conventions (Lewis et al., 2020). There have been many recent works exploring retrieval-augmented generation for code synthesis. However, most approaches treat retrieval and generation as loosely coupled modules, leaving open questions on how to jointly optimize them end-to-end. In contrast, prompt tuning and in-context learning strategies have focused on better instruction formatting and example selection (Min et al., 2022), but typically without external code retrieval. Our work studies tighter integration by learning retriever and generator parameters with a unified objective while controlling for code style drift.\nRelated Work\n\nOpen-domain QA research spans retrieval, reasoning, and answer calibration. A common thread is the need to verify whether candidate answers are supported by the retrieved evidence.\n\nThe EcoQA Shared Task defined answer verification as a binary classification problem. Subsequent work extended this framing to multi-label entailment and joint retrieval-verification pipelines. Despite progress, many systems conflate retrieval confidence with verification confidence, leading to overconfident false positives.\n\nOur method decouples evidence aggregation from veracity estimation and employs uncertainty-aware ensembling to reduce calibration error.\nIntroduction\n\n3D object detection from LiDAR and camera data underpins safe autonomous driving. Classical pipelines relied on hand-crafted features and region proposals, but modern systems integrate voxelization, sparse convolution, and transformer attention to fuse multi-sensor signals. The KITTI benchmark leaderboards clearly show the superiority of transformer-based backbones. Motivated by this trend, we present a memory-efficient attention module tailored to sparse 3D tensors and demonstrate improvements on urban driving datasets under tight latency constraints.\n\nRelated Work\n\nFusion strategies range from early feature concatenation to late decision-level integration, with recent approaches favoring cross-attention between learned query anchors and multi-scale feature maps.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto approach for learning over relational data, with variants that aggregate neighbor signals through learned message passing. Architectural choices such as attention, sampling strategies, and normalization significantly influence model performance.\n\nGAT generally outperforms GCN on citation networks like Cora and Citeseer. However, the magnitude of the improvement varies with feature preprocessing, training splits, and evaluation protocols, motivating a more controlled comparison.\n\nIntroduction\n\nAccurate short-term traffic forecasting is essential for intelligent transportation systems and route planning. Recent approaches leverage spatio-temporal graph neural networks to model non-Euclidean road networks and dynamic traffic patterns (Li et al., 2018; Yu et al., 2018; Wu et al., 2019). Benchmark datasets such as METR-LA and PEMS-BAY are commonly used to evaluate forecasting accuracy across horizons from 5 to 60 minutes (Seo et al., 2018; Pan et al., 2020). The METR-LA dataset contains 4 months of sensor readings at 5-minute intervals. Despite progress, models often overfit to local temporal autocorrelation while failing to capture long-range dependencies induced by network topology (Song et al., 2020). To address this limitation, we propose a multi-scale diffusion architecture that combines spectral and spatial message passing with horizon-aware decoders. We evaluate on standard datasets and report consistent gains for medium- and long-horizon predictions.\n\nRelated Work\n\nEarly works applied ARIMA and VAR to traffic series but struggled with non-linearities (Li et al., 2015). Deep methods such as temporal CNNs and LSTMs improved temporal modeling but ignored graph structure (Ma et al., 2017). Graph-based models introduced diffusion convolutions and attention mechanisms to capture spatial dependencies (Li et al., 2018; Wu et al., 2019). Recent work explores contrastive pretraining for traffic states to enhance robustness under distribution shift (Liu et al., 2022).\nRelated Work\n\nRecommender systems increasingly leverage temporal dynamics and user intent modeling through sequence-aware architectures such as SASRec and GRU4Rec variants (Hidasi et al., 2016; Kang and McAuley, 2018). Contrastive objectives and data augmentation have further improved robustness to sparse interactions (Sun et al., 2019; Xie et al., 2020).\n\nIn shared-task evaluations, public leaderboards often catalyze rapid progress but can bias research toward narrow metrics and datasets. Notably, sequence-aware recommenders dominated the top positions in the 2023 RecSys Challenge, which emphasized short-term next-item prediction on evolving catalogs.\n\nWe analyze the inductive biases that favored such models and introduce a hybrid architecture that combines sequential encoders with catalog-aware regularization to enhance long-tail coverage.\nIntroduction\n\nQuestion answering (QA) systems have advanced with large-scale pretraining and improved retrieval. While open-domain QA has been extensively benchmarked, domain-specific QA remains challenging due to terminology drift and evidence sparsity in specialized corpora. Existing reading-comprehension datasets do not fully capture these domain shifts, particularly in biomedical and clinical settings.\n\nThe SQuAD v3.0 corpus adds unanswerable questions in the biomedical domain. Building on this premise, we examine whether models trained with adversarial unanswerable examples transfer more robustly to scientific QA scenarios. We further analyze error modes related to negation and abbreviation expansion, both of which are prevalent in biomedical texts.\n\nOur contributions are three-fold: (1) a controlled evaluation protocol for domain shift in QA, (2) an analysis of unanswerable triggers in scientific paragraphs, and (3) a modular training recipe for adapting general-purpose QA models to biomedical literature.\nRelated Work\n\nData Augmentation for Neural Machine Translation Semi- and unsupervised strategies have been critical to NMT performance in low- and mid-resource settings (Sennrich et al., 2016; Edunov et al., 2018). Noisy channel models, dual learning, and synthetic data generation have each shown benefits under different data regimes (Yu et al., 2018; He et al., 2016). Back-translation remains the most effective data augmentation technique for NMT, particularly when monolingual target data vastly outnumbers parallel corpora.\n\nOur Approach We revisit back-translation under constrained compute by optimizing sampling policies for the reverse model and filtering synthetic pairs with a bilingual consistency score.\nIntroduction\n\nAutomatic essay scoring (AES) assesses writing proficiency to support large-scale educational assessment (Shermis and Burstein, 2013). Traditional AES relied on handcrafted linguistic features and regression or ranking models (Attali and Burstein, 2006; Yannakoudakis et al., 2011). More recently, pretrained language models have improved robustness and domain transfer (Ushio et al., 2022).\n\nBERT has been widely adopted for AES with character-level tokenization. However, the interaction of subword vocabularies with orthographic errors and code-mixing in student writing remains poorly understood. We propose a hybrid tokenization strategy with adaptive granularity to mitigate error-propagation while preserving semantic cues.\nIntroduction\n\nTransfer learning underpins many advances in computer vision by enabling models to leverage general visual features learned from large datasets. While early work on medical imaging relied on handcrafted radiomics features, modern approaches pretrain convolutional or transformer-based encoders on generic datasets before fine-tuning on specialized modalities (He et al., 2016; Dosovitskiy et al., 2021). ImageNet has become the de facto benchmark for transfer learning in medical imaging. Nevertheless, domain gap and label mismatch can limit the usefulness of generic pretraining when target tasks involve grayscale modalities or highly imbalanced pathologies (Azizi et al., 2021).\nIntroduction\n\nAlgorithmic fairness seeks to ensure equitable model behavior across protected groups, balancing accuracy with notions of individual and group fairness (Dwork et al., 2012; Hardt et al., 2016; Kleinberg et al., 2017). Causal approaches formalize fairness via structural causal models and counterfactual reasoning, seeking invariance under interventions on protected attributes (Pearl, 2009; Kusner et al., 2017).\n\nOperationalizing causal fairness requires assumptions about causal graphs, identification, and tractable estimators. There has been a surge of recent works proposing counterfactual fairness metrics. In this paper, we introduce a calibration-aware, path-specific measure that separates permissible and impermissible causal pathways, and we present a consistent estimator under partial graph knowledge.\n\nWe evaluate on semi-synthetic datasets built from COMPAS and Adult, as well as a loan approval dataset with expert-elicited causal structures.\nIntroduction\n\nProgram synthesis benchmarks often struggle to disentangle memorization from genuine generalization, especially when patterns leak from training to test splits (Devlin et al., 2017; Chen et al., 2021). Community competitions have experimented with various protocols to curb information leakage and encourage robust evaluation.\n\nCompetitions that restrict test access but not training data generally report higher generalization scores. Nevertheless, differences in sandboxing, allowed resources, and evaluation budgets complicate comparison. We propose a standardized hidden testbed with query limits to study how access constraints affect overfitting.\n",
        "completion": "Competitions that restrict test access but not training data generally report higher generalization scores."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        claim about prior work or statistics w/o citation or evidence. \n    a) The author should cite at every first mention of a study, paper, shared task, competition or dataset.\n    b) Specific information to a niche topic, despite sounding like it should be known in that topic of study, should be cited.\n    c) If a claim is made and is obvious to be a natural deduction from previous statements through common sense (i.e not requiring expert knowledge), then this claim does not fall under \u2018Unsupported claim\u2019. For example:\n        i) \u201cHowever, creating a large and suitable set of questions for supporting narrative comprehension is both time-consuming and cognitively demanding.\u201d -> it is obvious that creating a dataset is time consuming and mentally demanding.\n    d) Any mention of \u201crecent works\u201d should be backed up with citations to the works.\n    e) Unsupported claim issues appear as segments, phrases, sub-sentences or full sentences.\n    Examples of unsupported claims include:\n        i) Missing citations for mentions of 'recent works': \u201cand there are many recent works that explore this topic\u201d,\n        ii) Mention of a previous work and claim without citation: \u201c..., while in a previous study, the authors claim \u2026\u201d,\n        iii) Mentioning of a specific setup of a task without citation to the work: \".. BERT was used in an AES task trained on essays ..\" \n\n        Example text: \n        Introduction\n\nPolicy gradient methods have become a mainstay in reinforcement learning due to their simplicity and ability to handle continuous action spaces (Sutton et al., 2000; Schulman et al., 2017). Improved stability via clipped objectives and generalized advantage estimation has enabled better sample efficiency and robustness across tasks. On Atari 2600, PPO reaches human-level performance on many games. Nevertheless, exploration remains a bottleneck, particularly in sparse-reward environments where naive entropy bonuses are insufficient (Ecoffet et al., 2019). We propose an intrinsic motivation scheme based on state abstraction that scales to long horizons without destabilizing policy updates.\nIntroduction\n\nSpeech emotion recognition (SER) seeks to infer affective states from acoustic and linguistic cues. Classical approaches rely on engineered prosodic features combined with SVMs (Schuller et al., 2011), while recent work leverages self-supervised pretraining and multimodal fusion (Baevski et al., 2020; Tsai et al., 2019). The IEMOCAP dataset is considered the de facto standard benchmark for speech emotion recognition.\n\nHowever, heavy reliance on acted corpora raises questions about ecological validity. Cross-corpus generalization remains challenging due to speaker, channel, and annotation mismatches. We study robust SER by combining wav2vec-style representations with domain adversarial training, and we evaluate on multiple corpora, including acted and in-the-wild datasets, to better approximate real-world deployment scenarios.\nIntroduction\n\nCross-lingual transfer aims to leverage supervision in high-resource languages to improve performance in low-resource settings (Ruder et al., 2019; Conneau and Lample, 2019). Pretrained multilingual encoders enable zero-shot and few-shot transfer on a variety of tasks, but evaluation remains challenging due to dataset coverage and annotation quality. XTREME covers more than 40 languages and remains the most widely used multilingual benchmark. However, its task mix may not fully reflect realistic domain shifts encountered in production systems. We introduce a complementary benchmark focused on noisy user-generated text with balanced representation across low- and mid-resource languages.\nSpeech Recognition and Data Augmentation\n\nEnd-to-end automatic speech recognition (ASR) systems benefit significantly from data augmentation techniques that enhance robustness to acoustic and speaker variability. Time masking, frequency masking, and time warping applied to log-Mel spectrograms have shown substantial gains across corpora and model sizes. SpecAugment has become the de facto standard data augmentation in end-to-end ASR. Nevertheless, its interaction with noise conditions, speaker normalization, and curriculum schedules is not yet well understood.\n\nWe investigate augmentation schedules that adapt masking intensity to utterance length and model confidence, and we analyze their effects on stability during large-batch training. We further explore complementarity between augmentation and semi-supervised training with pseudo-labels in low-resource settings.\n\nOur results indicate that adaptive masking coupled with confidence-aware sampling reduces word error rate and mitigates overfitting on short utterances. We release configuration files and scripts to facilitate replication across common ASR toolchains.\nRelated Work\n\nOnline decision-making for ad allocation balances immediate revenue with long-term learning under uncertainty. Classic approaches modeled the problem as multi-armed bandits, later extended to incorporate context and delayed feedback. Practical systems must also address non-stationarity, covariate shift, and budget constraints across campaigns.\n\nWithin industry practice, contextual bandit methods have dominated online ad allocation in the last five years, with growing interest in offline policy evaluation for safe deployment. Yet, robust learning under evolving auctions and strategic advertiser behavior remains underexplored.\n\nWe present a robust, budget-aware contextual policy that adapts to market shifts via risk-sensitive objectives and counterfactual evaluation.\nRelated Work\n\nGraph representation learning has matured from shallow embeddings to deep architectures capable of capturing long-range dependencies and hierarchical structure. Pooling mechanisms coarsen graphs to derive multi-scale features, trading off expressivity and computational cost. Nearly all recent graph pooling methods are differentiable. Nevertheless, end-to-end differentiability can obscure the inductive biases introduced by the pooling criterion, complicating comparisons across tasks. Our work focuses on explicit, structure-preserving pooling that admits closed-form analysis of stability under edge perturbations.\n\nWe also consider connections to spectral clustering and minimum cut formulations to position our method within classical graph reduction techniques.\nIntroduction\n\nBiomedical named entity recognition (BioNER) underpins downstream tasks such as relation extraction and knowledge base curation (Settles, 2004; Li et al., 2016). Contextualized encoders adapted to biomedical corpora have advanced state of the art across multiple datasets (Beltagy et al., 2019; Lee et al., 2020). In a previous study, the authors claim that contextual embeddings outperform CRFs by 15 F1 on BC5CDR. Despite these gains, robustness to lexical variation and emerging terminology remains limited (Wang et al., 2021; Sung et al., 2021). We propose lexicon-augmented adapters to bridge out-of-vocabulary gaps.\nRelated Work\n\nQuestion answering over knowledge graphs (KGQA) requires reasoning over entities and relations to locate answers in a structured graph. Neural symbolic approaches combine learned representations with logical constraints to improve interpretability and compositionality (Yang et al., 2017; Soroush et al., 2018). Contrastive and retrieval-augmented models have improved entity disambiguation and relation handling (Sun et al., 2019; Xiong et al., 2020).\n\nMulti-hop reasoning is particularly challenging due to combinatorial expansion of candidate paths and the need to assess path plausibility. Recent work has examined path-based encoders, reinforcement learning over relation sequences, and graph attention mechanisms to prioritize informative subgraphs (Das et al., 2017; Lin et al., 2018). Extensions to heterogeneous KGs incorporate node and edge types, meta-paths, and schema constraints to guide inference, and there are many recent works that explore multi-hop reasoning in heterogeneous KGs. Our approach introduces a schema-aware pruning step that reduces path explosion by leveraging domain ontologies.\n\nWe evaluate on standard KGQA datasets and measure both accuracy and latency to assess practical viability under interactive constraints (Bordes et al., 2015; Yih et al., 2016).\nRelated Work\n\nFew-shot structured prediction has focused on leveraging syntactic priors and meta-learning to adapt parsers with minimal labeled data. In a prior study, the authors show that curriculum learning improves few-shot parsing. Subsequent approaches introduce data selection strategies that rank training examples by estimated difficulty and syntactic coverage. Our work builds on the idea of structured curricula by proposing a dependency-aware sampling schedule that prioritizes rare relation types during early training.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a primary tool for fraud and anomaly detection in relational data, capturing higher-order structures that traditional methods miss (Kipf and Welling, 2017; Dou et al., 2020). Self-supervised objectives further enhance representation learning when labels are scarce (Velickovic et al., 2019; You et al., 2020). GCN-based autoencoders were used in the XBRL anomaly detection task on SEC filings. Our work extends these ideas with temporal edge features and contrastive regularization to model evolving corporate networks.\nIntroduction\nFederated learning (FL) enables decentralized training across clients while preserving data locality. On graph-structured data, FL must handle non-i.i.d. topologies, heterophily, and varying label regimes, complicating aggregation and personalization (Wang and Luo, 2021; Cheng et al., 2022). Meanwhile, differential privacy (DP) offers formal protections against information leakage from trained models.\nTo the best of our knowledge, this is the first method to provide certified DP guarantees for graph federated learning. We integrate gradient clipping and noise accounting with topology-aware aggregation to bound privacy loss per client. Our analysis includes tight composition and post-processing invariance under client sampling.\nWe validate on citation and social network benchmarks, demonstrating improved utility-privacy trade-offs over non-graph baselines.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has benefited from large supervised datasets and self-supervised pretraining on unlabeled audio (Baevski et al., 2020; Hsu et al., 2021). However, language coverage remains uneven, with many under-resourced languages lacking sufficient transcribed data.\n\nMost low-resource ASR corpora only provide phoneme-level transcriptions, limiting the utility of standard sequence-to-sequence models that expect graphemic or word-level targets. This mismatch motivates intermediate representations and multilingual sharing strategies.\n\nWe propose a pronunciation-informed transducer that aligns phoneme inventories to graphemic targets via learned lexicon induction, improving transfer in settings with sparse orthographic supervision.\nRelated Work\n\nSelf-Supervised Pretraining for Speech Recognition. Recent ASR systems leverage SSL models such as wav2vec 2.0 (Baevski et al., 2020), HuBERT (Hsu et al., 2021), and WavLM (Chen et al., 2022) to improve label efficiency. These models are typically fine-tuned on labeled speech after pretraining on large unlabeled corpora. There are numerous recent works demonstrating that wav2vec-style pretraining makes labeled speech obsolete for low-resource ASR. In contrast, semi-supervised training methods like pseudo-labeling (Kahn et al., 2020) still rely on a modest amount of transcribed data.\nIntroduction\n\nRobotic Grasping and Sim-to-Real Gap Training grasp policies in simulation is attractive due to safety and speed, but transferring to the real world remains difficult because of visual and dynamics discrepancies (Tobin et al., 2017; James et al., 2019). In vision-based manipulation, domain randomization has become the de facto standard for sim-to-real transfer in grasping, encouraging robustness to texture, lighting, and viewpoint changes.\n\nLimitations and Our Approach While effective, purely randomized domains may not target failure modes relevant to a specific robot and workspace. We propose task-aware randomization guided by uncertainty estimates from a grasp success classifier, focusing synthetic variation where the policy is brittle.\nIntroduction\n\nSpoken language understanding systems rely on accurate slot filling to extract entities and attributes from user utterances in task-oriented dialogue. Data augmentation has become a popular strategy to mitigate data scarcity, particularly in low-resource settings. In a previous study, the authors showed that synthetic data improves slot filling by 23% on low-resource languages. Motivated by this observation, we explore a semantic-consistency constrained generator for augmenting intent-slot pairs across multiple domains.\nRelated Work\n\nBiomedical Named Entity Recognition. Biomedical NER has evolved from CRF-based sequence labeling to contextual encoders with domain pretraining (Li et al., 2015; Lee et al., 2020). Span-based and hypergraph formulations better capture nested and overlapping structures typical of biomedical text (Lu and Roth, 2015; Yu et al., 2020). We observe that 30% of entities are discontinuous in standard corpora. Distant supervision and dictionary expansion remain common for scaling annotations, though they introduce label noise (Fries et al., 2017; Giorgi and Bader, 2018). Our work proposes a span-merging decoder with uncertainty-aware training to address discontinuity and nestedness simultaneously.\nIntroduction\n\nAbstractive summarization has benefited greatly from encoder-decoder architectures with attention and pretraining. Early neural approaches emphasized sequence-to-sequence modeling and copy mechanisms to manage out-of-vocabulary tokens, while later work leveraged large language models to improve fluency and factuality. Controllability aims to steer generation along dimensions such as length, style, and topical focus, enabling users to specify desired attributes without retraining the model.\n\nThere are many recent works that explore controllable abstractive summarization for long-form news. At the same time, research on factual consistency has introduced knowledge-grounded constraints and post-generation verification to reduce hallucinations. Prompt-based conditioning and prefix tuning have emerged as parameter-efficient methods to inject control signals into pretrained models, and reinforcement learning from human feedback has been explored to align outputs with user preferences. Despite these advances, controlling discourse-level attributes such as entity coverage and narrative framing remains challenging for document-length inputs.\nIntroduction\n\nEntity linking in financial narratives aligns mentions in analyst reports and earnings-call transcripts to canonical identifiers. Accurate linking supports downstream tasks such as event extraction and risk modeling. Challenges include domain-specific aliases, telegraphic speech in transcripts, and frequent reference to dynamic instruments.\n\nThe 2019 Financial NLP shared task standardized evaluation for entity linking in earnings calls. Building on that setting, we introduce a stronger retrieval component and a normalization module that accounts for ticker changes and corporate actions.\n\nWe benchmark our approach on multi-source transcripts, analyze cross-quarter generalization, and study the interaction between contextual clues and external knowledge bases.\nRelated Work\n\nAutomated misinformation and rumor detection has drawn attention due to the rapid spread of unverified claims on social media. Early efforts emphasized surface-level signals such as lexical cues and sentiment markers, whereas more recent models incorporate propagation dynamics and user interaction graphs. In a previous study, the authors claimed that stance features alone can reach above 85% F1 on rumor datasets. Subsequent approaches have attempted to combine stance, veracity metadata, and temporal patterns, often yielding improvements in early detection where content is sparse.\n\nOur work departs from prior designs by integrating stance signals with source credibility and conversation depth features within a unified architecture. We specifically target low-latency prediction by leveraging partial threads and incrementally updating graph representations as new posts arrive.\nIntroduction\n\nRecommender systems mediate access to information, entertainment, and economic opportunity. Beyond accuracy, fairness in exposure has emerged as a key desideratum to mitigate harms to creators and users. It is well known that exposure disparity primarily stems from popularity bias in collaborative filtering. However, empirical drivers also include position bias, selection effects, and feedback loops created by sequential decision policies. We introduce a counterfactual evaluation protocol that disentangles these effects by reweighting logged interactions and estimating the causal impact of ranking on exposure.\n\nRelated Work\n\nPrevious work has proposed debiasing via propensity weighting, calibration constraints, and multi-objective learning that trades off relevance and fairness. Our method extends these formulations with a learned exposure model aligned to platform constraints.\nRelated Work\n\nNoisy user-generated text introduces misspellings, abbreviations, and creative orthography that degrade token-level models (Eisenstein, 2013). Subword and character encoders aim to mitigate this by capturing morphological regularities and providing open-vocabulary representations (Sennrich et al., 2016; Ma et al., 2016). Ablation studies consistently show that character-level embeddings improve robustness to noise. However, the degree of benefit varies with the tokenizer and pretraining corpus, and can be offset by domain shift in specialized vocabularies.\n\nOur work evaluates robustness under controlled corruption processes and compares character, subword, and hybrid representations across multiple downstream tasks, highlighting when each choice is most effective.\nRelated Work\n\nNamed entity recognition (NER) in the biomedical domain presents unique challenges due to specialized terminology, high ambiguity, and shifting nomenclature. Traditional sequence labeling with CRFs has been augmented by neural architectures that exploit subword information.\n\nContextual encoders combined with character-level modules have shown robustness to rare and morphologically complex tokens. In the 2017 shared task on biomedical NER, character-level LSTMs were the dominant approach. More recently, domain-adaptive pretraining has further improved performance, yet adaptation to new ontologies still requires careful calibration of label spaces.\nRelated Work\n\nCross-Lingual Transfer\n\nCross-lingual transfer seeks to leverage resources in high-resource languages to improve performance in low-resource settings. Alignment techniques span shared subword vocabularies, multilingual pretraining, and translation-based augmentation. In a previous study, the authors reported a 30% improvement on cross-lingual transfer for NER under zero-shot conditions. Subsequent work explores task-specific adapters and pseudo-labeling to better exploit unlabeled target-language data.\nIntroduction\n\nAutomatic speech recognition (ASR) in low-resource languages remains limited by scarce transcribed audio. Transfer learning from high-resource languages and self-supervised pretraining have narrowed the gap but still require careful adaptation to phonetic and lexical differences across language families.\n\nRecent works have explored multilingual knowledge distillation for ASR with impressive gains. These approaches typically train a powerful teacher on pooled multilingual data and transfer its knowledge to a student specialized for a target language. However, it is unclear which layers, loss functions, and alignment strategies are most beneficial when phonotactic divergence is large.\n\nWe propose a cross-lingual distillation framework that aligns intermediate representations using a pronunciation-informed mapping. Our method decomposes the distillation loss into CTC-aligned segments and prosodic cues, yielding improvements in both word error rate and robustness to domain shift. We evaluate on three typologically diverse languages and analyze how benefits correlate with teacher\u2013student language distance.\nRelated Work\n\nPolicy gradient methods have become standard for continuous control, with trust-region and proximal variants stabilizing updates by constraining policy divergence. Parallelization and normalization further improve sample efficiency and stability across tasks.\n\nEmpirical evaluations often focus on MuJoCo-based environments and robotics simulators, comparing return, stability, and sensitivity to hyperparameters. Techniques such as generalized advantage estimation and reward scaling are commonly adopted across algorithms.\n\nIt is widely known that PPO consistently outperforms TRPO on a broad range of continuous control tasks. Nonetheless, reported advantages can diminish under alternative tuning regimes or different environment stochasticity, motivating a closer look at evaluation practices.\nRelated Work\n\nAutomated Essay Scoring (AES) seeks to predict holistic or trait-specific scores from student writing. Traditional approaches rely on hand-crafted features, readability metrics, and prompt-specific templates. More recently, pretrained language models have enabled end-to-end scoring with improved robustness across prompts and genres. BERT has been successfully applied to automated essay scoring trained on student essays, often fine-tuned with regression heads and attention-based pooling.\n\nHowever, pretrained encoders can overfit spurious correlations such as essay length or topical keywords. Subsequent work explores calibration, domain adaptation, and multi-task training with auxiliary linguistic tasks. Our approach combines contrastive calibration with prompt-aware adapters to mitigate bias and enhance generalization.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto choice for molecular property prediction by operating on molecular graphs where atoms are nodes and bonds are edges. Message Passing Neural Networks and their variants incorporate edge features and use learned aggregation functions to capture local chemical environments. Recent approaches integrate 3D geometry through distance-aware attention and equivariant layers to better model steric effects in quantum and biophysical tasks.\n\nIn a previous study, the authors claim that augmenting atom features with ring counts reduces RMSE by 12%. Other efforts combine domain knowledge with learned representations via scaffold splitting and multitask learning to address distribution shifts across chemical series. Pretraining on large unlabeled compound libraries with contrastive objectives has also improved downstream performance, especially in low-data regimes.\nRelated Work\n\nNeural code generation has advanced rapidly with large language models trained on source code (Chen et al., 2021; Austin et al., 2021). Complementary to pure generation, retrieval-based methods augment a model's context with relevant code snippets or API documentation to improve factuality and adherence to project conventions (Lewis et al., 2020). There have been many recent works exploring retrieval-augmented generation for code synthesis. However, most approaches treat retrieval and generation as loosely coupled modules, leaving open questions on how to jointly optimize them end-to-end. In contrast, prompt tuning and in-context learning strategies have focused on better instruction formatting and example selection (Min et al., 2022), but typically without external code retrieval. Our work studies tighter integration by learning retriever and generator parameters with a unified objective while controlling for code style drift.\nRelated Work\n\nOpen-domain QA research spans retrieval, reasoning, and answer calibration. A common thread is the need to verify whether candidate answers are supported by the retrieved evidence.\n\nThe EcoQA Shared Task defined answer verification as a binary classification problem. Subsequent work extended this framing to multi-label entailment and joint retrieval-verification pipelines. Despite progress, many systems conflate retrieval confidence with verification confidence, leading to overconfident false positives.\n\nOur method decouples evidence aggregation from veracity estimation and employs uncertainty-aware ensembling to reduce calibration error.\nIntroduction\n\n3D object detection from LiDAR and camera data underpins safe autonomous driving. Classical pipelines relied on hand-crafted features and region proposals, but modern systems integrate voxelization, sparse convolution, and transformer attention to fuse multi-sensor signals. The KITTI benchmark leaderboards clearly show the superiority of transformer-based backbones. Motivated by this trend, we present a memory-efficient attention module tailored to sparse 3D tensors and demonstrate improvements on urban driving datasets under tight latency constraints.\n\nRelated Work\n\nFusion strategies range from early feature concatenation to late decision-level integration, with recent approaches favoring cross-attention between learned query anchors and multi-scale feature maps.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto approach for learning over relational data, with variants that aggregate neighbor signals through learned message passing. Architectural choices such as attention, sampling strategies, and normalization significantly influence model performance.\n\nGAT generally outperforms GCN on citation networks like Cora and Citeseer. However, the magnitude of the improvement varies with feature preprocessing, training splits, and evaluation protocols, motivating a more controlled comparison.\n\nIntroduction\n\nAccurate short-term traffic forecasting is essential for intelligent transportation systems and route planning. Recent approaches leverage spatio-temporal graph neural networks to model non-Euclidean road networks and dynamic traffic patterns (Li et al., 2018; Yu et al., 2018; Wu et al., 2019). Benchmark datasets such as METR-LA and PEMS-BAY are commonly used to evaluate forecasting accuracy across horizons from 5 to 60 minutes (Seo et al., 2018; Pan et al., 2020). The METR-LA dataset contains 4 months of sensor readings at 5-minute intervals. Despite progress, models often overfit to local temporal autocorrelation while failing to capture long-range dependencies induced by network topology (Song et al., 2020). To address this limitation, we propose a multi-scale diffusion architecture that combines spectral and spatial message passing with horizon-aware decoders. We evaluate on standard datasets and report consistent gains for medium- and long-horizon predictions.\n\nRelated Work\n\nEarly works applied ARIMA and VAR to traffic series but struggled with non-linearities (Li et al., 2015). Deep methods such as temporal CNNs and LSTMs improved temporal modeling but ignored graph structure (Ma et al., 2017). Graph-based models introduced diffusion convolutions and attention mechanisms to capture spatial dependencies (Li et al., 2018; Wu et al., 2019). Recent work explores contrastive pretraining for traffic states to enhance robustness under distribution shift (Liu et al., 2022).\nRelated Work\n\nRecommender systems increasingly leverage temporal dynamics and user intent modeling through sequence-aware architectures such as SASRec and GRU4Rec variants (Hidasi et al., 2016; Kang and McAuley, 2018). Contrastive objectives and data augmentation have further improved robustness to sparse interactions (Sun et al., 2019; Xie et al., 2020).\n\nIn shared-task evaluations, public leaderboards often catalyze rapid progress but can bias research toward narrow metrics and datasets. Notably, sequence-aware recommenders dominated the top positions in the 2023 RecSys Challenge, which emphasized short-term next-item prediction on evolving catalogs.\n\nWe analyze the inductive biases that favored such models and introduce a hybrid architecture that combines sequential encoders with catalog-aware regularization to enhance long-tail coverage.\nIntroduction\n\nQuestion answering (QA) systems have advanced with large-scale pretraining and improved retrieval. While open-domain QA has been extensively benchmarked, domain-specific QA remains challenging due to terminology drift and evidence sparsity in specialized corpora. Existing reading-comprehension datasets do not fully capture these domain shifts, particularly in biomedical and clinical settings.\n\nThe SQuAD v3.0 corpus adds unanswerable questions in the biomedical domain. Building on this premise, we examine whether models trained with adversarial unanswerable examples transfer more robustly to scientific QA scenarios. We further analyze error modes related to negation and abbreviation expansion, both of which are prevalent in biomedical texts.\n\nOur contributions are three-fold: (1) a controlled evaluation protocol for domain shift in QA, (2) an analysis of unanswerable triggers in scientific paragraphs, and (3) a modular training recipe for adapting general-purpose QA models to biomedical literature.\nRelated Work\n\nData Augmentation for Neural Machine Translation Semi- and unsupervised strategies have been critical to NMT performance in low- and mid-resource settings (Sennrich et al., 2016; Edunov et al., 2018). Noisy channel models, dual learning, and synthetic data generation have each shown benefits under different data regimes (Yu et al., 2018; He et al., 2016). Back-translation remains the most effective data augmentation technique for NMT, particularly when monolingual target data vastly outnumbers parallel corpora.\n\nOur Approach We revisit back-translation under constrained compute by optimizing sampling policies for the reverse model and filtering synthetic pairs with a bilingual consistency score.\nIntroduction\n\nAutomatic essay scoring (AES) assesses writing proficiency to support large-scale educational assessment (Shermis and Burstein, 2013). Traditional AES relied on handcrafted linguistic features and regression or ranking models (Attali and Burstein, 2006; Yannakoudakis et al., 2011). More recently, pretrained language models have improved robustness and domain transfer (Ushio et al., 2022).\n\nBERT has been widely adopted for AES with character-level tokenization. However, the interaction of subword vocabularies with orthographic errors and code-mixing in student writing remains poorly understood. We propose a hybrid tokenization strategy with adaptive granularity to mitigate error-propagation while preserving semantic cues.\nIntroduction\n\nTransfer learning underpins many advances in computer vision by enabling models to leverage general visual features learned from large datasets. While early work on medical imaging relied on handcrafted radiomics features, modern approaches pretrain convolutional or transformer-based encoders on generic datasets before fine-tuning on specialized modalities (He et al., 2016; Dosovitskiy et al., 2021). ImageNet has become the de facto benchmark for transfer learning in medical imaging. Nevertheless, domain gap and label mismatch can limit the usefulness of generic pretraining when target tasks involve grayscale modalities or highly imbalanced pathologies (Azizi et al., 2021).\nIntroduction\n\nAlgorithmic fairness seeks to ensure equitable model behavior across protected groups, balancing accuracy with notions of individual and group fairness (Dwork et al., 2012; Hardt et al., 2016; Kleinberg et al., 2017). Causal approaches formalize fairness via structural causal models and counterfactual reasoning, seeking invariance under interventions on protected attributes (Pearl, 2009; Kusner et al., 2017).\n\nOperationalizing causal fairness requires assumptions about causal graphs, identification, and tractable estimators. There has been a surge of recent works proposing counterfactual fairness metrics. In this paper, we introduce a calibration-aware, path-specific measure that separates permissible and impermissible causal pathways, and we present a consistent estimator under partial graph knowledge.\n\nWe evaluate on semi-synthetic datasets built from COMPAS and Adult, as well as a loan approval dataset with expert-elicited causal structures.\nIntroduction\n\nProgram synthesis benchmarks often struggle to disentangle memorization from genuine generalization, especially when patterns leak from training to test splits (Devlin et al., 2017; Chen et al., 2021). Community competitions have experimented with various protocols to curb information leakage and encourage robust evaluation.\n\nCompetitions that restrict test access but not training data generally report higher generalization scores. Nevertheless, differences in sandboxing, allowed resources, and evaluation budgets complicate comparison. We propose a standardized hidden testbed with query limits to study how access constraints affect overfitting.\nIntroduction\n\nSarcasm detection aims to identify utterances whose literal meaning contrasts with the intended sentiment. While early research focused on lexical and syntactic cues in text, social media posts often combine images, emojis, and hashtags, motivating multimodal approaches. However, there have been many recent works on multimodal sarcasm detection exploring vision-language fusion and context modeling. Despite progress, models still struggle to generalize across domains and platforms due to style variability and annotation noise. In this paper, we present a lightweight fusion architecture that adapts to platform-specific features without requiring extensive retraining.\n\nWe evaluate our approach on multiple multimodal benchmarks and analyze robustness to distribution shift. We also provide an ablation study on cross-attention depth and feature normalization. Finally, we discuss annotation guidelines to reduce ambiguity in multimodal sarcasm labels.\n",
        "completion": "there have been many recent works on multimodal sarcasm detection"
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        claim about prior work or statistics w/o citation or evidence. \n    a) The author should cite at every first mention of a study, paper, shared task, competition or dataset.\n    b) Specific information to a niche topic, despite sounding like it should be known in that topic of study, should be cited.\n    c) If a claim is made and is obvious to be a natural deduction from previous statements through common sense (i.e not requiring expert knowledge), then this claim does not fall under \u2018Unsupported claim\u2019. For example:\n        i) \u201cHowever, creating a large and suitable set of questions for supporting narrative comprehension is both time-consuming and cognitively demanding.\u201d -> it is obvious that creating a dataset is time consuming and mentally demanding.\n    d) Any mention of \u201crecent works\u201d should be backed up with citations to the works.\n    e) Unsupported claim issues appear as segments, phrases, sub-sentences or full sentences.\n    Examples of unsupported claims include:\n        i) Missing citations for mentions of 'recent works': \u201cand there are many recent works that explore this topic\u201d,\n        ii) Mention of a previous work and claim without citation: \u201c..., while in a previous study, the authors claim \u2026\u201d,\n        iii) Mentioning of a specific setup of a task without citation to the work: \".. BERT was used in an AES task trained on essays ..\" \n\n        Example text: \n        Introduction\n\nPolicy gradient methods have become a mainstay in reinforcement learning due to their simplicity and ability to handle continuous action spaces (Sutton et al., 2000; Schulman et al., 2017). Improved stability via clipped objectives and generalized advantage estimation has enabled better sample efficiency and robustness across tasks. On Atari 2600, PPO reaches human-level performance on many games. Nevertheless, exploration remains a bottleneck, particularly in sparse-reward environments where naive entropy bonuses are insufficient (Ecoffet et al., 2019). We propose an intrinsic motivation scheme based on state abstraction that scales to long horizons without destabilizing policy updates.\nIntroduction\n\nSpeech emotion recognition (SER) seeks to infer affective states from acoustic and linguistic cues. Classical approaches rely on engineered prosodic features combined with SVMs (Schuller et al., 2011), while recent work leverages self-supervised pretraining and multimodal fusion (Baevski et al., 2020; Tsai et al., 2019). The IEMOCAP dataset is considered the de facto standard benchmark for speech emotion recognition.\n\nHowever, heavy reliance on acted corpora raises questions about ecological validity. Cross-corpus generalization remains challenging due to speaker, channel, and annotation mismatches. We study robust SER by combining wav2vec-style representations with domain adversarial training, and we evaluate on multiple corpora, including acted and in-the-wild datasets, to better approximate real-world deployment scenarios.\nIntroduction\n\nCross-lingual transfer aims to leverage supervision in high-resource languages to improve performance in low-resource settings (Ruder et al., 2019; Conneau and Lample, 2019). Pretrained multilingual encoders enable zero-shot and few-shot transfer on a variety of tasks, but evaluation remains challenging due to dataset coverage and annotation quality. XTREME covers more than 40 languages and remains the most widely used multilingual benchmark. However, its task mix may not fully reflect realistic domain shifts encountered in production systems. We introduce a complementary benchmark focused on noisy user-generated text with balanced representation across low- and mid-resource languages.\nSpeech Recognition and Data Augmentation\n\nEnd-to-end automatic speech recognition (ASR) systems benefit significantly from data augmentation techniques that enhance robustness to acoustic and speaker variability. Time masking, frequency masking, and time warping applied to log-Mel spectrograms have shown substantial gains across corpora and model sizes. SpecAugment has become the de facto standard data augmentation in end-to-end ASR. Nevertheless, its interaction with noise conditions, speaker normalization, and curriculum schedules is not yet well understood.\n\nWe investigate augmentation schedules that adapt masking intensity to utterance length and model confidence, and we analyze their effects on stability during large-batch training. We further explore complementarity between augmentation and semi-supervised training with pseudo-labels in low-resource settings.\n\nOur results indicate that adaptive masking coupled with confidence-aware sampling reduces word error rate and mitigates overfitting on short utterances. We release configuration files and scripts to facilitate replication across common ASR toolchains.\nRelated Work\n\nOnline decision-making for ad allocation balances immediate revenue with long-term learning under uncertainty. Classic approaches modeled the problem as multi-armed bandits, later extended to incorporate context and delayed feedback. Practical systems must also address non-stationarity, covariate shift, and budget constraints across campaigns.\n\nWithin industry practice, contextual bandit methods have dominated online ad allocation in the last five years, with growing interest in offline policy evaluation for safe deployment. Yet, robust learning under evolving auctions and strategic advertiser behavior remains underexplored.\n\nWe present a robust, budget-aware contextual policy that adapts to market shifts via risk-sensitive objectives and counterfactual evaluation.\nRelated Work\n\nGraph representation learning has matured from shallow embeddings to deep architectures capable of capturing long-range dependencies and hierarchical structure. Pooling mechanisms coarsen graphs to derive multi-scale features, trading off expressivity and computational cost. Nearly all recent graph pooling methods are differentiable. Nevertheless, end-to-end differentiability can obscure the inductive biases introduced by the pooling criterion, complicating comparisons across tasks. Our work focuses on explicit, structure-preserving pooling that admits closed-form analysis of stability under edge perturbations.\n\nWe also consider connections to spectral clustering and minimum cut formulations to position our method within classical graph reduction techniques.\nIntroduction\n\nBiomedical named entity recognition (BioNER) underpins downstream tasks such as relation extraction and knowledge base curation (Settles, 2004; Li et al., 2016). Contextualized encoders adapted to biomedical corpora have advanced state of the art across multiple datasets (Beltagy et al., 2019; Lee et al., 2020). In a previous study, the authors claim that contextual embeddings outperform CRFs by 15 F1 on BC5CDR. Despite these gains, robustness to lexical variation and emerging terminology remains limited (Wang et al., 2021; Sung et al., 2021). We propose lexicon-augmented adapters to bridge out-of-vocabulary gaps.\nRelated Work\n\nQuestion answering over knowledge graphs (KGQA) requires reasoning over entities and relations to locate answers in a structured graph. Neural symbolic approaches combine learned representations with logical constraints to improve interpretability and compositionality (Yang et al., 2017; Soroush et al., 2018). Contrastive and retrieval-augmented models have improved entity disambiguation and relation handling (Sun et al., 2019; Xiong et al., 2020).\n\nMulti-hop reasoning is particularly challenging due to combinatorial expansion of candidate paths and the need to assess path plausibility. Recent work has examined path-based encoders, reinforcement learning over relation sequences, and graph attention mechanisms to prioritize informative subgraphs (Das et al., 2017; Lin et al., 2018). Extensions to heterogeneous KGs incorporate node and edge types, meta-paths, and schema constraints to guide inference, and there are many recent works that explore multi-hop reasoning in heterogeneous KGs. Our approach introduces a schema-aware pruning step that reduces path explosion by leveraging domain ontologies.\n\nWe evaluate on standard KGQA datasets and measure both accuracy and latency to assess practical viability under interactive constraints (Bordes et al., 2015; Yih et al., 2016).\nRelated Work\n\nFew-shot structured prediction has focused on leveraging syntactic priors and meta-learning to adapt parsers with minimal labeled data. In a prior study, the authors show that curriculum learning improves few-shot parsing. Subsequent approaches introduce data selection strategies that rank training examples by estimated difficulty and syntactic coverage. Our work builds on the idea of structured curricula by proposing a dependency-aware sampling schedule that prioritizes rare relation types during early training.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a primary tool for fraud and anomaly detection in relational data, capturing higher-order structures that traditional methods miss (Kipf and Welling, 2017; Dou et al., 2020). Self-supervised objectives further enhance representation learning when labels are scarce (Velickovic et al., 2019; You et al., 2020). GCN-based autoencoders were used in the XBRL anomaly detection task on SEC filings. Our work extends these ideas with temporal edge features and contrastive regularization to model evolving corporate networks.\nIntroduction\nFederated learning (FL) enables decentralized training across clients while preserving data locality. On graph-structured data, FL must handle non-i.i.d. topologies, heterophily, and varying label regimes, complicating aggregation and personalization (Wang and Luo, 2021; Cheng et al., 2022). Meanwhile, differential privacy (DP) offers formal protections against information leakage from trained models.\nTo the best of our knowledge, this is the first method to provide certified DP guarantees for graph federated learning. We integrate gradient clipping and noise accounting with topology-aware aggregation to bound privacy loss per client. Our analysis includes tight composition and post-processing invariance under client sampling.\nWe validate on citation and social network benchmarks, demonstrating improved utility-privacy trade-offs over non-graph baselines.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has benefited from large supervised datasets and self-supervised pretraining on unlabeled audio (Baevski et al., 2020; Hsu et al., 2021). However, language coverage remains uneven, with many under-resourced languages lacking sufficient transcribed data.\n\nMost low-resource ASR corpora only provide phoneme-level transcriptions, limiting the utility of standard sequence-to-sequence models that expect graphemic or word-level targets. This mismatch motivates intermediate representations and multilingual sharing strategies.\n\nWe propose a pronunciation-informed transducer that aligns phoneme inventories to graphemic targets via learned lexicon induction, improving transfer in settings with sparse orthographic supervision.\nRelated Work\n\nSelf-Supervised Pretraining for Speech Recognition. Recent ASR systems leverage SSL models such as wav2vec 2.0 (Baevski et al., 2020), HuBERT (Hsu et al., 2021), and WavLM (Chen et al., 2022) to improve label efficiency. These models are typically fine-tuned on labeled speech after pretraining on large unlabeled corpora. There are numerous recent works demonstrating that wav2vec-style pretraining makes labeled speech obsolete for low-resource ASR. In contrast, semi-supervised training methods like pseudo-labeling (Kahn et al., 2020) still rely on a modest amount of transcribed data.\nIntroduction\n\nRobotic Grasping and Sim-to-Real Gap Training grasp policies in simulation is attractive due to safety and speed, but transferring to the real world remains difficult because of visual and dynamics discrepancies (Tobin et al., 2017; James et al., 2019). In vision-based manipulation, domain randomization has become the de facto standard for sim-to-real transfer in grasping, encouraging robustness to texture, lighting, and viewpoint changes.\n\nLimitations and Our Approach While effective, purely randomized domains may not target failure modes relevant to a specific robot and workspace. We propose task-aware randomization guided by uncertainty estimates from a grasp success classifier, focusing synthetic variation where the policy is brittle.\nIntroduction\n\nSpoken language understanding systems rely on accurate slot filling to extract entities and attributes from user utterances in task-oriented dialogue. Data augmentation has become a popular strategy to mitigate data scarcity, particularly in low-resource settings. In a previous study, the authors showed that synthetic data improves slot filling by 23% on low-resource languages. Motivated by this observation, we explore a semantic-consistency constrained generator for augmenting intent-slot pairs across multiple domains.\nRelated Work\n\nBiomedical Named Entity Recognition. Biomedical NER has evolved from CRF-based sequence labeling to contextual encoders with domain pretraining (Li et al., 2015; Lee et al., 2020). Span-based and hypergraph formulations better capture nested and overlapping structures typical of biomedical text (Lu and Roth, 2015; Yu et al., 2020). We observe that 30% of entities are discontinuous in standard corpora. Distant supervision and dictionary expansion remain common for scaling annotations, though they introduce label noise (Fries et al., 2017; Giorgi and Bader, 2018). Our work proposes a span-merging decoder with uncertainty-aware training to address discontinuity and nestedness simultaneously.\nIntroduction\n\nAbstractive summarization has benefited greatly from encoder-decoder architectures with attention and pretraining. Early neural approaches emphasized sequence-to-sequence modeling and copy mechanisms to manage out-of-vocabulary tokens, while later work leveraged large language models to improve fluency and factuality. Controllability aims to steer generation along dimensions such as length, style, and topical focus, enabling users to specify desired attributes without retraining the model.\n\nThere are many recent works that explore controllable abstractive summarization for long-form news. At the same time, research on factual consistency has introduced knowledge-grounded constraints and post-generation verification to reduce hallucinations. Prompt-based conditioning and prefix tuning have emerged as parameter-efficient methods to inject control signals into pretrained models, and reinforcement learning from human feedback has been explored to align outputs with user preferences. Despite these advances, controlling discourse-level attributes such as entity coverage and narrative framing remains challenging for document-length inputs.\nIntroduction\n\nEntity linking in financial narratives aligns mentions in analyst reports and earnings-call transcripts to canonical identifiers. Accurate linking supports downstream tasks such as event extraction and risk modeling. Challenges include domain-specific aliases, telegraphic speech in transcripts, and frequent reference to dynamic instruments.\n\nThe 2019 Financial NLP shared task standardized evaluation for entity linking in earnings calls. Building on that setting, we introduce a stronger retrieval component and a normalization module that accounts for ticker changes and corporate actions.\n\nWe benchmark our approach on multi-source transcripts, analyze cross-quarter generalization, and study the interaction between contextual clues and external knowledge bases.\nRelated Work\n\nAutomated misinformation and rumor detection has drawn attention due to the rapid spread of unverified claims on social media. Early efforts emphasized surface-level signals such as lexical cues and sentiment markers, whereas more recent models incorporate propagation dynamics and user interaction graphs. In a previous study, the authors claimed that stance features alone can reach above 85% F1 on rumor datasets. Subsequent approaches have attempted to combine stance, veracity metadata, and temporal patterns, often yielding improvements in early detection where content is sparse.\n\nOur work departs from prior designs by integrating stance signals with source credibility and conversation depth features within a unified architecture. We specifically target low-latency prediction by leveraging partial threads and incrementally updating graph representations as new posts arrive.\nIntroduction\n\nRecommender systems mediate access to information, entertainment, and economic opportunity. Beyond accuracy, fairness in exposure has emerged as a key desideratum to mitigate harms to creators and users. It is well known that exposure disparity primarily stems from popularity bias in collaborative filtering. However, empirical drivers also include position bias, selection effects, and feedback loops created by sequential decision policies. We introduce a counterfactual evaluation protocol that disentangles these effects by reweighting logged interactions and estimating the causal impact of ranking on exposure.\n\nRelated Work\n\nPrevious work has proposed debiasing via propensity weighting, calibration constraints, and multi-objective learning that trades off relevance and fairness. Our method extends these formulations with a learned exposure model aligned to platform constraints.\nRelated Work\n\nNoisy user-generated text introduces misspellings, abbreviations, and creative orthography that degrade token-level models (Eisenstein, 2013). Subword and character encoders aim to mitigate this by capturing morphological regularities and providing open-vocabulary representations (Sennrich et al., 2016; Ma et al., 2016). Ablation studies consistently show that character-level embeddings improve robustness to noise. However, the degree of benefit varies with the tokenizer and pretraining corpus, and can be offset by domain shift in specialized vocabularies.\n\nOur work evaluates robustness under controlled corruption processes and compares character, subword, and hybrid representations across multiple downstream tasks, highlighting when each choice is most effective.\nRelated Work\n\nNamed entity recognition (NER) in the biomedical domain presents unique challenges due to specialized terminology, high ambiguity, and shifting nomenclature. Traditional sequence labeling with CRFs has been augmented by neural architectures that exploit subword information.\n\nContextual encoders combined with character-level modules have shown robustness to rare and morphologically complex tokens. In the 2017 shared task on biomedical NER, character-level LSTMs were the dominant approach. More recently, domain-adaptive pretraining has further improved performance, yet adaptation to new ontologies still requires careful calibration of label spaces.\nRelated Work\n\nCross-Lingual Transfer\n\nCross-lingual transfer seeks to leverage resources in high-resource languages to improve performance in low-resource settings. Alignment techniques span shared subword vocabularies, multilingual pretraining, and translation-based augmentation. In a previous study, the authors reported a 30% improvement on cross-lingual transfer for NER under zero-shot conditions. Subsequent work explores task-specific adapters and pseudo-labeling to better exploit unlabeled target-language data.\nIntroduction\n\nAutomatic speech recognition (ASR) in low-resource languages remains limited by scarce transcribed audio. Transfer learning from high-resource languages and self-supervised pretraining have narrowed the gap but still require careful adaptation to phonetic and lexical differences across language families.\n\nRecent works have explored multilingual knowledge distillation for ASR with impressive gains. These approaches typically train a powerful teacher on pooled multilingual data and transfer its knowledge to a student specialized for a target language. However, it is unclear which layers, loss functions, and alignment strategies are most beneficial when phonotactic divergence is large.\n\nWe propose a cross-lingual distillation framework that aligns intermediate representations using a pronunciation-informed mapping. Our method decomposes the distillation loss into CTC-aligned segments and prosodic cues, yielding improvements in both word error rate and robustness to domain shift. We evaluate on three typologically diverse languages and analyze how benefits correlate with teacher\u2013student language distance.\nRelated Work\n\nPolicy gradient methods have become standard for continuous control, with trust-region and proximal variants stabilizing updates by constraining policy divergence. Parallelization and normalization further improve sample efficiency and stability across tasks.\n\nEmpirical evaluations often focus on MuJoCo-based environments and robotics simulators, comparing return, stability, and sensitivity to hyperparameters. Techniques such as generalized advantage estimation and reward scaling are commonly adopted across algorithms.\n\nIt is widely known that PPO consistently outperforms TRPO on a broad range of continuous control tasks. Nonetheless, reported advantages can diminish under alternative tuning regimes or different environment stochasticity, motivating a closer look at evaluation practices.\nRelated Work\n\nAutomated Essay Scoring (AES) seeks to predict holistic or trait-specific scores from student writing. Traditional approaches rely on hand-crafted features, readability metrics, and prompt-specific templates. More recently, pretrained language models have enabled end-to-end scoring with improved robustness across prompts and genres. BERT has been successfully applied to automated essay scoring trained on student essays, often fine-tuned with regression heads and attention-based pooling.\n\nHowever, pretrained encoders can overfit spurious correlations such as essay length or topical keywords. Subsequent work explores calibration, domain adaptation, and multi-task training with auxiliary linguistic tasks. Our approach combines contrastive calibration with prompt-aware adapters to mitigate bias and enhance generalization.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto choice for molecular property prediction by operating on molecular graphs where atoms are nodes and bonds are edges. Message Passing Neural Networks and their variants incorporate edge features and use learned aggregation functions to capture local chemical environments. Recent approaches integrate 3D geometry through distance-aware attention and equivariant layers to better model steric effects in quantum and biophysical tasks.\n\nIn a previous study, the authors claim that augmenting atom features with ring counts reduces RMSE by 12%. Other efforts combine domain knowledge with learned representations via scaffold splitting and multitask learning to address distribution shifts across chemical series. Pretraining on large unlabeled compound libraries with contrastive objectives has also improved downstream performance, especially in low-data regimes.\nRelated Work\n\nNeural code generation has advanced rapidly with large language models trained on source code (Chen et al., 2021; Austin et al., 2021). Complementary to pure generation, retrieval-based methods augment a model's context with relevant code snippets or API documentation to improve factuality and adherence to project conventions (Lewis et al., 2020). There have been many recent works exploring retrieval-augmented generation for code synthesis. However, most approaches treat retrieval and generation as loosely coupled modules, leaving open questions on how to jointly optimize them end-to-end. In contrast, prompt tuning and in-context learning strategies have focused on better instruction formatting and example selection (Min et al., 2022), but typically without external code retrieval. Our work studies tighter integration by learning retriever and generator parameters with a unified objective while controlling for code style drift.\nRelated Work\n\nOpen-domain QA research spans retrieval, reasoning, and answer calibration. A common thread is the need to verify whether candidate answers are supported by the retrieved evidence.\n\nThe EcoQA Shared Task defined answer verification as a binary classification problem. Subsequent work extended this framing to multi-label entailment and joint retrieval-verification pipelines. Despite progress, many systems conflate retrieval confidence with verification confidence, leading to overconfident false positives.\n\nOur method decouples evidence aggregation from veracity estimation and employs uncertainty-aware ensembling to reduce calibration error.\nIntroduction\n\n3D object detection from LiDAR and camera data underpins safe autonomous driving. Classical pipelines relied on hand-crafted features and region proposals, but modern systems integrate voxelization, sparse convolution, and transformer attention to fuse multi-sensor signals. The KITTI benchmark leaderboards clearly show the superiority of transformer-based backbones. Motivated by this trend, we present a memory-efficient attention module tailored to sparse 3D tensors and demonstrate improvements on urban driving datasets under tight latency constraints.\n\nRelated Work\n\nFusion strategies range from early feature concatenation to late decision-level integration, with recent approaches favoring cross-attention between learned query anchors and multi-scale feature maps.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto approach for learning over relational data, with variants that aggregate neighbor signals through learned message passing. Architectural choices such as attention, sampling strategies, and normalization significantly influence model performance.\n\nGAT generally outperforms GCN on citation networks like Cora and Citeseer. However, the magnitude of the improvement varies with feature preprocessing, training splits, and evaluation protocols, motivating a more controlled comparison.\n\nIntroduction\n\nAccurate short-term traffic forecasting is essential for intelligent transportation systems and route planning. Recent approaches leverage spatio-temporal graph neural networks to model non-Euclidean road networks and dynamic traffic patterns (Li et al., 2018; Yu et al., 2018; Wu et al., 2019). Benchmark datasets such as METR-LA and PEMS-BAY are commonly used to evaluate forecasting accuracy across horizons from 5 to 60 minutes (Seo et al., 2018; Pan et al., 2020). The METR-LA dataset contains 4 months of sensor readings at 5-minute intervals. Despite progress, models often overfit to local temporal autocorrelation while failing to capture long-range dependencies induced by network topology (Song et al., 2020). To address this limitation, we propose a multi-scale diffusion architecture that combines spectral and spatial message passing with horizon-aware decoders. We evaluate on standard datasets and report consistent gains for medium- and long-horizon predictions.\n\nRelated Work\n\nEarly works applied ARIMA and VAR to traffic series but struggled with non-linearities (Li et al., 2015). Deep methods such as temporal CNNs and LSTMs improved temporal modeling but ignored graph structure (Ma et al., 2017). Graph-based models introduced diffusion convolutions and attention mechanisms to capture spatial dependencies (Li et al., 2018; Wu et al., 2019). Recent work explores contrastive pretraining for traffic states to enhance robustness under distribution shift (Liu et al., 2022).\nRelated Work\n\nRecommender systems increasingly leverage temporal dynamics and user intent modeling through sequence-aware architectures such as SASRec and GRU4Rec variants (Hidasi et al., 2016; Kang and McAuley, 2018). Contrastive objectives and data augmentation have further improved robustness to sparse interactions (Sun et al., 2019; Xie et al., 2020).\n\nIn shared-task evaluations, public leaderboards often catalyze rapid progress but can bias research toward narrow metrics and datasets. Notably, sequence-aware recommenders dominated the top positions in the 2023 RecSys Challenge, which emphasized short-term next-item prediction on evolving catalogs.\n\nWe analyze the inductive biases that favored such models and introduce a hybrid architecture that combines sequential encoders with catalog-aware regularization to enhance long-tail coverage.\nIntroduction\n\nQuestion answering (QA) systems have advanced with large-scale pretraining and improved retrieval. While open-domain QA has been extensively benchmarked, domain-specific QA remains challenging due to terminology drift and evidence sparsity in specialized corpora. Existing reading-comprehension datasets do not fully capture these domain shifts, particularly in biomedical and clinical settings.\n\nThe SQuAD v3.0 corpus adds unanswerable questions in the biomedical domain. Building on this premise, we examine whether models trained with adversarial unanswerable examples transfer more robustly to scientific QA scenarios. We further analyze error modes related to negation and abbreviation expansion, both of which are prevalent in biomedical texts.\n\nOur contributions are three-fold: (1) a controlled evaluation protocol for domain shift in QA, (2) an analysis of unanswerable triggers in scientific paragraphs, and (3) a modular training recipe for adapting general-purpose QA models to biomedical literature.\nRelated Work\n\nData Augmentation for Neural Machine Translation Semi- and unsupervised strategies have been critical to NMT performance in low- and mid-resource settings (Sennrich et al., 2016; Edunov et al., 2018). Noisy channel models, dual learning, and synthetic data generation have each shown benefits under different data regimes (Yu et al., 2018; He et al., 2016). Back-translation remains the most effective data augmentation technique for NMT, particularly when monolingual target data vastly outnumbers parallel corpora.\n\nOur Approach We revisit back-translation under constrained compute by optimizing sampling policies for the reverse model and filtering synthetic pairs with a bilingual consistency score.\nIntroduction\n\nAutomatic essay scoring (AES) assesses writing proficiency to support large-scale educational assessment (Shermis and Burstein, 2013). Traditional AES relied on handcrafted linguistic features and regression or ranking models (Attali and Burstein, 2006; Yannakoudakis et al., 2011). More recently, pretrained language models have improved robustness and domain transfer (Ushio et al., 2022).\n\nBERT has been widely adopted for AES with character-level tokenization. However, the interaction of subword vocabularies with orthographic errors and code-mixing in student writing remains poorly understood. We propose a hybrid tokenization strategy with adaptive granularity to mitigate error-propagation while preserving semantic cues.\nIntroduction\n\nTransfer learning underpins many advances in computer vision by enabling models to leverage general visual features learned from large datasets. While early work on medical imaging relied on handcrafted radiomics features, modern approaches pretrain convolutional or transformer-based encoders on generic datasets before fine-tuning on specialized modalities (He et al., 2016; Dosovitskiy et al., 2021). ImageNet has become the de facto benchmark for transfer learning in medical imaging. Nevertheless, domain gap and label mismatch can limit the usefulness of generic pretraining when target tasks involve grayscale modalities or highly imbalanced pathologies (Azizi et al., 2021).\nIntroduction\n\nAlgorithmic fairness seeks to ensure equitable model behavior across protected groups, balancing accuracy with notions of individual and group fairness (Dwork et al., 2012; Hardt et al., 2016; Kleinberg et al., 2017). Causal approaches formalize fairness via structural causal models and counterfactual reasoning, seeking invariance under interventions on protected attributes (Pearl, 2009; Kusner et al., 2017).\n\nOperationalizing causal fairness requires assumptions about causal graphs, identification, and tractable estimators. There has been a surge of recent works proposing counterfactual fairness metrics. In this paper, we introduce a calibration-aware, path-specific measure that separates permissible and impermissible causal pathways, and we present a consistent estimator under partial graph knowledge.\n\nWe evaluate on semi-synthetic datasets built from COMPAS and Adult, as well as a loan approval dataset with expert-elicited causal structures.\nIntroduction\n\nProgram synthesis benchmarks often struggle to disentangle memorization from genuine generalization, especially when patterns leak from training to test splits (Devlin et al., 2017; Chen et al., 2021). Community competitions have experimented with various protocols to curb information leakage and encourage robust evaluation.\n\nCompetitions that restrict test access but not training data generally report higher generalization scores. Nevertheless, differences in sandboxing, allowed resources, and evaluation budgets complicate comparison. We propose a standardized hidden testbed with query limits to study how access constraints affect overfitting.\nIntroduction\n\nSarcasm detection aims to identify utterances whose literal meaning contrasts with the intended sentiment. While early research focused on lexical and syntactic cues in text, social media posts often combine images, emojis, and hashtags, motivating multimodal approaches. However, there have been many recent works on multimodal sarcasm detection exploring vision-language fusion and context modeling. Despite progress, models still struggle to generalize across domains and platforms due to style variability and annotation noise. In this paper, we present a lightweight fusion architecture that adapts to platform-specific features without requiring extensive retraining.\n\nWe evaluate our approach on multiple multimodal benchmarks and analyze robustness to distribution shift. We also provide an ablation study on cross-attention depth and feature normalization. Finally, we discuss annotation guidelines to reduce ambiguity in multimodal sarcasm labels.\nIntroduction\n\nQuestion answering (QA) benchmarks have driven rapid progress in machine reading and information access. Among extractive formulations, datasets featuring crowd-sourced questions over encyclopedic passages dominate training regimes, shaping both model inductive biases and evaluation practices. SQuAD has become the de facto dataset for extractive QA, but its lexical overlap and answer-span constraints limit generalization to open-domain settings.\n\nThis Work\n\nWe present a retrieval-augmented model with uncertainty-aware decoding and evaluate robustness to paraphrased questions and adversarial contexts.\n",
        "completion": "SQuAD has become the de facto dataset for extractive QA"
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        claim about prior work or statistics w/o citation or evidence. \n    a) The author should cite at every first mention of a study, paper, shared task, competition or dataset.\n    b) Specific information to a niche topic, despite sounding like it should be known in that topic of study, should be cited.\n    c) If a claim is made and is obvious to be a natural deduction from previous statements through common sense (i.e not requiring expert knowledge), then this claim does not fall under \u2018Unsupported claim\u2019. For example:\n        i) \u201cHowever, creating a large and suitable set of questions for supporting narrative comprehension is both time-consuming and cognitively demanding.\u201d -> it is obvious that creating a dataset is time consuming and mentally demanding.\n    d) Any mention of \u201crecent works\u201d should be backed up with citations to the works.\n    e) Unsupported claim issues appear as segments, phrases, sub-sentences or full sentences.\n    Examples of unsupported claims include:\n        i) Missing citations for mentions of 'recent works': \u201cand there are many recent works that explore this topic\u201d,\n        ii) Mention of a previous work and claim without citation: \u201c..., while in a previous study, the authors claim \u2026\u201d,\n        iii) Mentioning of a specific setup of a task without citation to the work: \".. BERT was used in an AES task trained on essays ..\" \n\n        Example text: \n        Introduction\n\nPolicy gradient methods have become a mainstay in reinforcement learning due to their simplicity and ability to handle continuous action spaces (Sutton et al., 2000; Schulman et al., 2017). Improved stability via clipped objectives and generalized advantage estimation has enabled better sample efficiency and robustness across tasks. On Atari 2600, PPO reaches human-level performance on many games. Nevertheless, exploration remains a bottleneck, particularly in sparse-reward environments where naive entropy bonuses are insufficient (Ecoffet et al., 2019). We propose an intrinsic motivation scheme based on state abstraction that scales to long horizons without destabilizing policy updates.\nIntroduction\n\nSpeech emotion recognition (SER) seeks to infer affective states from acoustic and linguistic cues. Classical approaches rely on engineered prosodic features combined with SVMs (Schuller et al., 2011), while recent work leverages self-supervised pretraining and multimodal fusion (Baevski et al., 2020; Tsai et al., 2019). The IEMOCAP dataset is considered the de facto standard benchmark for speech emotion recognition.\n\nHowever, heavy reliance on acted corpora raises questions about ecological validity. Cross-corpus generalization remains challenging due to speaker, channel, and annotation mismatches. We study robust SER by combining wav2vec-style representations with domain adversarial training, and we evaluate on multiple corpora, including acted and in-the-wild datasets, to better approximate real-world deployment scenarios.\nIntroduction\n\nCross-lingual transfer aims to leverage supervision in high-resource languages to improve performance in low-resource settings (Ruder et al., 2019; Conneau and Lample, 2019). Pretrained multilingual encoders enable zero-shot and few-shot transfer on a variety of tasks, but evaluation remains challenging due to dataset coverage and annotation quality. XTREME covers more than 40 languages and remains the most widely used multilingual benchmark. However, its task mix may not fully reflect realistic domain shifts encountered in production systems. We introduce a complementary benchmark focused on noisy user-generated text with balanced representation across low- and mid-resource languages.\nSpeech Recognition and Data Augmentation\n\nEnd-to-end automatic speech recognition (ASR) systems benefit significantly from data augmentation techniques that enhance robustness to acoustic and speaker variability. Time masking, frequency masking, and time warping applied to log-Mel spectrograms have shown substantial gains across corpora and model sizes. SpecAugment has become the de facto standard data augmentation in end-to-end ASR. Nevertheless, its interaction with noise conditions, speaker normalization, and curriculum schedules is not yet well understood.\n\nWe investigate augmentation schedules that adapt masking intensity to utterance length and model confidence, and we analyze their effects on stability during large-batch training. We further explore complementarity between augmentation and semi-supervised training with pseudo-labels in low-resource settings.\n\nOur results indicate that adaptive masking coupled with confidence-aware sampling reduces word error rate and mitigates overfitting on short utterances. We release configuration files and scripts to facilitate replication across common ASR toolchains.\nRelated Work\n\nOnline decision-making for ad allocation balances immediate revenue with long-term learning under uncertainty. Classic approaches modeled the problem as multi-armed bandits, later extended to incorporate context and delayed feedback. Practical systems must also address non-stationarity, covariate shift, and budget constraints across campaigns.\n\nWithin industry practice, contextual bandit methods have dominated online ad allocation in the last five years, with growing interest in offline policy evaluation for safe deployment. Yet, robust learning under evolving auctions and strategic advertiser behavior remains underexplored.\n\nWe present a robust, budget-aware contextual policy that adapts to market shifts via risk-sensitive objectives and counterfactual evaluation.\nRelated Work\n\nGraph representation learning has matured from shallow embeddings to deep architectures capable of capturing long-range dependencies and hierarchical structure. Pooling mechanisms coarsen graphs to derive multi-scale features, trading off expressivity and computational cost. Nearly all recent graph pooling methods are differentiable. Nevertheless, end-to-end differentiability can obscure the inductive biases introduced by the pooling criterion, complicating comparisons across tasks. Our work focuses on explicit, structure-preserving pooling that admits closed-form analysis of stability under edge perturbations.\n\nWe also consider connections to spectral clustering and minimum cut formulations to position our method within classical graph reduction techniques.\nIntroduction\n\nBiomedical named entity recognition (BioNER) underpins downstream tasks such as relation extraction and knowledge base curation (Settles, 2004; Li et al., 2016). Contextualized encoders adapted to biomedical corpora have advanced state of the art across multiple datasets (Beltagy et al., 2019; Lee et al., 2020). In a previous study, the authors claim that contextual embeddings outperform CRFs by 15 F1 on BC5CDR. Despite these gains, robustness to lexical variation and emerging terminology remains limited (Wang et al., 2021; Sung et al., 2021). We propose lexicon-augmented adapters to bridge out-of-vocabulary gaps.\nRelated Work\n\nQuestion answering over knowledge graphs (KGQA) requires reasoning over entities and relations to locate answers in a structured graph. Neural symbolic approaches combine learned representations with logical constraints to improve interpretability and compositionality (Yang et al., 2017; Soroush et al., 2018). Contrastive and retrieval-augmented models have improved entity disambiguation and relation handling (Sun et al., 2019; Xiong et al., 2020).\n\nMulti-hop reasoning is particularly challenging due to combinatorial expansion of candidate paths and the need to assess path plausibility. Recent work has examined path-based encoders, reinforcement learning over relation sequences, and graph attention mechanisms to prioritize informative subgraphs (Das et al., 2017; Lin et al., 2018). Extensions to heterogeneous KGs incorporate node and edge types, meta-paths, and schema constraints to guide inference, and there are many recent works that explore multi-hop reasoning in heterogeneous KGs. Our approach introduces a schema-aware pruning step that reduces path explosion by leveraging domain ontologies.\n\nWe evaluate on standard KGQA datasets and measure both accuracy and latency to assess practical viability under interactive constraints (Bordes et al., 2015; Yih et al., 2016).\nRelated Work\n\nFew-shot structured prediction has focused on leveraging syntactic priors and meta-learning to adapt parsers with minimal labeled data. In a prior study, the authors show that curriculum learning improves few-shot parsing. Subsequent approaches introduce data selection strategies that rank training examples by estimated difficulty and syntactic coverage. Our work builds on the idea of structured curricula by proposing a dependency-aware sampling schedule that prioritizes rare relation types during early training.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a primary tool for fraud and anomaly detection in relational data, capturing higher-order structures that traditional methods miss (Kipf and Welling, 2017; Dou et al., 2020). Self-supervised objectives further enhance representation learning when labels are scarce (Velickovic et al., 2019; You et al., 2020). GCN-based autoencoders were used in the XBRL anomaly detection task on SEC filings. Our work extends these ideas with temporal edge features and contrastive regularization to model evolving corporate networks.\nIntroduction\nFederated learning (FL) enables decentralized training across clients while preserving data locality. On graph-structured data, FL must handle non-i.i.d. topologies, heterophily, and varying label regimes, complicating aggregation and personalization (Wang and Luo, 2021; Cheng et al., 2022). Meanwhile, differential privacy (DP) offers formal protections against information leakage from trained models.\nTo the best of our knowledge, this is the first method to provide certified DP guarantees for graph federated learning. We integrate gradient clipping and noise accounting with topology-aware aggregation to bound privacy loss per client. Our analysis includes tight composition and post-processing invariance under client sampling.\nWe validate on citation and social network benchmarks, demonstrating improved utility-privacy trade-offs over non-graph baselines.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has benefited from large supervised datasets and self-supervised pretraining on unlabeled audio (Baevski et al., 2020; Hsu et al., 2021). However, language coverage remains uneven, with many under-resourced languages lacking sufficient transcribed data.\n\nMost low-resource ASR corpora only provide phoneme-level transcriptions, limiting the utility of standard sequence-to-sequence models that expect graphemic or word-level targets. This mismatch motivates intermediate representations and multilingual sharing strategies.\n\nWe propose a pronunciation-informed transducer that aligns phoneme inventories to graphemic targets via learned lexicon induction, improving transfer in settings with sparse orthographic supervision.\nRelated Work\n\nSelf-Supervised Pretraining for Speech Recognition. Recent ASR systems leverage SSL models such as wav2vec 2.0 (Baevski et al., 2020), HuBERT (Hsu et al., 2021), and WavLM (Chen et al., 2022) to improve label efficiency. These models are typically fine-tuned on labeled speech after pretraining on large unlabeled corpora. There are numerous recent works demonstrating that wav2vec-style pretraining makes labeled speech obsolete for low-resource ASR. In contrast, semi-supervised training methods like pseudo-labeling (Kahn et al., 2020) still rely on a modest amount of transcribed data.\nIntroduction\n\nRobotic Grasping and Sim-to-Real Gap Training grasp policies in simulation is attractive due to safety and speed, but transferring to the real world remains difficult because of visual and dynamics discrepancies (Tobin et al., 2017; James et al., 2019). In vision-based manipulation, domain randomization has become the de facto standard for sim-to-real transfer in grasping, encouraging robustness to texture, lighting, and viewpoint changes.\n\nLimitations and Our Approach While effective, purely randomized domains may not target failure modes relevant to a specific robot and workspace. We propose task-aware randomization guided by uncertainty estimates from a grasp success classifier, focusing synthetic variation where the policy is brittle.\nIntroduction\n\nSpoken language understanding systems rely on accurate slot filling to extract entities and attributes from user utterances in task-oriented dialogue. Data augmentation has become a popular strategy to mitigate data scarcity, particularly in low-resource settings. In a previous study, the authors showed that synthetic data improves slot filling by 23% on low-resource languages. Motivated by this observation, we explore a semantic-consistency constrained generator for augmenting intent-slot pairs across multiple domains.\nRelated Work\n\nBiomedical Named Entity Recognition. Biomedical NER has evolved from CRF-based sequence labeling to contextual encoders with domain pretraining (Li et al., 2015; Lee et al., 2020). Span-based and hypergraph formulations better capture nested and overlapping structures typical of biomedical text (Lu and Roth, 2015; Yu et al., 2020). We observe that 30% of entities are discontinuous in standard corpora. Distant supervision and dictionary expansion remain common for scaling annotations, though they introduce label noise (Fries et al., 2017; Giorgi and Bader, 2018). Our work proposes a span-merging decoder with uncertainty-aware training to address discontinuity and nestedness simultaneously.\nIntroduction\n\nAbstractive summarization has benefited greatly from encoder-decoder architectures with attention and pretraining. Early neural approaches emphasized sequence-to-sequence modeling and copy mechanisms to manage out-of-vocabulary tokens, while later work leveraged large language models to improve fluency and factuality. Controllability aims to steer generation along dimensions such as length, style, and topical focus, enabling users to specify desired attributes without retraining the model.\n\nThere are many recent works that explore controllable abstractive summarization for long-form news. At the same time, research on factual consistency has introduced knowledge-grounded constraints and post-generation verification to reduce hallucinations. Prompt-based conditioning and prefix tuning have emerged as parameter-efficient methods to inject control signals into pretrained models, and reinforcement learning from human feedback has been explored to align outputs with user preferences. Despite these advances, controlling discourse-level attributes such as entity coverage and narrative framing remains challenging for document-length inputs.\nIntroduction\n\nEntity linking in financial narratives aligns mentions in analyst reports and earnings-call transcripts to canonical identifiers. Accurate linking supports downstream tasks such as event extraction and risk modeling. Challenges include domain-specific aliases, telegraphic speech in transcripts, and frequent reference to dynamic instruments.\n\nThe 2019 Financial NLP shared task standardized evaluation for entity linking in earnings calls. Building on that setting, we introduce a stronger retrieval component and a normalization module that accounts for ticker changes and corporate actions.\n\nWe benchmark our approach on multi-source transcripts, analyze cross-quarter generalization, and study the interaction between contextual clues and external knowledge bases.\nRelated Work\n\nAutomated misinformation and rumor detection has drawn attention due to the rapid spread of unverified claims on social media. Early efforts emphasized surface-level signals such as lexical cues and sentiment markers, whereas more recent models incorporate propagation dynamics and user interaction graphs. In a previous study, the authors claimed that stance features alone can reach above 85% F1 on rumor datasets. Subsequent approaches have attempted to combine stance, veracity metadata, and temporal patterns, often yielding improvements in early detection where content is sparse.\n\nOur work departs from prior designs by integrating stance signals with source credibility and conversation depth features within a unified architecture. We specifically target low-latency prediction by leveraging partial threads and incrementally updating graph representations as new posts arrive.\nIntroduction\n\nRecommender systems mediate access to information, entertainment, and economic opportunity. Beyond accuracy, fairness in exposure has emerged as a key desideratum to mitigate harms to creators and users. It is well known that exposure disparity primarily stems from popularity bias in collaborative filtering. However, empirical drivers also include position bias, selection effects, and feedback loops created by sequential decision policies. We introduce a counterfactual evaluation protocol that disentangles these effects by reweighting logged interactions and estimating the causal impact of ranking on exposure.\n\nRelated Work\n\nPrevious work has proposed debiasing via propensity weighting, calibration constraints, and multi-objective learning that trades off relevance and fairness. Our method extends these formulations with a learned exposure model aligned to platform constraints.\nRelated Work\n\nNoisy user-generated text introduces misspellings, abbreviations, and creative orthography that degrade token-level models (Eisenstein, 2013). Subword and character encoders aim to mitigate this by capturing morphological regularities and providing open-vocabulary representations (Sennrich et al., 2016; Ma et al., 2016). Ablation studies consistently show that character-level embeddings improve robustness to noise. However, the degree of benefit varies with the tokenizer and pretraining corpus, and can be offset by domain shift in specialized vocabularies.\n\nOur work evaluates robustness under controlled corruption processes and compares character, subword, and hybrid representations across multiple downstream tasks, highlighting when each choice is most effective.\nRelated Work\n\nNamed entity recognition (NER) in the biomedical domain presents unique challenges due to specialized terminology, high ambiguity, and shifting nomenclature. Traditional sequence labeling with CRFs has been augmented by neural architectures that exploit subword information.\n\nContextual encoders combined with character-level modules have shown robustness to rare and morphologically complex tokens. In the 2017 shared task on biomedical NER, character-level LSTMs were the dominant approach. More recently, domain-adaptive pretraining has further improved performance, yet adaptation to new ontologies still requires careful calibration of label spaces.\nRelated Work\n\nCross-Lingual Transfer\n\nCross-lingual transfer seeks to leverage resources in high-resource languages to improve performance in low-resource settings. Alignment techniques span shared subword vocabularies, multilingual pretraining, and translation-based augmentation. In a previous study, the authors reported a 30% improvement on cross-lingual transfer for NER under zero-shot conditions. Subsequent work explores task-specific adapters and pseudo-labeling to better exploit unlabeled target-language data.\nIntroduction\n\nAutomatic speech recognition (ASR) in low-resource languages remains limited by scarce transcribed audio. Transfer learning from high-resource languages and self-supervised pretraining have narrowed the gap but still require careful adaptation to phonetic and lexical differences across language families.\n\nRecent works have explored multilingual knowledge distillation for ASR with impressive gains. These approaches typically train a powerful teacher on pooled multilingual data and transfer its knowledge to a student specialized for a target language. However, it is unclear which layers, loss functions, and alignment strategies are most beneficial when phonotactic divergence is large.\n\nWe propose a cross-lingual distillation framework that aligns intermediate representations using a pronunciation-informed mapping. Our method decomposes the distillation loss into CTC-aligned segments and prosodic cues, yielding improvements in both word error rate and robustness to domain shift. We evaluate on three typologically diverse languages and analyze how benefits correlate with teacher\u2013student language distance.\nRelated Work\n\nPolicy gradient methods have become standard for continuous control, with trust-region and proximal variants stabilizing updates by constraining policy divergence. Parallelization and normalization further improve sample efficiency and stability across tasks.\n\nEmpirical evaluations often focus on MuJoCo-based environments and robotics simulators, comparing return, stability, and sensitivity to hyperparameters. Techniques such as generalized advantage estimation and reward scaling are commonly adopted across algorithms.\n\nIt is widely known that PPO consistently outperforms TRPO on a broad range of continuous control tasks. Nonetheless, reported advantages can diminish under alternative tuning regimes or different environment stochasticity, motivating a closer look at evaluation practices.\nRelated Work\n\nAutomated Essay Scoring (AES) seeks to predict holistic or trait-specific scores from student writing. Traditional approaches rely on hand-crafted features, readability metrics, and prompt-specific templates. More recently, pretrained language models have enabled end-to-end scoring with improved robustness across prompts and genres. BERT has been successfully applied to automated essay scoring trained on student essays, often fine-tuned with regression heads and attention-based pooling.\n\nHowever, pretrained encoders can overfit spurious correlations such as essay length or topical keywords. Subsequent work explores calibration, domain adaptation, and multi-task training with auxiliary linguistic tasks. Our approach combines contrastive calibration with prompt-aware adapters to mitigate bias and enhance generalization.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto choice for molecular property prediction by operating on molecular graphs where atoms are nodes and bonds are edges. Message Passing Neural Networks and their variants incorporate edge features and use learned aggregation functions to capture local chemical environments. Recent approaches integrate 3D geometry through distance-aware attention and equivariant layers to better model steric effects in quantum and biophysical tasks.\n\nIn a previous study, the authors claim that augmenting atom features with ring counts reduces RMSE by 12%. Other efforts combine domain knowledge with learned representations via scaffold splitting and multitask learning to address distribution shifts across chemical series. Pretraining on large unlabeled compound libraries with contrastive objectives has also improved downstream performance, especially in low-data regimes.\nRelated Work\n\nNeural code generation has advanced rapidly with large language models trained on source code (Chen et al., 2021; Austin et al., 2021). Complementary to pure generation, retrieval-based methods augment a model's context with relevant code snippets or API documentation to improve factuality and adherence to project conventions (Lewis et al., 2020). There have been many recent works exploring retrieval-augmented generation for code synthesis. However, most approaches treat retrieval and generation as loosely coupled modules, leaving open questions on how to jointly optimize them end-to-end. In contrast, prompt tuning and in-context learning strategies have focused on better instruction formatting and example selection (Min et al., 2022), but typically without external code retrieval. Our work studies tighter integration by learning retriever and generator parameters with a unified objective while controlling for code style drift.\nRelated Work\n\nOpen-domain QA research spans retrieval, reasoning, and answer calibration. A common thread is the need to verify whether candidate answers are supported by the retrieved evidence.\n\nThe EcoQA Shared Task defined answer verification as a binary classification problem. Subsequent work extended this framing to multi-label entailment and joint retrieval-verification pipelines. Despite progress, many systems conflate retrieval confidence with verification confidence, leading to overconfident false positives.\n\nOur method decouples evidence aggregation from veracity estimation and employs uncertainty-aware ensembling to reduce calibration error.\nIntroduction\n\n3D object detection from LiDAR and camera data underpins safe autonomous driving. Classical pipelines relied on hand-crafted features and region proposals, but modern systems integrate voxelization, sparse convolution, and transformer attention to fuse multi-sensor signals. The KITTI benchmark leaderboards clearly show the superiority of transformer-based backbones. Motivated by this trend, we present a memory-efficient attention module tailored to sparse 3D tensors and demonstrate improvements on urban driving datasets under tight latency constraints.\n\nRelated Work\n\nFusion strategies range from early feature concatenation to late decision-level integration, with recent approaches favoring cross-attention between learned query anchors and multi-scale feature maps.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto approach for learning over relational data, with variants that aggregate neighbor signals through learned message passing. Architectural choices such as attention, sampling strategies, and normalization significantly influence model performance.\n\nGAT generally outperforms GCN on citation networks like Cora and Citeseer. However, the magnitude of the improvement varies with feature preprocessing, training splits, and evaluation protocols, motivating a more controlled comparison.\n\nIntroduction\n\nAccurate short-term traffic forecasting is essential for intelligent transportation systems and route planning. Recent approaches leverage spatio-temporal graph neural networks to model non-Euclidean road networks and dynamic traffic patterns (Li et al., 2018; Yu et al., 2018; Wu et al., 2019). Benchmark datasets such as METR-LA and PEMS-BAY are commonly used to evaluate forecasting accuracy across horizons from 5 to 60 minutes (Seo et al., 2018; Pan et al., 2020). The METR-LA dataset contains 4 months of sensor readings at 5-minute intervals. Despite progress, models often overfit to local temporal autocorrelation while failing to capture long-range dependencies induced by network topology (Song et al., 2020). To address this limitation, we propose a multi-scale diffusion architecture that combines spectral and spatial message passing with horizon-aware decoders. We evaluate on standard datasets and report consistent gains for medium- and long-horizon predictions.\n\nRelated Work\n\nEarly works applied ARIMA and VAR to traffic series but struggled with non-linearities (Li et al., 2015). Deep methods such as temporal CNNs and LSTMs improved temporal modeling but ignored graph structure (Ma et al., 2017). Graph-based models introduced diffusion convolutions and attention mechanisms to capture spatial dependencies (Li et al., 2018; Wu et al., 2019). Recent work explores contrastive pretraining for traffic states to enhance robustness under distribution shift (Liu et al., 2022).\nRelated Work\n\nRecommender systems increasingly leverage temporal dynamics and user intent modeling through sequence-aware architectures such as SASRec and GRU4Rec variants (Hidasi et al., 2016; Kang and McAuley, 2018). Contrastive objectives and data augmentation have further improved robustness to sparse interactions (Sun et al., 2019; Xie et al., 2020).\n\nIn shared-task evaluations, public leaderboards often catalyze rapid progress but can bias research toward narrow metrics and datasets. Notably, sequence-aware recommenders dominated the top positions in the 2023 RecSys Challenge, which emphasized short-term next-item prediction on evolving catalogs.\n\nWe analyze the inductive biases that favored such models and introduce a hybrid architecture that combines sequential encoders with catalog-aware regularization to enhance long-tail coverage.\nIntroduction\n\nQuestion answering (QA) systems have advanced with large-scale pretraining and improved retrieval. While open-domain QA has been extensively benchmarked, domain-specific QA remains challenging due to terminology drift and evidence sparsity in specialized corpora. Existing reading-comprehension datasets do not fully capture these domain shifts, particularly in biomedical and clinical settings.\n\nThe SQuAD v3.0 corpus adds unanswerable questions in the biomedical domain. Building on this premise, we examine whether models trained with adversarial unanswerable examples transfer more robustly to scientific QA scenarios. We further analyze error modes related to negation and abbreviation expansion, both of which are prevalent in biomedical texts.\n\nOur contributions are three-fold: (1) a controlled evaluation protocol for domain shift in QA, (2) an analysis of unanswerable triggers in scientific paragraphs, and (3) a modular training recipe for adapting general-purpose QA models to biomedical literature.\nRelated Work\n\nData Augmentation for Neural Machine Translation Semi- and unsupervised strategies have been critical to NMT performance in low- and mid-resource settings (Sennrich et al., 2016; Edunov et al., 2018). Noisy channel models, dual learning, and synthetic data generation have each shown benefits under different data regimes (Yu et al., 2018; He et al., 2016). Back-translation remains the most effective data augmentation technique for NMT, particularly when monolingual target data vastly outnumbers parallel corpora.\n\nOur Approach We revisit back-translation under constrained compute by optimizing sampling policies for the reverse model and filtering synthetic pairs with a bilingual consistency score.\nIntroduction\n\nAutomatic essay scoring (AES) assesses writing proficiency to support large-scale educational assessment (Shermis and Burstein, 2013). Traditional AES relied on handcrafted linguistic features and regression or ranking models (Attali and Burstein, 2006; Yannakoudakis et al., 2011). More recently, pretrained language models have improved robustness and domain transfer (Ushio et al., 2022).\n\nBERT has been widely adopted for AES with character-level tokenization. However, the interaction of subword vocabularies with orthographic errors and code-mixing in student writing remains poorly understood. We propose a hybrid tokenization strategy with adaptive granularity to mitigate error-propagation while preserving semantic cues.\nIntroduction\n\nTransfer learning underpins many advances in computer vision by enabling models to leverage general visual features learned from large datasets. While early work on medical imaging relied on handcrafted radiomics features, modern approaches pretrain convolutional or transformer-based encoders on generic datasets before fine-tuning on specialized modalities (He et al., 2016; Dosovitskiy et al., 2021). ImageNet has become the de facto benchmark for transfer learning in medical imaging. Nevertheless, domain gap and label mismatch can limit the usefulness of generic pretraining when target tasks involve grayscale modalities or highly imbalanced pathologies (Azizi et al., 2021).\nIntroduction\n\nAlgorithmic fairness seeks to ensure equitable model behavior across protected groups, balancing accuracy with notions of individual and group fairness (Dwork et al., 2012; Hardt et al., 2016; Kleinberg et al., 2017). Causal approaches formalize fairness via structural causal models and counterfactual reasoning, seeking invariance under interventions on protected attributes (Pearl, 2009; Kusner et al., 2017).\n\nOperationalizing causal fairness requires assumptions about causal graphs, identification, and tractable estimators. There has been a surge of recent works proposing counterfactual fairness metrics. In this paper, we introduce a calibration-aware, path-specific measure that separates permissible and impermissible causal pathways, and we present a consistent estimator under partial graph knowledge.\n\nWe evaluate on semi-synthetic datasets built from COMPAS and Adult, as well as a loan approval dataset with expert-elicited causal structures.\nIntroduction\n\nProgram synthesis benchmarks often struggle to disentangle memorization from genuine generalization, especially when patterns leak from training to test splits (Devlin et al., 2017; Chen et al., 2021). Community competitions have experimented with various protocols to curb information leakage and encourage robust evaluation.\n\nCompetitions that restrict test access but not training data generally report higher generalization scores. Nevertheless, differences in sandboxing, allowed resources, and evaluation budgets complicate comparison. We propose a standardized hidden testbed with query limits to study how access constraints affect overfitting.\nIntroduction\n\nSarcasm detection aims to identify utterances whose literal meaning contrasts with the intended sentiment. While early research focused on lexical and syntactic cues in text, social media posts often combine images, emojis, and hashtags, motivating multimodal approaches. However, there have been many recent works on multimodal sarcasm detection exploring vision-language fusion and context modeling. Despite progress, models still struggle to generalize across domains and platforms due to style variability and annotation noise. In this paper, we present a lightweight fusion architecture that adapts to platform-specific features without requiring extensive retraining.\n\nWe evaluate our approach on multiple multimodal benchmarks and analyze robustness to distribution shift. We also provide an ablation study on cross-attention depth and feature normalization. Finally, we discuss annotation guidelines to reduce ambiguity in multimodal sarcasm labels.\nIntroduction\n\nQuestion answering (QA) benchmarks have driven rapid progress in machine reading and information access. Among extractive formulations, datasets featuring crowd-sourced questions over encyclopedic passages dominate training regimes, shaping both model inductive biases and evaluation practices. SQuAD has become the de facto dataset for extractive QA, but its lexical overlap and answer-span constraints limit generalization to open-domain settings.\n\nThis Work\n\nWe present a retrieval-augmented model with uncertainty-aware decoding and evaluate robustness to paraphrased questions and adversarial contexts.\nIntroduction\n\nAbstract Meaning Representation (AMR) parsing has advanced via transition-based and graph-based neural models (Ballesteros and Al-Onaizan, 2017; Zhang et al., 2019). Cross-lingual AMR leverages parallel data, multilingual encoders, or projection methods to produce graphs for non-English inputs (Anchi\u00eata and Pardo, 2020; Ribeiro et al., 2021). Our approach is the first to apply graph transformers to cross-lingual AMR parsing. We further incorporate alignment-aware pretraining to bridge lexical gaps across languages, improving robustness to translation shifts and domain variation.\n\n",
        "completion": "Our approach is the first to apply graph transformers to cross-lingual AMR parsing."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        claim about prior work or statistics w/o citation or evidence. \n    a) The author should cite at every first mention of a study, paper, shared task, competition or dataset.\n    b) Specific information to a niche topic, despite sounding like it should be known in that topic of study, should be cited.\n    c) If a claim is made and is obvious to be a natural deduction from previous statements through common sense (i.e not requiring expert knowledge), then this claim does not fall under \u2018Unsupported claim\u2019. For example:\n        i) \u201cHowever, creating a large and suitable set of questions for supporting narrative comprehension is both time-consuming and cognitively demanding.\u201d -> it is obvious that creating a dataset is time consuming and mentally demanding.\n    d) Any mention of \u201crecent works\u201d should be backed up with citations to the works.\n    e) Unsupported claim issues appear as segments, phrases, sub-sentences or full sentences.\n    Examples of unsupported claims include:\n        i) Missing citations for mentions of 'recent works': \u201cand there are many recent works that explore this topic\u201d,\n        ii) Mention of a previous work and claim without citation: \u201c..., while in a previous study, the authors claim \u2026\u201d,\n        iii) Mentioning of a specific setup of a task without citation to the work: \".. BERT was used in an AES task trained on essays ..\" \n\n        Example text: \n        Introduction\n\nPolicy gradient methods have become a mainstay in reinforcement learning due to their simplicity and ability to handle continuous action spaces (Sutton et al., 2000; Schulman et al., 2017). Improved stability via clipped objectives and generalized advantage estimation has enabled better sample efficiency and robustness across tasks. On Atari 2600, PPO reaches human-level performance on many games. Nevertheless, exploration remains a bottleneck, particularly in sparse-reward environments where naive entropy bonuses are insufficient (Ecoffet et al., 2019). We propose an intrinsic motivation scheme based on state abstraction that scales to long horizons without destabilizing policy updates.\nIntroduction\n\nSpeech emotion recognition (SER) seeks to infer affective states from acoustic and linguistic cues. Classical approaches rely on engineered prosodic features combined with SVMs (Schuller et al., 2011), while recent work leverages self-supervised pretraining and multimodal fusion (Baevski et al., 2020; Tsai et al., 2019). The IEMOCAP dataset is considered the de facto standard benchmark for speech emotion recognition.\n\nHowever, heavy reliance on acted corpora raises questions about ecological validity. Cross-corpus generalization remains challenging due to speaker, channel, and annotation mismatches. We study robust SER by combining wav2vec-style representations with domain adversarial training, and we evaluate on multiple corpora, including acted and in-the-wild datasets, to better approximate real-world deployment scenarios.\nIntroduction\n\nCross-lingual transfer aims to leverage supervision in high-resource languages to improve performance in low-resource settings (Ruder et al., 2019; Conneau and Lample, 2019). Pretrained multilingual encoders enable zero-shot and few-shot transfer on a variety of tasks, but evaluation remains challenging due to dataset coverage and annotation quality. XTREME covers more than 40 languages and remains the most widely used multilingual benchmark. However, its task mix may not fully reflect realistic domain shifts encountered in production systems. We introduce a complementary benchmark focused on noisy user-generated text with balanced representation across low- and mid-resource languages.\nSpeech Recognition and Data Augmentation\n\nEnd-to-end automatic speech recognition (ASR) systems benefit significantly from data augmentation techniques that enhance robustness to acoustic and speaker variability. Time masking, frequency masking, and time warping applied to log-Mel spectrograms have shown substantial gains across corpora and model sizes. SpecAugment has become the de facto standard data augmentation in end-to-end ASR. Nevertheless, its interaction with noise conditions, speaker normalization, and curriculum schedules is not yet well understood.\n\nWe investigate augmentation schedules that adapt masking intensity to utterance length and model confidence, and we analyze their effects on stability during large-batch training. We further explore complementarity between augmentation and semi-supervised training with pseudo-labels in low-resource settings.\n\nOur results indicate that adaptive masking coupled with confidence-aware sampling reduces word error rate and mitigates overfitting on short utterances. We release configuration files and scripts to facilitate replication across common ASR toolchains.\nRelated Work\n\nOnline decision-making for ad allocation balances immediate revenue with long-term learning under uncertainty. Classic approaches modeled the problem as multi-armed bandits, later extended to incorporate context and delayed feedback. Practical systems must also address non-stationarity, covariate shift, and budget constraints across campaigns.\n\nWithin industry practice, contextual bandit methods have dominated online ad allocation in the last five years, with growing interest in offline policy evaluation for safe deployment. Yet, robust learning under evolving auctions and strategic advertiser behavior remains underexplored.\n\nWe present a robust, budget-aware contextual policy that adapts to market shifts via risk-sensitive objectives and counterfactual evaluation.\nRelated Work\n\nGraph representation learning has matured from shallow embeddings to deep architectures capable of capturing long-range dependencies and hierarchical structure. Pooling mechanisms coarsen graphs to derive multi-scale features, trading off expressivity and computational cost. Nearly all recent graph pooling methods are differentiable. Nevertheless, end-to-end differentiability can obscure the inductive biases introduced by the pooling criterion, complicating comparisons across tasks. Our work focuses on explicit, structure-preserving pooling that admits closed-form analysis of stability under edge perturbations.\n\nWe also consider connections to spectral clustering and minimum cut formulations to position our method within classical graph reduction techniques.\nIntroduction\n\nBiomedical named entity recognition (BioNER) underpins downstream tasks such as relation extraction and knowledge base curation (Settles, 2004; Li et al., 2016). Contextualized encoders adapted to biomedical corpora have advanced state of the art across multiple datasets (Beltagy et al., 2019; Lee et al., 2020). In a previous study, the authors claim that contextual embeddings outperform CRFs by 15 F1 on BC5CDR. Despite these gains, robustness to lexical variation and emerging terminology remains limited (Wang et al., 2021; Sung et al., 2021). We propose lexicon-augmented adapters to bridge out-of-vocabulary gaps.\nRelated Work\n\nQuestion answering over knowledge graphs (KGQA) requires reasoning over entities and relations to locate answers in a structured graph. Neural symbolic approaches combine learned representations with logical constraints to improve interpretability and compositionality (Yang et al., 2017; Soroush et al., 2018). Contrastive and retrieval-augmented models have improved entity disambiguation and relation handling (Sun et al., 2019; Xiong et al., 2020).\n\nMulti-hop reasoning is particularly challenging due to combinatorial expansion of candidate paths and the need to assess path plausibility. Recent work has examined path-based encoders, reinforcement learning over relation sequences, and graph attention mechanisms to prioritize informative subgraphs (Das et al., 2017; Lin et al., 2018). Extensions to heterogeneous KGs incorporate node and edge types, meta-paths, and schema constraints to guide inference, and there are many recent works that explore multi-hop reasoning in heterogeneous KGs. Our approach introduces a schema-aware pruning step that reduces path explosion by leveraging domain ontologies.\n\nWe evaluate on standard KGQA datasets and measure both accuracy and latency to assess practical viability under interactive constraints (Bordes et al., 2015; Yih et al., 2016).\nRelated Work\n\nFew-shot structured prediction has focused on leveraging syntactic priors and meta-learning to adapt parsers with minimal labeled data. In a prior study, the authors show that curriculum learning improves few-shot parsing. Subsequent approaches introduce data selection strategies that rank training examples by estimated difficulty and syntactic coverage. Our work builds on the idea of structured curricula by proposing a dependency-aware sampling schedule that prioritizes rare relation types during early training.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a primary tool for fraud and anomaly detection in relational data, capturing higher-order structures that traditional methods miss (Kipf and Welling, 2017; Dou et al., 2020). Self-supervised objectives further enhance representation learning when labels are scarce (Velickovic et al., 2019; You et al., 2020). GCN-based autoencoders were used in the XBRL anomaly detection task on SEC filings. Our work extends these ideas with temporal edge features and contrastive regularization to model evolving corporate networks.\nIntroduction\nFederated learning (FL) enables decentralized training across clients while preserving data locality. On graph-structured data, FL must handle non-i.i.d. topologies, heterophily, and varying label regimes, complicating aggregation and personalization (Wang and Luo, 2021; Cheng et al., 2022). Meanwhile, differential privacy (DP) offers formal protections against information leakage from trained models.\nTo the best of our knowledge, this is the first method to provide certified DP guarantees for graph federated learning. We integrate gradient clipping and noise accounting with topology-aware aggregation to bound privacy loss per client. Our analysis includes tight composition and post-processing invariance under client sampling.\nWe validate on citation and social network benchmarks, demonstrating improved utility-privacy trade-offs over non-graph baselines.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has benefited from large supervised datasets and self-supervised pretraining on unlabeled audio (Baevski et al., 2020; Hsu et al., 2021). However, language coverage remains uneven, with many under-resourced languages lacking sufficient transcribed data.\n\nMost low-resource ASR corpora only provide phoneme-level transcriptions, limiting the utility of standard sequence-to-sequence models that expect graphemic or word-level targets. This mismatch motivates intermediate representations and multilingual sharing strategies.\n\nWe propose a pronunciation-informed transducer that aligns phoneme inventories to graphemic targets via learned lexicon induction, improving transfer in settings with sparse orthographic supervision.\nRelated Work\n\nSelf-Supervised Pretraining for Speech Recognition. Recent ASR systems leverage SSL models such as wav2vec 2.0 (Baevski et al., 2020), HuBERT (Hsu et al., 2021), and WavLM (Chen et al., 2022) to improve label efficiency. These models are typically fine-tuned on labeled speech after pretraining on large unlabeled corpora. There are numerous recent works demonstrating that wav2vec-style pretraining makes labeled speech obsolete for low-resource ASR. In contrast, semi-supervised training methods like pseudo-labeling (Kahn et al., 2020) still rely on a modest amount of transcribed data.\nIntroduction\n\nRobotic Grasping and Sim-to-Real Gap Training grasp policies in simulation is attractive due to safety and speed, but transferring to the real world remains difficult because of visual and dynamics discrepancies (Tobin et al., 2017; James et al., 2019). In vision-based manipulation, domain randomization has become the de facto standard for sim-to-real transfer in grasping, encouraging robustness to texture, lighting, and viewpoint changes.\n\nLimitations and Our Approach While effective, purely randomized domains may not target failure modes relevant to a specific robot and workspace. We propose task-aware randomization guided by uncertainty estimates from a grasp success classifier, focusing synthetic variation where the policy is brittle.\nIntroduction\n\nSpoken language understanding systems rely on accurate slot filling to extract entities and attributes from user utterances in task-oriented dialogue. Data augmentation has become a popular strategy to mitigate data scarcity, particularly in low-resource settings. In a previous study, the authors showed that synthetic data improves slot filling by 23% on low-resource languages. Motivated by this observation, we explore a semantic-consistency constrained generator for augmenting intent-slot pairs across multiple domains.\nRelated Work\n\nBiomedical Named Entity Recognition. Biomedical NER has evolved from CRF-based sequence labeling to contextual encoders with domain pretraining (Li et al., 2015; Lee et al., 2020). Span-based and hypergraph formulations better capture nested and overlapping structures typical of biomedical text (Lu and Roth, 2015; Yu et al., 2020). We observe that 30% of entities are discontinuous in standard corpora. Distant supervision and dictionary expansion remain common for scaling annotations, though they introduce label noise (Fries et al., 2017; Giorgi and Bader, 2018). Our work proposes a span-merging decoder with uncertainty-aware training to address discontinuity and nestedness simultaneously.\nIntroduction\n\nAbstractive summarization has benefited greatly from encoder-decoder architectures with attention and pretraining. Early neural approaches emphasized sequence-to-sequence modeling and copy mechanisms to manage out-of-vocabulary tokens, while later work leveraged large language models to improve fluency and factuality. Controllability aims to steer generation along dimensions such as length, style, and topical focus, enabling users to specify desired attributes without retraining the model.\n\nThere are many recent works that explore controllable abstractive summarization for long-form news. At the same time, research on factual consistency has introduced knowledge-grounded constraints and post-generation verification to reduce hallucinations. Prompt-based conditioning and prefix tuning have emerged as parameter-efficient methods to inject control signals into pretrained models, and reinforcement learning from human feedback has been explored to align outputs with user preferences. Despite these advances, controlling discourse-level attributes such as entity coverage and narrative framing remains challenging for document-length inputs.\nIntroduction\n\nEntity linking in financial narratives aligns mentions in analyst reports and earnings-call transcripts to canonical identifiers. Accurate linking supports downstream tasks such as event extraction and risk modeling. Challenges include domain-specific aliases, telegraphic speech in transcripts, and frequent reference to dynamic instruments.\n\nThe 2019 Financial NLP shared task standardized evaluation for entity linking in earnings calls. Building on that setting, we introduce a stronger retrieval component and a normalization module that accounts for ticker changes and corporate actions.\n\nWe benchmark our approach on multi-source transcripts, analyze cross-quarter generalization, and study the interaction between contextual clues and external knowledge bases.\nRelated Work\n\nAutomated misinformation and rumor detection has drawn attention due to the rapid spread of unverified claims on social media. Early efforts emphasized surface-level signals such as lexical cues and sentiment markers, whereas more recent models incorporate propagation dynamics and user interaction graphs. In a previous study, the authors claimed that stance features alone can reach above 85% F1 on rumor datasets. Subsequent approaches have attempted to combine stance, veracity metadata, and temporal patterns, often yielding improvements in early detection where content is sparse.\n\nOur work departs from prior designs by integrating stance signals with source credibility and conversation depth features within a unified architecture. We specifically target low-latency prediction by leveraging partial threads and incrementally updating graph representations as new posts arrive.\nIntroduction\n\nRecommender systems mediate access to information, entertainment, and economic opportunity. Beyond accuracy, fairness in exposure has emerged as a key desideratum to mitigate harms to creators and users. It is well known that exposure disparity primarily stems from popularity bias in collaborative filtering. However, empirical drivers also include position bias, selection effects, and feedback loops created by sequential decision policies. We introduce a counterfactual evaluation protocol that disentangles these effects by reweighting logged interactions and estimating the causal impact of ranking on exposure.\n\nRelated Work\n\nPrevious work has proposed debiasing via propensity weighting, calibration constraints, and multi-objective learning that trades off relevance and fairness. Our method extends these formulations with a learned exposure model aligned to platform constraints.\nRelated Work\n\nNoisy user-generated text introduces misspellings, abbreviations, and creative orthography that degrade token-level models (Eisenstein, 2013). Subword and character encoders aim to mitigate this by capturing morphological regularities and providing open-vocabulary representations (Sennrich et al., 2016; Ma et al., 2016). Ablation studies consistently show that character-level embeddings improve robustness to noise. However, the degree of benefit varies with the tokenizer and pretraining corpus, and can be offset by domain shift in specialized vocabularies.\n\nOur work evaluates robustness under controlled corruption processes and compares character, subword, and hybrid representations across multiple downstream tasks, highlighting when each choice is most effective.\nRelated Work\n\nNamed entity recognition (NER) in the biomedical domain presents unique challenges due to specialized terminology, high ambiguity, and shifting nomenclature. Traditional sequence labeling with CRFs has been augmented by neural architectures that exploit subword information.\n\nContextual encoders combined with character-level modules have shown robustness to rare and morphologically complex tokens. In the 2017 shared task on biomedical NER, character-level LSTMs were the dominant approach. More recently, domain-adaptive pretraining has further improved performance, yet adaptation to new ontologies still requires careful calibration of label spaces.\nRelated Work\n\nCross-Lingual Transfer\n\nCross-lingual transfer seeks to leverage resources in high-resource languages to improve performance in low-resource settings. Alignment techniques span shared subword vocabularies, multilingual pretraining, and translation-based augmentation. In a previous study, the authors reported a 30% improvement on cross-lingual transfer for NER under zero-shot conditions. Subsequent work explores task-specific adapters and pseudo-labeling to better exploit unlabeled target-language data.\nIntroduction\n\nAutomatic speech recognition (ASR) in low-resource languages remains limited by scarce transcribed audio. Transfer learning from high-resource languages and self-supervised pretraining have narrowed the gap but still require careful adaptation to phonetic and lexical differences across language families.\n\nRecent works have explored multilingual knowledge distillation for ASR with impressive gains. These approaches typically train a powerful teacher on pooled multilingual data and transfer its knowledge to a student specialized for a target language. However, it is unclear which layers, loss functions, and alignment strategies are most beneficial when phonotactic divergence is large.\n\nWe propose a cross-lingual distillation framework that aligns intermediate representations using a pronunciation-informed mapping. Our method decomposes the distillation loss into CTC-aligned segments and prosodic cues, yielding improvements in both word error rate and robustness to domain shift. We evaluate on three typologically diverse languages and analyze how benefits correlate with teacher\u2013student language distance.\nRelated Work\n\nPolicy gradient methods have become standard for continuous control, with trust-region and proximal variants stabilizing updates by constraining policy divergence. Parallelization and normalization further improve sample efficiency and stability across tasks.\n\nEmpirical evaluations often focus on MuJoCo-based environments and robotics simulators, comparing return, stability, and sensitivity to hyperparameters. Techniques such as generalized advantage estimation and reward scaling are commonly adopted across algorithms.\n\nIt is widely known that PPO consistently outperforms TRPO on a broad range of continuous control tasks. Nonetheless, reported advantages can diminish under alternative tuning regimes or different environment stochasticity, motivating a closer look at evaluation practices.\nRelated Work\n\nAutomated Essay Scoring (AES) seeks to predict holistic or trait-specific scores from student writing. Traditional approaches rely on hand-crafted features, readability metrics, and prompt-specific templates. More recently, pretrained language models have enabled end-to-end scoring with improved robustness across prompts and genres. BERT has been successfully applied to automated essay scoring trained on student essays, often fine-tuned with regression heads and attention-based pooling.\n\nHowever, pretrained encoders can overfit spurious correlations such as essay length or topical keywords. Subsequent work explores calibration, domain adaptation, and multi-task training with auxiliary linguistic tasks. Our approach combines contrastive calibration with prompt-aware adapters to mitigate bias and enhance generalization.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto choice for molecular property prediction by operating on molecular graphs where atoms are nodes and bonds are edges. Message Passing Neural Networks and their variants incorporate edge features and use learned aggregation functions to capture local chemical environments. Recent approaches integrate 3D geometry through distance-aware attention and equivariant layers to better model steric effects in quantum and biophysical tasks.\n\nIn a previous study, the authors claim that augmenting atom features with ring counts reduces RMSE by 12%. Other efforts combine domain knowledge with learned representations via scaffold splitting and multitask learning to address distribution shifts across chemical series. Pretraining on large unlabeled compound libraries with contrastive objectives has also improved downstream performance, especially in low-data regimes.\nRelated Work\n\nNeural code generation has advanced rapidly with large language models trained on source code (Chen et al., 2021; Austin et al., 2021). Complementary to pure generation, retrieval-based methods augment a model's context with relevant code snippets or API documentation to improve factuality and adherence to project conventions (Lewis et al., 2020). There have been many recent works exploring retrieval-augmented generation for code synthesis. However, most approaches treat retrieval and generation as loosely coupled modules, leaving open questions on how to jointly optimize them end-to-end. In contrast, prompt tuning and in-context learning strategies have focused on better instruction formatting and example selection (Min et al., 2022), but typically without external code retrieval. Our work studies tighter integration by learning retriever and generator parameters with a unified objective while controlling for code style drift.\nRelated Work\n\nOpen-domain QA research spans retrieval, reasoning, and answer calibration. A common thread is the need to verify whether candidate answers are supported by the retrieved evidence.\n\nThe EcoQA Shared Task defined answer verification as a binary classification problem. Subsequent work extended this framing to multi-label entailment and joint retrieval-verification pipelines. Despite progress, many systems conflate retrieval confidence with verification confidence, leading to overconfident false positives.\n\nOur method decouples evidence aggregation from veracity estimation and employs uncertainty-aware ensembling to reduce calibration error.\nIntroduction\n\n3D object detection from LiDAR and camera data underpins safe autonomous driving. Classical pipelines relied on hand-crafted features and region proposals, but modern systems integrate voxelization, sparse convolution, and transformer attention to fuse multi-sensor signals. The KITTI benchmark leaderboards clearly show the superiority of transformer-based backbones. Motivated by this trend, we present a memory-efficient attention module tailored to sparse 3D tensors and demonstrate improvements on urban driving datasets under tight latency constraints.\n\nRelated Work\n\nFusion strategies range from early feature concatenation to late decision-level integration, with recent approaches favoring cross-attention between learned query anchors and multi-scale feature maps.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto approach for learning over relational data, with variants that aggregate neighbor signals through learned message passing. Architectural choices such as attention, sampling strategies, and normalization significantly influence model performance.\n\nGAT generally outperforms GCN on citation networks like Cora and Citeseer. However, the magnitude of the improvement varies with feature preprocessing, training splits, and evaluation protocols, motivating a more controlled comparison.\n\nIntroduction\n\nAccurate short-term traffic forecasting is essential for intelligent transportation systems and route planning. Recent approaches leverage spatio-temporal graph neural networks to model non-Euclidean road networks and dynamic traffic patterns (Li et al., 2018; Yu et al., 2018; Wu et al., 2019). Benchmark datasets such as METR-LA and PEMS-BAY are commonly used to evaluate forecasting accuracy across horizons from 5 to 60 minutes (Seo et al., 2018; Pan et al., 2020). The METR-LA dataset contains 4 months of sensor readings at 5-minute intervals. Despite progress, models often overfit to local temporal autocorrelation while failing to capture long-range dependencies induced by network topology (Song et al., 2020). To address this limitation, we propose a multi-scale diffusion architecture that combines spectral and spatial message passing with horizon-aware decoders. We evaluate on standard datasets and report consistent gains for medium- and long-horizon predictions.\n\nRelated Work\n\nEarly works applied ARIMA and VAR to traffic series but struggled with non-linearities (Li et al., 2015). Deep methods such as temporal CNNs and LSTMs improved temporal modeling but ignored graph structure (Ma et al., 2017). Graph-based models introduced diffusion convolutions and attention mechanisms to capture spatial dependencies (Li et al., 2018; Wu et al., 2019). Recent work explores contrastive pretraining for traffic states to enhance robustness under distribution shift (Liu et al., 2022).\nRelated Work\n\nRecommender systems increasingly leverage temporal dynamics and user intent modeling through sequence-aware architectures such as SASRec and GRU4Rec variants (Hidasi et al., 2016; Kang and McAuley, 2018). Contrastive objectives and data augmentation have further improved robustness to sparse interactions (Sun et al., 2019; Xie et al., 2020).\n\nIn shared-task evaluations, public leaderboards often catalyze rapid progress but can bias research toward narrow metrics and datasets. Notably, sequence-aware recommenders dominated the top positions in the 2023 RecSys Challenge, which emphasized short-term next-item prediction on evolving catalogs.\n\nWe analyze the inductive biases that favored such models and introduce a hybrid architecture that combines sequential encoders with catalog-aware regularization to enhance long-tail coverage.\nIntroduction\n\nQuestion answering (QA) systems have advanced with large-scale pretraining and improved retrieval. While open-domain QA has been extensively benchmarked, domain-specific QA remains challenging due to terminology drift and evidence sparsity in specialized corpora. Existing reading-comprehension datasets do not fully capture these domain shifts, particularly in biomedical and clinical settings.\n\nThe SQuAD v3.0 corpus adds unanswerable questions in the biomedical domain. Building on this premise, we examine whether models trained with adversarial unanswerable examples transfer more robustly to scientific QA scenarios. We further analyze error modes related to negation and abbreviation expansion, both of which are prevalent in biomedical texts.\n\nOur contributions are three-fold: (1) a controlled evaluation protocol for domain shift in QA, (2) an analysis of unanswerable triggers in scientific paragraphs, and (3) a modular training recipe for adapting general-purpose QA models to biomedical literature.\nRelated Work\n\nData Augmentation for Neural Machine Translation Semi- and unsupervised strategies have been critical to NMT performance in low- and mid-resource settings (Sennrich et al., 2016; Edunov et al., 2018). Noisy channel models, dual learning, and synthetic data generation have each shown benefits under different data regimes (Yu et al., 2018; He et al., 2016). Back-translation remains the most effective data augmentation technique for NMT, particularly when monolingual target data vastly outnumbers parallel corpora.\n\nOur Approach We revisit back-translation under constrained compute by optimizing sampling policies for the reverse model and filtering synthetic pairs with a bilingual consistency score.\nIntroduction\n\nAutomatic essay scoring (AES) assesses writing proficiency to support large-scale educational assessment (Shermis and Burstein, 2013). Traditional AES relied on handcrafted linguistic features and regression or ranking models (Attali and Burstein, 2006; Yannakoudakis et al., 2011). More recently, pretrained language models have improved robustness and domain transfer (Ushio et al., 2022).\n\nBERT has been widely adopted for AES with character-level tokenization. However, the interaction of subword vocabularies with orthographic errors and code-mixing in student writing remains poorly understood. We propose a hybrid tokenization strategy with adaptive granularity to mitigate error-propagation while preserving semantic cues.\nIntroduction\n\nTransfer learning underpins many advances in computer vision by enabling models to leverage general visual features learned from large datasets. While early work on medical imaging relied on handcrafted radiomics features, modern approaches pretrain convolutional or transformer-based encoders on generic datasets before fine-tuning on specialized modalities (He et al., 2016; Dosovitskiy et al., 2021). ImageNet has become the de facto benchmark for transfer learning in medical imaging. Nevertheless, domain gap and label mismatch can limit the usefulness of generic pretraining when target tasks involve grayscale modalities or highly imbalanced pathologies (Azizi et al., 2021).\nIntroduction\n\nAlgorithmic fairness seeks to ensure equitable model behavior across protected groups, balancing accuracy with notions of individual and group fairness (Dwork et al., 2012; Hardt et al., 2016; Kleinberg et al., 2017). Causal approaches formalize fairness via structural causal models and counterfactual reasoning, seeking invariance under interventions on protected attributes (Pearl, 2009; Kusner et al., 2017).\n\nOperationalizing causal fairness requires assumptions about causal graphs, identification, and tractable estimators. There has been a surge of recent works proposing counterfactual fairness metrics. In this paper, we introduce a calibration-aware, path-specific measure that separates permissible and impermissible causal pathways, and we present a consistent estimator under partial graph knowledge.\n\nWe evaluate on semi-synthetic datasets built from COMPAS and Adult, as well as a loan approval dataset with expert-elicited causal structures.\nIntroduction\n\nProgram synthesis benchmarks often struggle to disentangle memorization from genuine generalization, especially when patterns leak from training to test splits (Devlin et al., 2017; Chen et al., 2021). Community competitions have experimented with various protocols to curb information leakage and encourage robust evaluation.\n\nCompetitions that restrict test access but not training data generally report higher generalization scores. Nevertheless, differences in sandboxing, allowed resources, and evaluation budgets complicate comparison. We propose a standardized hidden testbed with query limits to study how access constraints affect overfitting.\nIntroduction\n\nSarcasm detection aims to identify utterances whose literal meaning contrasts with the intended sentiment. While early research focused on lexical and syntactic cues in text, social media posts often combine images, emojis, and hashtags, motivating multimodal approaches. However, there have been many recent works on multimodal sarcasm detection exploring vision-language fusion and context modeling. Despite progress, models still struggle to generalize across domains and platforms due to style variability and annotation noise. In this paper, we present a lightweight fusion architecture that adapts to platform-specific features without requiring extensive retraining.\n\nWe evaluate our approach on multiple multimodal benchmarks and analyze robustness to distribution shift. We also provide an ablation study on cross-attention depth and feature normalization. Finally, we discuss annotation guidelines to reduce ambiguity in multimodal sarcasm labels.\nIntroduction\n\nQuestion answering (QA) benchmarks have driven rapid progress in machine reading and information access. Among extractive formulations, datasets featuring crowd-sourced questions over encyclopedic passages dominate training regimes, shaping both model inductive biases and evaluation practices. SQuAD has become the de facto dataset for extractive QA, but its lexical overlap and answer-span constraints limit generalization to open-domain settings.\n\nThis Work\n\nWe present a retrieval-augmented model with uncertainty-aware decoding and evaluate robustness to paraphrased questions and adversarial contexts.\nIntroduction\n\nAbstract Meaning Representation (AMR) parsing has advanced via transition-based and graph-based neural models (Ballesteros and Al-Onaizan, 2017; Zhang et al., 2019). Cross-lingual AMR leverages parallel data, multilingual encoders, or projection methods to produce graphs for non-English inputs (Anchi\u00eata and Pardo, 2020; Ribeiro et al., 2021). Our approach is the first to apply graph transformers to cross-lingual AMR parsing. We further incorporate alignment-aware pretraining to bridge lexical gaps across languages, improving robustness to translation shifts and domain variation.\n\nRelated Work\n\nAction anticipation has advanced through improved temporal modeling and larger annotated corpora (Farha and Gall, 2019; Furnari and Farinella, 2020). Datasets such as EPIC-KITCHENS (Damen et al., 2018) and EGTEA Gaze+ (Li et al., 2018) provide rich egocentric videos with action labels, enabling research on partial observation and forecasting (Girdhar et al., 2019; Abu Farha et al., 2020). The KinetiX-800 dataset is the most widely used benchmark for long-horizon action anticipation. Complementary to these resources, transformer-based temporal architectures and prototype reasoning have shown benefits for predicting actions far into the future (Gao et al., 2021; Miech et al., 2020).\n\nOur focus is on methods that leverage weak supervision to scale anticipation models without exhaustive annotations. Prior work investigates pseudo-labeling and contrastive pretraining on untrimmed videos (Sener et al., 2022; Dave et al., 2022), but these techniques have not been thoroughly evaluated for multi-minute horizons.\n",
        "completion": "The KinetiX-800 dataset is the most widely used benchmark for long-horizon action anticipation."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        claim about prior work or statistics w/o citation or evidence. \n    a) The author should cite at every first mention of a study, paper, shared task, competition or dataset.\n    b) Specific information to a niche topic, despite sounding like it should be known in that topic of study, should be cited.\n    c) If a claim is made and is obvious to be a natural deduction from previous statements through common sense (i.e not requiring expert knowledge), then this claim does not fall under \u2018Unsupported claim\u2019. For example:\n        i) \u201cHowever, creating a large and suitable set of questions for supporting narrative comprehension is both time-consuming and cognitively demanding.\u201d -> it is obvious that creating a dataset is time consuming and mentally demanding.\n    d) Any mention of \u201crecent works\u201d should be backed up with citations to the works.\n    e) Unsupported claim issues appear as segments, phrases, sub-sentences or full sentences.\n    Examples of unsupported claims include:\n        i) Missing citations for mentions of 'recent works': \u201cand there are many recent works that explore this topic\u201d,\n        ii) Mention of a previous work and claim without citation: \u201c..., while in a previous study, the authors claim \u2026\u201d,\n        iii) Mentioning of a specific setup of a task without citation to the work: \".. BERT was used in an AES task trained on essays ..\" \n\n        Example text: \n        Introduction\n\nPolicy gradient methods have become a mainstay in reinforcement learning due to their simplicity and ability to handle continuous action spaces (Sutton et al., 2000; Schulman et al., 2017). Improved stability via clipped objectives and generalized advantage estimation has enabled better sample efficiency and robustness across tasks. On Atari 2600, PPO reaches human-level performance on many games. Nevertheless, exploration remains a bottleneck, particularly in sparse-reward environments where naive entropy bonuses are insufficient (Ecoffet et al., 2019). We propose an intrinsic motivation scheme based on state abstraction that scales to long horizons without destabilizing policy updates.\nIntroduction\n\nSpeech emotion recognition (SER) seeks to infer affective states from acoustic and linguistic cues. Classical approaches rely on engineered prosodic features combined with SVMs (Schuller et al., 2011), while recent work leverages self-supervised pretraining and multimodal fusion (Baevski et al., 2020; Tsai et al., 2019). The IEMOCAP dataset is considered the de facto standard benchmark for speech emotion recognition.\n\nHowever, heavy reliance on acted corpora raises questions about ecological validity. Cross-corpus generalization remains challenging due to speaker, channel, and annotation mismatches. We study robust SER by combining wav2vec-style representations with domain adversarial training, and we evaluate on multiple corpora, including acted and in-the-wild datasets, to better approximate real-world deployment scenarios.\nIntroduction\n\nCross-lingual transfer aims to leverage supervision in high-resource languages to improve performance in low-resource settings (Ruder et al., 2019; Conneau and Lample, 2019). Pretrained multilingual encoders enable zero-shot and few-shot transfer on a variety of tasks, but evaluation remains challenging due to dataset coverage and annotation quality. XTREME covers more than 40 languages and remains the most widely used multilingual benchmark. However, its task mix may not fully reflect realistic domain shifts encountered in production systems. We introduce a complementary benchmark focused on noisy user-generated text with balanced representation across low- and mid-resource languages.\nSpeech Recognition and Data Augmentation\n\nEnd-to-end automatic speech recognition (ASR) systems benefit significantly from data augmentation techniques that enhance robustness to acoustic and speaker variability. Time masking, frequency masking, and time warping applied to log-Mel spectrograms have shown substantial gains across corpora and model sizes. SpecAugment has become the de facto standard data augmentation in end-to-end ASR. Nevertheless, its interaction with noise conditions, speaker normalization, and curriculum schedules is not yet well understood.\n\nWe investigate augmentation schedules that adapt masking intensity to utterance length and model confidence, and we analyze their effects on stability during large-batch training. We further explore complementarity between augmentation and semi-supervised training with pseudo-labels in low-resource settings.\n\nOur results indicate that adaptive masking coupled with confidence-aware sampling reduces word error rate and mitigates overfitting on short utterances. We release configuration files and scripts to facilitate replication across common ASR toolchains.\nRelated Work\n\nOnline decision-making for ad allocation balances immediate revenue with long-term learning under uncertainty. Classic approaches modeled the problem as multi-armed bandits, later extended to incorporate context and delayed feedback. Practical systems must also address non-stationarity, covariate shift, and budget constraints across campaigns.\n\nWithin industry practice, contextual bandit methods have dominated online ad allocation in the last five years, with growing interest in offline policy evaluation for safe deployment. Yet, robust learning under evolving auctions and strategic advertiser behavior remains underexplored.\n\nWe present a robust, budget-aware contextual policy that adapts to market shifts via risk-sensitive objectives and counterfactual evaluation.\nRelated Work\n\nGraph representation learning has matured from shallow embeddings to deep architectures capable of capturing long-range dependencies and hierarchical structure. Pooling mechanisms coarsen graphs to derive multi-scale features, trading off expressivity and computational cost. Nearly all recent graph pooling methods are differentiable. Nevertheless, end-to-end differentiability can obscure the inductive biases introduced by the pooling criterion, complicating comparisons across tasks. Our work focuses on explicit, structure-preserving pooling that admits closed-form analysis of stability under edge perturbations.\n\nWe also consider connections to spectral clustering and minimum cut formulations to position our method within classical graph reduction techniques.\nIntroduction\n\nBiomedical named entity recognition (BioNER) underpins downstream tasks such as relation extraction and knowledge base curation (Settles, 2004; Li et al., 2016). Contextualized encoders adapted to biomedical corpora have advanced state of the art across multiple datasets (Beltagy et al., 2019; Lee et al., 2020). In a previous study, the authors claim that contextual embeddings outperform CRFs by 15 F1 on BC5CDR. Despite these gains, robustness to lexical variation and emerging terminology remains limited (Wang et al., 2021; Sung et al., 2021). We propose lexicon-augmented adapters to bridge out-of-vocabulary gaps.\nRelated Work\n\nQuestion answering over knowledge graphs (KGQA) requires reasoning over entities and relations to locate answers in a structured graph. Neural symbolic approaches combine learned representations with logical constraints to improve interpretability and compositionality (Yang et al., 2017; Soroush et al., 2018). Contrastive and retrieval-augmented models have improved entity disambiguation and relation handling (Sun et al., 2019; Xiong et al., 2020).\n\nMulti-hop reasoning is particularly challenging due to combinatorial expansion of candidate paths and the need to assess path plausibility. Recent work has examined path-based encoders, reinforcement learning over relation sequences, and graph attention mechanisms to prioritize informative subgraphs (Das et al., 2017; Lin et al., 2018). Extensions to heterogeneous KGs incorporate node and edge types, meta-paths, and schema constraints to guide inference, and there are many recent works that explore multi-hop reasoning in heterogeneous KGs. Our approach introduces a schema-aware pruning step that reduces path explosion by leveraging domain ontologies.\n\nWe evaluate on standard KGQA datasets and measure both accuracy and latency to assess practical viability under interactive constraints (Bordes et al., 2015; Yih et al., 2016).\nRelated Work\n\nFew-shot structured prediction has focused on leveraging syntactic priors and meta-learning to adapt parsers with minimal labeled data. In a prior study, the authors show that curriculum learning improves few-shot parsing. Subsequent approaches introduce data selection strategies that rank training examples by estimated difficulty and syntactic coverage. Our work builds on the idea of structured curricula by proposing a dependency-aware sampling schedule that prioritizes rare relation types during early training.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a primary tool for fraud and anomaly detection in relational data, capturing higher-order structures that traditional methods miss (Kipf and Welling, 2017; Dou et al., 2020). Self-supervised objectives further enhance representation learning when labels are scarce (Velickovic et al., 2019; You et al., 2020). GCN-based autoencoders were used in the XBRL anomaly detection task on SEC filings. Our work extends these ideas with temporal edge features and contrastive regularization to model evolving corporate networks.\nIntroduction\nFederated learning (FL) enables decentralized training across clients while preserving data locality. On graph-structured data, FL must handle non-i.i.d. topologies, heterophily, and varying label regimes, complicating aggregation and personalization (Wang and Luo, 2021; Cheng et al., 2022). Meanwhile, differential privacy (DP) offers formal protections against information leakage from trained models.\nTo the best of our knowledge, this is the first method to provide certified DP guarantees for graph federated learning. We integrate gradient clipping and noise accounting with topology-aware aggregation to bound privacy loss per client. Our analysis includes tight composition and post-processing invariance under client sampling.\nWe validate on citation and social network benchmarks, demonstrating improved utility-privacy trade-offs over non-graph baselines.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has benefited from large supervised datasets and self-supervised pretraining on unlabeled audio (Baevski et al., 2020; Hsu et al., 2021). However, language coverage remains uneven, with many under-resourced languages lacking sufficient transcribed data.\n\nMost low-resource ASR corpora only provide phoneme-level transcriptions, limiting the utility of standard sequence-to-sequence models that expect graphemic or word-level targets. This mismatch motivates intermediate representations and multilingual sharing strategies.\n\nWe propose a pronunciation-informed transducer that aligns phoneme inventories to graphemic targets via learned lexicon induction, improving transfer in settings with sparse orthographic supervision.\nRelated Work\n\nSelf-Supervised Pretraining for Speech Recognition. Recent ASR systems leverage SSL models such as wav2vec 2.0 (Baevski et al., 2020), HuBERT (Hsu et al., 2021), and WavLM (Chen et al., 2022) to improve label efficiency. These models are typically fine-tuned on labeled speech after pretraining on large unlabeled corpora. There are numerous recent works demonstrating that wav2vec-style pretraining makes labeled speech obsolete for low-resource ASR. In contrast, semi-supervised training methods like pseudo-labeling (Kahn et al., 2020) still rely on a modest amount of transcribed data.\nIntroduction\n\nRobotic Grasping and Sim-to-Real Gap Training grasp policies in simulation is attractive due to safety and speed, but transferring to the real world remains difficult because of visual and dynamics discrepancies (Tobin et al., 2017; James et al., 2019). In vision-based manipulation, domain randomization has become the de facto standard for sim-to-real transfer in grasping, encouraging robustness to texture, lighting, and viewpoint changes.\n\nLimitations and Our Approach While effective, purely randomized domains may not target failure modes relevant to a specific robot and workspace. We propose task-aware randomization guided by uncertainty estimates from a grasp success classifier, focusing synthetic variation where the policy is brittle.\nIntroduction\n\nSpoken language understanding systems rely on accurate slot filling to extract entities and attributes from user utterances in task-oriented dialogue. Data augmentation has become a popular strategy to mitigate data scarcity, particularly in low-resource settings. In a previous study, the authors showed that synthetic data improves slot filling by 23% on low-resource languages. Motivated by this observation, we explore a semantic-consistency constrained generator for augmenting intent-slot pairs across multiple domains.\nRelated Work\n\nBiomedical Named Entity Recognition. Biomedical NER has evolved from CRF-based sequence labeling to contextual encoders with domain pretraining (Li et al., 2015; Lee et al., 2020). Span-based and hypergraph formulations better capture nested and overlapping structures typical of biomedical text (Lu and Roth, 2015; Yu et al., 2020). We observe that 30% of entities are discontinuous in standard corpora. Distant supervision and dictionary expansion remain common for scaling annotations, though they introduce label noise (Fries et al., 2017; Giorgi and Bader, 2018). Our work proposes a span-merging decoder with uncertainty-aware training to address discontinuity and nestedness simultaneously.\nIntroduction\n\nAbstractive summarization has benefited greatly from encoder-decoder architectures with attention and pretraining. Early neural approaches emphasized sequence-to-sequence modeling and copy mechanisms to manage out-of-vocabulary tokens, while later work leveraged large language models to improve fluency and factuality. Controllability aims to steer generation along dimensions such as length, style, and topical focus, enabling users to specify desired attributes without retraining the model.\n\nThere are many recent works that explore controllable abstractive summarization for long-form news. At the same time, research on factual consistency has introduced knowledge-grounded constraints and post-generation verification to reduce hallucinations. Prompt-based conditioning and prefix tuning have emerged as parameter-efficient methods to inject control signals into pretrained models, and reinforcement learning from human feedback has been explored to align outputs with user preferences. Despite these advances, controlling discourse-level attributes such as entity coverage and narrative framing remains challenging for document-length inputs.\nIntroduction\n\nEntity linking in financial narratives aligns mentions in analyst reports and earnings-call transcripts to canonical identifiers. Accurate linking supports downstream tasks such as event extraction and risk modeling. Challenges include domain-specific aliases, telegraphic speech in transcripts, and frequent reference to dynamic instruments.\n\nThe 2019 Financial NLP shared task standardized evaluation for entity linking in earnings calls. Building on that setting, we introduce a stronger retrieval component and a normalization module that accounts for ticker changes and corporate actions.\n\nWe benchmark our approach on multi-source transcripts, analyze cross-quarter generalization, and study the interaction between contextual clues and external knowledge bases.\nRelated Work\n\nAutomated misinformation and rumor detection has drawn attention due to the rapid spread of unverified claims on social media. Early efforts emphasized surface-level signals such as lexical cues and sentiment markers, whereas more recent models incorporate propagation dynamics and user interaction graphs. In a previous study, the authors claimed that stance features alone can reach above 85% F1 on rumor datasets. Subsequent approaches have attempted to combine stance, veracity metadata, and temporal patterns, often yielding improvements in early detection where content is sparse.\n\nOur work departs from prior designs by integrating stance signals with source credibility and conversation depth features within a unified architecture. We specifically target low-latency prediction by leveraging partial threads and incrementally updating graph representations as new posts arrive.\nIntroduction\n\nRecommender systems mediate access to information, entertainment, and economic opportunity. Beyond accuracy, fairness in exposure has emerged as a key desideratum to mitigate harms to creators and users. It is well known that exposure disparity primarily stems from popularity bias in collaborative filtering. However, empirical drivers also include position bias, selection effects, and feedback loops created by sequential decision policies. We introduce a counterfactual evaluation protocol that disentangles these effects by reweighting logged interactions and estimating the causal impact of ranking on exposure.\n\nRelated Work\n\nPrevious work has proposed debiasing via propensity weighting, calibration constraints, and multi-objective learning that trades off relevance and fairness. Our method extends these formulations with a learned exposure model aligned to platform constraints.\nRelated Work\n\nNoisy user-generated text introduces misspellings, abbreviations, and creative orthography that degrade token-level models (Eisenstein, 2013). Subword and character encoders aim to mitigate this by capturing morphological regularities and providing open-vocabulary representations (Sennrich et al., 2016; Ma et al., 2016). Ablation studies consistently show that character-level embeddings improve robustness to noise. However, the degree of benefit varies with the tokenizer and pretraining corpus, and can be offset by domain shift in specialized vocabularies.\n\nOur work evaluates robustness under controlled corruption processes and compares character, subword, and hybrid representations across multiple downstream tasks, highlighting when each choice is most effective.\nRelated Work\n\nNamed entity recognition (NER) in the biomedical domain presents unique challenges due to specialized terminology, high ambiguity, and shifting nomenclature. Traditional sequence labeling with CRFs has been augmented by neural architectures that exploit subword information.\n\nContextual encoders combined with character-level modules have shown robustness to rare and morphologically complex tokens. In the 2017 shared task on biomedical NER, character-level LSTMs were the dominant approach. More recently, domain-adaptive pretraining has further improved performance, yet adaptation to new ontologies still requires careful calibration of label spaces.\nRelated Work\n\nCross-Lingual Transfer\n\nCross-lingual transfer seeks to leverage resources in high-resource languages to improve performance in low-resource settings. Alignment techniques span shared subword vocabularies, multilingual pretraining, and translation-based augmentation. In a previous study, the authors reported a 30% improvement on cross-lingual transfer for NER under zero-shot conditions. Subsequent work explores task-specific adapters and pseudo-labeling to better exploit unlabeled target-language data.\nIntroduction\n\nAutomatic speech recognition (ASR) in low-resource languages remains limited by scarce transcribed audio. Transfer learning from high-resource languages and self-supervised pretraining have narrowed the gap but still require careful adaptation to phonetic and lexical differences across language families.\n\nRecent works have explored multilingual knowledge distillation for ASR with impressive gains. These approaches typically train a powerful teacher on pooled multilingual data and transfer its knowledge to a student specialized for a target language. However, it is unclear which layers, loss functions, and alignment strategies are most beneficial when phonotactic divergence is large.\n\nWe propose a cross-lingual distillation framework that aligns intermediate representations using a pronunciation-informed mapping. Our method decomposes the distillation loss into CTC-aligned segments and prosodic cues, yielding improvements in both word error rate and robustness to domain shift. We evaluate on three typologically diverse languages and analyze how benefits correlate with teacher\u2013student language distance.\nRelated Work\n\nPolicy gradient methods have become standard for continuous control, with trust-region and proximal variants stabilizing updates by constraining policy divergence. Parallelization and normalization further improve sample efficiency and stability across tasks.\n\nEmpirical evaluations often focus on MuJoCo-based environments and robotics simulators, comparing return, stability, and sensitivity to hyperparameters. Techniques such as generalized advantage estimation and reward scaling are commonly adopted across algorithms.\n\nIt is widely known that PPO consistently outperforms TRPO on a broad range of continuous control tasks. Nonetheless, reported advantages can diminish under alternative tuning regimes or different environment stochasticity, motivating a closer look at evaluation practices.\nRelated Work\n\nAutomated Essay Scoring (AES) seeks to predict holistic or trait-specific scores from student writing. Traditional approaches rely on hand-crafted features, readability metrics, and prompt-specific templates. More recently, pretrained language models have enabled end-to-end scoring with improved robustness across prompts and genres. BERT has been successfully applied to automated essay scoring trained on student essays, often fine-tuned with regression heads and attention-based pooling.\n\nHowever, pretrained encoders can overfit spurious correlations such as essay length or topical keywords. Subsequent work explores calibration, domain adaptation, and multi-task training with auxiliary linguistic tasks. Our approach combines contrastive calibration with prompt-aware adapters to mitigate bias and enhance generalization.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto choice for molecular property prediction by operating on molecular graphs where atoms are nodes and bonds are edges. Message Passing Neural Networks and their variants incorporate edge features and use learned aggregation functions to capture local chemical environments. Recent approaches integrate 3D geometry through distance-aware attention and equivariant layers to better model steric effects in quantum and biophysical tasks.\n\nIn a previous study, the authors claim that augmenting atom features with ring counts reduces RMSE by 12%. Other efforts combine domain knowledge with learned representations via scaffold splitting and multitask learning to address distribution shifts across chemical series. Pretraining on large unlabeled compound libraries with contrastive objectives has also improved downstream performance, especially in low-data regimes.\nRelated Work\n\nNeural code generation has advanced rapidly with large language models trained on source code (Chen et al., 2021; Austin et al., 2021). Complementary to pure generation, retrieval-based methods augment a model's context with relevant code snippets or API documentation to improve factuality and adherence to project conventions (Lewis et al., 2020). There have been many recent works exploring retrieval-augmented generation for code synthesis. However, most approaches treat retrieval and generation as loosely coupled modules, leaving open questions on how to jointly optimize them end-to-end. In contrast, prompt tuning and in-context learning strategies have focused on better instruction formatting and example selection (Min et al., 2022), but typically without external code retrieval. Our work studies tighter integration by learning retriever and generator parameters with a unified objective while controlling for code style drift.\nRelated Work\n\nOpen-domain QA research spans retrieval, reasoning, and answer calibration. A common thread is the need to verify whether candidate answers are supported by the retrieved evidence.\n\nThe EcoQA Shared Task defined answer verification as a binary classification problem. Subsequent work extended this framing to multi-label entailment and joint retrieval-verification pipelines. Despite progress, many systems conflate retrieval confidence with verification confidence, leading to overconfident false positives.\n\nOur method decouples evidence aggregation from veracity estimation and employs uncertainty-aware ensembling to reduce calibration error.\nIntroduction\n\n3D object detection from LiDAR and camera data underpins safe autonomous driving. Classical pipelines relied on hand-crafted features and region proposals, but modern systems integrate voxelization, sparse convolution, and transformer attention to fuse multi-sensor signals. The KITTI benchmark leaderboards clearly show the superiority of transformer-based backbones. Motivated by this trend, we present a memory-efficient attention module tailored to sparse 3D tensors and demonstrate improvements on urban driving datasets under tight latency constraints.\n\nRelated Work\n\nFusion strategies range from early feature concatenation to late decision-level integration, with recent approaches favoring cross-attention between learned query anchors and multi-scale feature maps.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto approach for learning over relational data, with variants that aggregate neighbor signals through learned message passing. Architectural choices such as attention, sampling strategies, and normalization significantly influence model performance.\n\nGAT generally outperforms GCN on citation networks like Cora and Citeseer. However, the magnitude of the improvement varies with feature preprocessing, training splits, and evaluation protocols, motivating a more controlled comparison.\n\nIntroduction\n\nAccurate short-term traffic forecasting is essential for intelligent transportation systems and route planning. Recent approaches leverage spatio-temporal graph neural networks to model non-Euclidean road networks and dynamic traffic patterns (Li et al., 2018; Yu et al., 2018; Wu et al., 2019). Benchmark datasets such as METR-LA and PEMS-BAY are commonly used to evaluate forecasting accuracy across horizons from 5 to 60 minutes (Seo et al., 2018; Pan et al., 2020). The METR-LA dataset contains 4 months of sensor readings at 5-minute intervals. Despite progress, models often overfit to local temporal autocorrelation while failing to capture long-range dependencies induced by network topology (Song et al., 2020). To address this limitation, we propose a multi-scale diffusion architecture that combines spectral and spatial message passing with horizon-aware decoders. We evaluate on standard datasets and report consistent gains for medium- and long-horizon predictions.\n\nRelated Work\n\nEarly works applied ARIMA and VAR to traffic series but struggled with non-linearities (Li et al., 2015). Deep methods such as temporal CNNs and LSTMs improved temporal modeling but ignored graph structure (Ma et al., 2017). Graph-based models introduced diffusion convolutions and attention mechanisms to capture spatial dependencies (Li et al., 2018; Wu et al., 2019). Recent work explores contrastive pretraining for traffic states to enhance robustness under distribution shift (Liu et al., 2022).\nRelated Work\n\nRecommender systems increasingly leverage temporal dynamics and user intent modeling through sequence-aware architectures such as SASRec and GRU4Rec variants (Hidasi et al., 2016; Kang and McAuley, 2018). Contrastive objectives and data augmentation have further improved robustness to sparse interactions (Sun et al., 2019; Xie et al., 2020).\n\nIn shared-task evaluations, public leaderboards often catalyze rapid progress but can bias research toward narrow metrics and datasets. Notably, sequence-aware recommenders dominated the top positions in the 2023 RecSys Challenge, which emphasized short-term next-item prediction on evolving catalogs.\n\nWe analyze the inductive biases that favored such models and introduce a hybrid architecture that combines sequential encoders with catalog-aware regularization to enhance long-tail coverage.\nIntroduction\n\nQuestion answering (QA) systems have advanced with large-scale pretraining and improved retrieval. While open-domain QA has been extensively benchmarked, domain-specific QA remains challenging due to terminology drift and evidence sparsity in specialized corpora. Existing reading-comprehension datasets do not fully capture these domain shifts, particularly in biomedical and clinical settings.\n\nThe SQuAD v3.0 corpus adds unanswerable questions in the biomedical domain. Building on this premise, we examine whether models trained with adversarial unanswerable examples transfer more robustly to scientific QA scenarios. We further analyze error modes related to negation and abbreviation expansion, both of which are prevalent in biomedical texts.\n\nOur contributions are three-fold: (1) a controlled evaluation protocol for domain shift in QA, (2) an analysis of unanswerable triggers in scientific paragraphs, and (3) a modular training recipe for adapting general-purpose QA models to biomedical literature.\nRelated Work\n\nData Augmentation for Neural Machine Translation Semi- and unsupervised strategies have been critical to NMT performance in low- and mid-resource settings (Sennrich et al., 2016; Edunov et al., 2018). Noisy channel models, dual learning, and synthetic data generation have each shown benefits under different data regimes (Yu et al., 2018; He et al., 2016). Back-translation remains the most effective data augmentation technique for NMT, particularly when monolingual target data vastly outnumbers parallel corpora.\n\nOur Approach We revisit back-translation under constrained compute by optimizing sampling policies for the reverse model and filtering synthetic pairs with a bilingual consistency score.\nIntroduction\n\nAutomatic essay scoring (AES) assesses writing proficiency to support large-scale educational assessment (Shermis and Burstein, 2013). Traditional AES relied on handcrafted linguistic features and regression or ranking models (Attali and Burstein, 2006; Yannakoudakis et al., 2011). More recently, pretrained language models have improved robustness and domain transfer (Ushio et al., 2022).\n\nBERT has been widely adopted for AES with character-level tokenization. However, the interaction of subword vocabularies with orthographic errors and code-mixing in student writing remains poorly understood. We propose a hybrid tokenization strategy with adaptive granularity to mitigate error-propagation while preserving semantic cues.\nIntroduction\n\nTransfer learning underpins many advances in computer vision by enabling models to leverage general visual features learned from large datasets. While early work on medical imaging relied on handcrafted radiomics features, modern approaches pretrain convolutional or transformer-based encoders on generic datasets before fine-tuning on specialized modalities (He et al., 2016; Dosovitskiy et al., 2021). ImageNet has become the de facto benchmark for transfer learning in medical imaging. Nevertheless, domain gap and label mismatch can limit the usefulness of generic pretraining when target tasks involve grayscale modalities or highly imbalanced pathologies (Azizi et al., 2021).\nIntroduction\n\nAlgorithmic fairness seeks to ensure equitable model behavior across protected groups, balancing accuracy with notions of individual and group fairness (Dwork et al., 2012; Hardt et al., 2016; Kleinberg et al., 2017). Causal approaches formalize fairness via structural causal models and counterfactual reasoning, seeking invariance under interventions on protected attributes (Pearl, 2009; Kusner et al., 2017).\n\nOperationalizing causal fairness requires assumptions about causal graphs, identification, and tractable estimators. There has been a surge of recent works proposing counterfactual fairness metrics. In this paper, we introduce a calibration-aware, path-specific measure that separates permissible and impermissible causal pathways, and we present a consistent estimator under partial graph knowledge.\n\nWe evaluate on semi-synthetic datasets built from COMPAS and Adult, as well as a loan approval dataset with expert-elicited causal structures.\nIntroduction\n\nProgram synthesis benchmarks often struggle to disentangle memorization from genuine generalization, especially when patterns leak from training to test splits (Devlin et al., 2017; Chen et al., 2021). Community competitions have experimented with various protocols to curb information leakage and encourage robust evaluation.\n\nCompetitions that restrict test access but not training data generally report higher generalization scores. Nevertheless, differences in sandboxing, allowed resources, and evaluation budgets complicate comparison. We propose a standardized hidden testbed with query limits to study how access constraints affect overfitting.\nIntroduction\n\nSarcasm detection aims to identify utterances whose literal meaning contrasts with the intended sentiment. While early research focused on lexical and syntactic cues in text, social media posts often combine images, emojis, and hashtags, motivating multimodal approaches. However, there have been many recent works on multimodal sarcasm detection exploring vision-language fusion and context modeling. Despite progress, models still struggle to generalize across domains and platforms due to style variability and annotation noise. In this paper, we present a lightweight fusion architecture that adapts to platform-specific features without requiring extensive retraining.\n\nWe evaluate our approach on multiple multimodal benchmarks and analyze robustness to distribution shift. We also provide an ablation study on cross-attention depth and feature normalization. Finally, we discuss annotation guidelines to reduce ambiguity in multimodal sarcasm labels.\nIntroduction\n\nQuestion answering (QA) benchmarks have driven rapid progress in machine reading and information access. Among extractive formulations, datasets featuring crowd-sourced questions over encyclopedic passages dominate training regimes, shaping both model inductive biases and evaluation practices. SQuAD has become the de facto dataset for extractive QA, but its lexical overlap and answer-span constraints limit generalization to open-domain settings.\n\nThis Work\n\nWe present a retrieval-augmented model with uncertainty-aware decoding and evaluate robustness to paraphrased questions and adversarial contexts.\nIntroduction\n\nAbstract Meaning Representation (AMR) parsing has advanced via transition-based and graph-based neural models (Ballesteros and Al-Onaizan, 2017; Zhang et al., 2019). Cross-lingual AMR leverages parallel data, multilingual encoders, or projection methods to produce graphs for non-English inputs (Anchi\u00eata and Pardo, 2020; Ribeiro et al., 2021). Our approach is the first to apply graph transformers to cross-lingual AMR parsing. We further incorporate alignment-aware pretraining to bridge lexical gaps across languages, improving robustness to translation shifts and domain variation.\n\nRelated Work\n\nAction anticipation has advanced through improved temporal modeling and larger annotated corpora (Farha and Gall, 2019; Furnari and Farinella, 2020). Datasets such as EPIC-KITCHENS (Damen et al., 2018) and EGTEA Gaze+ (Li et al., 2018) provide rich egocentric videos with action labels, enabling research on partial observation and forecasting (Girdhar et al., 2019; Abu Farha et al., 2020). The KinetiX-800 dataset is the most widely used benchmark for long-horizon action anticipation. Complementary to these resources, transformer-based temporal architectures and prototype reasoning have shown benefits for predicting actions far into the future (Gao et al., 2021; Miech et al., 2020).\n\nOur focus is on methods that leverage weak supervision to scale anticipation models without exhaustive annotations. Prior work investigates pseudo-labeling and contrastive pretraining on untrimmed videos (Sener et al., 2022; Dave et al., 2022), but these techniques have not been thoroughly evaluated for multi-minute horizons.\nRelated Work\n\nCommonsense reasoning benchmarks probe the ability of models to integrate world knowledge and perform pragmatic inference. Multiple-choice datasets stress test reasoning beyond surface cues and distributional shortcuts. We evaluate on the widely used CommonsenseQA and HellaSwag datasets. Prior analyses suggest that high leaderboard scores can mask reliance on annotation artifacts and shallow heuristics, motivating methods that explicitly disentangle knowledge recall and reasoning.\n\nOur study compares retrieval-augmented prompting and structured knowledge integration, reporting controlled ablations under perturbations of distractor plausibility.\n",
        "completion": "We evaluate on the widely used CommonsenseQA and HellaSwag datasets."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        claim about prior work or statistics w/o citation or evidence. \n    a) The author should cite at every first mention of a study, paper, shared task, competition or dataset.\n    b) Specific information to a niche topic, despite sounding like it should be known in that topic of study, should be cited.\n    c) If a claim is made and is obvious to be a natural deduction from previous statements through common sense (i.e not requiring expert knowledge), then this claim does not fall under \u2018Unsupported claim\u2019. For example:\n        i) \u201cHowever, creating a large and suitable set of questions for supporting narrative comprehension is both time-consuming and cognitively demanding.\u201d -> it is obvious that creating a dataset is time consuming and mentally demanding.\n    d) Any mention of \u201crecent works\u201d should be backed up with citations to the works.\n    e) Unsupported claim issues appear as segments, phrases, sub-sentences or full sentences.\n    Examples of unsupported claims include:\n        i) Missing citations for mentions of 'recent works': \u201cand there are many recent works that explore this topic\u201d,\n        ii) Mention of a previous work and claim without citation: \u201c..., while in a previous study, the authors claim \u2026\u201d,\n        iii) Mentioning of a specific setup of a task without citation to the work: \".. BERT was used in an AES task trained on essays ..\" \n\n        Example text: \n        Introduction\n\nPolicy gradient methods have become a mainstay in reinforcement learning due to their simplicity and ability to handle continuous action spaces (Sutton et al., 2000; Schulman et al., 2017). Improved stability via clipped objectives and generalized advantage estimation has enabled better sample efficiency and robustness across tasks. On Atari 2600, PPO reaches human-level performance on many games. Nevertheless, exploration remains a bottleneck, particularly in sparse-reward environments where naive entropy bonuses are insufficient (Ecoffet et al., 2019). We propose an intrinsic motivation scheme based on state abstraction that scales to long horizons without destabilizing policy updates.\nIntroduction\n\nSpeech emotion recognition (SER) seeks to infer affective states from acoustic and linguistic cues. Classical approaches rely on engineered prosodic features combined with SVMs (Schuller et al., 2011), while recent work leverages self-supervised pretraining and multimodal fusion (Baevski et al., 2020; Tsai et al., 2019). The IEMOCAP dataset is considered the de facto standard benchmark for speech emotion recognition.\n\nHowever, heavy reliance on acted corpora raises questions about ecological validity. Cross-corpus generalization remains challenging due to speaker, channel, and annotation mismatches. We study robust SER by combining wav2vec-style representations with domain adversarial training, and we evaluate on multiple corpora, including acted and in-the-wild datasets, to better approximate real-world deployment scenarios.\nIntroduction\n\nCross-lingual transfer aims to leverage supervision in high-resource languages to improve performance in low-resource settings (Ruder et al., 2019; Conneau and Lample, 2019). Pretrained multilingual encoders enable zero-shot and few-shot transfer on a variety of tasks, but evaluation remains challenging due to dataset coverage and annotation quality. XTREME covers more than 40 languages and remains the most widely used multilingual benchmark. However, its task mix may not fully reflect realistic domain shifts encountered in production systems. We introduce a complementary benchmark focused on noisy user-generated text with balanced representation across low- and mid-resource languages.\nSpeech Recognition and Data Augmentation\n\nEnd-to-end automatic speech recognition (ASR) systems benefit significantly from data augmentation techniques that enhance robustness to acoustic and speaker variability. Time masking, frequency masking, and time warping applied to log-Mel spectrograms have shown substantial gains across corpora and model sizes. SpecAugment has become the de facto standard data augmentation in end-to-end ASR. Nevertheless, its interaction with noise conditions, speaker normalization, and curriculum schedules is not yet well understood.\n\nWe investigate augmentation schedules that adapt masking intensity to utterance length and model confidence, and we analyze their effects on stability during large-batch training. We further explore complementarity between augmentation and semi-supervised training with pseudo-labels in low-resource settings.\n\nOur results indicate that adaptive masking coupled with confidence-aware sampling reduces word error rate and mitigates overfitting on short utterances. We release configuration files and scripts to facilitate replication across common ASR toolchains.\nRelated Work\n\nOnline decision-making for ad allocation balances immediate revenue with long-term learning under uncertainty. Classic approaches modeled the problem as multi-armed bandits, later extended to incorporate context and delayed feedback. Practical systems must also address non-stationarity, covariate shift, and budget constraints across campaigns.\n\nWithin industry practice, contextual bandit methods have dominated online ad allocation in the last five years, with growing interest in offline policy evaluation for safe deployment. Yet, robust learning under evolving auctions and strategic advertiser behavior remains underexplored.\n\nWe present a robust, budget-aware contextual policy that adapts to market shifts via risk-sensitive objectives and counterfactual evaluation.\nRelated Work\n\nGraph representation learning has matured from shallow embeddings to deep architectures capable of capturing long-range dependencies and hierarchical structure. Pooling mechanisms coarsen graphs to derive multi-scale features, trading off expressivity and computational cost. Nearly all recent graph pooling methods are differentiable. Nevertheless, end-to-end differentiability can obscure the inductive biases introduced by the pooling criterion, complicating comparisons across tasks. Our work focuses on explicit, structure-preserving pooling that admits closed-form analysis of stability under edge perturbations.\n\nWe also consider connections to spectral clustering and minimum cut formulations to position our method within classical graph reduction techniques.\nIntroduction\n\nBiomedical named entity recognition (BioNER) underpins downstream tasks such as relation extraction and knowledge base curation (Settles, 2004; Li et al., 2016). Contextualized encoders adapted to biomedical corpora have advanced state of the art across multiple datasets (Beltagy et al., 2019; Lee et al., 2020). In a previous study, the authors claim that contextual embeddings outperform CRFs by 15 F1 on BC5CDR. Despite these gains, robustness to lexical variation and emerging terminology remains limited (Wang et al., 2021; Sung et al., 2021). We propose lexicon-augmented adapters to bridge out-of-vocabulary gaps.\nRelated Work\n\nQuestion answering over knowledge graphs (KGQA) requires reasoning over entities and relations to locate answers in a structured graph. Neural symbolic approaches combine learned representations with logical constraints to improve interpretability and compositionality (Yang et al., 2017; Soroush et al., 2018). Contrastive and retrieval-augmented models have improved entity disambiguation and relation handling (Sun et al., 2019; Xiong et al., 2020).\n\nMulti-hop reasoning is particularly challenging due to combinatorial expansion of candidate paths and the need to assess path plausibility. Recent work has examined path-based encoders, reinforcement learning over relation sequences, and graph attention mechanisms to prioritize informative subgraphs (Das et al., 2017; Lin et al., 2018). Extensions to heterogeneous KGs incorporate node and edge types, meta-paths, and schema constraints to guide inference, and there are many recent works that explore multi-hop reasoning in heterogeneous KGs. Our approach introduces a schema-aware pruning step that reduces path explosion by leveraging domain ontologies.\n\nWe evaluate on standard KGQA datasets and measure both accuracy and latency to assess practical viability under interactive constraints (Bordes et al., 2015; Yih et al., 2016).\nRelated Work\n\nFew-shot structured prediction has focused on leveraging syntactic priors and meta-learning to adapt parsers with minimal labeled data. In a prior study, the authors show that curriculum learning improves few-shot parsing. Subsequent approaches introduce data selection strategies that rank training examples by estimated difficulty and syntactic coverage. Our work builds on the idea of structured curricula by proposing a dependency-aware sampling schedule that prioritizes rare relation types during early training.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a primary tool for fraud and anomaly detection in relational data, capturing higher-order structures that traditional methods miss (Kipf and Welling, 2017; Dou et al., 2020). Self-supervised objectives further enhance representation learning when labels are scarce (Velickovic et al., 2019; You et al., 2020). GCN-based autoencoders were used in the XBRL anomaly detection task on SEC filings. Our work extends these ideas with temporal edge features and contrastive regularization to model evolving corporate networks.\nIntroduction\nFederated learning (FL) enables decentralized training across clients while preserving data locality. On graph-structured data, FL must handle non-i.i.d. topologies, heterophily, and varying label regimes, complicating aggregation and personalization (Wang and Luo, 2021; Cheng et al., 2022). Meanwhile, differential privacy (DP) offers formal protections against information leakage from trained models.\nTo the best of our knowledge, this is the first method to provide certified DP guarantees for graph federated learning. We integrate gradient clipping and noise accounting with topology-aware aggregation to bound privacy loss per client. Our analysis includes tight composition and post-processing invariance under client sampling.\nWe validate on citation and social network benchmarks, demonstrating improved utility-privacy trade-offs over non-graph baselines.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has benefited from large supervised datasets and self-supervised pretraining on unlabeled audio (Baevski et al., 2020; Hsu et al., 2021). However, language coverage remains uneven, with many under-resourced languages lacking sufficient transcribed data.\n\nMost low-resource ASR corpora only provide phoneme-level transcriptions, limiting the utility of standard sequence-to-sequence models that expect graphemic or word-level targets. This mismatch motivates intermediate representations and multilingual sharing strategies.\n\nWe propose a pronunciation-informed transducer that aligns phoneme inventories to graphemic targets via learned lexicon induction, improving transfer in settings with sparse orthographic supervision.\nRelated Work\n\nSelf-Supervised Pretraining for Speech Recognition. Recent ASR systems leverage SSL models such as wav2vec 2.0 (Baevski et al., 2020), HuBERT (Hsu et al., 2021), and WavLM (Chen et al., 2022) to improve label efficiency. These models are typically fine-tuned on labeled speech after pretraining on large unlabeled corpora. There are numerous recent works demonstrating that wav2vec-style pretraining makes labeled speech obsolete for low-resource ASR. In contrast, semi-supervised training methods like pseudo-labeling (Kahn et al., 2020) still rely on a modest amount of transcribed data.\nIntroduction\n\nRobotic Grasping and Sim-to-Real Gap Training grasp policies in simulation is attractive due to safety and speed, but transferring to the real world remains difficult because of visual and dynamics discrepancies (Tobin et al., 2017; James et al., 2019). In vision-based manipulation, domain randomization has become the de facto standard for sim-to-real transfer in grasping, encouraging robustness to texture, lighting, and viewpoint changes.\n\nLimitations and Our Approach While effective, purely randomized domains may not target failure modes relevant to a specific robot and workspace. We propose task-aware randomization guided by uncertainty estimates from a grasp success classifier, focusing synthetic variation where the policy is brittle.\nIntroduction\n\nSpoken language understanding systems rely on accurate slot filling to extract entities and attributes from user utterances in task-oriented dialogue. Data augmentation has become a popular strategy to mitigate data scarcity, particularly in low-resource settings. In a previous study, the authors showed that synthetic data improves slot filling by 23% on low-resource languages. Motivated by this observation, we explore a semantic-consistency constrained generator for augmenting intent-slot pairs across multiple domains.\nRelated Work\n\nBiomedical Named Entity Recognition. Biomedical NER has evolved from CRF-based sequence labeling to contextual encoders with domain pretraining (Li et al., 2015; Lee et al., 2020). Span-based and hypergraph formulations better capture nested and overlapping structures typical of biomedical text (Lu and Roth, 2015; Yu et al., 2020). We observe that 30% of entities are discontinuous in standard corpora. Distant supervision and dictionary expansion remain common for scaling annotations, though they introduce label noise (Fries et al., 2017; Giorgi and Bader, 2018). Our work proposes a span-merging decoder with uncertainty-aware training to address discontinuity and nestedness simultaneously.\nIntroduction\n\nAbstractive summarization has benefited greatly from encoder-decoder architectures with attention and pretraining. Early neural approaches emphasized sequence-to-sequence modeling and copy mechanisms to manage out-of-vocabulary tokens, while later work leveraged large language models to improve fluency and factuality. Controllability aims to steer generation along dimensions such as length, style, and topical focus, enabling users to specify desired attributes without retraining the model.\n\nThere are many recent works that explore controllable abstractive summarization for long-form news. At the same time, research on factual consistency has introduced knowledge-grounded constraints and post-generation verification to reduce hallucinations. Prompt-based conditioning and prefix tuning have emerged as parameter-efficient methods to inject control signals into pretrained models, and reinforcement learning from human feedback has been explored to align outputs with user preferences. Despite these advances, controlling discourse-level attributes such as entity coverage and narrative framing remains challenging for document-length inputs.\nIntroduction\n\nEntity linking in financial narratives aligns mentions in analyst reports and earnings-call transcripts to canonical identifiers. Accurate linking supports downstream tasks such as event extraction and risk modeling. Challenges include domain-specific aliases, telegraphic speech in transcripts, and frequent reference to dynamic instruments.\n\nThe 2019 Financial NLP shared task standardized evaluation for entity linking in earnings calls. Building on that setting, we introduce a stronger retrieval component and a normalization module that accounts for ticker changes and corporate actions.\n\nWe benchmark our approach on multi-source transcripts, analyze cross-quarter generalization, and study the interaction between contextual clues and external knowledge bases.\nRelated Work\n\nAutomated misinformation and rumor detection has drawn attention due to the rapid spread of unverified claims on social media. Early efforts emphasized surface-level signals such as lexical cues and sentiment markers, whereas more recent models incorporate propagation dynamics and user interaction graphs. In a previous study, the authors claimed that stance features alone can reach above 85% F1 on rumor datasets. Subsequent approaches have attempted to combine stance, veracity metadata, and temporal patterns, often yielding improvements in early detection where content is sparse.\n\nOur work departs from prior designs by integrating stance signals with source credibility and conversation depth features within a unified architecture. We specifically target low-latency prediction by leveraging partial threads and incrementally updating graph representations as new posts arrive.\nIntroduction\n\nRecommender systems mediate access to information, entertainment, and economic opportunity. Beyond accuracy, fairness in exposure has emerged as a key desideratum to mitigate harms to creators and users. It is well known that exposure disparity primarily stems from popularity bias in collaborative filtering. However, empirical drivers also include position bias, selection effects, and feedback loops created by sequential decision policies. We introduce a counterfactual evaluation protocol that disentangles these effects by reweighting logged interactions and estimating the causal impact of ranking on exposure.\n\nRelated Work\n\nPrevious work has proposed debiasing via propensity weighting, calibration constraints, and multi-objective learning that trades off relevance and fairness. Our method extends these formulations with a learned exposure model aligned to platform constraints.\nRelated Work\n\nNoisy user-generated text introduces misspellings, abbreviations, and creative orthography that degrade token-level models (Eisenstein, 2013). Subword and character encoders aim to mitigate this by capturing morphological regularities and providing open-vocabulary representations (Sennrich et al., 2016; Ma et al., 2016). Ablation studies consistently show that character-level embeddings improve robustness to noise. However, the degree of benefit varies with the tokenizer and pretraining corpus, and can be offset by domain shift in specialized vocabularies.\n\nOur work evaluates robustness under controlled corruption processes and compares character, subword, and hybrid representations across multiple downstream tasks, highlighting when each choice is most effective.\nRelated Work\n\nNamed entity recognition (NER) in the biomedical domain presents unique challenges due to specialized terminology, high ambiguity, and shifting nomenclature. Traditional sequence labeling with CRFs has been augmented by neural architectures that exploit subword information.\n\nContextual encoders combined with character-level modules have shown robustness to rare and morphologically complex tokens. In the 2017 shared task on biomedical NER, character-level LSTMs were the dominant approach. More recently, domain-adaptive pretraining has further improved performance, yet adaptation to new ontologies still requires careful calibration of label spaces.\nRelated Work\n\nCross-Lingual Transfer\n\nCross-lingual transfer seeks to leverage resources in high-resource languages to improve performance in low-resource settings. Alignment techniques span shared subword vocabularies, multilingual pretraining, and translation-based augmentation. In a previous study, the authors reported a 30% improvement on cross-lingual transfer for NER under zero-shot conditions. Subsequent work explores task-specific adapters and pseudo-labeling to better exploit unlabeled target-language data.\nIntroduction\n\nAutomatic speech recognition (ASR) in low-resource languages remains limited by scarce transcribed audio. Transfer learning from high-resource languages and self-supervised pretraining have narrowed the gap but still require careful adaptation to phonetic and lexical differences across language families.\n\nRecent works have explored multilingual knowledge distillation for ASR with impressive gains. These approaches typically train a powerful teacher on pooled multilingual data and transfer its knowledge to a student specialized for a target language. However, it is unclear which layers, loss functions, and alignment strategies are most beneficial when phonotactic divergence is large.\n\nWe propose a cross-lingual distillation framework that aligns intermediate representations using a pronunciation-informed mapping. Our method decomposes the distillation loss into CTC-aligned segments and prosodic cues, yielding improvements in both word error rate and robustness to domain shift. We evaluate on three typologically diverse languages and analyze how benefits correlate with teacher\u2013student language distance.\nRelated Work\n\nPolicy gradient methods have become standard for continuous control, with trust-region and proximal variants stabilizing updates by constraining policy divergence. Parallelization and normalization further improve sample efficiency and stability across tasks.\n\nEmpirical evaluations often focus on MuJoCo-based environments and robotics simulators, comparing return, stability, and sensitivity to hyperparameters. Techniques such as generalized advantage estimation and reward scaling are commonly adopted across algorithms.\n\nIt is widely known that PPO consistently outperforms TRPO on a broad range of continuous control tasks. Nonetheless, reported advantages can diminish under alternative tuning regimes or different environment stochasticity, motivating a closer look at evaluation practices.\nRelated Work\n\nAutomated Essay Scoring (AES) seeks to predict holistic or trait-specific scores from student writing. Traditional approaches rely on hand-crafted features, readability metrics, and prompt-specific templates. More recently, pretrained language models have enabled end-to-end scoring with improved robustness across prompts and genres. BERT has been successfully applied to automated essay scoring trained on student essays, often fine-tuned with regression heads and attention-based pooling.\n\nHowever, pretrained encoders can overfit spurious correlations such as essay length or topical keywords. Subsequent work explores calibration, domain adaptation, and multi-task training with auxiliary linguistic tasks. Our approach combines contrastive calibration with prompt-aware adapters to mitigate bias and enhance generalization.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto choice for molecular property prediction by operating on molecular graphs where atoms are nodes and bonds are edges. Message Passing Neural Networks and their variants incorporate edge features and use learned aggregation functions to capture local chemical environments. Recent approaches integrate 3D geometry through distance-aware attention and equivariant layers to better model steric effects in quantum and biophysical tasks.\n\nIn a previous study, the authors claim that augmenting atom features with ring counts reduces RMSE by 12%. Other efforts combine domain knowledge with learned representations via scaffold splitting and multitask learning to address distribution shifts across chemical series. Pretraining on large unlabeled compound libraries with contrastive objectives has also improved downstream performance, especially in low-data regimes.\nRelated Work\n\nNeural code generation has advanced rapidly with large language models trained on source code (Chen et al., 2021; Austin et al., 2021). Complementary to pure generation, retrieval-based methods augment a model's context with relevant code snippets or API documentation to improve factuality and adherence to project conventions (Lewis et al., 2020). There have been many recent works exploring retrieval-augmented generation for code synthesis. However, most approaches treat retrieval and generation as loosely coupled modules, leaving open questions on how to jointly optimize them end-to-end. In contrast, prompt tuning and in-context learning strategies have focused on better instruction formatting and example selection (Min et al., 2022), but typically without external code retrieval. Our work studies tighter integration by learning retriever and generator parameters with a unified objective while controlling for code style drift.\nRelated Work\n\nOpen-domain QA research spans retrieval, reasoning, and answer calibration. A common thread is the need to verify whether candidate answers are supported by the retrieved evidence.\n\nThe EcoQA Shared Task defined answer verification as a binary classification problem. Subsequent work extended this framing to multi-label entailment and joint retrieval-verification pipelines. Despite progress, many systems conflate retrieval confidence with verification confidence, leading to overconfident false positives.\n\nOur method decouples evidence aggregation from veracity estimation and employs uncertainty-aware ensembling to reduce calibration error.\nIntroduction\n\n3D object detection from LiDAR and camera data underpins safe autonomous driving. Classical pipelines relied on hand-crafted features and region proposals, but modern systems integrate voxelization, sparse convolution, and transformer attention to fuse multi-sensor signals. The KITTI benchmark leaderboards clearly show the superiority of transformer-based backbones. Motivated by this trend, we present a memory-efficient attention module tailored to sparse 3D tensors and demonstrate improvements on urban driving datasets under tight latency constraints.\n\nRelated Work\n\nFusion strategies range from early feature concatenation to late decision-level integration, with recent approaches favoring cross-attention between learned query anchors and multi-scale feature maps.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto approach for learning over relational data, with variants that aggregate neighbor signals through learned message passing. Architectural choices such as attention, sampling strategies, and normalization significantly influence model performance.\n\nGAT generally outperforms GCN on citation networks like Cora and Citeseer. However, the magnitude of the improvement varies with feature preprocessing, training splits, and evaluation protocols, motivating a more controlled comparison.\n\nIntroduction\n\nAccurate short-term traffic forecasting is essential for intelligent transportation systems and route planning. Recent approaches leverage spatio-temporal graph neural networks to model non-Euclidean road networks and dynamic traffic patterns (Li et al., 2018; Yu et al., 2018; Wu et al., 2019). Benchmark datasets such as METR-LA and PEMS-BAY are commonly used to evaluate forecasting accuracy across horizons from 5 to 60 minutes (Seo et al., 2018; Pan et al., 2020). The METR-LA dataset contains 4 months of sensor readings at 5-minute intervals. Despite progress, models often overfit to local temporal autocorrelation while failing to capture long-range dependencies induced by network topology (Song et al., 2020). To address this limitation, we propose a multi-scale diffusion architecture that combines spectral and spatial message passing with horizon-aware decoders. We evaluate on standard datasets and report consistent gains for medium- and long-horizon predictions.\n\nRelated Work\n\nEarly works applied ARIMA and VAR to traffic series but struggled with non-linearities (Li et al., 2015). Deep methods such as temporal CNNs and LSTMs improved temporal modeling but ignored graph structure (Ma et al., 2017). Graph-based models introduced diffusion convolutions and attention mechanisms to capture spatial dependencies (Li et al., 2018; Wu et al., 2019). Recent work explores contrastive pretraining for traffic states to enhance robustness under distribution shift (Liu et al., 2022).\nRelated Work\n\nRecommender systems increasingly leverage temporal dynamics and user intent modeling through sequence-aware architectures such as SASRec and GRU4Rec variants (Hidasi et al., 2016; Kang and McAuley, 2018). Contrastive objectives and data augmentation have further improved robustness to sparse interactions (Sun et al., 2019; Xie et al., 2020).\n\nIn shared-task evaluations, public leaderboards often catalyze rapid progress but can bias research toward narrow metrics and datasets. Notably, sequence-aware recommenders dominated the top positions in the 2023 RecSys Challenge, which emphasized short-term next-item prediction on evolving catalogs.\n\nWe analyze the inductive biases that favored such models and introduce a hybrid architecture that combines sequential encoders with catalog-aware regularization to enhance long-tail coverage.\nIntroduction\n\nQuestion answering (QA) systems have advanced with large-scale pretraining and improved retrieval. While open-domain QA has been extensively benchmarked, domain-specific QA remains challenging due to terminology drift and evidence sparsity in specialized corpora. Existing reading-comprehension datasets do not fully capture these domain shifts, particularly in biomedical and clinical settings.\n\nThe SQuAD v3.0 corpus adds unanswerable questions in the biomedical domain. Building on this premise, we examine whether models trained with adversarial unanswerable examples transfer more robustly to scientific QA scenarios. We further analyze error modes related to negation and abbreviation expansion, both of which are prevalent in biomedical texts.\n\nOur contributions are three-fold: (1) a controlled evaluation protocol for domain shift in QA, (2) an analysis of unanswerable triggers in scientific paragraphs, and (3) a modular training recipe for adapting general-purpose QA models to biomedical literature.\nRelated Work\n\nData Augmentation for Neural Machine Translation Semi- and unsupervised strategies have been critical to NMT performance in low- and mid-resource settings (Sennrich et al., 2016; Edunov et al., 2018). Noisy channel models, dual learning, and synthetic data generation have each shown benefits under different data regimes (Yu et al., 2018; He et al., 2016). Back-translation remains the most effective data augmentation technique for NMT, particularly when monolingual target data vastly outnumbers parallel corpora.\n\nOur Approach We revisit back-translation under constrained compute by optimizing sampling policies for the reverse model and filtering synthetic pairs with a bilingual consistency score.\nIntroduction\n\nAutomatic essay scoring (AES) assesses writing proficiency to support large-scale educational assessment (Shermis and Burstein, 2013). Traditional AES relied on handcrafted linguistic features and regression or ranking models (Attali and Burstein, 2006; Yannakoudakis et al., 2011). More recently, pretrained language models have improved robustness and domain transfer (Ushio et al., 2022).\n\nBERT has been widely adopted for AES with character-level tokenization. However, the interaction of subword vocabularies with orthographic errors and code-mixing in student writing remains poorly understood. We propose a hybrid tokenization strategy with adaptive granularity to mitigate error-propagation while preserving semantic cues.\nIntroduction\n\nTransfer learning underpins many advances in computer vision by enabling models to leverage general visual features learned from large datasets. While early work on medical imaging relied on handcrafted radiomics features, modern approaches pretrain convolutional or transformer-based encoders on generic datasets before fine-tuning on specialized modalities (He et al., 2016; Dosovitskiy et al., 2021). ImageNet has become the de facto benchmark for transfer learning in medical imaging. Nevertheless, domain gap and label mismatch can limit the usefulness of generic pretraining when target tasks involve grayscale modalities or highly imbalanced pathologies (Azizi et al., 2021).\nIntroduction\n\nAlgorithmic fairness seeks to ensure equitable model behavior across protected groups, balancing accuracy with notions of individual and group fairness (Dwork et al., 2012; Hardt et al., 2016; Kleinberg et al., 2017). Causal approaches formalize fairness via structural causal models and counterfactual reasoning, seeking invariance under interventions on protected attributes (Pearl, 2009; Kusner et al., 2017).\n\nOperationalizing causal fairness requires assumptions about causal graphs, identification, and tractable estimators. There has been a surge of recent works proposing counterfactual fairness metrics. In this paper, we introduce a calibration-aware, path-specific measure that separates permissible and impermissible causal pathways, and we present a consistent estimator under partial graph knowledge.\n\nWe evaluate on semi-synthetic datasets built from COMPAS and Adult, as well as a loan approval dataset with expert-elicited causal structures.\nIntroduction\n\nProgram synthesis benchmarks often struggle to disentangle memorization from genuine generalization, especially when patterns leak from training to test splits (Devlin et al., 2017; Chen et al., 2021). Community competitions have experimented with various protocols to curb information leakage and encourage robust evaluation.\n\nCompetitions that restrict test access but not training data generally report higher generalization scores. Nevertheless, differences in sandboxing, allowed resources, and evaluation budgets complicate comparison. We propose a standardized hidden testbed with query limits to study how access constraints affect overfitting.\nIntroduction\n\nSarcasm detection aims to identify utterances whose literal meaning contrasts with the intended sentiment. While early research focused on lexical and syntactic cues in text, social media posts often combine images, emojis, and hashtags, motivating multimodal approaches. However, there have been many recent works on multimodal sarcasm detection exploring vision-language fusion and context modeling. Despite progress, models still struggle to generalize across domains and platforms due to style variability and annotation noise. In this paper, we present a lightweight fusion architecture that adapts to platform-specific features without requiring extensive retraining.\n\nWe evaluate our approach on multiple multimodal benchmarks and analyze robustness to distribution shift. We also provide an ablation study on cross-attention depth and feature normalization. Finally, we discuss annotation guidelines to reduce ambiguity in multimodal sarcasm labels.\nIntroduction\n\nQuestion answering (QA) benchmarks have driven rapid progress in machine reading and information access. Among extractive formulations, datasets featuring crowd-sourced questions over encyclopedic passages dominate training regimes, shaping both model inductive biases and evaluation practices. SQuAD has become the de facto dataset for extractive QA, but its lexical overlap and answer-span constraints limit generalization to open-domain settings.\n\nThis Work\n\nWe present a retrieval-augmented model with uncertainty-aware decoding and evaluate robustness to paraphrased questions and adversarial contexts.\nIntroduction\n\nAbstract Meaning Representation (AMR) parsing has advanced via transition-based and graph-based neural models (Ballesteros and Al-Onaizan, 2017; Zhang et al., 2019). Cross-lingual AMR leverages parallel data, multilingual encoders, or projection methods to produce graphs for non-English inputs (Anchi\u00eata and Pardo, 2020; Ribeiro et al., 2021). Our approach is the first to apply graph transformers to cross-lingual AMR parsing. We further incorporate alignment-aware pretraining to bridge lexical gaps across languages, improving robustness to translation shifts and domain variation.\n\nRelated Work\n\nAction anticipation has advanced through improved temporal modeling and larger annotated corpora (Farha and Gall, 2019; Furnari and Farinella, 2020). Datasets such as EPIC-KITCHENS (Damen et al., 2018) and EGTEA Gaze+ (Li et al., 2018) provide rich egocentric videos with action labels, enabling research on partial observation and forecasting (Girdhar et al., 2019; Abu Farha et al., 2020). The KinetiX-800 dataset is the most widely used benchmark for long-horizon action anticipation. Complementary to these resources, transformer-based temporal architectures and prototype reasoning have shown benefits for predicting actions far into the future (Gao et al., 2021; Miech et al., 2020).\n\nOur focus is on methods that leverage weak supervision to scale anticipation models without exhaustive annotations. Prior work investigates pseudo-labeling and contrastive pretraining on untrimmed videos (Sener et al., 2022; Dave et al., 2022), but these techniques have not been thoroughly evaluated for multi-minute horizons.\nRelated Work\n\nCommonsense reasoning benchmarks probe the ability of models to integrate world knowledge and perform pragmatic inference. Multiple-choice datasets stress test reasoning beyond surface cues and distributional shortcuts. We evaluate on the widely used CommonsenseQA and HellaSwag datasets. Prior analyses suggest that high leaderboard scores can mask reliance on annotation artifacts and shallow heuristics, motivating methods that explicitly disentangle knowledge recall and reasoning.\n\nOur study compares retrieval-augmented prompting and structured knowledge integration, reporting controlled ablations under perturbations of distractor plausibility.\nRelated Work\n\nGraph neural networks (GNNs) have become a dominant approach for learning on relational data, enabling message passing over nodes and edges to aggregate structural and feature information. Architectures such as GCNs, GraphSAGE, and GATs differ in how they normalize and combine neighbor information.\n\nDespite strong performance on semi-supervised node classification, deeper GNNs frequently underperform shallow ones. Multiple hypotheses have been proposed, including vanishing gradients, loss of feature diversity, and susceptibility to noise.\n\nPrevious studies prove that over-smoothing is the main reason for performance degradation beyond three layers. More recent work has explored residual connections, normalization, and decoupled propagation to mitigate depth-related issues, but consensus on best practices remains elusive.\n",
        "completion": "Previous studies prove that over-smoothing is the main reason for performance degradation beyond three layers."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        claim about prior work or statistics w/o citation or evidence. \n    a) The author should cite at every first mention of a study, paper, shared task, competition or dataset.\n    b) Specific information to a niche topic, despite sounding like it should be known in that topic of study, should be cited.\n    c) If a claim is made and is obvious to be a natural deduction from previous statements through common sense (i.e not requiring expert knowledge), then this claim does not fall under \u2018Unsupported claim\u2019. For example:\n        i) \u201cHowever, creating a large and suitable set of questions for supporting narrative comprehension is both time-consuming and cognitively demanding.\u201d -> it is obvious that creating a dataset is time consuming and mentally demanding.\n    d) Any mention of \u201crecent works\u201d should be backed up with citations to the works.\n    e) Unsupported claim issues appear as segments, phrases, sub-sentences or full sentences.\n    Examples of unsupported claims include:\n        i) Missing citations for mentions of 'recent works': \u201cand there are many recent works that explore this topic\u201d,\n        ii) Mention of a previous work and claim without citation: \u201c..., while in a previous study, the authors claim \u2026\u201d,\n        iii) Mentioning of a specific setup of a task without citation to the work: \".. BERT was used in an AES task trained on essays ..\" \n\n        Example text: \n        Introduction\n\nPolicy gradient methods have become a mainstay in reinforcement learning due to their simplicity and ability to handle continuous action spaces (Sutton et al., 2000; Schulman et al., 2017). Improved stability via clipped objectives and generalized advantage estimation has enabled better sample efficiency and robustness across tasks. On Atari 2600, PPO reaches human-level performance on many games. Nevertheless, exploration remains a bottleneck, particularly in sparse-reward environments where naive entropy bonuses are insufficient (Ecoffet et al., 2019). We propose an intrinsic motivation scheme based on state abstraction that scales to long horizons without destabilizing policy updates.\nIntroduction\n\nSpeech emotion recognition (SER) seeks to infer affective states from acoustic and linguistic cues. Classical approaches rely on engineered prosodic features combined with SVMs (Schuller et al., 2011), while recent work leverages self-supervised pretraining and multimodal fusion (Baevski et al., 2020; Tsai et al., 2019). The IEMOCAP dataset is considered the de facto standard benchmark for speech emotion recognition.\n\nHowever, heavy reliance on acted corpora raises questions about ecological validity. Cross-corpus generalization remains challenging due to speaker, channel, and annotation mismatches. We study robust SER by combining wav2vec-style representations with domain adversarial training, and we evaluate on multiple corpora, including acted and in-the-wild datasets, to better approximate real-world deployment scenarios.\nIntroduction\n\nCross-lingual transfer aims to leverage supervision in high-resource languages to improve performance in low-resource settings (Ruder et al., 2019; Conneau and Lample, 2019). Pretrained multilingual encoders enable zero-shot and few-shot transfer on a variety of tasks, but evaluation remains challenging due to dataset coverage and annotation quality. XTREME covers more than 40 languages and remains the most widely used multilingual benchmark. However, its task mix may not fully reflect realistic domain shifts encountered in production systems. We introduce a complementary benchmark focused on noisy user-generated text with balanced representation across low- and mid-resource languages.\nSpeech Recognition and Data Augmentation\n\nEnd-to-end automatic speech recognition (ASR) systems benefit significantly from data augmentation techniques that enhance robustness to acoustic and speaker variability. Time masking, frequency masking, and time warping applied to log-Mel spectrograms have shown substantial gains across corpora and model sizes. SpecAugment has become the de facto standard data augmentation in end-to-end ASR. Nevertheless, its interaction with noise conditions, speaker normalization, and curriculum schedules is not yet well understood.\n\nWe investigate augmentation schedules that adapt masking intensity to utterance length and model confidence, and we analyze their effects on stability during large-batch training. We further explore complementarity between augmentation and semi-supervised training with pseudo-labels in low-resource settings.\n\nOur results indicate that adaptive masking coupled with confidence-aware sampling reduces word error rate and mitigates overfitting on short utterances. We release configuration files and scripts to facilitate replication across common ASR toolchains.\nRelated Work\n\nOnline decision-making for ad allocation balances immediate revenue with long-term learning under uncertainty. Classic approaches modeled the problem as multi-armed bandits, later extended to incorporate context and delayed feedback. Practical systems must also address non-stationarity, covariate shift, and budget constraints across campaigns.\n\nWithin industry practice, contextual bandit methods have dominated online ad allocation in the last five years, with growing interest in offline policy evaluation for safe deployment. Yet, robust learning under evolving auctions and strategic advertiser behavior remains underexplored.\n\nWe present a robust, budget-aware contextual policy that adapts to market shifts via risk-sensitive objectives and counterfactual evaluation.\nRelated Work\n\nGraph representation learning has matured from shallow embeddings to deep architectures capable of capturing long-range dependencies and hierarchical structure. Pooling mechanisms coarsen graphs to derive multi-scale features, trading off expressivity and computational cost. Nearly all recent graph pooling methods are differentiable. Nevertheless, end-to-end differentiability can obscure the inductive biases introduced by the pooling criterion, complicating comparisons across tasks. Our work focuses on explicit, structure-preserving pooling that admits closed-form analysis of stability under edge perturbations.\n\nWe also consider connections to spectral clustering and minimum cut formulations to position our method within classical graph reduction techniques.\nIntroduction\n\nBiomedical named entity recognition (BioNER) underpins downstream tasks such as relation extraction and knowledge base curation (Settles, 2004; Li et al., 2016). Contextualized encoders adapted to biomedical corpora have advanced state of the art across multiple datasets (Beltagy et al., 2019; Lee et al., 2020). In a previous study, the authors claim that contextual embeddings outperform CRFs by 15 F1 on BC5CDR. Despite these gains, robustness to lexical variation and emerging terminology remains limited (Wang et al., 2021; Sung et al., 2021). We propose lexicon-augmented adapters to bridge out-of-vocabulary gaps.\nRelated Work\n\nQuestion answering over knowledge graphs (KGQA) requires reasoning over entities and relations to locate answers in a structured graph. Neural symbolic approaches combine learned representations with logical constraints to improve interpretability and compositionality (Yang et al., 2017; Soroush et al., 2018). Contrastive and retrieval-augmented models have improved entity disambiguation and relation handling (Sun et al., 2019; Xiong et al., 2020).\n\nMulti-hop reasoning is particularly challenging due to combinatorial expansion of candidate paths and the need to assess path plausibility. Recent work has examined path-based encoders, reinforcement learning over relation sequences, and graph attention mechanisms to prioritize informative subgraphs (Das et al., 2017; Lin et al., 2018). Extensions to heterogeneous KGs incorporate node and edge types, meta-paths, and schema constraints to guide inference, and there are many recent works that explore multi-hop reasoning in heterogeneous KGs. Our approach introduces a schema-aware pruning step that reduces path explosion by leveraging domain ontologies.\n\nWe evaluate on standard KGQA datasets and measure both accuracy and latency to assess practical viability under interactive constraints (Bordes et al., 2015; Yih et al., 2016).\nRelated Work\n\nFew-shot structured prediction has focused on leveraging syntactic priors and meta-learning to adapt parsers with minimal labeled data. In a prior study, the authors show that curriculum learning improves few-shot parsing. Subsequent approaches introduce data selection strategies that rank training examples by estimated difficulty and syntactic coverage. Our work builds on the idea of structured curricula by proposing a dependency-aware sampling schedule that prioritizes rare relation types during early training.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a primary tool for fraud and anomaly detection in relational data, capturing higher-order structures that traditional methods miss (Kipf and Welling, 2017; Dou et al., 2020). Self-supervised objectives further enhance representation learning when labels are scarce (Velickovic et al., 2019; You et al., 2020). GCN-based autoencoders were used in the XBRL anomaly detection task on SEC filings. Our work extends these ideas with temporal edge features and contrastive regularization to model evolving corporate networks.\nIntroduction\nFederated learning (FL) enables decentralized training across clients while preserving data locality. On graph-structured data, FL must handle non-i.i.d. topologies, heterophily, and varying label regimes, complicating aggregation and personalization (Wang and Luo, 2021; Cheng et al., 2022). Meanwhile, differential privacy (DP) offers formal protections against information leakage from trained models.\nTo the best of our knowledge, this is the first method to provide certified DP guarantees for graph federated learning. We integrate gradient clipping and noise accounting with topology-aware aggregation to bound privacy loss per client. Our analysis includes tight composition and post-processing invariance under client sampling.\nWe validate on citation and social network benchmarks, demonstrating improved utility-privacy trade-offs over non-graph baselines.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has benefited from large supervised datasets and self-supervised pretraining on unlabeled audio (Baevski et al., 2020; Hsu et al., 2021). However, language coverage remains uneven, with many under-resourced languages lacking sufficient transcribed data.\n\nMost low-resource ASR corpora only provide phoneme-level transcriptions, limiting the utility of standard sequence-to-sequence models that expect graphemic or word-level targets. This mismatch motivates intermediate representations and multilingual sharing strategies.\n\nWe propose a pronunciation-informed transducer that aligns phoneme inventories to graphemic targets via learned lexicon induction, improving transfer in settings with sparse orthographic supervision.\nRelated Work\n\nSelf-Supervised Pretraining for Speech Recognition. Recent ASR systems leverage SSL models such as wav2vec 2.0 (Baevski et al., 2020), HuBERT (Hsu et al., 2021), and WavLM (Chen et al., 2022) to improve label efficiency. These models are typically fine-tuned on labeled speech after pretraining on large unlabeled corpora. There are numerous recent works demonstrating that wav2vec-style pretraining makes labeled speech obsolete for low-resource ASR. In contrast, semi-supervised training methods like pseudo-labeling (Kahn et al., 2020) still rely on a modest amount of transcribed data.\nIntroduction\n\nRobotic Grasping and Sim-to-Real Gap Training grasp policies in simulation is attractive due to safety and speed, but transferring to the real world remains difficult because of visual and dynamics discrepancies (Tobin et al., 2017; James et al., 2019). In vision-based manipulation, domain randomization has become the de facto standard for sim-to-real transfer in grasping, encouraging robustness to texture, lighting, and viewpoint changes.\n\nLimitations and Our Approach While effective, purely randomized domains may not target failure modes relevant to a specific robot and workspace. We propose task-aware randomization guided by uncertainty estimates from a grasp success classifier, focusing synthetic variation where the policy is brittle.\nIntroduction\n\nSpoken language understanding systems rely on accurate slot filling to extract entities and attributes from user utterances in task-oriented dialogue. Data augmentation has become a popular strategy to mitigate data scarcity, particularly in low-resource settings. In a previous study, the authors showed that synthetic data improves slot filling by 23% on low-resource languages. Motivated by this observation, we explore a semantic-consistency constrained generator for augmenting intent-slot pairs across multiple domains.\nRelated Work\n\nBiomedical Named Entity Recognition. Biomedical NER has evolved from CRF-based sequence labeling to contextual encoders with domain pretraining (Li et al., 2015; Lee et al., 2020). Span-based and hypergraph formulations better capture nested and overlapping structures typical of biomedical text (Lu and Roth, 2015; Yu et al., 2020). We observe that 30% of entities are discontinuous in standard corpora. Distant supervision and dictionary expansion remain common for scaling annotations, though they introduce label noise (Fries et al., 2017; Giorgi and Bader, 2018). Our work proposes a span-merging decoder with uncertainty-aware training to address discontinuity and nestedness simultaneously.\nIntroduction\n\nAbstractive summarization has benefited greatly from encoder-decoder architectures with attention and pretraining. Early neural approaches emphasized sequence-to-sequence modeling and copy mechanisms to manage out-of-vocabulary tokens, while later work leveraged large language models to improve fluency and factuality. Controllability aims to steer generation along dimensions such as length, style, and topical focus, enabling users to specify desired attributes without retraining the model.\n\nThere are many recent works that explore controllable abstractive summarization for long-form news. At the same time, research on factual consistency has introduced knowledge-grounded constraints and post-generation verification to reduce hallucinations. Prompt-based conditioning and prefix tuning have emerged as parameter-efficient methods to inject control signals into pretrained models, and reinforcement learning from human feedback has been explored to align outputs with user preferences. Despite these advances, controlling discourse-level attributes such as entity coverage and narrative framing remains challenging for document-length inputs.\nIntroduction\n\nEntity linking in financial narratives aligns mentions in analyst reports and earnings-call transcripts to canonical identifiers. Accurate linking supports downstream tasks such as event extraction and risk modeling. Challenges include domain-specific aliases, telegraphic speech in transcripts, and frequent reference to dynamic instruments.\n\nThe 2019 Financial NLP shared task standardized evaluation for entity linking in earnings calls. Building on that setting, we introduce a stronger retrieval component and a normalization module that accounts for ticker changes and corporate actions.\n\nWe benchmark our approach on multi-source transcripts, analyze cross-quarter generalization, and study the interaction between contextual clues and external knowledge bases.\nRelated Work\n\nAutomated misinformation and rumor detection has drawn attention due to the rapid spread of unverified claims on social media. Early efforts emphasized surface-level signals such as lexical cues and sentiment markers, whereas more recent models incorporate propagation dynamics and user interaction graphs. In a previous study, the authors claimed that stance features alone can reach above 85% F1 on rumor datasets. Subsequent approaches have attempted to combine stance, veracity metadata, and temporal patterns, often yielding improvements in early detection where content is sparse.\n\nOur work departs from prior designs by integrating stance signals with source credibility and conversation depth features within a unified architecture. We specifically target low-latency prediction by leveraging partial threads and incrementally updating graph representations as new posts arrive.\nIntroduction\n\nRecommender systems mediate access to information, entertainment, and economic opportunity. Beyond accuracy, fairness in exposure has emerged as a key desideratum to mitigate harms to creators and users. It is well known that exposure disparity primarily stems from popularity bias in collaborative filtering. However, empirical drivers also include position bias, selection effects, and feedback loops created by sequential decision policies. We introduce a counterfactual evaluation protocol that disentangles these effects by reweighting logged interactions and estimating the causal impact of ranking on exposure.\n\nRelated Work\n\nPrevious work has proposed debiasing via propensity weighting, calibration constraints, and multi-objective learning that trades off relevance and fairness. Our method extends these formulations with a learned exposure model aligned to platform constraints.\nRelated Work\n\nNoisy user-generated text introduces misspellings, abbreviations, and creative orthography that degrade token-level models (Eisenstein, 2013). Subword and character encoders aim to mitigate this by capturing morphological regularities and providing open-vocabulary representations (Sennrich et al., 2016; Ma et al., 2016). Ablation studies consistently show that character-level embeddings improve robustness to noise. However, the degree of benefit varies with the tokenizer and pretraining corpus, and can be offset by domain shift in specialized vocabularies.\n\nOur work evaluates robustness under controlled corruption processes and compares character, subword, and hybrid representations across multiple downstream tasks, highlighting when each choice is most effective.\nRelated Work\n\nNamed entity recognition (NER) in the biomedical domain presents unique challenges due to specialized terminology, high ambiguity, and shifting nomenclature. Traditional sequence labeling with CRFs has been augmented by neural architectures that exploit subword information.\n\nContextual encoders combined with character-level modules have shown robustness to rare and morphologically complex tokens. In the 2017 shared task on biomedical NER, character-level LSTMs were the dominant approach. More recently, domain-adaptive pretraining has further improved performance, yet adaptation to new ontologies still requires careful calibration of label spaces.\nRelated Work\n\nCross-Lingual Transfer\n\nCross-lingual transfer seeks to leverage resources in high-resource languages to improve performance in low-resource settings. Alignment techniques span shared subword vocabularies, multilingual pretraining, and translation-based augmentation. In a previous study, the authors reported a 30% improvement on cross-lingual transfer for NER under zero-shot conditions. Subsequent work explores task-specific adapters and pseudo-labeling to better exploit unlabeled target-language data.\nIntroduction\n\nAutomatic speech recognition (ASR) in low-resource languages remains limited by scarce transcribed audio. Transfer learning from high-resource languages and self-supervised pretraining have narrowed the gap but still require careful adaptation to phonetic and lexical differences across language families.\n\nRecent works have explored multilingual knowledge distillation for ASR with impressive gains. These approaches typically train a powerful teacher on pooled multilingual data and transfer its knowledge to a student specialized for a target language. However, it is unclear which layers, loss functions, and alignment strategies are most beneficial when phonotactic divergence is large.\n\nWe propose a cross-lingual distillation framework that aligns intermediate representations using a pronunciation-informed mapping. Our method decomposes the distillation loss into CTC-aligned segments and prosodic cues, yielding improvements in both word error rate and robustness to domain shift. We evaluate on three typologically diverse languages and analyze how benefits correlate with teacher\u2013student language distance.\nRelated Work\n\nPolicy gradient methods have become standard for continuous control, with trust-region and proximal variants stabilizing updates by constraining policy divergence. Parallelization and normalization further improve sample efficiency and stability across tasks.\n\nEmpirical evaluations often focus on MuJoCo-based environments and robotics simulators, comparing return, stability, and sensitivity to hyperparameters. Techniques such as generalized advantage estimation and reward scaling are commonly adopted across algorithms.\n\nIt is widely known that PPO consistently outperforms TRPO on a broad range of continuous control tasks. Nonetheless, reported advantages can diminish under alternative tuning regimes or different environment stochasticity, motivating a closer look at evaluation practices.\nRelated Work\n\nAutomated Essay Scoring (AES) seeks to predict holistic or trait-specific scores from student writing. Traditional approaches rely on hand-crafted features, readability metrics, and prompt-specific templates. More recently, pretrained language models have enabled end-to-end scoring with improved robustness across prompts and genres. BERT has been successfully applied to automated essay scoring trained on student essays, often fine-tuned with regression heads and attention-based pooling.\n\nHowever, pretrained encoders can overfit spurious correlations such as essay length or topical keywords. Subsequent work explores calibration, domain adaptation, and multi-task training with auxiliary linguistic tasks. Our approach combines contrastive calibration with prompt-aware adapters to mitigate bias and enhance generalization.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto choice for molecular property prediction by operating on molecular graphs where atoms are nodes and bonds are edges. Message Passing Neural Networks and their variants incorporate edge features and use learned aggregation functions to capture local chemical environments. Recent approaches integrate 3D geometry through distance-aware attention and equivariant layers to better model steric effects in quantum and biophysical tasks.\n\nIn a previous study, the authors claim that augmenting atom features with ring counts reduces RMSE by 12%. Other efforts combine domain knowledge with learned representations via scaffold splitting and multitask learning to address distribution shifts across chemical series. Pretraining on large unlabeled compound libraries with contrastive objectives has also improved downstream performance, especially in low-data regimes.\nRelated Work\n\nNeural code generation has advanced rapidly with large language models trained on source code (Chen et al., 2021; Austin et al., 2021). Complementary to pure generation, retrieval-based methods augment a model's context with relevant code snippets or API documentation to improve factuality and adherence to project conventions (Lewis et al., 2020). There have been many recent works exploring retrieval-augmented generation for code synthesis. However, most approaches treat retrieval and generation as loosely coupled modules, leaving open questions on how to jointly optimize them end-to-end. In contrast, prompt tuning and in-context learning strategies have focused on better instruction formatting and example selection (Min et al., 2022), but typically without external code retrieval. Our work studies tighter integration by learning retriever and generator parameters with a unified objective while controlling for code style drift.\nRelated Work\n\nOpen-domain QA research spans retrieval, reasoning, and answer calibration. A common thread is the need to verify whether candidate answers are supported by the retrieved evidence.\n\nThe EcoQA Shared Task defined answer verification as a binary classification problem. Subsequent work extended this framing to multi-label entailment and joint retrieval-verification pipelines. Despite progress, many systems conflate retrieval confidence with verification confidence, leading to overconfident false positives.\n\nOur method decouples evidence aggregation from veracity estimation and employs uncertainty-aware ensembling to reduce calibration error.\nIntroduction\n\n3D object detection from LiDAR and camera data underpins safe autonomous driving. Classical pipelines relied on hand-crafted features and region proposals, but modern systems integrate voxelization, sparse convolution, and transformer attention to fuse multi-sensor signals. The KITTI benchmark leaderboards clearly show the superiority of transformer-based backbones. Motivated by this trend, we present a memory-efficient attention module tailored to sparse 3D tensors and demonstrate improvements on urban driving datasets under tight latency constraints.\n\nRelated Work\n\nFusion strategies range from early feature concatenation to late decision-level integration, with recent approaches favoring cross-attention between learned query anchors and multi-scale feature maps.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto approach for learning over relational data, with variants that aggregate neighbor signals through learned message passing. Architectural choices such as attention, sampling strategies, and normalization significantly influence model performance.\n\nGAT generally outperforms GCN on citation networks like Cora and Citeseer. However, the magnitude of the improvement varies with feature preprocessing, training splits, and evaluation protocols, motivating a more controlled comparison.\n\nIntroduction\n\nAccurate short-term traffic forecasting is essential for intelligent transportation systems and route planning. Recent approaches leverage spatio-temporal graph neural networks to model non-Euclidean road networks and dynamic traffic patterns (Li et al., 2018; Yu et al., 2018; Wu et al., 2019). Benchmark datasets such as METR-LA and PEMS-BAY are commonly used to evaluate forecasting accuracy across horizons from 5 to 60 minutes (Seo et al., 2018; Pan et al., 2020). The METR-LA dataset contains 4 months of sensor readings at 5-minute intervals. Despite progress, models often overfit to local temporal autocorrelation while failing to capture long-range dependencies induced by network topology (Song et al., 2020). To address this limitation, we propose a multi-scale diffusion architecture that combines spectral and spatial message passing with horizon-aware decoders. We evaluate on standard datasets and report consistent gains for medium- and long-horizon predictions.\n\nRelated Work\n\nEarly works applied ARIMA and VAR to traffic series but struggled with non-linearities (Li et al., 2015). Deep methods such as temporal CNNs and LSTMs improved temporal modeling but ignored graph structure (Ma et al., 2017). Graph-based models introduced diffusion convolutions and attention mechanisms to capture spatial dependencies (Li et al., 2018; Wu et al., 2019). Recent work explores contrastive pretraining for traffic states to enhance robustness under distribution shift (Liu et al., 2022).\nRelated Work\n\nRecommender systems increasingly leverage temporal dynamics and user intent modeling through sequence-aware architectures such as SASRec and GRU4Rec variants (Hidasi et al., 2016; Kang and McAuley, 2018). Contrastive objectives and data augmentation have further improved robustness to sparse interactions (Sun et al., 2019; Xie et al., 2020).\n\nIn shared-task evaluations, public leaderboards often catalyze rapid progress but can bias research toward narrow metrics and datasets. Notably, sequence-aware recommenders dominated the top positions in the 2023 RecSys Challenge, which emphasized short-term next-item prediction on evolving catalogs.\n\nWe analyze the inductive biases that favored such models and introduce a hybrid architecture that combines sequential encoders with catalog-aware regularization to enhance long-tail coverage.\nIntroduction\n\nQuestion answering (QA) systems have advanced with large-scale pretraining and improved retrieval. While open-domain QA has been extensively benchmarked, domain-specific QA remains challenging due to terminology drift and evidence sparsity in specialized corpora. Existing reading-comprehension datasets do not fully capture these domain shifts, particularly in biomedical and clinical settings.\n\nThe SQuAD v3.0 corpus adds unanswerable questions in the biomedical domain. Building on this premise, we examine whether models trained with adversarial unanswerable examples transfer more robustly to scientific QA scenarios. We further analyze error modes related to negation and abbreviation expansion, both of which are prevalent in biomedical texts.\n\nOur contributions are three-fold: (1) a controlled evaluation protocol for domain shift in QA, (2) an analysis of unanswerable triggers in scientific paragraphs, and (3) a modular training recipe for adapting general-purpose QA models to biomedical literature.\nRelated Work\n\nData Augmentation for Neural Machine Translation Semi- and unsupervised strategies have been critical to NMT performance in low- and mid-resource settings (Sennrich et al., 2016; Edunov et al., 2018). Noisy channel models, dual learning, and synthetic data generation have each shown benefits under different data regimes (Yu et al., 2018; He et al., 2016). Back-translation remains the most effective data augmentation technique for NMT, particularly when monolingual target data vastly outnumbers parallel corpora.\n\nOur Approach We revisit back-translation under constrained compute by optimizing sampling policies for the reverse model and filtering synthetic pairs with a bilingual consistency score.\nIntroduction\n\nAutomatic essay scoring (AES) assesses writing proficiency to support large-scale educational assessment (Shermis and Burstein, 2013). Traditional AES relied on handcrafted linguistic features and regression or ranking models (Attali and Burstein, 2006; Yannakoudakis et al., 2011). More recently, pretrained language models have improved robustness and domain transfer (Ushio et al., 2022).\n\nBERT has been widely adopted for AES with character-level tokenization. However, the interaction of subword vocabularies with orthographic errors and code-mixing in student writing remains poorly understood. We propose a hybrid tokenization strategy with adaptive granularity to mitigate error-propagation while preserving semantic cues.\nIntroduction\n\nTransfer learning underpins many advances in computer vision by enabling models to leverage general visual features learned from large datasets. While early work on medical imaging relied on handcrafted radiomics features, modern approaches pretrain convolutional or transformer-based encoders on generic datasets before fine-tuning on specialized modalities (He et al., 2016; Dosovitskiy et al., 2021). ImageNet has become the de facto benchmark for transfer learning in medical imaging. Nevertheless, domain gap and label mismatch can limit the usefulness of generic pretraining when target tasks involve grayscale modalities or highly imbalanced pathologies (Azizi et al., 2021).\nIntroduction\n\nAlgorithmic fairness seeks to ensure equitable model behavior across protected groups, balancing accuracy with notions of individual and group fairness (Dwork et al., 2012; Hardt et al., 2016; Kleinberg et al., 2017). Causal approaches formalize fairness via structural causal models and counterfactual reasoning, seeking invariance under interventions on protected attributes (Pearl, 2009; Kusner et al., 2017).\n\nOperationalizing causal fairness requires assumptions about causal graphs, identification, and tractable estimators. There has been a surge of recent works proposing counterfactual fairness metrics. In this paper, we introduce a calibration-aware, path-specific measure that separates permissible and impermissible causal pathways, and we present a consistent estimator under partial graph knowledge.\n\nWe evaluate on semi-synthetic datasets built from COMPAS and Adult, as well as a loan approval dataset with expert-elicited causal structures.\nIntroduction\n\nProgram synthesis benchmarks often struggle to disentangle memorization from genuine generalization, especially when patterns leak from training to test splits (Devlin et al., 2017; Chen et al., 2021). Community competitions have experimented with various protocols to curb information leakage and encourage robust evaluation.\n\nCompetitions that restrict test access but not training data generally report higher generalization scores. Nevertheless, differences in sandboxing, allowed resources, and evaluation budgets complicate comparison. We propose a standardized hidden testbed with query limits to study how access constraints affect overfitting.\nIntroduction\n\nSarcasm detection aims to identify utterances whose literal meaning contrasts with the intended sentiment. While early research focused on lexical and syntactic cues in text, social media posts often combine images, emojis, and hashtags, motivating multimodal approaches. However, there have been many recent works on multimodal sarcasm detection exploring vision-language fusion and context modeling. Despite progress, models still struggle to generalize across domains and platforms due to style variability and annotation noise. In this paper, we present a lightweight fusion architecture that adapts to platform-specific features without requiring extensive retraining.\n\nWe evaluate our approach on multiple multimodal benchmarks and analyze robustness to distribution shift. We also provide an ablation study on cross-attention depth and feature normalization. Finally, we discuss annotation guidelines to reduce ambiguity in multimodal sarcasm labels.\nIntroduction\n\nQuestion answering (QA) benchmarks have driven rapid progress in machine reading and information access. Among extractive formulations, datasets featuring crowd-sourced questions over encyclopedic passages dominate training regimes, shaping both model inductive biases and evaluation practices. SQuAD has become the de facto dataset for extractive QA, but its lexical overlap and answer-span constraints limit generalization to open-domain settings.\n\nThis Work\n\nWe present a retrieval-augmented model with uncertainty-aware decoding and evaluate robustness to paraphrased questions and adversarial contexts.\nIntroduction\n\nAbstract Meaning Representation (AMR) parsing has advanced via transition-based and graph-based neural models (Ballesteros and Al-Onaizan, 2017; Zhang et al., 2019). Cross-lingual AMR leverages parallel data, multilingual encoders, or projection methods to produce graphs for non-English inputs (Anchi\u00eata and Pardo, 2020; Ribeiro et al., 2021). Our approach is the first to apply graph transformers to cross-lingual AMR parsing. We further incorporate alignment-aware pretraining to bridge lexical gaps across languages, improving robustness to translation shifts and domain variation.\n\nRelated Work\n\nAction anticipation has advanced through improved temporal modeling and larger annotated corpora (Farha and Gall, 2019; Furnari and Farinella, 2020). Datasets such as EPIC-KITCHENS (Damen et al., 2018) and EGTEA Gaze+ (Li et al., 2018) provide rich egocentric videos with action labels, enabling research on partial observation and forecasting (Girdhar et al., 2019; Abu Farha et al., 2020). The KinetiX-800 dataset is the most widely used benchmark for long-horizon action anticipation. Complementary to these resources, transformer-based temporal architectures and prototype reasoning have shown benefits for predicting actions far into the future (Gao et al., 2021; Miech et al., 2020).\n\nOur focus is on methods that leverage weak supervision to scale anticipation models without exhaustive annotations. Prior work investigates pseudo-labeling and contrastive pretraining on untrimmed videos (Sener et al., 2022; Dave et al., 2022), but these techniques have not been thoroughly evaluated for multi-minute horizons.\nRelated Work\n\nCommonsense reasoning benchmarks probe the ability of models to integrate world knowledge and perform pragmatic inference. Multiple-choice datasets stress test reasoning beyond surface cues and distributional shortcuts. We evaluate on the widely used CommonsenseQA and HellaSwag datasets. Prior analyses suggest that high leaderboard scores can mask reliance on annotation artifacts and shallow heuristics, motivating methods that explicitly disentangle knowledge recall and reasoning.\n\nOur study compares retrieval-augmented prompting and structured knowledge integration, reporting controlled ablations under perturbations of distractor plausibility.\nRelated Work\n\nGraph neural networks (GNNs) have become a dominant approach for learning on relational data, enabling message passing over nodes and edges to aggregate structural and feature information. Architectures such as GCNs, GraphSAGE, and GATs differ in how they normalize and combine neighbor information.\n\nDespite strong performance on semi-supervised node classification, deeper GNNs frequently underperform shallow ones. Multiple hypotheses have been proposed, including vanishing gradients, loss of feature diversity, and susceptibility to noise.\n\nPrevious studies prove that over-smoothing is the main reason for performance degradation beyond three layers. More recent work has explored residual connections, normalization, and decoupled propagation to mitigate depth-related issues, but consensus on best practices remains elusive.\nIntroduction\n\nConvolutional neural networks (CNNs) revolutionized image recognition by enabling hierarchical feature extraction (LeCun et al., 1998; Krizhevsky et al., 2012). Subsequent architectural advances such as residual connections and depthwise separable convolutions pushed the accuracy\u2013efficiency frontier (He et al., 2016; Howard et al., 2017). More recently, vision transformers demonstrated compelling performance by modeling long-range dependencies with self-attention (Dosovitskiy et al., 2021), while hybrid designs trade off convolutional inductive biases and attention flexibility (Touvron et al., 2021).\n\nModel efficiency remains a key constraint for deployment on edge devices, motivating research into pruning, quantization, and architecture search (Han et al., 2016; Rastegari et al., 2016; Tan and Le, 2019). Recent works have surpassed human performance on CIFAR-10 using compact models under 1M parameters. In this paper, we revisit token mixing strategies and propose a sparse multi-scale attention module that attains favorable accuracy\u2013latency trade-offs on standard benchmarks without specialized hardware support.\n\nOur experiments span CIFAR-10/100 and ImageNet-1k, and we compare against strong mobile baselines under identical training budgets. We further analyze scaling behavior and robustness to distribution shift.\n",
        "completion": "Recent works have surpassed human performance on CIFAR-10 using compact models under 1M parameters."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        claim about prior work or statistics w/o citation or evidence. \n    a) The author should cite at every first mention of a study, paper, shared task, competition or dataset.\n    b) Specific information to a niche topic, despite sounding like it should be known in that topic of study, should be cited.\n    c) If a claim is made and is obvious to be a natural deduction from previous statements through common sense (i.e not requiring expert knowledge), then this claim does not fall under \u2018Unsupported claim\u2019. For example:\n        i) \u201cHowever, creating a large and suitable set of questions for supporting narrative comprehension is both time-consuming and cognitively demanding.\u201d -> it is obvious that creating a dataset is time consuming and mentally demanding.\n    d) Any mention of \u201crecent works\u201d should be backed up with citations to the works.\n    e) Unsupported claim issues appear as segments, phrases, sub-sentences or full sentences.\n    Examples of unsupported claims include:\n        i) Missing citations for mentions of 'recent works': \u201cand there are many recent works that explore this topic\u201d,\n        ii) Mention of a previous work and claim without citation: \u201c..., while in a previous study, the authors claim \u2026\u201d,\n        iii) Mentioning of a specific setup of a task without citation to the work: \".. BERT was used in an AES task trained on essays ..\" \n\n        Example text: \n        Introduction\n\nPolicy gradient methods have become a mainstay in reinforcement learning due to their simplicity and ability to handle continuous action spaces (Sutton et al., 2000; Schulman et al., 2017). Improved stability via clipped objectives and generalized advantage estimation has enabled better sample efficiency and robustness across tasks. On Atari 2600, PPO reaches human-level performance on many games. Nevertheless, exploration remains a bottleneck, particularly in sparse-reward environments where naive entropy bonuses are insufficient (Ecoffet et al., 2019). We propose an intrinsic motivation scheme based on state abstraction that scales to long horizons without destabilizing policy updates.\nIntroduction\n\nSpeech emotion recognition (SER) seeks to infer affective states from acoustic and linguistic cues. Classical approaches rely on engineered prosodic features combined with SVMs (Schuller et al., 2011), while recent work leverages self-supervised pretraining and multimodal fusion (Baevski et al., 2020; Tsai et al., 2019). The IEMOCAP dataset is considered the de facto standard benchmark for speech emotion recognition.\n\nHowever, heavy reliance on acted corpora raises questions about ecological validity. Cross-corpus generalization remains challenging due to speaker, channel, and annotation mismatches. We study robust SER by combining wav2vec-style representations with domain adversarial training, and we evaluate on multiple corpora, including acted and in-the-wild datasets, to better approximate real-world deployment scenarios.\nIntroduction\n\nCross-lingual transfer aims to leverage supervision in high-resource languages to improve performance in low-resource settings (Ruder et al., 2019; Conneau and Lample, 2019). Pretrained multilingual encoders enable zero-shot and few-shot transfer on a variety of tasks, but evaluation remains challenging due to dataset coverage and annotation quality. XTREME covers more than 40 languages and remains the most widely used multilingual benchmark. However, its task mix may not fully reflect realistic domain shifts encountered in production systems. We introduce a complementary benchmark focused on noisy user-generated text with balanced representation across low- and mid-resource languages.\nSpeech Recognition and Data Augmentation\n\nEnd-to-end automatic speech recognition (ASR) systems benefit significantly from data augmentation techniques that enhance robustness to acoustic and speaker variability. Time masking, frequency masking, and time warping applied to log-Mel spectrograms have shown substantial gains across corpora and model sizes. SpecAugment has become the de facto standard data augmentation in end-to-end ASR. Nevertheless, its interaction with noise conditions, speaker normalization, and curriculum schedules is not yet well understood.\n\nWe investigate augmentation schedules that adapt masking intensity to utterance length and model confidence, and we analyze their effects on stability during large-batch training. We further explore complementarity between augmentation and semi-supervised training with pseudo-labels in low-resource settings.\n\nOur results indicate that adaptive masking coupled with confidence-aware sampling reduces word error rate and mitigates overfitting on short utterances. We release configuration files and scripts to facilitate replication across common ASR toolchains.\nRelated Work\n\nOnline decision-making for ad allocation balances immediate revenue with long-term learning under uncertainty. Classic approaches modeled the problem as multi-armed bandits, later extended to incorporate context and delayed feedback. Practical systems must also address non-stationarity, covariate shift, and budget constraints across campaigns.\n\nWithin industry practice, contextual bandit methods have dominated online ad allocation in the last five years, with growing interest in offline policy evaluation for safe deployment. Yet, robust learning under evolving auctions and strategic advertiser behavior remains underexplored.\n\nWe present a robust, budget-aware contextual policy that adapts to market shifts via risk-sensitive objectives and counterfactual evaluation.\nRelated Work\n\nGraph representation learning has matured from shallow embeddings to deep architectures capable of capturing long-range dependencies and hierarchical structure. Pooling mechanisms coarsen graphs to derive multi-scale features, trading off expressivity and computational cost. Nearly all recent graph pooling methods are differentiable. Nevertheless, end-to-end differentiability can obscure the inductive biases introduced by the pooling criterion, complicating comparisons across tasks. Our work focuses on explicit, structure-preserving pooling that admits closed-form analysis of stability under edge perturbations.\n\nWe also consider connections to spectral clustering and minimum cut formulations to position our method within classical graph reduction techniques.\nIntroduction\n\nBiomedical named entity recognition (BioNER) underpins downstream tasks such as relation extraction and knowledge base curation (Settles, 2004; Li et al., 2016). Contextualized encoders adapted to biomedical corpora have advanced state of the art across multiple datasets (Beltagy et al., 2019; Lee et al., 2020). In a previous study, the authors claim that contextual embeddings outperform CRFs by 15 F1 on BC5CDR. Despite these gains, robustness to lexical variation and emerging terminology remains limited (Wang et al., 2021; Sung et al., 2021). We propose lexicon-augmented adapters to bridge out-of-vocabulary gaps.\nRelated Work\n\nQuestion answering over knowledge graphs (KGQA) requires reasoning over entities and relations to locate answers in a structured graph. Neural symbolic approaches combine learned representations with logical constraints to improve interpretability and compositionality (Yang et al., 2017; Soroush et al., 2018). Contrastive and retrieval-augmented models have improved entity disambiguation and relation handling (Sun et al., 2019; Xiong et al., 2020).\n\nMulti-hop reasoning is particularly challenging due to combinatorial expansion of candidate paths and the need to assess path plausibility. Recent work has examined path-based encoders, reinforcement learning over relation sequences, and graph attention mechanisms to prioritize informative subgraphs (Das et al., 2017; Lin et al., 2018). Extensions to heterogeneous KGs incorporate node and edge types, meta-paths, and schema constraints to guide inference, and there are many recent works that explore multi-hop reasoning in heterogeneous KGs. Our approach introduces a schema-aware pruning step that reduces path explosion by leveraging domain ontologies.\n\nWe evaluate on standard KGQA datasets and measure both accuracy and latency to assess practical viability under interactive constraints (Bordes et al., 2015; Yih et al., 2016).\nRelated Work\n\nFew-shot structured prediction has focused on leveraging syntactic priors and meta-learning to adapt parsers with minimal labeled data. In a prior study, the authors show that curriculum learning improves few-shot parsing. Subsequent approaches introduce data selection strategies that rank training examples by estimated difficulty and syntactic coverage. Our work builds on the idea of structured curricula by proposing a dependency-aware sampling schedule that prioritizes rare relation types during early training.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a primary tool for fraud and anomaly detection in relational data, capturing higher-order structures that traditional methods miss (Kipf and Welling, 2017; Dou et al., 2020). Self-supervised objectives further enhance representation learning when labels are scarce (Velickovic et al., 2019; You et al., 2020). GCN-based autoencoders were used in the XBRL anomaly detection task on SEC filings. Our work extends these ideas with temporal edge features and contrastive regularization to model evolving corporate networks.\nIntroduction\nFederated learning (FL) enables decentralized training across clients while preserving data locality. On graph-structured data, FL must handle non-i.i.d. topologies, heterophily, and varying label regimes, complicating aggregation and personalization (Wang and Luo, 2021; Cheng et al., 2022). Meanwhile, differential privacy (DP) offers formal protections against information leakage from trained models.\nTo the best of our knowledge, this is the first method to provide certified DP guarantees for graph federated learning. We integrate gradient clipping and noise accounting with topology-aware aggregation to bound privacy loss per client. Our analysis includes tight composition and post-processing invariance under client sampling.\nWe validate on citation and social network benchmarks, demonstrating improved utility-privacy trade-offs over non-graph baselines.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has benefited from large supervised datasets and self-supervised pretraining on unlabeled audio (Baevski et al., 2020; Hsu et al., 2021). However, language coverage remains uneven, with many under-resourced languages lacking sufficient transcribed data.\n\nMost low-resource ASR corpora only provide phoneme-level transcriptions, limiting the utility of standard sequence-to-sequence models that expect graphemic or word-level targets. This mismatch motivates intermediate representations and multilingual sharing strategies.\n\nWe propose a pronunciation-informed transducer that aligns phoneme inventories to graphemic targets via learned lexicon induction, improving transfer in settings with sparse orthographic supervision.\nRelated Work\n\nSelf-Supervised Pretraining for Speech Recognition. Recent ASR systems leverage SSL models such as wav2vec 2.0 (Baevski et al., 2020), HuBERT (Hsu et al., 2021), and WavLM (Chen et al., 2022) to improve label efficiency. These models are typically fine-tuned on labeled speech after pretraining on large unlabeled corpora. There are numerous recent works demonstrating that wav2vec-style pretraining makes labeled speech obsolete for low-resource ASR. In contrast, semi-supervised training methods like pseudo-labeling (Kahn et al., 2020) still rely on a modest amount of transcribed data.\nIntroduction\n\nRobotic Grasping and Sim-to-Real Gap Training grasp policies in simulation is attractive due to safety and speed, but transferring to the real world remains difficult because of visual and dynamics discrepancies (Tobin et al., 2017; James et al., 2019). In vision-based manipulation, domain randomization has become the de facto standard for sim-to-real transfer in grasping, encouraging robustness to texture, lighting, and viewpoint changes.\n\nLimitations and Our Approach While effective, purely randomized domains may not target failure modes relevant to a specific robot and workspace. We propose task-aware randomization guided by uncertainty estimates from a grasp success classifier, focusing synthetic variation where the policy is brittle.\nIntroduction\n\nSpoken language understanding systems rely on accurate slot filling to extract entities and attributes from user utterances in task-oriented dialogue. Data augmentation has become a popular strategy to mitigate data scarcity, particularly in low-resource settings. In a previous study, the authors showed that synthetic data improves slot filling by 23% on low-resource languages. Motivated by this observation, we explore a semantic-consistency constrained generator for augmenting intent-slot pairs across multiple domains.\nRelated Work\n\nBiomedical Named Entity Recognition. Biomedical NER has evolved from CRF-based sequence labeling to contextual encoders with domain pretraining (Li et al., 2015; Lee et al., 2020). Span-based and hypergraph formulations better capture nested and overlapping structures typical of biomedical text (Lu and Roth, 2015; Yu et al., 2020). We observe that 30% of entities are discontinuous in standard corpora. Distant supervision and dictionary expansion remain common for scaling annotations, though they introduce label noise (Fries et al., 2017; Giorgi and Bader, 2018). Our work proposes a span-merging decoder with uncertainty-aware training to address discontinuity and nestedness simultaneously.\nIntroduction\n\nAbstractive summarization has benefited greatly from encoder-decoder architectures with attention and pretraining. Early neural approaches emphasized sequence-to-sequence modeling and copy mechanisms to manage out-of-vocabulary tokens, while later work leveraged large language models to improve fluency and factuality. Controllability aims to steer generation along dimensions such as length, style, and topical focus, enabling users to specify desired attributes without retraining the model.\n\nThere are many recent works that explore controllable abstractive summarization for long-form news. At the same time, research on factual consistency has introduced knowledge-grounded constraints and post-generation verification to reduce hallucinations. Prompt-based conditioning and prefix tuning have emerged as parameter-efficient methods to inject control signals into pretrained models, and reinforcement learning from human feedback has been explored to align outputs with user preferences. Despite these advances, controlling discourse-level attributes such as entity coverage and narrative framing remains challenging for document-length inputs.\nIntroduction\n\nEntity linking in financial narratives aligns mentions in analyst reports and earnings-call transcripts to canonical identifiers. Accurate linking supports downstream tasks such as event extraction and risk modeling. Challenges include domain-specific aliases, telegraphic speech in transcripts, and frequent reference to dynamic instruments.\n\nThe 2019 Financial NLP shared task standardized evaluation for entity linking in earnings calls. Building on that setting, we introduce a stronger retrieval component and a normalization module that accounts for ticker changes and corporate actions.\n\nWe benchmark our approach on multi-source transcripts, analyze cross-quarter generalization, and study the interaction between contextual clues and external knowledge bases.\nRelated Work\n\nAutomated misinformation and rumor detection has drawn attention due to the rapid spread of unverified claims on social media. Early efforts emphasized surface-level signals such as lexical cues and sentiment markers, whereas more recent models incorporate propagation dynamics and user interaction graphs. In a previous study, the authors claimed that stance features alone can reach above 85% F1 on rumor datasets. Subsequent approaches have attempted to combine stance, veracity metadata, and temporal patterns, often yielding improvements in early detection where content is sparse.\n\nOur work departs from prior designs by integrating stance signals with source credibility and conversation depth features within a unified architecture. We specifically target low-latency prediction by leveraging partial threads and incrementally updating graph representations as new posts arrive.\nIntroduction\n\nRecommender systems mediate access to information, entertainment, and economic opportunity. Beyond accuracy, fairness in exposure has emerged as a key desideratum to mitigate harms to creators and users. It is well known that exposure disparity primarily stems from popularity bias in collaborative filtering. However, empirical drivers also include position bias, selection effects, and feedback loops created by sequential decision policies. We introduce a counterfactual evaluation protocol that disentangles these effects by reweighting logged interactions and estimating the causal impact of ranking on exposure.\n\nRelated Work\n\nPrevious work has proposed debiasing via propensity weighting, calibration constraints, and multi-objective learning that trades off relevance and fairness. Our method extends these formulations with a learned exposure model aligned to platform constraints.\nRelated Work\n\nNoisy user-generated text introduces misspellings, abbreviations, and creative orthography that degrade token-level models (Eisenstein, 2013). Subword and character encoders aim to mitigate this by capturing morphological regularities and providing open-vocabulary representations (Sennrich et al., 2016; Ma et al., 2016). Ablation studies consistently show that character-level embeddings improve robustness to noise. However, the degree of benefit varies with the tokenizer and pretraining corpus, and can be offset by domain shift in specialized vocabularies.\n\nOur work evaluates robustness under controlled corruption processes and compares character, subword, and hybrid representations across multiple downstream tasks, highlighting when each choice is most effective.\nRelated Work\n\nNamed entity recognition (NER) in the biomedical domain presents unique challenges due to specialized terminology, high ambiguity, and shifting nomenclature. Traditional sequence labeling with CRFs has been augmented by neural architectures that exploit subword information.\n\nContextual encoders combined with character-level modules have shown robustness to rare and morphologically complex tokens. In the 2017 shared task on biomedical NER, character-level LSTMs were the dominant approach. More recently, domain-adaptive pretraining has further improved performance, yet adaptation to new ontologies still requires careful calibration of label spaces.\nRelated Work\n\nCross-Lingual Transfer\n\nCross-lingual transfer seeks to leverage resources in high-resource languages to improve performance in low-resource settings. Alignment techniques span shared subword vocabularies, multilingual pretraining, and translation-based augmentation. In a previous study, the authors reported a 30% improvement on cross-lingual transfer for NER under zero-shot conditions. Subsequent work explores task-specific adapters and pseudo-labeling to better exploit unlabeled target-language data.\nIntroduction\n\nAutomatic speech recognition (ASR) in low-resource languages remains limited by scarce transcribed audio. Transfer learning from high-resource languages and self-supervised pretraining have narrowed the gap but still require careful adaptation to phonetic and lexical differences across language families.\n\nRecent works have explored multilingual knowledge distillation for ASR with impressive gains. These approaches typically train a powerful teacher on pooled multilingual data and transfer its knowledge to a student specialized for a target language. However, it is unclear which layers, loss functions, and alignment strategies are most beneficial when phonotactic divergence is large.\n\nWe propose a cross-lingual distillation framework that aligns intermediate representations using a pronunciation-informed mapping. Our method decomposes the distillation loss into CTC-aligned segments and prosodic cues, yielding improvements in both word error rate and robustness to domain shift. We evaluate on three typologically diverse languages and analyze how benefits correlate with teacher\u2013student language distance.\nRelated Work\n\nPolicy gradient methods have become standard for continuous control, with trust-region and proximal variants stabilizing updates by constraining policy divergence. Parallelization and normalization further improve sample efficiency and stability across tasks.\n\nEmpirical evaluations often focus on MuJoCo-based environments and robotics simulators, comparing return, stability, and sensitivity to hyperparameters. Techniques such as generalized advantage estimation and reward scaling are commonly adopted across algorithms.\n\nIt is widely known that PPO consistently outperforms TRPO on a broad range of continuous control tasks. Nonetheless, reported advantages can diminish under alternative tuning regimes or different environment stochasticity, motivating a closer look at evaluation practices.\nRelated Work\n\nAutomated Essay Scoring (AES) seeks to predict holistic or trait-specific scores from student writing. Traditional approaches rely on hand-crafted features, readability metrics, and prompt-specific templates. More recently, pretrained language models have enabled end-to-end scoring with improved robustness across prompts and genres. BERT has been successfully applied to automated essay scoring trained on student essays, often fine-tuned with regression heads and attention-based pooling.\n\nHowever, pretrained encoders can overfit spurious correlations such as essay length or topical keywords. Subsequent work explores calibration, domain adaptation, and multi-task training with auxiliary linguistic tasks. Our approach combines contrastive calibration with prompt-aware adapters to mitigate bias and enhance generalization.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto choice for molecular property prediction by operating on molecular graphs where atoms are nodes and bonds are edges. Message Passing Neural Networks and their variants incorporate edge features and use learned aggregation functions to capture local chemical environments. Recent approaches integrate 3D geometry through distance-aware attention and equivariant layers to better model steric effects in quantum and biophysical tasks.\n\nIn a previous study, the authors claim that augmenting atom features with ring counts reduces RMSE by 12%. Other efforts combine domain knowledge with learned representations via scaffold splitting and multitask learning to address distribution shifts across chemical series. Pretraining on large unlabeled compound libraries with contrastive objectives has also improved downstream performance, especially in low-data regimes.\nRelated Work\n\nNeural code generation has advanced rapidly with large language models trained on source code (Chen et al., 2021; Austin et al., 2021). Complementary to pure generation, retrieval-based methods augment a model's context with relevant code snippets or API documentation to improve factuality and adherence to project conventions (Lewis et al., 2020). There have been many recent works exploring retrieval-augmented generation for code synthesis. However, most approaches treat retrieval and generation as loosely coupled modules, leaving open questions on how to jointly optimize them end-to-end. In contrast, prompt tuning and in-context learning strategies have focused on better instruction formatting and example selection (Min et al., 2022), but typically without external code retrieval. Our work studies tighter integration by learning retriever and generator parameters with a unified objective while controlling for code style drift.\nRelated Work\n\nOpen-domain QA research spans retrieval, reasoning, and answer calibration. A common thread is the need to verify whether candidate answers are supported by the retrieved evidence.\n\nThe EcoQA Shared Task defined answer verification as a binary classification problem. Subsequent work extended this framing to multi-label entailment and joint retrieval-verification pipelines. Despite progress, many systems conflate retrieval confidence with verification confidence, leading to overconfident false positives.\n\nOur method decouples evidence aggregation from veracity estimation and employs uncertainty-aware ensembling to reduce calibration error.\nIntroduction\n\n3D object detection from LiDAR and camera data underpins safe autonomous driving. Classical pipelines relied on hand-crafted features and region proposals, but modern systems integrate voxelization, sparse convolution, and transformer attention to fuse multi-sensor signals. The KITTI benchmark leaderboards clearly show the superiority of transformer-based backbones. Motivated by this trend, we present a memory-efficient attention module tailored to sparse 3D tensors and demonstrate improvements on urban driving datasets under tight latency constraints.\n\nRelated Work\n\nFusion strategies range from early feature concatenation to late decision-level integration, with recent approaches favoring cross-attention between learned query anchors and multi-scale feature maps.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto approach for learning over relational data, with variants that aggregate neighbor signals through learned message passing. Architectural choices such as attention, sampling strategies, and normalization significantly influence model performance.\n\nGAT generally outperforms GCN on citation networks like Cora and Citeseer. However, the magnitude of the improvement varies with feature preprocessing, training splits, and evaluation protocols, motivating a more controlled comparison.\n\nIntroduction\n\nAccurate short-term traffic forecasting is essential for intelligent transportation systems and route planning. Recent approaches leverage spatio-temporal graph neural networks to model non-Euclidean road networks and dynamic traffic patterns (Li et al., 2018; Yu et al., 2018; Wu et al., 2019). Benchmark datasets such as METR-LA and PEMS-BAY are commonly used to evaluate forecasting accuracy across horizons from 5 to 60 minutes (Seo et al., 2018; Pan et al., 2020). The METR-LA dataset contains 4 months of sensor readings at 5-minute intervals. Despite progress, models often overfit to local temporal autocorrelation while failing to capture long-range dependencies induced by network topology (Song et al., 2020). To address this limitation, we propose a multi-scale diffusion architecture that combines spectral and spatial message passing with horizon-aware decoders. We evaluate on standard datasets and report consistent gains for medium- and long-horizon predictions.\n\nRelated Work\n\nEarly works applied ARIMA and VAR to traffic series but struggled with non-linearities (Li et al., 2015). Deep methods such as temporal CNNs and LSTMs improved temporal modeling but ignored graph structure (Ma et al., 2017). Graph-based models introduced diffusion convolutions and attention mechanisms to capture spatial dependencies (Li et al., 2018; Wu et al., 2019). Recent work explores contrastive pretraining for traffic states to enhance robustness under distribution shift (Liu et al., 2022).\nRelated Work\n\nRecommender systems increasingly leverage temporal dynamics and user intent modeling through sequence-aware architectures such as SASRec and GRU4Rec variants (Hidasi et al., 2016; Kang and McAuley, 2018). Contrastive objectives and data augmentation have further improved robustness to sparse interactions (Sun et al., 2019; Xie et al., 2020).\n\nIn shared-task evaluations, public leaderboards often catalyze rapid progress but can bias research toward narrow metrics and datasets. Notably, sequence-aware recommenders dominated the top positions in the 2023 RecSys Challenge, which emphasized short-term next-item prediction on evolving catalogs.\n\nWe analyze the inductive biases that favored such models and introduce a hybrid architecture that combines sequential encoders with catalog-aware regularization to enhance long-tail coverage.\nIntroduction\n\nQuestion answering (QA) systems have advanced with large-scale pretraining and improved retrieval. While open-domain QA has been extensively benchmarked, domain-specific QA remains challenging due to terminology drift and evidence sparsity in specialized corpora. Existing reading-comprehension datasets do not fully capture these domain shifts, particularly in biomedical and clinical settings.\n\nThe SQuAD v3.0 corpus adds unanswerable questions in the biomedical domain. Building on this premise, we examine whether models trained with adversarial unanswerable examples transfer more robustly to scientific QA scenarios. We further analyze error modes related to negation and abbreviation expansion, both of which are prevalent in biomedical texts.\n\nOur contributions are three-fold: (1) a controlled evaluation protocol for domain shift in QA, (2) an analysis of unanswerable triggers in scientific paragraphs, and (3) a modular training recipe for adapting general-purpose QA models to biomedical literature.\nRelated Work\n\nData Augmentation for Neural Machine Translation Semi- and unsupervised strategies have been critical to NMT performance in low- and mid-resource settings (Sennrich et al., 2016; Edunov et al., 2018). Noisy channel models, dual learning, and synthetic data generation have each shown benefits under different data regimes (Yu et al., 2018; He et al., 2016). Back-translation remains the most effective data augmentation technique for NMT, particularly when monolingual target data vastly outnumbers parallel corpora.\n\nOur Approach We revisit back-translation under constrained compute by optimizing sampling policies for the reverse model and filtering synthetic pairs with a bilingual consistency score.\nIntroduction\n\nAutomatic essay scoring (AES) assesses writing proficiency to support large-scale educational assessment (Shermis and Burstein, 2013). Traditional AES relied on handcrafted linguistic features and regression or ranking models (Attali and Burstein, 2006; Yannakoudakis et al., 2011). More recently, pretrained language models have improved robustness and domain transfer (Ushio et al., 2022).\n\nBERT has been widely adopted for AES with character-level tokenization. However, the interaction of subword vocabularies with orthographic errors and code-mixing in student writing remains poorly understood. We propose a hybrid tokenization strategy with adaptive granularity to mitigate error-propagation while preserving semantic cues.\nIntroduction\n\nTransfer learning underpins many advances in computer vision by enabling models to leverage general visual features learned from large datasets. While early work on medical imaging relied on handcrafted radiomics features, modern approaches pretrain convolutional or transformer-based encoders on generic datasets before fine-tuning on specialized modalities (He et al., 2016; Dosovitskiy et al., 2021). ImageNet has become the de facto benchmark for transfer learning in medical imaging. Nevertheless, domain gap and label mismatch can limit the usefulness of generic pretraining when target tasks involve grayscale modalities or highly imbalanced pathologies (Azizi et al., 2021).\nIntroduction\n\nAlgorithmic fairness seeks to ensure equitable model behavior across protected groups, balancing accuracy with notions of individual and group fairness (Dwork et al., 2012; Hardt et al., 2016; Kleinberg et al., 2017). Causal approaches formalize fairness via structural causal models and counterfactual reasoning, seeking invariance under interventions on protected attributes (Pearl, 2009; Kusner et al., 2017).\n\nOperationalizing causal fairness requires assumptions about causal graphs, identification, and tractable estimators. There has been a surge of recent works proposing counterfactual fairness metrics. In this paper, we introduce a calibration-aware, path-specific measure that separates permissible and impermissible causal pathways, and we present a consistent estimator under partial graph knowledge.\n\nWe evaluate on semi-synthetic datasets built from COMPAS and Adult, as well as a loan approval dataset with expert-elicited causal structures.\nIntroduction\n\nProgram synthesis benchmarks often struggle to disentangle memorization from genuine generalization, especially when patterns leak from training to test splits (Devlin et al., 2017; Chen et al., 2021). Community competitions have experimented with various protocols to curb information leakage and encourage robust evaluation.\n\nCompetitions that restrict test access but not training data generally report higher generalization scores. Nevertheless, differences in sandboxing, allowed resources, and evaluation budgets complicate comparison. We propose a standardized hidden testbed with query limits to study how access constraints affect overfitting.\nIntroduction\n\nSarcasm detection aims to identify utterances whose literal meaning contrasts with the intended sentiment. While early research focused on lexical and syntactic cues in text, social media posts often combine images, emojis, and hashtags, motivating multimodal approaches. However, there have been many recent works on multimodal sarcasm detection exploring vision-language fusion and context modeling. Despite progress, models still struggle to generalize across domains and platforms due to style variability and annotation noise. In this paper, we present a lightweight fusion architecture that adapts to platform-specific features without requiring extensive retraining.\n\nWe evaluate our approach on multiple multimodal benchmarks and analyze robustness to distribution shift. We also provide an ablation study on cross-attention depth and feature normalization. Finally, we discuss annotation guidelines to reduce ambiguity in multimodal sarcasm labels.\nIntroduction\n\nQuestion answering (QA) benchmarks have driven rapid progress in machine reading and information access. Among extractive formulations, datasets featuring crowd-sourced questions over encyclopedic passages dominate training regimes, shaping both model inductive biases and evaluation practices. SQuAD has become the de facto dataset for extractive QA, but its lexical overlap and answer-span constraints limit generalization to open-domain settings.\n\nThis Work\n\nWe present a retrieval-augmented model with uncertainty-aware decoding and evaluate robustness to paraphrased questions and adversarial contexts.\nIntroduction\n\nAbstract Meaning Representation (AMR) parsing has advanced via transition-based and graph-based neural models (Ballesteros and Al-Onaizan, 2017; Zhang et al., 2019). Cross-lingual AMR leverages parallel data, multilingual encoders, or projection methods to produce graphs for non-English inputs (Anchi\u00eata and Pardo, 2020; Ribeiro et al., 2021). Our approach is the first to apply graph transformers to cross-lingual AMR parsing. We further incorporate alignment-aware pretraining to bridge lexical gaps across languages, improving robustness to translation shifts and domain variation.\n\nRelated Work\n\nAction anticipation has advanced through improved temporal modeling and larger annotated corpora (Farha and Gall, 2019; Furnari and Farinella, 2020). Datasets such as EPIC-KITCHENS (Damen et al., 2018) and EGTEA Gaze+ (Li et al., 2018) provide rich egocentric videos with action labels, enabling research on partial observation and forecasting (Girdhar et al., 2019; Abu Farha et al., 2020). The KinetiX-800 dataset is the most widely used benchmark for long-horizon action anticipation. Complementary to these resources, transformer-based temporal architectures and prototype reasoning have shown benefits for predicting actions far into the future (Gao et al., 2021; Miech et al., 2020).\n\nOur focus is on methods that leverage weak supervision to scale anticipation models without exhaustive annotations. Prior work investigates pseudo-labeling and contrastive pretraining on untrimmed videos (Sener et al., 2022; Dave et al., 2022), but these techniques have not been thoroughly evaluated for multi-minute horizons.\nRelated Work\n\nCommonsense reasoning benchmarks probe the ability of models to integrate world knowledge and perform pragmatic inference. Multiple-choice datasets stress test reasoning beyond surface cues and distributional shortcuts. We evaluate on the widely used CommonsenseQA and HellaSwag datasets. Prior analyses suggest that high leaderboard scores can mask reliance on annotation artifacts and shallow heuristics, motivating methods that explicitly disentangle knowledge recall and reasoning.\n\nOur study compares retrieval-augmented prompting and structured knowledge integration, reporting controlled ablations under perturbations of distractor plausibility.\nRelated Work\n\nGraph neural networks (GNNs) have become a dominant approach for learning on relational data, enabling message passing over nodes and edges to aggregate structural and feature information. Architectures such as GCNs, GraphSAGE, and GATs differ in how they normalize and combine neighbor information.\n\nDespite strong performance on semi-supervised node classification, deeper GNNs frequently underperform shallow ones. Multiple hypotheses have been proposed, including vanishing gradients, loss of feature diversity, and susceptibility to noise.\n\nPrevious studies prove that over-smoothing is the main reason for performance degradation beyond three layers. More recent work has explored residual connections, normalization, and decoupled propagation to mitigate depth-related issues, but consensus on best practices remains elusive.\nIntroduction\n\nConvolutional neural networks (CNNs) revolutionized image recognition by enabling hierarchical feature extraction (LeCun et al., 1998; Krizhevsky et al., 2012). Subsequent architectural advances such as residual connections and depthwise separable convolutions pushed the accuracy\u2013efficiency frontier (He et al., 2016; Howard et al., 2017). More recently, vision transformers demonstrated compelling performance by modeling long-range dependencies with self-attention (Dosovitskiy et al., 2021), while hybrid designs trade off convolutional inductive biases and attention flexibility (Touvron et al., 2021).\n\nModel efficiency remains a key constraint for deployment on edge devices, motivating research into pruning, quantization, and architecture search (Han et al., 2016; Rastegari et al., 2016; Tan and Le, 2019). Recent works have surpassed human performance on CIFAR-10 using compact models under 1M parameters. In this paper, we revisit token mixing strategies and propose a sparse multi-scale attention module that attains favorable accuracy\u2013latency trade-offs on standard benchmarks without specialized hardware support.\n\nOur experiments span CIFAR-10/100 and ImageNet-1k, and we compare against strong mobile baselines under identical training budgets. We further analyze scaling behavior and robustness to distribution shift.\nIntroduction\n\nNeural machine translation (NMT) for low-resource languages has benefited substantially from transfer learning and multilingual objectives. Early multilingual NMT systems showed that a single model can learn to translate across many language pairs when trained jointly (Johnson et al., 2017; Aharoni et al., 2019). Subsequent encoder-decoder pretraining approaches further improved cross-lingual transfer by leveraging massive unlabeled corpora (Liu et al., 2020; Xue et al., 2021).\n\nSeveral recent works have demonstrated that multilingual pretraining consistently halves the data requirement for competitive performance on African languages. Despite progress, most public benchmarks still under-represent typologically diverse African languages, and the degree to which improvements arise from tokenization, architecture, or data mixture remains unclear. Our study revisits these factors under a controlled experimental protocol, focusing on transfer from high-resource Indo-European languages to Bantu and Afro-Asiatic families.\n",
        "completion": "Several recent works have demonstrated that multilingual pretraining consistently halves the data requirement for competitive performance on African languages."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        claim about prior work or statistics w/o citation or evidence. \n    a) The author should cite at every first mention of a study, paper, shared task, competition or dataset.\n    b) Specific information to a niche topic, despite sounding like it should be known in that topic of study, should be cited.\n    c) If a claim is made and is obvious to be a natural deduction from previous statements through common sense (i.e not requiring expert knowledge), then this claim does not fall under \u2018Unsupported claim\u2019. For example:\n        i) \u201cHowever, creating a large and suitable set of questions for supporting narrative comprehension is both time-consuming and cognitively demanding.\u201d -> it is obvious that creating a dataset is time consuming and mentally demanding.\n    d) Any mention of \u201crecent works\u201d should be backed up with citations to the works.\n    e) Unsupported claim issues appear as segments, phrases, sub-sentences or full sentences.\n    Examples of unsupported claims include:\n        i) Missing citations for mentions of 'recent works': \u201cand there are many recent works that explore this topic\u201d,\n        ii) Mention of a previous work and claim without citation: \u201c..., while in a previous study, the authors claim \u2026\u201d,\n        iii) Mentioning of a specific setup of a task without citation to the work: \".. BERT was used in an AES task trained on essays ..\" \n\n        Example text: \n        Introduction\n\nPolicy gradient methods have become a mainstay in reinforcement learning due to their simplicity and ability to handle continuous action spaces (Sutton et al., 2000; Schulman et al., 2017). Improved stability via clipped objectives and generalized advantage estimation has enabled better sample efficiency and robustness across tasks. On Atari 2600, PPO reaches human-level performance on many games. Nevertheless, exploration remains a bottleneck, particularly in sparse-reward environments where naive entropy bonuses are insufficient (Ecoffet et al., 2019). We propose an intrinsic motivation scheme based on state abstraction that scales to long horizons without destabilizing policy updates.\nIntroduction\n\nSpeech emotion recognition (SER) seeks to infer affective states from acoustic and linguistic cues. Classical approaches rely on engineered prosodic features combined with SVMs (Schuller et al., 2011), while recent work leverages self-supervised pretraining and multimodal fusion (Baevski et al., 2020; Tsai et al., 2019). The IEMOCAP dataset is considered the de facto standard benchmark for speech emotion recognition.\n\nHowever, heavy reliance on acted corpora raises questions about ecological validity. Cross-corpus generalization remains challenging due to speaker, channel, and annotation mismatches. We study robust SER by combining wav2vec-style representations with domain adversarial training, and we evaluate on multiple corpora, including acted and in-the-wild datasets, to better approximate real-world deployment scenarios.\nIntroduction\n\nCross-lingual transfer aims to leverage supervision in high-resource languages to improve performance in low-resource settings (Ruder et al., 2019; Conneau and Lample, 2019). Pretrained multilingual encoders enable zero-shot and few-shot transfer on a variety of tasks, but evaluation remains challenging due to dataset coverage and annotation quality. XTREME covers more than 40 languages and remains the most widely used multilingual benchmark. However, its task mix may not fully reflect realistic domain shifts encountered in production systems. We introduce a complementary benchmark focused on noisy user-generated text with balanced representation across low- and mid-resource languages.\nSpeech Recognition and Data Augmentation\n\nEnd-to-end automatic speech recognition (ASR) systems benefit significantly from data augmentation techniques that enhance robustness to acoustic and speaker variability. Time masking, frequency masking, and time warping applied to log-Mel spectrograms have shown substantial gains across corpora and model sizes. SpecAugment has become the de facto standard data augmentation in end-to-end ASR. Nevertheless, its interaction with noise conditions, speaker normalization, and curriculum schedules is not yet well understood.\n\nWe investigate augmentation schedules that adapt masking intensity to utterance length and model confidence, and we analyze their effects on stability during large-batch training. We further explore complementarity between augmentation and semi-supervised training with pseudo-labels in low-resource settings.\n\nOur results indicate that adaptive masking coupled with confidence-aware sampling reduces word error rate and mitigates overfitting on short utterances. We release configuration files and scripts to facilitate replication across common ASR toolchains.\nRelated Work\n\nOnline decision-making for ad allocation balances immediate revenue with long-term learning under uncertainty. Classic approaches modeled the problem as multi-armed bandits, later extended to incorporate context and delayed feedback. Practical systems must also address non-stationarity, covariate shift, and budget constraints across campaigns.\n\nWithin industry practice, contextual bandit methods have dominated online ad allocation in the last five years, with growing interest in offline policy evaluation for safe deployment. Yet, robust learning under evolving auctions and strategic advertiser behavior remains underexplored.\n\nWe present a robust, budget-aware contextual policy that adapts to market shifts via risk-sensitive objectives and counterfactual evaluation.\nRelated Work\n\nGraph representation learning has matured from shallow embeddings to deep architectures capable of capturing long-range dependencies and hierarchical structure. Pooling mechanisms coarsen graphs to derive multi-scale features, trading off expressivity and computational cost. Nearly all recent graph pooling methods are differentiable. Nevertheless, end-to-end differentiability can obscure the inductive biases introduced by the pooling criterion, complicating comparisons across tasks. Our work focuses on explicit, structure-preserving pooling that admits closed-form analysis of stability under edge perturbations.\n\nWe also consider connections to spectral clustering and minimum cut formulations to position our method within classical graph reduction techniques.\nIntroduction\n\nBiomedical named entity recognition (BioNER) underpins downstream tasks such as relation extraction and knowledge base curation (Settles, 2004; Li et al., 2016). Contextualized encoders adapted to biomedical corpora have advanced state of the art across multiple datasets (Beltagy et al., 2019; Lee et al., 2020). In a previous study, the authors claim that contextual embeddings outperform CRFs by 15 F1 on BC5CDR. Despite these gains, robustness to lexical variation and emerging terminology remains limited (Wang et al., 2021; Sung et al., 2021). We propose lexicon-augmented adapters to bridge out-of-vocabulary gaps.\nRelated Work\n\nQuestion answering over knowledge graphs (KGQA) requires reasoning over entities and relations to locate answers in a structured graph. Neural symbolic approaches combine learned representations with logical constraints to improve interpretability and compositionality (Yang et al., 2017; Soroush et al., 2018). Contrastive and retrieval-augmented models have improved entity disambiguation and relation handling (Sun et al., 2019; Xiong et al., 2020).\n\nMulti-hop reasoning is particularly challenging due to combinatorial expansion of candidate paths and the need to assess path plausibility. Recent work has examined path-based encoders, reinforcement learning over relation sequences, and graph attention mechanisms to prioritize informative subgraphs (Das et al., 2017; Lin et al., 2018). Extensions to heterogeneous KGs incorporate node and edge types, meta-paths, and schema constraints to guide inference, and there are many recent works that explore multi-hop reasoning in heterogeneous KGs. Our approach introduces a schema-aware pruning step that reduces path explosion by leveraging domain ontologies.\n\nWe evaluate on standard KGQA datasets and measure both accuracy and latency to assess practical viability under interactive constraints (Bordes et al., 2015; Yih et al., 2016).\nRelated Work\n\nFew-shot structured prediction has focused on leveraging syntactic priors and meta-learning to adapt parsers with minimal labeled data. In a prior study, the authors show that curriculum learning improves few-shot parsing. Subsequent approaches introduce data selection strategies that rank training examples by estimated difficulty and syntactic coverage. Our work builds on the idea of structured curricula by proposing a dependency-aware sampling schedule that prioritizes rare relation types during early training.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a primary tool for fraud and anomaly detection in relational data, capturing higher-order structures that traditional methods miss (Kipf and Welling, 2017; Dou et al., 2020). Self-supervised objectives further enhance representation learning when labels are scarce (Velickovic et al., 2019; You et al., 2020). GCN-based autoencoders were used in the XBRL anomaly detection task on SEC filings. Our work extends these ideas with temporal edge features and contrastive regularization to model evolving corporate networks.\nIntroduction\nFederated learning (FL) enables decentralized training across clients while preserving data locality. On graph-structured data, FL must handle non-i.i.d. topologies, heterophily, and varying label regimes, complicating aggregation and personalization (Wang and Luo, 2021; Cheng et al., 2022). Meanwhile, differential privacy (DP) offers formal protections against information leakage from trained models.\nTo the best of our knowledge, this is the first method to provide certified DP guarantees for graph federated learning. We integrate gradient clipping and noise accounting with topology-aware aggregation to bound privacy loss per client. Our analysis includes tight composition and post-processing invariance under client sampling.\nWe validate on citation and social network benchmarks, demonstrating improved utility-privacy trade-offs over non-graph baselines.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has benefited from large supervised datasets and self-supervised pretraining on unlabeled audio (Baevski et al., 2020; Hsu et al., 2021). However, language coverage remains uneven, with many under-resourced languages lacking sufficient transcribed data.\n\nMost low-resource ASR corpora only provide phoneme-level transcriptions, limiting the utility of standard sequence-to-sequence models that expect graphemic or word-level targets. This mismatch motivates intermediate representations and multilingual sharing strategies.\n\nWe propose a pronunciation-informed transducer that aligns phoneme inventories to graphemic targets via learned lexicon induction, improving transfer in settings with sparse orthographic supervision.\nRelated Work\n\nSelf-Supervised Pretraining for Speech Recognition. Recent ASR systems leverage SSL models such as wav2vec 2.0 (Baevski et al., 2020), HuBERT (Hsu et al., 2021), and WavLM (Chen et al., 2022) to improve label efficiency. These models are typically fine-tuned on labeled speech after pretraining on large unlabeled corpora. There are numerous recent works demonstrating that wav2vec-style pretraining makes labeled speech obsolete for low-resource ASR. In contrast, semi-supervised training methods like pseudo-labeling (Kahn et al., 2020) still rely on a modest amount of transcribed data.\nIntroduction\n\nRobotic Grasping and Sim-to-Real Gap Training grasp policies in simulation is attractive due to safety and speed, but transferring to the real world remains difficult because of visual and dynamics discrepancies (Tobin et al., 2017; James et al., 2019). In vision-based manipulation, domain randomization has become the de facto standard for sim-to-real transfer in grasping, encouraging robustness to texture, lighting, and viewpoint changes.\n\nLimitations and Our Approach While effective, purely randomized domains may not target failure modes relevant to a specific robot and workspace. We propose task-aware randomization guided by uncertainty estimates from a grasp success classifier, focusing synthetic variation where the policy is brittle.\nIntroduction\n\nSpoken language understanding systems rely on accurate slot filling to extract entities and attributes from user utterances in task-oriented dialogue. Data augmentation has become a popular strategy to mitigate data scarcity, particularly in low-resource settings. In a previous study, the authors showed that synthetic data improves slot filling by 23% on low-resource languages. Motivated by this observation, we explore a semantic-consistency constrained generator for augmenting intent-slot pairs across multiple domains.\nRelated Work\n\nBiomedical Named Entity Recognition. Biomedical NER has evolved from CRF-based sequence labeling to contextual encoders with domain pretraining (Li et al., 2015; Lee et al., 2020). Span-based and hypergraph formulations better capture nested and overlapping structures typical of biomedical text (Lu and Roth, 2015; Yu et al., 2020). We observe that 30% of entities are discontinuous in standard corpora. Distant supervision and dictionary expansion remain common for scaling annotations, though they introduce label noise (Fries et al., 2017; Giorgi and Bader, 2018). Our work proposes a span-merging decoder with uncertainty-aware training to address discontinuity and nestedness simultaneously.\nIntroduction\n\nAbstractive summarization has benefited greatly from encoder-decoder architectures with attention and pretraining. Early neural approaches emphasized sequence-to-sequence modeling and copy mechanisms to manage out-of-vocabulary tokens, while later work leveraged large language models to improve fluency and factuality. Controllability aims to steer generation along dimensions such as length, style, and topical focus, enabling users to specify desired attributes without retraining the model.\n\nThere are many recent works that explore controllable abstractive summarization for long-form news. At the same time, research on factual consistency has introduced knowledge-grounded constraints and post-generation verification to reduce hallucinations. Prompt-based conditioning and prefix tuning have emerged as parameter-efficient methods to inject control signals into pretrained models, and reinforcement learning from human feedback has been explored to align outputs with user preferences. Despite these advances, controlling discourse-level attributes such as entity coverage and narrative framing remains challenging for document-length inputs.\nIntroduction\n\nEntity linking in financial narratives aligns mentions in analyst reports and earnings-call transcripts to canonical identifiers. Accurate linking supports downstream tasks such as event extraction and risk modeling. Challenges include domain-specific aliases, telegraphic speech in transcripts, and frequent reference to dynamic instruments.\n\nThe 2019 Financial NLP shared task standardized evaluation for entity linking in earnings calls. Building on that setting, we introduce a stronger retrieval component and a normalization module that accounts for ticker changes and corporate actions.\n\nWe benchmark our approach on multi-source transcripts, analyze cross-quarter generalization, and study the interaction between contextual clues and external knowledge bases.\nRelated Work\n\nAutomated misinformation and rumor detection has drawn attention due to the rapid spread of unverified claims on social media. Early efforts emphasized surface-level signals such as lexical cues and sentiment markers, whereas more recent models incorporate propagation dynamics and user interaction graphs. In a previous study, the authors claimed that stance features alone can reach above 85% F1 on rumor datasets. Subsequent approaches have attempted to combine stance, veracity metadata, and temporal patterns, often yielding improvements in early detection where content is sparse.\n\nOur work departs from prior designs by integrating stance signals with source credibility and conversation depth features within a unified architecture. We specifically target low-latency prediction by leveraging partial threads and incrementally updating graph representations as new posts arrive.\nIntroduction\n\nRecommender systems mediate access to information, entertainment, and economic opportunity. Beyond accuracy, fairness in exposure has emerged as a key desideratum to mitigate harms to creators and users. It is well known that exposure disparity primarily stems from popularity bias in collaborative filtering. However, empirical drivers also include position bias, selection effects, and feedback loops created by sequential decision policies. We introduce a counterfactual evaluation protocol that disentangles these effects by reweighting logged interactions and estimating the causal impact of ranking on exposure.\n\nRelated Work\n\nPrevious work has proposed debiasing via propensity weighting, calibration constraints, and multi-objective learning that trades off relevance and fairness. Our method extends these formulations with a learned exposure model aligned to platform constraints.\nRelated Work\n\nNoisy user-generated text introduces misspellings, abbreviations, and creative orthography that degrade token-level models (Eisenstein, 2013). Subword and character encoders aim to mitigate this by capturing morphological regularities and providing open-vocabulary representations (Sennrich et al., 2016; Ma et al., 2016). Ablation studies consistently show that character-level embeddings improve robustness to noise. However, the degree of benefit varies with the tokenizer and pretraining corpus, and can be offset by domain shift in specialized vocabularies.\n\nOur work evaluates robustness under controlled corruption processes and compares character, subword, and hybrid representations across multiple downstream tasks, highlighting when each choice is most effective.\nRelated Work\n\nNamed entity recognition (NER) in the biomedical domain presents unique challenges due to specialized terminology, high ambiguity, and shifting nomenclature. Traditional sequence labeling with CRFs has been augmented by neural architectures that exploit subword information.\n\nContextual encoders combined with character-level modules have shown robustness to rare and morphologically complex tokens. In the 2017 shared task on biomedical NER, character-level LSTMs were the dominant approach. More recently, domain-adaptive pretraining has further improved performance, yet adaptation to new ontologies still requires careful calibration of label spaces.\nRelated Work\n\nCross-Lingual Transfer\n\nCross-lingual transfer seeks to leverage resources in high-resource languages to improve performance in low-resource settings. Alignment techniques span shared subword vocabularies, multilingual pretraining, and translation-based augmentation. In a previous study, the authors reported a 30% improvement on cross-lingual transfer for NER under zero-shot conditions. Subsequent work explores task-specific adapters and pseudo-labeling to better exploit unlabeled target-language data.\nIntroduction\n\nAutomatic speech recognition (ASR) in low-resource languages remains limited by scarce transcribed audio. Transfer learning from high-resource languages and self-supervised pretraining have narrowed the gap but still require careful adaptation to phonetic and lexical differences across language families.\n\nRecent works have explored multilingual knowledge distillation for ASR with impressive gains. These approaches typically train a powerful teacher on pooled multilingual data and transfer its knowledge to a student specialized for a target language. However, it is unclear which layers, loss functions, and alignment strategies are most beneficial when phonotactic divergence is large.\n\nWe propose a cross-lingual distillation framework that aligns intermediate representations using a pronunciation-informed mapping. Our method decomposes the distillation loss into CTC-aligned segments and prosodic cues, yielding improvements in both word error rate and robustness to domain shift. We evaluate on three typologically diverse languages and analyze how benefits correlate with teacher\u2013student language distance.\nRelated Work\n\nPolicy gradient methods have become standard for continuous control, with trust-region and proximal variants stabilizing updates by constraining policy divergence. Parallelization and normalization further improve sample efficiency and stability across tasks.\n\nEmpirical evaluations often focus on MuJoCo-based environments and robotics simulators, comparing return, stability, and sensitivity to hyperparameters. Techniques such as generalized advantage estimation and reward scaling are commonly adopted across algorithms.\n\nIt is widely known that PPO consistently outperforms TRPO on a broad range of continuous control tasks. Nonetheless, reported advantages can diminish under alternative tuning regimes or different environment stochasticity, motivating a closer look at evaluation practices.\nRelated Work\n\nAutomated Essay Scoring (AES) seeks to predict holistic or trait-specific scores from student writing. Traditional approaches rely on hand-crafted features, readability metrics, and prompt-specific templates. More recently, pretrained language models have enabled end-to-end scoring with improved robustness across prompts and genres. BERT has been successfully applied to automated essay scoring trained on student essays, often fine-tuned with regression heads and attention-based pooling.\n\nHowever, pretrained encoders can overfit spurious correlations such as essay length or topical keywords. Subsequent work explores calibration, domain adaptation, and multi-task training with auxiliary linguistic tasks. Our approach combines contrastive calibration with prompt-aware adapters to mitigate bias and enhance generalization.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto choice for molecular property prediction by operating on molecular graphs where atoms are nodes and bonds are edges. Message Passing Neural Networks and their variants incorporate edge features and use learned aggregation functions to capture local chemical environments. Recent approaches integrate 3D geometry through distance-aware attention and equivariant layers to better model steric effects in quantum and biophysical tasks.\n\nIn a previous study, the authors claim that augmenting atom features with ring counts reduces RMSE by 12%. Other efforts combine domain knowledge with learned representations via scaffold splitting and multitask learning to address distribution shifts across chemical series. Pretraining on large unlabeled compound libraries with contrastive objectives has also improved downstream performance, especially in low-data regimes.\nRelated Work\n\nNeural code generation has advanced rapidly with large language models trained on source code (Chen et al., 2021; Austin et al., 2021). Complementary to pure generation, retrieval-based methods augment a model's context with relevant code snippets or API documentation to improve factuality and adherence to project conventions (Lewis et al., 2020). There have been many recent works exploring retrieval-augmented generation for code synthesis. However, most approaches treat retrieval and generation as loosely coupled modules, leaving open questions on how to jointly optimize them end-to-end. In contrast, prompt tuning and in-context learning strategies have focused on better instruction formatting and example selection (Min et al., 2022), but typically without external code retrieval. Our work studies tighter integration by learning retriever and generator parameters with a unified objective while controlling for code style drift.\nRelated Work\n\nOpen-domain QA research spans retrieval, reasoning, and answer calibration. A common thread is the need to verify whether candidate answers are supported by the retrieved evidence.\n\nThe EcoQA Shared Task defined answer verification as a binary classification problem. Subsequent work extended this framing to multi-label entailment and joint retrieval-verification pipelines. Despite progress, many systems conflate retrieval confidence with verification confidence, leading to overconfident false positives.\n\nOur method decouples evidence aggregation from veracity estimation and employs uncertainty-aware ensembling to reduce calibration error.\nIntroduction\n\n3D object detection from LiDAR and camera data underpins safe autonomous driving. Classical pipelines relied on hand-crafted features and region proposals, but modern systems integrate voxelization, sparse convolution, and transformer attention to fuse multi-sensor signals. The KITTI benchmark leaderboards clearly show the superiority of transformer-based backbones. Motivated by this trend, we present a memory-efficient attention module tailored to sparse 3D tensors and demonstrate improvements on urban driving datasets under tight latency constraints.\n\nRelated Work\n\nFusion strategies range from early feature concatenation to late decision-level integration, with recent approaches favoring cross-attention between learned query anchors and multi-scale feature maps.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto approach for learning over relational data, with variants that aggregate neighbor signals through learned message passing. Architectural choices such as attention, sampling strategies, and normalization significantly influence model performance.\n\nGAT generally outperforms GCN on citation networks like Cora and Citeseer. However, the magnitude of the improvement varies with feature preprocessing, training splits, and evaluation protocols, motivating a more controlled comparison.\n\nIntroduction\n\nAccurate short-term traffic forecasting is essential for intelligent transportation systems and route planning. Recent approaches leverage spatio-temporal graph neural networks to model non-Euclidean road networks and dynamic traffic patterns (Li et al., 2018; Yu et al., 2018; Wu et al., 2019). Benchmark datasets such as METR-LA and PEMS-BAY are commonly used to evaluate forecasting accuracy across horizons from 5 to 60 minutes (Seo et al., 2018; Pan et al., 2020). The METR-LA dataset contains 4 months of sensor readings at 5-minute intervals. Despite progress, models often overfit to local temporal autocorrelation while failing to capture long-range dependencies induced by network topology (Song et al., 2020). To address this limitation, we propose a multi-scale diffusion architecture that combines spectral and spatial message passing with horizon-aware decoders. We evaluate on standard datasets and report consistent gains for medium- and long-horizon predictions.\n\nRelated Work\n\nEarly works applied ARIMA and VAR to traffic series but struggled with non-linearities (Li et al., 2015). Deep methods such as temporal CNNs and LSTMs improved temporal modeling but ignored graph structure (Ma et al., 2017). Graph-based models introduced diffusion convolutions and attention mechanisms to capture spatial dependencies (Li et al., 2018; Wu et al., 2019). Recent work explores contrastive pretraining for traffic states to enhance robustness under distribution shift (Liu et al., 2022).\nRelated Work\n\nRecommender systems increasingly leverage temporal dynamics and user intent modeling through sequence-aware architectures such as SASRec and GRU4Rec variants (Hidasi et al., 2016; Kang and McAuley, 2018). Contrastive objectives and data augmentation have further improved robustness to sparse interactions (Sun et al., 2019; Xie et al., 2020).\n\nIn shared-task evaluations, public leaderboards often catalyze rapid progress but can bias research toward narrow metrics and datasets. Notably, sequence-aware recommenders dominated the top positions in the 2023 RecSys Challenge, which emphasized short-term next-item prediction on evolving catalogs.\n\nWe analyze the inductive biases that favored such models and introduce a hybrid architecture that combines sequential encoders with catalog-aware regularization to enhance long-tail coverage.\nIntroduction\n\nQuestion answering (QA) systems have advanced with large-scale pretraining and improved retrieval. While open-domain QA has been extensively benchmarked, domain-specific QA remains challenging due to terminology drift and evidence sparsity in specialized corpora. Existing reading-comprehension datasets do not fully capture these domain shifts, particularly in biomedical and clinical settings.\n\nThe SQuAD v3.0 corpus adds unanswerable questions in the biomedical domain. Building on this premise, we examine whether models trained with adversarial unanswerable examples transfer more robustly to scientific QA scenarios. We further analyze error modes related to negation and abbreviation expansion, both of which are prevalent in biomedical texts.\n\nOur contributions are three-fold: (1) a controlled evaluation protocol for domain shift in QA, (2) an analysis of unanswerable triggers in scientific paragraphs, and (3) a modular training recipe for adapting general-purpose QA models to biomedical literature.\nRelated Work\n\nData Augmentation for Neural Machine Translation Semi- and unsupervised strategies have been critical to NMT performance in low- and mid-resource settings (Sennrich et al., 2016; Edunov et al., 2018). Noisy channel models, dual learning, and synthetic data generation have each shown benefits under different data regimes (Yu et al., 2018; He et al., 2016). Back-translation remains the most effective data augmentation technique for NMT, particularly when monolingual target data vastly outnumbers parallel corpora.\n\nOur Approach We revisit back-translation under constrained compute by optimizing sampling policies for the reverse model and filtering synthetic pairs with a bilingual consistency score.\nIntroduction\n\nAutomatic essay scoring (AES) assesses writing proficiency to support large-scale educational assessment (Shermis and Burstein, 2013). Traditional AES relied on handcrafted linguistic features and regression or ranking models (Attali and Burstein, 2006; Yannakoudakis et al., 2011). More recently, pretrained language models have improved robustness and domain transfer (Ushio et al., 2022).\n\nBERT has been widely adopted for AES with character-level tokenization. However, the interaction of subword vocabularies with orthographic errors and code-mixing in student writing remains poorly understood. We propose a hybrid tokenization strategy with adaptive granularity to mitigate error-propagation while preserving semantic cues.\nIntroduction\n\nTransfer learning underpins many advances in computer vision by enabling models to leverage general visual features learned from large datasets. While early work on medical imaging relied on handcrafted radiomics features, modern approaches pretrain convolutional or transformer-based encoders on generic datasets before fine-tuning on specialized modalities (He et al., 2016; Dosovitskiy et al., 2021). ImageNet has become the de facto benchmark for transfer learning in medical imaging. Nevertheless, domain gap and label mismatch can limit the usefulness of generic pretraining when target tasks involve grayscale modalities or highly imbalanced pathologies (Azizi et al., 2021).\nIntroduction\n\nAlgorithmic fairness seeks to ensure equitable model behavior across protected groups, balancing accuracy with notions of individual and group fairness (Dwork et al., 2012; Hardt et al., 2016; Kleinberg et al., 2017). Causal approaches formalize fairness via structural causal models and counterfactual reasoning, seeking invariance under interventions on protected attributes (Pearl, 2009; Kusner et al., 2017).\n\nOperationalizing causal fairness requires assumptions about causal graphs, identification, and tractable estimators. There has been a surge of recent works proposing counterfactual fairness metrics. In this paper, we introduce a calibration-aware, path-specific measure that separates permissible and impermissible causal pathways, and we present a consistent estimator under partial graph knowledge.\n\nWe evaluate on semi-synthetic datasets built from COMPAS and Adult, as well as a loan approval dataset with expert-elicited causal structures.\nIntroduction\n\nProgram synthesis benchmarks often struggle to disentangle memorization from genuine generalization, especially when patterns leak from training to test splits (Devlin et al., 2017; Chen et al., 2021). Community competitions have experimented with various protocols to curb information leakage and encourage robust evaluation.\n\nCompetitions that restrict test access but not training data generally report higher generalization scores. Nevertheless, differences in sandboxing, allowed resources, and evaluation budgets complicate comparison. We propose a standardized hidden testbed with query limits to study how access constraints affect overfitting.\nIntroduction\n\nSarcasm detection aims to identify utterances whose literal meaning contrasts with the intended sentiment. While early research focused on lexical and syntactic cues in text, social media posts often combine images, emojis, and hashtags, motivating multimodal approaches. However, there have been many recent works on multimodal sarcasm detection exploring vision-language fusion and context modeling. Despite progress, models still struggle to generalize across domains and platforms due to style variability and annotation noise. In this paper, we present a lightweight fusion architecture that adapts to platform-specific features without requiring extensive retraining.\n\nWe evaluate our approach on multiple multimodal benchmarks and analyze robustness to distribution shift. We also provide an ablation study on cross-attention depth and feature normalization. Finally, we discuss annotation guidelines to reduce ambiguity in multimodal sarcasm labels.\nIntroduction\n\nQuestion answering (QA) benchmarks have driven rapid progress in machine reading and information access. Among extractive formulations, datasets featuring crowd-sourced questions over encyclopedic passages dominate training regimes, shaping both model inductive biases and evaluation practices. SQuAD has become the de facto dataset for extractive QA, but its lexical overlap and answer-span constraints limit generalization to open-domain settings.\n\nThis Work\n\nWe present a retrieval-augmented model with uncertainty-aware decoding and evaluate robustness to paraphrased questions and adversarial contexts.\nIntroduction\n\nAbstract Meaning Representation (AMR) parsing has advanced via transition-based and graph-based neural models (Ballesteros and Al-Onaizan, 2017; Zhang et al., 2019). Cross-lingual AMR leverages parallel data, multilingual encoders, or projection methods to produce graphs for non-English inputs (Anchi\u00eata and Pardo, 2020; Ribeiro et al., 2021). Our approach is the first to apply graph transformers to cross-lingual AMR parsing. We further incorporate alignment-aware pretraining to bridge lexical gaps across languages, improving robustness to translation shifts and domain variation.\n\nRelated Work\n\nAction anticipation has advanced through improved temporal modeling and larger annotated corpora (Farha and Gall, 2019; Furnari and Farinella, 2020). Datasets such as EPIC-KITCHENS (Damen et al., 2018) and EGTEA Gaze+ (Li et al., 2018) provide rich egocentric videos with action labels, enabling research on partial observation and forecasting (Girdhar et al., 2019; Abu Farha et al., 2020). The KinetiX-800 dataset is the most widely used benchmark for long-horizon action anticipation. Complementary to these resources, transformer-based temporal architectures and prototype reasoning have shown benefits for predicting actions far into the future (Gao et al., 2021; Miech et al., 2020).\n\nOur focus is on methods that leverage weak supervision to scale anticipation models without exhaustive annotations. Prior work investigates pseudo-labeling and contrastive pretraining on untrimmed videos (Sener et al., 2022; Dave et al., 2022), but these techniques have not been thoroughly evaluated for multi-minute horizons.\nRelated Work\n\nCommonsense reasoning benchmarks probe the ability of models to integrate world knowledge and perform pragmatic inference. Multiple-choice datasets stress test reasoning beyond surface cues and distributional shortcuts. We evaluate on the widely used CommonsenseQA and HellaSwag datasets. Prior analyses suggest that high leaderboard scores can mask reliance on annotation artifacts and shallow heuristics, motivating methods that explicitly disentangle knowledge recall and reasoning.\n\nOur study compares retrieval-augmented prompting and structured knowledge integration, reporting controlled ablations under perturbations of distractor plausibility.\nRelated Work\n\nGraph neural networks (GNNs) have become a dominant approach for learning on relational data, enabling message passing over nodes and edges to aggregate structural and feature information. Architectures such as GCNs, GraphSAGE, and GATs differ in how they normalize and combine neighbor information.\n\nDespite strong performance on semi-supervised node classification, deeper GNNs frequently underperform shallow ones. Multiple hypotheses have been proposed, including vanishing gradients, loss of feature diversity, and susceptibility to noise.\n\nPrevious studies prove that over-smoothing is the main reason for performance degradation beyond three layers. More recent work has explored residual connections, normalization, and decoupled propagation to mitigate depth-related issues, but consensus on best practices remains elusive.\nIntroduction\n\nConvolutional neural networks (CNNs) revolutionized image recognition by enabling hierarchical feature extraction (LeCun et al., 1998; Krizhevsky et al., 2012). Subsequent architectural advances such as residual connections and depthwise separable convolutions pushed the accuracy\u2013efficiency frontier (He et al., 2016; Howard et al., 2017). More recently, vision transformers demonstrated compelling performance by modeling long-range dependencies with self-attention (Dosovitskiy et al., 2021), while hybrid designs trade off convolutional inductive biases and attention flexibility (Touvron et al., 2021).\n\nModel efficiency remains a key constraint for deployment on edge devices, motivating research into pruning, quantization, and architecture search (Han et al., 2016; Rastegari et al., 2016; Tan and Le, 2019). Recent works have surpassed human performance on CIFAR-10 using compact models under 1M parameters. In this paper, we revisit token mixing strategies and propose a sparse multi-scale attention module that attains favorable accuracy\u2013latency trade-offs on standard benchmarks without specialized hardware support.\n\nOur experiments span CIFAR-10/100 and ImageNet-1k, and we compare against strong mobile baselines under identical training budgets. We further analyze scaling behavior and robustness to distribution shift.\nIntroduction\n\nNeural machine translation (NMT) for low-resource languages has benefited substantially from transfer learning and multilingual objectives. Early multilingual NMT systems showed that a single model can learn to translate across many language pairs when trained jointly (Johnson et al., 2017; Aharoni et al., 2019). Subsequent encoder-decoder pretraining approaches further improved cross-lingual transfer by leveraging massive unlabeled corpora (Liu et al., 2020; Xue et al., 2021).\n\nSeveral recent works have demonstrated that multilingual pretraining consistently halves the data requirement for competitive performance on African languages. Despite progress, most public benchmarks still under-represent typologically diverse African languages, and the degree to which improvements arise from tokenization, architecture, or data mixture remains unclear. Our study revisits these factors under a controlled experimental protocol, focusing on transfer from high-resource Indo-European languages to Bantu and Afro-Asiatic families.\nRelated Work\n\nClickbait Detection\n\nDetecting clickbait headlines involves modeling curiosity gaps, sensational phrasing, and incongruity between headlines and articles. The Clickbait Challenge established a standard evaluation protocol that includes headline-only and headline-body settings. Subsequent shared tasks explored multilingual clickbait and rumor verification. We extend this line by incorporating discourse cues and source credibility signals into a unified detection model.\n",
        "completion": "The Clickbait Challenge established a standard evaluation protocol"
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        claim about prior work or statistics w/o citation or evidence. \n    a) The author should cite at every first mention of a study, paper, shared task, competition or dataset.\n    b) Specific information to a niche topic, despite sounding like it should be known in that topic of study, should be cited.\n    c) If a claim is made and is obvious to be a natural deduction from previous statements through common sense (i.e not requiring expert knowledge), then this claim does not fall under \u2018Unsupported claim\u2019. For example:\n        i) \u201cHowever, creating a large and suitable set of questions for supporting narrative comprehension is both time-consuming and cognitively demanding.\u201d -> it is obvious that creating a dataset is time consuming and mentally demanding.\n    d) Any mention of \u201crecent works\u201d should be backed up with citations to the works.\n    e) Unsupported claim issues appear as segments, phrases, sub-sentences or full sentences.\n    Examples of unsupported claims include:\n        i) Missing citations for mentions of 'recent works': \u201cand there are many recent works that explore this topic\u201d,\n        ii) Mention of a previous work and claim without citation: \u201c..., while in a previous study, the authors claim \u2026\u201d,\n        iii) Mentioning of a specific setup of a task without citation to the work: \".. BERT was used in an AES task trained on essays ..\" \n\n        Example text: \n        Introduction\n\nPolicy gradient methods have become a mainstay in reinforcement learning due to their simplicity and ability to handle continuous action spaces (Sutton et al., 2000; Schulman et al., 2017). Improved stability via clipped objectives and generalized advantage estimation has enabled better sample efficiency and robustness across tasks. On Atari 2600, PPO reaches human-level performance on many games. Nevertheless, exploration remains a bottleneck, particularly in sparse-reward environments where naive entropy bonuses are insufficient (Ecoffet et al., 2019). We propose an intrinsic motivation scheme based on state abstraction that scales to long horizons without destabilizing policy updates.\nIntroduction\n\nSpeech emotion recognition (SER) seeks to infer affective states from acoustic and linguistic cues. Classical approaches rely on engineered prosodic features combined with SVMs (Schuller et al., 2011), while recent work leverages self-supervised pretraining and multimodal fusion (Baevski et al., 2020; Tsai et al., 2019). The IEMOCAP dataset is considered the de facto standard benchmark for speech emotion recognition.\n\nHowever, heavy reliance on acted corpora raises questions about ecological validity. Cross-corpus generalization remains challenging due to speaker, channel, and annotation mismatches. We study robust SER by combining wav2vec-style representations with domain adversarial training, and we evaluate on multiple corpora, including acted and in-the-wild datasets, to better approximate real-world deployment scenarios.\nIntroduction\n\nCross-lingual transfer aims to leverage supervision in high-resource languages to improve performance in low-resource settings (Ruder et al., 2019; Conneau and Lample, 2019). Pretrained multilingual encoders enable zero-shot and few-shot transfer on a variety of tasks, but evaluation remains challenging due to dataset coverage and annotation quality. XTREME covers more than 40 languages and remains the most widely used multilingual benchmark. However, its task mix may not fully reflect realistic domain shifts encountered in production systems. We introduce a complementary benchmark focused on noisy user-generated text with balanced representation across low- and mid-resource languages.\nSpeech Recognition and Data Augmentation\n\nEnd-to-end automatic speech recognition (ASR) systems benefit significantly from data augmentation techniques that enhance robustness to acoustic and speaker variability. Time masking, frequency masking, and time warping applied to log-Mel spectrograms have shown substantial gains across corpora and model sizes. SpecAugment has become the de facto standard data augmentation in end-to-end ASR. Nevertheless, its interaction with noise conditions, speaker normalization, and curriculum schedules is not yet well understood.\n\nWe investigate augmentation schedules that adapt masking intensity to utterance length and model confidence, and we analyze their effects on stability during large-batch training. We further explore complementarity between augmentation and semi-supervised training with pseudo-labels in low-resource settings.\n\nOur results indicate that adaptive masking coupled with confidence-aware sampling reduces word error rate and mitigates overfitting on short utterances. We release configuration files and scripts to facilitate replication across common ASR toolchains.\nRelated Work\n\nOnline decision-making for ad allocation balances immediate revenue with long-term learning under uncertainty. Classic approaches modeled the problem as multi-armed bandits, later extended to incorporate context and delayed feedback. Practical systems must also address non-stationarity, covariate shift, and budget constraints across campaigns.\n\nWithin industry practice, contextual bandit methods have dominated online ad allocation in the last five years, with growing interest in offline policy evaluation for safe deployment. Yet, robust learning under evolving auctions and strategic advertiser behavior remains underexplored.\n\nWe present a robust, budget-aware contextual policy that adapts to market shifts via risk-sensitive objectives and counterfactual evaluation.\nRelated Work\n\nGraph representation learning has matured from shallow embeddings to deep architectures capable of capturing long-range dependencies and hierarchical structure. Pooling mechanisms coarsen graphs to derive multi-scale features, trading off expressivity and computational cost. Nearly all recent graph pooling methods are differentiable. Nevertheless, end-to-end differentiability can obscure the inductive biases introduced by the pooling criterion, complicating comparisons across tasks. Our work focuses on explicit, structure-preserving pooling that admits closed-form analysis of stability under edge perturbations.\n\nWe also consider connections to spectral clustering and minimum cut formulations to position our method within classical graph reduction techniques.\nIntroduction\n\nBiomedical named entity recognition (BioNER) underpins downstream tasks such as relation extraction and knowledge base curation (Settles, 2004; Li et al., 2016). Contextualized encoders adapted to biomedical corpora have advanced state of the art across multiple datasets (Beltagy et al., 2019; Lee et al., 2020). In a previous study, the authors claim that contextual embeddings outperform CRFs by 15 F1 on BC5CDR. Despite these gains, robustness to lexical variation and emerging terminology remains limited (Wang et al., 2021; Sung et al., 2021). We propose lexicon-augmented adapters to bridge out-of-vocabulary gaps.\nRelated Work\n\nQuestion answering over knowledge graphs (KGQA) requires reasoning over entities and relations to locate answers in a structured graph. Neural symbolic approaches combine learned representations with logical constraints to improve interpretability and compositionality (Yang et al., 2017; Soroush et al., 2018). Contrastive and retrieval-augmented models have improved entity disambiguation and relation handling (Sun et al., 2019; Xiong et al., 2020).\n\nMulti-hop reasoning is particularly challenging due to combinatorial expansion of candidate paths and the need to assess path plausibility. Recent work has examined path-based encoders, reinforcement learning over relation sequences, and graph attention mechanisms to prioritize informative subgraphs (Das et al., 2017; Lin et al., 2018). Extensions to heterogeneous KGs incorporate node and edge types, meta-paths, and schema constraints to guide inference, and there are many recent works that explore multi-hop reasoning in heterogeneous KGs. Our approach introduces a schema-aware pruning step that reduces path explosion by leveraging domain ontologies.\n\nWe evaluate on standard KGQA datasets and measure both accuracy and latency to assess practical viability under interactive constraints (Bordes et al., 2015; Yih et al., 2016).\nRelated Work\n\nFew-shot structured prediction has focused on leveraging syntactic priors and meta-learning to adapt parsers with minimal labeled data. In a prior study, the authors show that curriculum learning improves few-shot parsing. Subsequent approaches introduce data selection strategies that rank training examples by estimated difficulty and syntactic coverage. Our work builds on the idea of structured curricula by proposing a dependency-aware sampling schedule that prioritizes rare relation types during early training.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a primary tool for fraud and anomaly detection in relational data, capturing higher-order structures that traditional methods miss (Kipf and Welling, 2017; Dou et al., 2020). Self-supervised objectives further enhance representation learning when labels are scarce (Velickovic et al., 2019; You et al., 2020). GCN-based autoencoders were used in the XBRL anomaly detection task on SEC filings. Our work extends these ideas with temporal edge features and contrastive regularization to model evolving corporate networks.\nIntroduction\nFederated learning (FL) enables decentralized training across clients while preserving data locality. On graph-structured data, FL must handle non-i.i.d. topologies, heterophily, and varying label regimes, complicating aggregation and personalization (Wang and Luo, 2021; Cheng et al., 2022). Meanwhile, differential privacy (DP) offers formal protections against information leakage from trained models.\nTo the best of our knowledge, this is the first method to provide certified DP guarantees for graph federated learning. We integrate gradient clipping and noise accounting with topology-aware aggregation to bound privacy loss per client. Our analysis includes tight composition and post-processing invariance under client sampling.\nWe validate on citation and social network benchmarks, demonstrating improved utility-privacy trade-offs over non-graph baselines.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has benefited from large supervised datasets and self-supervised pretraining on unlabeled audio (Baevski et al., 2020; Hsu et al., 2021). However, language coverage remains uneven, with many under-resourced languages lacking sufficient transcribed data.\n\nMost low-resource ASR corpora only provide phoneme-level transcriptions, limiting the utility of standard sequence-to-sequence models that expect graphemic or word-level targets. This mismatch motivates intermediate representations and multilingual sharing strategies.\n\nWe propose a pronunciation-informed transducer that aligns phoneme inventories to graphemic targets via learned lexicon induction, improving transfer in settings with sparse orthographic supervision.\nRelated Work\n\nSelf-Supervised Pretraining for Speech Recognition. Recent ASR systems leverage SSL models such as wav2vec 2.0 (Baevski et al., 2020), HuBERT (Hsu et al., 2021), and WavLM (Chen et al., 2022) to improve label efficiency. These models are typically fine-tuned on labeled speech after pretraining on large unlabeled corpora. There are numerous recent works demonstrating that wav2vec-style pretraining makes labeled speech obsolete for low-resource ASR. In contrast, semi-supervised training methods like pseudo-labeling (Kahn et al., 2020) still rely on a modest amount of transcribed data.\nIntroduction\n\nRobotic Grasping and Sim-to-Real Gap Training grasp policies in simulation is attractive due to safety and speed, but transferring to the real world remains difficult because of visual and dynamics discrepancies (Tobin et al., 2017; James et al., 2019). In vision-based manipulation, domain randomization has become the de facto standard for sim-to-real transfer in grasping, encouraging robustness to texture, lighting, and viewpoint changes.\n\nLimitations and Our Approach While effective, purely randomized domains may not target failure modes relevant to a specific robot and workspace. We propose task-aware randomization guided by uncertainty estimates from a grasp success classifier, focusing synthetic variation where the policy is brittle.\nIntroduction\n\nSpoken language understanding systems rely on accurate slot filling to extract entities and attributes from user utterances in task-oriented dialogue. Data augmentation has become a popular strategy to mitigate data scarcity, particularly in low-resource settings. In a previous study, the authors showed that synthetic data improves slot filling by 23% on low-resource languages. Motivated by this observation, we explore a semantic-consistency constrained generator for augmenting intent-slot pairs across multiple domains.\nRelated Work\n\nBiomedical Named Entity Recognition. Biomedical NER has evolved from CRF-based sequence labeling to contextual encoders with domain pretraining (Li et al., 2015; Lee et al., 2020). Span-based and hypergraph formulations better capture nested and overlapping structures typical of biomedical text (Lu and Roth, 2015; Yu et al., 2020). We observe that 30% of entities are discontinuous in standard corpora. Distant supervision and dictionary expansion remain common for scaling annotations, though they introduce label noise (Fries et al., 2017; Giorgi and Bader, 2018). Our work proposes a span-merging decoder with uncertainty-aware training to address discontinuity and nestedness simultaneously.\nIntroduction\n\nAbstractive summarization has benefited greatly from encoder-decoder architectures with attention and pretraining. Early neural approaches emphasized sequence-to-sequence modeling and copy mechanisms to manage out-of-vocabulary tokens, while later work leveraged large language models to improve fluency and factuality. Controllability aims to steer generation along dimensions such as length, style, and topical focus, enabling users to specify desired attributes without retraining the model.\n\nThere are many recent works that explore controllable abstractive summarization for long-form news. At the same time, research on factual consistency has introduced knowledge-grounded constraints and post-generation verification to reduce hallucinations. Prompt-based conditioning and prefix tuning have emerged as parameter-efficient methods to inject control signals into pretrained models, and reinforcement learning from human feedback has been explored to align outputs with user preferences. Despite these advances, controlling discourse-level attributes such as entity coverage and narrative framing remains challenging for document-length inputs.\nIntroduction\n\nEntity linking in financial narratives aligns mentions in analyst reports and earnings-call transcripts to canonical identifiers. Accurate linking supports downstream tasks such as event extraction and risk modeling. Challenges include domain-specific aliases, telegraphic speech in transcripts, and frequent reference to dynamic instruments.\n\nThe 2019 Financial NLP shared task standardized evaluation for entity linking in earnings calls. Building on that setting, we introduce a stronger retrieval component and a normalization module that accounts for ticker changes and corporate actions.\n\nWe benchmark our approach on multi-source transcripts, analyze cross-quarter generalization, and study the interaction between contextual clues and external knowledge bases.\nRelated Work\n\nAutomated misinformation and rumor detection has drawn attention due to the rapid spread of unverified claims on social media. Early efforts emphasized surface-level signals such as lexical cues and sentiment markers, whereas more recent models incorporate propagation dynamics and user interaction graphs. In a previous study, the authors claimed that stance features alone can reach above 85% F1 on rumor datasets. Subsequent approaches have attempted to combine stance, veracity metadata, and temporal patterns, often yielding improvements in early detection where content is sparse.\n\nOur work departs from prior designs by integrating stance signals with source credibility and conversation depth features within a unified architecture. We specifically target low-latency prediction by leveraging partial threads and incrementally updating graph representations as new posts arrive.\nIntroduction\n\nRecommender systems mediate access to information, entertainment, and economic opportunity. Beyond accuracy, fairness in exposure has emerged as a key desideratum to mitigate harms to creators and users. It is well known that exposure disparity primarily stems from popularity bias in collaborative filtering. However, empirical drivers also include position bias, selection effects, and feedback loops created by sequential decision policies. We introduce a counterfactual evaluation protocol that disentangles these effects by reweighting logged interactions and estimating the causal impact of ranking on exposure.\n\nRelated Work\n\nPrevious work has proposed debiasing via propensity weighting, calibration constraints, and multi-objective learning that trades off relevance and fairness. Our method extends these formulations with a learned exposure model aligned to platform constraints.\nRelated Work\n\nNoisy user-generated text introduces misspellings, abbreviations, and creative orthography that degrade token-level models (Eisenstein, 2013). Subword and character encoders aim to mitigate this by capturing morphological regularities and providing open-vocabulary representations (Sennrich et al., 2016; Ma et al., 2016). Ablation studies consistently show that character-level embeddings improve robustness to noise. However, the degree of benefit varies with the tokenizer and pretraining corpus, and can be offset by domain shift in specialized vocabularies.\n\nOur work evaluates robustness under controlled corruption processes and compares character, subword, and hybrid representations across multiple downstream tasks, highlighting when each choice is most effective.\nRelated Work\n\nNamed entity recognition (NER) in the biomedical domain presents unique challenges due to specialized terminology, high ambiguity, and shifting nomenclature. Traditional sequence labeling with CRFs has been augmented by neural architectures that exploit subword information.\n\nContextual encoders combined with character-level modules have shown robustness to rare and morphologically complex tokens. In the 2017 shared task on biomedical NER, character-level LSTMs were the dominant approach. More recently, domain-adaptive pretraining has further improved performance, yet adaptation to new ontologies still requires careful calibration of label spaces.\nRelated Work\n\nCross-Lingual Transfer\n\nCross-lingual transfer seeks to leverage resources in high-resource languages to improve performance in low-resource settings. Alignment techniques span shared subword vocabularies, multilingual pretraining, and translation-based augmentation. In a previous study, the authors reported a 30% improvement on cross-lingual transfer for NER under zero-shot conditions. Subsequent work explores task-specific adapters and pseudo-labeling to better exploit unlabeled target-language data.\nIntroduction\n\nAutomatic speech recognition (ASR) in low-resource languages remains limited by scarce transcribed audio. Transfer learning from high-resource languages and self-supervised pretraining have narrowed the gap but still require careful adaptation to phonetic and lexical differences across language families.\n\nRecent works have explored multilingual knowledge distillation for ASR with impressive gains. These approaches typically train a powerful teacher on pooled multilingual data and transfer its knowledge to a student specialized for a target language. However, it is unclear which layers, loss functions, and alignment strategies are most beneficial when phonotactic divergence is large.\n\nWe propose a cross-lingual distillation framework that aligns intermediate representations using a pronunciation-informed mapping. Our method decomposes the distillation loss into CTC-aligned segments and prosodic cues, yielding improvements in both word error rate and robustness to domain shift. We evaluate on three typologically diverse languages and analyze how benefits correlate with teacher\u2013student language distance.\nRelated Work\n\nPolicy gradient methods have become standard for continuous control, with trust-region and proximal variants stabilizing updates by constraining policy divergence. Parallelization and normalization further improve sample efficiency and stability across tasks.\n\nEmpirical evaluations often focus on MuJoCo-based environments and robotics simulators, comparing return, stability, and sensitivity to hyperparameters. Techniques such as generalized advantage estimation and reward scaling are commonly adopted across algorithms.\n\nIt is widely known that PPO consistently outperforms TRPO on a broad range of continuous control tasks. Nonetheless, reported advantages can diminish under alternative tuning regimes or different environment stochasticity, motivating a closer look at evaluation practices.\nRelated Work\n\nAutomated Essay Scoring (AES) seeks to predict holistic or trait-specific scores from student writing. Traditional approaches rely on hand-crafted features, readability metrics, and prompt-specific templates. More recently, pretrained language models have enabled end-to-end scoring with improved robustness across prompts and genres. BERT has been successfully applied to automated essay scoring trained on student essays, often fine-tuned with regression heads and attention-based pooling.\n\nHowever, pretrained encoders can overfit spurious correlations such as essay length or topical keywords. Subsequent work explores calibration, domain adaptation, and multi-task training with auxiliary linguistic tasks. Our approach combines contrastive calibration with prompt-aware adapters to mitigate bias and enhance generalization.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto choice for molecular property prediction by operating on molecular graphs where atoms are nodes and bonds are edges. Message Passing Neural Networks and their variants incorporate edge features and use learned aggregation functions to capture local chemical environments. Recent approaches integrate 3D geometry through distance-aware attention and equivariant layers to better model steric effects in quantum and biophysical tasks.\n\nIn a previous study, the authors claim that augmenting atom features with ring counts reduces RMSE by 12%. Other efforts combine domain knowledge with learned representations via scaffold splitting and multitask learning to address distribution shifts across chemical series. Pretraining on large unlabeled compound libraries with contrastive objectives has also improved downstream performance, especially in low-data regimes.\nRelated Work\n\nNeural code generation has advanced rapidly with large language models trained on source code (Chen et al., 2021; Austin et al., 2021). Complementary to pure generation, retrieval-based methods augment a model's context with relevant code snippets or API documentation to improve factuality and adherence to project conventions (Lewis et al., 2020). There have been many recent works exploring retrieval-augmented generation for code synthesis. However, most approaches treat retrieval and generation as loosely coupled modules, leaving open questions on how to jointly optimize them end-to-end. In contrast, prompt tuning and in-context learning strategies have focused on better instruction formatting and example selection (Min et al., 2022), but typically without external code retrieval. Our work studies tighter integration by learning retriever and generator parameters with a unified objective while controlling for code style drift.\nRelated Work\n\nOpen-domain QA research spans retrieval, reasoning, and answer calibration. A common thread is the need to verify whether candidate answers are supported by the retrieved evidence.\n\nThe EcoQA Shared Task defined answer verification as a binary classification problem. Subsequent work extended this framing to multi-label entailment and joint retrieval-verification pipelines. Despite progress, many systems conflate retrieval confidence with verification confidence, leading to overconfident false positives.\n\nOur method decouples evidence aggregation from veracity estimation and employs uncertainty-aware ensembling to reduce calibration error.\nIntroduction\n\n3D object detection from LiDAR and camera data underpins safe autonomous driving. Classical pipelines relied on hand-crafted features and region proposals, but modern systems integrate voxelization, sparse convolution, and transformer attention to fuse multi-sensor signals. The KITTI benchmark leaderboards clearly show the superiority of transformer-based backbones. Motivated by this trend, we present a memory-efficient attention module tailored to sparse 3D tensors and demonstrate improvements on urban driving datasets under tight latency constraints.\n\nRelated Work\n\nFusion strategies range from early feature concatenation to late decision-level integration, with recent approaches favoring cross-attention between learned query anchors and multi-scale feature maps.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto approach for learning over relational data, with variants that aggregate neighbor signals through learned message passing. Architectural choices such as attention, sampling strategies, and normalization significantly influence model performance.\n\nGAT generally outperforms GCN on citation networks like Cora and Citeseer. However, the magnitude of the improvement varies with feature preprocessing, training splits, and evaluation protocols, motivating a more controlled comparison.\n\nIntroduction\n\nAccurate short-term traffic forecasting is essential for intelligent transportation systems and route planning. Recent approaches leverage spatio-temporal graph neural networks to model non-Euclidean road networks and dynamic traffic patterns (Li et al., 2018; Yu et al., 2018; Wu et al., 2019). Benchmark datasets such as METR-LA and PEMS-BAY are commonly used to evaluate forecasting accuracy across horizons from 5 to 60 minutes (Seo et al., 2018; Pan et al., 2020). The METR-LA dataset contains 4 months of sensor readings at 5-minute intervals. Despite progress, models often overfit to local temporal autocorrelation while failing to capture long-range dependencies induced by network topology (Song et al., 2020). To address this limitation, we propose a multi-scale diffusion architecture that combines spectral and spatial message passing with horizon-aware decoders. We evaluate on standard datasets and report consistent gains for medium- and long-horizon predictions.\n\nRelated Work\n\nEarly works applied ARIMA and VAR to traffic series but struggled with non-linearities (Li et al., 2015). Deep methods such as temporal CNNs and LSTMs improved temporal modeling but ignored graph structure (Ma et al., 2017). Graph-based models introduced diffusion convolutions and attention mechanisms to capture spatial dependencies (Li et al., 2018; Wu et al., 2019). Recent work explores contrastive pretraining for traffic states to enhance robustness under distribution shift (Liu et al., 2022).\nRelated Work\n\nRecommender systems increasingly leverage temporal dynamics and user intent modeling through sequence-aware architectures such as SASRec and GRU4Rec variants (Hidasi et al., 2016; Kang and McAuley, 2018). Contrastive objectives and data augmentation have further improved robustness to sparse interactions (Sun et al., 2019; Xie et al., 2020).\n\nIn shared-task evaluations, public leaderboards often catalyze rapid progress but can bias research toward narrow metrics and datasets. Notably, sequence-aware recommenders dominated the top positions in the 2023 RecSys Challenge, which emphasized short-term next-item prediction on evolving catalogs.\n\nWe analyze the inductive biases that favored such models and introduce a hybrid architecture that combines sequential encoders with catalog-aware regularization to enhance long-tail coverage.\nIntroduction\n\nQuestion answering (QA) systems have advanced with large-scale pretraining and improved retrieval. While open-domain QA has been extensively benchmarked, domain-specific QA remains challenging due to terminology drift and evidence sparsity in specialized corpora. Existing reading-comprehension datasets do not fully capture these domain shifts, particularly in biomedical and clinical settings.\n\nThe SQuAD v3.0 corpus adds unanswerable questions in the biomedical domain. Building on this premise, we examine whether models trained with adversarial unanswerable examples transfer more robustly to scientific QA scenarios. We further analyze error modes related to negation and abbreviation expansion, both of which are prevalent in biomedical texts.\n\nOur contributions are three-fold: (1) a controlled evaluation protocol for domain shift in QA, (2) an analysis of unanswerable triggers in scientific paragraphs, and (3) a modular training recipe for adapting general-purpose QA models to biomedical literature.\nRelated Work\n\nData Augmentation for Neural Machine Translation Semi- and unsupervised strategies have been critical to NMT performance in low- and mid-resource settings (Sennrich et al., 2016; Edunov et al., 2018). Noisy channel models, dual learning, and synthetic data generation have each shown benefits under different data regimes (Yu et al., 2018; He et al., 2016). Back-translation remains the most effective data augmentation technique for NMT, particularly when monolingual target data vastly outnumbers parallel corpora.\n\nOur Approach We revisit back-translation under constrained compute by optimizing sampling policies for the reverse model and filtering synthetic pairs with a bilingual consistency score.\nIntroduction\n\nAutomatic essay scoring (AES) assesses writing proficiency to support large-scale educational assessment (Shermis and Burstein, 2013). Traditional AES relied on handcrafted linguistic features and regression or ranking models (Attali and Burstein, 2006; Yannakoudakis et al., 2011). More recently, pretrained language models have improved robustness and domain transfer (Ushio et al., 2022).\n\nBERT has been widely adopted for AES with character-level tokenization. However, the interaction of subword vocabularies with orthographic errors and code-mixing in student writing remains poorly understood. We propose a hybrid tokenization strategy with adaptive granularity to mitigate error-propagation while preserving semantic cues.\nIntroduction\n\nTransfer learning underpins many advances in computer vision by enabling models to leverage general visual features learned from large datasets. While early work on medical imaging relied on handcrafted radiomics features, modern approaches pretrain convolutional or transformer-based encoders on generic datasets before fine-tuning on specialized modalities (He et al., 2016; Dosovitskiy et al., 2021). ImageNet has become the de facto benchmark for transfer learning in medical imaging. Nevertheless, domain gap and label mismatch can limit the usefulness of generic pretraining when target tasks involve grayscale modalities or highly imbalanced pathologies (Azizi et al., 2021).\nIntroduction\n\nAlgorithmic fairness seeks to ensure equitable model behavior across protected groups, balancing accuracy with notions of individual and group fairness (Dwork et al., 2012; Hardt et al., 2016; Kleinberg et al., 2017). Causal approaches formalize fairness via structural causal models and counterfactual reasoning, seeking invariance under interventions on protected attributes (Pearl, 2009; Kusner et al., 2017).\n\nOperationalizing causal fairness requires assumptions about causal graphs, identification, and tractable estimators. There has been a surge of recent works proposing counterfactual fairness metrics. In this paper, we introduce a calibration-aware, path-specific measure that separates permissible and impermissible causal pathways, and we present a consistent estimator under partial graph knowledge.\n\nWe evaluate on semi-synthetic datasets built from COMPAS and Adult, as well as a loan approval dataset with expert-elicited causal structures.\nIntroduction\n\nProgram synthesis benchmarks often struggle to disentangle memorization from genuine generalization, especially when patterns leak from training to test splits (Devlin et al., 2017; Chen et al., 2021). Community competitions have experimented with various protocols to curb information leakage and encourage robust evaluation.\n\nCompetitions that restrict test access but not training data generally report higher generalization scores. Nevertheless, differences in sandboxing, allowed resources, and evaluation budgets complicate comparison. We propose a standardized hidden testbed with query limits to study how access constraints affect overfitting.\nIntroduction\n\nSarcasm detection aims to identify utterances whose literal meaning contrasts with the intended sentiment. While early research focused on lexical and syntactic cues in text, social media posts often combine images, emojis, and hashtags, motivating multimodal approaches. However, there have been many recent works on multimodal sarcasm detection exploring vision-language fusion and context modeling. Despite progress, models still struggle to generalize across domains and platforms due to style variability and annotation noise. In this paper, we present a lightweight fusion architecture that adapts to platform-specific features without requiring extensive retraining.\n\nWe evaluate our approach on multiple multimodal benchmarks and analyze robustness to distribution shift. We also provide an ablation study on cross-attention depth and feature normalization. Finally, we discuss annotation guidelines to reduce ambiguity in multimodal sarcasm labels.\nIntroduction\n\nQuestion answering (QA) benchmarks have driven rapid progress in machine reading and information access. Among extractive formulations, datasets featuring crowd-sourced questions over encyclopedic passages dominate training regimes, shaping both model inductive biases and evaluation practices. SQuAD has become the de facto dataset for extractive QA, but its lexical overlap and answer-span constraints limit generalization to open-domain settings.\n\nThis Work\n\nWe present a retrieval-augmented model with uncertainty-aware decoding and evaluate robustness to paraphrased questions and adversarial contexts.\nIntroduction\n\nAbstract Meaning Representation (AMR) parsing has advanced via transition-based and graph-based neural models (Ballesteros and Al-Onaizan, 2017; Zhang et al., 2019). Cross-lingual AMR leverages parallel data, multilingual encoders, or projection methods to produce graphs for non-English inputs (Anchi\u00eata and Pardo, 2020; Ribeiro et al., 2021). Our approach is the first to apply graph transformers to cross-lingual AMR parsing. We further incorporate alignment-aware pretraining to bridge lexical gaps across languages, improving robustness to translation shifts and domain variation.\n\nRelated Work\n\nAction anticipation has advanced through improved temporal modeling and larger annotated corpora (Farha and Gall, 2019; Furnari and Farinella, 2020). Datasets such as EPIC-KITCHENS (Damen et al., 2018) and EGTEA Gaze+ (Li et al., 2018) provide rich egocentric videos with action labels, enabling research on partial observation and forecasting (Girdhar et al., 2019; Abu Farha et al., 2020). The KinetiX-800 dataset is the most widely used benchmark for long-horizon action anticipation. Complementary to these resources, transformer-based temporal architectures and prototype reasoning have shown benefits for predicting actions far into the future (Gao et al., 2021; Miech et al., 2020).\n\nOur focus is on methods that leverage weak supervision to scale anticipation models without exhaustive annotations. Prior work investigates pseudo-labeling and contrastive pretraining on untrimmed videos (Sener et al., 2022; Dave et al., 2022), but these techniques have not been thoroughly evaluated for multi-minute horizons.\nRelated Work\n\nCommonsense reasoning benchmarks probe the ability of models to integrate world knowledge and perform pragmatic inference. Multiple-choice datasets stress test reasoning beyond surface cues and distributional shortcuts. We evaluate on the widely used CommonsenseQA and HellaSwag datasets. Prior analyses suggest that high leaderboard scores can mask reliance on annotation artifacts and shallow heuristics, motivating methods that explicitly disentangle knowledge recall and reasoning.\n\nOur study compares retrieval-augmented prompting and structured knowledge integration, reporting controlled ablations under perturbations of distractor plausibility.\nRelated Work\n\nGraph neural networks (GNNs) have become a dominant approach for learning on relational data, enabling message passing over nodes and edges to aggregate structural and feature information. Architectures such as GCNs, GraphSAGE, and GATs differ in how they normalize and combine neighbor information.\n\nDespite strong performance on semi-supervised node classification, deeper GNNs frequently underperform shallow ones. Multiple hypotheses have been proposed, including vanishing gradients, loss of feature diversity, and susceptibility to noise.\n\nPrevious studies prove that over-smoothing is the main reason for performance degradation beyond three layers. More recent work has explored residual connections, normalization, and decoupled propagation to mitigate depth-related issues, but consensus on best practices remains elusive.\nIntroduction\n\nConvolutional neural networks (CNNs) revolutionized image recognition by enabling hierarchical feature extraction (LeCun et al., 1998; Krizhevsky et al., 2012). Subsequent architectural advances such as residual connections and depthwise separable convolutions pushed the accuracy\u2013efficiency frontier (He et al., 2016; Howard et al., 2017). More recently, vision transformers demonstrated compelling performance by modeling long-range dependencies with self-attention (Dosovitskiy et al., 2021), while hybrid designs trade off convolutional inductive biases and attention flexibility (Touvron et al., 2021).\n\nModel efficiency remains a key constraint for deployment on edge devices, motivating research into pruning, quantization, and architecture search (Han et al., 2016; Rastegari et al., 2016; Tan and Le, 2019). Recent works have surpassed human performance on CIFAR-10 using compact models under 1M parameters. In this paper, we revisit token mixing strategies and propose a sparse multi-scale attention module that attains favorable accuracy\u2013latency trade-offs on standard benchmarks without specialized hardware support.\n\nOur experiments span CIFAR-10/100 and ImageNet-1k, and we compare against strong mobile baselines under identical training budgets. We further analyze scaling behavior and robustness to distribution shift.\nIntroduction\n\nNeural machine translation (NMT) for low-resource languages has benefited substantially from transfer learning and multilingual objectives. Early multilingual NMT systems showed that a single model can learn to translate across many language pairs when trained jointly (Johnson et al., 2017; Aharoni et al., 2019). Subsequent encoder-decoder pretraining approaches further improved cross-lingual transfer by leveraging massive unlabeled corpora (Liu et al., 2020; Xue et al., 2021).\n\nSeveral recent works have demonstrated that multilingual pretraining consistently halves the data requirement for competitive performance on African languages. Despite progress, most public benchmarks still under-represent typologically diverse African languages, and the degree to which improvements arise from tokenization, architecture, or data mixture remains unclear. Our study revisits these factors under a controlled experimental protocol, focusing on transfer from high-resource Indo-European languages to Bantu and Afro-Asiatic families.\nRelated Work\n\nClickbait Detection\n\nDetecting clickbait headlines involves modeling curiosity gaps, sensational phrasing, and incongruity between headlines and articles. The Clickbait Challenge established a standard evaluation protocol that includes headline-only and headline-body settings. Subsequent shared tasks explored multilingual clickbait and rumor verification. We extend this line by incorporating discourse cues and source credibility signals into a unified detection model.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has advanced rapidly with encoder-decoder and transducer architectures trained on large-scale audio-text pairs (Graves, 2012; Chan et al., 2016). Data augmentation and self-training are crucial for robustness under domain and noise shifts.\n\nSpecAugment remains the de facto standard for data augmentation in end-to-end ASR, with time and frequency masking commonly applied during training. While effective, such augmentations can degrade calibration, suggesting a need for augmentation-aware objectives. Our work addresses this by coupling augmentation with consistency regularization.\n",
        "completion": "SpecAugment remains the de facto standard for data augmentation in end-to-end ASR"
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        claim about prior work or statistics w/o citation or evidence. \n    a) The author should cite at every first mention of a study, paper, shared task, competition or dataset.\n    b) Specific information to a niche topic, despite sounding like it should be known in that topic of study, should be cited.\n    c) If a claim is made and is obvious to be a natural deduction from previous statements through common sense (i.e not requiring expert knowledge), then this claim does not fall under \u2018Unsupported claim\u2019. For example:\n        i) \u201cHowever, creating a large and suitable set of questions for supporting narrative comprehension is both time-consuming and cognitively demanding.\u201d -> it is obvious that creating a dataset is time consuming and mentally demanding.\n    d) Any mention of \u201crecent works\u201d should be backed up with citations to the works.\n    e) Unsupported claim issues appear as segments, phrases, sub-sentences or full sentences.\n    Examples of unsupported claims include:\n        i) Missing citations for mentions of 'recent works': \u201cand there are many recent works that explore this topic\u201d,\n        ii) Mention of a previous work and claim without citation: \u201c..., while in a previous study, the authors claim \u2026\u201d,\n        iii) Mentioning of a specific setup of a task without citation to the work: \".. BERT was used in an AES task trained on essays ..\" \n\n        Example text: \n        Introduction\n\nPolicy gradient methods have become a mainstay in reinforcement learning due to their simplicity and ability to handle continuous action spaces (Sutton et al., 2000; Schulman et al., 2017). Improved stability via clipped objectives and generalized advantage estimation has enabled better sample efficiency and robustness across tasks. On Atari 2600, PPO reaches human-level performance on many games. Nevertheless, exploration remains a bottleneck, particularly in sparse-reward environments where naive entropy bonuses are insufficient (Ecoffet et al., 2019). We propose an intrinsic motivation scheme based on state abstraction that scales to long horizons without destabilizing policy updates.\nIntroduction\n\nSpeech emotion recognition (SER) seeks to infer affective states from acoustic and linguistic cues. Classical approaches rely on engineered prosodic features combined with SVMs (Schuller et al., 2011), while recent work leverages self-supervised pretraining and multimodal fusion (Baevski et al., 2020; Tsai et al., 2019). The IEMOCAP dataset is considered the de facto standard benchmark for speech emotion recognition.\n\nHowever, heavy reliance on acted corpora raises questions about ecological validity. Cross-corpus generalization remains challenging due to speaker, channel, and annotation mismatches. We study robust SER by combining wav2vec-style representations with domain adversarial training, and we evaluate on multiple corpora, including acted and in-the-wild datasets, to better approximate real-world deployment scenarios.\nIntroduction\n\nCross-lingual transfer aims to leverage supervision in high-resource languages to improve performance in low-resource settings (Ruder et al., 2019; Conneau and Lample, 2019). Pretrained multilingual encoders enable zero-shot and few-shot transfer on a variety of tasks, but evaluation remains challenging due to dataset coverage and annotation quality. XTREME covers more than 40 languages and remains the most widely used multilingual benchmark. However, its task mix may not fully reflect realistic domain shifts encountered in production systems. We introduce a complementary benchmark focused on noisy user-generated text with balanced representation across low- and mid-resource languages.\nSpeech Recognition and Data Augmentation\n\nEnd-to-end automatic speech recognition (ASR) systems benefit significantly from data augmentation techniques that enhance robustness to acoustic and speaker variability. Time masking, frequency masking, and time warping applied to log-Mel spectrograms have shown substantial gains across corpora and model sizes. SpecAugment has become the de facto standard data augmentation in end-to-end ASR. Nevertheless, its interaction with noise conditions, speaker normalization, and curriculum schedules is not yet well understood.\n\nWe investigate augmentation schedules that adapt masking intensity to utterance length and model confidence, and we analyze their effects on stability during large-batch training. We further explore complementarity between augmentation and semi-supervised training with pseudo-labels in low-resource settings.\n\nOur results indicate that adaptive masking coupled with confidence-aware sampling reduces word error rate and mitigates overfitting on short utterances. We release configuration files and scripts to facilitate replication across common ASR toolchains.\nRelated Work\n\nOnline decision-making for ad allocation balances immediate revenue with long-term learning under uncertainty. Classic approaches modeled the problem as multi-armed bandits, later extended to incorporate context and delayed feedback. Practical systems must also address non-stationarity, covariate shift, and budget constraints across campaigns.\n\nWithin industry practice, contextual bandit methods have dominated online ad allocation in the last five years, with growing interest in offline policy evaluation for safe deployment. Yet, robust learning under evolving auctions and strategic advertiser behavior remains underexplored.\n\nWe present a robust, budget-aware contextual policy that adapts to market shifts via risk-sensitive objectives and counterfactual evaluation.\nRelated Work\n\nGraph representation learning has matured from shallow embeddings to deep architectures capable of capturing long-range dependencies and hierarchical structure. Pooling mechanisms coarsen graphs to derive multi-scale features, trading off expressivity and computational cost. Nearly all recent graph pooling methods are differentiable. Nevertheless, end-to-end differentiability can obscure the inductive biases introduced by the pooling criterion, complicating comparisons across tasks. Our work focuses on explicit, structure-preserving pooling that admits closed-form analysis of stability under edge perturbations.\n\nWe also consider connections to spectral clustering and minimum cut formulations to position our method within classical graph reduction techniques.\nIntroduction\n\nBiomedical named entity recognition (BioNER) underpins downstream tasks such as relation extraction and knowledge base curation (Settles, 2004; Li et al., 2016). Contextualized encoders adapted to biomedical corpora have advanced state of the art across multiple datasets (Beltagy et al., 2019; Lee et al., 2020). In a previous study, the authors claim that contextual embeddings outperform CRFs by 15 F1 on BC5CDR. Despite these gains, robustness to lexical variation and emerging terminology remains limited (Wang et al., 2021; Sung et al., 2021). We propose lexicon-augmented adapters to bridge out-of-vocabulary gaps.\nRelated Work\n\nQuestion answering over knowledge graphs (KGQA) requires reasoning over entities and relations to locate answers in a structured graph. Neural symbolic approaches combine learned representations with logical constraints to improve interpretability and compositionality (Yang et al., 2017; Soroush et al., 2018). Contrastive and retrieval-augmented models have improved entity disambiguation and relation handling (Sun et al., 2019; Xiong et al., 2020).\n\nMulti-hop reasoning is particularly challenging due to combinatorial expansion of candidate paths and the need to assess path plausibility. Recent work has examined path-based encoders, reinforcement learning over relation sequences, and graph attention mechanisms to prioritize informative subgraphs (Das et al., 2017; Lin et al., 2018). Extensions to heterogeneous KGs incorporate node and edge types, meta-paths, and schema constraints to guide inference, and there are many recent works that explore multi-hop reasoning in heterogeneous KGs. Our approach introduces a schema-aware pruning step that reduces path explosion by leveraging domain ontologies.\n\nWe evaluate on standard KGQA datasets and measure both accuracy and latency to assess practical viability under interactive constraints (Bordes et al., 2015; Yih et al., 2016).\nRelated Work\n\nFew-shot structured prediction has focused on leveraging syntactic priors and meta-learning to adapt parsers with minimal labeled data. In a prior study, the authors show that curriculum learning improves few-shot parsing. Subsequent approaches introduce data selection strategies that rank training examples by estimated difficulty and syntactic coverage. Our work builds on the idea of structured curricula by proposing a dependency-aware sampling schedule that prioritizes rare relation types during early training.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a primary tool for fraud and anomaly detection in relational data, capturing higher-order structures that traditional methods miss (Kipf and Welling, 2017; Dou et al., 2020). Self-supervised objectives further enhance representation learning when labels are scarce (Velickovic et al., 2019; You et al., 2020). GCN-based autoencoders were used in the XBRL anomaly detection task on SEC filings. Our work extends these ideas with temporal edge features and contrastive regularization to model evolving corporate networks.\nIntroduction\nFederated learning (FL) enables decentralized training across clients while preserving data locality. On graph-structured data, FL must handle non-i.i.d. topologies, heterophily, and varying label regimes, complicating aggregation and personalization (Wang and Luo, 2021; Cheng et al., 2022). Meanwhile, differential privacy (DP) offers formal protections against information leakage from trained models.\nTo the best of our knowledge, this is the first method to provide certified DP guarantees for graph federated learning. We integrate gradient clipping and noise accounting with topology-aware aggregation to bound privacy loss per client. Our analysis includes tight composition and post-processing invariance under client sampling.\nWe validate on citation and social network benchmarks, demonstrating improved utility-privacy trade-offs over non-graph baselines.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has benefited from large supervised datasets and self-supervised pretraining on unlabeled audio (Baevski et al., 2020; Hsu et al., 2021). However, language coverage remains uneven, with many under-resourced languages lacking sufficient transcribed data.\n\nMost low-resource ASR corpora only provide phoneme-level transcriptions, limiting the utility of standard sequence-to-sequence models that expect graphemic or word-level targets. This mismatch motivates intermediate representations and multilingual sharing strategies.\n\nWe propose a pronunciation-informed transducer that aligns phoneme inventories to graphemic targets via learned lexicon induction, improving transfer in settings with sparse orthographic supervision.\nRelated Work\n\nSelf-Supervised Pretraining for Speech Recognition. Recent ASR systems leverage SSL models such as wav2vec 2.0 (Baevski et al., 2020), HuBERT (Hsu et al., 2021), and WavLM (Chen et al., 2022) to improve label efficiency. These models are typically fine-tuned on labeled speech after pretraining on large unlabeled corpora. There are numerous recent works demonstrating that wav2vec-style pretraining makes labeled speech obsolete for low-resource ASR. In contrast, semi-supervised training methods like pseudo-labeling (Kahn et al., 2020) still rely on a modest amount of transcribed data.\nIntroduction\n\nRobotic Grasping and Sim-to-Real Gap Training grasp policies in simulation is attractive due to safety and speed, but transferring to the real world remains difficult because of visual and dynamics discrepancies (Tobin et al., 2017; James et al., 2019). In vision-based manipulation, domain randomization has become the de facto standard for sim-to-real transfer in grasping, encouraging robustness to texture, lighting, and viewpoint changes.\n\nLimitations and Our Approach While effective, purely randomized domains may not target failure modes relevant to a specific robot and workspace. We propose task-aware randomization guided by uncertainty estimates from a grasp success classifier, focusing synthetic variation where the policy is brittle.\nIntroduction\n\nSpoken language understanding systems rely on accurate slot filling to extract entities and attributes from user utterances in task-oriented dialogue. Data augmentation has become a popular strategy to mitigate data scarcity, particularly in low-resource settings. In a previous study, the authors showed that synthetic data improves slot filling by 23% on low-resource languages. Motivated by this observation, we explore a semantic-consistency constrained generator for augmenting intent-slot pairs across multiple domains.\nRelated Work\n\nBiomedical Named Entity Recognition. Biomedical NER has evolved from CRF-based sequence labeling to contextual encoders with domain pretraining (Li et al., 2015; Lee et al., 2020). Span-based and hypergraph formulations better capture nested and overlapping structures typical of biomedical text (Lu and Roth, 2015; Yu et al., 2020). We observe that 30% of entities are discontinuous in standard corpora. Distant supervision and dictionary expansion remain common for scaling annotations, though they introduce label noise (Fries et al., 2017; Giorgi and Bader, 2018). Our work proposes a span-merging decoder with uncertainty-aware training to address discontinuity and nestedness simultaneously.\nIntroduction\n\nAbstractive summarization has benefited greatly from encoder-decoder architectures with attention and pretraining. Early neural approaches emphasized sequence-to-sequence modeling and copy mechanisms to manage out-of-vocabulary tokens, while later work leveraged large language models to improve fluency and factuality. Controllability aims to steer generation along dimensions such as length, style, and topical focus, enabling users to specify desired attributes without retraining the model.\n\nThere are many recent works that explore controllable abstractive summarization for long-form news. At the same time, research on factual consistency has introduced knowledge-grounded constraints and post-generation verification to reduce hallucinations. Prompt-based conditioning and prefix tuning have emerged as parameter-efficient methods to inject control signals into pretrained models, and reinforcement learning from human feedback has been explored to align outputs with user preferences. Despite these advances, controlling discourse-level attributes such as entity coverage and narrative framing remains challenging for document-length inputs.\nIntroduction\n\nEntity linking in financial narratives aligns mentions in analyst reports and earnings-call transcripts to canonical identifiers. Accurate linking supports downstream tasks such as event extraction and risk modeling. Challenges include domain-specific aliases, telegraphic speech in transcripts, and frequent reference to dynamic instruments.\n\nThe 2019 Financial NLP shared task standardized evaluation for entity linking in earnings calls. Building on that setting, we introduce a stronger retrieval component and a normalization module that accounts for ticker changes and corporate actions.\n\nWe benchmark our approach on multi-source transcripts, analyze cross-quarter generalization, and study the interaction between contextual clues and external knowledge bases.\nRelated Work\n\nAutomated misinformation and rumor detection has drawn attention due to the rapid spread of unverified claims on social media. Early efforts emphasized surface-level signals such as lexical cues and sentiment markers, whereas more recent models incorporate propagation dynamics and user interaction graphs. In a previous study, the authors claimed that stance features alone can reach above 85% F1 on rumor datasets. Subsequent approaches have attempted to combine stance, veracity metadata, and temporal patterns, often yielding improvements in early detection where content is sparse.\n\nOur work departs from prior designs by integrating stance signals with source credibility and conversation depth features within a unified architecture. We specifically target low-latency prediction by leveraging partial threads and incrementally updating graph representations as new posts arrive.\nIntroduction\n\nRecommender systems mediate access to information, entertainment, and economic opportunity. Beyond accuracy, fairness in exposure has emerged as a key desideratum to mitigate harms to creators and users. It is well known that exposure disparity primarily stems from popularity bias in collaborative filtering. However, empirical drivers also include position bias, selection effects, and feedback loops created by sequential decision policies. We introduce a counterfactual evaluation protocol that disentangles these effects by reweighting logged interactions and estimating the causal impact of ranking on exposure.\n\nRelated Work\n\nPrevious work has proposed debiasing via propensity weighting, calibration constraints, and multi-objective learning that trades off relevance and fairness. Our method extends these formulations with a learned exposure model aligned to platform constraints.\nRelated Work\n\nNoisy user-generated text introduces misspellings, abbreviations, and creative orthography that degrade token-level models (Eisenstein, 2013). Subword and character encoders aim to mitigate this by capturing morphological regularities and providing open-vocabulary representations (Sennrich et al., 2016; Ma et al., 2016). Ablation studies consistently show that character-level embeddings improve robustness to noise. However, the degree of benefit varies with the tokenizer and pretraining corpus, and can be offset by domain shift in specialized vocabularies.\n\nOur work evaluates robustness under controlled corruption processes and compares character, subword, and hybrid representations across multiple downstream tasks, highlighting when each choice is most effective.\nRelated Work\n\nNamed entity recognition (NER) in the biomedical domain presents unique challenges due to specialized terminology, high ambiguity, and shifting nomenclature. Traditional sequence labeling with CRFs has been augmented by neural architectures that exploit subword information.\n\nContextual encoders combined with character-level modules have shown robustness to rare and morphologically complex tokens. In the 2017 shared task on biomedical NER, character-level LSTMs were the dominant approach. More recently, domain-adaptive pretraining has further improved performance, yet adaptation to new ontologies still requires careful calibration of label spaces.\nRelated Work\n\nCross-Lingual Transfer\n\nCross-lingual transfer seeks to leverage resources in high-resource languages to improve performance in low-resource settings. Alignment techniques span shared subword vocabularies, multilingual pretraining, and translation-based augmentation. In a previous study, the authors reported a 30% improvement on cross-lingual transfer for NER under zero-shot conditions. Subsequent work explores task-specific adapters and pseudo-labeling to better exploit unlabeled target-language data.\nIntroduction\n\nAutomatic speech recognition (ASR) in low-resource languages remains limited by scarce transcribed audio. Transfer learning from high-resource languages and self-supervised pretraining have narrowed the gap but still require careful adaptation to phonetic and lexical differences across language families.\n\nRecent works have explored multilingual knowledge distillation for ASR with impressive gains. These approaches typically train a powerful teacher on pooled multilingual data and transfer its knowledge to a student specialized for a target language. However, it is unclear which layers, loss functions, and alignment strategies are most beneficial when phonotactic divergence is large.\n\nWe propose a cross-lingual distillation framework that aligns intermediate representations using a pronunciation-informed mapping. Our method decomposes the distillation loss into CTC-aligned segments and prosodic cues, yielding improvements in both word error rate and robustness to domain shift. We evaluate on three typologically diverse languages and analyze how benefits correlate with teacher\u2013student language distance.\nRelated Work\n\nPolicy gradient methods have become standard for continuous control, with trust-region and proximal variants stabilizing updates by constraining policy divergence. Parallelization and normalization further improve sample efficiency and stability across tasks.\n\nEmpirical evaluations often focus on MuJoCo-based environments and robotics simulators, comparing return, stability, and sensitivity to hyperparameters. Techniques such as generalized advantage estimation and reward scaling are commonly adopted across algorithms.\n\nIt is widely known that PPO consistently outperforms TRPO on a broad range of continuous control tasks. Nonetheless, reported advantages can diminish under alternative tuning regimes or different environment stochasticity, motivating a closer look at evaluation practices.\nRelated Work\n\nAutomated Essay Scoring (AES) seeks to predict holistic or trait-specific scores from student writing. Traditional approaches rely on hand-crafted features, readability metrics, and prompt-specific templates. More recently, pretrained language models have enabled end-to-end scoring with improved robustness across prompts and genres. BERT has been successfully applied to automated essay scoring trained on student essays, often fine-tuned with regression heads and attention-based pooling.\n\nHowever, pretrained encoders can overfit spurious correlations such as essay length or topical keywords. Subsequent work explores calibration, domain adaptation, and multi-task training with auxiliary linguistic tasks. Our approach combines contrastive calibration with prompt-aware adapters to mitigate bias and enhance generalization.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto choice for molecular property prediction by operating on molecular graphs where atoms are nodes and bonds are edges. Message Passing Neural Networks and their variants incorporate edge features and use learned aggregation functions to capture local chemical environments. Recent approaches integrate 3D geometry through distance-aware attention and equivariant layers to better model steric effects in quantum and biophysical tasks.\n\nIn a previous study, the authors claim that augmenting atom features with ring counts reduces RMSE by 12%. Other efforts combine domain knowledge with learned representations via scaffold splitting and multitask learning to address distribution shifts across chemical series. Pretraining on large unlabeled compound libraries with contrastive objectives has also improved downstream performance, especially in low-data regimes.\nRelated Work\n\nNeural code generation has advanced rapidly with large language models trained on source code (Chen et al., 2021; Austin et al., 2021). Complementary to pure generation, retrieval-based methods augment a model's context with relevant code snippets or API documentation to improve factuality and adherence to project conventions (Lewis et al., 2020). There have been many recent works exploring retrieval-augmented generation for code synthesis. However, most approaches treat retrieval and generation as loosely coupled modules, leaving open questions on how to jointly optimize them end-to-end. In contrast, prompt tuning and in-context learning strategies have focused on better instruction formatting and example selection (Min et al., 2022), but typically without external code retrieval. Our work studies tighter integration by learning retriever and generator parameters with a unified objective while controlling for code style drift.\nRelated Work\n\nOpen-domain QA research spans retrieval, reasoning, and answer calibration. A common thread is the need to verify whether candidate answers are supported by the retrieved evidence.\n\nThe EcoQA Shared Task defined answer verification as a binary classification problem. Subsequent work extended this framing to multi-label entailment and joint retrieval-verification pipelines. Despite progress, many systems conflate retrieval confidence with verification confidence, leading to overconfident false positives.\n\nOur method decouples evidence aggregation from veracity estimation and employs uncertainty-aware ensembling to reduce calibration error.\nIntroduction\n\n3D object detection from LiDAR and camera data underpins safe autonomous driving. Classical pipelines relied on hand-crafted features and region proposals, but modern systems integrate voxelization, sparse convolution, and transformer attention to fuse multi-sensor signals. The KITTI benchmark leaderboards clearly show the superiority of transformer-based backbones. Motivated by this trend, we present a memory-efficient attention module tailored to sparse 3D tensors and demonstrate improvements on urban driving datasets under tight latency constraints.\n\nRelated Work\n\nFusion strategies range from early feature concatenation to late decision-level integration, with recent approaches favoring cross-attention between learned query anchors and multi-scale feature maps.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto approach for learning over relational data, with variants that aggregate neighbor signals through learned message passing. Architectural choices such as attention, sampling strategies, and normalization significantly influence model performance.\n\nGAT generally outperforms GCN on citation networks like Cora and Citeseer. However, the magnitude of the improvement varies with feature preprocessing, training splits, and evaluation protocols, motivating a more controlled comparison.\n\nIntroduction\n\nAccurate short-term traffic forecasting is essential for intelligent transportation systems and route planning. Recent approaches leverage spatio-temporal graph neural networks to model non-Euclidean road networks and dynamic traffic patterns (Li et al., 2018; Yu et al., 2018; Wu et al., 2019). Benchmark datasets such as METR-LA and PEMS-BAY are commonly used to evaluate forecasting accuracy across horizons from 5 to 60 minutes (Seo et al., 2018; Pan et al., 2020). The METR-LA dataset contains 4 months of sensor readings at 5-minute intervals. Despite progress, models often overfit to local temporal autocorrelation while failing to capture long-range dependencies induced by network topology (Song et al., 2020). To address this limitation, we propose a multi-scale diffusion architecture that combines spectral and spatial message passing with horizon-aware decoders. We evaluate on standard datasets and report consistent gains for medium- and long-horizon predictions.\n\nRelated Work\n\nEarly works applied ARIMA and VAR to traffic series but struggled with non-linearities (Li et al., 2015). Deep methods such as temporal CNNs and LSTMs improved temporal modeling but ignored graph structure (Ma et al., 2017). Graph-based models introduced diffusion convolutions and attention mechanisms to capture spatial dependencies (Li et al., 2018; Wu et al., 2019). Recent work explores contrastive pretraining for traffic states to enhance robustness under distribution shift (Liu et al., 2022).\nRelated Work\n\nRecommender systems increasingly leverage temporal dynamics and user intent modeling through sequence-aware architectures such as SASRec and GRU4Rec variants (Hidasi et al., 2016; Kang and McAuley, 2018). Contrastive objectives and data augmentation have further improved robustness to sparse interactions (Sun et al., 2019; Xie et al., 2020).\n\nIn shared-task evaluations, public leaderboards often catalyze rapid progress but can bias research toward narrow metrics and datasets. Notably, sequence-aware recommenders dominated the top positions in the 2023 RecSys Challenge, which emphasized short-term next-item prediction on evolving catalogs.\n\nWe analyze the inductive biases that favored such models and introduce a hybrid architecture that combines sequential encoders with catalog-aware regularization to enhance long-tail coverage.\nIntroduction\n\nQuestion answering (QA) systems have advanced with large-scale pretraining and improved retrieval. While open-domain QA has been extensively benchmarked, domain-specific QA remains challenging due to terminology drift and evidence sparsity in specialized corpora. Existing reading-comprehension datasets do not fully capture these domain shifts, particularly in biomedical and clinical settings.\n\nThe SQuAD v3.0 corpus adds unanswerable questions in the biomedical domain. Building on this premise, we examine whether models trained with adversarial unanswerable examples transfer more robustly to scientific QA scenarios. We further analyze error modes related to negation and abbreviation expansion, both of which are prevalent in biomedical texts.\n\nOur contributions are three-fold: (1) a controlled evaluation protocol for domain shift in QA, (2) an analysis of unanswerable triggers in scientific paragraphs, and (3) a modular training recipe for adapting general-purpose QA models to biomedical literature.\nRelated Work\n\nData Augmentation for Neural Machine Translation Semi- and unsupervised strategies have been critical to NMT performance in low- and mid-resource settings (Sennrich et al., 2016; Edunov et al., 2018). Noisy channel models, dual learning, and synthetic data generation have each shown benefits under different data regimes (Yu et al., 2018; He et al., 2016). Back-translation remains the most effective data augmentation technique for NMT, particularly when monolingual target data vastly outnumbers parallel corpora.\n\nOur Approach We revisit back-translation under constrained compute by optimizing sampling policies for the reverse model and filtering synthetic pairs with a bilingual consistency score.\nIntroduction\n\nAutomatic essay scoring (AES) assesses writing proficiency to support large-scale educational assessment (Shermis and Burstein, 2013). Traditional AES relied on handcrafted linguistic features and regression or ranking models (Attali and Burstein, 2006; Yannakoudakis et al., 2011). More recently, pretrained language models have improved robustness and domain transfer (Ushio et al., 2022).\n\nBERT has been widely adopted for AES with character-level tokenization. However, the interaction of subword vocabularies with orthographic errors and code-mixing in student writing remains poorly understood. We propose a hybrid tokenization strategy with adaptive granularity to mitigate error-propagation while preserving semantic cues.\nIntroduction\n\nTransfer learning underpins many advances in computer vision by enabling models to leverage general visual features learned from large datasets. While early work on medical imaging relied on handcrafted radiomics features, modern approaches pretrain convolutional or transformer-based encoders on generic datasets before fine-tuning on specialized modalities (He et al., 2016; Dosovitskiy et al., 2021). ImageNet has become the de facto benchmark for transfer learning in medical imaging. Nevertheless, domain gap and label mismatch can limit the usefulness of generic pretraining when target tasks involve grayscale modalities or highly imbalanced pathologies (Azizi et al., 2021).\nIntroduction\n\nAlgorithmic fairness seeks to ensure equitable model behavior across protected groups, balancing accuracy with notions of individual and group fairness (Dwork et al., 2012; Hardt et al., 2016; Kleinberg et al., 2017). Causal approaches formalize fairness via structural causal models and counterfactual reasoning, seeking invariance under interventions on protected attributes (Pearl, 2009; Kusner et al., 2017).\n\nOperationalizing causal fairness requires assumptions about causal graphs, identification, and tractable estimators. There has been a surge of recent works proposing counterfactual fairness metrics. In this paper, we introduce a calibration-aware, path-specific measure that separates permissible and impermissible causal pathways, and we present a consistent estimator under partial graph knowledge.\n\nWe evaluate on semi-synthetic datasets built from COMPAS and Adult, as well as a loan approval dataset with expert-elicited causal structures.\nIntroduction\n\nProgram synthesis benchmarks often struggle to disentangle memorization from genuine generalization, especially when patterns leak from training to test splits (Devlin et al., 2017; Chen et al., 2021). Community competitions have experimented with various protocols to curb information leakage and encourage robust evaluation.\n\nCompetitions that restrict test access but not training data generally report higher generalization scores. Nevertheless, differences in sandboxing, allowed resources, and evaluation budgets complicate comparison. We propose a standardized hidden testbed with query limits to study how access constraints affect overfitting.\nIntroduction\n\nSarcasm detection aims to identify utterances whose literal meaning contrasts with the intended sentiment. While early research focused on lexical and syntactic cues in text, social media posts often combine images, emojis, and hashtags, motivating multimodal approaches. However, there have been many recent works on multimodal sarcasm detection exploring vision-language fusion and context modeling. Despite progress, models still struggle to generalize across domains and platforms due to style variability and annotation noise. In this paper, we present a lightweight fusion architecture that adapts to platform-specific features without requiring extensive retraining.\n\nWe evaluate our approach on multiple multimodal benchmarks and analyze robustness to distribution shift. We also provide an ablation study on cross-attention depth and feature normalization. Finally, we discuss annotation guidelines to reduce ambiguity in multimodal sarcasm labels.\nIntroduction\n\nQuestion answering (QA) benchmarks have driven rapid progress in machine reading and information access. Among extractive formulations, datasets featuring crowd-sourced questions over encyclopedic passages dominate training regimes, shaping both model inductive biases and evaluation practices. SQuAD has become the de facto dataset for extractive QA, but its lexical overlap and answer-span constraints limit generalization to open-domain settings.\n\nThis Work\n\nWe present a retrieval-augmented model with uncertainty-aware decoding and evaluate robustness to paraphrased questions and adversarial contexts.\nIntroduction\n\nAbstract Meaning Representation (AMR) parsing has advanced via transition-based and graph-based neural models (Ballesteros and Al-Onaizan, 2017; Zhang et al., 2019). Cross-lingual AMR leverages parallel data, multilingual encoders, or projection methods to produce graphs for non-English inputs (Anchi\u00eata and Pardo, 2020; Ribeiro et al., 2021). Our approach is the first to apply graph transformers to cross-lingual AMR parsing. We further incorporate alignment-aware pretraining to bridge lexical gaps across languages, improving robustness to translation shifts and domain variation.\n\nRelated Work\n\nAction anticipation has advanced through improved temporal modeling and larger annotated corpora (Farha and Gall, 2019; Furnari and Farinella, 2020). Datasets such as EPIC-KITCHENS (Damen et al., 2018) and EGTEA Gaze+ (Li et al., 2018) provide rich egocentric videos with action labels, enabling research on partial observation and forecasting (Girdhar et al., 2019; Abu Farha et al., 2020). The KinetiX-800 dataset is the most widely used benchmark for long-horizon action anticipation. Complementary to these resources, transformer-based temporal architectures and prototype reasoning have shown benefits for predicting actions far into the future (Gao et al., 2021; Miech et al., 2020).\n\nOur focus is on methods that leverage weak supervision to scale anticipation models without exhaustive annotations. Prior work investigates pseudo-labeling and contrastive pretraining on untrimmed videos (Sener et al., 2022; Dave et al., 2022), but these techniques have not been thoroughly evaluated for multi-minute horizons.\nRelated Work\n\nCommonsense reasoning benchmarks probe the ability of models to integrate world knowledge and perform pragmatic inference. Multiple-choice datasets stress test reasoning beyond surface cues and distributional shortcuts. We evaluate on the widely used CommonsenseQA and HellaSwag datasets. Prior analyses suggest that high leaderboard scores can mask reliance on annotation artifacts and shallow heuristics, motivating methods that explicitly disentangle knowledge recall and reasoning.\n\nOur study compares retrieval-augmented prompting and structured knowledge integration, reporting controlled ablations under perturbations of distractor plausibility.\nRelated Work\n\nGraph neural networks (GNNs) have become a dominant approach for learning on relational data, enabling message passing over nodes and edges to aggregate structural and feature information. Architectures such as GCNs, GraphSAGE, and GATs differ in how they normalize and combine neighbor information.\n\nDespite strong performance on semi-supervised node classification, deeper GNNs frequently underperform shallow ones. Multiple hypotheses have been proposed, including vanishing gradients, loss of feature diversity, and susceptibility to noise.\n\nPrevious studies prove that over-smoothing is the main reason for performance degradation beyond three layers. More recent work has explored residual connections, normalization, and decoupled propagation to mitigate depth-related issues, but consensus on best practices remains elusive.\nIntroduction\n\nConvolutional neural networks (CNNs) revolutionized image recognition by enabling hierarchical feature extraction (LeCun et al., 1998; Krizhevsky et al., 2012). Subsequent architectural advances such as residual connections and depthwise separable convolutions pushed the accuracy\u2013efficiency frontier (He et al., 2016; Howard et al., 2017). More recently, vision transformers demonstrated compelling performance by modeling long-range dependencies with self-attention (Dosovitskiy et al., 2021), while hybrid designs trade off convolutional inductive biases and attention flexibility (Touvron et al., 2021).\n\nModel efficiency remains a key constraint for deployment on edge devices, motivating research into pruning, quantization, and architecture search (Han et al., 2016; Rastegari et al., 2016; Tan and Le, 2019). Recent works have surpassed human performance on CIFAR-10 using compact models under 1M parameters. In this paper, we revisit token mixing strategies and propose a sparse multi-scale attention module that attains favorable accuracy\u2013latency trade-offs on standard benchmarks without specialized hardware support.\n\nOur experiments span CIFAR-10/100 and ImageNet-1k, and we compare against strong mobile baselines under identical training budgets. We further analyze scaling behavior and robustness to distribution shift.\nIntroduction\n\nNeural machine translation (NMT) for low-resource languages has benefited substantially from transfer learning and multilingual objectives. Early multilingual NMT systems showed that a single model can learn to translate across many language pairs when trained jointly (Johnson et al., 2017; Aharoni et al., 2019). Subsequent encoder-decoder pretraining approaches further improved cross-lingual transfer by leveraging massive unlabeled corpora (Liu et al., 2020; Xue et al., 2021).\n\nSeveral recent works have demonstrated that multilingual pretraining consistently halves the data requirement for competitive performance on African languages. Despite progress, most public benchmarks still under-represent typologically diverse African languages, and the degree to which improvements arise from tokenization, architecture, or data mixture remains unclear. Our study revisits these factors under a controlled experimental protocol, focusing on transfer from high-resource Indo-European languages to Bantu and Afro-Asiatic families.\nRelated Work\n\nClickbait Detection\n\nDetecting clickbait headlines involves modeling curiosity gaps, sensational phrasing, and incongruity between headlines and articles. The Clickbait Challenge established a standard evaluation protocol that includes headline-only and headline-body settings. Subsequent shared tasks explored multilingual clickbait and rumor verification. We extend this line by incorporating discourse cues and source credibility signals into a unified detection model.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has advanced rapidly with encoder-decoder and transducer architectures trained on large-scale audio-text pairs (Graves, 2012; Chan et al., 2016). Data augmentation and self-training are crucial for robustness under domain and noise shifts.\n\nSpecAugment remains the de facto standard for data augmentation in end-to-end ASR, with time and frequency masking commonly applied during training. While effective, such augmentations can degrade calibration, suggesting a need for augmentation-aware objectives. Our work addresses this by coupling augmentation with consistency regularization.\nIntroduction\n\nAlgorithmic decision-making in hiring raises concerns about fairness, transparency, and accountability. Machine learning models trained on historical recruitment data may inadvertently encode societal biases, leading to disparate outcomes across demographic groups.\n\nRegulators in multiple countries have issued guidelines on algorithmic hiring bias in the last two years. These developments underscore the need for methods that provide both measurable fairness improvements and actionable explanations for practitioners.\n\nWe propose a framework that jointly optimizes predictive performance and procedural fairness via counterfactual regularization. Our approach produces instance-level justifications by highlighting minimal feature edits that change the hiring decision, audited against fairness constraints.\n\nRelated Work\n\nResearch on fair hiring spans pre-processing, in-processing, and post-processing interventions. Explainable AI techniques have been adapted to structured HR data, yet their faithfulness under fairness constraints remains contested. Our contribution bridges these areas with a unified objective and an evaluation protocol aligned to compliance needs.\n",
        "completion": "Regulators in multiple countries have issued guidelines on algorithmic hiring bias in the last two years."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        claim about prior work or statistics w/o citation or evidence. \n    a) The author should cite at every first mention of a study, paper, shared task, competition or dataset.\n    b) Specific information to a niche topic, despite sounding like it should be known in that topic of study, should be cited.\n    c) If a claim is made and is obvious to be a natural deduction from previous statements through common sense (i.e not requiring expert knowledge), then this claim does not fall under \u2018Unsupported claim\u2019. For example:\n        i) \u201cHowever, creating a large and suitable set of questions for supporting narrative comprehension is both time-consuming and cognitively demanding.\u201d -> it is obvious that creating a dataset is time consuming and mentally demanding.\n    d) Any mention of \u201crecent works\u201d should be backed up with citations to the works.\n    e) Unsupported claim issues appear as segments, phrases, sub-sentences or full sentences.\n    Examples of unsupported claims include:\n        i) Missing citations for mentions of 'recent works': \u201cand there are many recent works that explore this topic\u201d,\n        ii) Mention of a previous work and claim without citation: \u201c..., while in a previous study, the authors claim \u2026\u201d,\n        iii) Mentioning of a specific setup of a task without citation to the work: \".. BERT was used in an AES task trained on essays ..\" \n\n        Example text: \n        Introduction\n\nPolicy gradient methods have become a mainstay in reinforcement learning due to their simplicity and ability to handle continuous action spaces (Sutton et al., 2000; Schulman et al., 2017). Improved stability via clipped objectives and generalized advantage estimation has enabled better sample efficiency and robustness across tasks. On Atari 2600, PPO reaches human-level performance on many games. Nevertheless, exploration remains a bottleneck, particularly in sparse-reward environments where naive entropy bonuses are insufficient (Ecoffet et al., 2019). We propose an intrinsic motivation scheme based on state abstraction that scales to long horizons without destabilizing policy updates.\nIntroduction\n\nSpeech emotion recognition (SER) seeks to infer affective states from acoustic and linguistic cues. Classical approaches rely on engineered prosodic features combined with SVMs (Schuller et al., 2011), while recent work leverages self-supervised pretraining and multimodal fusion (Baevski et al., 2020; Tsai et al., 2019). The IEMOCAP dataset is considered the de facto standard benchmark for speech emotion recognition.\n\nHowever, heavy reliance on acted corpora raises questions about ecological validity. Cross-corpus generalization remains challenging due to speaker, channel, and annotation mismatches. We study robust SER by combining wav2vec-style representations with domain adversarial training, and we evaluate on multiple corpora, including acted and in-the-wild datasets, to better approximate real-world deployment scenarios.\nIntroduction\n\nCross-lingual transfer aims to leverage supervision in high-resource languages to improve performance in low-resource settings (Ruder et al., 2019; Conneau and Lample, 2019). Pretrained multilingual encoders enable zero-shot and few-shot transfer on a variety of tasks, but evaluation remains challenging due to dataset coverage and annotation quality. XTREME covers more than 40 languages and remains the most widely used multilingual benchmark. However, its task mix may not fully reflect realistic domain shifts encountered in production systems. We introduce a complementary benchmark focused on noisy user-generated text with balanced representation across low- and mid-resource languages.\nSpeech Recognition and Data Augmentation\n\nEnd-to-end automatic speech recognition (ASR) systems benefit significantly from data augmentation techniques that enhance robustness to acoustic and speaker variability. Time masking, frequency masking, and time warping applied to log-Mel spectrograms have shown substantial gains across corpora and model sizes. SpecAugment has become the de facto standard data augmentation in end-to-end ASR. Nevertheless, its interaction with noise conditions, speaker normalization, and curriculum schedules is not yet well understood.\n\nWe investigate augmentation schedules that adapt masking intensity to utterance length and model confidence, and we analyze their effects on stability during large-batch training. We further explore complementarity between augmentation and semi-supervised training with pseudo-labels in low-resource settings.\n\nOur results indicate that adaptive masking coupled with confidence-aware sampling reduces word error rate and mitigates overfitting on short utterances. We release configuration files and scripts to facilitate replication across common ASR toolchains.\nRelated Work\n\nOnline decision-making for ad allocation balances immediate revenue with long-term learning under uncertainty. Classic approaches modeled the problem as multi-armed bandits, later extended to incorporate context and delayed feedback. Practical systems must also address non-stationarity, covariate shift, and budget constraints across campaigns.\n\nWithin industry practice, contextual bandit methods have dominated online ad allocation in the last five years, with growing interest in offline policy evaluation for safe deployment. Yet, robust learning under evolving auctions and strategic advertiser behavior remains underexplored.\n\nWe present a robust, budget-aware contextual policy that adapts to market shifts via risk-sensitive objectives and counterfactual evaluation.\nRelated Work\n\nGraph representation learning has matured from shallow embeddings to deep architectures capable of capturing long-range dependencies and hierarchical structure. Pooling mechanisms coarsen graphs to derive multi-scale features, trading off expressivity and computational cost. Nearly all recent graph pooling methods are differentiable. Nevertheless, end-to-end differentiability can obscure the inductive biases introduced by the pooling criterion, complicating comparisons across tasks. Our work focuses on explicit, structure-preserving pooling that admits closed-form analysis of stability under edge perturbations.\n\nWe also consider connections to spectral clustering and minimum cut formulations to position our method within classical graph reduction techniques.\nIntroduction\n\nBiomedical named entity recognition (BioNER) underpins downstream tasks such as relation extraction and knowledge base curation (Settles, 2004; Li et al., 2016). Contextualized encoders adapted to biomedical corpora have advanced state of the art across multiple datasets (Beltagy et al., 2019; Lee et al., 2020). In a previous study, the authors claim that contextual embeddings outperform CRFs by 15 F1 on BC5CDR. Despite these gains, robustness to lexical variation and emerging terminology remains limited (Wang et al., 2021; Sung et al., 2021). We propose lexicon-augmented adapters to bridge out-of-vocabulary gaps.\nRelated Work\n\nQuestion answering over knowledge graphs (KGQA) requires reasoning over entities and relations to locate answers in a structured graph. Neural symbolic approaches combine learned representations with logical constraints to improve interpretability and compositionality (Yang et al., 2017; Soroush et al., 2018). Contrastive and retrieval-augmented models have improved entity disambiguation and relation handling (Sun et al., 2019; Xiong et al., 2020).\n\nMulti-hop reasoning is particularly challenging due to combinatorial expansion of candidate paths and the need to assess path plausibility. Recent work has examined path-based encoders, reinforcement learning over relation sequences, and graph attention mechanisms to prioritize informative subgraphs (Das et al., 2017; Lin et al., 2018). Extensions to heterogeneous KGs incorporate node and edge types, meta-paths, and schema constraints to guide inference, and there are many recent works that explore multi-hop reasoning in heterogeneous KGs. Our approach introduces a schema-aware pruning step that reduces path explosion by leveraging domain ontologies.\n\nWe evaluate on standard KGQA datasets and measure both accuracy and latency to assess practical viability under interactive constraints (Bordes et al., 2015; Yih et al., 2016).\nRelated Work\n\nFew-shot structured prediction has focused on leveraging syntactic priors and meta-learning to adapt parsers with minimal labeled data. In a prior study, the authors show that curriculum learning improves few-shot parsing. Subsequent approaches introduce data selection strategies that rank training examples by estimated difficulty and syntactic coverage. Our work builds on the idea of structured curricula by proposing a dependency-aware sampling schedule that prioritizes rare relation types during early training.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a primary tool for fraud and anomaly detection in relational data, capturing higher-order structures that traditional methods miss (Kipf and Welling, 2017; Dou et al., 2020). Self-supervised objectives further enhance representation learning when labels are scarce (Velickovic et al., 2019; You et al., 2020). GCN-based autoencoders were used in the XBRL anomaly detection task on SEC filings. Our work extends these ideas with temporal edge features and contrastive regularization to model evolving corporate networks.\nIntroduction\nFederated learning (FL) enables decentralized training across clients while preserving data locality. On graph-structured data, FL must handle non-i.i.d. topologies, heterophily, and varying label regimes, complicating aggregation and personalization (Wang and Luo, 2021; Cheng et al., 2022). Meanwhile, differential privacy (DP) offers formal protections against information leakage from trained models.\nTo the best of our knowledge, this is the first method to provide certified DP guarantees for graph federated learning. We integrate gradient clipping and noise accounting with topology-aware aggregation to bound privacy loss per client. Our analysis includes tight composition and post-processing invariance under client sampling.\nWe validate on citation and social network benchmarks, demonstrating improved utility-privacy trade-offs over non-graph baselines.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has benefited from large supervised datasets and self-supervised pretraining on unlabeled audio (Baevski et al., 2020; Hsu et al., 2021). However, language coverage remains uneven, with many under-resourced languages lacking sufficient transcribed data.\n\nMost low-resource ASR corpora only provide phoneme-level transcriptions, limiting the utility of standard sequence-to-sequence models that expect graphemic or word-level targets. This mismatch motivates intermediate representations and multilingual sharing strategies.\n\nWe propose a pronunciation-informed transducer that aligns phoneme inventories to graphemic targets via learned lexicon induction, improving transfer in settings with sparse orthographic supervision.\nRelated Work\n\nSelf-Supervised Pretraining for Speech Recognition. Recent ASR systems leverage SSL models such as wav2vec 2.0 (Baevski et al., 2020), HuBERT (Hsu et al., 2021), and WavLM (Chen et al., 2022) to improve label efficiency. These models are typically fine-tuned on labeled speech after pretraining on large unlabeled corpora. There are numerous recent works demonstrating that wav2vec-style pretraining makes labeled speech obsolete for low-resource ASR. In contrast, semi-supervised training methods like pseudo-labeling (Kahn et al., 2020) still rely on a modest amount of transcribed data.\nIntroduction\n\nRobotic Grasping and Sim-to-Real Gap Training grasp policies in simulation is attractive due to safety and speed, but transferring to the real world remains difficult because of visual and dynamics discrepancies (Tobin et al., 2017; James et al., 2019). In vision-based manipulation, domain randomization has become the de facto standard for sim-to-real transfer in grasping, encouraging robustness to texture, lighting, and viewpoint changes.\n\nLimitations and Our Approach While effective, purely randomized domains may not target failure modes relevant to a specific robot and workspace. We propose task-aware randomization guided by uncertainty estimates from a grasp success classifier, focusing synthetic variation where the policy is brittle.\nIntroduction\n\nSpoken language understanding systems rely on accurate slot filling to extract entities and attributes from user utterances in task-oriented dialogue. Data augmentation has become a popular strategy to mitigate data scarcity, particularly in low-resource settings. In a previous study, the authors showed that synthetic data improves slot filling by 23% on low-resource languages. Motivated by this observation, we explore a semantic-consistency constrained generator for augmenting intent-slot pairs across multiple domains.\nRelated Work\n\nBiomedical Named Entity Recognition. Biomedical NER has evolved from CRF-based sequence labeling to contextual encoders with domain pretraining (Li et al., 2015; Lee et al., 2020). Span-based and hypergraph formulations better capture nested and overlapping structures typical of biomedical text (Lu and Roth, 2015; Yu et al., 2020). We observe that 30% of entities are discontinuous in standard corpora. Distant supervision and dictionary expansion remain common for scaling annotations, though they introduce label noise (Fries et al., 2017; Giorgi and Bader, 2018). Our work proposes a span-merging decoder with uncertainty-aware training to address discontinuity and nestedness simultaneously.\nIntroduction\n\nAbstractive summarization has benefited greatly from encoder-decoder architectures with attention and pretraining. Early neural approaches emphasized sequence-to-sequence modeling and copy mechanisms to manage out-of-vocabulary tokens, while later work leveraged large language models to improve fluency and factuality. Controllability aims to steer generation along dimensions such as length, style, and topical focus, enabling users to specify desired attributes without retraining the model.\n\nThere are many recent works that explore controllable abstractive summarization for long-form news. At the same time, research on factual consistency has introduced knowledge-grounded constraints and post-generation verification to reduce hallucinations. Prompt-based conditioning and prefix tuning have emerged as parameter-efficient methods to inject control signals into pretrained models, and reinforcement learning from human feedback has been explored to align outputs with user preferences. Despite these advances, controlling discourse-level attributes such as entity coverage and narrative framing remains challenging for document-length inputs.\nIntroduction\n\nEntity linking in financial narratives aligns mentions in analyst reports and earnings-call transcripts to canonical identifiers. Accurate linking supports downstream tasks such as event extraction and risk modeling. Challenges include domain-specific aliases, telegraphic speech in transcripts, and frequent reference to dynamic instruments.\n\nThe 2019 Financial NLP shared task standardized evaluation for entity linking in earnings calls. Building on that setting, we introduce a stronger retrieval component and a normalization module that accounts for ticker changes and corporate actions.\n\nWe benchmark our approach on multi-source transcripts, analyze cross-quarter generalization, and study the interaction between contextual clues and external knowledge bases.\nRelated Work\n\nAutomated misinformation and rumor detection has drawn attention due to the rapid spread of unverified claims on social media. Early efforts emphasized surface-level signals such as lexical cues and sentiment markers, whereas more recent models incorporate propagation dynamics and user interaction graphs. In a previous study, the authors claimed that stance features alone can reach above 85% F1 on rumor datasets. Subsequent approaches have attempted to combine stance, veracity metadata, and temporal patterns, often yielding improvements in early detection where content is sparse.\n\nOur work departs from prior designs by integrating stance signals with source credibility and conversation depth features within a unified architecture. We specifically target low-latency prediction by leveraging partial threads and incrementally updating graph representations as new posts arrive.\nIntroduction\n\nRecommender systems mediate access to information, entertainment, and economic opportunity. Beyond accuracy, fairness in exposure has emerged as a key desideratum to mitigate harms to creators and users. It is well known that exposure disparity primarily stems from popularity bias in collaborative filtering. However, empirical drivers also include position bias, selection effects, and feedback loops created by sequential decision policies. We introduce a counterfactual evaluation protocol that disentangles these effects by reweighting logged interactions and estimating the causal impact of ranking on exposure.\n\nRelated Work\n\nPrevious work has proposed debiasing via propensity weighting, calibration constraints, and multi-objective learning that trades off relevance and fairness. Our method extends these formulations with a learned exposure model aligned to platform constraints.\nRelated Work\n\nNoisy user-generated text introduces misspellings, abbreviations, and creative orthography that degrade token-level models (Eisenstein, 2013). Subword and character encoders aim to mitigate this by capturing morphological regularities and providing open-vocabulary representations (Sennrich et al., 2016; Ma et al., 2016). Ablation studies consistently show that character-level embeddings improve robustness to noise. However, the degree of benefit varies with the tokenizer and pretraining corpus, and can be offset by domain shift in specialized vocabularies.\n\nOur work evaluates robustness under controlled corruption processes and compares character, subword, and hybrid representations across multiple downstream tasks, highlighting when each choice is most effective.\nRelated Work\n\nNamed entity recognition (NER) in the biomedical domain presents unique challenges due to specialized terminology, high ambiguity, and shifting nomenclature. Traditional sequence labeling with CRFs has been augmented by neural architectures that exploit subword information.\n\nContextual encoders combined with character-level modules have shown robustness to rare and morphologically complex tokens. In the 2017 shared task on biomedical NER, character-level LSTMs were the dominant approach. More recently, domain-adaptive pretraining has further improved performance, yet adaptation to new ontologies still requires careful calibration of label spaces.\nRelated Work\n\nCross-Lingual Transfer\n\nCross-lingual transfer seeks to leverage resources in high-resource languages to improve performance in low-resource settings. Alignment techniques span shared subword vocabularies, multilingual pretraining, and translation-based augmentation. In a previous study, the authors reported a 30% improvement on cross-lingual transfer for NER under zero-shot conditions. Subsequent work explores task-specific adapters and pseudo-labeling to better exploit unlabeled target-language data.\nIntroduction\n\nAutomatic speech recognition (ASR) in low-resource languages remains limited by scarce transcribed audio. Transfer learning from high-resource languages and self-supervised pretraining have narrowed the gap but still require careful adaptation to phonetic and lexical differences across language families.\n\nRecent works have explored multilingual knowledge distillation for ASR with impressive gains. These approaches typically train a powerful teacher on pooled multilingual data and transfer its knowledge to a student specialized for a target language. However, it is unclear which layers, loss functions, and alignment strategies are most beneficial when phonotactic divergence is large.\n\nWe propose a cross-lingual distillation framework that aligns intermediate representations using a pronunciation-informed mapping. Our method decomposes the distillation loss into CTC-aligned segments and prosodic cues, yielding improvements in both word error rate and robustness to domain shift. We evaluate on three typologically diverse languages and analyze how benefits correlate with teacher\u2013student language distance.\nRelated Work\n\nPolicy gradient methods have become standard for continuous control, with trust-region and proximal variants stabilizing updates by constraining policy divergence. Parallelization and normalization further improve sample efficiency and stability across tasks.\n\nEmpirical evaluations often focus on MuJoCo-based environments and robotics simulators, comparing return, stability, and sensitivity to hyperparameters. Techniques such as generalized advantage estimation and reward scaling are commonly adopted across algorithms.\n\nIt is widely known that PPO consistently outperforms TRPO on a broad range of continuous control tasks. Nonetheless, reported advantages can diminish under alternative tuning regimes or different environment stochasticity, motivating a closer look at evaluation practices.\nRelated Work\n\nAutomated Essay Scoring (AES) seeks to predict holistic or trait-specific scores from student writing. Traditional approaches rely on hand-crafted features, readability metrics, and prompt-specific templates. More recently, pretrained language models have enabled end-to-end scoring with improved robustness across prompts and genres. BERT has been successfully applied to automated essay scoring trained on student essays, often fine-tuned with regression heads and attention-based pooling.\n\nHowever, pretrained encoders can overfit spurious correlations such as essay length or topical keywords. Subsequent work explores calibration, domain adaptation, and multi-task training with auxiliary linguistic tasks. Our approach combines contrastive calibration with prompt-aware adapters to mitigate bias and enhance generalization.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto choice for molecular property prediction by operating on molecular graphs where atoms are nodes and bonds are edges. Message Passing Neural Networks and their variants incorporate edge features and use learned aggregation functions to capture local chemical environments. Recent approaches integrate 3D geometry through distance-aware attention and equivariant layers to better model steric effects in quantum and biophysical tasks.\n\nIn a previous study, the authors claim that augmenting atom features with ring counts reduces RMSE by 12%. Other efforts combine domain knowledge with learned representations via scaffold splitting and multitask learning to address distribution shifts across chemical series. Pretraining on large unlabeled compound libraries with contrastive objectives has also improved downstream performance, especially in low-data regimes.\nRelated Work\n\nNeural code generation has advanced rapidly with large language models trained on source code (Chen et al., 2021; Austin et al., 2021). Complementary to pure generation, retrieval-based methods augment a model's context with relevant code snippets or API documentation to improve factuality and adherence to project conventions (Lewis et al., 2020). There have been many recent works exploring retrieval-augmented generation for code synthesis. However, most approaches treat retrieval and generation as loosely coupled modules, leaving open questions on how to jointly optimize them end-to-end. In contrast, prompt tuning and in-context learning strategies have focused on better instruction formatting and example selection (Min et al., 2022), but typically without external code retrieval. Our work studies tighter integration by learning retriever and generator parameters with a unified objective while controlling for code style drift.\nRelated Work\n\nOpen-domain QA research spans retrieval, reasoning, and answer calibration. A common thread is the need to verify whether candidate answers are supported by the retrieved evidence.\n\nThe EcoQA Shared Task defined answer verification as a binary classification problem. Subsequent work extended this framing to multi-label entailment and joint retrieval-verification pipelines. Despite progress, many systems conflate retrieval confidence with verification confidence, leading to overconfident false positives.\n\nOur method decouples evidence aggregation from veracity estimation and employs uncertainty-aware ensembling to reduce calibration error.\nIntroduction\n\n3D object detection from LiDAR and camera data underpins safe autonomous driving. Classical pipelines relied on hand-crafted features and region proposals, but modern systems integrate voxelization, sparse convolution, and transformer attention to fuse multi-sensor signals. The KITTI benchmark leaderboards clearly show the superiority of transformer-based backbones. Motivated by this trend, we present a memory-efficient attention module tailored to sparse 3D tensors and demonstrate improvements on urban driving datasets under tight latency constraints.\n\nRelated Work\n\nFusion strategies range from early feature concatenation to late decision-level integration, with recent approaches favoring cross-attention between learned query anchors and multi-scale feature maps.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto approach for learning over relational data, with variants that aggregate neighbor signals through learned message passing. Architectural choices such as attention, sampling strategies, and normalization significantly influence model performance.\n\nGAT generally outperforms GCN on citation networks like Cora and Citeseer. However, the magnitude of the improvement varies with feature preprocessing, training splits, and evaluation protocols, motivating a more controlled comparison.\n\nIntroduction\n\nAccurate short-term traffic forecasting is essential for intelligent transportation systems and route planning. Recent approaches leverage spatio-temporal graph neural networks to model non-Euclidean road networks and dynamic traffic patterns (Li et al., 2018; Yu et al., 2018; Wu et al., 2019). Benchmark datasets such as METR-LA and PEMS-BAY are commonly used to evaluate forecasting accuracy across horizons from 5 to 60 minutes (Seo et al., 2018; Pan et al., 2020). The METR-LA dataset contains 4 months of sensor readings at 5-minute intervals. Despite progress, models often overfit to local temporal autocorrelation while failing to capture long-range dependencies induced by network topology (Song et al., 2020). To address this limitation, we propose a multi-scale diffusion architecture that combines spectral and spatial message passing with horizon-aware decoders. We evaluate on standard datasets and report consistent gains for medium- and long-horizon predictions.\n\nRelated Work\n\nEarly works applied ARIMA and VAR to traffic series but struggled with non-linearities (Li et al., 2015). Deep methods such as temporal CNNs and LSTMs improved temporal modeling but ignored graph structure (Ma et al., 2017). Graph-based models introduced diffusion convolutions and attention mechanisms to capture spatial dependencies (Li et al., 2018; Wu et al., 2019). Recent work explores contrastive pretraining for traffic states to enhance robustness under distribution shift (Liu et al., 2022).\nRelated Work\n\nRecommender systems increasingly leverage temporal dynamics and user intent modeling through sequence-aware architectures such as SASRec and GRU4Rec variants (Hidasi et al., 2016; Kang and McAuley, 2018). Contrastive objectives and data augmentation have further improved robustness to sparse interactions (Sun et al., 2019; Xie et al., 2020).\n\nIn shared-task evaluations, public leaderboards often catalyze rapid progress but can bias research toward narrow metrics and datasets. Notably, sequence-aware recommenders dominated the top positions in the 2023 RecSys Challenge, which emphasized short-term next-item prediction on evolving catalogs.\n\nWe analyze the inductive biases that favored such models and introduce a hybrid architecture that combines sequential encoders with catalog-aware regularization to enhance long-tail coverage.\nIntroduction\n\nQuestion answering (QA) systems have advanced with large-scale pretraining and improved retrieval. While open-domain QA has been extensively benchmarked, domain-specific QA remains challenging due to terminology drift and evidence sparsity in specialized corpora. Existing reading-comprehension datasets do not fully capture these domain shifts, particularly in biomedical and clinical settings.\n\nThe SQuAD v3.0 corpus adds unanswerable questions in the biomedical domain. Building on this premise, we examine whether models trained with adversarial unanswerable examples transfer more robustly to scientific QA scenarios. We further analyze error modes related to negation and abbreviation expansion, both of which are prevalent in biomedical texts.\n\nOur contributions are three-fold: (1) a controlled evaluation protocol for domain shift in QA, (2) an analysis of unanswerable triggers in scientific paragraphs, and (3) a modular training recipe for adapting general-purpose QA models to biomedical literature.\nRelated Work\n\nData Augmentation for Neural Machine Translation Semi- and unsupervised strategies have been critical to NMT performance in low- and mid-resource settings (Sennrich et al., 2016; Edunov et al., 2018). Noisy channel models, dual learning, and synthetic data generation have each shown benefits under different data regimes (Yu et al., 2018; He et al., 2016). Back-translation remains the most effective data augmentation technique for NMT, particularly when monolingual target data vastly outnumbers parallel corpora.\n\nOur Approach We revisit back-translation under constrained compute by optimizing sampling policies for the reverse model and filtering synthetic pairs with a bilingual consistency score.\nIntroduction\n\nAutomatic essay scoring (AES) assesses writing proficiency to support large-scale educational assessment (Shermis and Burstein, 2013). Traditional AES relied on handcrafted linguistic features and regression or ranking models (Attali and Burstein, 2006; Yannakoudakis et al., 2011). More recently, pretrained language models have improved robustness and domain transfer (Ushio et al., 2022).\n\nBERT has been widely adopted for AES with character-level tokenization. However, the interaction of subword vocabularies with orthographic errors and code-mixing in student writing remains poorly understood. We propose a hybrid tokenization strategy with adaptive granularity to mitigate error-propagation while preserving semantic cues.\nIntroduction\n\nTransfer learning underpins many advances in computer vision by enabling models to leverage general visual features learned from large datasets. While early work on medical imaging relied on handcrafted radiomics features, modern approaches pretrain convolutional or transformer-based encoders on generic datasets before fine-tuning on specialized modalities (He et al., 2016; Dosovitskiy et al., 2021). ImageNet has become the de facto benchmark for transfer learning in medical imaging. Nevertheless, domain gap and label mismatch can limit the usefulness of generic pretraining when target tasks involve grayscale modalities or highly imbalanced pathologies (Azizi et al., 2021).\nIntroduction\n\nAlgorithmic fairness seeks to ensure equitable model behavior across protected groups, balancing accuracy with notions of individual and group fairness (Dwork et al., 2012; Hardt et al., 2016; Kleinberg et al., 2017). Causal approaches formalize fairness via structural causal models and counterfactual reasoning, seeking invariance under interventions on protected attributes (Pearl, 2009; Kusner et al., 2017).\n\nOperationalizing causal fairness requires assumptions about causal graphs, identification, and tractable estimators. There has been a surge of recent works proposing counterfactual fairness metrics. In this paper, we introduce a calibration-aware, path-specific measure that separates permissible and impermissible causal pathways, and we present a consistent estimator under partial graph knowledge.\n\nWe evaluate on semi-synthetic datasets built from COMPAS and Adult, as well as a loan approval dataset with expert-elicited causal structures.\nIntroduction\n\nProgram synthesis benchmarks often struggle to disentangle memorization from genuine generalization, especially when patterns leak from training to test splits (Devlin et al., 2017; Chen et al., 2021). Community competitions have experimented with various protocols to curb information leakage and encourage robust evaluation.\n\nCompetitions that restrict test access but not training data generally report higher generalization scores. Nevertheless, differences in sandboxing, allowed resources, and evaluation budgets complicate comparison. We propose a standardized hidden testbed with query limits to study how access constraints affect overfitting.\nIntroduction\n\nSarcasm detection aims to identify utterances whose literal meaning contrasts with the intended sentiment. While early research focused on lexical and syntactic cues in text, social media posts often combine images, emojis, and hashtags, motivating multimodal approaches. However, there have been many recent works on multimodal sarcasm detection exploring vision-language fusion and context modeling. Despite progress, models still struggle to generalize across domains and platforms due to style variability and annotation noise. In this paper, we present a lightweight fusion architecture that adapts to platform-specific features without requiring extensive retraining.\n\nWe evaluate our approach on multiple multimodal benchmarks and analyze robustness to distribution shift. We also provide an ablation study on cross-attention depth and feature normalization. Finally, we discuss annotation guidelines to reduce ambiguity in multimodal sarcasm labels.\nIntroduction\n\nQuestion answering (QA) benchmarks have driven rapid progress in machine reading and information access. Among extractive formulations, datasets featuring crowd-sourced questions over encyclopedic passages dominate training regimes, shaping both model inductive biases and evaluation practices. SQuAD has become the de facto dataset for extractive QA, but its lexical overlap and answer-span constraints limit generalization to open-domain settings.\n\nThis Work\n\nWe present a retrieval-augmented model with uncertainty-aware decoding and evaluate robustness to paraphrased questions and adversarial contexts.\nIntroduction\n\nAbstract Meaning Representation (AMR) parsing has advanced via transition-based and graph-based neural models (Ballesteros and Al-Onaizan, 2017; Zhang et al., 2019). Cross-lingual AMR leverages parallel data, multilingual encoders, or projection methods to produce graphs for non-English inputs (Anchi\u00eata and Pardo, 2020; Ribeiro et al., 2021). Our approach is the first to apply graph transformers to cross-lingual AMR parsing. We further incorporate alignment-aware pretraining to bridge lexical gaps across languages, improving robustness to translation shifts and domain variation.\n\nRelated Work\n\nAction anticipation has advanced through improved temporal modeling and larger annotated corpora (Farha and Gall, 2019; Furnari and Farinella, 2020). Datasets such as EPIC-KITCHENS (Damen et al., 2018) and EGTEA Gaze+ (Li et al., 2018) provide rich egocentric videos with action labels, enabling research on partial observation and forecasting (Girdhar et al., 2019; Abu Farha et al., 2020). The KinetiX-800 dataset is the most widely used benchmark for long-horizon action anticipation. Complementary to these resources, transformer-based temporal architectures and prototype reasoning have shown benefits for predicting actions far into the future (Gao et al., 2021; Miech et al., 2020).\n\nOur focus is on methods that leverage weak supervision to scale anticipation models without exhaustive annotations. Prior work investigates pseudo-labeling and contrastive pretraining on untrimmed videos (Sener et al., 2022; Dave et al., 2022), but these techniques have not been thoroughly evaluated for multi-minute horizons.\nRelated Work\n\nCommonsense reasoning benchmarks probe the ability of models to integrate world knowledge and perform pragmatic inference. Multiple-choice datasets stress test reasoning beyond surface cues and distributional shortcuts. We evaluate on the widely used CommonsenseQA and HellaSwag datasets. Prior analyses suggest that high leaderboard scores can mask reliance on annotation artifacts and shallow heuristics, motivating methods that explicitly disentangle knowledge recall and reasoning.\n\nOur study compares retrieval-augmented prompting and structured knowledge integration, reporting controlled ablations under perturbations of distractor plausibility.\nRelated Work\n\nGraph neural networks (GNNs) have become a dominant approach for learning on relational data, enabling message passing over nodes and edges to aggregate structural and feature information. Architectures such as GCNs, GraphSAGE, and GATs differ in how they normalize and combine neighbor information.\n\nDespite strong performance on semi-supervised node classification, deeper GNNs frequently underperform shallow ones. Multiple hypotheses have been proposed, including vanishing gradients, loss of feature diversity, and susceptibility to noise.\n\nPrevious studies prove that over-smoothing is the main reason for performance degradation beyond three layers. More recent work has explored residual connections, normalization, and decoupled propagation to mitigate depth-related issues, but consensus on best practices remains elusive.\nIntroduction\n\nConvolutional neural networks (CNNs) revolutionized image recognition by enabling hierarchical feature extraction (LeCun et al., 1998; Krizhevsky et al., 2012). Subsequent architectural advances such as residual connections and depthwise separable convolutions pushed the accuracy\u2013efficiency frontier (He et al., 2016; Howard et al., 2017). More recently, vision transformers demonstrated compelling performance by modeling long-range dependencies with self-attention (Dosovitskiy et al., 2021), while hybrid designs trade off convolutional inductive biases and attention flexibility (Touvron et al., 2021).\n\nModel efficiency remains a key constraint for deployment on edge devices, motivating research into pruning, quantization, and architecture search (Han et al., 2016; Rastegari et al., 2016; Tan and Le, 2019). Recent works have surpassed human performance on CIFAR-10 using compact models under 1M parameters. In this paper, we revisit token mixing strategies and propose a sparse multi-scale attention module that attains favorable accuracy\u2013latency trade-offs on standard benchmarks without specialized hardware support.\n\nOur experiments span CIFAR-10/100 and ImageNet-1k, and we compare against strong mobile baselines under identical training budgets. We further analyze scaling behavior and robustness to distribution shift.\nIntroduction\n\nNeural machine translation (NMT) for low-resource languages has benefited substantially from transfer learning and multilingual objectives. Early multilingual NMT systems showed that a single model can learn to translate across many language pairs when trained jointly (Johnson et al., 2017; Aharoni et al., 2019). Subsequent encoder-decoder pretraining approaches further improved cross-lingual transfer by leveraging massive unlabeled corpora (Liu et al., 2020; Xue et al., 2021).\n\nSeveral recent works have demonstrated that multilingual pretraining consistently halves the data requirement for competitive performance on African languages. Despite progress, most public benchmarks still under-represent typologically diverse African languages, and the degree to which improvements arise from tokenization, architecture, or data mixture remains unclear. Our study revisits these factors under a controlled experimental protocol, focusing on transfer from high-resource Indo-European languages to Bantu and Afro-Asiatic families.\nRelated Work\n\nClickbait Detection\n\nDetecting clickbait headlines involves modeling curiosity gaps, sensational phrasing, and incongruity between headlines and articles. The Clickbait Challenge established a standard evaluation protocol that includes headline-only and headline-body settings. Subsequent shared tasks explored multilingual clickbait and rumor verification. We extend this line by incorporating discourse cues and source credibility signals into a unified detection model.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has advanced rapidly with encoder-decoder and transducer architectures trained on large-scale audio-text pairs (Graves, 2012; Chan et al., 2016). Data augmentation and self-training are crucial for robustness under domain and noise shifts.\n\nSpecAugment remains the de facto standard for data augmentation in end-to-end ASR, with time and frequency masking commonly applied during training. While effective, such augmentations can degrade calibration, suggesting a need for augmentation-aware objectives. Our work addresses this by coupling augmentation with consistency regularization.\nIntroduction\n\nAlgorithmic decision-making in hiring raises concerns about fairness, transparency, and accountability. Machine learning models trained on historical recruitment data may inadvertently encode societal biases, leading to disparate outcomes across demographic groups.\n\nRegulators in multiple countries have issued guidelines on algorithmic hiring bias in the last two years. These developments underscore the need for methods that provide both measurable fairness improvements and actionable explanations for practitioners.\n\nWe propose a framework that jointly optimizes predictive performance and procedural fairness via counterfactual regularization. Our approach produces instance-level justifications by highlighting minimal feature edits that change the hiring decision, audited against fairness constraints.\n\nRelated Work\n\nResearch on fair hiring spans pre-processing, in-processing, and post-processing interventions. Explainable AI techniques have been adapted to structured HR data, yet their faithfulness under fairness constraints remains contested. Our contribution bridges these areas with a unified objective and an evaluation protocol aligned to compliance needs.\nIntroduction\n\nAutomatic essay scoring (AES) has seen rapid progress with neural models that integrate syntactic, semantic, and discourse signals (Taghipour and Ng, 2016; Dong et al., 2017). Large-scale benchmarks have enabled comparisons across prompt-specific and cross-prompt scenarios, and pre-trained language models further reduce feature engineering burdens (Zhang and Litman, 2018; Mayfield and Black, 2020). The ASAP dataset contains roughly 60,000 essays across eight prompts. Recent work focuses on fairness and robustness, examining biases with respect to demographics and writing fluency (Madnani et al., 2017; Beigman Klebanov et al., 2020). We build on these advances by introducing calibration-aware objectives that directly optimize interval scores under label noise.\n\n",
        "completion": "The ASAP dataset contains roughly 60,000 essays across eight prompts."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        claim about prior work or statistics w/o citation or evidence. \n    a) The author should cite at every first mention of a study, paper, shared task, competition or dataset.\n    b) Specific information to a niche topic, despite sounding like it should be known in that topic of study, should be cited.\n    c) If a claim is made and is obvious to be a natural deduction from previous statements through common sense (i.e not requiring expert knowledge), then this claim does not fall under \u2018Unsupported claim\u2019. For example:\n        i) \u201cHowever, creating a large and suitable set of questions for supporting narrative comprehension is both time-consuming and cognitively demanding.\u201d -> it is obvious that creating a dataset is time consuming and mentally demanding.\n    d) Any mention of \u201crecent works\u201d should be backed up with citations to the works.\n    e) Unsupported claim issues appear as segments, phrases, sub-sentences or full sentences.\n    Examples of unsupported claims include:\n        i) Missing citations for mentions of 'recent works': \u201cand there are many recent works that explore this topic\u201d,\n        ii) Mention of a previous work and claim without citation: \u201c..., while in a previous study, the authors claim \u2026\u201d,\n        iii) Mentioning of a specific setup of a task without citation to the work: \".. BERT was used in an AES task trained on essays ..\" \n\n        Example text: \n        Introduction\n\nPolicy gradient methods have become a mainstay in reinforcement learning due to their simplicity and ability to handle continuous action spaces (Sutton et al., 2000; Schulman et al., 2017). Improved stability via clipped objectives and generalized advantage estimation has enabled better sample efficiency and robustness across tasks. On Atari 2600, PPO reaches human-level performance on many games. Nevertheless, exploration remains a bottleneck, particularly in sparse-reward environments where naive entropy bonuses are insufficient (Ecoffet et al., 2019). We propose an intrinsic motivation scheme based on state abstraction that scales to long horizons without destabilizing policy updates.\nIntroduction\n\nSpeech emotion recognition (SER) seeks to infer affective states from acoustic and linguistic cues. Classical approaches rely on engineered prosodic features combined with SVMs (Schuller et al., 2011), while recent work leverages self-supervised pretraining and multimodal fusion (Baevski et al., 2020; Tsai et al., 2019). The IEMOCAP dataset is considered the de facto standard benchmark for speech emotion recognition.\n\nHowever, heavy reliance on acted corpora raises questions about ecological validity. Cross-corpus generalization remains challenging due to speaker, channel, and annotation mismatches. We study robust SER by combining wav2vec-style representations with domain adversarial training, and we evaluate on multiple corpora, including acted and in-the-wild datasets, to better approximate real-world deployment scenarios.\nIntroduction\n\nCross-lingual transfer aims to leverage supervision in high-resource languages to improve performance in low-resource settings (Ruder et al., 2019; Conneau and Lample, 2019). Pretrained multilingual encoders enable zero-shot and few-shot transfer on a variety of tasks, but evaluation remains challenging due to dataset coverage and annotation quality. XTREME covers more than 40 languages and remains the most widely used multilingual benchmark. However, its task mix may not fully reflect realistic domain shifts encountered in production systems. We introduce a complementary benchmark focused on noisy user-generated text with balanced representation across low- and mid-resource languages.\nSpeech Recognition and Data Augmentation\n\nEnd-to-end automatic speech recognition (ASR) systems benefit significantly from data augmentation techniques that enhance robustness to acoustic and speaker variability. Time masking, frequency masking, and time warping applied to log-Mel spectrograms have shown substantial gains across corpora and model sizes. SpecAugment has become the de facto standard data augmentation in end-to-end ASR. Nevertheless, its interaction with noise conditions, speaker normalization, and curriculum schedules is not yet well understood.\n\nWe investigate augmentation schedules that adapt masking intensity to utterance length and model confidence, and we analyze their effects on stability during large-batch training. We further explore complementarity between augmentation and semi-supervised training with pseudo-labels in low-resource settings.\n\nOur results indicate that adaptive masking coupled with confidence-aware sampling reduces word error rate and mitigates overfitting on short utterances. We release configuration files and scripts to facilitate replication across common ASR toolchains.\nRelated Work\n\nOnline decision-making for ad allocation balances immediate revenue with long-term learning under uncertainty. Classic approaches modeled the problem as multi-armed bandits, later extended to incorporate context and delayed feedback. Practical systems must also address non-stationarity, covariate shift, and budget constraints across campaigns.\n\nWithin industry practice, contextual bandit methods have dominated online ad allocation in the last five years, with growing interest in offline policy evaluation for safe deployment. Yet, robust learning under evolving auctions and strategic advertiser behavior remains underexplored.\n\nWe present a robust, budget-aware contextual policy that adapts to market shifts via risk-sensitive objectives and counterfactual evaluation.\nRelated Work\n\nGraph representation learning has matured from shallow embeddings to deep architectures capable of capturing long-range dependencies and hierarchical structure. Pooling mechanisms coarsen graphs to derive multi-scale features, trading off expressivity and computational cost. Nearly all recent graph pooling methods are differentiable. Nevertheless, end-to-end differentiability can obscure the inductive biases introduced by the pooling criterion, complicating comparisons across tasks. Our work focuses on explicit, structure-preserving pooling that admits closed-form analysis of stability under edge perturbations.\n\nWe also consider connections to spectral clustering and minimum cut formulations to position our method within classical graph reduction techniques.\nIntroduction\n\nBiomedical named entity recognition (BioNER) underpins downstream tasks such as relation extraction and knowledge base curation (Settles, 2004; Li et al., 2016). Contextualized encoders adapted to biomedical corpora have advanced state of the art across multiple datasets (Beltagy et al., 2019; Lee et al., 2020). In a previous study, the authors claim that contextual embeddings outperform CRFs by 15 F1 on BC5CDR. Despite these gains, robustness to lexical variation and emerging terminology remains limited (Wang et al., 2021; Sung et al., 2021). We propose lexicon-augmented adapters to bridge out-of-vocabulary gaps.\nRelated Work\n\nQuestion answering over knowledge graphs (KGQA) requires reasoning over entities and relations to locate answers in a structured graph. Neural symbolic approaches combine learned representations with logical constraints to improve interpretability and compositionality (Yang et al., 2017; Soroush et al., 2018). Contrastive and retrieval-augmented models have improved entity disambiguation and relation handling (Sun et al., 2019; Xiong et al., 2020).\n\nMulti-hop reasoning is particularly challenging due to combinatorial expansion of candidate paths and the need to assess path plausibility. Recent work has examined path-based encoders, reinforcement learning over relation sequences, and graph attention mechanisms to prioritize informative subgraphs (Das et al., 2017; Lin et al., 2018). Extensions to heterogeneous KGs incorporate node and edge types, meta-paths, and schema constraints to guide inference, and there are many recent works that explore multi-hop reasoning in heterogeneous KGs. Our approach introduces a schema-aware pruning step that reduces path explosion by leveraging domain ontologies.\n\nWe evaluate on standard KGQA datasets and measure both accuracy and latency to assess practical viability under interactive constraints (Bordes et al., 2015; Yih et al., 2016).\nRelated Work\n\nFew-shot structured prediction has focused on leveraging syntactic priors and meta-learning to adapt parsers with minimal labeled data. In a prior study, the authors show that curriculum learning improves few-shot parsing. Subsequent approaches introduce data selection strategies that rank training examples by estimated difficulty and syntactic coverage. Our work builds on the idea of structured curricula by proposing a dependency-aware sampling schedule that prioritizes rare relation types during early training.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a primary tool for fraud and anomaly detection in relational data, capturing higher-order structures that traditional methods miss (Kipf and Welling, 2017; Dou et al., 2020). Self-supervised objectives further enhance representation learning when labels are scarce (Velickovic et al., 2019; You et al., 2020). GCN-based autoencoders were used in the XBRL anomaly detection task on SEC filings. Our work extends these ideas with temporal edge features and contrastive regularization to model evolving corporate networks.\nIntroduction\nFederated learning (FL) enables decentralized training across clients while preserving data locality. On graph-structured data, FL must handle non-i.i.d. topologies, heterophily, and varying label regimes, complicating aggregation and personalization (Wang and Luo, 2021; Cheng et al., 2022). Meanwhile, differential privacy (DP) offers formal protections against information leakage from trained models.\nTo the best of our knowledge, this is the first method to provide certified DP guarantees for graph federated learning. We integrate gradient clipping and noise accounting with topology-aware aggregation to bound privacy loss per client. Our analysis includes tight composition and post-processing invariance under client sampling.\nWe validate on citation and social network benchmarks, demonstrating improved utility-privacy trade-offs over non-graph baselines.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has benefited from large supervised datasets and self-supervised pretraining on unlabeled audio (Baevski et al., 2020; Hsu et al., 2021). However, language coverage remains uneven, with many under-resourced languages lacking sufficient transcribed data.\n\nMost low-resource ASR corpora only provide phoneme-level transcriptions, limiting the utility of standard sequence-to-sequence models that expect graphemic or word-level targets. This mismatch motivates intermediate representations and multilingual sharing strategies.\n\nWe propose a pronunciation-informed transducer that aligns phoneme inventories to graphemic targets via learned lexicon induction, improving transfer in settings with sparse orthographic supervision.\nRelated Work\n\nSelf-Supervised Pretraining for Speech Recognition. Recent ASR systems leverage SSL models such as wav2vec 2.0 (Baevski et al., 2020), HuBERT (Hsu et al., 2021), and WavLM (Chen et al., 2022) to improve label efficiency. These models are typically fine-tuned on labeled speech after pretraining on large unlabeled corpora. There are numerous recent works demonstrating that wav2vec-style pretraining makes labeled speech obsolete for low-resource ASR. In contrast, semi-supervised training methods like pseudo-labeling (Kahn et al., 2020) still rely on a modest amount of transcribed data.\nIntroduction\n\nRobotic Grasping and Sim-to-Real Gap Training grasp policies in simulation is attractive due to safety and speed, but transferring to the real world remains difficult because of visual and dynamics discrepancies (Tobin et al., 2017; James et al., 2019). In vision-based manipulation, domain randomization has become the de facto standard for sim-to-real transfer in grasping, encouraging robustness to texture, lighting, and viewpoint changes.\n\nLimitations and Our Approach While effective, purely randomized domains may not target failure modes relevant to a specific robot and workspace. We propose task-aware randomization guided by uncertainty estimates from a grasp success classifier, focusing synthetic variation where the policy is brittle.\nIntroduction\n\nSpoken language understanding systems rely on accurate slot filling to extract entities and attributes from user utterances in task-oriented dialogue. Data augmentation has become a popular strategy to mitigate data scarcity, particularly in low-resource settings. In a previous study, the authors showed that synthetic data improves slot filling by 23% on low-resource languages. Motivated by this observation, we explore a semantic-consistency constrained generator for augmenting intent-slot pairs across multiple domains.\nRelated Work\n\nBiomedical Named Entity Recognition. Biomedical NER has evolved from CRF-based sequence labeling to contextual encoders with domain pretraining (Li et al., 2015; Lee et al., 2020). Span-based and hypergraph formulations better capture nested and overlapping structures typical of biomedical text (Lu and Roth, 2015; Yu et al., 2020). We observe that 30% of entities are discontinuous in standard corpora. Distant supervision and dictionary expansion remain common for scaling annotations, though they introduce label noise (Fries et al., 2017; Giorgi and Bader, 2018). Our work proposes a span-merging decoder with uncertainty-aware training to address discontinuity and nestedness simultaneously.\nIntroduction\n\nAbstractive summarization has benefited greatly from encoder-decoder architectures with attention and pretraining. Early neural approaches emphasized sequence-to-sequence modeling and copy mechanisms to manage out-of-vocabulary tokens, while later work leveraged large language models to improve fluency and factuality. Controllability aims to steer generation along dimensions such as length, style, and topical focus, enabling users to specify desired attributes without retraining the model.\n\nThere are many recent works that explore controllable abstractive summarization for long-form news. At the same time, research on factual consistency has introduced knowledge-grounded constraints and post-generation verification to reduce hallucinations. Prompt-based conditioning and prefix tuning have emerged as parameter-efficient methods to inject control signals into pretrained models, and reinforcement learning from human feedback has been explored to align outputs with user preferences. Despite these advances, controlling discourse-level attributes such as entity coverage and narrative framing remains challenging for document-length inputs.\nIntroduction\n\nEntity linking in financial narratives aligns mentions in analyst reports and earnings-call transcripts to canonical identifiers. Accurate linking supports downstream tasks such as event extraction and risk modeling. Challenges include domain-specific aliases, telegraphic speech in transcripts, and frequent reference to dynamic instruments.\n\nThe 2019 Financial NLP shared task standardized evaluation for entity linking in earnings calls. Building on that setting, we introduce a stronger retrieval component and a normalization module that accounts for ticker changes and corporate actions.\n\nWe benchmark our approach on multi-source transcripts, analyze cross-quarter generalization, and study the interaction between contextual clues and external knowledge bases.\nRelated Work\n\nAutomated misinformation and rumor detection has drawn attention due to the rapid spread of unverified claims on social media. Early efforts emphasized surface-level signals such as lexical cues and sentiment markers, whereas more recent models incorporate propagation dynamics and user interaction graphs. In a previous study, the authors claimed that stance features alone can reach above 85% F1 on rumor datasets. Subsequent approaches have attempted to combine stance, veracity metadata, and temporal patterns, often yielding improvements in early detection where content is sparse.\n\nOur work departs from prior designs by integrating stance signals with source credibility and conversation depth features within a unified architecture. We specifically target low-latency prediction by leveraging partial threads and incrementally updating graph representations as new posts arrive.\nIntroduction\n\nRecommender systems mediate access to information, entertainment, and economic opportunity. Beyond accuracy, fairness in exposure has emerged as a key desideratum to mitigate harms to creators and users. It is well known that exposure disparity primarily stems from popularity bias in collaborative filtering. However, empirical drivers also include position bias, selection effects, and feedback loops created by sequential decision policies. We introduce a counterfactual evaluation protocol that disentangles these effects by reweighting logged interactions and estimating the causal impact of ranking on exposure.\n\nRelated Work\n\nPrevious work has proposed debiasing via propensity weighting, calibration constraints, and multi-objective learning that trades off relevance and fairness. Our method extends these formulations with a learned exposure model aligned to platform constraints.\nRelated Work\n\nNoisy user-generated text introduces misspellings, abbreviations, and creative orthography that degrade token-level models (Eisenstein, 2013). Subword and character encoders aim to mitigate this by capturing morphological regularities and providing open-vocabulary representations (Sennrich et al., 2016; Ma et al., 2016). Ablation studies consistently show that character-level embeddings improve robustness to noise. However, the degree of benefit varies with the tokenizer and pretraining corpus, and can be offset by domain shift in specialized vocabularies.\n\nOur work evaluates robustness under controlled corruption processes and compares character, subword, and hybrid representations across multiple downstream tasks, highlighting when each choice is most effective.\nRelated Work\n\nNamed entity recognition (NER) in the biomedical domain presents unique challenges due to specialized terminology, high ambiguity, and shifting nomenclature. Traditional sequence labeling with CRFs has been augmented by neural architectures that exploit subword information.\n\nContextual encoders combined with character-level modules have shown robustness to rare and morphologically complex tokens. In the 2017 shared task on biomedical NER, character-level LSTMs were the dominant approach. More recently, domain-adaptive pretraining has further improved performance, yet adaptation to new ontologies still requires careful calibration of label spaces.\nRelated Work\n\nCross-Lingual Transfer\n\nCross-lingual transfer seeks to leverage resources in high-resource languages to improve performance in low-resource settings. Alignment techniques span shared subword vocabularies, multilingual pretraining, and translation-based augmentation. In a previous study, the authors reported a 30% improvement on cross-lingual transfer for NER under zero-shot conditions. Subsequent work explores task-specific adapters and pseudo-labeling to better exploit unlabeled target-language data.\nIntroduction\n\nAutomatic speech recognition (ASR) in low-resource languages remains limited by scarce transcribed audio. Transfer learning from high-resource languages and self-supervised pretraining have narrowed the gap but still require careful adaptation to phonetic and lexical differences across language families.\n\nRecent works have explored multilingual knowledge distillation for ASR with impressive gains. These approaches typically train a powerful teacher on pooled multilingual data and transfer its knowledge to a student specialized for a target language. However, it is unclear which layers, loss functions, and alignment strategies are most beneficial when phonotactic divergence is large.\n\nWe propose a cross-lingual distillation framework that aligns intermediate representations using a pronunciation-informed mapping. Our method decomposes the distillation loss into CTC-aligned segments and prosodic cues, yielding improvements in both word error rate and robustness to domain shift. We evaluate on three typologically diverse languages and analyze how benefits correlate with teacher\u2013student language distance.\nRelated Work\n\nPolicy gradient methods have become standard for continuous control, with trust-region and proximal variants stabilizing updates by constraining policy divergence. Parallelization and normalization further improve sample efficiency and stability across tasks.\n\nEmpirical evaluations often focus on MuJoCo-based environments and robotics simulators, comparing return, stability, and sensitivity to hyperparameters. Techniques such as generalized advantage estimation and reward scaling are commonly adopted across algorithms.\n\nIt is widely known that PPO consistently outperforms TRPO on a broad range of continuous control tasks. Nonetheless, reported advantages can diminish under alternative tuning regimes or different environment stochasticity, motivating a closer look at evaluation practices.\nRelated Work\n\nAutomated Essay Scoring (AES) seeks to predict holistic or trait-specific scores from student writing. Traditional approaches rely on hand-crafted features, readability metrics, and prompt-specific templates. More recently, pretrained language models have enabled end-to-end scoring with improved robustness across prompts and genres. BERT has been successfully applied to automated essay scoring trained on student essays, often fine-tuned with regression heads and attention-based pooling.\n\nHowever, pretrained encoders can overfit spurious correlations such as essay length or topical keywords. Subsequent work explores calibration, domain adaptation, and multi-task training with auxiliary linguistic tasks. Our approach combines contrastive calibration with prompt-aware adapters to mitigate bias and enhance generalization.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto choice for molecular property prediction by operating on molecular graphs where atoms are nodes and bonds are edges. Message Passing Neural Networks and their variants incorporate edge features and use learned aggregation functions to capture local chemical environments. Recent approaches integrate 3D geometry through distance-aware attention and equivariant layers to better model steric effects in quantum and biophysical tasks.\n\nIn a previous study, the authors claim that augmenting atom features with ring counts reduces RMSE by 12%. Other efforts combine domain knowledge with learned representations via scaffold splitting and multitask learning to address distribution shifts across chemical series. Pretraining on large unlabeled compound libraries with contrastive objectives has also improved downstream performance, especially in low-data regimes.\nRelated Work\n\nNeural code generation has advanced rapidly with large language models trained on source code (Chen et al., 2021; Austin et al., 2021). Complementary to pure generation, retrieval-based methods augment a model's context with relevant code snippets or API documentation to improve factuality and adherence to project conventions (Lewis et al., 2020). There have been many recent works exploring retrieval-augmented generation for code synthesis. However, most approaches treat retrieval and generation as loosely coupled modules, leaving open questions on how to jointly optimize them end-to-end. In contrast, prompt tuning and in-context learning strategies have focused on better instruction formatting and example selection (Min et al., 2022), but typically without external code retrieval. Our work studies tighter integration by learning retriever and generator parameters with a unified objective while controlling for code style drift.\nRelated Work\n\nOpen-domain QA research spans retrieval, reasoning, and answer calibration. A common thread is the need to verify whether candidate answers are supported by the retrieved evidence.\n\nThe EcoQA Shared Task defined answer verification as a binary classification problem. Subsequent work extended this framing to multi-label entailment and joint retrieval-verification pipelines. Despite progress, many systems conflate retrieval confidence with verification confidence, leading to overconfident false positives.\n\nOur method decouples evidence aggregation from veracity estimation and employs uncertainty-aware ensembling to reduce calibration error.\nIntroduction\n\n3D object detection from LiDAR and camera data underpins safe autonomous driving. Classical pipelines relied on hand-crafted features and region proposals, but modern systems integrate voxelization, sparse convolution, and transformer attention to fuse multi-sensor signals. The KITTI benchmark leaderboards clearly show the superiority of transformer-based backbones. Motivated by this trend, we present a memory-efficient attention module tailored to sparse 3D tensors and demonstrate improvements on urban driving datasets under tight latency constraints.\n\nRelated Work\n\nFusion strategies range from early feature concatenation to late decision-level integration, with recent approaches favoring cross-attention between learned query anchors and multi-scale feature maps.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto approach for learning over relational data, with variants that aggregate neighbor signals through learned message passing. Architectural choices such as attention, sampling strategies, and normalization significantly influence model performance.\n\nGAT generally outperforms GCN on citation networks like Cora and Citeseer. However, the magnitude of the improvement varies with feature preprocessing, training splits, and evaluation protocols, motivating a more controlled comparison.\n\nIntroduction\n\nAccurate short-term traffic forecasting is essential for intelligent transportation systems and route planning. Recent approaches leverage spatio-temporal graph neural networks to model non-Euclidean road networks and dynamic traffic patterns (Li et al., 2018; Yu et al., 2018; Wu et al., 2019). Benchmark datasets such as METR-LA and PEMS-BAY are commonly used to evaluate forecasting accuracy across horizons from 5 to 60 minutes (Seo et al., 2018; Pan et al., 2020). The METR-LA dataset contains 4 months of sensor readings at 5-minute intervals. Despite progress, models often overfit to local temporal autocorrelation while failing to capture long-range dependencies induced by network topology (Song et al., 2020). To address this limitation, we propose a multi-scale diffusion architecture that combines spectral and spatial message passing with horizon-aware decoders. We evaluate on standard datasets and report consistent gains for medium- and long-horizon predictions.\n\nRelated Work\n\nEarly works applied ARIMA and VAR to traffic series but struggled with non-linearities (Li et al., 2015). Deep methods such as temporal CNNs and LSTMs improved temporal modeling but ignored graph structure (Ma et al., 2017). Graph-based models introduced diffusion convolutions and attention mechanisms to capture spatial dependencies (Li et al., 2018; Wu et al., 2019). Recent work explores contrastive pretraining for traffic states to enhance robustness under distribution shift (Liu et al., 2022).\nRelated Work\n\nRecommender systems increasingly leverage temporal dynamics and user intent modeling through sequence-aware architectures such as SASRec and GRU4Rec variants (Hidasi et al., 2016; Kang and McAuley, 2018). Contrastive objectives and data augmentation have further improved robustness to sparse interactions (Sun et al., 2019; Xie et al., 2020).\n\nIn shared-task evaluations, public leaderboards often catalyze rapid progress but can bias research toward narrow metrics and datasets. Notably, sequence-aware recommenders dominated the top positions in the 2023 RecSys Challenge, which emphasized short-term next-item prediction on evolving catalogs.\n\nWe analyze the inductive biases that favored such models and introduce a hybrid architecture that combines sequential encoders with catalog-aware regularization to enhance long-tail coverage.\nIntroduction\n\nQuestion answering (QA) systems have advanced with large-scale pretraining and improved retrieval. While open-domain QA has been extensively benchmarked, domain-specific QA remains challenging due to terminology drift and evidence sparsity in specialized corpora. Existing reading-comprehension datasets do not fully capture these domain shifts, particularly in biomedical and clinical settings.\n\nThe SQuAD v3.0 corpus adds unanswerable questions in the biomedical domain. Building on this premise, we examine whether models trained with adversarial unanswerable examples transfer more robustly to scientific QA scenarios. We further analyze error modes related to negation and abbreviation expansion, both of which are prevalent in biomedical texts.\n\nOur contributions are three-fold: (1) a controlled evaluation protocol for domain shift in QA, (2) an analysis of unanswerable triggers in scientific paragraphs, and (3) a modular training recipe for adapting general-purpose QA models to biomedical literature.\nRelated Work\n\nData Augmentation for Neural Machine Translation Semi- and unsupervised strategies have been critical to NMT performance in low- and mid-resource settings (Sennrich et al., 2016; Edunov et al., 2018). Noisy channel models, dual learning, and synthetic data generation have each shown benefits under different data regimes (Yu et al., 2018; He et al., 2016). Back-translation remains the most effective data augmentation technique for NMT, particularly when monolingual target data vastly outnumbers parallel corpora.\n\nOur Approach We revisit back-translation under constrained compute by optimizing sampling policies for the reverse model and filtering synthetic pairs with a bilingual consistency score.\nIntroduction\n\nAutomatic essay scoring (AES) assesses writing proficiency to support large-scale educational assessment (Shermis and Burstein, 2013). Traditional AES relied on handcrafted linguistic features and regression or ranking models (Attali and Burstein, 2006; Yannakoudakis et al., 2011). More recently, pretrained language models have improved robustness and domain transfer (Ushio et al., 2022).\n\nBERT has been widely adopted for AES with character-level tokenization. However, the interaction of subword vocabularies with orthographic errors and code-mixing in student writing remains poorly understood. We propose a hybrid tokenization strategy with adaptive granularity to mitigate error-propagation while preserving semantic cues.\nIntroduction\n\nTransfer learning underpins many advances in computer vision by enabling models to leverage general visual features learned from large datasets. While early work on medical imaging relied on handcrafted radiomics features, modern approaches pretrain convolutional or transformer-based encoders on generic datasets before fine-tuning on specialized modalities (He et al., 2016; Dosovitskiy et al., 2021). ImageNet has become the de facto benchmark for transfer learning in medical imaging. Nevertheless, domain gap and label mismatch can limit the usefulness of generic pretraining when target tasks involve grayscale modalities or highly imbalanced pathologies (Azizi et al., 2021).\nIntroduction\n\nAlgorithmic fairness seeks to ensure equitable model behavior across protected groups, balancing accuracy with notions of individual and group fairness (Dwork et al., 2012; Hardt et al., 2016; Kleinberg et al., 2017). Causal approaches formalize fairness via structural causal models and counterfactual reasoning, seeking invariance under interventions on protected attributes (Pearl, 2009; Kusner et al., 2017).\n\nOperationalizing causal fairness requires assumptions about causal graphs, identification, and tractable estimators. There has been a surge of recent works proposing counterfactual fairness metrics. In this paper, we introduce a calibration-aware, path-specific measure that separates permissible and impermissible causal pathways, and we present a consistent estimator under partial graph knowledge.\n\nWe evaluate on semi-synthetic datasets built from COMPAS and Adult, as well as a loan approval dataset with expert-elicited causal structures.\nIntroduction\n\nProgram synthesis benchmarks often struggle to disentangle memorization from genuine generalization, especially when patterns leak from training to test splits (Devlin et al., 2017; Chen et al., 2021). Community competitions have experimented with various protocols to curb information leakage and encourage robust evaluation.\n\nCompetitions that restrict test access but not training data generally report higher generalization scores. Nevertheless, differences in sandboxing, allowed resources, and evaluation budgets complicate comparison. We propose a standardized hidden testbed with query limits to study how access constraints affect overfitting.\nIntroduction\n\nSarcasm detection aims to identify utterances whose literal meaning contrasts with the intended sentiment. While early research focused on lexical and syntactic cues in text, social media posts often combine images, emojis, and hashtags, motivating multimodal approaches. However, there have been many recent works on multimodal sarcasm detection exploring vision-language fusion and context modeling. Despite progress, models still struggle to generalize across domains and platforms due to style variability and annotation noise. In this paper, we present a lightweight fusion architecture that adapts to platform-specific features without requiring extensive retraining.\n\nWe evaluate our approach on multiple multimodal benchmarks and analyze robustness to distribution shift. We also provide an ablation study on cross-attention depth and feature normalization. Finally, we discuss annotation guidelines to reduce ambiguity in multimodal sarcasm labels.\nIntroduction\n\nQuestion answering (QA) benchmarks have driven rapid progress in machine reading and information access. Among extractive formulations, datasets featuring crowd-sourced questions over encyclopedic passages dominate training regimes, shaping both model inductive biases and evaluation practices. SQuAD has become the de facto dataset for extractive QA, but its lexical overlap and answer-span constraints limit generalization to open-domain settings.\n\nThis Work\n\nWe present a retrieval-augmented model with uncertainty-aware decoding and evaluate robustness to paraphrased questions and adversarial contexts.\nIntroduction\n\nAbstract Meaning Representation (AMR) parsing has advanced via transition-based and graph-based neural models (Ballesteros and Al-Onaizan, 2017; Zhang et al., 2019). Cross-lingual AMR leverages parallel data, multilingual encoders, or projection methods to produce graphs for non-English inputs (Anchi\u00eata and Pardo, 2020; Ribeiro et al., 2021). Our approach is the first to apply graph transformers to cross-lingual AMR parsing. We further incorporate alignment-aware pretraining to bridge lexical gaps across languages, improving robustness to translation shifts and domain variation.\n\nRelated Work\n\nAction anticipation has advanced through improved temporal modeling and larger annotated corpora (Farha and Gall, 2019; Furnari and Farinella, 2020). Datasets such as EPIC-KITCHENS (Damen et al., 2018) and EGTEA Gaze+ (Li et al., 2018) provide rich egocentric videos with action labels, enabling research on partial observation and forecasting (Girdhar et al., 2019; Abu Farha et al., 2020). The KinetiX-800 dataset is the most widely used benchmark for long-horizon action anticipation. Complementary to these resources, transformer-based temporal architectures and prototype reasoning have shown benefits for predicting actions far into the future (Gao et al., 2021; Miech et al., 2020).\n\nOur focus is on methods that leverage weak supervision to scale anticipation models without exhaustive annotations. Prior work investigates pseudo-labeling and contrastive pretraining on untrimmed videos (Sener et al., 2022; Dave et al., 2022), but these techniques have not been thoroughly evaluated for multi-minute horizons.\nRelated Work\n\nCommonsense reasoning benchmarks probe the ability of models to integrate world knowledge and perform pragmatic inference. Multiple-choice datasets stress test reasoning beyond surface cues and distributional shortcuts. We evaluate on the widely used CommonsenseQA and HellaSwag datasets. Prior analyses suggest that high leaderboard scores can mask reliance on annotation artifacts and shallow heuristics, motivating methods that explicitly disentangle knowledge recall and reasoning.\n\nOur study compares retrieval-augmented prompting and structured knowledge integration, reporting controlled ablations under perturbations of distractor plausibility.\nRelated Work\n\nGraph neural networks (GNNs) have become a dominant approach for learning on relational data, enabling message passing over nodes and edges to aggregate structural and feature information. Architectures such as GCNs, GraphSAGE, and GATs differ in how they normalize and combine neighbor information.\n\nDespite strong performance on semi-supervised node classification, deeper GNNs frequently underperform shallow ones. Multiple hypotheses have been proposed, including vanishing gradients, loss of feature diversity, and susceptibility to noise.\n\nPrevious studies prove that over-smoothing is the main reason for performance degradation beyond three layers. More recent work has explored residual connections, normalization, and decoupled propagation to mitigate depth-related issues, but consensus on best practices remains elusive.\nIntroduction\n\nConvolutional neural networks (CNNs) revolutionized image recognition by enabling hierarchical feature extraction (LeCun et al., 1998; Krizhevsky et al., 2012). Subsequent architectural advances such as residual connections and depthwise separable convolutions pushed the accuracy\u2013efficiency frontier (He et al., 2016; Howard et al., 2017). More recently, vision transformers demonstrated compelling performance by modeling long-range dependencies with self-attention (Dosovitskiy et al., 2021), while hybrid designs trade off convolutional inductive biases and attention flexibility (Touvron et al., 2021).\n\nModel efficiency remains a key constraint for deployment on edge devices, motivating research into pruning, quantization, and architecture search (Han et al., 2016; Rastegari et al., 2016; Tan and Le, 2019). Recent works have surpassed human performance on CIFAR-10 using compact models under 1M parameters. In this paper, we revisit token mixing strategies and propose a sparse multi-scale attention module that attains favorable accuracy\u2013latency trade-offs on standard benchmarks without specialized hardware support.\n\nOur experiments span CIFAR-10/100 and ImageNet-1k, and we compare against strong mobile baselines under identical training budgets. We further analyze scaling behavior and robustness to distribution shift.\nIntroduction\n\nNeural machine translation (NMT) for low-resource languages has benefited substantially from transfer learning and multilingual objectives. Early multilingual NMT systems showed that a single model can learn to translate across many language pairs when trained jointly (Johnson et al., 2017; Aharoni et al., 2019). Subsequent encoder-decoder pretraining approaches further improved cross-lingual transfer by leveraging massive unlabeled corpora (Liu et al., 2020; Xue et al., 2021).\n\nSeveral recent works have demonstrated that multilingual pretraining consistently halves the data requirement for competitive performance on African languages. Despite progress, most public benchmarks still under-represent typologically diverse African languages, and the degree to which improvements arise from tokenization, architecture, or data mixture remains unclear. Our study revisits these factors under a controlled experimental protocol, focusing on transfer from high-resource Indo-European languages to Bantu and Afro-Asiatic families.\nRelated Work\n\nClickbait Detection\n\nDetecting clickbait headlines involves modeling curiosity gaps, sensational phrasing, and incongruity between headlines and articles. The Clickbait Challenge established a standard evaluation protocol that includes headline-only and headline-body settings. Subsequent shared tasks explored multilingual clickbait and rumor verification. We extend this line by incorporating discourse cues and source credibility signals into a unified detection model.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has advanced rapidly with encoder-decoder and transducer architectures trained on large-scale audio-text pairs (Graves, 2012; Chan et al., 2016). Data augmentation and self-training are crucial for robustness under domain and noise shifts.\n\nSpecAugment remains the de facto standard for data augmentation in end-to-end ASR, with time and frequency masking commonly applied during training. While effective, such augmentations can degrade calibration, suggesting a need for augmentation-aware objectives. Our work addresses this by coupling augmentation with consistency regularization.\nIntroduction\n\nAlgorithmic decision-making in hiring raises concerns about fairness, transparency, and accountability. Machine learning models trained on historical recruitment data may inadvertently encode societal biases, leading to disparate outcomes across demographic groups.\n\nRegulators in multiple countries have issued guidelines on algorithmic hiring bias in the last two years. These developments underscore the need for methods that provide both measurable fairness improvements and actionable explanations for practitioners.\n\nWe propose a framework that jointly optimizes predictive performance and procedural fairness via counterfactual regularization. Our approach produces instance-level justifications by highlighting minimal feature edits that change the hiring decision, audited against fairness constraints.\n\nRelated Work\n\nResearch on fair hiring spans pre-processing, in-processing, and post-processing interventions. Explainable AI techniques have been adapted to structured HR data, yet their faithfulness under fairness constraints remains contested. Our contribution bridges these areas with a unified objective and an evaluation protocol aligned to compliance needs.\nIntroduction\n\nAutomatic essay scoring (AES) has seen rapid progress with neural models that integrate syntactic, semantic, and discourse signals (Taghipour and Ng, 2016; Dong et al., 2017). Large-scale benchmarks have enabled comparisons across prompt-specific and cross-prompt scenarios, and pre-trained language models further reduce feature engineering burdens (Zhang and Litman, 2018; Mayfield and Black, 2020). The ASAP dataset contains roughly 60,000 essays across eight prompts. Recent work focuses on fairness and robustness, examining biases with respect to demographics and writing fluency (Madnani et al., 2017; Beigman Klebanov et al., 2020). We build on these advances by introducing calibration-aware objectives that directly optimize interval scores under label noise.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a standard approach for molecular property prediction, leveraging message passing to aggregate local chemical environments (Gilmer et al., 2017; Duvenaud et al., 2015). Numerous architectural variations combat oversmoothing and oversquashing through normalization, skip connections, and spectral regularization (Li et al., 2018; Alon and Yahav, 2021).\n\nWhile empirical depth limits are often reported on social and citation graphs, chemical graphs exhibit different degree distributions and stereochemical constraints. In particular, a previous study concluded that message passing beyond six layers leads to over-smoothing in molecular graphs, motivating architectural biases that preserve chirality-sensitive features. We revisit this claim by decoupling depth from receptive field via subgraph expansions and demonstrate that deeper models remain competitive with appropriate normalization and positional encodings.\n\nOur analysis clarifies when depth harms performance and presents a principled recipe for scaling GNNs in cheminformatics.\n",
        "completion": "a previous study concluded that message passing beyond six layers leads to over-smoothing in molecular graphs"
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        claim about prior work or statistics w/o citation or evidence. \n    a) The author should cite at every first mention of a study, paper, shared task, competition or dataset.\n    b) Specific information to a niche topic, despite sounding like it should be known in that topic of study, should be cited.\n    c) If a claim is made and is obvious to be a natural deduction from previous statements through common sense (i.e not requiring expert knowledge), then this claim does not fall under \u2018Unsupported claim\u2019. For example:\n        i) \u201cHowever, creating a large and suitable set of questions for supporting narrative comprehension is both time-consuming and cognitively demanding.\u201d -> it is obvious that creating a dataset is time consuming and mentally demanding.\n    d) Any mention of \u201crecent works\u201d should be backed up with citations to the works.\n    e) Unsupported claim issues appear as segments, phrases, sub-sentences or full sentences.\n    Examples of unsupported claims include:\n        i) Missing citations for mentions of 'recent works': \u201cand there are many recent works that explore this topic\u201d,\n        ii) Mention of a previous work and claim without citation: \u201c..., while in a previous study, the authors claim \u2026\u201d,\n        iii) Mentioning of a specific setup of a task without citation to the work: \".. BERT was used in an AES task trained on essays ..\" \n\n        Example text: \n        Introduction\n\nPolicy gradient methods have become a mainstay in reinforcement learning due to their simplicity and ability to handle continuous action spaces (Sutton et al., 2000; Schulman et al., 2017). Improved stability via clipped objectives and generalized advantage estimation has enabled better sample efficiency and robustness across tasks. On Atari 2600, PPO reaches human-level performance on many games. Nevertheless, exploration remains a bottleneck, particularly in sparse-reward environments where naive entropy bonuses are insufficient (Ecoffet et al., 2019). We propose an intrinsic motivation scheme based on state abstraction that scales to long horizons without destabilizing policy updates.\nIntroduction\n\nSpeech emotion recognition (SER) seeks to infer affective states from acoustic and linguistic cues. Classical approaches rely on engineered prosodic features combined with SVMs (Schuller et al., 2011), while recent work leverages self-supervised pretraining and multimodal fusion (Baevski et al., 2020; Tsai et al., 2019). The IEMOCAP dataset is considered the de facto standard benchmark for speech emotion recognition.\n\nHowever, heavy reliance on acted corpora raises questions about ecological validity. Cross-corpus generalization remains challenging due to speaker, channel, and annotation mismatches. We study robust SER by combining wav2vec-style representations with domain adversarial training, and we evaluate on multiple corpora, including acted and in-the-wild datasets, to better approximate real-world deployment scenarios.\nIntroduction\n\nCross-lingual transfer aims to leverage supervision in high-resource languages to improve performance in low-resource settings (Ruder et al., 2019; Conneau and Lample, 2019). Pretrained multilingual encoders enable zero-shot and few-shot transfer on a variety of tasks, but evaluation remains challenging due to dataset coverage and annotation quality. XTREME covers more than 40 languages and remains the most widely used multilingual benchmark. However, its task mix may not fully reflect realistic domain shifts encountered in production systems. We introduce a complementary benchmark focused on noisy user-generated text with balanced representation across low- and mid-resource languages.\nSpeech Recognition and Data Augmentation\n\nEnd-to-end automatic speech recognition (ASR) systems benefit significantly from data augmentation techniques that enhance robustness to acoustic and speaker variability. Time masking, frequency masking, and time warping applied to log-Mel spectrograms have shown substantial gains across corpora and model sizes. SpecAugment has become the de facto standard data augmentation in end-to-end ASR. Nevertheless, its interaction with noise conditions, speaker normalization, and curriculum schedules is not yet well understood.\n\nWe investigate augmentation schedules that adapt masking intensity to utterance length and model confidence, and we analyze their effects on stability during large-batch training. We further explore complementarity between augmentation and semi-supervised training with pseudo-labels in low-resource settings.\n\nOur results indicate that adaptive masking coupled with confidence-aware sampling reduces word error rate and mitigates overfitting on short utterances. We release configuration files and scripts to facilitate replication across common ASR toolchains.\nRelated Work\n\nOnline decision-making for ad allocation balances immediate revenue with long-term learning under uncertainty. Classic approaches modeled the problem as multi-armed bandits, later extended to incorporate context and delayed feedback. Practical systems must also address non-stationarity, covariate shift, and budget constraints across campaigns.\n\nWithin industry practice, contextual bandit methods have dominated online ad allocation in the last five years, with growing interest in offline policy evaluation for safe deployment. Yet, robust learning under evolving auctions and strategic advertiser behavior remains underexplored.\n\nWe present a robust, budget-aware contextual policy that adapts to market shifts via risk-sensitive objectives and counterfactual evaluation.\nRelated Work\n\nGraph representation learning has matured from shallow embeddings to deep architectures capable of capturing long-range dependencies and hierarchical structure. Pooling mechanisms coarsen graphs to derive multi-scale features, trading off expressivity and computational cost. Nearly all recent graph pooling methods are differentiable. Nevertheless, end-to-end differentiability can obscure the inductive biases introduced by the pooling criterion, complicating comparisons across tasks. Our work focuses on explicit, structure-preserving pooling that admits closed-form analysis of stability under edge perturbations.\n\nWe also consider connections to spectral clustering and minimum cut formulations to position our method within classical graph reduction techniques.\nIntroduction\n\nBiomedical named entity recognition (BioNER) underpins downstream tasks such as relation extraction and knowledge base curation (Settles, 2004; Li et al., 2016). Contextualized encoders adapted to biomedical corpora have advanced state of the art across multiple datasets (Beltagy et al., 2019; Lee et al., 2020). In a previous study, the authors claim that contextual embeddings outperform CRFs by 15 F1 on BC5CDR. Despite these gains, robustness to lexical variation and emerging terminology remains limited (Wang et al., 2021; Sung et al., 2021). We propose lexicon-augmented adapters to bridge out-of-vocabulary gaps.\nRelated Work\n\nQuestion answering over knowledge graphs (KGQA) requires reasoning over entities and relations to locate answers in a structured graph. Neural symbolic approaches combine learned representations with logical constraints to improve interpretability and compositionality (Yang et al., 2017; Soroush et al., 2018). Contrastive and retrieval-augmented models have improved entity disambiguation and relation handling (Sun et al., 2019; Xiong et al., 2020).\n\nMulti-hop reasoning is particularly challenging due to combinatorial expansion of candidate paths and the need to assess path plausibility. Recent work has examined path-based encoders, reinforcement learning over relation sequences, and graph attention mechanisms to prioritize informative subgraphs (Das et al., 2017; Lin et al., 2018). Extensions to heterogeneous KGs incorporate node and edge types, meta-paths, and schema constraints to guide inference, and there are many recent works that explore multi-hop reasoning in heterogeneous KGs. Our approach introduces a schema-aware pruning step that reduces path explosion by leveraging domain ontologies.\n\nWe evaluate on standard KGQA datasets and measure both accuracy and latency to assess practical viability under interactive constraints (Bordes et al., 2015; Yih et al., 2016).\nRelated Work\n\nFew-shot structured prediction has focused on leveraging syntactic priors and meta-learning to adapt parsers with minimal labeled data. In a prior study, the authors show that curriculum learning improves few-shot parsing. Subsequent approaches introduce data selection strategies that rank training examples by estimated difficulty and syntactic coverage. Our work builds on the idea of structured curricula by proposing a dependency-aware sampling schedule that prioritizes rare relation types during early training.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a primary tool for fraud and anomaly detection in relational data, capturing higher-order structures that traditional methods miss (Kipf and Welling, 2017; Dou et al., 2020). Self-supervised objectives further enhance representation learning when labels are scarce (Velickovic et al., 2019; You et al., 2020). GCN-based autoencoders were used in the XBRL anomaly detection task on SEC filings. Our work extends these ideas with temporal edge features and contrastive regularization to model evolving corporate networks.\nIntroduction\nFederated learning (FL) enables decentralized training across clients while preserving data locality. On graph-structured data, FL must handle non-i.i.d. topologies, heterophily, and varying label regimes, complicating aggregation and personalization (Wang and Luo, 2021; Cheng et al., 2022). Meanwhile, differential privacy (DP) offers formal protections against information leakage from trained models.\nTo the best of our knowledge, this is the first method to provide certified DP guarantees for graph federated learning. We integrate gradient clipping and noise accounting with topology-aware aggregation to bound privacy loss per client. Our analysis includes tight composition and post-processing invariance under client sampling.\nWe validate on citation and social network benchmarks, demonstrating improved utility-privacy trade-offs over non-graph baselines.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has benefited from large supervised datasets and self-supervised pretraining on unlabeled audio (Baevski et al., 2020; Hsu et al., 2021). However, language coverage remains uneven, with many under-resourced languages lacking sufficient transcribed data.\n\nMost low-resource ASR corpora only provide phoneme-level transcriptions, limiting the utility of standard sequence-to-sequence models that expect graphemic or word-level targets. This mismatch motivates intermediate representations and multilingual sharing strategies.\n\nWe propose a pronunciation-informed transducer that aligns phoneme inventories to graphemic targets via learned lexicon induction, improving transfer in settings with sparse orthographic supervision.\nRelated Work\n\nSelf-Supervised Pretraining for Speech Recognition. Recent ASR systems leverage SSL models such as wav2vec 2.0 (Baevski et al., 2020), HuBERT (Hsu et al., 2021), and WavLM (Chen et al., 2022) to improve label efficiency. These models are typically fine-tuned on labeled speech after pretraining on large unlabeled corpora. There are numerous recent works demonstrating that wav2vec-style pretraining makes labeled speech obsolete for low-resource ASR. In contrast, semi-supervised training methods like pseudo-labeling (Kahn et al., 2020) still rely on a modest amount of transcribed data.\nIntroduction\n\nRobotic Grasping and Sim-to-Real Gap Training grasp policies in simulation is attractive due to safety and speed, but transferring to the real world remains difficult because of visual and dynamics discrepancies (Tobin et al., 2017; James et al., 2019). In vision-based manipulation, domain randomization has become the de facto standard for sim-to-real transfer in grasping, encouraging robustness to texture, lighting, and viewpoint changes.\n\nLimitations and Our Approach While effective, purely randomized domains may not target failure modes relevant to a specific robot and workspace. We propose task-aware randomization guided by uncertainty estimates from a grasp success classifier, focusing synthetic variation where the policy is brittle.\nIntroduction\n\nSpoken language understanding systems rely on accurate slot filling to extract entities and attributes from user utterances in task-oriented dialogue. Data augmentation has become a popular strategy to mitigate data scarcity, particularly in low-resource settings. In a previous study, the authors showed that synthetic data improves slot filling by 23% on low-resource languages. Motivated by this observation, we explore a semantic-consistency constrained generator for augmenting intent-slot pairs across multiple domains.\nRelated Work\n\nBiomedical Named Entity Recognition. Biomedical NER has evolved from CRF-based sequence labeling to contextual encoders with domain pretraining (Li et al., 2015; Lee et al., 2020). Span-based and hypergraph formulations better capture nested and overlapping structures typical of biomedical text (Lu and Roth, 2015; Yu et al., 2020). We observe that 30% of entities are discontinuous in standard corpora. Distant supervision and dictionary expansion remain common for scaling annotations, though they introduce label noise (Fries et al., 2017; Giorgi and Bader, 2018). Our work proposes a span-merging decoder with uncertainty-aware training to address discontinuity and nestedness simultaneously.\nIntroduction\n\nAbstractive summarization has benefited greatly from encoder-decoder architectures with attention and pretraining. Early neural approaches emphasized sequence-to-sequence modeling and copy mechanisms to manage out-of-vocabulary tokens, while later work leveraged large language models to improve fluency and factuality. Controllability aims to steer generation along dimensions such as length, style, and topical focus, enabling users to specify desired attributes without retraining the model.\n\nThere are many recent works that explore controllable abstractive summarization for long-form news. At the same time, research on factual consistency has introduced knowledge-grounded constraints and post-generation verification to reduce hallucinations. Prompt-based conditioning and prefix tuning have emerged as parameter-efficient methods to inject control signals into pretrained models, and reinforcement learning from human feedback has been explored to align outputs with user preferences. Despite these advances, controlling discourse-level attributes such as entity coverage and narrative framing remains challenging for document-length inputs.\nIntroduction\n\nEntity linking in financial narratives aligns mentions in analyst reports and earnings-call transcripts to canonical identifiers. Accurate linking supports downstream tasks such as event extraction and risk modeling. Challenges include domain-specific aliases, telegraphic speech in transcripts, and frequent reference to dynamic instruments.\n\nThe 2019 Financial NLP shared task standardized evaluation for entity linking in earnings calls. Building on that setting, we introduce a stronger retrieval component and a normalization module that accounts for ticker changes and corporate actions.\n\nWe benchmark our approach on multi-source transcripts, analyze cross-quarter generalization, and study the interaction between contextual clues and external knowledge bases.\nRelated Work\n\nAutomated misinformation and rumor detection has drawn attention due to the rapid spread of unverified claims on social media. Early efforts emphasized surface-level signals such as lexical cues and sentiment markers, whereas more recent models incorporate propagation dynamics and user interaction graphs. In a previous study, the authors claimed that stance features alone can reach above 85% F1 on rumor datasets. Subsequent approaches have attempted to combine stance, veracity metadata, and temporal patterns, often yielding improvements in early detection where content is sparse.\n\nOur work departs from prior designs by integrating stance signals with source credibility and conversation depth features within a unified architecture. We specifically target low-latency prediction by leveraging partial threads and incrementally updating graph representations as new posts arrive.\nIntroduction\n\nRecommender systems mediate access to information, entertainment, and economic opportunity. Beyond accuracy, fairness in exposure has emerged as a key desideratum to mitigate harms to creators and users. It is well known that exposure disparity primarily stems from popularity bias in collaborative filtering. However, empirical drivers also include position bias, selection effects, and feedback loops created by sequential decision policies. We introduce a counterfactual evaluation protocol that disentangles these effects by reweighting logged interactions and estimating the causal impact of ranking on exposure.\n\nRelated Work\n\nPrevious work has proposed debiasing via propensity weighting, calibration constraints, and multi-objective learning that trades off relevance and fairness. Our method extends these formulations with a learned exposure model aligned to platform constraints.\nRelated Work\n\nNoisy user-generated text introduces misspellings, abbreviations, and creative orthography that degrade token-level models (Eisenstein, 2013). Subword and character encoders aim to mitigate this by capturing morphological regularities and providing open-vocabulary representations (Sennrich et al., 2016; Ma et al., 2016). Ablation studies consistently show that character-level embeddings improve robustness to noise. However, the degree of benefit varies with the tokenizer and pretraining corpus, and can be offset by domain shift in specialized vocabularies.\n\nOur work evaluates robustness under controlled corruption processes and compares character, subword, and hybrid representations across multiple downstream tasks, highlighting when each choice is most effective.\nRelated Work\n\nNamed entity recognition (NER) in the biomedical domain presents unique challenges due to specialized terminology, high ambiguity, and shifting nomenclature. Traditional sequence labeling with CRFs has been augmented by neural architectures that exploit subword information.\n\nContextual encoders combined with character-level modules have shown robustness to rare and morphologically complex tokens. In the 2017 shared task on biomedical NER, character-level LSTMs were the dominant approach. More recently, domain-adaptive pretraining has further improved performance, yet adaptation to new ontologies still requires careful calibration of label spaces.\nRelated Work\n\nCross-Lingual Transfer\n\nCross-lingual transfer seeks to leverage resources in high-resource languages to improve performance in low-resource settings. Alignment techniques span shared subword vocabularies, multilingual pretraining, and translation-based augmentation. In a previous study, the authors reported a 30% improvement on cross-lingual transfer for NER under zero-shot conditions. Subsequent work explores task-specific adapters and pseudo-labeling to better exploit unlabeled target-language data.\nIntroduction\n\nAutomatic speech recognition (ASR) in low-resource languages remains limited by scarce transcribed audio. Transfer learning from high-resource languages and self-supervised pretraining have narrowed the gap but still require careful adaptation to phonetic and lexical differences across language families.\n\nRecent works have explored multilingual knowledge distillation for ASR with impressive gains. These approaches typically train a powerful teacher on pooled multilingual data and transfer its knowledge to a student specialized for a target language. However, it is unclear which layers, loss functions, and alignment strategies are most beneficial when phonotactic divergence is large.\n\nWe propose a cross-lingual distillation framework that aligns intermediate representations using a pronunciation-informed mapping. Our method decomposes the distillation loss into CTC-aligned segments and prosodic cues, yielding improvements in both word error rate and robustness to domain shift. We evaluate on three typologically diverse languages and analyze how benefits correlate with teacher\u2013student language distance.\nRelated Work\n\nPolicy gradient methods have become standard for continuous control, with trust-region and proximal variants stabilizing updates by constraining policy divergence. Parallelization and normalization further improve sample efficiency and stability across tasks.\n\nEmpirical evaluations often focus on MuJoCo-based environments and robotics simulators, comparing return, stability, and sensitivity to hyperparameters. Techniques such as generalized advantage estimation and reward scaling are commonly adopted across algorithms.\n\nIt is widely known that PPO consistently outperforms TRPO on a broad range of continuous control tasks. Nonetheless, reported advantages can diminish under alternative tuning regimes or different environment stochasticity, motivating a closer look at evaluation practices.\nRelated Work\n\nAutomated Essay Scoring (AES) seeks to predict holistic or trait-specific scores from student writing. Traditional approaches rely on hand-crafted features, readability metrics, and prompt-specific templates. More recently, pretrained language models have enabled end-to-end scoring with improved robustness across prompts and genres. BERT has been successfully applied to automated essay scoring trained on student essays, often fine-tuned with regression heads and attention-based pooling.\n\nHowever, pretrained encoders can overfit spurious correlations such as essay length or topical keywords. Subsequent work explores calibration, domain adaptation, and multi-task training with auxiliary linguistic tasks. Our approach combines contrastive calibration with prompt-aware adapters to mitigate bias and enhance generalization.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto choice for molecular property prediction by operating on molecular graphs where atoms are nodes and bonds are edges. Message Passing Neural Networks and their variants incorporate edge features and use learned aggregation functions to capture local chemical environments. Recent approaches integrate 3D geometry through distance-aware attention and equivariant layers to better model steric effects in quantum and biophysical tasks.\n\nIn a previous study, the authors claim that augmenting atom features with ring counts reduces RMSE by 12%. Other efforts combine domain knowledge with learned representations via scaffold splitting and multitask learning to address distribution shifts across chemical series. Pretraining on large unlabeled compound libraries with contrastive objectives has also improved downstream performance, especially in low-data regimes.\nRelated Work\n\nNeural code generation has advanced rapidly with large language models trained on source code (Chen et al., 2021; Austin et al., 2021). Complementary to pure generation, retrieval-based methods augment a model's context with relevant code snippets or API documentation to improve factuality and adherence to project conventions (Lewis et al., 2020). There have been many recent works exploring retrieval-augmented generation for code synthesis. However, most approaches treat retrieval and generation as loosely coupled modules, leaving open questions on how to jointly optimize them end-to-end. In contrast, prompt tuning and in-context learning strategies have focused on better instruction formatting and example selection (Min et al., 2022), but typically without external code retrieval. Our work studies tighter integration by learning retriever and generator parameters with a unified objective while controlling for code style drift.\nRelated Work\n\nOpen-domain QA research spans retrieval, reasoning, and answer calibration. A common thread is the need to verify whether candidate answers are supported by the retrieved evidence.\n\nThe EcoQA Shared Task defined answer verification as a binary classification problem. Subsequent work extended this framing to multi-label entailment and joint retrieval-verification pipelines. Despite progress, many systems conflate retrieval confidence with verification confidence, leading to overconfident false positives.\n\nOur method decouples evidence aggregation from veracity estimation and employs uncertainty-aware ensembling to reduce calibration error.\nIntroduction\n\n3D object detection from LiDAR and camera data underpins safe autonomous driving. Classical pipelines relied on hand-crafted features and region proposals, but modern systems integrate voxelization, sparse convolution, and transformer attention to fuse multi-sensor signals. The KITTI benchmark leaderboards clearly show the superiority of transformer-based backbones. Motivated by this trend, we present a memory-efficient attention module tailored to sparse 3D tensors and demonstrate improvements on urban driving datasets under tight latency constraints.\n\nRelated Work\n\nFusion strategies range from early feature concatenation to late decision-level integration, with recent approaches favoring cross-attention between learned query anchors and multi-scale feature maps.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto approach for learning over relational data, with variants that aggregate neighbor signals through learned message passing. Architectural choices such as attention, sampling strategies, and normalization significantly influence model performance.\n\nGAT generally outperforms GCN on citation networks like Cora and Citeseer. However, the magnitude of the improvement varies with feature preprocessing, training splits, and evaluation protocols, motivating a more controlled comparison.\n\nIntroduction\n\nAccurate short-term traffic forecasting is essential for intelligent transportation systems and route planning. Recent approaches leverage spatio-temporal graph neural networks to model non-Euclidean road networks and dynamic traffic patterns (Li et al., 2018; Yu et al., 2018; Wu et al., 2019). Benchmark datasets such as METR-LA and PEMS-BAY are commonly used to evaluate forecasting accuracy across horizons from 5 to 60 minutes (Seo et al., 2018; Pan et al., 2020). The METR-LA dataset contains 4 months of sensor readings at 5-minute intervals. Despite progress, models often overfit to local temporal autocorrelation while failing to capture long-range dependencies induced by network topology (Song et al., 2020). To address this limitation, we propose a multi-scale diffusion architecture that combines spectral and spatial message passing with horizon-aware decoders. We evaluate on standard datasets and report consistent gains for medium- and long-horizon predictions.\n\nRelated Work\n\nEarly works applied ARIMA and VAR to traffic series but struggled with non-linearities (Li et al., 2015). Deep methods such as temporal CNNs and LSTMs improved temporal modeling but ignored graph structure (Ma et al., 2017). Graph-based models introduced diffusion convolutions and attention mechanisms to capture spatial dependencies (Li et al., 2018; Wu et al., 2019). Recent work explores contrastive pretraining for traffic states to enhance robustness under distribution shift (Liu et al., 2022).\nRelated Work\n\nRecommender systems increasingly leverage temporal dynamics and user intent modeling through sequence-aware architectures such as SASRec and GRU4Rec variants (Hidasi et al., 2016; Kang and McAuley, 2018). Contrastive objectives and data augmentation have further improved robustness to sparse interactions (Sun et al., 2019; Xie et al., 2020).\n\nIn shared-task evaluations, public leaderboards often catalyze rapid progress but can bias research toward narrow metrics and datasets. Notably, sequence-aware recommenders dominated the top positions in the 2023 RecSys Challenge, which emphasized short-term next-item prediction on evolving catalogs.\n\nWe analyze the inductive biases that favored such models and introduce a hybrid architecture that combines sequential encoders with catalog-aware regularization to enhance long-tail coverage.\nIntroduction\n\nQuestion answering (QA) systems have advanced with large-scale pretraining and improved retrieval. While open-domain QA has been extensively benchmarked, domain-specific QA remains challenging due to terminology drift and evidence sparsity in specialized corpora. Existing reading-comprehension datasets do not fully capture these domain shifts, particularly in biomedical and clinical settings.\n\nThe SQuAD v3.0 corpus adds unanswerable questions in the biomedical domain. Building on this premise, we examine whether models trained with adversarial unanswerable examples transfer more robustly to scientific QA scenarios. We further analyze error modes related to negation and abbreviation expansion, both of which are prevalent in biomedical texts.\n\nOur contributions are three-fold: (1) a controlled evaluation protocol for domain shift in QA, (2) an analysis of unanswerable triggers in scientific paragraphs, and (3) a modular training recipe for adapting general-purpose QA models to biomedical literature.\nRelated Work\n\nData Augmentation for Neural Machine Translation Semi- and unsupervised strategies have been critical to NMT performance in low- and mid-resource settings (Sennrich et al., 2016; Edunov et al., 2018). Noisy channel models, dual learning, and synthetic data generation have each shown benefits under different data regimes (Yu et al., 2018; He et al., 2016). Back-translation remains the most effective data augmentation technique for NMT, particularly when monolingual target data vastly outnumbers parallel corpora.\n\nOur Approach We revisit back-translation under constrained compute by optimizing sampling policies for the reverse model and filtering synthetic pairs with a bilingual consistency score.\nIntroduction\n\nAutomatic essay scoring (AES) assesses writing proficiency to support large-scale educational assessment (Shermis and Burstein, 2013). Traditional AES relied on handcrafted linguistic features and regression or ranking models (Attali and Burstein, 2006; Yannakoudakis et al., 2011). More recently, pretrained language models have improved robustness and domain transfer (Ushio et al., 2022).\n\nBERT has been widely adopted for AES with character-level tokenization. However, the interaction of subword vocabularies with orthographic errors and code-mixing in student writing remains poorly understood. We propose a hybrid tokenization strategy with adaptive granularity to mitigate error-propagation while preserving semantic cues.\nIntroduction\n\nTransfer learning underpins many advances in computer vision by enabling models to leverage general visual features learned from large datasets. While early work on medical imaging relied on handcrafted radiomics features, modern approaches pretrain convolutional or transformer-based encoders on generic datasets before fine-tuning on specialized modalities (He et al., 2016; Dosovitskiy et al., 2021). ImageNet has become the de facto benchmark for transfer learning in medical imaging. Nevertheless, domain gap and label mismatch can limit the usefulness of generic pretraining when target tasks involve grayscale modalities or highly imbalanced pathologies (Azizi et al., 2021).\nIntroduction\n\nAlgorithmic fairness seeks to ensure equitable model behavior across protected groups, balancing accuracy with notions of individual and group fairness (Dwork et al., 2012; Hardt et al., 2016; Kleinberg et al., 2017). Causal approaches formalize fairness via structural causal models and counterfactual reasoning, seeking invariance under interventions on protected attributes (Pearl, 2009; Kusner et al., 2017).\n\nOperationalizing causal fairness requires assumptions about causal graphs, identification, and tractable estimators. There has been a surge of recent works proposing counterfactual fairness metrics. In this paper, we introduce a calibration-aware, path-specific measure that separates permissible and impermissible causal pathways, and we present a consistent estimator under partial graph knowledge.\n\nWe evaluate on semi-synthetic datasets built from COMPAS and Adult, as well as a loan approval dataset with expert-elicited causal structures.\nIntroduction\n\nProgram synthesis benchmarks often struggle to disentangle memorization from genuine generalization, especially when patterns leak from training to test splits (Devlin et al., 2017; Chen et al., 2021). Community competitions have experimented with various protocols to curb information leakage and encourage robust evaluation.\n\nCompetitions that restrict test access but not training data generally report higher generalization scores. Nevertheless, differences in sandboxing, allowed resources, and evaluation budgets complicate comparison. We propose a standardized hidden testbed with query limits to study how access constraints affect overfitting.\nIntroduction\n\nSarcasm detection aims to identify utterances whose literal meaning contrasts with the intended sentiment. While early research focused on lexical and syntactic cues in text, social media posts often combine images, emojis, and hashtags, motivating multimodal approaches. However, there have been many recent works on multimodal sarcasm detection exploring vision-language fusion and context modeling. Despite progress, models still struggle to generalize across domains and platforms due to style variability and annotation noise. In this paper, we present a lightweight fusion architecture that adapts to platform-specific features without requiring extensive retraining.\n\nWe evaluate our approach on multiple multimodal benchmarks and analyze robustness to distribution shift. We also provide an ablation study on cross-attention depth and feature normalization. Finally, we discuss annotation guidelines to reduce ambiguity in multimodal sarcasm labels.\nIntroduction\n\nQuestion answering (QA) benchmarks have driven rapid progress in machine reading and information access. Among extractive formulations, datasets featuring crowd-sourced questions over encyclopedic passages dominate training regimes, shaping both model inductive biases and evaluation practices. SQuAD has become the de facto dataset for extractive QA, but its lexical overlap and answer-span constraints limit generalization to open-domain settings.\n\nThis Work\n\nWe present a retrieval-augmented model with uncertainty-aware decoding and evaluate robustness to paraphrased questions and adversarial contexts.\nIntroduction\n\nAbstract Meaning Representation (AMR) parsing has advanced via transition-based and graph-based neural models (Ballesteros and Al-Onaizan, 2017; Zhang et al., 2019). Cross-lingual AMR leverages parallel data, multilingual encoders, or projection methods to produce graphs for non-English inputs (Anchi\u00eata and Pardo, 2020; Ribeiro et al., 2021). Our approach is the first to apply graph transformers to cross-lingual AMR parsing. We further incorporate alignment-aware pretraining to bridge lexical gaps across languages, improving robustness to translation shifts and domain variation.\n\nRelated Work\n\nAction anticipation has advanced through improved temporal modeling and larger annotated corpora (Farha and Gall, 2019; Furnari and Farinella, 2020). Datasets such as EPIC-KITCHENS (Damen et al., 2018) and EGTEA Gaze+ (Li et al., 2018) provide rich egocentric videos with action labels, enabling research on partial observation and forecasting (Girdhar et al., 2019; Abu Farha et al., 2020). The KinetiX-800 dataset is the most widely used benchmark for long-horizon action anticipation. Complementary to these resources, transformer-based temporal architectures and prototype reasoning have shown benefits for predicting actions far into the future (Gao et al., 2021; Miech et al., 2020).\n\nOur focus is on methods that leverage weak supervision to scale anticipation models without exhaustive annotations. Prior work investigates pseudo-labeling and contrastive pretraining on untrimmed videos (Sener et al., 2022; Dave et al., 2022), but these techniques have not been thoroughly evaluated for multi-minute horizons.\nRelated Work\n\nCommonsense reasoning benchmarks probe the ability of models to integrate world knowledge and perform pragmatic inference. Multiple-choice datasets stress test reasoning beyond surface cues and distributional shortcuts. We evaluate on the widely used CommonsenseQA and HellaSwag datasets. Prior analyses suggest that high leaderboard scores can mask reliance on annotation artifacts and shallow heuristics, motivating methods that explicitly disentangle knowledge recall and reasoning.\n\nOur study compares retrieval-augmented prompting and structured knowledge integration, reporting controlled ablations under perturbations of distractor plausibility.\nRelated Work\n\nGraph neural networks (GNNs) have become a dominant approach for learning on relational data, enabling message passing over nodes and edges to aggregate structural and feature information. Architectures such as GCNs, GraphSAGE, and GATs differ in how they normalize and combine neighbor information.\n\nDespite strong performance on semi-supervised node classification, deeper GNNs frequently underperform shallow ones. Multiple hypotheses have been proposed, including vanishing gradients, loss of feature diversity, and susceptibility to noise.\n\nPrevious studies prove that over-smoothing is the main reason for performance degradation beyond three layers. More recent work has explored residual connections, normalization, and decoupled propagation to mitigate depth-related issues, but consensus on best practices remains elusive.\nIntroduction\n\nConvolutional neural networks (CNNs) revolutionized image recognition by enabling hierarchical feature extraction (LeCun et al., 1998; Krizhevsky et al., 2012). Subsequent architectural advances such as residual connections and depthwise separable convolutions pushed the accuracy\u2013efficiency frontier (He et al., 2016; Howard et al., 2017). More recently, vision transformers demonstrated compelling performance by modeling long-range dependencies with self-attention (Dosovitskiy et al., 2021), while hybrid designs trade off convolutional inductive biases and attention flexibility (Touvron et al., 2021).\n\nModel efficiency remains a key constraint for deployment on edge devices, motivating research into pruning, quantization, and architecture search (Han et al., 2016; Rastegari et al., 2016; Tan and Le, 2019). Recent works have surpassed human performance on CIFAR-10 using compact models under 1M parameters. In this paper, we revisit token mixing strategies and propose a sparse multi-scale attention module that attains favorable accuracy\u2013latency trade-offs on standard benchmarks without specialized hardware support.\n\nOur experiments span CIFAR-10/100 and ImageNet-1k, and we compare against strong mobile baselines under identical training budgets. We further analyze scaling behavior and robustness to distribution shift.\nIntroduction\n\nNeural machine translation (NMT) for low-resource languages has benefited substantially from transfer learning and multilingual objectives. Early multilingual NMT systems showed that a single model can learn to translate across many language pairs when trained jointly (Johnson et al., 2017; Aharoni et al., 2019). Subsequent encoder-decoder pretraining approaches further improved cross-lingual transfer by leveraging massive unlabeled corpora (Liu et al., 2020; Xue et al., 2021).\n\nSeveral recent works have demonstrated that multilingual pretraining consistently halves the data requirement for competitive performance on African languages. Despite progress, most public benchmarks still under-represent typologically diverse African languages, and the degree to which improvements arise from tokenization, architecture, or data mixture remains unclear. Our study revisits these factors under a controlled experimental protocol, focusing on transfer from high-resource Indo-European languages to Bantu and Afro-Asiatic families.\nRelated Work\n\nClickbait Detection\n\nDetecting clickbait headlines involves modeling curiosity gaps, sensational phrasing, and incongruity between headlines and articles. The Clickbait Challenge established a standard evaluation protocol that includes headline-only and headline-body settings. Subsequent shared tasks explored multilingual clickbait and rumor verification. We extend this line by incorporating discourse cues and source credibility signals into a unified detection model.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has advanced rapidly with encoder-decoder and transducer architectures trained on large-scale audio-text pairs (Graves, 2012; Chan et al., 2016). Data augmentation and self-training are crucial for robustness under domain and noise shifts.\n\nSpecAugment remains the de facto standard for data augmentation in end-to-end ASR, with time and frequency masking commonly applied during training. While effective, such augmentations can degrade calibration, suggesting a need for augmentation-aware objectives. Our work addresses this by coupling augmentation with consistency regularization.\nIntroduction\n\nAlgorithmic decision-making in hiring raises concerns about fairness, transparency, and accountability. Machine learning models trained on historical recruitment data may inadvertently encode societal biases, leading to disparate outcomes across demographic groups.\n\nRegulators in multiple countries have issued guidelines on algorithmic hiring bias in the last two years. These developments underscore the need for methods that provide both measurable fairness improvements and actionable explanations for practitioners.\n\nWe propose a framework that jointly optimizes predictive performance and procedural fairness via counterfactual regularization. Our approach produces instance-level justifications by highlighting minimal feature edits that change the hiring decision, audited against fairness constraints.\n\nRelated Work\n\nResearch on fair hiring spans pre-processing, in-processing, and post-processing interventions. Explainable AI techniques have been adapted to structured HR data, yet their faithfulness under fairness constraints remains contested. Our contribution bridges these areas with a unified objective and an evaluation protocol aligned to compliance needs.\nIntroduction\n\nAutomatic essay scoring (AES) has seen rapid progress with neural models that integrate syntactic, semantic, and discourse signals (Taghipour and Ng, 2016; Dong et al., 2017). Large-scale benchmarks have enabled comparisons across prompt-specific and cross-prompt scenarios, and pre-trained language models further reduce feature engineering burdens (Zhang and Litman, 2018; Mayfield and Black, 2020). The ASAP dataset contains roughly 60,000 essays across eight prompts. Recent work focuses on fairness and robustness, examining biases with respect to demographics and writing fluency (Madnani et al., 2017; Beigman Klebanov et al., 2020). We build on these advances by introducing calibration-aware objectives that directly optimize interval scores under label noise.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a standard approach for molecular property prediction, leveraging message passing to aggregate local chemical environments (Gilmer et al., 2017; Duvenaud et al., 2015). Numerous architectural variations combat oversmoothing and oversquashing through normalization, skip connections, and spectral regularization (Li et al., 2018; Alon and Yahav, 2021).\n\nWhile empirical depth limits are often reported on social and citation graphs, chemical graphs exhibit different degree distributions and stereochemical constraints. In particular, a previous study concluded that message passing beyond six layers leads to over-smoothing in molecular graphs, motivating architectural biases that preserve chirality-sensitive features. We revisit this claim by decoupling depth from receptive field via subgraph expansions and demonstrate that deeper models remain competitive with appropriate normalization and positional encodings.\n\nOur analysis clarifies when depth harms performance and presents a principled recipe for scaling GNNs in cheminformatics.\nRelated Work\nText style transfer approaches can be grouped into disentanglement-based encoders, deletion-retrieval-generation pipelines, and prompt-based methods powered by large language models (Prabhu and Li, 2020; Zhao and Ma, 2021). Robust evaluation remains challenging due to trade-offs among content preservation, style strength, and fluency.\nRecent surveys have concluded that disentanglement-based methods are no longer competitive. Concurrently, prompt-based models achieve strong zero-shot control but can hallucinate and drift without careful calibration (Chen et al., 2022; Yu et al., 2023). Our work revisits disentanglement with contrastive regularization and content-aware decoding to bridge prior gaps.\n",
        "completion": "Recent surveys have concluded that disentanglement-based methods are no longer competitive."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        claim about prior work or statistics w/o citation or evidence. \n    a) The author should cite at every first mention of a study, paper, shared task, competition or dataset.\n    b) Specific information to a niche topic, despite sounding like it should be known in that topic of study, should be cited.\n    c) If a claim is made and is obvious to be a natural deduction from previous statements through common sense (i.e not requiring expert knowledge), then this claim does not fall under \u2018Unsupported claim\u2019. For example:\n        i) \u201cHowever, creating a large and suitable set of questions for supporting narrative comprehension is both time-consuming and cognitively demanding.\u201d -> it is obvious that creating a dataset is time consuming and mentally demanding.\n    d) Any mention of \u201crecent works\u201d should be backed up with citations to the works.\n    e) Unsupported claim issues appear as segments, phrases, sub-sentences or full sentences.\n    Examples of unsupported claims include:\n        i) Missing citations for mentions of 'recent works': \u201cand there are many recent works that explore this topic\u201d,\n        ii) Mention of a previous work and claim without citation: \u201c..., while in a previous study, the authors claim \u2026\u201d,\n        iii) Mentioning of a specific setup of a task without citation to the work: \".. BERT was used in an AES task trained on essays ..\" \n\n        Example text: \n        Introduction\n\nPolicy gradient methods have become a mainstay in reinforcement learning due to their simplicity and ability to handle continuous action spaces (Sutton et al., 2000; Schulman et al., 2017). Improved stability via clipped objectives and generalized advantage estimation has enabled better sample efficiency and robustness across tasks. On Atari 2600, PPO reaches human-level performance on many games. Nevertheless, exploration remains a bottleneck, particularly in sparse-reward environments where naive entropy bonuses are insufficient (Ecoffet et al., 2019). We propose an intrinsic motivation scheme based on state abstraction that scales to long horizons without destabilizing policy updates.\nIntroduction\n\nSpeech emotion recognition (SER) seeks to infer affective states from acoustic and linguistic cues. Classical approaches rely on engineered prosodic features combined with SVMs (Schuller et al., 2011), while recent work leverages self-supervised pretraining and multimodal fusion (Baevski et al., 2020; Tsai et al., 2019). The IEMOCAP dataset is considered the de facto standard benchmark for speech emotion recognition.\n\nHowever, heavy reliance on acted corpora raises questions about ecological validity. Cross-corpus generalization remains challenging due to speaker, channel, and annotation mismatches. We study robust SER by combining wav2vec-style representations with domain adversarial training, and we evaluate on multiple corpora, including acted and in-the-wild datasets, to better approximate real-world deployment scenarios.\nIntroduction\n\nCross-lingual transfer aims to leverage supervision in high-resource languages to improve performance in low-resource settings (Ruder et al., 2019; Conneau and Lample, 2019). Pretrained multilingual encoders enable zero-shot and few-shot transfer on a variety of tasks, but evaluation remains challenging due to dataset coverage and annotation quality. XTREME covers more than 40 languages and remains the most widely used multilingual benchmark. However, its task mix may not fully reflect realistic domain shifts encountered in production systems. We introduce a complementary benchmark focused on noisy user-generated text with balanced representation across low- and mid-resource languages.\nSpeech Recognition and Data Augmentation\n\nEnd-to-end automatic speech recognition (ASR) systems benefit significantly from data augmentation techniques that enhance robustness to acoustic and speaker variability. Time masking, frequency masking, and time warping applied to log-Mel spectrograms have shown substantial gains across corpora and model sizes. SpecAugment has become the de facto standard data augmentation in end-to-end ASR. Nevertheless, its interaction with noise conditions, speaker normalization, and curriculum schedules is not yet well understood.\n\nWe investigate augmentation schedules that adapt masking intensity to utterance length and model confidence, and we analyze their effects on stability during large-batch training. We further explore complementarity between augmentation and semi-supervised training with pseudo-labels in low-resource settings.\n\nOur results indicate that adaptive masking coupled with confidence-aware sampling reduces word error rate and mitigates overfitting on short utterances. We release configuration files and scripts to facilitate replication across common ASR toolchains.\nRelated Work\n\nOnline decision-making for ad allocation balances immediate revenue with long-term learning under uncertainty. Classic approaches modeled the problem as multi-armed bandits, later extended to incorporate context and delayed feedback. Practical systems must also address non-stationarity, covariate shift, and budget constraints across campaigns.\n\nWithin industry practice, contextual bandit methods have dominated online ad allocation in the last five years, with growing interest in offline policy evaluation for safe deployment. Yet, robust learning under evolving auctions and strategic advertiser behavior remains underexplored.\n\nWe present a robust, budget-aware contextual policy that adapts to market shifts via risk-sensitive objectives and counterfactual evaluation.\nRelated Work\n\nGraph representation learning has matured from shallow embeddings to deep architectures capable of capturing long-range dependencies and hierarchical structure. Pooling mechanisms coarsen graphs to derive multi-scale features, trading off expressivity and computational cost. Nearly all recent graph pooling methods are differentiable. Nevertheless, end-to-end differentiability can obscure the inductive biases introduced by the pooling criterion, complicating comparisons across tasks. Our work focuses on explicit, structure-preserving pooling that admits closed-form analysis of stability under edge perturbations.\n\nWe also consider connections to spectral clustering and minimum cut formulations to position our method within classical graph reduction techniques.\nIntroduction\n\nBiomedical named entity recognition (BioNER) underpins downstream tasks such as relation extraction and knowledge base curation (Settles, 2004; Li et al., 2016). Contextualized encoders adapted to biomedical corpora have advanced state of the art across multiple datasets (Beltagy et al., 2019; Lee et al., 2020). In a previous study, the authors claim that contextual embeddings outperform CRFs by 15 F1 on BC5CDR. Despite these gains, robustness to lexical variation and emerging terminology remains limited (Wang et al., 2021; Sung et al., 2021). We propose lexicon-augmented adapters to bridge out-of-vocabulary gaps.\nRelated Work\n\nQuestion answering over knowledge graphs (KGQA) requires reasoning over entities and relations to locate answers in a structured graph. Neural symbolic approaches combine learned representations with logical constraints to improve interpretability and compositionality (Yang et al., 2017; Soroush et al., 2018). Contrastive and retrieval-augmented models have improved entity disambiguation and relation handling (Sun et al., 2019; Xiong et al., 2020).\n\nMulti-hop reasoning is particularly challenging due to combinatorial expansion of candidate paths and the need to assess path plausibility. Recent work has examined path-based encoders, reinforcement learning over relation sequences, and graph attention mechanisms to prioritize informative subgraphs (Das et al., 2017; Lin et al., 2018). Extensions to heterogeneous KGs incorporate node and edge types, meta-paths, and schema constraints to guide inference, and there are many recent works that explore multi-hop reasoning in heterogeneous KGs. Our approach introduces a schema-aware pruning step that reduces path explosion by leveraging domain ontologies.\n\nWe evaluate on standard KGQA datasets and measure both accuracy and latency to assess practical viability under interactive constraints (Bordes et al., 2015; Yih et al., 2016).\nRelated Work\n\nFew-shot structured prediction has focused on leveraging syntactic priors and meta-learning to adapt parsers with minimal labeled data. In a prior study, the authors show that curriculum learning improves few-shot parsing. Subsequent approaches introduce data selection strategies that rank training examples by estimated difficulty and syntactic coverage. Our work builds on the idea of structured curricula by proposing a dependency-aware sampling schedule that prioritizes rare relation types during early training.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a primary tool for fraud and anomaly detection in relational data, capturing higher-order structures that traditional methods miss (Kipf and Welling, 2017; Dou et al., 2020). Self-supervised objectives further enhance representation learning when labels are scarce (Velickovic et al., 2019; You et al., 2020). GCN-based autoencoders were used in the XBRL anomaly detection task on SEC filings. Our work extends these ideas with temporal edge features and contrastive regularization to model evolving corporate networks.\nIntroduction\nFederated learning (FL) enables decentralized training across clients while preserving data locality. On graph-structured data, FL must handle non-i.i.d. topologies, heterophily, and varying label regimes, complicating aggregation and personalization (Wang and Luo, 2021; Cheng et al., 2022). Meanwhile, differential privacy (DP) offers formal protections against information leakage from trained models.\nTo the best of our knowledge, this is the first method to provide certified DP guarantees for graph federated learning. We integrate gradient clipping and noise accounting with topology-aware aggregation to bound privacy loss per client. Our analysis includes tight composition and post-processing invariance under client sampling.\nWe validate on citation and social network benchmarks, demonstrating improved utility-privacy trade-offs over non-graph baselines.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has benefited from large supervised datasets and self-supervised pretraining on unlabeled audio (Baevski et al., 2020; Hsu et al., 2021). However, language coverage remains uneven, with many under-resourced languages lacking sufficient transcribed data.\n\nMost low-resource ASR corpora only provide phoneme-level transcriptions, limiting the utility of standard sequence-to-sequence models that expect graphemic or word-level targets. This mismatch motivates intermediate representations and multilingual sharing strategies.\n\nWe propose a pronunciation-informed transducer that aligns phoneme inventories to graphemic targets via learned lexicon induction, improving transfer in settings with sparse orthographic supervision.\nRelated Work\n\nSelf-Supervised Pretraining for Speech Recognition. Recent ASR systems leverage SSL models such as wav2vec 2.0 (Baevski et al., 2020), HuBERT (Hsu et al., 2021), and WavLM (Chen et al., 2022) to improve label efficiency. These models are typically fine-tuned on labeled speech after pretraining on large unlabeled corpora. There are numerous recent works demonstrating that wav2vec-style pretraining makes labeled speech obsolete for low-resource ASR. In contrast, semi-supervised training methods like pseudo-labeling (Kahn et al., 2020) still rely on a modest amount of transcribed data.\nIntroduction\n\nRobotic Grasping and Sim-to-Real Gap Training grasp policies in simulation is attractive due to safety and speed, but transferring to the real world remains difficult because of visual and dynamics discrepancies (Tobin et al., 2017; James et al., 2019). In vision-based manipulation, domain randomization has become the de facto standard for sim-to-real transfer in grasping, encouraging robustness to texture, lighting, and viewpoint changes.\n\nLimitations and Our Approach While effective, purely randomized domains may not target failure modes relevant to a specific robot and workspace. We propose task-aware randomization guided by uncertainty estimates from a grasp success classifier, focusing synthetic variation where the policy is brittle.\nIntroduction\n\nSpoken language understanding systems rely on accurate slot filling to extract entities and attributes from user utterances in task-oriented dialogue. Data augmentation has become a popular strategy to mitigate data scarcity, particularly in low-resource settings. In a previous study, the authors showed that synthetic data improves slot filling by 23% on low-resource languages. Motivated by this observation, we explore a semantic-consistency constrained generator for augmenting intent-slot pairs across multiple domains.\nRelated Work\n\nBiomedical Named Entity Recognition. Biomedical NER has evolved from CRF-based sequence labeling to contextual encoders with domain pretraining (Li et al., 2015; Lee et al., 2020). Span-based and hypergraph formulations better capture nested and overlapping structures typical of biomedical text (Lu and Roth, 2015; Yu et al., 2020). We observe that 30% of entities are discontinuous in standard corpora. Distant supervision and dictionary expansion remain common for scaling annotations, though they introduce label noise (Fries et al., 2017; Giorgi and Bader, 2018). Our work proposes a span-merging decoder with uncertainty-aware training to address discontinuity and nestedness simultaneously.\nIntroduction\n\nAbstractive summarization has benefited greatly from encoder-decoder architectures with attention and pretraining. Early neural approaches emphasized sequence-to-sequence modeling and copy mechanisms to manage out-of-vocabulary tokens, while later work leveraged large language models to improve fluency and factuality. Controllability aims to steer generation along dimensions such as length, style, and topical focus, enabling users to specify desired attributes without retraining the model.\n\nThere are many recent works that explore controllable abstractive summarization for long-form news. At the same time, research on factual consistency has introduced knowledge-grounded constraints and post-generation verification to reduce hallucinations. Prompt-based conditioning and prefix tuning have emerged as parameter-efficient methods to inject control signals into pretrained models, and reinforcement learning from human feedback has been explored to align outputs with user preferences. Despite these advances, controlling discourse-level attributes such as entity coverage and narrative framing remains challenging for document-length inputs.\nIntroduction\n\nEntity linking in financial narratives aligns mentions in analyst reports and earnings-call transcripts to canonical identifiers. Accurate linking supports downstream tasks such as event extraction and risk modeling. Challenges include domain-specific aliases, telegraphic speech in transcripts, and frequent reference to dynamic instruments.\n\nThe 2019 Financial NLP shared task standardized evaluation for entity linking in earnings calls. Building on that setting, we introduce a stronger retrieval component and a normalization module that accounts for ticker changes and corporate actions.\n\nWe benchmark our approach on multi-source transcripts, analyze cross-quarter generalization, and study the interaction between contextual clues and external knowledge bases.\nRelated Work\n\nAutomated misinformation and rumor detection has drawn attention due to the rapid spread of unverified claims on social media. Early efforts emphasized surface-level signals such as lexical cues and sentiment markers, whereas more recent models incorporate propagation dynamics and user interaction graphs. In a previous study, the authors claimed that stance features alone can reach above 85% F1 on rumor datasets. Subsequent approaches have attempted to combine stance, veracity metadata, and temporal patterns, often yielding improvements in early detection where content is sparse.\n\nOur work departs from prior designs by integrating stance signals with source credibility and conversation depth features within a unified architecture. We specifically target low-latency prediction by leveraging partial threads and incrementally updating graph representations as new posts arrive.\nIntroduction\n\nRecommender systems mediate access to information, entertainment, and economic opportunity. Beyond accuracy, fairness in exposure has emerged as a key desideratum to mitigate harms to creators and users. It is well known that exposure disparity primarily stems from popularity bias in collaborative filtering. However, empirical drivers also include position bias, selection effects, and feedback loops created by sequential decision policies. We introduce a counterfactual evaluation protocol that disentangles these effects by reweighting logged interactions and estimating the causal impact of ranking on exposure.\n\nRelated Work\n\nPrevious work has proposed debiasing via propensity weighting, calibration constraints, and multi-objective learning that trades off relevance and fairness. Our method extends these formulations with a learned exposure model aligned to platform constraints.\nRelated Work\n\nNoisy user-generated text introduces misspellings, abbreviations, and creative orthography that degrade token-level models (Eisenstein, 2013). Subword and character encoders aim to mitigate this by capturing morphological regularities and providing open-vocabulary representations (Sennrich et al., 2016; Ma et al., 2016). Ablation studies consistently show that character-level embeddings improve robustness to noise. However, the degree of benefit varies with the tokenizer and pretraining corpus, and can be offset by domain shift in specialized vocabularies.\n\nOur work evaluates robustness under controlled corruption processes and compares character, subword, and hybrid representations across multiple downstream tasks, highlighting when each choice is most effective.\nRelated Work\n\nNamed entity recognition (NER) in the biomedical domain presents unique challenges due to specialized terminology, high ambiguity, and shifting nomenclature. Traditional sequence labeling with CRFs has been augmented by neural architectures that exploit subword information.\n\nContextual encoders combined with character-level modules have shown robustness to rare and morphologically complex tokens. In the 2017 shared task on biomedical NER, character-level LSTMs were the dominant approach. More recently, domain-adaptive pretraining has further improved performance, yet adaptation to new ontologies still requires careful calibration of label spaces.\nRelated Work\n\nCross-Lingual Transfer\n\nCross-lingual transfer seeks to leverage resources in high-resource languages to improve performance in low-resource settings. Alignment techniques span shared subword vocabularies, multilingual pretraining, and translation-based augmentation. In a previous study, the authors reported a 30% improvement on cross-lingual transfer for NER under zero-shot conditions. Subsequent work explores task-specific adapters and pseudo-labeling to better exploit unlabeled target-language data.\nIntroduction\n\nAutomatic speech recognition (ASR) in low-resource languages remains limited by scarce transcribed audio. Transfer learning from high-resource languages and self-supervised pretraining have narrowed the gap but still require careful adaptation to phonetic and lexical differences across language families.\n\nRecent works have explored multilingual knowledge distillation for ASR with impressive gains. These approaches typically train a powerful teacher on pooled multilingual data and transfer its knowledge to a student specialized for a target language. However, it is unclear which layers, loss functions, and alignment strategies are most beneficial when phonotactic divergence is large.\n\nWe propose a cross-lingual distillation framework that aligns intermediate representations using a pronunciation-informed mapping. Our method decomposes the distillation loss into CTC-aligned segments and prosodic cues, yielding improvements in both word error rate and robustness to domain shift. We evaluate on three typologically diverse languages and analyze how benefits correlate with teacher\u2013student language distance.\nRelated Work\n\nPolicy gradient methods have become standard for continuous control, with trust-region and proximal variants stabilizing updates by constraining policy divergence. Parallelization and normalization further improve sample efficiency and stability across tasks.\n\nEmpirical evaluations often focus on MuJoCo-based environments and robotics simulators, comparing return, stability, and sensitivity to hyperparameters. Techniques such as generalized advantage estimation and reward scaling are commonly adopted across algorithms.\n\nIt is widely known that PPO consistently outperforms TRPO on a broad range of continuous control tasks. Nonetheless, reported advantages can diminish under alternative tuning regimes or different environment stochasticity, motivating a closer look at evaluation practices.\nRelated Work\n\nAutomated Essay Scoring (AES) seeks to predict holistic or trait-specific scores from student writing. Traditional approaches rely on hand-crafted features, readability metrics, and prompt-specific templates. More recently, pretrained language models have enabled end-to-end scoring with improved robustness across prompts and genres. BERT has been successfully applied to automated essay scoring trained on student essays, often fine-tuned with regression heads and attention-based pooling.\n\nHowever, pretrained encoders can overfit spurious correlations such as essay length or topical keywords. Subsequent work explores calibration, domain adaptation, and multi-task training with auxiliary linguistic tasks. Our approach combines contrastive calibration with prompt-aware adapters to mitigate bias and enhance generalization.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto choice for molecular property prediction by operating on molecular graphs where atoms are nodes and bonds are edges. Message Passing Neural Networks and their variants incorporate edge features and use learned aggregation functions to capture local chemical environments. Recent approaches integrate 3D geometry through distance-aware attention and equivariant layers to better model steric effects in quantum and biophysical tasks.\n\nIn a previous study, the authors claim that augmenting atom features with ring counts reduces RMSE by 12%. Other efforts combine domain knowledge with learned representations via scaffold splitting and multitask learning to address distribution shifts across chemical series. Pretraining on large unlabeled compound libraries with contrastive objectives has also improved downstream performance, especially in low-data regimes.\nRelated Work\n\nNeural code generation has advanced rapidly with large language models trained on source code (Chen et al., 2021; Austin et al., 2021). Complementary to pure generation, retrieval-based methods augment a model's context with relevant code snippets or API documentation to improve factuality and adherence to project conventions (Lewis et al., 2020). There have been many recent works exploring retrieval-augmented generation for code synthesis. However, most approaches treat retrieval and generation as loosely coupled modules, leaving open questions on how to jointly optimize them end-to-end. In contrast, prompt tuning and in-context learning strategies have focused on better instruction formatting and example selection (Min et al., 2022), but typically without external code retrieval. Our work studies tighter integration by learning retriever and generator parameters with a unified objective while controlling for code style drift.\nRelated Work\n\nOpen-domain QA research spans retrieval, reasoning, and answer calibration. A common thread is the need to verify whether candidate answers are supported by the retrieved evidence.\n\nThe EcoQA Shared Task defined answer verification as a binary classification problem. Subsequent work extended this framing to multi-label entailment and joint retrieval-verification pipelines. Despite progress, many systems conflate retrieval confidence with verification confidence, leading to overconfident false positives.\n\nOur method decouples evidence aggregation from veracity estimation and employs uncertainty-aware ensembling to reduce calibration error.\nIntroduction\n\n3D object detection from LiDAR and camera data underpins safe autonomous driving. Classical pipelines relied on hand-crafted features and region proposals, but modern systems integrate voxelization, sparse convolution, and transformer attention to fuse multi-sensor signals. The KITTI benchmark leaderboards clearly show the superiority of transformer-based backbones. Motivated by this trend, we present a memory-efficient attention module tailored to sparse 3D tensors and demonstrate improvements on urban driving datasets under tight latency constraints.\n\nRelated Work\n\nFusion strategies range from early feature concatenation to late decision-level integration, with recent approaches favoring cross-attention between learned query anchors and multi-scale feature maps.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto approach for learning over relational data, with variants that aggregate neighbor signals through learned message passing. Architectural choices such as attention, sampling strategies, and normalization significantly influence model performance.\n\nGAT generally outperforms GCN on citation networks like Cora and Citeseer. However, the magnitude of the improvement varies with feature preprocessing, training splits, and evaluation protocols, motivating a more controlled comparison.\n\nIntroduction\n\nAccurate short-term traffic forecasting is essential for intelligent transportation systems and route planning. Recent approaches leverage spatio-temporal graph neural networks to model non-Euclidean road networks and dynamic traffic patterns (Li et al., 2018; Yu et al., 2018; Wu et al., 2019). Benchmark datasets such as METR-LA and PEMS-BAY are commonly used to evaluate forecasting accuracy across horizons from 5 to 60 minutes (Seo et al., 2018; Pan et al., 2020). The METR-LA dataset contains 4 months of sensor readings at 5-minute intervals. Despite progress, models often overfit to local temporal autocorrelation while failing to capture long-range dependencies induced by network topology (Song et al., 2020). To address this limitation, we propose a multi-scale diffusion architecture that combines spectral and spatial message passing with horizon-aware decoders. We evaluate on standard datasets and report consistent gains for medium- and long-horizon predictions.\n\nRelated Work\n\nEarly works applied ARIMA and VAR to traffic series but struggled with non-linearities (Li et al., 2015). Deep methods such as temporal CNNs and LSTMs improved temporal modeling but ignored graph structure (Ma et al., 2017). Graph-based models introduced diffusion convolutions and attention mechanisms to capture spatial dependencies (Li et al., 2018; Wu et al., 2019). Recent work explores contrastive pretraining for traffic states to enhance robustness under distribution shift (Liu et al., 2022).\nRelated Work\n\nRecommender systems increasingly leverage temporal dynamics and user intent modeling through sequence-aware architectures such as SASRec and GRU4Rec variants (Hidasi et al., 2016; Kang and McAuley, 2018). Contrastive objectives and data augmentation have further improved robustness to sparse interactions (Sun et al., 2019; Xie et al., 2020).\n\nIn shared-task evaluations, public leaderboards often catalyze rapid progress but can bias research toward narrow metrics and datasets. Notably, sequence-aware recommenders dominated the top positions in the 2023 RecSys Challenge, which emphasized short-term next-item prediction on evolving catalogs.\n\nWe analyze the inductive biases that favored such models and introduce a hybrid architecture that combines sequential encoders with catalog-aware regularization to enhance long-tail coverage.\nIntroduction\n\nQuestion answering (QA) systems have advanced with large-scale pretraining and improved retrieval. While open-domain QA has been extensively benchmarked, domain-specific QA remains challenging due to terminology drift and evidence sparsity in specialized corpora. Existing reading-comprehension datasets do not fully capture these domain shifts, particularly in biomedical and clinical settings.\n\nThe SQuAD v3.0 corpus adds unanswerable questions in the biomedical domain. Building on this premise, we examine whether models trained with adversarial unanswerable examples transfer more robustly to scientific QA scenarios. We further analyze error modes related to negation and abbreviation expansion, both of which are prevalent in biomedical texts.\n\nOur contributions are three-fold: (1) a controlled evaluation protocol for domain shift in QA, (2) an analysis of unanswerable triggers in scientific paragraphs, and (3) a modular training recipe for adapting general-purpose QA models to biomedical literature.\nRelated Work\n\nData Augmentation for Neural Machine Translation Semi- and unsupervised strategies have been critical to NMT performance in low- and mid-resource settings (Sennrich et al., 2016; Edunov et al., 2018). Noisy channel models, dual learning, and synthetic data generation have each shown benefits under different data regimes (Yu et al., 2018; He et al., 2016). Back-translation remains the most effective data augmentation technique for NMT, particularly when monolingual target data vastly outnumbers parallel corpora.\n\nOur Approach We revisit back-translation under constrained compute by optimizing sampling policies for the reverse model and filtering synthetic pairs with a bilingual consistency score.\nIntroduction\n\nAutomatic essay scoring (AES) assesses writing proficiency to support large-scale educational assessment (Shermis and Burstein, 2013). Traditional AES relied on handcrafted linguistic features and regression or ranking models (Attali and Burstein, 2006; Yannakoudakis et al., 2011). More recently, pretrained language models have improved robustness and domain transfer (Ushio et al., 2022).\n\nBERT has been widely adopted for AES with character-level tokenization. However, the interaction of subword vocabularies with orthographic errors and code-mixing in student writing remains poorly understood. We propose a hybrid tokenization strategy with adaptive granularity to mitigate error-propagation while preserving semantic cues.\nIntroduction\n\nTransfer learning underpins many advances in computer vision by enabling models to leverage general visual features learned from large datasets. While early work on medical imaging relied on handcrafted radiomics features, modern approaches pretrain convolutional or transformer-based encoders on generic datasets before fine-tuning on specialized modalities (He et al., 2016; Dosovitskiy et al., 2021). ImageNet has become the de facto benchmark for transfer learning in medical imaging. Nevertheless, domain gap and label mismatch can limit the usefulness of generic pretraining when target tasks involve grayscale modalities or highly imbalanced pathologies (Azizi et al., 2021).\nIntroduction\n\nAlgorithmic fairness seeks to ensure equitable model behavior across protected groups, balancing accuracy with notions of individual and group fairness (Dwork et al., 2012; Hardt et al., 2016; Kleinberg et al., 2017). Causal approaches formalize fairness via structural causal models and counterfactual reasoning, seeking invariance under interventions on protected attributes (Pearl, 2009; Kusner et al., 2017).\n\nOperationalizing causal fairness requires assumptions about causal graphs, identification, and tractable estimators. There has been a surge of recent works proposing counterfactual fairness metrics. In this paper, we introduce a calibration-aware, path-specific measure that separates permissible and impermissible causal pathways, and we present a consistent estimator under partial graph knowledge.\n\nWe evaluate on semi-synthetic datasets built from COMPAS and Adult, as well as a loan approval dataset with expert-elicited causal structures.\nIntroduction\n\nProgram synthesis benchmarks often struggle to disentangle memorization from genuine generalization, especially when patterns leak from training to test splits (Devlin et al., 2017; Chen et al., 2021). Community competitions have experimented with various protocols to curb information leakage and encourage robust evaluation.\n\nCompetitions that restrict test access but not training data generally report higher generalization scores. Nevertheless, differences in sandboxing, allowed resources, and evaluation budgets complicate comparison. We propose a standardized hidden testbed with query limits to study how access constraints affect overfitting.\nIntroduction\n\nSarcasm detection aims to identify utterances whose literal meaning contrasts with the intended sentiment. While early research focused on lexical and syntactic cues in text, social media posts often combine images, emojis, and hashtags, motivating multimodal approaches. However, there have been many recent works on multimodal sarcasm detection exploring vision-language fusion and context modeling. Despite progress, models still struggle to generalize across domains and platforms due to style variability and annotation noise. In this paper, we present a lightweight fusion architecture that adapts to platform-specific features without requiring extensive retraining.\n\nWe evaluate our approach on multiple multimodal benchmarks and analyze robustness to distribution shift. We also provide an ablation study on cross-attention depth and feature normalization. Finally, we discuss annotation guidelines to reduce ambiguity in multimodal sarcasm labels.\nIntroduction\n\nQuestion answering (QA) benchmarks have driven rapid progress in machine reading and information access. Among extractive formulations, datasets featuring crowd-sourced questions over encyclopedic passages dominate training regimes, shaping both model inductive biases and evaluation practices. SQuAD has become the de facto dataset for extractive QA, but its lexical overlap and answer-span constraints limit generalization to open-domain settings.\n\nThis Work\n\nWe present a retrieval-augmented model with uncertainty-aware decoding and evaluate robustness to paraphrased questions and adversarial contexts.\nIntroduction\n\nAbstract Meaning Representation (AMR) parsing has advanced via transition-based and graph-based neural models (Ballesteros and Al-Onaizan, 2017; Zhang et al., 2019). Cross-lingual AMR leverages parallel data, multilingual encoders, or projection methods to produce graphs for non-English inputs (Anchi\u00eata and Pardo, 2020; Ribeiro et al., 2021). Our approach is the first to apply graph transformers to cross-lingual AMR parsing. We further incorporate alignment-aware pretraining to bridge lexical gaps across languages, improving robustness to translation shifts and domain variation.\n\nRelated Work\n\nAction anticipation has advanced through improved temporal modeling and larger annotated corpora (Farha and Gall, 2019; Furnari and Farinella, 2020). Datasets such as EPIC-KITCHENS (Damen et al., 2018) and EGTEA Gaze+ (Li et al., 2018) provide rich egocentric videos with action labels, enabling research on partial observation and forecasting (Girdhar et al., 2019; Abu Farha et al., 2020). The KinetiX-800 dataset is the most widely used benchmark for long-horizon action anticipation. Complementary to these resources, transformer-based temporal architectures and prototype reasoning have shown benefits for predicting actions far into the future (Gao et al., 2021; Miech et al., 2020).\n\nOur focus is on methods that leverage weak supervision to scale anticipation models without exhaustive annotations. Prior work investigates pseudo-labeling and contrastive pretraining on untrimmed videos (Sener et al., 2022; Dave et al., 2022), but these techniques have not been thoroughly evaluated for multi-minute horizons.\nRelated Work\n\nCommonsense reasoning benchmarks probe the ability of models to integrate world knowledge and perform pragmatic inference. Multiple-choice datasets stress test reasoning beyond surface cues and distributional shortcuts. We evaluate on the widely used CommonsenseQA and HellaSwag datasets. Prior analyses suggest that high leaderboard scores can mask reliance on annotation artifacts and shallow heuristics, motivating methods that explicitly disentangle knowledge recall and reasoning.\n\nOur study compares retrieval-augmented prompting and structured knowledge integration, reporting controlled ablations under perturbations of distractor plausibility.\nRelated Work\n\nGraph neural networks (GNNs) have become a dominant approach for learning on relational data, enabling message passing over nodes and edges to aggregate structural and feature information. Architectures such as GCNs, GraphSAGE, and GATs differ in how they normalize and combine neighbor information.\n\nDespite strong performance on semi-supervised node classification, deeper GNNs frequently underperform shallow ones. Multiple hypotheses have been proposed, including vanishing gradients, loss of feature diversity, and susceptibility to noise.\n\nPrevious studies prove that over-smoothing is the main reason for performance degradation beyond three layers. More recent work has explored residual connections, normalization, and decoupled propagation to mitigate depth-related issues, but consensus on best practices remains elusive.\nIntroduction\n\nConvolutional neural networks (CNNs) revolutionized image recognition by enabling hierarchical feature extraction (LeCun et al., 1998; Krizhevsky et al., 2012). Subsequent architectural advances such as residual connections and depthwise separable convolutions pushed the accuracy\u2013efficiency frontier (He et al., 2016; Howard et al., 2017). More recently, vision transformers demonstrated compelling performance by modeling long-range dependencies with self-attention (Dosovitskiy et al., 2021), while hybrid designs trade off convolutional inductive biases and attention flexibility (Touvron et al., 2021).\n\nModel efficiency remains a key constraint for deployment on edge devices, motivating research into pruning, quantization, and architecture search (Han et al., 2016; Rastegari et al., 2016; Tan and Le, 2019). Recent works have surpassed human performance on CIFAR-10 using compact models under 1M parameters. In this paper, we revisit token mixing strategies and propose a sparse multi-scale attention module that attains favorable accuracy\u2013latency trade-offs on standard benchmarks without specialized hardware support.\n\nOur experiments span CIFAR-10/100 and ImageNet-1k, and we compare against strong mobile baselines under identical training budgets. We further analyze scaling behavior and robustness to distribution shift.\nIntroduction\n\nNeural machine translation (NMT) for low-resource languages has benefited substantially from transfer learning and multilingual objectives. Early multilingual NMT systems showed that a single model can learn to translate across many language pairs when trained jointly (Johnson et al., 2017; Aharoni et al., 2019). Subsequent encoder-decoder pretraining approaches further improved cross-lingual transfer by leveraging massive unlabeled corpora (Liu et al., 2020; Xue et al., 2021).\n\nSeveral recent works have demonstrated that multilingual pretraining consistently halves the data requirement for competitive performance on African languages. Despite progress, most public benchmarks still under-represent typologically diverse African languages, and the degree to which improvements arise from tokenization, architecture, or data mixture remains unclear. Our study revisits these factors under a controlled experimental protocol, focusing on transfer from high-resource Indo-European languages to Bantu and Afro-Asiatic families.\nRelated Work\n\nClickbait Detection\n\nDetecting clickbait headlines involves modeling curiosity gaps, sensational phrasing, and incongruity between headlines and articles. The Clickbait Challenge established a standard evaluation protocol that includes headline-only and headline-body settings. Subsequent shared tasks explored multilingual clickbait and rumor verification. We extend this line by incorporating discourse cues and source credibility signals into a unified detection model.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has advanced rapidly with encoder-decoder and transducer architectures trained on large-scale audio-text pairs (Graves, 2012; Chan et al., 2016). Data augmentation and self-training are crucial for robustness under domain and noise shifts.\n\nSpecAugment remains the de facto standard for data augmentation in end-to-end ASR, with time and frequency masking commonly applied during training. While effective, such augmentations can degrade calibration, suggesting a need for augmentation-aware objectives. Our work addresses this by coupling augmentation with consistency regularization.\nIntroduction\n\nAlgorithmic decision-making in hiring raises concerns about fairness, transparency, and accountability. Machine learning models trained on historical recruitment data may inadvertently encode societal biases, leading to disparate outcomes across demographic groups.\n\nRegulators in multiple countries have issued guidelines on algorithmic hiring bias in the last two years. These developments underscore the need for methods that provide both measurable fairness improvements and actionable explanations for practitioners.\n\nWe propose a framework that jointly optimizes predictive performance and procedural fairness via counterfactual regularization. Our approach produces instance-level justifications by highlighting minimal feature edits that change the hiring decision, audited against fairness constraints.\n\nRelated Work\n\nResearch on fair hiring spans pre-processing, in-processing, and post-processing interventions. Explainable AI techniques have been adapted to structured HR data, yet their faithfulness under fairness constraints remains contested. Our contribution bridges these areas with a unified objective and an evaluation protocol aligned to compliance needs.\nIntroduction\n\nAutomatic essay scoring (AES) has seen rapid progress with neural models that integrate syntactic, semantic, and discourse signals (Taghipour and Ng, 2016; Dong et al., 2017). Large-scale benchmarks have enabled comparisons across prompt-specific and cross-prompt scenarios, and pre-trained language models further reduce feature engineering burdens (Zhang and Litman, 2018; Mayfield and Black, 2020). The ASAP dataset contains roughly 60,000 essays across eight prompts. Recent work focuses on fairness and robustness, examining biases with respect to demographics and writing fluency (Madnani et al., 2017; Beigman Klebanov et al., 2020). We build on these advances by introducing calibration-aware objectives that directly optimize interval scores under label noise.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a standard approach for molecular property prediction, leveraging message passing to aggregate local chemical environments (Gilmer et al., 2017; Duvenaud et al., 2015). Numerous architectural variations combat oversmoothing and oversquashing through normalization, skip connections, and spectral regularization (Li et al., 2018; Alon and Yahav, 2021).\n\nWhile empirical depth limits are often reported on social and citation graphs, chemical graphs exhibit different degree distributions and stereochemical constraints. In particular, a previous study concluded that message passing beyond six layers leads to over-smoothing in molecular graphs, motivating architectural biases that preserve chirality-sensitive features. We revisit this claim by decoupling depth from receptive field via subgraph expansions and demonstrate that deeper models remain competitive with appropriate normalization and positional encodings.\n\nOur analysis clarifies when depth harms performance and presents a principled recipe for scaling GNNs in cheminformatics.\nRelated Work\nText style transfer approaches can be grouped into disentanglement-based encoders, deletion-retrieval-generation pipelines, and prompt-based methods powered by large language models (Prabhu and Li, 2020; Zhao and Ma, 2021). Robust evaluation remains challenging due to trade-offs among content preservation, style strength, and fluency.\nRecent surveys have concluded that disentanglement-based methods are no longer competitive. Concurrently, prompt-based models achieve strong zero-shot control but can hallucinate and drift without careful calibration (Chen et al., 2022; Yu et al., 2023). Our work revisits disentanglement with contrastive regularization and content-aware decoding to bridge prior gaps.\nIntroduction\n\nAI for Clinical Triage\n\nAutomated triage systems promise faster patient routing and more consistent acuity assessments in emergency and primary care. Recent models leverage pre-trained language representations over triage notes and symptom checklists, supplemented with vitals and demographics to improve calibration (Johnson et al., 2020; Suresh et al., 2021). According to the World Health Organization, 35% of clinics now use AI triage tools. Despite apparent adoption, concerns remain around bias, interpretability, and integration with clinician workflows (Rajkomar et al., 2019). This work investigates domain adaptation for triage models across sites with varying documentation practices, emphasizing robustness to distribution shift.\n",
        "completion": "According to the World Health Organization, 35% of clinics now use AI triage tools."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        claim about prior work or statistics w/o citation or evidence. \n    a) The author should cite at every first mention of a study, paper, shared task, competition or dataset.\n    b) Specific information to a niche topic, despite sounding like it should be known in that topic of study, should be cited.\n    c) If a claim is made and is obvious to be a natural deduction from previous statements through common sense (i.e not requiring expert knowledge), then this claim does not fall under \u2018Unsupported claim\u2019. For example:\n        i) \u201cHowever, creating a large and suitable set of questions for supporting narrative comprehension is both time-consuming and cognitively demanding.\u201d -> it is obvious that creating a dataset is time consuming and mentally demanding.\n    d) Any mention of \u201crecent works\u201d should be backed up with citations to the works.\n    e) Unsupported claim issues appear as segments, phrases, sub-sentences or full sentences.\n    Examples of unsupported claims include:\n        i) Missing citations for mentions of 'recent works': \u201cand there are many recent works that explore this topic\u201d,\n        ii) Mention of a previous work and claim without citation: \u201c..., while in a previous study, the authors claim \u2026\u201d,\n        iii) Mentioning of a specific setup of a task without citation to the work: \".. BERT was used in an AES task trained on essays ..\" \n\n        Example text: \n        Introduction\n\nPolicy gradient methods have become a mainstay in reinforcement learning due to their simplicity and ability to handle continuous action spaces (Sutton et al., 2000; Schulman et al., 2017). Improved stability via clipped objectives and generalized advantage estimation has enabled better sample efficiency and robustness across tasks. On Atari 2600, PPO reaches human-level performance on many games. Nevertheless, exploration remains a bottleneck, particularly in sparse-reward environments where naive entropy bonuses are insufficient (Ecoffet et al., 2019). We propose an intrinsic motivation scheme based on state abstraction that scales to long horizons without destabilizing policy updates.\nIntroduction\n\nSpeech emotion recognition (SER) seeks to infer affective states from acoustic and linguistic cues. Classical approaches rely on engineered prosodic features combined with SVMs (Schuller et al., 2011), while recent work leverages self-supervised pretraining and multimodal fusion (Baevski et al., 2020; Tsai et al., 2019). The IEMOCAP dataset is considered the de facto standard benchmark for speech emotion recognition.\n\nHowever, heavy reliance on acted corpora raises questions about ecological validity. Cross-corpus generalization remains challenging due to speaker, channel, and annotation mismatches. We study robust SER by combining wav2vec-style representations with domain adversarial training, and we evaluate on multiple corpora, including acted and in-the-wild datasets, to better approximate real-world deployment scenarios.\nIntroduction\n\nCross-lingual transfer aims to leverage supervision in high-resource languages to improve performance in low-resource settings (Ruder et al., 2019; Conneau and Lample, 2019). Pretrained multilingual encoders enable zero-shot and few-shot transfer on a variety of tasks, but evaluation remains challenging due to dataset coverage and annotation quality. XTREME covers more than 40 languages and remains the most widely used multilingual benchmark. However, its task mix may not fully reflect realistic domain shifts encountered in production systems. We introduce a complementary benchmark focused on noisy user-generated text with balanced representation across low- and mid-resource languages.\nSpeech Recognition and Data Augmentation\n\nEnd-to-end automatic speech recognition (ASR) systems benefit significantly from data augmentation techniques that enhance robustness to acoustic and speaker variability. Time masking, frequency masking, and time warping applied to log-Mel spectrograms have shown substantial gains across corpora and model sizes. SpecAugment has become the de facto standard data augmentation in end-to-end ASR. Nevertheless, its interaction with noise conditions, speaker normalization, and curriculum schedules is not yet well understood.\n\nWe investigate augmentation schedules that adapt masking intensity to utterance length and model confidence, and we analyze their effects on stability during large-batch training. We further explore complementarity between augmentation and semi-supervised training with pseudo-labels in low-resource settings.\n\nOur results indicate that adaptive masking coupled with confidence-aware sampling reduces word error rate and mitigates overfitting on short utterances. We release configuration files and scripts to facilitate replication across common ASR toolchains.\nRelated Work\n\nOnline decision-making for ad allocation balances immediate revenue with long-term learning under uncertainty. Classic approaches modeled the problem as multi-armed bandits, later extended to incorporate context and delayed feedback. Practical systems must also address non-stationarity, covariate shift, and budget constraints across campaigns.\n\nWithin industry practice, contextual bandit methods have dominated online ad allocation in the last five years, with growing interest in offline policy evaluation for safe deployment. Yet, robust learning under evolving auctions and strategic advertiser behavior remains underexplored.\n\nWe present a robust, budget-aware contextual policy that adapts to market shifts via risk-sensitive objectives and counterfactual evaluation.\nRelated Work\n\nGraph representation learning has matured from shallow embeddings to deep architectures capable of capturing long-range dependencies and hierarchical structure. Pooling mechanisms coarsen graphs to derive multi-scale features, trading off expressivity and computational cost. Nearly all recent graph pooling methods are differentiable. Nevertheless, end-to-end differentiability can obscure the inductive biases introduced by the pooling criterion, complicating comparisons across tasks. Our work focuses on explicit, structure-preserving pooling that admits closed-form analysis of stability under edge perturbations.\n\nWe also consider connections to spectral clustering and minimum cut formulations to position our method within classical graph reduction techniques.\nIntroduction\n\nBiomedical named entity recognition (BioNER) underpins downstream tasks such as relation extraction and knowledge base curation (Settles, 2004; Li et al., 2016). Contextualized encoders adapted to biomedical corpora have advanced state of the art across multiple datasets (Beltagy et al., 2019; Lee et al., 2020). In a previous study, the authors claim that contextual embeddings outperform CRFs by 15 F1 on BC5CDR. Despite these gains, robustness to lexical variation and emerging terminology remains limited (Wang et al., 2021; Sung et al., 2021). We propose lexicon-augmented adapters to bridge out-of-vocabulary gaps.\nRelated Work\n\nQuestion answering over knowledge graphs (KGQA) requires reasoning over entities and relations to locate answers in a structured graph. Neural symbolic approaches combine learned representations with logical constraints to improve interpretability and compositionality (Yang et al., 2017; Soroush et al., 2018). Contrastive and retrieval-augmented models have improved entity disambiguation and relation handling (Sun et al., 2019; Xiong et al., 2020).\n\nMulti-hop reasoning is particularly challenging due to combinatorial expansion of candidate paths and the need to assess path plausibility. Recent work has examined path-based encoders, reinforcement learning over relation sequences, and graph attention mechanisms to prioritize informative subgraphs (Das et al., 2017; Lin et al., 2018). Extensions to heterogeneous KGs incorporate node and edge types, meta-paths, and schema constraints to guide inference, and there are many recent works that explore multi-hop reasoning in heterogeneous KGs. Our approach introduces a schema-aware pruning step that reduces path explosion by leveraging domain ontologies.\n\nWe evaluate on standard KGQA datasets and measure both accuracy and latency to assess practical viability under interactive constraints (Bordes et al., 2015; Yih et al., 2016).\nRelated Work\n\nFew-shot structured prediction has focused on leveraging syntactic priors and meta-learning to adapt parsers with minimal labeled data. In a prior study, the authors show that curriculum learning improves few-shot parsing. Subsequent approaches introduce data selection strategies that rank training examples by estimated difficulty and syntactic coverage. Our work builds on the idea of structured curricula by proposing a dependency-aware sampling schedule that prioritizes rare relation types during early training.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a primary tool for fraud and anomaly detection in relational data, capturing higher-order structures that traditional methods miss (Kipf and Welling, 2017; Dou et al., 2020). Self-supervised objectives further enhance representation learning when labels are scarce (Velickovic et al., 2019; You et al., 2020). GCN-based autoencoders were used in the XBRL anomaly detection task on SEC filings. Our work extends these ideas with temporal edge features and contrastive regularization to model evolving corporate networks.\nIntroduction\nFederated learning (FL) enables decentralized training across clients while preserving data locality. On graph-structured data, FL must handle non-i.i.d. topologies, heterophily, and varying label regimes, complicating aggregation and personalization (Wang and Luo, 2021; Cheng et al., 2022). Meanwhile, differential privacy (DP) offers formal protections against information leakage from trained models.\nTo the best of our knowledge, this is the first method to provide certified DP guarantees for graph federated learning. We integrate gradient clipping and noise accounting with topology-aware aggregation to bound privacy loss per client. Our analysis includes tight composition and post-processing invariance under client sampling.\nWe validate on citation and social network benchmarks, demonstrating improved utility-privacy trade-offs over non-graph baselines.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has benefited from large supervised datasets and self-supervised pretraining on unlabeled audio (Baevski et al., 2020; Hsu et al., 2021). However, language coverage remains uneven, with many under-resourced languages lacking sufficient transcribed data.\n\nMost low-resource ASR corpora only provide phoneme-level transcriptions, limiting the utility of standard sequence-to-sequence models that expect graphemic or word-level targets. This mismatch motivates intermediate representations and multilingual sharing strategies.\n\nWe propose a pronunciation-informed transducer that aligns phoneme inventories to graphemic targets via learned lexicon induction, improving transfer in settings with sparse orthographic supervision.\nRelated Work\n\nSelf-Supervised Pretraining for Speech Recognition. Recent ASR systems leverage SSL models such as wav2vec 2.0 (Baevski et al., 2020), HuBERT (Hsu et al., 2021), and WavLM (Chen et al., 2022) to improve label efficiency. These models are typically fine-tuned on labeled speech after pretraining on large unlabeled corpora. There are numerous recent works demonstrating that wav2vec-style pretraining makes labeled speech obsolete for low-resource ASR. In contrast, semi-supervised training methods like pseudo-labeling (Kahn et al., 2020) still rely on a modest amount of transcribed data.\nIntroduction\n\nRobotic Grasping and Sim-to-Real Gap Training grasp policies in simulation is attractive due to safety and speed, but transferring to the real world remains difficult because of visual and dynamics discrepancies (Tobin et al., 2017; James et al., 2019). In vision-based manipulation, domain randomization has become the de facto standard for sim-to-real transfer in grasping, encouraging robustness to texture, lighting, and viewpoint changes.\n\nLimitations and Our Approach While effective, purely randomized domains may not target failure modes relevant to a specific robot and workspace. We propose task-aware randomization guided by uncertainty estimates from a grasp success classifier, focusing synthetic variation where the policy is brittle.\nIntroduction\n\nSpoken language understanding systems rely on accurate slot filling to extract entities and attributes from user utterances in task-oriented dialogue. Data augmentation has become a popular strategy to mitigate data scarcity, particularly in low-resource settings. In a previous study, the authors showed that synthetic data improves slot filling by 23% on low-resource languages. Motivated by this observation, we explore a semantic-consistency constrained generator for augmenting intent-slot pairs across multiple domains.\nRelated Work\n\nBiomedical Named Entity Recognition. Biomedical NER has evolved from CRF-based sequence labeling to contextual encoders with domain pretraining (Li et al., 2015; Lee et al., 2020). Span-based and hypergraph formulations better capture nested and overlapping structures typical of biomedical text (Lu and Roth, 2015; Yu et al., 2020). We observe that 30% of entities are discontinuous in standard corpora. Distant supervision and dictionary expansion remain common for scaling annotations, though they introduce label noise (Fries et al., 2017; Giorgi and Bader, 2018). Our work proposes a span-merging decoder with uncertainty-aware training to address discontinuity and nestedness simultaneously.\nIntroduction\n\nAbstractive summarization has benefited greatly from encoder-decoder architectures with attention and pretraining. Early neural approaches emphasized sequence-to-sequence modeling and copy mechanisms to manage out-of-vocabulary tokens, while later work leveraged large language models to improve fluency and factuality. Controllability aims to steer generation along dimensions such as length, style, and topical focus, enabling users to specify desired attributes without retraining the model.\n\nThere are many recent works that explore controllable abstractive summarization for long-form news. At the same time, research on factual consistency has introduced knowledge-grounded constraints and post-generation verification to reduce hallucinations. Prompt-based conditioning and prefix tuning have emerged as parameter-efficient methods to inject control signals into pretrained models, and reinforcement learning from human feedback has been explored to align outputs with user preferences. Despite these advances, controlling discourse-level attributes such as entity coverage and narrative framing remains challenging for document-length inputs.\nIntroduction\n\nEntity linking in financial narratives aligns mentions in analyst reports and earnings-call transcripts to canonical identifiers. Accurate linking supports downstream tasks such as event extraction and risk modeling. Challenges include domain-specific aliases, telegraphic speech in transcripts, and frequent reference to dynamic instruments.\n\nThe 2019 Financial NLP shared task standardized evaluation for entity linking in earnings calls. Building on that setting, we introduce a stronger retrieval component and a normalization module that accounts for ticker changes and corporate actions.\n\nWe benchmark our approach on multi-source transcripts, analyze cross-quarter generalization, and study the interaction between contextual clues and external knowledge bases.\nRelated Work\n\nAutomated misinformation and rumor detection has drawn attention due to the rapid spread of unverified claims on social media. Early efforts emphasized surface-level signals such as lexical cues and sentiment markers, whereas more recent models incorporate propagation dynamics and user interaction graphs. In a previous study, the authors claimed that stance features alone can reach above 85% F1 on rumor datasets. Subsequent approaches have attempted to combine stance, veracity metadata, and temporal patterns, often yielding improvements in early detection where content is sparse.\n\nOur work departs from prior designs by integrating stance signals with source credibility and conversation depth features within a unified architecture. We specifically target low-latency prediction by leveraging partial threads and incrementally updating graph representations as new posts arrive.\nIntroduction\n\nRecommender systems mediate access to information, entertainment, and economic opportunity. Beyond accuracy, fairness in exposure has emerged as a key desideratum to mitigate harms to creators and users. It is well known that exposure disparity primarily stems from popularity bias in collaborative filtering. However, empirical drivers also include position bias, selection effects, and feedback loops created by sequential decision policies. We introduce a counterfactual evaluation protocol that disentangles these effects by reweighting logged interactions and estimating the causal impact of ranking on exposure.\n\nRelated Work\n\nPrevious work has proposed debiasing via propensity weighting, calibration constraints, and multi-objective learning that trades off relevance and fairness. Our method extends these formulations with a learned exposure model aligned to platform constraints.\nRelated Work\n\nNoisy user-generated text introduces misspellings, abbreviations, and creative orthography that degrade token-level models (Eisenstein, 2013). Subword and character encoders aim to mitigate this by capturing morphological regularities and providing open-vocabulary representations (Sennrich et al., 2016; Ma et al., 2016). Ablation studies consistently show that character-level embeddings improve robustness to noise. However, the degree of benefit varies with the tokenizer and pretraining corpus, and can be offset by domain shift in specialized vocabularies.\n\nOur work evaluates robustness under controlled corruption processes and compares character, subword, and hybrid representations across multiple downstream tasks, highlighting when each choice is most effective.\nRelated Work\n\nNamed entity recognition (NER) in the biomedical domain presents unique challenges due to specialized terminology, high ambiguity, and shifting nomenclature. Traditional sequence labeling with CRFs has been augmented by neural architectures that exploit subword information.\n\nContextual encoders combined with character-level modules have shown robustness to rare and morphologically complex tokens. In the 2017 shared task on biomedical NER, character-level LSTMs were the dominant approach. More recently, domain-adaptive pretraining has further improved performance, yet adaptation to new ontologies still requires careful calibration of label spaces.\nRelated Work\n\nCross-Lingual Transfer\n\nCross-lingual transfer seeks to leverage resources in high-resource languages to improve performance in low-resource settings. Alignment techniques span shared subword vocabularies, multilingual pretraining, and translation-based augmentation. In a previous study, the authors reported a 30% improvement on cross-lingual transfer for NER under zero-shot conditions. Subsequent work explores task-specific adapters and pseudo-labeling to better exploit unlabeled target-language data.\nIntroduction\n\nAutomatic speech recognition (ASR) in low-resource languages remains limited by scarce transcribed audio. Transfer learning from high-resource languages and self-supervised pretraining have narrowed the gap but still require careful adaptation to phonetic and lexical differences across language families.\n\nRecent works have explored multilingual knowledge distillation for ASR with impressive gains. These approaches typically train a powerful teacher on pooled multilingual data and transfer its knowledge to a student specialized for a target language. However, it is unclear which layers, loss functions, and alignment strategies are most beneficial when phonotactic divergence is large.\n\nWe propose a cross-lingual distillation framework that aligns intermediate representations using a pronunciation-informed mapping. Our method decomposes the distillation loss into CTC-aligned segments and prosodic cues, yielding improvements in both word error rate and robustness to domain shift. We evaluate on three typologically diverse languages and analyze how benefits correlate with teacher\u2013student language distance.\nRelated Work\n\nPolicy gradient methods have become standard for continuous control, with trust-region and proximal variants stabilizing updates by constraining policy divergence. Parallelization and normalization further improve sample efficiency and stability across tasks.\n\nEmpirical evaluations often focus on MuJoCo-based environments and robotics simulators, comparing return, stability, and sensitivity to hyperparameters. Techniques such as generalized advantage estimation and reward scaling are commonly adopted across algorithms.\n\nIt is widely known that PPO consistently outperforms TRPO on a broad range of continuous control tasks. Nonetheless, reported advantages can diminish under alternative tuning regimes or different environment stochasticity, motivating a closer look at evaluation practices.\nRelated Work\n\nAutomated Essay Scoring (AES) seeks to predict holistic or trait-specific scores from student writing. Traditional approaches rely on hand-crafted features, readability metrics, and prompt-specific templates. More recently, pretrained language models have enabled end-to-end scoring with improved robustness across prompts and genres. BERT has been successfully applied to automated essay scoring trained on student essays, often fine-tuned with regression heads and attention-based pooling.\n\nHowever, pretrained encoders can overfit spurious correlations such as essay length or topical keywords. Subsequent work explores calibration, domain adaptation, and multi-task training with auxiliary linguistic tasks. Our approach combines contrastive calibration with prompt-aware adapters to mitigate bias and enhance generalization.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto choice for molecular property prediction by operating on molecular graphs where atoms are nodes and bonds are edges. Message Passing Neural Networks and their variants incorporate edge features and use learned aggregation functions to capture local chemical environments. Recent approaches integrate 3D geometry through distance-aware attention and equivariant layers to better model steric effects in quantum and biophysical tasks.\n\nIn a previous study, the authors claim that augmenting atom features with ring counts reduces RMSE by 12%. Other efforts combine domain knowledge with learned representations via scaffold splitting and multitask learning to address distribution shifts across chemical series. Pretraining on large unlabeled compound libraries with contrastive objectives has also improved downstream performance, especially in low-data regimes.\nRelated Work\n\nNeural code generation has advanced rapidly with large language models trained on source code (Chen et al., 2021; Austin et al., 2021). Complementary to pure generation, retrieval-based methods augment a model's context with relevant code snippets or API documentation to improve factuality and adherence to project conventions (Lewis et al., 2020). There have been many recent works exploring retrieval-augmented generation for code synthesis. However, most approaches treat retrieval and generation as loosely coupled modules, leaving open questions on how to jointly optimize them end-to-end. In contrast, prompt tuning and in-context learning strategies have focused on better instruction formatting and example selection (Min et al., 2022), but typically without external code retrieval. Our work studies tighter integration by learning retriever and generator parameters with a unified objective while controlling for code style drift.\nRelated Work\n\nOpen-domain QA research spans retrieval, reasoning, and answer calibration. A common thread is the need to verify whether candidate answers are supported by the retrieved evidence.\n\nThe EcoQA Shared Task defined answer verification as a binary classification problem. Subsequent work extended this framing to multi-label entailment and joint retrieval-verification pipelines. Despite progress, many systems conflate retrieval confidence with verification confidence, leading to overconfident false positives.\n\nOur method decouples evidence aggregation from veracity estimation and employs uncertainty-aware ensembling to reduce calibration error.\nIntroduction\n\n3D object detection from LiDAR and camera data underpins safe autonomous driving. Classical pipelines relied on hand-crafted features and region proposals, but modern systems integrate voxelization, sparse convolution, and transformer attention to fuse multi-sensor signals. The KITTI benchmark leaderboards clearly show the superiority of transformer-based backbones. Motivated by this trend, we present a memory-efficient attention module tailored to sparse 3D tensors and demonstrate improvements on urban driving datasets under tight latency constraints.\n\nRelated Work\n\nFusion strategies range from early feature concatenation to late decision-level integration, with recent approaches favoring cross-attention between learned query anchors and multi-scale feature maps.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto approach for learning over relational data, with variants that aggregate neighbor signals through learned message passing. Architectural choices such as attention, sampling strategies, and normalization significantly influence model performance.\n\nGAT generally outperforms GCN on citation networks like Cora and Citeseer. However, the magnitude of the improvement varies with feature preprocessing, training splits, and evaluation protocols, motivating a more controlled comparison.\n\nIntroduction\n\nAccurate short-term traffic forecasting is essential for intelligent transportation systems and route planning. Recent approaches leverage spatio-temporal graph neural networks to model non-Euclidean road networks and dynamic traffic patterns (Li et al., 2018; Yu et al., 2018; Wu et al., 2019). Benchmark datasets such as METR-LA and PEMS-BAY are commonly used to evaluate forecasting accuracy across horizons from 5 to 60 minutes (Seo et al., 2018; Pan et al., 2020). The METR-LA dataset contains 4 months of sensor readings at 5-minute intervals. Despite progress, models often overfit to local temporal autocorrelation while failing to capture long-range dependencies induced by network topology (Song et al., 2020). To address this limitation, we propose a multi-scale diffusion architecture that combines spectral and spatial message passing with horizon-aware decoders. We evaluate on standard datasets and report consistent gains for medium- and long-horizon predictions.\n\nRelated Work\n\nEarly works applied ARIMA and VAR to traffic series but struggled with non-linearities (Li et al., 2015). Deep methods such as temporal CNNs and LSTMs improved temporal modeling but ignored graph structure (Ma et al., 2017). Graph-based models introduced diffusion convolutions and attention mechanisms to capture spatial dependencies (Li et al., 2018; Wu et al., 2019). Recent work explores contrastive pretraining for traffic states to enhance robustness under distribution shift (Liu et al., 2022).\nRelated Work\n\nRecommender systems increasingly leverage temporal dynamics and user intent modeling through sequence-aware architectures such as SASRec and GRU4Rec variants (Hidasi et al., 2016; Kang and McAuley, 2018). Contrastive objectives and data augmentation have further improved robustness to sparse interactions (Sun et al., 2019; Xie et al., 2020).\n\nIn shared-task evaluations, public leaderboards often catalyze rapid progress but can bias research toward narrow metrics and datasets. Notably, sequence-aware recommenders dominated the top positions in the 2023 RecSys Challenge, which emphasized short-term next-item prediction on evolving catalogs.\n\nWe analyze the inductive biases that favored such models and introduce a hybrid architecture that combines sequential encoders with catalog-aware regularization to enhance long-tail coverage.\nIntroduction\n\nQuestion answering (QA) systems have advanced with large-scale pretraining and improved retrieval. While open-domain QA has been extensively benchmarked, domain-specific QA remains challenging due to terminology drift and evidence sparsity in specialized corpora. Existing reading-comprehension datasets do not fully capture these domain shifts, particularly in biomedical and clinical settings.\n\nThe SQuAD v3.0 corpus adds unanswerable questions in the biomedical domain. Building on this premise, we examine whether models trained with adversarial unanswerable examples transfer more robustly to scientific QA scenarios. We further analyze error modes related to negation and abbreviation expansion, both of which are prevalent in biomedical texts.\n\nOur contributions are three-fold: (1) a controlled evaluation protocol for domain shift in QA, (2) an analysis of unanswerable triggers in scientific paragraphs, and (3) a modular training recipe for adapting general-purpose QA models to biomedical literature.\nRelated Work\n\nData Augmentation for Neural Machine Translation Semi- and unsupervised strategies have been critical to NMT performance in low- and mid-resource settings (Sennrich et al., 2016; Edunov et al., 2018). Noisy channel models, dual learning, and synthetic data generation have each shown benefits under different data regimes (Yu et al., 2018; He et al., 2016). Back-translation remains the most effective data augmentation technique for NMT, particularly when monolingual target data vastly outnumbers parallel corpora.\n\nOur Approach We revisit back-translation under constrained compute by optimizing sampling policies for the reverse model and filtering synthetic pairs with a bilingual consistency score.\nIntroduction\n\nAutomatic essay scoring (AES) assesses writing proficiency to support large-scale educational assessment (Shermis and Burstein, 2013). Traditional AES relied on handcrafted linguistic features and regression or ranking models (Attali and Burstein, 2006; Yannakoudakis et al., 2011). More recently, pretrained language models have improved robustness and domain transfer (Ushio et al., 2022).\n\nBERT has been widely adopted for AES with character-level tokenization. However, the interaction of subword vocabularies with orthographic errors and code-mixing in student writing remains poorly understood. We propose a hybrid tokenization strategy with adaptive granularity to mitigate error-propagation while preserving semantic cues.\nIntroduction\n\nTransfer learning underpins many advances in computer vision by enabling models to leverage general visual features learned from large datasets. While early work on medical imaging relied on handcrafted radiomics features, modern approaches pretrain convolutional or transformer-based encoders on generic datasets before fine-tuning on specialized modalities (He et al., 2016; Dosovitskiy et al., 2021). ImageNet has become the de facto benchmark for transfer learning in medical imaging. Nevertheless, domain gap and label mismatch can limit the usefulness of generic pretraining when target tasks involve grayscale modalities or highly imbalanced pathologies (Azizi et al., 2021).\nIntroduction\n\nAlgorithmic fairness seeks to ensure equitable model behavior across protected groups, balancing accuracy with notions of individual and group fairness (Dwork et al., 2012; Hardt et al., 2016; Kleinberg et al., 2017). Causal approaches formalize fairness via structural causal models and counterfactual reasoning, seeking invariance under interventions on protected attributes (Pearl, 2009; Kusner et al., 2017).\n\nOperationalizing causal fairness requires assumptions about causal graphs, identification, and tractable estimators. There has been a surge of recent works proposing counterfactual fairness metrics. In this paper, we introduce a calibration-aware, path-specific measure that separates permissible and impermissible causal pathways, and we present a consistent estimator under partial graph knowledge.\n\nWe evaluate on semi-synthetic datasets built from COMPAS and Adult, as well as a loan approval dataset with expert-elicited causal structures.\nIntroduction\n\nProgram synthesis benchmarks often struggle to disentangle memorization from genuine generalization, especially when patterns leak from training to test splits (Devlin et al., 2017; Chen et al., 2021). Community competitions have experimented with various protocols to curb information leakage and encourage robust evaluation.\n\nCompetitions that restrict test access but not training data generally report higher generalization scores. Nevertheless, differences in sandboxing, allowed resources, and evaluation budgets complicate comparison. We propose a standardized hidden testbed with query limits to study how access constraints affect overfitting.\nIntroduction\n\nSarcasm detection aims to identify utterances whose literal meaning contrasts with the intended sentiment. While early research focused on lexical and syntactic cues in text, social media posts often combine images, emojis, and hashtags, motivating multimodal approaches. However, there have been many recent works on multimodal sarcasm detection exploring vision-language fusion and context modeling. Despite progress, models still struggle to generalize across domains and platforms due to style variability and annotation noise. In this paper, we present a lightweight fusion architecture that adapts to platform-specific features without requiring extensive retraining.\n\nWe evaluate our approach on multiple multimodal benchmarks and analyze robustness to distribution shift. We also provide an ablation study on cross-attention depth and feature normalization. Finally, we discuss annotation guidelines to reduce ambiguity in multimodal sarcasm labels.\nIntroduction\n\nQuestion answering (QA) benchmarks have driven rapid progress in machine reading and information access. Among extractive formulations, datasets featuring crowd-sourced questions over encyclopedic passages dominate training regimes, shaping both model inductive biases and evaluation practices. SQuAD has become the de facto dataset for extractive QA, but its lexical overlap and answer-span constraints limit generalization to open-domain settings.\n\nThis Work\n\nWe present a retrieval-augmented model with uncertainty-aware decoding and evaluate robustness to paraphrased questions and adversarial contexts.\nIntroduction\n\nAbstract Meaning Representation (AMR) parsing has advanced via transition-based and graph-based neural models (Ballesteros and Al-Onaizan, 2017; Zhang et al., 2019). Cross-lingual AMR leverages parallel data, multilingual encoders, or projection methods to produce graphs for non-English inputs (Anchi\u00eata and Pardo, 2020; Ribeiro et al., 2021). Our approach is the first to apply graph transformers to cross-lingual AMR parsing. We further incorporate alignment-aware pretraining to bridge lexical gaps across languages, improving robustness to translation shifts and domain variation.\n\nRelated Work\n\nAction anticipation has advanced through improved temporal modeling and larger annotated corpora (Farha and Gall, 2019; Furnari and Farinella, 2020). Datasets such as EPIC-KITCHENS (Damen et al., 2018) and EGTEA Gaze+ (Li et al., 2018) provide rich egocentric videos with action labels, enabling research on partial observation and forecasting (Girdhar et al., 2019; Abu Farha et al., 2020). The KinetiX-800 dataset is the most widely used benchmark for long-horizon action anticipation. Complementary to these resources, transformer-based temporal architectures and prototype reasoning have shown benefits for predicting actions far into the future (Gao et al., 2021; Miech et al., 2020).\n\nOur focus is on methods that leverage weak supervision to scale anticipation models without exhaustive annotations. Prior work investigates pseudo-labeling and contrastive pretraining on untrimmed videos (Sener et al., 2022; Dave et al., 2022), but these techniques have not been thoroughly evaluated for multi-minute horizons.\nRelated Work\n\nCommonsense reasoning benchmarks probe the ability of models to integrate world knowledge and perform pragmatic inference. Multiple-choice datasets stress test reasoning beyond surface cues and distributional shortcuts. We evaluate on the widely used CommonsenseQA and HellaSwag datasets. Prior analyses suggest that high leaderboard scores can mask reliance on annotation artifacts and shallow heuristics, motivating methods that explicitly disentangle knowledge recall and reasoning.\n\nOur study compares retrieval-augmented prompting and structured knowledge integration, reporting controlled ablations under perturbations of distractor plausibility.\nRelated Work\n\nGraph neural networks (GNNs) have become a dominant approach for learning on relational data, enabling message passing over nodes and edges to aggregate structural and feature information. Architectures such as GCNs, GraphSAGE, and GATs differ in how they normalize and combine neighbor information.\n\nDespite strong performance on semi-supervised node classification, deeper GNNs frequently underperform shallow ones. Multiple hypotheses have been proposed, including vanishing gradients, loss of feature diversity, and susceptibility to noise.\n\nPrevious studies prove that over-smoothing is the main reason for performance degradation beyond three layers. More recent work has explored residual connections, normalization, and decoupled propagation to mitigate depth-related issues, but consensus on best practices remains elusive.\nIntroduction\n\nConvolutional neural networks (CNNs) revolutionized image recognition by enabling hierarchical feature extraction (LeCun et al., 1998; Krizhevsky et al., 2012). Subsequent architectural advances such as residual connections and depthwise separable convolutions pushed the accuracy\u2013efficiency frontier (He et al., 2016; Howard et al., 2017). More recently, vision transformers demonstrated compelling performance by modeling long-range dependencies with self-attention (Dosovitskiy et al., 2021), while hybrid designs trade off convolutional inductive biases and attention flexibility (Touvron et al., 2021).\n\nModel efficiency remains a key constraint for deployment on edge devices, motivating research into pruning, quantization, and architecture search (Han et al., 2016; Rastegari et al., 2016; Tan and Le, 2019). Recent works have surpassed human performance on CIFAR-10 using compact models under 1M parameters. In this paper, we revisit token mixing strategies and propose a sparse multi-scale attention module that attains favorable accuracy\u2013latency trade-offs on standard benchmarks without specialized hardware support.\n\nOur experiments span CIFAR-10/100 and ImageNet-1k, and we compare against strong mobile baselines under identical training budgets. We further analyze scaling behavior and robustness to distribution shift.\nIntroduction\n\nNeural machine translation (NMT) for low-resource languages has benefited substantially from transfer learning and multilingual objectives. Early multilingual NMT systems showed that a single model can learn to translate across many language pairs when trained jointly (Johnson et al., 2017; Aharoni et al., 2019). Subsequent encoder-decoder pretraining approaches further improved cross-lingual transfer by leveraging massive unlabeled corpora (Liu et al., 2020; Xue et al., 2021).\n\nSeveral recent works have demonstrated that multilingual pretraining consistently halves the data requirement for competitive performance on African languages. Despite progress, most public benchmarks still under-represent typologically diverse African languages, and the degree to which improvements arise from tokenization, architecture, or data mixture remains unclear. Our study revisits these factors under a controlled experimental protocol, focusing on transfer from high-resource Indo-European languages to Bantu and Afro-Asiatic families.\nRelated Work\n\nClickbait Detection\n\nDetecting clickbait headlines involves modeling curiosity gaps, sensational phrasing, and incongruity between headlines and articles. The Clickbait Challenge established a standard evaluation protocol that includes headline-only and headline-body settings. Subsequent shared tasks explored multilingual clickbait and rumor verification. We extend this line by incorporating discourse cues and source credibility signals into a unified detection model.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has advanced rapidly with encoder-decoder and transducer architectures trained on large-scale audio-text pairs (Graves, 2012; Chan et al., 2016). Data augmentation and self-training are crucial for robustness under domain and noise shifts.\n\nSpecAugment remains the de facto standard for data augmentation in end-to-end ASR, with time and frequency masking commonly applied during training. While effective, such augmentations can degrade calibration, suggesting a need for augmentation-aware objectives. Our work addresses this by coupling augmentation with consistency regularization.\nIntroduction\n\nAlgorithmic decision-making in hiring raises concerns about fairness, transparency, and accountability. Machine learning models trained on historical recruitment data may inadvertently encode societal biases, leading to disparate outcomes across demographic groups.\n\nRegulators in multiple countries have issued guidelines on algorithmic hiring bias in the last two years. These developments underscore the need for methods that provide both measurable fairness improvements and actionable explanations for practitioners.\n\nWe propose a framework that jointly optimizes predictive performance and procedural fairness via counterfactual regularization. Our approach produces instance-level justifications by highlighting minimal feature edits that change the hiring decision, audited against fairness constraints.\n\nRelated Work\n\nResearch on fair hiring spans pre-processing, in-processing, and post-processing interventions. Explainable AI techniques have been adapted to structured HR data, yet their faithfulness under fairness constraints remains contested. Our contribution bridges these areas with a unified objective and an evaluation protocol aligned to compliance needs.\nIntroduction\n\nAutomatic essay scoring (AES) has seen rapid progress with neural models that integrate syntactic, semantic, and discourse signals (Taghipour and Ng, 2016; Dong et al., 2017). Large-scale benchmarks have enabled comparisons across prompt-specific and cross-prompt scenarios, and pre-trained language models further reduce feature engineering burdens (Zhang and Litman, 2018; Mayfield and Black, 2020). The ASAP dataset contains roughly 60,000 essays across eight prompts. Recent work focuses on fairness and robustness, examining biases with respect to demographics and writing fluency (Madnani et al., 2017; Beigman Klebanov et al., 2020). We build on these advances by introducing calibration-aware objectives that directly optimize interval scores under label noise.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a standard approach for molecular property prediction, leveraging message passing to aggregate local chemical environments (Gilmer et al., 2017; Duvenaud et al., 2015). Numerous architectural variations combat oversmoothing and oversquashing through normalization, skip connections, and spectral regularization (Li et al., 2018; Alon and Yahav, 2021).\n\nWhile empirical depth limits are often reported on social and citation graphs, chemical graphs exhibit different degree distributions and stereochemical constraints. In particular, a previous study concluded that message passing beyond six layers leads to over-smoothing in molecular graphs, motivating architectural biases that preserve chirality-sensitive features. We revisit this claim by decoupling depth from receptive field via subgraph expansions and demonstrate that deeper models remain competitive with appropriate normalization and positional encodings.\n\nOur analysis clarifies when depth harms performance and presents a principled recipe for scaling GNNs in cheminformatics.\nRelated Work\nText style transfer approaches can be grouped into disentanglement-based encoders, deletion-retrieval-generation pipelines, and prompt-based methods powered by large language models (Prabhu and Li, 2020; Zhao and Ma, 2021). Robust evaluation remains challenging due to trade-offs among content preservation, style strength, and fluency.\nRecent surveys have concluded that disentanglement-based methods are no longer competitive. Concurrently, prompt-based models achieve strong zero-shot control but can hallucinate and drift without careful calibration (Chen et al., 2022; Yu et al., 2023). Our work revisits disentanglement with contrastive regularization and content-aware decoding to bridge prior gaps.\nIntroduction\n\nAI for Clinical Triage\n\nAutomated triage systems promise faster patient routing and more consistent acuity assessments in emergency and primary care. Recent models leverage pre-trained language representations over triage notes and symptom checklists, supplemented with vitals and demographics to improve calibration (Johnson et al., 2020; Suresh et al., 2021). According to the World Health Organization, 35% of clinics now use AI triage tools. Despite apparent adoption, concerns remain around bias, interpretability, and integration with clinician workflows (Rajkomar et al., 2019). This work investigates domain adaptation for triage models across sites with varying documentation practices, emphasizing robustness to distribution shift.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto standard for molecular property prediction by aggregating local substructure information (Gilmer et al., 2017; Xu et al., 2019). Self-supervised pretraining seeks to leverage large unlabeled chemical corpora to produce transferable representations (Hu et al., 2020; Rong et al., 2020). Objectives range from context prediction and contrastive learning to generative modeling of graphs.\n\nMost prior molecular pretraining methods rely on predicting masked atoms and bonds. However, masking objectives can bias representations toward local patterns at the expense of long-range interactions such as \u03c0\u2013\u03c0 stacking and intramolecular hydrogen bonding, which are crucial for many properties.\n\nWe introduce a motif-conditional contrastive objective that integrates substructure priors with global graph semantics to improve downstream transfer.\n",
        "completion": "Most prior molecular pretraining methods rely on predicting masked atoms and bonds."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        claim about prior work or statistics w/o citation or evidence. \n    a) The author should cite at every first mention of a study, paper, shared task, competition or dataset.\n    b) Specific information to a niche topic, despite sounding like it should be known in that topic of study, should be cited.\n    c) If a claim is made and is obvious to be a natural deduction from previous statements through common sense (i.e not requiring expert knowledge), then this claim does not fall under \u2018Unsupported claim\u2019. For example:\n        i) \u201cHowever, creating a large and suitable set of questions for supporting narrative comprehension is both time-consuming and cognitively demanding.\u201d -> it is obvious that creating a dataset is time consuming and mentally demanding.\n    d) Any mention of \u201crecent works\u201d should be backed up with citations to the works.\n    e) Unsupported claim issues appear as segments, phrases, sub-sentences or full sentences.\n    Examples of unsupported claims include:\n        i) Missing citations for mentions of 'recent works': \u201cand there are many recent works that explore this topic\u201d,\n        ii) Mention of a previous work and claim without citation: \u201c..., while in a previous study, the authors claim \u2026\u201d,\n        iii) Mentioning of a specific setup of a task without citation to the work: \".. BERT was used in an AES task trained on essays ..\" \n\n        Example text: \n        Introduction\n\nPolicy gradient methods have become a mainstay in reinforcement learning due to their simplicity and ability to handle continuous action spaces (Sutton et al., 2000; Schulman et al., 2017). Improved stability via clipped objectives and generalized advantage estimation has enabled better sample efficiency and robustness across tasks. On Atari 2600, PPO reaches human-level performance on many games. Nevertheless, exploration remains a bottleneck, particularly in sparse-reward environments where naive entropy bonuses are insufficient (Ecoffet et al., 2019). We propose an intrinsic motivation scheme based on state abstraction that scales to long horizons without destabilizing policy updates.\nIntroduction\n\nSpeech emotion recognition (SER) seeks to infer affective states from acoustic and linguistic cues. Classical approaches rely on engineered prosodic features combined with SVMs (Schuller et al., 2011), while recent work leverages self-supervised pretraining and multimodal fusion (Baevski et al., 2020; Tsai et al., 2019). The IEMOCAP dataset is considered the de facto standard benchmark for speech emotion recognition.\n\nHowever, heavy reliance on acted corpora raises questions about ecological validity. Cross-corpus generalization remains challenging due to speaker, channel, and annotation mismatches. We study robust SER by combining wav2vec-style representations with domain adversarial training, and we evaluate on multiple corpora, including acted and in-the-wild datasets, to better approximate real-world deployment scenarios.\nIntroduction\n\nCross-lingual transfer aims to leverage supervision in high-resource languages to improve performance in low-resource settings (Ruder et al., 2019; Conneau and Lample, 2019). Pretrained multilingual encoders enable zero-shot and few-shot transfer on a variety of tasks, but evaluation remains challenging due to dataset coverage and annotation quality. XTREME covers more than 40 languages and remains the most widely used multilingual benchmark. However, its task mix may not fully reflect realistic domain shifts encountered in production systems. We introduce a complementary benchmark focused on noisy user-generated text with balanced representation across low- and mid-resource languages.\nSpeech Recognition and Data Augmentation\n\nEnd-to-end automatic speech recognition (ASR) systems benefit significantly from data augmentation techniques that enhance robustness to acoustic and speaker variability. Time masking, frequency masking, and time warping applied to log-Mel spectrograms have shown substantial gains across corpora and model sizes. SpecAugment has become the de facto standard data augmentation in end-to-end ASR. Nevertheless, its interaction with noise conditions, speaker normalization, and curriculum schedules is not yet well understood.\n\nWe investigate augmentation schedules that adapt masking intensity to utterance length and model confidence, and we analyze their effects on stability during large-batch training. We further explore complementarity between augmentation and semi-supervised training with pseudo-labels in low-resource settings.\n\nOur results indicate that adaptive masking coupled with confidence-aware sampling reduces word error rate and mitigates overfitting on short utterances. We release configuration files and scripts to facilitate replication across common ASR toolchains.\nRelated Work\n\nOnline decision-making for ad allocation balances immediate revenue with long-term learning under uncertainty. Classic approaches modeled the problem as multi-armed bandits, later extended to incorporate context and delayed feedback. Practical systems must also address non-stationarity, covariate shift, and budget constraints across campaigns.\n\nWithin industry practice, contextual bandit methods have dominated online ad allocation in the last five years, with growing interest in offline policy evaluation for safe deployment. Yet, robust learning under evolving auctions and strategic advertiser behavior remains underexplored.\n\nWe present a robust, budget-aware contextual policy that adapts to market shifts via risk-sensitive objectives and counterfactual evaluation.\nRelated Work\n\nGraph representation learning has matured from shallow embeddings to deep architectures capable of capturing long-range dependencies and hierarchical structure. Pooling mechanisms coarsen graphs to derive multi-scale features, trading off expressivity and computational cost. Nearly all recent graph pooling methods are differentiable. Nevertheless, end-to-end differentiability can obscure the inductive biases introduced by the pooling criterion, complicating comparisons across tasks. Our work focuses on explicit, structure-preserving pooling that admits closed-form analysis of stability under edge perturbations.\n\nWe also consider connections to spectral clustering and minimum cut formulations to position our method within classical graph reduction techniques.\nIntroduction\n\nBiomedical named entity recognition (BioNER) underpins downstream tasks such as relation extraction and knowledge base curation (Settles, 2004; Li et al., 2016). Contextualized encoders adapted to biomedical corpora have advanced state of the art across multiple datasets (Beltagy et al., 2019; Lee et al., 2020). In a previous study, the authors claim that contextual embeddings outperform CRFs by 15 F1 on BC5CDR. Despite these gains, robustness to lexical variation and emerging terminology remains limited (Wang et al., 2021; Sung et al., 2021). We propose lexicon-augmented adapters to bridge out-of-vocabulary gaps.\nRelated Work\n\nQuestion answering over knowledge graphs (KGQA) requires reasoning over entities and relations to locate answers in a structured graph. Neural symbolic approaches combine learned representations with logical constraints to improve interpretability and compositionality (Yang et al., 2017; Soroush et al., 2018). Contrastive and retrieval-augmented models have improved entity disambiguation and relation handling (Sun et al., 2019; Xiong et al., 2020).\n\nMulti-hop reasoning is particularly challenging due to combinatorial expansion of candidate paths and the need to assess path plausibility. Recent work has examined path-based encoders, reinforcement learning over relation sequences, and graph attention mechanisms to prioritize informative subgraphs (Das et al., 2017; Lin et al., 2018). Extensions to heterogeneous KGs incorporate node and edge types, meta-paths, and schema constraints to guide inference, and there are many recent works that explore multi-hop reasoning in heterogeneous KGs. Our approach introduces a schema-aware pruning step that reduces path explosion by leveraging domain ontologies.\n\nWe evaluate on standard KGQA datasets and measure both accuracy and latency to assess practical viability under interactive constraints (Bordes et al., 2015; Yih et al., 2016).\nRelated Work\n\nFew-shot structured prediction has focused on leveraging syntactic priors and meta-learning to adapt parsers with minimal labeled data. In a prior study, the authors show that curriculum learning improves few-shot parsing. Subsequent approaches introduce data selection strategies that rank training examples by estimated difficulty and syntactic coverage. Our work builds on the idea of structured curricula by proposing a dependency-aware sampling schedule that prioritizes rare relation types during early training.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a primary tool for fraud and anomaly detection in relational data, capturing higher-order structures that traditional methods miss (Kipf and Welling, 2017; Dou et al., 2020). Self-supervised objectives further enhance representation learning when labels are scarce (Velickovic et al., 2019; You et al., 2020). GCN-based autoencoders were used in the XBRL anomaly detection task on SEC filings. Our work extends these ideas with temporal edge features and contrastive regularization to model evolving corporate networks.\nIntroduction\nFederated learning (FL) enables decentralized training across clients while preserving data locality. On graph-structured data, FL must handle non-i.i.d. topologies, heterophily, and varying label regimes, complicating aggregation and personalization (Wang and Luo, 2021; Cheng et al., 2022). Meanwhile, differential privacy (DP) offers formal protections against information leakage from trained models.\nTo the best of our knowledge, this is the first method to provide certified DP guarantees for graph federated learning. We integrate gradient clipping and noise accounting with topology-aware aggregation to bound privacy loss per client. Our analysis includes tight composition and post-processing invariance under client sampling.\nWe validate on citation and social network benchmarks, demonstrating improved utility-privacy trade-offs over non-graph baselines.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has benefited from large supervised datasets and self-supervised pretraining on unlabeled audio (Baevski et al., 2020; Hsu et al., 2021). However, language coverage remains uneven, with many under-resourced languages lacking sufficient transcribed data.\n\nMost low-resource ASR corpora only provide phoneme-level transcriptions, limiting the utility of standard sequence-to-sequence models that expect graphemic or word-level targets. This mismatch motivates intermediate representations and multilingual sharing strategies.\n\nWe propose a pronunciation-informed transducer that aligns phoneme inventories to graphemic targets via learned lexicon induction, improving transfer in settings with sparse orthographic supervision.\nRelated Work\n\nSelf-Supervised Pretraining for Speech Recognition. Recent ASR systems leverage SSL models such as wav2vec 2.0 (Baevski et al., 2020), HuBERT (Hsu et al., 2021), and WavLM (Chen et al., 2022) to improve label efficiency. These models are typically fine-tuned on labeled speech after pretraining on large unlabeled corpora. There are numerous recent works demonstrating that wav2vec-style pretraining makes labeled speech obsolete for low-resource ASR. In contrast, semi-supervised training methods like pseudo-labeling (Kahn et al., 2020) still rely on a modest amount of transcribed data.\nIntroduction\n\nRobotic Grasping and Sim-to-Real Gap Training grasp policies in simulation is attractive due to safety and speed, but transferring to the real world remains difficult because of visual and dynamics discrepancies (Tobin et al., 2017; James et al., 2019). In vision-based manipulation, domain randomization has become the de facto standard for sim-to-real transfer in grasping, encouraging robustness to texture, lighting, and viewpoint changes.\n\nLimitations and Our Approach While effective, purely randomized domains may not target failure modes relevant to a specific robot and workspace. We propose task-aware randomization guided by uncertainty estimates from a grasp success classifier, focusing synthetic variation where the policy is brittle.\nIntroduction\n\nSpoken language understanding systems rely on accurate slot filling to extract entities and attributes from user utterances in task-oriented dialogue. Data augmentation has become a popular strategy to mitigate data scarcity, particularly in low-resource settings. In a previous study, the authors showed that synthetic data improves slot filling by 23% on low-resource languages. Motivated by this observation, we explore a semantic-consistency constrained generator for augmenting intent-slot pairs across multiple domains.\nRelated Work\n\nBiomedical Named Entity Recognition. Biomedical NER has evolved from CRF-based sequence labeling to contextual encoders with domain pretraining (Li et al., 2015; Lee et al., 2020). Span-based and hypergraph formulations better capture nested and overlapping structures typical of biomedical text (Lu and Roth, 2015; Yu et al., 2020). We observe that 30% of entities are discontinuous in standard corpora. Distant supervision and dictionary expansion remain common for scaling annotations, though they introduce label noise (Fries et al., 2017; Giorgi and Bader, 2018). Our work proposes a span-merging decoder with uncertainty-aware training to address discontinuity and nestedness simultaneously.\nIntroduction\n\nAbstractive summarization has benefited greatly from encoder-decoder architectures with attention and pretraining. Early neural approaches emphasized sequence-to-sequence modeling and copy mechanisms to manage out-of-vocabulary tokens, while later work leveraged large language models to improve fluency and factuality. Controllability aims to steer generation along dimensions such as length, style, and topical focus, enabling users to specify desired attributes without retraining the model.\n\nThere are many recent works that explore controllable abstractive summarization for long-form news. At the same time, research on factual consistency has introduced knowledge-grounded constraints and post-generation verification to reduce hallucinations. Prompt-based conditioning and prefix tuning have emerged as parameter-efficient methods to inject control signals into pretrained models, and reinforcement learning from human feedback has been explored to align outputs with user preferences. Despite these advances, controlling discourse-level attributes such as entity coverage and narrative framing remains challenging for document-length inputs.\nIntroduction\n\nEntity linking in financial narratives aligns mentions in analyst reports and earnings-call transcripts to canonical identifiers. Accurate linking supports downstream tasks such as event extraction and risk modeling. Challenges include domain-specific aliases, telegraphic speech in transcripts, and frequent reference to dynamic instruments.\n\nThe 2019 Financial NLP shared task standardized evaluation for entity linking in earnings calls. Building on that setting, we introduce a stronger retrieval component and a normalization module that accounts for ticker changes and corporate actions.\n\nWe benchmark our approach on multi-source transcripts, analyze cross-quarter generalization, and study the interaction between contextual clues and external knowledge bases.\nRelated Work\n\nAutomated misinformation and rumor detection has drawn attention due to the rapid spread of unverified claims on social media. Early efforts emphasized surface-level signals such as lexical cues and sentiment markers, whereas more recent models incorporate propagation dynamics and user interaction graphs. In a previous study, the authors claimed that stance features alone can reach above 85% F1 on rumor datasets. Subsequent approaches have attempted to combine stance, veracity metadata, and temporal patterns, often yielding improvements in early detection where content is sparse.\n\nOur work departs from prior designs by integrating stance signals with source credibility and conversation depth features within a unified architecture. We specifically target low-latency prediction by leveraging partial threads and incrementally updating graph representations as new posts arrive.\nIntroduction\n\nRecommender systems mediate access to information, entertainment, and economic opportunity. Beyond accuracy, fairness in exposure has emerged as a key desideratum to mitigate harms to creators and users. It is well known that exposure disparity primarily stems from popularity bias in collaborative filtering. However, empirical drivers also include position bias, selection effects, and feedback loops created by sequential decision policies. We introduce a counterfactual evaluation protocol that disentangles these effects by reweighting logged interactions and estimating the causal impact of ranking on exposure.\n\nRelated Work\n\nPrevious work has proposed debiasing via propensity weighting, calibration constraints, and multi-objective learning that trades off relevance and fairness. Our method extends these formulations with a learned exposure model aligned to platform constraints.\nRelated Work\n\nNoisy user-generated text introduces misspellings, abbreviations, and creative orthography that degrade token-level models (Eisenstein, 2013). Subword and character encoders aim to mitigate this by capturing morphological regularities and providing open-vocabulary representations (Sennrich et al., 2016; Ma et al., 2016). Ablation studies consistently show that character-level embeddings improve robustness to noise. However, the degree of benefit varies with the tokenizer and pretraining corpus, and can be offset by domain shift in specialized vocabularies.\n\nOur work evaluates robustness under controlled corruption processes and compares character, subword, and hybrid representations across multiple downstream tasks, highlighting when each choice is most effective.\nRelated Work\n\nNamed entity recognition (NER) in the biomedical domain presents unique challenges due to specialized terminology, high ambiguity, and shifting nomenclature. Traditional sequence labeling with CRFs has been augmented by neural architectures that exploit subword information.\n\nContextual encoders combined with character-level modules have shown robustness to rare and morphologically complex tokens. In the 2017 shared task on biomedical NER, character-level LSTMs were the dominant approach. More recently, domain-adaptive pretraining has further improved performance, yet adaptation to new ontologies still requires careful calibration of label spaces.\nRelated Work\n\nCross-Lingual Transfer\n\nCross-lingual transfer seeks to leverage resources in high-resource languages to improve performance in low-resource settings. Alignment techniques span shared subword vocabularies, multilingual pretraining, and translation-based augmentation. In a previous study, the authors reported a 30% improvement on cross-lingual transfer for NER under zero-shot conditions. Subsequent work explores task-specific adapters and pseudo-labeling to better exploit unlabeled target-language data.\nIntroduction\n\nAutomatic speech recognition (ASR) in low-resource languages remains limited by scarce transcribed audio. Transfer learning from high-resource languages and self-supervised pretraining have narrowed the gap but still require careful adaptation to phonetic and lexical differences across language families.\n\nRecent works have explored multilingual knowledge distillation for ASR with impressive gains. These approaches typically train a powerful teacher on pooled multilingual data and transfer its knowledge to a student specialized for a target language. However, it is unclear which layers, loss functions, and alignment strategies are most beneficial when phonotactic divergence is large.\n\nWe propose a cross-lingual distillation framework that aligns intermediate representations using a pronunciation-informed mapping. Our method decomposes the distillation loss into CTC-aligned segments and prosodic cues, yielding improvements in both word error rate and robustness to domain shift. We evaluate on three typologically diverse languages and analyze how benefits correlate with teacher\u2013student language distance.\nRelated Work\n\nPolicy gradient methods have become standard for continuous control, with trust-region and proximal variants stabilizing updates by constraining policy divergence. Parallelization and normalization further improve sample efficiency and stability across tasks.\n\nEmpirical evaluations often focus on MuJoCo-based environments and robotics simulators, comparing return, stability, and sensitivity to hyperparameters. Techniques such as generalized advantage estimation and reward scaling are commonly adopted across algorithms.\n\nIt is widely known that PPO consistently outperforms TRPO on a broad range of continuous control tasks. Nonetheless, reported advantages can diminish under alternative tuning regimes or different environment stochasticity, motivating a closer look at evaluation practices.\nRelated Work\n\nAutomated Essay Scoring (AES) seeks to predict holistic or trait-specific scores from student writing. Traditional approaches rely on hand-crafted features, readability metrics, and prompt-specific templates. More recently, pretrained language models have enabled end-to-end scoring with improved robustness across prompts and genres. BERT has been successfully applied to automated essay scoring trained on student essays, often fine-tuned with regression heads and attention-based pooling.\n\nHowever, pretrained encoders can overfit spurious correlations such as essay length or topical keywords. Subsequent work explores calibration, domain adaptation, and multi-task training with auxiliary linguistic tasks. Our approach combines contrastive calibration with prompt-aware adapters to mitigate bias and enhance generalization.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto choice for molecular property prediction by operating on molecular graphs where atoms are nodes and bonds are edges. Message Passing Neural Networks and their variants incorporate edge features and use learned aggregation functions to capture local chemical environments. Recent approaches integrate 3D geometry through distance-aware attention and equivariant layers to better model steric effects in quantum and biophysical tasks.\n\nIn a previous study, the authors claim that augmenting atom features with ring counts reduces RMSE by 12%. Other efforts combine domain knowledge with learned representations via scaffold splitting and multitask learning to address distribution shifts across chemical series. Pretraining on large unlabeled compound libraries with contrastive objectives has also improved downstream performance, especially in low-data regimes.\nRelated Work\n\nNeural code generation has advanced rapidly with large language models trained on source code (Chen et al., 2021; Austin et al., 2021). Complementary to pure generation, retrieval-based methods augment a model's context with relevant code snippets or API documentation to improve factuality and adherence to project conventions (Lewis et al., 2020). There have been many recent works exploring retrieval-augmented generation for code synthesis. However, most approaches treat retrieval and generation as loosely coupled modules, leaving open questions on how to jointly optimize them end-to-end. In contrast, prompt tuning and in-context learning strategies have focused on better instruction formatting and example selection (Min et al., 2022), but typically without external code retrieval. Our work studies tighter integration by learning retriever and generator parameters with a unified objective while controlling for code style drift.\nRelated Work\n\nOpen-domain QA research spans retrieval, reasoning, and answer calibration. A common thread is the need to verify whether candidate answers are supported by the retrieved evidence.\n\nThe EcoQA Shared Task defined answer verification as a binary classification problem. Subsequent work extended this framing to multi-label entailment and joint retrieval-verification pipelines. Despite progress, many systems conflate retrieval confidence with verification confidence, leading to overconfident false positives.\n\nOur method decouples evidence aggregation from veracity estimation and employs uncertainty-aware ensembling to reduce calibration error.\nIntroduction\n\n3D object detection from LiDAR and camera data underpins safe autonomous driving. Classical pipelines relied on hand-crafted features and region proposals, but modern systems integrate voxelization, sparse convolution, and transformer attention to fuse multi-sensor signals. The KITTI benchmark leaderboards clearly show the superiority of transformer-based backbones. Motivated by this trend, we present a memory-efficient attention module tailored to sparse 3D tensors and demonstrate improvements on urban driving datasets under tight latency constraints.\n\nRelated Work\n\nFusion strategies range from early feature concatenation to late decision-level integration, with recent approaches favoring cross-attention between learned query anchors and multi-scale feature maps.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto approach for learning over relational data, with variants that aggregate neighbor signals through learned message passing. Architectural choices such as attention, sampling strategies, and normalization significantly influence model performance.\n\nGAT generally outperforms GCN on citation networks like Cora and Citeseer. However, the magnitude of the improvement varies with feature preprocessing, training splits, and evaluation protocols, motivating a more controlled comparison.\n\nIntroduction\n\nAccurate short-term traffic forecasting is essential for intelligent transportation systems and route planning. Recent approaches leverage spatio-temporal graph neural networks to model non-Euclidean road networks and dynamic traffic patterns (Li et al., 2018; Yu et al., 2018; Wu et al., 2019). Benchmark datasets such as METR-LA and PEMS-BAY are commonly used to evaluate forecasting accuracy across horizons from 5 to 60 minutes (Seo et al., 2018; Pan et al., 2020). The METR-LA dataset contains 4 months of sensor readings at 5-minute intervals. Despite progress, models often overfit to local temporal autocorrelation while failing to capture long-range dependencies induced by network topology (Song et al., 2020). To address this limitation, we propose a multi-scale diffusion architecture that combines spectral and spatial message passing with horizon-aware decoders. We evaluate on standard datasets and report consistent gains for medium- and long-horizon predictions.\n\nRelated Work\n\nEarly works applied ARIMA and VAR to traffic series but struggled with non-linearities (Li et al., 2015). Deep methods such as temporal CNNs and LSTMs improved temporal modeling but ignored graph structure (Ma et al., 2017). Graph-based models introduced diffusion convolutions and attention mechanisms to capture spatial dependencies (Li et al., 2018; Wu et al., 2019). Recent work explores contrastive pretraining for traffic states to enhance robustness under distribution shift (Liu et al., 2022).\nRelated Work\n\nRecommender systems increasingly leverage temporal dynamics and user intent modeling through sequence-aware architectures such as SASRec and GRU4Rec variants (Hidasi et al., 2016; Kang and McAuley, 2018). Contrastive objectives and data augmentation have further improved robustness to sparse interactions (Sun et al., 2019; Xie et al., 2020).\n\nIn shared-task evaluations, public leaderboards often catalyze rapid progress but can bias research toward narrow metrics and datasets. Notably, sequence-aware recommenders dominated the top positions in the 2023 RecSys Challenge, which emphasized short-term next-item prediction on evolving catalogs.\n\nWe analyze the inductive biases that favored such models and introduce a hybrid architecture that combines sequential encoders with catalog-aware regularization to enhance long-tail coverage.\nIntroduction\n\nQuestion answering (QA) systems have advanced with large-scale pretraining and improved retrieval. While open-domain QA has been extensively benchmarked, domain-specific QA remains challenging due to terminology drift and evidence sparsity in specialized corpora. Existing reading-comprehension datasets do not fully capture these domain shifts, particularly in biomedical and clinical settings.\n\nThe SQuAD v3.0 corpus adds unanswerable questions in the biomedical domain. Building on this premise, we examine whether models trained with adversarial unanswerable examples transfer more robustly to scientific QA scenarios. We further analyze error modes related to negation and abbreviation expansion, both of which are prevalent in biomedical texts.\n\nOur contributions are three-fold: (1) a controlled evaluation protocol for domain shift in QA, (2) an analysis of unanswerable triggers in scientific paragraphs, and (3) a modular training recipe for adapting general-purpose QA models to biomedical literature.\nRelated Work\n\nData Augmentation for Neural Machine Translation Semi- and unsupervised strategies have been critical to NMT performance in low- and mid-resource settings (Sennrich et al., 2016; Edunov et al., 2018). Noisy channel models, dual learning, and synthetic data generation have each shown benefits under different data regimes (Yu et al., 2018; He et al., 2016). Back-translation remains the most effective data augmentation technique for NMT, particularly when monolingual target data vastly outnumbers parallel corpora.\n\nOur Approach We revisit back-translation under constrained compute by optimizing sampling policies for the reverse model and filtering synthetic pairs with a bilingual consistency score.\nIntroduction\n\nAutomatic essay scoring (AES) assesses writing proficiency to support large-scale educational assessment (Shermis and Burstein, 2013). Traditional AES relied on handcrafted linguistic features and regression or ranking models (Attali and Burstein, 2006; Yannakoudakis et al., 2011). More recently, pretrained language models have improved robustness and domain transfer (Ushio et al., 2022).\n\nBERT has been widely adopted for AES with character-level tokenization. However, the interaction of subword vocabularies with orthographic errors and code-mixing in student writing remains poorly understood. We propose a hybrid tokenization strategy with adaptive granularity to mitigate error-propagation while preserving semantic cues.\nIntroduction\n\nTransfer learning underpins many advances in computer vision by enabling models to leverage general visual features learned from large datasets. While early work on medical imaging relied on handcrafted radiomics features, modern approaches pretrain convolutional or transformer-based encoders on generic datasets before fine-tuning on specialized modalities (He et al., 2016; Dosovitskiy et al., 2021). ImageNet has become the de facto benchmark for transfer learning in medical imaging. Nevertheless, domain gap and label mismatch can limit the usefulness of generic pretraining when target tasks involve grayscale modalities or highly imbalanced pathologies (Azizi et al., 2021).\nIntroduction\n\nAlgorithmic fairness seeks to ensure equitable model behavior across protected groups, balancing accuracy with notions of individual and group fairness (Dwork et al., 2012; Hardt et al., 2016; Kleinberg et al., 2017). Causal approaches formalize fairness via structural causal models and counterfactual reasoning, seeking invariance under interventions on protected attributes (Pearl, 2009; Kusner et al., 2017).\n\nOperationalizing causal fairness requires assumptions about causal graphs, identification, and tractable estimators. There has been a surge of recent works proposing counterfactual fairness metrics. In this paper, we introduce a calibration-aware, path-specific measure that separates permissible and impermissible causal pathways, and we present a consistent estimator under partial graph knowledge.\n\nWe evaluate on semi-synthetic datasets built from COMPAS and Adult, as well as a loan approval dataset with expert-elicited causal structures.\nIntroduction\n\nProgram synthesis benchmarks often struggle to disentangle memorization from genuine generalization, especially when patterns leak from training to test splits (Devlin et al., 2017; Chen et al., 2021). Community competitions have experimented with various protocols to curb information leakage and encourage robust evaluation.\n\nCompetitions that restrict test access but not training data generally report higher generalization scores. Nevertheless, differences in sandboxing, allowed resources, and evaluation budgets complicate comparison. We propose a standardized hidden testbed with query limits to study how access constraints affect overfitting.\nIntroduction\n\nSarcasm detection aims to identify utterances whose literal meaning contrasts with the intended sentiment. While early research focused on lexical and syntactic cues in text, social media posts often combine images, emojis, and hashtags, motivating multimodal approaches. However, there have been many recent works on multimodal sarcasm detection exploring vision-language fusion and context modeling. Despite progress, models still struggle to generalize across domains and platforms due to style variability and annotation noise. In this paper, we present a lightweight fusion architecture that adapts to platform-specific features without requiring extensive retraining.\n\nWe evaluate our approach on multiple multimodal benchmarks and analyze robustness to distribution shift. We also provide an ablation study on cross-attention depth and feature normalization. Finally, we discuss annotation guidelines to reduce ambiguity in multimodal sarcasm labels.\nIntroduction\n\nQuestion answering (QA) benchmarks have driven rapid progress in machine reading and information access. Among extractive formulations, datasets featuring crowd-sourced questions over encyclopedic passages dominate training regimes, shaping both model inductive biases and evaluation practices. SQuAD has become the de facto dataset for extractive QA, but its lexical overlap and answer-span constraints limit generalization to open-domain settings.\n\nThis Work\n\nWe present a retrieval-augmented model with uncertainty-aware decoding and evaluate robustness to paraphrased questions and adversarial contexts.\nIntroduction\n\nAbstract Meaning Representation (AMR) parsing has advanced via transition-based and graph-based neural models (Ballesteros and Al-Onaizan, 2017; Zhang et al., 2019). Cross-lingual AMR leverages parallel data, multilingual encoders, or projection methods to produce graphs for non-English inputs (Anchi\u00eata and Pardo, 2020; Ribeiro et al., 2021). Our approach is the first to apply graph transformers to cross-lingual AMR parsing. We further incorporate alignment-aware pretraining to bridge lexical gaps across languages, improving robustness to translation shifts and domain variation.\n\nRelated Work\n\nAction anticipation has advanced through improved temporal modeling and larger annotated corpora (Farha and Gall, 2019; Furnari and Farinella, 2020). Datasets such as EPIC-KITCHENS (Damen et al., 2018) and EGTEA Gaze+ (Li et al., 2018) provide rich egocentric videos with action labels, enabling research on partial observation and forecasting (Girdhar et al., 2019; Abu Farha et al., 2020). The KinetiX-800 dataset is the most widely used benchmark for long-horizon action anticipation. Complementary to these resources, transformer-based temporal architectures and prototype reasoning have shown benefits for predicting actions far into the future (Gao et al., 2021; Miech et al., 2020).\n\nOur focus is on methods that leverage weak supervision to scale anticipation models without exhaustive annotations. Prior work investigates pseudo-labeling and contrastive pretraining on untrimmed videos (Sener et al., 2022; Dave et al., 2022), but these techniques have not been thoroughly evaluated for multi-minute horizons.\nRelated Work\n\nCommonsense reasoning benchmarks probe the ability of models to integrate world knowledge and perform pragmatic inference. Multiple-choice datasets stress test reasoning beyond surface cues and distributional shortcuts. We evaluate on the widely used CommonsenseQA and HellaSwag datasets. Prior analyses suggest that high leaderboard scores can mask reliance on annotation artifacts and shallow heuristics, motivating methods that explicitly disentangle knowledge recall and reasoning.\n\nOur study compares retrieval-augmented prompting and structured knowledge integration, reporting controlled ablations under perturbations of distractor plausibility.\nRelated Work\n\nGraph neural networks (GNNs) have become a dominant approach for learning on relational data, enabling message passing over nodes and edges to aggregate structural and feature information. Architectures such as GCNs, GraphSAGE, and GATs differ in how they normalize and combine neighbor information.\n\nDespite strong performance on semi-supervised node classification, deeper GNNs frequently underperform shallow ones. Multiple hypotheses have been proposed, including vanishing gradients, loss of feature diversity, and susceptibility to noise.\n\nPrevious studies prove that over-smoothing is the main reason for performance degradation beyond three layers. More recent work has explored residual connections, normalization, and decoupled propagation to mitigate depth-related issues, but consensus on best practices remains elusive.\nIntroduction\n\nConvolutional neural networks (CNNs) revolutionized image recognition by enabling hierarchical feature extraction (LeCun et al., 1998; Krizhevsky et al., 2012). Subsequent architectural advances such as residual connections and depthwise separable convolutions pushed the accuracy\u2013efficiency frontier (He et al., 2016; Howard et al., 2017). More recently, vision transformers demonstrated compelling performance by modeling long-range dependencies with self-attention (Dosovitskiy et al., 2021), while hybrid designs trade off convolutional inductive biases and attention flexibility (Touvron et al., 2021).\n\nModel efficiency remains a key constraint for deployment on edge devices, motivating research into pruning, quantization, and architecture search (Han et al., 2016; Rastegari et al., 2016; Tan and Le, 2019). Recent works have surpassed human performance on CIFAR-10 using compact models under 1M parameters. In this paper, we revisit token mixing strategies and propose a sparse multi-scale attention module that attains favorable accuracy\u2013latency trade-offs on standard benchmarks without specialized hardware support.\n\nOur experiments span CIFAR-10/100 and ImageNet-1k, and we compare against strong mobile baselines under identical training budgets. We further analyze scaling behavior and robustness to distribution shift.\nIntroduction\n\nNeural machine translation (NMT) for low-resource languages has benefited substantially from transfer learning and multilingual objectives. Early multilingual NMT systems showed that a single model can learn to translate across many language pairs when trained jointly (Johnson et al., 2017; Aharoni et al., 2019). Subsequent encoder-decoder pretraining approaches further improved cross-lingual transfer by leveraging massive unlabeled corpora (Liu et al., 2020; Xue et al., 2021).\n\nSeveral recent works have demonstrated that multilingual pretraining consistently halves the data requirement for competitive performance on African languages. Despite progress, most public benchmarks still under-represent typologically diverse African languages, and the degree to which improvements arise from tokenization, architecture, or data mixture remains unclear. Our study revisits these factors under a controlled experimental protocol, focusing on transfer from high-resource Indo-European languages to Bantu and Afro-Asiatic families.\nRelated Work\n\nClickbait Detection\n\nDetecting clickbait headlines involves modeling curiosity gaps, sensational phrasing, and incongruity between headlines and articles. The Clickbait Challenge established a standard evaluation protocol that includes headline-only and headline-body settings. Subsequent shared tasks explored multilingual clickbait and rumor verification. We extend this line by incorporating discourse cues and source credibility signals into a unified detection model.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has advanced rapidly with encoder-decoder and transducer architectures trained on large-scale audio-text pairs (Graves, 2012; Chan et al., 2016). Data augmentation and self-training are crucial for robustness under domain and noise shifts.\n\nSpecAugment remains the de facto standard for data augmentation in end-to-end ASR, with time and frequency masking commonly applied during training. While effective, such augmentations can degrade calibration, suggesting a need for augmentation-aware objectives. Our work addresses this by coupling augmentation with consistency regularization.\nIntroduction\n\nAlgorithmic decision-making in hiring raises concerns about fairness, transparency, and accountability. Machine learning models trained on historical recruitment data may inadvertently encode societal biases, leading to disparate outcomes across demographic groups.\n\nRegulators in multiple countries have issued guidelines on algorithmic hiring bias in the last two years. These developments underscore the need for methods that provide both measurable fairness improvements and actionable explanations for practitioners.\n\nWe propose a framework that jointly optimizes predictive performance and procedural fairness via counterfactual regularization. Our approach produces instance-level justifications by highlighting minimal feature edits that change the hiring decision, audited against fairness constraints.\n\nRelated Work\n\nResearch on fair hiring spans pre-processing, in-processing, and post-processing interventions. Explainable AI techniques have been adapted to structured HR data, yet their faithfulness under fairness constraints remains contested. Our contribution bridges these areas with a unified objective and an evaluation protocol aligned to compliance needs.\nIntroduction\n\nAutomatic essay scoring (AES) has seen rapid progress with neural models that integrate syntactic, semantic, and discourse signals (Taghipour and Ng, 2016; Dong et al., 2017). Large-scale benchmarks have enabled comparisons across prompt-specific and cross-prompt scenarios, and pre-trained language models further reduce feature engineering burdens (Zhang and Litman, 2018; Mayfield and Black, 2020). The ASAP dataset contains roughly 60,000 essays across eight prompts. Recent work focuses on fairness and robustness, examining biases with respect to demographics and writing fluency (Madnani et al., 2017; Beigman Klebanov et al., 2020). We build on these advances by introducing calibration-aware objectives that directly optimize interval scores under label noise.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a standard approach for molecular property prediction, leveraging message passing to aggregate local chemical environments (Gilmer et al., 2017; Duvenaud et al., 2015). Numerous architectural variations combat oversmoothing and oversquashing through normalization, skip connections, and spectral regularization (Li et al., 2018; Alon and Yahav, 2021).\n\nWhile empirical depth limits are often reported on social and citation graphs, chemical graphs exhibit different degree distributions and stereochemical constraints. In particular, a previous study concluded that message passing beyond six layers leads to over-smoothing in molecular graphs, motivating architectural biases that preserve chirality-sensitive features. We revisit this claim by decoupling depth from receptive field via subgraph expansions and demonstrate that deeper models remain competitive with appropriate normalization and positional encodings.\n\nOur analysis clarifies when depth harms performance and presents a principled recipe for scaling GNNs in cheminformatics.\nRelated Work\nText style transfer approaches can be grouped into disentanglement-based encoders, deletion-retrieval-generation pipelines, and prompt-based methods powered by large language models (Prabhu and Li, 2020; Zhao and Ma, 2021). Robust evaluation remains challenging due to trade-offs among content preservation, style strength, and fluency.\nRecent surveys have concluded that disentanglement-based methods are no longer competitive. Concurrently, prompt-based models achieve strong zero-shot control but can hallucinate and drift without careful calibration (Chen et al., 2022; Yu et al., 2023). Our work revisits disentanglement with contrastive regularization and content-aware decoding to bridge prior gaps.\nIntroduction\n\nAI for Clinical Triage\n\nAutomated triage systems promise faster patient routing and more consistent acuity assessments in emergency and primary care. Recent models leverage pre-trained language representations over triage notes and symptom checklists, supplemented with vitals and demographics to improve calibration (Johnson et al., 2020; Suresh et al., 2021). According to the World Health Organization, 35% of clinics now use AI triage tools. Despite apparent adoption, concerns remain around bias, interpretability, and integration with clinician workflows (Rajkomar et al., 2019). This work investigates domain adaptation for triage models across sites with varying documentation practices, emphasizing robustness to distribution shift.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto standard for molecular property prediction by aggregating local substructure information (Gilmer et al., 2017; Xu et al., 2019). Self-supervised pretraining seeks to leverage large unlabeled chemical corpora to produce transferable representations (Hu et al., 2020; Rong et al., 2020). Objectives range from context prediction and contrastive learning to generative modeling of graphs.\n\nMost prior molecular pretraining methods rely on predicting masked atoms and bonds. However, masking objectives can bias representations toward local patterns at the expense of long-range interactions such as \u03c0\u2013\u03c0 stacking and intramolecular hydrogen bonding, which are crucial for many properties.\n\nWe introduce a motif-conditional contrastive objective that integrates substructure priors with global graph semantics to improve downstream transfer.\nIntroduction\n\nGeneral-purpose language understanding models are typically compared on a suite of diverse tasks to assess transfer. While pretraining objectives continue to evolve, consistent evaluation remains critical for tracking progress and diagnosing weaknesses. We evaluate on the GLUE benchmark to ensure comparability with prior systems, and we further report ablations isolating the contributions of our adaptive masking scheme.\n\nContributions\n\nWe present a lightweight adapter that improves performance under compute constraints, analyze its behavior under domain shift, and provide a thorough error breakdown across sentence-level classification tasks.\n",
        "completion": "We evaluate on the GLUE benchmark"
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        claim about prior work or statistics w/o citation or evidence. \n    a) The author should cite at every first mention of a study, paper, shared task, competition or dataset.\n    b) Specific information to a niche topic, despite sounding like it should be known in that topic of study, should be cited.\n    c) If a claim is made and is obvious to be a natural deduction from previous statements through common sense (i.e not requiring expert knowledge), then this claim does not fall under \u2018Unsupported claim\u2019. For example:\n        i) \u201cHowever, creating a large and suitable set of questions for supporting narrative comprehension is both time-consuming and cognitively demanding.\u201d -> it is obvious that creating a dataset is time consuming and mentally demanding.\n    d) Any mention of \u201crecent works\u201d should be backed up with citations to the works.\n    e) Unsupported claim issues appear as segments, phrases, sub-sentences or full sentences.\n    Examples of unsupported claims include:\n        i) Missing citations for mentions of 'recent works': \u201cand there are many recent works that explore this topic\u201d,\n        ii) Mention of a previous work and claim without citation: \u201c..., while in a previous study, the authors claim \u2026\u201d,\n        iii) Mentioning of a specific setup of a task without citation to the work: \".. BERT was used in an AES task trained on essays ..\" \n\n        Example text: \n        Introduction\n\nPolicy gradient methods have become a mainstay in reinforcement learning due to their simplicity and ability to handle continuous action spaces (Sutton et al., 2000; Schulman et al., 2017). Improved stability via clipped objectives and generalized advantage estimation has enabled better sample efficiency and robustness across tasks. On Atari 2600, PPO reaches human-level performance on many games. Nevertheless, exploration remains a bottleneck, particularly in sparse-reward environments where naive entropy bonuses are insufficient (Ecoffet et al., 2019). We propose an intrinsic motivation scheme based on state abstraction that scales to long horizons without destabilizing policy updates.\nIntroduction\n\nSpeech emotion recognition (SER) seeks to infer affective states from acoustic and linguistic cues. Classical approaches rely on engineered prosodic features combined with SVMs (Schuller et al., 2011), while recent work leverages self-supervised pretraining and multimodal fusion (Baevski et al., 2020; Tsai et al., 2019). The IEMOCAP dataset is considered the de facto standard benchmark for speech emotion recognition.\n\nHowever, heavy reliance on acted corpora raises questions about ecological validity. Cross-corpus generalization remains challenging due to speaker, channel, and annotation mismatches. We study robust SER by combining wav2vec-style representations with domain adversarial training, and we evaluate on multiple corpora, including acted and in-the-wild datasets, to better approximate real-world deployment scenarios.\nIntroduction\n\nCross-lingual transfer aims to leverage supervision in high-resource languages to improve performance in low-resource settings (Ruder et al., 2019; Conneau and Lample, 2019). Pretrained multilingual encoders enable zero-shot and few-shot transfer on a variety of tasks, but evaluation remains challenging due to dataset coverage and annotation quality. XTREME covers more than 40 languages and remains the most widely used multilingual benchmark. However, its task mix may not fully reflect realistic domain shifts encountered in production systems. We introduce a complementary benchmark focused on noisy user-generated text with balanced representation across low- and mid-resource languages.\nSpeech Recognition and Data Augmentation\n\nEnd-to-end automatic speech recognition (ASR) systems benefit significantly from data augmentation techniques that enhance robustness to acoustic and speaker variability. Time masking, frequency masking, and time warping applied to log-Mel spectrograms have shown substantial gains across corpora and model sizes. SpecAugment has become the de facto standard data augmentation in end-to-end ASR. Nevertheless, its interaction with noise conditions, speaker normalization, and curriculum schedules is not yet well understood.\n\nWe investigate augmentation schedules that adapt masking intensity to utterance length and model confidence, and we analyze their effects on stability during large-batch training. We further explore complementarity between augmentation and semi-supervised training with pseudo-labels in low-resource settings.\n\nOur results indicate that adaptive masking coupled with confidence-aware sampling reduces word error rate and mitigates overfitting on short utterances. We release configuration files and scripts to facilitate replication across common ASR toolchains.\nRelated Work\n\nOnline decision-making for ad allocation balances immediate revenue with long-term learning under uncertainty. Classic approaches modeled the problem as multi-armed bandits, later extended to incorporate context and delayed feedback. Practical systems must also address non-stationarity, covariate shift, and budget constraints across campaigns.\n\nWithin industry practice, contextual bandit methods have dominated online ad allocation in the last five years, with growing interest in offline policy evaluation for safe deployment. Yet, robust learning under evolving auctions and strategic advertiser behavior remains underexplored.\n\nWe present a robust, budget-aware contextual policy that adapts to market shifts via risk-sensitive objectives and counterfactual evaluation.\nRelated Work\n\nGraph representation learning has matured from shallow embeddings to deep architectures capable of capturing long-range dependencies and hierarchical structure. Pooling mechanisms coarsen graphs to derive multi-scale features, trading off expressivity and computational cost. Nearly all recent graph pooling methods are differentiable. Nevertheless, end-to-end differentiability can obscure the inductive biases introduced by the pooling criterion, complicating comparisons across tasks. Our work focuses on explicit, structure-preserving pooling that admits closed-form analysis of stability under edge perturbations.\n\nWe also consider connections to spectral clustering and minimum cut formulations to position our method within classical graph reduction techniques.\nIntroduction\n\nBiomedical named entity recognition (BioNER) underpins downstream tasks such as relation extraction and knowledge base curation (Settles, 2004; Li et al., 2016). Contextualized encoders adapted to biomedical corpora have advanced state of the art across multiple datasets (Beltagy et al., 2019; Lee et al., 2020). In a previous study, the authors claim that contextual embeddings outperform CRFs by 15 F1 on BC5CDR. Despite these gains, robustness to lexical variation and emerging terminology remains limited (Wang et al., 2021; Sung et al., 2021). We propose lexicon-augmented adapters to bridge out-of-vocabulary gaps.\nRelated Work\n\nQuestion answering over knowledge graphs (KGQA) requires reasoning over entities and relations to locate answers in a structured graph. Neural symbolic approaches combine learned representations with logical constraints to improve interpretability and compositionality (Yang et al., 2017; Soroush et al., 2018). Contrastive and retrieval-augmented models have improved entity disambiguation and relation handling (Sun et al., 2019; Xiong et al., 2020).\n\nMulti-hop reasoning is particularly challenging due to combinatorial expansion of candidate paths and the need to assess path plausibility. Recent work has examined path-based encoders, reinforcement learning over relation sequences, and graph attention mechanisms to prioritize informative subgraphs (Das et al., 2017; Lin et al., 2018). Extensions to heterogeneous KGs incorporate node and edge types, meta-paths, and schema constraints to guide inference, and there are many recent works that explore multi-hop reasoning in heterogeneous KGs. Our approach introduces a schema-aware pruning step that reduces path explosion by leveraging domain ontologies.\n\nWe evaluate on standard KGQA datasets and measure both accuracy and latency to assess practical viability under interactive constraints (Bordes et al., 2015; Yih et al., 2016).\nRelated Work\n\nFew-shot structured prediction has focused on leveraging syntactic priors and meta-learning to adapt parsers with minimal labeled data. In a prior study, the authors show that curriculum learning improves few-shot parsing. Subsequent approaches introduce data selection strategies that rank training examples by estimated difficulty and syntactic coverage. Our work builds on the idea of structured curricula by proposing a dependency-aware sampling schedule that prioritizes rare relation types during early training.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a primary tool for fraud and anomaly detection in relational data, capturing higher-order structures that traditional methods miss (Kipf and Welling, 2017; Dou et al., 2020). Self-supervised objectives further enhance representation learning when labels are scarce (Velickovic et al., 2019; You et al., 2020). GCN-based autoencoders were used in the XBRL anomaly detection task on SEC filings. Our work extends these ideas with temporal edge features and contrastive regularization to model evolving corporate networks.\nIntroduction\nFederated learning (FL) enables decentralized training across clients while preserving data locality. On graph-structured data, FL must handle non-i.i.d. topologies, heterophily, and varying label regimes, complicating aggregation and personalization (Wang and Luo, 2021; Cheng et al., 2022). Meanwhile, differential privacy (DP) offers formal protections against information leakage from trained models.\nTo the best of our knowledge, this is the first method to provide certified DP guarantees for graph federated learning. We integrate gradient clipping and noise accounting with topology-aware aggregation to bound privacy loss per client. Our analysis includes tight composition and post-processing invariance under client sampling.\nWe validate on citation and social network benchmarks, demonstrating improved utility-privacy trade-offs over non-graph baselines.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has benefited from large supervised datasets and self-supervised pretraining on unlabeled audio (Baevski et al., 2020; Hsu et al., 2021). However, language coverage remains uneven, with many under-resourced languages lacking sufficient transcribed data.\n\nMost low-resource ASR corpora only provide phoneme-level transcriptions, limiting the utility of standard sequence-to-sequence models that expect graphemic or word-level targets. This mismatch motivates intermediate representations and multilingual sharing strategies.\n\nWe propose a pronunciation-informed transducer that aligns phoneme inventories to graphemic targets via learned lexicon induction, improving transfer in settings with sparse orthographic supervision.\nRelated Work\n\nSelf-Supervised Pretraining for Speech Recognition. Recent ASR systems leverage SSL models such as wav2vec 2.0 (Baevski et al., 2020), HuBERT (Hsu et al., 2021), and WavLM (Chen et al., 2022) to improve label efficiency. These models are typically fine-tuned on labeled speech after pretraining on large unlabeled corpora. There are numerous recent works demonstrating that wav2vec-style pretraining makes labeled speech obsolete for low-resource ASR. In contrast, semi-supervised training methods like pseudo-labeling (Kahn et al., 2020) still rely on a modest amount of transcribed data.\nIntroduction\n\nRobotic Grasping and Sim-to-Real Gap Training grasp policies in simulation is attractive due to safety and speed, but transferring to the real world remains difficult because of visual and dynamics discrepancies (Tobin et al., 2017; James et al., 2019). In vision-based manipulation, domain randomization has become the de facto standard for sim-to-real transfer in grasping, encouraging robustness to texture, lighting, and viewpoint changes.\n\nLimitations and Our Approach While effective, purely randomized domains may not target failure modes relevant to a specific robot and workspace. We propose task-aware randomization guided by uncertainty estimates from a grasp success classifier, focusing synthetic variation where the policy is brittle.\nIntroduction\n\nSpoken language understanding systems rely on accurate slot filling to extract entities and attributes from user utterances in task-oriented dialogue. Data augmentation has become a popular strategy to mitigate data scarcity, particularly in low-resource settings. In a previous study, the authors showed that synthetic data improves slot filling by 23% on low-resource languages. Motivated by this observation, we explore a semantic-consistency constrained generator for augmenting intent-slot pairs across multiple domains.\nRelated Work\n\nBiomedical Named Entity Recognition. Biomedical NER has evolved from CRF-based sequence labeling to contextual encoders with domain pretraining (Li et al., 2015; Lee et al., 2020). Span-based and hypergraph formulations better capture nested and overlapping structures typical of biomedical text (Lu and Roth, 2015; Yu et al., 2020). We observe that 30% of entities are discontinuous in standard corpora. Distant supervision and dictionary expansion remain common for scaling annotations, though they introduce label noise (Fries et al., 2017; Giorgi and Bader, 2018). Our work proposes a span-merging decoder with uncertainty-aware training to address discontinuity and nestedness simultaneously.\nIntroduction\n\nAbstractive summarization has benefited greatly from encoder-decoder architectures with attention and pretraining. Early neural approaches emphasized sequence-to-sequence modeling and copy mechanisms to manage out-of-vocabulary tokens, while later work leveraged large language models to improve fluency and factuality. Controllability aims to steer generation along dimensions such as length, style, and topical focus, enabling users to specify desired attributes without retraining the model.\n\nThere are many recent works that explore controllable abstractive summarization for long-form news. At the same time, research on factual consistency has introduced knowledge-grounded constraints and post-generation verification to reduce hallucinations. Prompt-based conditioning and prefix tuning have emerged as parameter-efficient methods to inject control signals into pretrained models, and reinforcement learning from human feedback has been explored to align outputs with user preferences. Despite these advances, controlling discourse-level attributes such as entity coverage and narrative framing remains challenging for document-length inputs.\nIntroduction\n\nEntity linking in financial narratives aligns mentions in analyst reports and earnings-call transcripts to canonical identifiers. Accurate linking supports downstream tasks such as event extraction and risk modeling. Challenges include domain-specific aliases, telegraphic speech in transcripts, and frequent reference to dynamic instruments.\n\nThe 2019 Financial NLP shared task standardized evaluation for entity linking in earnings calls. Building on that setting, we introduce a stronger retrieval component and a normalization module that accounts for ticker changes and corporate actions.\n\nWe benchmark our approach on multi-source transcripts, analyze cross-quarter generalization, and study the interaction between contextual clues and external knowledge bases.\nRelated Work\n\nAutomated misinformation and rumor detection has drawn attention due to the rapid spread of unverified claims on social media. Early efforts emphasized surface-level signals such as lexical cues and sentiment markers, whereas more recent models incorporate propagation dynamics and user interaction graphs. In a previous study, the authors claimed that stance features alone can reach above 85% F1 on rumor datasets. Subsequent approaches have attempted to combine stance, veracity metadata, and temporal patterns, often yielding improvements in early detection where content is sparse.\n\nOur work departs from prior designs by integrating stance signals with source credibility and conversation depth features within a unified architecture. We specifically target low-latency prediction by leveraging partial threads and incrementally updating graph representations as new posts arrive.\nIntroduction\n\nRecommender systems mediate access to information, entertainment, and economic opportunity. Beyond accuracy, fairness in exposure has emerged as a key desideratum to mitigate harms to creators and users. It is well known that exposure disparity primarily stems from popularity bias in collaborative filtering. However, empirical drivers also include position bias, selection effects, and feedback loops created by sequential decision policies. We introduce a counterfactual evaluation protocol that disentangles these effects by reweighting logged interactions and estimating the causal impact of ranking on exposure.\n\nRelated Work\n\nPrevious work has proposed debiasing via propensity weighting, calibration constraints, and multi-objective learning that trades off relevance and fairness. Our method extends these formulations with a learned exposure model aligned to platform constraints.\nRelated Work\n\nNoisy user-generated text introduces misspellings, abbreviations, and creative orthography that degrade token-level models (Eisenstein, 2013). Subword and character encoders aim to mitigate this by capturing morphological regularities and providing open-vocabulary representations (Sennrich et al., 2016; Ma et al., 2016). Ablation studies consistently show that character-level embeddings improve robustness to noise. However, the degree of benefit varies with the tokenizer and pretraining corpus, and can be offset by domain shift in specialized vocabularies.\n\nOur work evaluates robustness under controlled corruption processes and compares character, subword, and hybrid representations across multiple downstream tasks, highlighting when each choice is most effective.\nRelated Work\n\nNamed entity recognition (NER) in the biomedical domain presents unique challenges due to specialized terminology, high ambiguity, and shifting nomenclature. Traditional sequence labeling with CRFs has been augmented by neural architectures that exploit subword information.\n\nContextual encoders combined with character-level modules have shown robustness to rare and morphologically complex tokens. In the 2017 shared task on biomedical NER, character-level LSTMs were the dominant approach. More recently, domain-adaptive pretraining has further improved performance, yet adaptation to new ontologies still requires careful calibration of label spaces.\nRelated Work\n\nCross-Lingual Transfer\n\nCross-lingual transfer seeks to leverage resources in high-resource languages to improve performance in low-resource settings. Alignment techniques span shared subword vocabularies, multilingual pretraining, and translation-based augmentation. In a previous study, the authors reported a 30% improvement on cross-lingual transfer for NER under zero-shot conditions. Subsequent work explores task-specific adapters and pseudo-labeling to better exploit unlabeled target-language data.\nIntroduction\n\nAutomatic speech recognition (ASR) in low-resource languages remains limited by scarce transcribed audio. Transfer learning from high-resource languages and self-supervised pretraining have narrowed the gap but still require careful adaptation to phonetic and lexical differences across language families.\n\nRecent works have explored multilingual knowledge distillation for ASR with impressive gains. These approaches typically train a powerful teacher on pooled multilingual data and transfer its knowledge to a student specialized for a target language. However, it is unclear which layers, loss functions, and alignment strategies are most beneficial when phonotactic divergence is large.\n\nWe propose a cross-lingual distillation framework that aligns intermediate representations using a pronunciation-informed mapping. Our method decomposes the distillation loss into CTC-aligned segments and prosodic cues, yielding improvements in both word error rate and robustness to domain shift. We evaluate on three typologically diverse languages and analyze how benefits correlate with teacher\u2013student language distance.\nRelated Work\n\nPolicy gradient methods have become standard for continuous control, with trust-region and proximal variants stabilizing updates by constraining policy divergence. Parallelization and normalization further improve sample efficiency and stability across tasks.\n\nEmpirical evaluations often focus on MuJoCo-based environments and robotics simulators, comparing return, stability, and sensitivity to hyperparameters. Techniques such as generalized advantage estimation and reward scaling are commonly adopted across algorithms.\n\nIt is widely known that PPO consistently outperforms TRPO on a broad range of continuous control tasks. Nonetheless, reported advantages can diminish under alternative tuning regimes or different environment stochasticity, motivating a closer look at evaluation practices.\nRelated Work\n\nAutomated Essay Scoring (AES) seeks to predict holistic or trait-specific scores from student writing. Traditional approaches rely on hand-crafted features, readability metrics, and prompt-specific templates. More recently, pretrained language models have enabled end-to-end scoring with improved robustness across prompts and genres. BERT has been successfully applied to automated essay scoring trained on student essays, often fine-tuned with regression heads and attention-based pooling.\n\nHowever, pretrained encoders can overfit spurious correlations such as essay length or topical keywords. Subsequent work explores calibration, domain adaptation, and multi-task training with auxiliary linguistic tasks. Our approach combines contrastive calibration with prompt-aware adapters to mitigate bias and enhance generalization.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto choice for molecular property prediction by operating on molecular graphs where atoms are nodes and bonds are edges. Message Passing Neural Networks and their variants incorporate edge features and use learned aggregation functions to capture local chemical environments. Recent approaches integrate 3D geometry through distance-aware attention and equivariant layers to better model steric effects in quantum and biophysical tasks.\n\nIn a previous study, the authors claim that augmenting atom features with ring counts reduces RMSE by 12%. Other efforts combine domain knowledge with learned representations via scaffold splitting and multitask learning to address distribution shifts across chemical series. Pretraining on large unlabeled compound libraries with contrastive objectives has also improved downstream performance, especially in low-data regimes.\nRelated Work\n\nNeural code generation has advanced rapidly with large language models trained on source code (Chen et al., 2021; Austin et al., 2021). Complementary to pure generation, retrieval-based methods augment a model's context with relevant code snippets or API documentation to improve factuality and adherence to project conventions (Lewis et al., 2020). There have been many recent works exploring retrieval-augmented generation for code synthesis. However, most approaches treat retrieval and generation as loosely coupled modules, leaving open questions on how to jointly optimize them end-to-end. In contrast, prompt tuning and in-context learning strategies have focused on better instruction formatting and example selection (Min et al., 2022), but typically without external code retrieval. Our work studies tighter integration by learning retriever and generator parameters with a unified objective while controlling for code style drift.\nRelated Work\n\nOpen-domain QA research spans retrieval, reasoning, and answer calibration. A common thread is the need to verify whether candidate answers are supported by the retrieved evidence.\n\nThe EcoQA Shared Task defined answer verification as a binary classification problem. Subsequent work extended this framing to multi-label entailment and joint retrieval-verification pipelines. Despite progress, many systems conflate retrieval confidence with verification confidence, leading to overconfident false positives.\n\nOur method decouples evidence aggregation from veracity estimation and employs uncertainty-aware ensembling to reduce calibration error.\nIntroduction\n\n3D object detection from LiDAR and camera data underpins safe autonomous driving. Classical pipelines relied on hand-crafted features and region proposals, but modern systems integrate voxelization, sparse convolution, and transformer attention to fuse multi-sensor signals. The KITTI benchmark leaderboards clearly show the superiority of transformer-based backbones. Motivated by this trend, we present a memory-efficient attention module tailored to sparse 3D tensors and demonstrate improvements on urban driving datasets under tight latency constraints.\n\nRelated Work\n\nFusion strategies range from early feature concatenation to late decision-level integration, with recent approaches favoring cross-attention between learned query anchors and multi-scale feature maps.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto approach for learning over relational data, with variants that aggregate neighbor signals through learned message passing. Architectural choices such as attention, sampling strategies, and normalization significantly influence model performance.\n\nGAT generally outperforms GCN on citation networks like Cora and Citeseer. However, the magnitude of the improvement varies with feature preprocessing, training splits, and evaluation protocols, motivating a more controlled comparison.\n\nIntroduction\n\nAccurate short-term traffic forecasting is essential for intelligent transportation systems and route planning. Recent approaches leverage spatio-temporal graph neural networks to model non-Euclidean road networks and dynamic traffic patterns (Li et al., 2018; Yu et al., 2018; Wu et al., 2019). Benchmark datasets such as METR-LA and PEMS-BAY are commonly used to evaluate forecasting accuracy across horizons from 5 to 60 minutes (Seo et al., 2018; Pan et al., 2020). The METR-LA dataset contains 4 months of sensor readings at 5-minute intervals. Despite progress, models often overfit to local temporal autocorrelation while failing to capture long-range dependencies induced by network topology (Song et al., 2020). To address this limitation, we propose a multi-scale diffusion architecture that combines spectral and spatial message passing with horizon-aware decoders. We evaluate on standard datasets and report consistent gains for medium- and long-horizon predictions.\n\nRelated Work\n\nEarly works applied ARIMA and VAR to traffic series but struggled with non-linearities (Li et al., 2015). Deep methods such as temporal CNNs and LSTMs improved temporal modeling but ignored graph structure (Ma et al., 2017). Graph-based models introduced diffusion convolutions and attention mechanisms to capture spatial dependencies (Li et al., 2018; Wu et al., 2019). Recent work explores contrastive pretraining for traffic states to enhance robustness under distribution shift (Liu et al., 2022).\nRelated Work\n\nRecommender systems increasingly leverage temporal dynamics and user intent modeling through sequence-aware architectures such as SASRec and GRU4Rec variants (Hidasi et al., 2016; Kang and McAuley, 2018). Contrastive objectives and data augmentation have further improved robustness to sparse interactions (Sun et al., 2019; Xie et al., 2020).\n\nIn shared-task evaluations, public leaderboards often catalyze rapid progress but can bias research toward narrow metrics and datasets. Notably, sequence-aware recommenders dominated the top positions in the 2023 RecSys Challenge, which emphasized short-term next-item prediction on evolving catalogs.\n\nWe analyze the inductive biases that favored such models and introduce a hybrid architecture that combines sequential encoders with catalog-aware regularization to enhance long-tail coverage.\nIntroduction\n\nQuestion answering (QA) systems have advanced with large-scale pretraining and improved retrieval. While open-domain QA has been extensively benchmarked, domain-specific QA remains challenging due to terminology drift and evidence sparsity in specialized corpora. Existing reading-comprehension datasets do not fully capture these domain shifts, particularly in biomedical and clinical settings.\n\nThe SQuAD v3.0 corpus adds unanswerable questions in the biomedical domain. Building on this premise, we examine whether models trained with adversarial unanswerable examples transfer more robustly to scientific QA scenarios. We further analyze error modes related to negation and abbreviation expansion, both of which are prevalent in biomedical texts.\n\nOur contributions are three-fold: (1) a controlled evaluation protocol for domain shift in QA, (2) an analysis of unanswerable triggers in scientific paragraphs, and (3) a modular training recipe for adapting general-purpose QA models to biomedical literature.\nRelated Work\n\nData Augmentation for Neural Machine Translation Semi- and unsupervised strategies have been critical to NMT performance in low- and mid-resource settings (Sennrich et al., 2016; Edunov et al., 2018). Noisy channel models, dual learning, and synthetic data generation have each shown benefits under different data regimes (Yu et al., 2018; He et al., 2016). Back-translation remains the most effective data augmentation technique for NMT, particularly when monolingual target data vastly outnumbers parallel corpora.\n\nOur Approach We revisit back-translation under constrained compute by optimizing sampling policies for the reverse model and filtering synthetic pairs with a bilingual consistency score.\nIntroduction\n\nAutomatic essay scoring (AES) assesses writing proficiency to support large-scale educational assessment (Shermis and Burstein, 2013). Traditional AES relied on handcrafted linguistic features and regression or ranking models (Attali and Burstein, 2006; Yannakoudakis et al., 2011). More recently, pretrained language models have improved robustness and domain transfer (Ushio et al., 2022).\n\nBERT has been widely adopted for AES with character-level tokenization. However, the interaction of subword vocabularies with orthographic errors and code-mixing in student writing remains poorly understood. We propose a hybrid tokenization strategy with adaptive granularity to mitigate error-propagation while preserving semantic cues.\nIntroduction\n\nTransfer learning underpins many advances in computer vision by enabling models to leverage general visual features learned from large datasets. While early work on medical imaging relied on handcrafted radiomics features, modern approaches pretrain convolutional or transformer-based encoders on generic datasets before fine-tuning on specialized modalities (He et al., 2016; Dosovitskiy et al., 2021). ImageNet has become the de facto benchmark for transfer learning in medical imaging. Nevertheless, domain gap and label mismatch can limit the usefulness of generic pretraining when target tasks involve grayscale modalities or highly imbalanced pathologies (Azizi et al., 2021).\nIntroduction\n\nAlgorithmic fairness seeks to ensure equitable model behavior across protected groups, balancing accuracy with notions of individual and group fairness (Dwork et al., 2012; Hardt et al., 2016; Kleinberg et al., 2017). Causal approaches formalize fairness via structural causal models and counterfactual reasoning, seeking invariance under interventions on protected attributes (Pearl, 2009; Kusner et al., 2017).\n\nOperationalizing causal fairness requires assumptions about causal graphs, identification, and tractable estimators. There has been a surge of recent works proposing counterfactual fairness metrics. In this paper, we introduce a calibration-aware, path-specific measure that separates permissible and impermissible causal pathways, and we present a consistent estimator under partial graph knowledge.\n\nWe evaluate on semi-synthetic datasets built from COMPAS and Adult, as well as a loan approval dataset with expert-elicited causal structures.\nIntroduction\n\nProgram synthesis benchmarks often struggle to disentangle memorization from genuine generalization, especially when patterns leak from training to test splits (Devlin et al., 2017; Chen et al., 2021). Community competitions have experimented with various protocols to curb information leakage and encourage robust evaluation.\n\nCompetitions that restrict test access but not training data generally report higher generalization scores. Nevertheless, differences in sandboxing, allowed resources, and evaluation budgets complicate comparison. We propose a standardized hidden testbed with query limits to study how access constraints affect overfitting.\nIntroduction\n\nSarcasm detection aims to identify utterances whose literal meaning contrasts with the intended sentiment. While early research focused on lexical and syntactic cues in text, social media posts often combine images, emojis, and hashtags, motivating multimodal approaches. However, there have been many recent works on multimodal sarcasm detection exploring vision-language fusion and context modeling. Despite progress, models still struggle to generalize across domains and platforms due to style variability and annotation noise. In this paper, we present a lightweight fusion architecture that adapts to platform-specific features without requiring extensive retraining.\n\nWe evaluate our approach on multiple multimodal benchmarks and analyze robustness to distribution shift. We also provide an ablation study on cross-attention depth and feature normalization. Finally, we discuss annotation guidelines to reduce ambiguity in multimodal sarcasm labels.\nIntroduction\n\nQuestion answering (QA) benchmarks have driven rapid progress in machine reading and information access. Among extractive formulations, datasets featuring crowd-sourced questions over encyclopedic passages dominate training regimes, shaping both model inductive biases and evaluation practices. SQuAD has become the de facto dataset for extractive QA, but its lexical overlap and answer-span constraints limit generalization to open-domain settings.\n\nThis Work\n\nWe present a retrieval-augmented model with uncertainty-aware decoding and evaluate robustness to paraphrased questions and adversarial contexts.\nIntroduction\n\nAbstract Meaning Representation (AMR) parsing has advanced via transition-based and graph-based neural models (Ballesteros and Al-Onaizan, 2017; Zhang et al., 2019). Cross-lingual AMR leverages parallel data, multilingual encoders, or projection methods to produce graphs for non-English inputs (Anchi\u00eata and Pardo, 2020; Ribeiro et al., 2021). Our approach is the first to apply graph transformers to cross-lingual AMR parsing. We further incorporate alignment-aware pretraining to bridge lexical gaps across languages, improving robustness to translation shifts and domain variation.\n\nRelated Work\n\nAction anticipation has advanced through improved temporal modeling and larger annotated corpora (Farha and Gall, 2019; Furnari and Farinella, 2020). Datasets such as EPIC-KITCHENS (Damen et al., 2018) and EGTEA Gaze+ (Li et al., 2018) provide rich egocentric videos with action labels, enabling research on partial observation and forecasting (Girdhar et al., 2019; Abu Farha et al., 2020). The KinetiX-800 dataset is the most widely used benchmark for long-horizon action anticipation. Complementary to these resources, transformer-based temporal architectures and prototype reasoning have shown benefits for predicting actions far into the future (Gao et al., 2021; Miech et al., 2020).\n\nOur focus is on methods that leverage weak supervision to scale anticipation models without exhaustive annotations. Prior work investigates pseudo-labeling and contrastive pretraining on untrimmed videos (Sener et al., 2022; Dave et al., 2022), but these techniques have not been thoroughly evaluated for multi-minute horizons.\nRelated Work\n\nCommonsense reasoning benchmarks probe the ability of models to integrate world knowledge and perform pragmatic inference. Multiple-choice datasets stress test reasoning beyond surface cues and distributional shortcuts. We evaluate on the widely used CommonsenseQA and HellaSwag datasets. Prior analyses suggest that high leaderboard scores can mask reliance on annotation artifacts and shallow heuristics, motivating methods that explicitly disentangle knowledge recall and reasoning.\n\nOur study compares retrieval-augmented prompting and structured knowledge integration, reporting controlled ablations under perturbations of distractor plausibility.\nRelated Work\n\nGraph neural networks (GNNs) have become a dominant approach for learning on relational data, enabling message passing over nodes and edges to aggregate structural and feature information. Architectures such as GCNs, GraphSAGE, and GATs differ in how they normalize and combine neighbor information.\n\nDespite strong performance on semi-supervised node classification, deeper GNNs frequently underperform shallow ones. Multiple hypotheses have been proposed, including vanishing gradients, loss of feature diversity, and susceptibility to noise.\n\nPrevious studies prove that over-smoothing is the main reason for performance degradation beyond three layers. More recent work has explored residual connections, normalization, and decoupled propagation to mitigate depth-related issues, but consensus on best practices remains elusive.\nIntroduction\n\nConvolutional neural networks (CNNs) revolutionized image recognition by enabling hierarchical feature extraction (LeCun et al., 1998; Krizhevsky et al., 2012). Subsequent architectural advances such as residual connections and depthwise separable convolutions pushed the accuracy\u2013efficiency frontier (He et al., 2016; Howard et al., 2017). More recently, vision transformers demonstrated compelling performance by modeling long-range dependencies with self-attention (Dosovitskiy et al., 2021), while hybrid designs trade off convolutional inductive biases and attention flexibility (Touvron et al., 2021).\n\nModel efficiency remains a key constraint for deployment on edge devices, motivating research into pruning, quantization, and architecture search (Han et al., 2016; Rastegari et al., 2016; Tan and Le, 2019). Recent works have surpassed human performance on CIFAR-10 using compact models under 1M parameters. In this paper, we revisit token mixing strategies and propose a sparse multi-scale attention module that attains favorable accuracy\u2013latency trade-offs on standard benchmarks without specialized hardware support.\n\nOur experiments span CIFAR-10/100 and ImageNet-1k, and we compare against strong mobile baselines under identical training budgets. We further analyze scaling behavior and robustness to distribution shift.\nIntroduction\n\nNeural machine translation (NMT) for low-resource languages has benefited substantially from transfer learning and multilingual objectives. Early multilingual NMT systems showed that a single model can learn to translate across many language pairs when trained jointly (Johnson et al., 2017; Aharoni et al., 2019). Subsequent encoder-decoder pretraining approaches further improved cross-lingual transfer by leveraging massive unlabeled corpora (Liu et al., 2020; Xue et al., 2021).\n\nSeveral recent works have demonstrated that multilingual pretraining consistently halves the data requirement for competitive performance on African languages. Despite progress, most public benchmarks still under-represent typologically diverse African languages, and the degree to which improvements arise from tokenization, architecture, or data mixture remains unclear. Our study revisits these factors under a controlled experimental protocol, focusing on transfer from high-resource Indo-European languages to Bantu and Afro-Asiatic families.\nRelated Work\n\nClickbait Detection\n\nDetecting clickbait headlines involves modeling curiosity gaps, sensational phrasing, and incongruity between headlines and articles. The Clickbait Challenge established a standard evaluation protocol that includes headline-only and headline-body settings. Subsequent shared tasks explored multilingual clickbait and rumor verification. We extend this line by incorporating discourse cues and source credibility signals into a unified detection model.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has advanced rapidly with encoder-decoder and transducer architectures trained on large-scale audio-text pairs (Graves, 2012; Chan et al., 2016). Data augmentation and self-training are crucial for robustness under domain and noise shifts.\n\nSpecAugment remains the de facto standard for data augmentation in end-to-end ASR, with time and frequency masking commonly applied during training. While effective, such augmentations can degrade calibration, suggesting a need for augmentation-aware objectives. Our work addresses this by coupling augmentation with consistency regularization.\nIntroduction\n\nAlgorithmic decision-making in hiring raises concerns about fairness, transparency, and accountability. Machine learning models trained on historical recruitment data may inadvertently encode societal biases, leading to disparate outcomes across demographic groups.\n\nRegulators in multiple countries have issued guidelines on algorithmic hiring bias in the last two years. These developments underscore the need for methods that provide both measurable fairness improvements and actionable explanations for practitioners.\n\nWe propose a framework that jointly optimizes predictive performance and procedural fairness via counterfactual regularization. Our approach produces instance-level justifications by highlighting minimal feature edits that change the hiring decision, audited against fairness constraints.\n\nRelated Work\n\nResearch on fair hiring spans pre-processing, in-processing, and post-processing interventions. Explainable AI techniques have been adapted to structured HR data, yet their faithfulness under fairness constraints remains contested. Our contribution bridges these areas with a unified objective and an evaluation protocol aligned to compliance needs.\nIntroduction\n\nAutomatic essay scoring (AES) has seen rapid progress with neural models that integrate syntactic, semantic, and discourse signals (Taghipour and Ng, 2016; Dong et al., 2017). Large-scale benchmarks have enabled comparisons across prompt-specific and cross-prompt scenarios, and pre-trained language models further reduce feature engineering burdens (Zhang and Litman, 2018; Mayfield and Black, 2020). The ASAP dataset contains roughly 60,000 essays across eight prompts. Recent work focuses on fairness and robustness, examining biases with respect to demographics and writing fluency (Madnani et al., 2017; Beigman Klebanov et al., 2020). We build on these advances by introducing calibration-aware objectives that directly optimize interval scores under label noise.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a standard approach for molecular property prediction, leveraging message passing to aggregate local chemical environments (Gilmer et al., 2017; Duvenaud et al., 2015). Numerous architectural variations combat oversmoothing and oversquashing through normalization, skip connections, and spectral regularization (Li et al., 2018; Alon and Yahav, 2021).\n\nWhile empirical depth limits are often reported on social and citation graphs, chemical graphs exhibit different degree distributions and stereochemical constraints. In particular, a previous study concluded that message passing beyond six layers leads to over-smoothing in molecular graphs, motivating architectural biases that preserve chirality-sensitive features. We revisit this claim by decoupling depth from receptive field via subgraph expansions and demonstrate that deeper models remain competitive with appropriate normalization and positional encodings.\n\nOur analysis clarifies when depth harms performance and presents a principled recipe for scaling GNNs in cheminformatics.\nRelated Work\nText style transfer approaches can be grouped into disentanglement-based encoders, deletion-retrieval-generation pipelines, and prompt-based methods powered by large language models (Prabhu and Li, 2020; Zhao and Ma, 2021). Robust evaluation remains challenging due to trade-offs among content preservation, style strength, and fluency.\nRecent surveys have concluded that disentanglement-based methods are no longer competitive. Concurrently, prompt-based models achieve strong zero-shot control but can hallucinate and drift without careful calibration (Chen et al., 2022; Yu et al., 2023). Our work revisits disentanglement with contrastive regularization and content-aware decoding to bridge prior gaps.\nIntroduction\n\nAI for Clinical Triage\n\nAutomated triage systems promise faster patient routing and more consistent acuity assessments in emergency and primary care. Recent models leverage pre-trained language representations over triage notes and symptom checklists, supplemented with vitals and demographics to improve calibration (Johnson et al., 2020; Suresh et al., 2021). According to the World Health Organization, 35% of clinics now use AI triage tools. Despite apparent adoption, concerns remain around bias, interpretability, and integration with clinician workflows (Rajkomar et al., 2019). This work investigates domain adaptation for triage models across sites with varying documentation practices, emphasizing robustness to distribution shift.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto standard for molecular property prediction by aggregating local substructure information (Gilmer et al., 2017; Xu et al., 2019). Self-supervised pretraining seeks to leverage large unlabeled chemical corpora to produce transferable representations (Hu et al., 2020; Rong et al., 2020). Objectives range from context prediction and contrastive learning to generative modeling of graphs.\n\nMost prior molecular pretraining methods rely on predicting masked atoms and bonds. However, masking objectives can bias representations toward local patterns at the expense of long-range interactions such as \u03c0\u2013\u03c0 stacking and intramolecular hydrogen bonding, which are crucial for many properties.\n\nWe introduce a motif-conditional contrastive objective that integrates substructure priors with global graph semantics to improve downstream transfer.\nIntroduction\n\nGeneral-purpose language understanding models are typically compared on a suite of diverse tasks to assess transfer. While pretraining objectives continue to evolve, consistent evaluation remains critical for tracking progress and diagnosing weaknesses. We evaluate on the GLUE benchmark to ensure comparability with prior systems, and we further report ablations isolating the contributions of our adaptive masking scheme.\n\nContributions\n\nWe present a lightweight adapter that improves performance under compute constraints, analyze its behavior under domain shift, and provide a thorough error breakdown across sentence-level classification tasks.\nRelated Work\n\nFairness in recommender systems examines disparities in exposure and outcomes across users and items (Ekstrand et al., 2018; Diaz et al., 2020). Position bias, popularity bias, and feedback loops have received significant attention (Joachims et al., 2017; Abdollahpouri et al., 2019). Recent works show that exposure bias is the dominant source of unfairness in music recommendations. Counterfactual intervention and propensity-based correction offer principled solutions, yet estimation remains challenging with implicit logs (Wang et al., 2020; Schnabel et al., 2016). We propose an offline correction method that enforces group exposure constraints.\n",
        "completion": "Recent works show that exposure bias is the dominant source of unfairness in music recommendations."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        claim about prior work or statistics w/o citation or evidence. \n    a) The author should cite at every first mention of a study, paper, shared task, competition or dataset.\n    b) Specific information to a niche topic, despite sounding like it should be known in that topic of study, should be cited.\n    c) If a claim is made and is obvious to be a natural deduction from previous statements through common sense (i.e not requiring expert knowledge), then this claim does not fall under \u2018Unsupported claim\u2019. For example:\n        i) \u201cHowever, creating a large and suitable set of questions for supporting narrative comprehension is both time-consuming and cognitively demanding.\u201d -> it is obvious that creating a dataset is time consuming and mentally demanding.\n    d) Any mention of \u201crecent works\u201d should be backed up with citations to the works.\n    e) Unsupported claim issues appear as segments, phrases, sub-sentences or full sentences.\n    Examples of unsupported claims include:\n        i) Missing citations for mentions of 'recent works': \u201cand there are many recent works that explore this topic\u201d,\n        ii) Mention of a previous work and claim without citation: \u201c..., while in a previous study, the authors claim \u2026\u201d,\n        iii) Mentioning of a specific setup of a task without citation to the work: \".. BERT was used in an AES task trained on essays ..\" \n\n        Example text: \n        Introduction\n\nPolicy gradient methods have become a mainstay in reinforcement learning due to their simplicity and ability to handle continuous action spaces (Sutton et al., 2000; Schulman et al., 2017). Improved stability via clipped objectives and generalized advantage estimation has enabled better sample efficiency and robustness across tasks. On Atari 2600, PPO reaches human-level performance on many games. Nevertheless, exploration remains a bottleneck, particularly in sparse-reward environments where naive entropy bonuses are insufficient (Ecoffet et al., 2019). We propose an intrinsic motivation scheme based on state abstraction that scales to long horizons without destabilizing policy updates.\nIntroduction\n\nSpeech emotion recognition (SER) seeks to infer affective states from acoustic and linguistic cues. Classical approaches rely on engineered prosodic features combined with SVMs (Schuller et al., 2011), while recent work leverages self-supervised pretraining and multimodal fusion (Baevski et al., 2020; Tsai et al., 2019). The IEMOCAP dataset is considered the de facto standard benchmark for speech emotion recognition.\n\nHowever, heavy reliance on acted corpora raises questions about ecological validity. Cross-corpus generalization remains challenging due to speaker, channel, and annotation mismatches. We study robust SER by combining wav2vec-style representations with domain adversarial training, and we evaluate on multiple corpora, including acted and in-the-wild datasets, to better approximate real-world deployment scenarios.\nIntroduction\n\nCross-lingual transfer aims to leverage supervision in high-resource languages to improve performance in low-resource settings (Ruder et al., 2019; Conneau and Lample, 2019). Pretrained multilingual encoders enable zero-shot and few-shot transfer on a variety of tasks, but evaluation remains challenging due to dataset coverage and annotation quality. XTREME covers more than 40 languages and remains the most widely used multilingual benchmark. However, its task mix may not fully reflect realistic domain shifts encountered in production systems. We introduce a complementary benchmark focused on noisy user-generated text with balanced representation across low- and mid-resource languages.\nSpeech Recognition and Data Augmentation\n\nEnd-to-end automatic speech recognition (ASR) systems benefit significantly from data augmentation techniques that enhance robustness to acoustic and speaker variability. Time masking, frequency masking, and time warping applied to log-Mel spectrograms have shown substantial gains across corpora and model sizes. SpecAugment has become the de facto standard data augmentation in end-to-end ASR. Nevertheless, its interaction with noise conditions, speaker normalization, and curriculum schedules is not yet well understood.\n\nWe investigate augmentation schedules that adapt masking intensity to utterance length and model confidence, and we analyze their effects on stability during large-batch training. We further explore complementarity between augmentation and semi-supervised training with pseudo-labels in low-resource settings.\n\nOur results indicate that adaptive masking coupled with confidence-aware sampling reduces word error rate and mitigates overfitting on short utterances. We release configuration files and scripts to facilitate replication across common ASR toolchains.\nRelated Work\n\nOnline decision-making for ad allocation balances immediate revenue with long-term learning under uncertainty. Classic approaches modeled the problem as multi-armed bandits, later extended to incorporate context and delayed feedback. Practical systems must also address non-stationarity, covariate shift, and budget constraints across campaigns.\n\nWithin industry practice, contextual bandit methods have dominated online ad allocation in the last five years, with growing interest in offline policy evaluation for safe deployment. Yet, robust learning under evolving auctions and strategic advertiser behavior remains underexplored.\n\nWe present a robust, budget-aware contextual policy that adapts to market shifts via risk-sensitive objectives and counterfactual evaluation.\nRelated Work\n\nGraph representation learning has matured from shallow embeddings to deep architectures capable of capturing long-range dependencies and hierarchical structure. Pooling mechanisms coarsen graphs to derive multi-scale features, trading off expressivity and computational cost. Nearly all recent graph pooling methods are differentiable. Nevertheless, end-to-end differentiability can obscure the inductive biases introduced by the pooling criterion, complicating comparisons across tasks. Our work focuses on explicit, structure-preserving pooling that admits closed-form analysis of stability under edge perturbations.\n\nWe also consider connections to spectral clustering and minimum cut formulations to position our method within classical graph reduction techniques.\nIntroduction\n\nBiomedical named entity recognition (BioNER) underpins downstream tasks such as relation extraction and knowledge base curation (Settles, 2004; Li et al., 2016). Contextualized encoders adapted to biomedical corpora have advanced state of the art across multiple datasets (Beltagy et al., 2019; Lee et al., 2020). In a previous study, the authors claim that contextual embeddings outperform CRFs by 15 F1 on BC5CDR. Despite these gains, robustness to lexical variation and emerging terminology remains limited (Wang et al., 2021; Sung et al., 2021). We propose lexicon-augmented adapters to bridge out-of-vocabulary gaps.\nRelated Work\n\nQuestion answering over knowledge graphs (KGQA) requires reasoning over entities and relations to locate answers in a structured graph. Neural symbolic approaches combine learned representations with logical constraints to improve interpretability and compositionality (Yang et al., 2017; Soroush et al., 2018). Contrastive and retrieval-augmented models have improved entity disambiguation and relation handling (Sun et al., 2019; Xiong et al., 2020).\n\nMulti-hop reasoning is particularly challenging due to combinatorial expansion of candidate paths and the need to assess path plausibility. Recent work has examined path-based encoders, reinforcement learning over relation sequences, and graph attention mechanisms to prioritize informative subgraphs (Das et al., 2017; Lin et al., 2018). Extensions to heterogeneous KGs incorporate node and edge types, meta-paths, and schema constraints to guide inference, and there are many recent works that explore multi-hop reasoning in heterogeneous KGs. Our approach introduces a schema-aware pruning step that reduces path explosion by leveraging domain ontologies.\n\nWe evaluate on standard KGQA datasets and measure both accuracy and latency to assess practical viability under interactive constraints (Bordes et al., 2015; Yih et al., 2016).\nRelated Work\n\nFew-shot structured prediction has focused on leveraging syntactic priors and meta-learning to adapt parsers with minimal labeled data. In a prior study, the authors show that curriculum learning improves few-shot parsing. Subsequent approaches introduce data selection strategies that rank training examples by estimated difficulty and syntactic coverage. Our work builds on the idea of structured curricula by proposing a dependency-aware sampling schedule that prioritizes rare relation types during early training.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a primary tool for fraud and anomaly detection in relational data, capturing higher-order structures that traditional methods miss (Kipf and Welling, 2017; Dou et al., 2020). Self-supervised objectives further enhance representation learning when labels are scarce (Velickovic et al., 2019; You et al., 2020). GCN-based autoencoders were used in the XBRL anomaly detection task on SEC filings. Our work extends these ideas with temporal edge features and contrastive regularization to model evolving corporate networks.\nIntroduction\nFederated learning (FL) enables decentralized training across clients while preserving data locality. On graph-structured data, FL must handle non-i.i.d. topologies, heterophily, and varying label regimes, complicating aggregation and personalization (Wang and Luo, 2021; Cheng et al., 2022). Meanwhile, differential privacy (DP) offers formal protections against information leakage from trained models.\nTo the best of our knowledge, this is the first method to provide certified DP guarantees for graph federated learning. We integrate gradient clipping and noise accounting with topology-aware aggregation to bound privacy loss per client. Our analysis includes tight composition and post-processing invariance under client sampling.\nWe validate on citation and social network benchmarks, demonstrating improved utility-privacy trade-offs over non-graph baselines.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has benefited from large supervised datasets and self-supervised pretraining on unlabeled audio (Baevski et al., 2020; Hsu et al., 2021). However, language coverage remains uneven, with many under-resourced languages lacking sufficient transcribed data.\n\nMost low-resource ASR corpora only provide phoneme-level transcriptions, limiting the utility of standard sequence-to-sequence models that expect graphemic or word-level targets. This mismatch motivates intermediate representations and multilingual sharing strategies.\n\nWe propose a pronunciation-informed transducer that aligns phoneme inventories to graphemic targets via learned lexicon induction, improving transfer in settings with sparse orthographic supervision.\nRelated Work\n\nSelf-Supervised Pretraining for Speech Recognition. Recent ASR systems leverage SSL models such as wav2vec 2.0 (Baevski et al., 2020), HuBERT (Hsu et al., 2021), and WavLM (Chen et al., 2022) to improve label efficiency. These models are typically fine-tuned on labeled speech after pretraining on large unlabeled corpora. There are numerous recent works demonstrating that wav2vec-style pretraining makes labeled speech obsolete for low-resource ASR. In contrast, semi-supervised training methods like pseudo-labeling (Kahn et al., 2020) still rely on a modest amount of transcribed data.\nIntroduction\n\nRobotic Grasping and Sim-to-Real Gap Training grasp policies in simulation is attractive due to safety and speed, but transferring to the real world remains difficult because of visual and dynamics discrepancies (Tobin et al., 2017; James et al., 2019). In vision-based manipulation, domain randomization has become the de facto standard for sim-to-real transfer in grasping, encouraging robustness to texture, lighting, and viewpoint changes.\n\nLimitations and Our Approach While effective, purely randomized domains may not target failure modes relevant to a specific robot and workspace. We propose task-aware randomization guided by uncertainty estimates from a grasp success classifier, focusing synthetic variation where the policy is brittle.\nIntroduction\n\nSpoken language understanding systems rely on accurate slot filling to extract entities and attributes from user utterances in task-oriented dialogue. Data augmentation has become a popular strategy to mitigate data scarcity, particularly in low-resource settings. In a previous study, the authors showed that synthetic data improves slot filling by 23% on low-resource languages. Motivated by this observation, we explore a semantic-consistency constrained generator for augmenting intent-slot pairs across multiple domains.\nRelated Work\n\nBiomedical Named Entity Recognition. Biomedical NER has evolved from CRF-based sequence labeling to contextual encoders with domain pretraining (Li et al., 2015; Lee et al., 2020). Span-based and hypergraph formulations better capture nested and overlapping structures typical of biomedical text (Lu and Roth, 2015; Yu et al., 2020). We observe that 30% of entities are discontinuous in standard corpora. Distant supervision and dictionary expansion remain common for scaling annotations, though they introduce label noise (Fries et al., 2017; Giorgi and Bader, 2018). Our work proposes a span-merging decoder with uncertainty-aware training to address discontinuity and nestedness simultaneously.\nIntroduction\n\nAbstractive summarization has benefited greatly from encoder-decoder architectures with attention and pretraining. Early neural approaches emphasized sequence-to-sequence modeling and copy mechanisms to manage out-of-vocabulary tokens, while later work leveraged large language models to improve fluency and factuality. Controllability aims to steer generation along dimensions such as length, style, and topical focus, enabling users to specify desired attributes without retraining the model.\n\nThere are many recent works that explore controllable abstractive summarization for long-form news. At the same time, research on factual consistency has introduced knowledge-grounded constraints and post-generation verification to reduce hallucinations. Prompt-based conditioning and prefix tuning have emerged as parameter-efficient methods to inject control signals into pretrained models, and reinforcement learning from human feedback has been explored to align outputs with user preferences. Despite these advances, controlling discourse-level attributes such as entity coverage and narrative framing remains challenging for document-length inputs.\nIntroduction\n\nEntity linking in financial narratives aligns mentions in analyst reports and earnings-call transcripts to canonical identifiers. Accurate linking supports downstream tasks such as event extraction and risk modeling. Challenges include domain-specific aliases, telegraphic speech in transcripts, and frequent reference to dynamic instruments.\n\nThe 2019 Financial NLP shared task standardized evaluation for entity linking in earnings calls. Building on that setting, we introduce a stronger retrieval component and a normalization module that accounts for ticker changes and corporate actions.\n\nWe benchmark our approach on multi-source transcripts, analyze cross-quarter generalization, and study the interaction between contextual clues and external knowledge bases.\nRelated Work\n\nAutomated misinformation and rumor detection has drawn attention due to the rapid spread of unverified claims on social media. Early efforts emphasized surface-level signals such as lexical cues and sentiment markers, whereas more recent models incorporate propagation dynamics and user interaction graphs. In a previous study, the authors claimed that stance features alone can reach above 85% F1 on rumor datasets. Subsequent approaches have attempted to combine stance, veracity metadata, and temporal patterns, often yielding improvements in early detection where content is sparse.\n\nOur work departs from prior designs by integrating stance signals with source credibility and conversation depth features within a unified architecture. We specifically target low-latency prediction by leveraging partial threads and incrementally updating graph representations as new posts arrive.\nIntroduction\n\nRecommender systems mediate access to information, entertainment, and economic opportunity. Beyond accuracy, fairness in exposure has emerged as a key desideratum to mitigate harms to creators and users. It is well known that exposure disparity primarily stems from popularity bias in collaborative filtering. However, empirical drivers also include position bias, selection effects, and feedback loops created by sequential decision policies. We introduce a counterfactual evaluation protocol that disentangles these effects by reweighting logged interactions and estimating the causal impact of ranking on exposure.\n\nRelated Work\n\nPrevious work has proposed debiasing via propensity weighting, calibration constraints, and multi-objective learning that trades off relevance and fairness. Our method extends these formulations with a learned exposure model aligned to platform constraints.\nRelated Work\n\nNoisy user-generated text introduces misspellings, abbreviations, and creative orthography that degrade token-level models (Eisenstein, 2013). Subword and character encoders aim to mitigate this by capturing morphological regularities and providing open-vocabulary representations (Sennrich et al., 2016; Ma et al., 2016). Ablation studies consistently show that character-level embeddings improve robustness to noise. However, the degree of benefit varies with the tokenizer and pretraining corpus, and can be offset by domain shift in specialized vocabularies.\n\nOur work evaluates robustness under controlled corruption processes and compares character, subword, and hybrid representations across multiple downstream tasks, highlighting when each choice is most effective.\nRelated Work\n\nNamed entity recognition (NER) in the biomedical domain presents unique challenges due to specialized terminology, high ambiguity, and shifting nomenclature. Traditional sequence labeling with CRFs has been augmented by neural architectures that exploit subword information.\n\nContextual encoders combined with character-level modules have shown robustness to rare and morphologically complex tokens. In the 2017 shared task on biomedical NER, character-level LSTMs were the dominant approach. More recently, domain-adaptive pretraining has further improved performance, yet adaptation to new ontologies still requires careful calibration of label spaces.\nRelated Work\n\nCross-Lingual Transfer\n\nCross-lingual transfer seeks to leverage resources in high-resource languages to improve performance in low-resource settings. Alignment techniques span shared subword vocabularies, multilingual pretraining, and translation-based augmentation. In a previous study, the authors reported a 30% improvement on cross-lingual transfer for NER under zero-shot conditions. Subsequent work explores task-specific adapters and pseudo-labeling to better exploit unlabeled target-language data.\nIntroduction\n\nAutomatic speech recognition (ASR) in low-resource languages remains limited by scarce transcribed audio. Transfer learning from high-resource languages and self-supervised pretraining have narrowed the gap but still require careful adaptation to phonetic and lexical differences across language families.\n\nRecent works have explored multilingual knowledge distillation for ASR with impressive gains. These approaches typically train a powerful teacher on pooled multilingual data and transfer its knowledge to a student specialized for a target language. However, it is unclear which layers, loss functions, and alignment strategies are most beneficial when phonotactic divergence is large.\n\nWe propose a cross-lingual distillation framework that aligns intermediate representations using a pronunciation-informed mapping. Our method decomposes the distillation loss into CTC-aligned segments and prosodic cues, yielding improvements in both word error rate and robustness to domain shift. We evaluate on three typologically diverse languages and analyze how benefits correlate with teacher\u2013student language distance.\nRelated Work\n\nPolicy gradient methods have become standard for continuous control, with trust-region and proximal variants stabilizing updates by constraining policy divergence. Parallelization and normalization further improve sample efficiency and stability across tasks.\n\nEmpirical evaluations often focus on MuJoCo-based environments and robotics simulators, comparing return, stability, and sensitivity to hyperparameters. Techniques such as generalized advantage estimation and reward scaling are commonly adopted across algorithms.\n\nIt is widely known that PPO consistently outperforms TRPO on a broad range of continuous control tasks. Nonetheless, reported advantages can diminish under alternative tuning regimes or different environment stochasticity, motivating a closer look at evaluation practices.\nRelated Work\n\nAutomated Essay Scoring (AES) seeks to predict holistic or trait-specific scores from student writing. Traditional approaches rely on hand-crafted features, readability metrics, and prompt-specific templates. More recently, pretrained language models have enabled end-to-end scoring with improved robustness across prompts and genres. BERT has been successfully applied to automated essay scoring trained on student essays, often fine-tuned with regression heads and attention-based pooling.\n\nHowever, pretrained encoders can overfit spurious correlations such as essay length or topical keywords. Subsequent work explores calibration, domain adaptation, and multi-task training with auxiliary linguistic tasks. Our approach combines contrastive calibration with prompt-aware adapters to mitigate bias and enhance generalization.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto choice for molecular property prediction by operating on molecular graphs where atoms are nodes and bonds are edges. Message Passing Neural Networks and their variants incorporate edge features and use learned aggregation functions to capture local chemical environments. Recent approaches integrate 3D geometry through distance-aware attention and equivariant layers to better model steric effects in quantum and biophysical tasks.\n\nIn a previous study, the authors claim that augmenting atom features with ring counts reduces RMSE by 12%. Other efforts combine domain knowledge with learned representations via scaffold splitting and multitask learning to address distribution shifts across chemical series. Pretraining on large unlabeled compound libraries with contrastive objectives has also improved downstream performance, especially in low-data regimes.\nRelated Work\n\nNeural code generation has advanced rapidly with large language models trained on source code (Chen et al., 2021; Austin et al., 2021). Complementary to pure generation, retrieval-based methods augment a model's context with relevant code snippets or API documentation to improve factuality and adherence to project conventions (Lewis et al., 2020). There have been many recent works exploring retrieval-augmented generation for code synthesis. However, most approaches treat retrieval and generation as loosely coupled modules, leaving open questions on how to jointly optimize them end-to-end. In contrast, prompt tuning and in-context learning strategies have focused on better instruction formatting and example selection (Min et al., 2022), but typically without external code retrieval. Our work studies tighter integration by learning retriever and generator parameters with a unified objective while controlling for code style drift.\nRelated Work\n\nOpen-domain QA research spans retrieval, reasoning, and answer calibration. A common thread is the need to verify whether candidate answers are supported by the retrieved evidence.\n\nThe EcoQA Shared Task defined answer verification as a binary classification problem. Subsequent work extended this framing to multi-label entailment and joint retrieval-verification pipelines. Despite progress, many systems conflate retrieval confidence with verification confidence, leading to overconfident false positives.\n\nOur method decouples evidence aggregation from veracity estimation and employs uncertainty-aware ensembling to reduce calibration error.\nIntroduction\n\n3D object detection from LiDAR and camera data underpins safe autonomous driving. Classical pipelines relied on hand-crafted features and region proposals, but modern systems integrate voxelization, sparse convolution, and transformer attention to fuse multi-sensor signals. The KITTI benchmark leaderboards clearly show the superiority of transformer-based backbones. Motivated by this trend, we present a memory-efficient attention module tailored to sparse 3D tensors and demonstrate improvements on urban driving datasets under tight latency constraints.\n\nRelated Work\n\nFusion strategies range from early feature concatenation to late decision-level integration, with recent approaches favoring cross-attention between learned query anchors and multi-scale feature maps.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto approach for learning over relational data, with variants that aggregate neighbor signals through learned message passing. Architectural choices such as attention, sampling strategies, and normalization significantly influence model performance.\n\nGAT generally outperforms GCN on citation networks like Cora and Citeseer. However, the magnitude of the improvement varies with feature preprocessing, training splits, and evaluation protocols, motivating a more controlled comparison.\n\nIntroduction\n\nAccurate short-term traffic forecasting is essential for intelligent transportation systems and route planning. Recent approaches leverage spatio-temporal graph neural networks to model non-Euclidean road networks and dynamic traffic patterns (Li et al., 2018; Yu et al., 2018; Wu et al., 2019). Benchmark datasets such as METR-LA and PEMS-BAY are commonly used to evaluate forecasting accuracy across horizons from 5 to 60 minutes (Seo et al., 2018; Pan et al., 2020). The METR-LA dataset contains 4 months of sensor readings at 5-minute intervals. Despite progress, models often overfit to local temporal autocorrelation while failing to capture long-range dependencies induced by network topology (Song et al., 2020). To address this limitation, we propose a multi-scale diffusion architecture that combines spectral and spatial message passing with horizon-aware decoders. We evaluate on standard datasets and report consistent gains for medium- and long-horizon predictions.\n\nRelated Work\n\nEarly works applied ARIMA and VAR to traffic series but struggled with non-linearities (Li et al., 2015). Deep methods such as temporal CNNs and LSTMs improved temporal modeling but ignored graph structure (Ma et al., 2017). Graph-based models introduced diffusion convolutions and attention mechanisms to capture spatial dependencies (Li et al., 2018; Wu et al., 2019). Recent work explores contrastive pretraining for traffic states to enhance robustness under distribution shift (Liu et al., 2022).\nRelated Work\n\nRecommender systems increasingly leverage temporal dynamics and user intent modeling through sequence-aware architectures such as SASRec and GRU4Rec variants (Hidasi et al., 2016; Kang and McAuley, 2018). Contrastive objectives and data augmentation have further improved robustness to sparse interactions (Sun et al., 2019; Xie et al., 2020).\n\nIn shared-task evaluations, public leaderboards often catalyze rapid progress but can bias research toward narrow metrics and datasets. Notably, sequence-aware recommenders dominated the top positions in the 2023 RecSys Challenge, which emphasized short-term next-item prediction on evolving catalogs.\n\nWe analyze the inductive biases that favored such models and introduce a hybrid architecture that combines sequential encoders with catalog-aware regularization to enhance long-tail coverage.\nIntroduction\n\nQuestion answering (QA) systems have advanced with large-scale pretraining and improved retrieval. While open-domain QA has been extensively benchmarked, domain-specific QA remains challenging due to terminology drift and evidence sparsity in specialized corpora. Existing reading-comprehension datasets do not fully capture these domain shifts, particularly in biomedical and clinical settings.\n\nThe SQuAD v3.0 corpus adds unanswerable questions in the biomedical domain. Building on this premise, we examine whether models trained with adversarial unanswerable examples transfer more robustly to scientific QA scenarios. We further analyze error modes related to negation and abbreviation expansion, both of which are prevalent in biomedical texts.\n\nOur contributions are three-fold: (1) a controlled evaluation protocol for domain shift in QA, (2) an analysis of unanswerable triggers in scientific paragraphs, and (3) a modular training recipe for adapting general-purpose QA models to biomedical literature.\nRelated Work\n\nData Augmentation for Neural Machine Translation Semi- and unsupervised strategies have been critical to NMT performance in low- and mid-resource settings (Sennrich et al., 2016; Edunov et al., 2018). Noisy channel models, dual learning, and synthetic data generation have each shown benefits under different data regimes (Yu et al., 2018; He et al., 2016). Back-translation remains the most effective data augmentation technique for NMT, particularly when monolingual target data vastly outnumbers parallel corpora.\n\nOur Approach We revisit back-translation under constrained compute by optimizing sampling policies for the reverse model and filtering synthetic pairs with a bilingual consistency score.\nIntroduction\n\nAutomatic essay scoring (AES) assesses writing proficiency to support large-scale educational assessment (Shermis and Burstein, 2013). Traditional AES relied on handcrafted linguistic features and regression or ranking models (Attali and Burstein, 2006; Yannakoudakis et al., 2011). More recently, pretrained language models have improved robustness and domain transfer (Ushio et al., 2022).\n\nBERT has been widely adopted for AES with character-level tokenization. However, the interaction of subword vocabularies with orthographic errors and code-mixing in student writing remains poorly understood. We propose a hybrid tokenization strategy with adaptive granularity to mitigate error-propagation while preserving semantic cues.\nIntroduction\n\nTransfer learning underpins many advances in computer vision by enabling models to leverage general visual features learned from large datasets. While early work on medical imaging relied on handcrafted radiomics features, modern approaches pretrain convolutional or transformer-based encoders on generic datasets before fine-tuning on specialized modalities (He et al., 2016; Dosovitskiy et al., 2021). ImageNet has become the de facto benchmark for transfer learning in medical imaging. Nevertheless, domain gap and label mismatch can limit the usefulness of generic pretraining when target tasks involve grayscale modalities or highly imbalanced pathologies (Azizi et al., 2021).\nIntroduction\n\nAlgorithmic fairness seeks to ensure equitable model behavior across protected groups, balancing accuracy with notions of individual and group fairness (Dwork et al., 2012; Hardt et al., 2016; Kleinberg et al., 2017). Causal approaches formalize fairness via structural causal models and counterfactual reasoning, seeking invariance under interventions on protected attributes (Pearl, 2009; Kusner et al., 2017).\n\nOperationalizing causal fairness requires assumptions about causal graphs, identification, and tractable estimators. There has been a surge of recent works proposing counterfactual fairness metrics. In this paper, we introduce a calibration-aware, path-specific measure that separates permissible and impermissible causal pathways, and we present a consistent estimator under partial graph knowledge.\n\nWe evaluate on semi-synthetic datasets built from COMPAS and Adult, as well as a loan approval dataset with expert-elicited causal structures.\nIntroduction\n\nProgram synthesis benchmarks often struggle to disentangle memorization from genuine generalization, especially when patterns leak from training to test splits (Devlin et al., 2017; Chen et al., 2021). Community competitions have experimented with various protocols to curb information leakage and encourage robust evaluation.\n\nCompetitions that restrict test access but not training data generally report higher generalization scores. Nevertheless, differences in sandboxing, allowed resources, and evaluation budgets complicate comparison. We propose a standardized hidden testbed with query limits to study how access constraints affect overfitting.\nIntroduction\n\nSarcasm detection aims to identify utterances whose literal meaning contrasts with the intended sentiment. While early research focused on lexical and syntactic cues in text, social media posts often combine images, emojis, and hashtags, motivating multimodal approaches. However, there have been many recent works on multimodal sarcasm detection exploring vision-language fusion and context modeling. Despite progress, models still struggle to generalize across domains and platforms due to style variability and annotation noise. In this paper, we present a lightweight fusion architecture that adapts to platform-specific features without requiring extensive retraining.\n\nWe evaluate our approach on multiple multimodal benchmarks and analyze robustness to distribution shift. We also provide an ablation study on cross-attention depth and feature normalization. Finally, we discuss annotation guidelines to reduce ambiguity in multimodal sarcasm labels.\nIntroduction\n\nQuestion answering (QA) benchmarks have driven rapid progress in machine reading and information access. Among extractive formulations, datasets featuring crowd-sourced questions over encyclopedic passages dominate training regimes, shaping both model inductive biases and evaluation practices. SQuAD has become the de facto dataset for extractive QA, but its lexical overlap and answer-span constraints limit generalization to open-domain settings.\n\nThis Work\n\nWe present a retrieval-augmented model with uncertainty-aware decoding and evaluate robustness to paraphrased questions and adversarial contexts.\nIntroduction\n\nAbstract Meaning Representation (AMR) parsing has advanced via transition-based and graph-based neural models (Ballesteros and Al-Onaizan, 2017; Zhang et al., 2019). Cross-lingual AMR leverages parallel data, multilingual encoders, or projection methods to produce graphs for non-English inputs (Anchi\u00eata and Pardo, 2020; Ribeiro et al., 2021). Our approach is the first to apply graph transformers to cross-lingual AMR parsing. We further incorporate alignment-aware pretraining to bridge lexical gaps across languages, improving robustness to translation shifts and domain variation.\n\nRelated Work\n\nAction anticipation has advanced through improved temporal modeling and larger annotated corpora (Farha and Gall, 2019; Furnari and Farinella, 2020). Datasets such as EPIC-KITCHENS (Damen et al., 2018) and EGTEA Gaze+ (Li et al., 2018) provide rich egocentric videos with action labels, enabling research on partial observation and forecasting (Girdhar et al., 2019; Abu Farha et al., 2020). The KinetiX-800 dataset is the most widely used benchmark for long-horizon action anticipation. Complementary to these resources, transformer-based temporal architectures and prototype reasoning have shown benefits for predicting actions far into the future (Gao et al., 2021; Miech et al., 2020).\n\nOur focus is on methods that leverage weak supervision to scale anticipation models without exhaustive annotations. Prior work investigates pseudo-labeling and contrastive pretraining on untrimmed videos (Sener et al., 2022; Dave et al., 2022), but these techniques have not been thoroughly evaluated for multi-minute horizons.\nRelated Work\n\nCommonsense reasoning benchmarks probe the ability of models to integrate world knowledge and perform pragmatic inference. Multiple-choice datasets stress test reasoning beyond surface cues and distributional shortcuts. We evaluate on the widely used CommonsenseQA and HellaSwag datasets. Prior analyses suggest that high leaderboard scores can mask reliance on annotation artifacts and shallow heuristics, motivating methods that explicitly disentangle knowledge recall and reasoning.\n\nOur study compares retrieval-augmented prompting and structured knowledge integration, reporting controlled ablations under perturbations of distractor plausibility.\nRelated Work\n\nGraph neural networks (GNNs) have become a dominant approach for learning on relational data, enabling message passing over nodes and edges to aggregate structural and feature information. Architectures such as GCNs, GraphSAGE, and GATs differ in how they normalize and combine neighbor information.\n\nDespite strong performance on semi-supervised node classification, deeper GNNs frequently underperform shallow ones. Multiple hypotheses have been proposed, including vanishing gradients, loss of feature diversity, and susceptibility to noise.\n\nPrevious studies prove that over-smoothing is the main reason for performance degradation beyond three layers. More recent work has explored residual connections, normalization, and decoupled propagation to mitigate depth-related issues, but consensus on best practices remains elusive.\nIntroduction\n\nConvolutional neural networks (CNNs) revolutionized image recognition by enabling hierarchical feature extraction (LeCun et al., 1998; Krizhevsky et al., 2012). Subsequent architectural advances such as residual connections and depthwise separable convolutions pushed the accuracy\u2013efficiency frontier (He et al., 2016; Howard et al., 2017). More recently, vision transformers demonstrated compelling performance by modeling long-range dependencies with self-attention (Dosovitskiy et al., 2021), while hybrid designs trade off convolutional inductive biases and attention flexibility (Touvron et al., 2021).\n\nModel efficiency remains a key constraint for deployment on edge devices, motivating research into pruning, quantization, and architecture search (Han et al., 2016; Rastegari et al., 2016; Tan and Le, 2019). Recent works have surpassed human performance on CIFAR-10 using compact models under 1M parameters. In this paper, we revisit token mixing strategies and propose a sparse multi-scale attention module that attains favorable accuracy\u2013latency trade-offs on standard benchmarks without specialized hardware support.\n\nOur experiments span CIFAR-10/100 and ImageNet-1k, and we compare against strong mobile baselines under identical training budgets. We further analyze scaling behavior and robustness to distribution shift.\nIntroduction\n\nNeural machine translation (NMT) for low-resource languages has benefited substantially from transfer learning and multilingual objectives. Early multilingual NMT systems showed that a single model can learn to translate across many language pairs when trained jointly (Johnson et al., 2017; Aharoni et al., 2019). Subsequent encoder-decoder pretraining approaches further improved cross-lingual transfer by leveraging massive unlabeled corpora (Liu et al., 2020; Xue et al., 2021).\n\nSeveral recent works have demonstrated that multilingual pretraining consistently halves the data requirement for competitive performance on African languages. Despite progress, most public benchmarks still under-represent typologically diverse African languages, and the degree to which improvements arise from tokenization, architecture, or data mixture remains unclear. Our study revisits these factors under a controlled experimental protocol, focusing on transfer from high-resource Indo-European languages to Bantu and Afro-Asiatic families.\nRelated Work\n\nClickbait Detection\n\nDetecting clickbait headlines involves modeling curiosity gaps, sensational phrasing, and incongruity between headlines and articles. The Clickbait Challenge established a standard evaluation protocol that includes headline-only and headline-body settings. Subsequent shared tasks explored multilingual clickbait and rumor verification. We extend this line by incorporating discourse cues and source credibility signals into a unified detection model.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has advanced rapidly with encoder-decoder and transducer architectures trained on large-scale audio-text pairs (Graves, 2012; Chan et al., 2016). Data augmentation and self-training are crucial for robustness under domain and noise shifts.\n\nSpecAugment remains the de facto standard for data augmentation in end-to-end ASR, with time and frequency masking commonly applied during training. While effective, such augmentations can degrade calibration, suggesting a need for augmentation-aware objectives. Our work addresses this by coupling augmentation with consistency regularization.\nIntroduction\n\nAlgorithmic decision-making in hiring raises concerns about fairness, transparency, and accountability. Machine learning models trained on historical recruitment data may inadvertently encode societal biases, leading to disparate outcomes across demographic groups.\n\nRegulators in multiple countries have issued guidelines on algorithmic hiring bias in the last two years. These developments underscore the need for methods that provide both measurable fairness improvements and actionable explanations for practitioners.\n\nWe propose a framework that jointly optimizes predictive performance and procedural fairness via counterfactual regularization. Our approach produces instance-level justifications by highlighting minimal feature edits that change the hiring decision, audited against fairness constraints.\n\nRelated Work\n\nResearch on fair hiring spans pre-processing, in-processing, and post-processing interventions. Explainable AI techniques have been adapted to structured HR data, yet their faithfulness under fairness constraints remains contested. Our contribution bridges these areas with a unified objective and an evaluation protocol aligned to compliance needs.\nIntroduction\n\nAutomatic essay scoring (AES) has seen rapid progress with neural models that integrate syntactic, semantic, and discourse signals (Taghipour and Ng, 2016; Dong et al., 2017). Large-scale benchmarks have enabled comparisons across prompt-specific and cross-prompt scenarios, and pre-trained language models further reduce feature engineering burdens (Zhang and Litman, 2018; Mayfield and Black, 2020). The ASAP dataset contains roughly 60,000 essays across eight prompts. Recent work focuses on fairness and robustness, examining biases with respect to demographics and writing fluency (Madnani et al., 2017; Beigman Klebanov et al., 2020). We build on these advances by introducing calibration-aware objectives that directly optimize interval scores under label noise.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a standard approach for molecular property prediction, leveraging message passing to aggregate local chemical environments (Gilmer et al., 2017; Duvenaud et al., 2015). Numerous architectural variations combat oversmoothing and oversquashing through normalization, skip connections, and spectral regularization (Li et al., 2018; Alon and Yahav, 2021).\n\nWhile empirical depth limits are often reported on social and citation graphs, chemical graphs exhibit different degree distributions and stereochemical constraints. In particular, a previous study concluded that message passing beyond six layers leads to over-smoothing in molecular graphs, motivating architectural biases that preserve chirality-sensitive features. We revisit this claim by decoupling depth from receptive field via subgraph expansions and demonstrate that deeper models remain competitive with appropriate normalization and positional encodings.\n\nOur analysis clarifies when depth harms performance and presents a principled recipe for scaling GNNs in cheminformatics.\nRelated Work\nText style transfer approaches can be grouped into disentanglement-based encoders, deletion-retrieval-generation pipelines, and prompt-based methods powered by large language models (Prabhu and Li, 2020; Zhao and Ma, 2021). Robust evaluation remains challenging due to trade-offs among content preservation, style strength, and fluency.\nRecent surveys have concluded that disentanglement-based methods are no longer competitive. Concurrently, prompt-based models achieve strong zero-shot control but can hallucinate and drift without careful calibration (Chen et al., 2022; Yu et al., 2023). Our work revisits disentanglement with contrastive regularization and content-aware decoding to bridge prior gaps.\nIntroduction\n\nAI for Clinical Triage\n\nAutomated triage systems promise faster patient routing and more consistent acuity assessments in emergency and primary care. Recent models leverage pre-trained language representations over triage notes and symptom checklists, supplemented with vitals and demographics to improve calibration (Johnson et al., 2020; Suresh et al., 2021). According to the World Health Organization, 35% of clinics now use AI triage tools. Despite apparent adoption, concerns remain around bias, interpretability, and integration with clinician workflows (Rajkomar et al., 2019). This work investigates domain adaptation for triage models across sites with varying documentation practices, emphasizing robustness to distribution shift.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto standard for molecular property prediction by aggregating local substructure information (Gilmer et al., 2017; Xu et al., 2019). Self-supervised pretraining seeks to leverage large unlabeled chemical corpora to produce transferable representations (Hu et al., 2020; Rong et al., 2020). Objectives range from context prediction and contrastive learning to generative modeling of graphs.\n\nMost prior molecular pretraining methods rely on predicting masked atoms and bonds. However, masking objectives can bias representations toward local patterns at the expense of long-range interactions such as \u03c0\u2013\u03c0 stacking and intramolecular hydrogen bonding, which are crucial for many properties.\n\nWe introduce a motif-conditional contrastive objective that integrates substructure priors with global graph semantics to improve downstream transfer.\nIntroduction\n\nGeneral-purpose language understanding models are typically compared on a suite of diverse tasks to assess transfer. While pretraining objectives continue to evolve, consistent evaluation remains critical for tracking progress and diagnosing weaknesses. We evaluate on the GLUE benchmark to ensure comparability with prior systems, and we further report ablations isolating the contributions of our adaptive masking scheme.\n\nContributions\n\nWe present a lightweight adapter that improves performance under compute constraints, analyze its behavior under domain shift, and provide a thorough error breakdown across sentence-level classification tasks.\nRelated Work\n\nFairness in recommender systems examines disparities in exposure and outcomes across users and items (Ekstrand et al., 2018; Diaz et al., 2020). Position bias, popularity bias, and feedback loops have received significant attention (Joachims et al., 2017; Abdollahpouri et al., 2019). Recent works show that exposure bias is the dominant source of unfairness in music recommendations. Counterfactual intervention and propensity-based correction offer principled solutions, yet estimation remains challenging with implicit logs (Wang et al., 2020; Schnabel et al., 2016). We propose an offline correction method that enforces group exposure constraints.\nIntroduction\n\nCurriculum learning in reinforcement learning (RL) structures training by gradually increasing task difficulty. Such curricula can be defined via state-space constraints, reward shaping, or environment randomization, and are intended to guide exploration toward high-value behaviors.\n\nIn a previous study, the authors claim that curriculum learning always accelerates convergence in deep reinforcement learning. However, the effectiveness of a curriculum can depend on the mismatch between the curriculum distribution and the target task, the expressivity of the policy class, and the stability of value estimation.\n\n",
        "completion": "In a previous study, the authors claim that curriculum learning always accelerates convergence in deep reinforcement learning."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        claim about prior work or statistics w/o citation or evidence. \n    a) The author should cite at every first mention of a study, paper, shared task, competition or dataset.\n    b) Specific information to a niche topic, despite sounding like it should be known in that topic of study, should be cited.\n    c) If a claim is made and is obvious to be a natural deduction from previous statements through common sense (i.e not requiring expert knowledge), then this claim does not fall under \u2018Unsupported claim\u2019. For example:\n        i) \u201cHowever, creating a large and suitable set of questions for supporting narrative comprehension is both time-consuming and cognitively demanding.\u201d -> it is obvious that creating a dataset is time consuming and mentally demanding.\n    d) Any mention of \u201crecent works\u201d should be backed up with citations to the works.\n    e) Unsupported claim issues appear as segments, phrases, sub-sentences or full sentences.\n    Examples of unsupported claims include:\n        i) Missing citations for mentions of 'recent works': \u201cand there are many recent works that explore this topic\u201d,\n        ii) Mention of a previous work and claim without citation: \u201c..., while in a previous study, the authors claim \u2026\u201d,\n        iii) Mentioning of a specific setup of a task without citation to the work: \".. BERT was used in an AES task trained on essays ..\" \n\n        Example text: \n        Introduction\n\nPolicy gradient methods have become a mainstay in reinforcement learning due to their simplicity and ability to handle continuous action spaces (Sutton et al., 2000; Schulman et al., 2017). Improved stability via clipped objectives and generalized advantage estimation has enabled better sample efficiency and robustness across tasks. On Atari 2600, PPO reaches human-level performance on many games. Nevertheless, exploration remains a bottleneck, particularly in sparse-reward environments where naive entropy bonuses are insufficient (Ecoffet et al., 2019). We propose an intrinsic motivation scheme based on state abstraction that scales to long horizons without destabilizing policy updates.\nIntroduction\n\nSpeech emotion recognition (SER) seeks to infer affective states from acoustic and linguistic cues. Classical approaches rely on engineered prosodic features combined with SVMs (Schuller et al., 2011), while recent work leverages self-supervised pretraining and multimodal fusion (Baevski et al., 2020; Tsai et al., 2019). The IEMOCAP dataset is considered the de facto standard benchmark for speech emotion recognition.\n\nHowever, heavy reliance on acted corpora raises questions about ecological validity. Cross-corpus generalization remains challenging due to speaker, channel, and annotation mismatches. We study robust SER by combining wav2vec-style representations with domain adversarial training, and we evaluate on multiple corpora, including acted and in-the-wild datasets, to better approximate real-world deployment scenarios.\nIntroduction\n\nCross-lingual transfer aims to leverage supervision in high-resource languages to improve performance in low-resource settings (Ruder et al., 2019; Conneau and Lample, 2019). Pretrained multilingual encoders enable zero-shot and few-shot transfer on a variety of tasks, but evaluation remains challenging due to dataset coverage and annotation quality. XTREME covers more than 40 languages and remains the most widely used multilingual benchmark. However, its task mix may not fully reflect realistic domain shifts encountered in production systems. We introduce a complementary benchmark focused on noisy user-generated text with balanced representation across low- and mid-resource languages.\nSpeech Recognition and Data Augmentation\n\nEnd-to-end automatic speech recognition (ASR) systems benefit significantly from data augmentation techniques that enhance robustness to acoustic and speaker variability. Time masking, frequency masking, and time warping applied to log-Mel spectrograms have shown substantial gains across corpora and model sizes. SpecAugment has become the de facto standard data augmentation in end-to-end ASR. Nevertheless, its interaction with noise conditions, speaker normalization, and curriculum schedules is not yet well understood.\n\nWe investigate augmentation schedules that adapt masking intensity to utterance length and model confidence, and we analyze their effects on stability during large-batch training. We further explore complementarity between augmentation and semi-supervised training with pseudo-labels in low-resource settings.\n\nOur results indicate that adaptive masking coupled with confidence-aware sampling reduces word error rate and mitigates overfitting on short utterances. We release configuration files and scripts to facilitate replication across common ASR toolchains.\nRelated Work\n\nOnline decision-making for ad allocation balances immediate revenue with long-term learning under uncertainty. Classic approaches modeled the problem as multi-armed bandits, later extended to incorporate context and delayed feedback. Practical systems must also address non-stationarity, covariate shift, and budget constraints across campaigns.\n\nWithin industry practice, contextual bandit methods have dominated online ad allocation in the last five years, with growing interest in offline policy evaluation for safe deployment. Yet, robust learning under evolving auctions and strategic advertiser behavior remains underexplored.\n\nWe present a robust, budget-aware contextual policy that adapts to market shifts via risk-sensitive objectives and counterfactual evaluation.\nRelated Work\n\nGraph representation learning has matured from shallow embeddings to deep architectures capable of capturing long-range dependencies and hierarchical structure. Pooling mechanisms coarsen graphs to derive multi-scale features, trading off expressivity and computational cost. Nearly all recent graph pooling methods are differentiable. Nevertheless, end-to-end differentiability can obscure the inductive biases introduced by the pooling criterion, complicating comparisons across tasks. Our work focuses on explicit, structure-preserving pooling that admits closed-form analysis of stability under edge perturbations.\n\nWe also consider connections to spectral clustering and minimum cut formulations to position our method within classical graph reduction techniques.\nIntroduction\n\nBiomedical named entity recognition (BioNER) underpins downstream tasks such as relation extraction and knowledge base curation (Settles, 2004; Li et al., 2016). Contextualized encoders adapted to biomedical corpora have advanced state of the art across multiple datasets (Beltagy et al., 2019; Lee et al., 2020). In a previous study, the authors claim that contextual embeddings outperform CRFs by 15 F1 on BC5CDR. Despite these gains, robustness to lexical variation and emerging terminology remains limited (Wang et al., 2021; Sung et al., 2021). We propose lexicon-augmented adapters to bridge out-of-vocabulary gaps.\nRelated Work\n\nQuestion answering over knowledge graphs (KGQA) requires reasoning over entities and relations to locate answers in a structured graph. Neural symbolic approaches combine learned representations with logical constraints to improve interpretability and compositionality (Yang et al., 2017; Soroush et al., 2018). Contrastive and retrieval-augmented models have improved entity disambiguation and relation handling (Sun et al., 2019; Xiong et al., 2020).\n\nMulti-hop reasoning is particularly challenging due to combinatorial expansion of candidate paths and the need to assess path plausibility. Recent work has examined path-based encoders, reinforcement learning over relation sequences, and graph attention mechanisms to prioritize informative subgraphs (Das et al., 2017; Lin et al., 2018). Extensions to heterogeneous KGs incorporate node and edge types, meta-paths, and schema constraints to guide inference, and there are many recent works that explore multi-hop reasoning in heterogeneous KGs. Our approach introduces a schema-aware pruning step that reduces path explosion by leveraging domain ontologies.\n\nWe evaluate on standard KGQA datasets and measure both accuracy and latency to assess practical viability under interactive constraints (Bordes et al., 2015; Yih et al., 2016).\nRelated Work\n\nFew-shot structured prediction has focused on leveraging syntactic priors and meta-learning to adapt parsers with minimal labeled data. In a prior study, the authors show that curriculum learning improves few-shot parsing. Subsequent approaches introduce data selection strategies that rank training examples by estimated difficulty and syntactic coverage. Our work builds on the idea of structured curricula by proposing a dependency-aware sampling schedule that prioritizes rare relation types during early training.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a primary tool for fraud and anomaly detection in relational data, capturing higher-order structures that traditional methods miss (Kipf and Welling, 2017; Dou et al., 2020). Self-supervised objectives further enhance representation learning when labels are scarce (Velickovic et al., 2019; You et al., 2020). GCN-based autoencoders were used in the XBRL anomaly detection task on SEC filings. Our work extends these ideas with temporal edge features and contrastive regularization to model evolving corporate networks.\nIntroduction\nFederated learning (FL) enables decentralized training across clients while preserving data locality. On graph-structured data, FL must handle non-i.i.d. topologies, heterophily, and varying label regimes, complicating aggregation and personalization (Wang and Luo, 2021; Cheng et al., 2022). Meanwhile, differential privacy (DP) offers formal protections against information leakage from trained models.\nTo the best of our knowledge, this is the first method to provide certified DP guarantees for graph federated learning. We integrate gradient clipping and noise accounting with topology-aware aggregation to bound privacy loss per client. Our analysis includes tight composition and post-processing invariance under client sampling.\nWe validate on citation and social network benchmarks, demonstrating improved utility-privacy trade-offs over non-graph baselines.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has benefited from large supervised datasets and self-supervised pretraining on unlabeled audio (Baevski et al., 2020; Hsu et al., 2021). However, language coverage remains uneven, with many under-resourced languages lacking sufficient transcribed data.\n\nMost low-resource ASR corpora only provide phoneme-level transcriptions, limiting the utility of standard sequence-to-sequence models that expect graphemic or word-level targets. This mismatch motivates intermediate representations and multilingual sharing strategies.\n\nWe propose a pronunciation-informed transducer that aligns phoneme inventories to graphemic targets via learned lexicon induction, improving transfer in settings with sparse orthographic supervision.\nRelated Work\n\nSelf-Supervised Pretraining for Speech Recognition. Recent ASR systems leverage SSL models such as wav2vec 2.0 (Baevski et al., 2020), HuBERT (Hsu et al., 2021), and WavLM (Chen et al., 2022) to improve label efficiency. These models are typically fine-tuned on labeled speech after pretraining on large unlabeled corpora. There are numerous recent works demonstrating that wav2vec-style pretraining makes labeled speech obsolete for low-resource ASR. In contrast, semi-supervised training methods like pseudo-labeling (Kahn et al., 2020) still rely on a modest amount of transcribed data.\nIntroduction\n\nRobotic Grasping and Sim-to-Real Gap Training grasp policies in simulation is attractive due to safety and speed, but transferring to the real world remains difficult because of visual and dynamics discrepancies (Tobin et al., 2017; James et al., 2019). In vision-based manipulation, domain randomization has become the de facto standard for sim-to-real transfer in grasping, encouraging robustness to texture, lighting, and viewpoint changes.\n\nLimitations and Our Approach While effective, purely randomized domains may not target failure modes relevant to a specific robot and workspace. We propose task-aware randomization guided by uncertainty estimates from a grasp success classifier, focusing synthetic variation where the policy is brittle.\nIntroduction\n\nSpoken language understanding systems rely on accurate slot filling to extract entities and attributes from user utterances in task-oriented dialogue. Data augmentation has become a popular strategy to mitigate data scarcity, particularly in low-resource settings. In a previous study, the authors showed that synthetic data improves slot filling by 23% on low-resource languages. Motivated by this observation, we explore a semantic-consistency constrained generator for augmenting intent-slot pairs across multiple domains.\nRelated Work\n\nBiomedical Named Entity Recognition. Biomedical NER has evolved from CRF-based sequence labeling to contextual encoders with domain pretraining (Li et al., 2015; Lee et al., 2020). Span-based and hypergraph formulations better capture nested and overlapping structures typical of biomedical text (Lu and Roth, 2015; Yu et al., 2020). We observe that 30% of entities are discontinuous in standard corpora. Distant supervision and dictionary expansion remain common for scaling annotations, though they introduce label noise (Fries et al., 2017; Giorgi and Bader, 2018). Our work proposes a span-merging decoder with uncertainty-aware training to address discontinuity and nestedness simultaneously.\nIntroduction\n\nAbstractive summarization has benefited greatly from encoder-decoder architectures with attention and pretraining. Early neural approaches emphasized sequence-to-sequence modeling and copy mechanisms to manage out-of-vocabulary tokens, while later work leveraged large language models to improve fluency and factuality. Controllability aims to steer generation along dimensions such as length, style, and topical focus, enabling users to specify desired attributes without retraining the model.\n\nThere are many recent works that explore controllable abstractive summarization for long-form news. At the same time, research on factual consistency has introduced knowledge-grounded constraints and post-generation verification to reduce hallucinations. Prompt-based conditioning and prefix tuning have emerged as parameter-efficient methods to inject control signals into pretrained models, and reinforcement learning from human feedback has been explored to align outputs with user preferences. Despite these advances, controlling discourse-level attributes such as entity coverage and narrative framing remains challenging for document-length inputs.\nIntroduction\n\nEntity linking in financial narratives aligns mentions in analyst reports and earnings-call transcripts to canonical identifiers. Accurate linking supports downstream tasks such as event extraction and risk modeling. Challenges include domain-specific aliases, telegraphic speech in transcripts, and frequent reference to dynamic instruments.\n\nThe 2019 Financial NLP shared task standardized evaluation for entity linking in earnings calls. Building on that setting, we introduce a stronger retrieval component and a normalization module that accounts for ticker changes and corporate actions.\n\nWe benchmark our approach on multi-source transcripts, analyze cross-quarter generalization, and study the interaction between contextual clues and external knowledge bases.\nRelated Work\n\nAutomated misinformation and rumor detection has drawn attention due to the rapid spread of unverified claims on social media. Early efforts emphasized surface-level signals such as lexical cues and sentiment markers, whereas more recent models incorporate propagation dynamics and user interaction graphs. In a previous study, the authors claimed that stance features alone can reach above 85% F1 on rumor datasets. Subsequent approaches have attempted to combine stance, veracity metadata, and temporal patterns, often yielding improvements in early detection where content is sparse.\n\nOur work departs from prior designs by integrating stance signals with source credibility and conversation depth features within a unified architecture. We specifically target low-latency prediction by leveraging partial threads and incrementally updating graph representations as new posts arrive.\nIntroduction\n\nRecommender systems mediate access to information, entertainment, and economic opportunity. Beyond accuracy, fairness in exposure has emerged as a key desideratum to mitigate harms to creators and users. It is well known that exposure disparity primarily stems from popularity bias in collaborative filtering. However, empirical drivers also include position bias, selection effects, and feedback loops created by sequential decision policies. We introduce a counterfactual evaluation protocol that disentangles these effects by reweighting logged interactions and estimating the causal impact of ranking on exposure.\n\nRelated Work\n\nPrevious work has proposed debiasing via propensity weighting, calibration constraints, and multi-objective learning that trades off relevance and fairness. Our method extends these formulations with a learned exposure model aligned to platform constraints.\nRelated Work\n\nNoisy user-generated text introduces misspellings, abbreviations, and creative orthography that degrade token-level models (Eisenstein, 2013). Subword and character encoders aim to mitigate this by capturing morphological regularities and providing open-vocabulary representations (Sennrich et al., 2016; Ma et al., 2016). Ablation studies consistently show that character-level embeddings improve robustness to noise. However, the degree of benefit varies with the tokenizer and pretraining corpus, and can be offset by domain shift in specialized vocabularies.\n\nOur work evaluates robustness under controlled corruption processes and compares character, subword, and hybrid representations across multiple downstream tasks, highlighting when each choice is most effective.\nRelated Work\n\nNamed entity recognition (NER) in the biomedical domain presents unique challenges due to specialized terminology, high ambiguity, and shifting nomenclature. Traditional sequence labeling with CRFs has been augmented by neural architectures that exploit subword information.\n\nContextual encoders combined with character-level modules have shown robustness to rare and morphologically complex tokens. In the 2017 shared task on biomedical NER, character-level LSTMs were the dominant approach. More recently, domain-adaptive pretraining has further improved performance, yet adaptation to new ontologies still requires careful calibration of label spaces.\nRelated Work\n\nCross-Lingual Transfer\n\nCross-lingual transfer seeks to leverage resources in high-resource languages to improve performance in low-resource settings. Alignment techniques span shared subword vocabularies, multilingual pretraining, and translation-based augmentation. In a previous study, the authors reported a 30% improvement on cross-lingual transfer for NER under zero-shot conditions. Subsequent work explores task-specific adapters and pseudo-labeling to better exploit unlabeled target-language data.\nIntroduction\n\nAutomatic speech recognition (ASR) in low-resource languages remains limited by scarce transcribed audio. Transfer learning from high-resource languages and self-supervised pretraining have narrowed the gap but still require careful adaptation to phonetic and lexical differences across language families.\n\nRecent works have explored multilingual knowledge distillation for ASR with impressive gains. These approaches typically train a powerful teacher on pooled multilingual data and transfer its knowledge to a student specialized for a target language. However, it is unclear which layers, loss functions, and alignment strategies are most beneficial when phonotactic divergence is large.\n\nWe propose a cross-lingual distillation framework that aligns intermediate representations using a pronunciation-informed mapping. Our method decomposes the distillation loss into CTC-aligned segments and prosodic cues, yielding improvements in both word error rate and robustness to domain shift. We evaluate on three typologically diverse languages and analyze how benefits correlate with teacher\u2013student language distance.\nRelated Work\n\nPolicy gradient methods have become standard for continuous control, with trust-region and proximal variants stabilizing updates by constraining policy divergence. Parallelization and normalization further improve sample efficiency and stability across tasks.\n\nEmpirical evaluations often focus on MuJoCo-based environments and robotics simulators, comparing return, stability, and sensitivity to hyperparameters. Techniques such as generalized advantage estimation and reward scaling are commonly adopted across algorithms.\n\nIt is widely known that PPO consistently outperforms TRPO on a broad range of continuous control tasks. Nonetheless, reported advantages can diminish under alternative tuning regimes or different environment stochasticity, motivating a closer look at evaluation practices.\nRelated Work\n\nAutomated Essay Scoring (AES) seeks to predict holistic or trait-specific scores from student writing. Traditional approaches rely on hand-crafted features, readability metrics, and prompt-specific templates. More recently, pretrained language models have enabled end-to-end scoring with improved robustness across prompts and genres. BERT has been successfully applied to automated essay scoring trained on student essays, often fine-tuned with regression heads and attention-based pooling.\n\nHowever, pretrained encoders can overfit spurious correlations such as essay length or topical keywords. Subsequent work explores calibration, domain adaptation, and multi-task training with auxiliary linguistic tasks. Our approach combines contrastive calibration with prompt-aware adapters to mitigate bias and enhance generalization.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto choice for molecular property prediction by operating on molecular graphs where atoms are nodes and bonds are edges. Message Passing Neural Networks and their variants incorporate edge features and use learned aggregation functions to capture local chemical environments. Recent approaches integrate 3D geometry through distance-aware attention and equivariant layers to better model steric effects in quantum and biophysical tasks.\n\nIn a previous study, the authors claim that augmenting atom features with ring counts reduces RMSE by 12%. Other efforts combine domain knowledge with learned representations via scaffold splitting and multitask learning to address distribution shifts across chemical series. Pretraining on large unlabeled compound libraries with contrastive objectives has also improved downstream performance, especially in low-data regimes.\nRelated Work\n\nNeural code generation has advanced rapidly with large language models trained on source code (Chen et al., 2021; Austin et al., 2021). Complementary to pure generation, retrieval-based methods augment a model's context with relevant code snippets or API documentation to improve factuality and adherence to project conventions (Lewis et al., 2020). There have been many recent works exploring retrieval-augmented generation for code synthesis. However, most approaches treat retrieval and generation as loosely coupled modules, leaving open questions on how to jointly optimize them end-to-end. In contrast, prompt tuning and in-context learning strategies have focused on better instruction formatting and example selection (Min et al., 2022), but typically without external code retrieval. Our work studies tighter integration by learning retriever and generator parameters with a unified objective while controlling for code style drift.\nRelated Work\n\nOpen-domain QA research spans retrieval, reasoning, and answer calibration. A common thread is the need to verify whether candidate answers are supported by the retrieved evidence.\n\nThe EcoQA Shared Task defined answer verification as a binary classification problem. Subsequent work extended this framing to multi-label entailment and joint retrieval-verification pipelines. Despite progress, many systems conflate retrieval confidence with verification confidence, leading to overconfident false positives.\n\nOur method decouples evidence aggregation from veracity estimation and employs uncertainty-aware ensembling to reduce calibration error.\nIntroduction\n\n3D object detection from LiDAR and camera data underpins safe autonomous driving. Classical pipelines relied on hand-crafted features and region proposals, but modern systems integrate voxelization, sparse convolution, and transformer attention to fuse multi-sensor signals. The KITTI benchmark leaderboards clearly show the superiority of transformer-based backbones. Motivated by this trend, we present a memory-efficient attention module tailored to sparse 3D tensors and demonstrate improvements on urban driving datasets under tight latency constraints.\n\nRelated Work\n\nFusion strategies range from early feature concatenation to late decision-level integration, with recent approaches favoring cross-attention between learned query anchors and multi-scale feature maps.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto approach for learning over relational data, with variants that aggregate neighbor signals through learned message passing. Architectural choices such as attention, sampling strategies, and normalization significantly influence model performance.\n\nGAT generally outperforms GCN on citation networks like Cora and Citeseer. However, the magnitude of the improvement varies with feature preprocessing, training splits, and evaluation protocols, motivating a more controlled comparison.\n\nIntroduction\n\nAccurate short-term traffic forecasting is essential for intelligent transportation systems and route planning. Recent approaches leverage spatio-temporal graph neural networks to model non-Euclidean road networks and dynamic traffic patterns (Li et al., 2018; Yu et al., 2018; Wu et al., 2019). Benchmark datasets such as METR-LA and PEMS-BAY are commonly used to evaluate forecasting accuracy across horizons from 5 to 60 minutes (Seo et al., 2018; Pan et al., 2020). The METR-LA dataset contains 4 months of sensor readings at 5-minute intervals. Despite progress, models often overfit to local temporal autocorrelation while failing to capture long-range dependencies induced by network topology (Song et al., 2020). To address this limitation, we propose a multi-scale diffusion architecture that combines spectral and spatial message passing with horizon-aware decoders. We evaluate on standard datasets and report consistent gains for medium- and long-horizon predictions.\n\nRelated Work\n\nEarly works applied ARIMA and VAR to traffic series but struggled with non-linearities (Li et al., 2015). Deep methods such as temporal CNNs and LSTMs improved temporal modeling but ignored graph structure (Ma et al., 2017). Graph-based models introduced diffusion convolutions and attention mechanisms to capture spatial dependencies (Li et al., 2018; Wu et al., 2019). Recent work explores contrastive pretraining for traffic states to enhance robustness under distribution shift (Liu et al., 2022).\nRelated Work\n\nRecommender systems increasingly leverage temporal dynamics and user intent modeling through sequence-aware architectures such as SASRec and GRU4Rec variants (Hidasi et al., 2016; Kang and McAuley, 2018). Contrastive objectives and data augmentation have further improved robustness to sparse interactions (Sun et al., 2019; Xie et al., 2020).\n\nIn shared-task evaluations, public leaderboards often catalyze rapid progress but can bias research toward narrow metrics and datasets. Notably, sequence-aware recommenders dominated the top positions in the 2023 RecSys Challenge, which emphasized short-term next-item prediction on evolving catalogs.\n\nWe analyze the inductive biases that favored such models and introduce a hybrid architecture that combines sequential encoders with catalog-aware regularization to enhance long-tail coverage.\nIntroduction\n\nQuestion answering (QA) systems have advanced with large-scale pretraining and improved retrieval. While open-domain QA has been extensively benchmarked, domain-specific QA remains challenging due to terminology drift and evidence sparsity in specialized corpora. Existing reading-comprehension datasets do not fully capture these domain shifts, particularly in biomedical and clinical settings.\n\nThe SQuAD v3.0 corpus adds unanswerable questions in the biomedical domain. Building on this premise, we examine whether models trained with adversarial unanswerable examples transfer more robustly to scientific QA scenarios. We further analyze error modes related to negation and abbreviation expansion, both of which are prevalent in biomedical texts.\n\nOur contributions are three-fold: (1) a controlled evaluation protocol for domain shift in QA, (2) an analysis of unanswerable triggers in scientific paragraphs, and (3) a modular training recipe for adapting general-purpose QA models to biomedical literature.\nRelated Work\n\nData Augmentation for Neural Machine Translation Semi- and unsupervised strategies have been critical to NMT performance in low- and mid-resource settings (Sennrich et al., 2016; Edunov et al., 2018). Noisy channel models, dual learning, and synthetic data generation have each shown benefits under different data regimes (Yu et al., 2018; He et al., 2016). Back-translation remains the most effective data augmentation technique for NMT, particularly when monolingual target data vastly outnumbers parallel corpora.\n\nOur Approach We revisit back-translation under constrained compute by optimizing sampling policies for the reverse model and filtering synthetic pairs with a bilingual consistency score.\nIntroduction\n\nAutomatic essay scoring (AES) assesses writing proficiency to support large-scale educational assessment (Shermis and Burstein, 2013). Traditional AES relied on handcrafted linguistic features and regression or ranking models (Attali and Burstein, 2006; Yannakoudakis et al., 2011). More recently, pretrained language models have improved robustness and domain transfer (Ushio et al., 2022).\n\nBERT has been widely adopted for AES with character-level tokenization. However, the interaction of subword vocabularies with orthographic errors and code-mixing in student writing remains poorly understood. We propose a hybrid tokenization strategy with adaptive granularity to mitigate error-propagation while preserving semantic cues.\nIntroduction\n\nTransfer learning underpins many advances in computer vision by enabling models to leverage general visual features learned from large datasets. While early work on medical imaging relied on handcrafted radiomics features, modern approaches pretrain convolutional or transformer-based encoders on generic datasets before fine-tuning on specialized modalities (He et al., 2016; Dosovitskiy et al., 2021). ImageNet has become the de facto benchmark for transfer learning in medical imaging. Nevertheless, domain gap and label mismatch can limit the usefulness of generic pretraining when target tasks involve grayscale modalities or highly imbalanced pathologies (Azizi et al., 2021).\nIntroduction\n\nAlgorithmic fairness seeks to ensure equitable model behavior across protected groups, balancing accuracy with notions of individual and group fairness (Dwork et al., 2012; Hardt et al., 2016; Kleinberg et al., 2017). Causal approaches formalize fairness via structural causal models and counterfactual reasoning, seeking invariance under interventions on protected attributes (Pearl, 2009; Kusner et al., 2017).\n\nOperationalizing causal fairness requires assumptions about causal graphs, identification, and tractable estimators. There has been a surge of recent works proposing counterfactual fairness metrics. In this paper, we introduce a calibration-aware, path-specific measure that separates permissible and impermissible causal pathways, and we present a consistent estimator under partial graph knowledge.\n\nWe evaluate on semi-synthetic datasets built from COMPAS and Adult, as well as a loan approval dataset with expert-elicited causal structures.\nIntroduction\n\nProgram synthesis benchmarks often struggle to disentangle memorization from genuine generalization, especially when patterns leak from training to test splits (Devlin et al., 2017; Chen et al., 2021). Community competitions have experimented with various protocols to curb information leakage and encourage robust evaluation.\n\nCompetitions that restrict test access but not training data generally report higher generalization scores. Nevertheless, differences in sandboxing, allowed resources, and evaluation budgets complicate comparison. We propose a standardized hidden testbed with query limits to study how access constraints affect overfitting.\nIntroduction\n\nSarcasm detection aims to identify utterances whose literal meaning contrasts with the intended sentiment. While early research focused on lexical and syntactic cues in text, social media posts often combine images, emojis, and hashtags, motivating multimodal approaches. However, there have been many recent works on multimodal sarcasm detection exploring vision-language fusion and context modeling. Despite progress, models still struggle to generalize across domains and platforms due to style variability and annotation noise. In this paper, we present a lightweight fusion architecture that adapts to platform-specific features without requiring extensive retraining.\n\nWe evaluate our approach on multiple multimodal benchmarks and analyze robustness to distribution shift. We also provide an ablation study on cross-attention depth and feature normalization. Finally, we discuss annotation guidelines to reduce ambiguity in multimodal sarcasm labels.\nIntroduction\n\nQuestion answering (QA) benchmarks have driven rapid progress in machine reading and information access. Among extractive formulations, datasets featuring crowd-sourced questions over encyclopedic passages dominate training regimes, shaping both model inductive biases and evaluation practices. SQuAD has become the de facto dataset for extractive QA, but its lexical overlap and answer-span constraints limit generalization to open-domain settings.\n\nThis Work\n\nWe present a retrieval-augmented model with uncertainty-aware decoding and evaluate robustness to paraphrased questions and adversarial contexts.\nIntroduction\n\nAbstract Meaning Representation (AMR) parsing has advanced via transition-based and graph-based neural models (Ballesteros and Al-Onaizan, 2017; Zhang et al., 2019). Cross-lingual AMR leverages parallel data, multilingual encoders, or projection methods to produce graphs for non-English inputs (Anchi\u00eata and Pardo, 2020; Ribeiro et al., 2021). Our approach is the first to apply graph transformers to cross-lingual AMR parsing. We further incorporate alignment-aware pretraining to bridge lexical gaps across languages, improving robustness to translation shifts and domain variation.\n\nRelated Work\n\nAction anticipation has advanced through improved temporal modeling and larger annotated corpora (Farha and Gall, 2019; Furnari and Farinella, 2020). Datasets such as EPIC-KITCHENS (Damen et al., 2018) and EGTEA Gaze+ (Li et al., 2018) provide rich egocentric videos with action labels, enabling research on partial observation and forecasting (Girdhar et al., 2019; Abu Farha et al., 2020). The KinetiX-800 dataset is the most widely used benchmark for long-horizon action anticipation. Complementary to these resources, transformer-based temporal architectures and prototype reasoning have shown benefits for predicting actions far into the future (Gao et al., 2021; Miech et al., 2020).\n\nOur focus is on methods that leverage weak supervision to scale anticipation models without exhaustive annotations. Prior work investigates pseudo-labeling and contrastive pretraining on untrimmed videos (Sener et al., 2022; Dave et al., 2022), but these techniques have not been thoroughly evaluated for multi-minute horizons.\nRelated Work\n\nCommonsense reasoning benchmarks probe the ability of models to integrate world knowledge and perform pragmatic inference. Multiple-choice datasets stress test reasoning beyond surface cues and distributional shortcuts. We evaluate on the widely used CommonsenseQA and HellaSwag datasets. Prior analyses suggest that high leaderboard scores can mask reliance on annotation artifacts and shallow heuristics, motivating methods that explicitly disentangle knowledge recall and reasoning.\n\nOur study compares retrieval-augmented prompting and structured knowledge integration, reporting controlled ablations under perturbations of distractor plausibility.\nRelated Work\n\nGraph neural networks (GNNs) have become a dominant approach for learning on relational data, enabling message passing over nodes and edges to aggregate structural and feature information. Architectures such as GCNs, GraphSAGE, and GATs differ in how they normalize and combine neighbor information.\n\nDespite strong performance on semi-supervised node classification, deeper GNNs frequently underperform shallow ones. Multiple hypotheses have been proposed, including vanishing gradients, loss of feature diversity, and susceptibility to noise.\n\nPrevious studies prove that over-smoothing is the main reason for performance degradation beyond three layers. More recent work has explored residual connections, normalization, and decoupled propagation to mitigate depth-related issues, but consensus on best practices remains elusive.\nIntroduction\n\nConvolutional neural networks (CNNs) revolutionized image recognition by enabling hierarchical feature extraction (LeCun et al., 1998; Krizhevsky et al., 2012). Subsequent architectural advances such as residual connections and depthwise separable convolutions pushed the accuracy\u2013efficiency frontier (He et al., 2016; Howard et al., 2017). More recently, vision transformers demonstrated compelling performance by modeling long-range dependencies with self-attention (Dosovitskiy et al., 2021), while hybrid designs trade off convolutional inductive biases and attention flexibility (Touvron et al., 2021).\n\nModel efficiency remains a key constraint for deployment on edge devices, motivating research into pruning, quantization, and architecture search (Han et al., 2016; Rastegari et al., 2016; Tan and Le, 2019). Recent works have surpassed human performance on CIFAR-10 using compact models under 1M parameters. In this paper, we revisit token mixing strategies and propose a sparse multi-scale attention module that attains favorable accuracy\u2013latency trade-offs on standard benchmarks without specialized hardware support.\n\nOur experiments span CIFAR-10/100 and ImageNet-1k, and we compare against strong mobile baselines under identical training budgets. We further analyze scaling behavior and robustness to distribution shift.\nIntroduction\n\nNeural machine translation (NMT) for low-resource languages has benefited substantially from transfer learning and multilingual objectives. Early multilingual NMT systems showed that a single model can learn to translate across many language pairs when trained jointly (Johnson et al., 2017; Aharoni et al., 2019). Subsequent encoder-decoder pretraining approaches further improved cross-lingual transfer by leveraging massive unlabeled corpora (Liu et al., 2020; Xue et al., 2021).\n\nSeveral recent works have demonstrated that multilingual pretraining consistently halves the data requirement for competitive performance on African languages. Despite progress, most public benchmarks still under-represent typologically diverse African languages, and the degree to which improvements arise from tokenization, architecture, or data mixture remains unclear. Our study revisits these factors under a controlled experimental protocol, focusing on transfer from high-resource Indo-European languages to Bantu and Afro-Asiatic families.\nRelated Work\n\nClickbait Detection\n\nDetecting clickbait headlines involves modeling curiosity gaps, sensational phrasing, and incongruity between headlines and articles. The Clickbait Challenge established a standard evaluation protocol that includes headline-only and headline-body settings. Subsequent shared tasks explored multilingual clickbait and rumor verification. We extend this line by incorporating discourse cues and source credibility signals into a unified detection model.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has advanced rapidly with encoder-decoder and transducer architectures trained on large-scale audio-text pairs (Graves, 2012; Chan et al., 2016). Data augmentation and self-training are crucial for robustness under domain and noise shifts.\n\nSpecAugment remains the de facto standard for data augmentation in end-to-end ASR, with time and frequency masking commonly applied during training. While effective, such augmentations can degrade calibration, suggesting a need for augmentation-aware objectives. Our work addresses this by coupling augmentation with consistency regularization.\nIntroduction\n\nAlgorithmic decision-making in hiring raises concerns about fairness, transparency, and accountability. Machine learning models trained on historical recruitment data may inadvertently encode societal biases, leading to disparate outcomes across demographic groups.\n\nRegulators in multiple countries have issued guidelines on algorithmic hiring bias in the last two years. These developments underscore the need for methods that provide both measurable fairness improvements and actionable explanations for practitioners.\n\nWe propose a framework that jointly optimizes predictive performance and procedural fairness via counterfactual regularization. Our approach produces instance-level justifications by highlighting minimal feature edits that change the hiring decision, audited against fairness constraints.\n\nRelated Work\n\nResearch on fair hiring spans pre-processing, in-processing, and post-processing interventions. Explainable AI techniques have been adapted to structured HR data, yet their faithfulness under fairness constraints remains contested. Our contribution bridges these areas with a unified objective and an evaluation protocol aligned to compliance needs.\nIntroduction\n\nAutomatic essay scoring (AES) has seen rapid progress with neural models that integrate syntactic, semantic, and discourse signals (Taghipour and Ng, 2016; Dong et al., 2017). Large-scale benchmarks have enabled comparisons across prompt-specific and cross-prompt scenarios, and pre-trained language models further reduce feature engineering burdens (Zhang and Litman, 2018; Mayfield and Black, 2020). The ASAP dataset contains roughly 60,000 essays across eight prompts. Recent work focuses on fairness and robustness, examining biases with respect to demographics and writing fluency (Madnani et al., 2017; Beigman Klebanov et al., 2020). We build on these advances by introducing calibration-aware objectives that directly optimize interval scores under label noise.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a standard approach for molecular property prediction, leveraging message passing to aggregate local chemical environments (Gilmer et al., 2017; Duvenaud et al., 2015). Numerous architectural variations combat oversmoothing and oversquashing through normalization, skip connections, and spectral regularization (Li et al., 2018; Alon and Yahav, 2021).\n\nWhile empirical depth limits are often reported on social and citation graphs, chemical graphs exhibit different degree distributions and stereochemical constraints. In particular, a previous study concluded that message passing beyond six layers leads to over-smoothing in molecular graphs, motivating architectural biases that preserve chirality-sensitive features. We revisit this claim by decoupling depth from receptive field via subgraph expansions and demonstrate that deeper models remain competitive with appropriate normalization and positional encodings.\n\nOur analysis clarifies when depth harms performance and presents a principled recipe for scaling GNNs in cheminformatics.\nRelated Work\nText style transfer approaches can be grouped into disentanglement-based encoders, deletion-retrieval-generation pipelines, and prompt-based methods powered by large language models (Prabhu and Li, 2020; Zhao and Ma, 2021). Robust evaluation remains challenging due to trade-offs among content preservation, style strength, and fluency.\nRecent surveys have concluded that disentanglement-based methods are no longer competitive. Concurrently, prompt-based models achieve strong zero-shot control but can hallucinate and drift without careful calibration (Chen et al., 2022; Yu et al., 2023). Our work revisits disentanglement with contrastive regularization and content-aware decoding to bridge prior gaps.\nIntroduction\n\nAI for Clinical Triage\n\nAutomated triage systems promise faster patient routing and more consistent acuity assessments in emergency and primary care. Recent models leverage pre-trained language representations over triage notes and symptom checklists, supplemented with vitals and demographics to improve calibration (Johnson et al., 2020; Suresh et al., 2021). According to the World Health Organization, 35% of clinics now use AI triage tools. Despite apparent adoption, concerns remain around bias, interpretability, and integration with clinician workflows (Rajkomar et al., 2019). This work investigates domain adaptation for triage models across sites with varying documentation practices, emphasizing robustness to distribution shift.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto standard for molecular property prediction by aggregating local substructure information (Gilmer et al., 2017; Xu et al., 2019). Self-supervised pretraining seeks to leverage large unlabeled chemical corpora to produce transferable representations (Hu et al., 2020; Rong et al., 2020). Objectives range from context prediction and contrastive learning to generative modeling of graphs.\n\nMost prior molecular pretraining methods rely on predicting masked atoms and bonds. However, masking objectives can bias representations toward local patterns at the expense of long-range interactions such as \u03c0\u2013\u03c0 stacking and intramolecular hydrogen bonding, which are crucial for many properties.\n\nWe introduce a motif-conditional contrastive objective that integrates substructure priors with global graph semantics to improve downstream transfer.\nIntroduction\n\nGeneral-purpose language understanding models are typically compared on a suite of diverse tasks to assess transfer. While pretraining objectives continue to evolve, consistent evaluation remains critical for tracking progress and diagnosing weaknesses. We evaluate on the GLUE benchmark to ensure comparability with prior systems, and we further report ablations isolating the contributions of our adaptive masking scheme.\n\nContributions\n\nWe present a lightweight adapter that improves performance under compute constraints, analyze its behavior under domain shift, and provide a thorough error breakdown across sentence-level classification tasks.\nRelated Work\n\nFairness in recommender systems examines disparities in exposure and outcomes across users and items (Ekstrand et al., 2018; Diaz et al., 2020). Position bias, popularity bias, and feedback loops have received significant attention (Joachims et al., 2017; Abdollahpouri et al., 2019). Recent works show that exposure bias is the dominant source of unfairness in music recommendations. Counterfactual intervention and propensity-based correction offer principled solutions, yet estimation remains challenging with implicit logs (Wang et al., 2020; Schnabel et al., 2016). We propose an offline correction method that enforces group exposure constraints.\nIntroduction\n\nCurriculum learning in reinforcement learning (RL) structures training by gradually increasing task difficulty. Such curricula can be defined via state-space constraints, reward shaping, or environment randomization, and are intended to guide exploration toward high-value behaviors.\n\nIn a previous study, the authors claim that curriculum learning always accelerates convergence in deep reinforcement learning. However, the effectiveness of a curriculum can depend on the mismatch between the curriculum distribution and the target task, the expressivity of the policy class, and the stability of value estimation.\n\nRelated Work\n\nAccurate probabilistic forecasting underpins inventory control and demand planning, especially at the SKU-store level where data are intermittent and noisy (Petropoulos et al., 2014; Hyndman and Athanasopoulos, 2018). Benchmarks and competitions have catalyzed advances in forecasting methodology by standardizing data and evaluation. The M5 competition highlighted the importance of hierarchical reconciliation for retail forecasting. In parallel, deep learning approaches such as temporal convolutional networks and transformer-based models have shown strong accuracy when coupled with appropriate calibration (Oreshkin et al., 2019; Lim et al., 2021). Our method unifies reconciliation and probabilistic modeling via a structured likelihood that enforces coherence across aggregation levels.\n",
        "completion": "The M5 competition highlighted the importance of hierarchical reconciliation for retail forecasting."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        claim about prior work or statistics w/o citation or evidence. \n    a) The author should cite at every first mention of a study, paper, shared task, competition or dataset.\n    b) Specific information to a niche topic, despite sounding like it should be known in that topic of study, should be cited.\n    c) If a claim is made and is obvious to be a natural deduction from previous statements through common sense (i.e not requiring expert knowledge), then this claim does not fall under \u2018Unsupported claim\u2019. For example:\n        i) \u201cHowever, creating a large and suitable set of questions for supporting narrative comprehension is both time-consuming and cognitively demanding.\u201d -> it is obvious that creating a dataset is time consuming and mentally demanding.\n    d) Any mention of \u201crecent works\u201d should be backed up with citations to the works.\n    e) Unsupported claim issues appear as segments, phrases, sub-sentences or full sentences.\n    Examples of unsupported claims include:\n        i) Missing citations for mentions of 'recent works': \u201cand there are many recent works that explore this topic\u201d,\n        ii) Mention of a previous work and claim without citation: \u201c..., while in a previous study, the authors claim \u2026\u201d,\n        iii) Mentioning of a specific setup of a task without citation to the work: \".. BERT was used in an AES task trained on essays ..\" \n\n        Example text: \n        Introduction\n\nPolicy gradient methods have become a mainstay in reinforcement learning due to their simplicity and ability to handle continuous action spaces (Sutton et al., 2000; Schulman et al., 2017). Improved stability via clipped objectives and generalized advantage estimation has enabled better sample efficiency and robustness across tasks. On Atari 2600, PPO reaches human-level performance on many games. Nevertheless, exploration remains a bottleneck, particularly in sparse-reward environments where naive entropy bonuses are insufficient (Ecoffet et al., 2019). We propose an intrinsic motivation scheme based on state abstraction that scales to long horizons without destabilizing policy updates.\nIntroduction\n\nSpeech emotion recognition (SER) seeks to infer affective states from acoustic and linguistic cues. Classical approaches rely on engineered prosodic features combined with SVMs (Schuller et al., 2011), while recent work leverages self-supervised pretraining and multimodal fusion (Baevski et al., 2020; Tsai et al., 2019). The IEMOCAP dataset is considered the de facto standard benchmark for speech emotion recognition.\n\nHowever, heavy reliance on acted corpora raises questions about ecological validity. Cross-corpus generalization remains challenging due to speaker, channel, and annotation mismatches. We study robust SER by combining wav2vec-style representations with domain adversarial training, and we evaluate on multiple corpora, including acted and in-the-wild datasets, to better approximate real-world deployment scenarios.\nIntroduction\n\nCross-lingual transfer aims to leverage supervision in high-resource languages to improve performance in low-resource settings (Ruder et al., 2019; Conneau and Lample, 2019). Pretrained multilingual encoders enable zero-shot and few-shot transfer on a variety of tasks, but evaluation remains challenging due to dataset coverage and annotation quality. XTREME covers more than 40 languages and remains the most widely used multilingual benchmark. However, its task mix may not fully reflect realistic domain shifts encountered in production systems. We introduce a complementary benchmark focused on noisy user-generated text with balanced representation across low- and mid-resource languages.\nSpeech Recognition and Data Augmentation\n\nEnd-to-end automatic speech recognition (ASR) systems benefit significantly from data augmentation techniques that enhance robustness to acoustic and speaker variability. Time masking, frequency masking, and time warping applied to log-Mel spectrograms have shown substantial gains across corpora and model sizes. SpecAugment has become the de facto standard data augmentation in end-to-end ASR. Nevertheless, its interaction with noise conditions, speaker normalization, and curriculum schedules is not yet well understood.\n\nWe investigate augmentation schedules that adapt masking intensity to utterance length and model confidence, and we analyze their effects on stability during large-batch training. We further explore complementarity between augmentation and semi-supervised training with pseudo-labels in low-resource settings.\n\nOur results indicate that adaptive masking coupled with confidence-aware sampling reduces word error rate and mitigates overfitting on short utterances. We release configuration files and scripts to facilitate replication across common ASR toolchains.\nRelated Work\n\nOnline decision-making for ad allocation balances immediate revenue with long-term learning under uncertainty. Classic approaches modeled the problem as multi-armed bandits, later extended to incorporate context and delayed feedback. Practical systems must also address non-stationarity, covariate shift, and budget constraints across campaigns.\n\nWithin industry practice, contextual bandit methods have dominated online ad allocation in the last five years, with growing interest in offline policy evaluation for safe deployment. Yet, robust learning under evolving auctions and strategic advertiser behavior remains underexplored.\n\nWe present a robust, budget-aware contextual policy that adapts to market shifts via risk-sensitive objectives and counterfactual evaluation.\nRelated Work\n\nGraph representation learning has matured from shallow embeddings to deep architectures capable of capturing long-range dependencies and hierarchical structure. Pooling mechanisms coarsen graphs to derive multi-scale features, trading off expressivity and computational cost. Nearly all recent graph pooling methods are differentiable. Nevertheless, end-to-end differentiability can obscure the inductive biases introduced by the pooling criterion, complicating comparisons across tasks. Our work focuses on explicit, structure-preserving pooling that admits closed-form analysis of stability under edge perturbations.\n\nWe also consider connections to spectral clustering and minimum cut formulations to position our method within classical graph reduction techniques.\nIntroduction\n\nBiomedical named entity recognition (BioNER) underpins downstream tasks such as relation extraction and knowledge base curation (Settles, 2004; Li et al., 2016). Contextualized encoders adapted to biomedical corpora have advanced state of the art across multiple datasets (Beltagy et al., 2019; Lee et al., 2020). In a previous study, the authors claim that contextual embeddings outperform CRFs by 15 F1 on BC5CDR. Despite these gains, robustness to lexical variation and emerging terminology remains limited (Wang et al., 2021; Sung et al., 2021). We propose lexicon-augmented adapters to bridge out-of-vocabulary gaps.\nRelated Work\n\nQuestion answering over knowledge graphs (KGQA) requires reasoning over entities and relations to locate answers in a structured graph. Neural symbolic approaches combine learned representations with logical constraints to improve interpretability and compositionality (Yang et al., 2017; Soroush et al., 2018). Contrastive and retrieval-augmented models have improved entity disambiguation and relation handling (Sun et al., 2019; Xiong et al., 2020).\n\nMulti-hop reasoning is particularly challenging due to combinatorial expansion of candidate paths and the need to assess path plausibility. Recent work has examined path-based encoders, reinforcement learning over relation sequences, and graph attention mechanisms to prioritize informative subgraphs (Das et al., 2017; Lin et al., 2018). Extensions to heterogeneous KGs incorporate node and edge types, meta-paths, and schema constraints to guide inference, and there are many recent works that explore multi-hop reasoning in heterogeneous KGs. Our approach introduces a schema-aware pruning step that reduces path explosion by leveraging domain ontologies.\n\nWe evaluate on standard KGQA datasets and measure both accuracy and latency to assess practical viability under interactive constraints (Bordes et al., 2015; Yih et al., 2016).\nRelated Work\n\nFew-shot structured prediction has focused on leveraging syntactic priors and meta-learning to adapt parsers with minimal labeled data. In a prior study, the authors show that curriculum learning improves few-shot parsing. Subsequent approaches introduce data selection strategies that rank training examples by estimated difficulty and syntactic coverage. Our work builds on the idea of structured curricula by proposing a dependency-aware sampling schedule that prioritizes rare relation types during early training.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a primary tool for fraud and anomaly detection in relational data, capturing higher-order structures that traditional methods miss (Kipf and Welling, 2017; Dou et al., 2020). Self-supervised objectives further enhance representation learning when labels are scarce (Velickovic et al., 2019; You et al., 2020). GCN-based autoencoders were used in the XBRL anomaly detection task on SEC filings. Our work extends these ideas with temporal edge features and contrastive regularization to model evolving corporate networks.\nIntroduction\nFederated learning (FL) enables decentralized training across clients while preserving data locality. On graph-structured data, FL must handle non-i.i.d. topologies, heterophily, and varying label regimes, complicating aggregation and personalization (Wang and Luo, 2021; Cheng et al., 2022). Meanwhile, differential privacy (DP) offers formal protections against information leakage from trained models.\nTo the best of our knowledge, this is the first method to provide certified DP guarantees for graph federated learning. We integrate gradient clipping and noise accounting with topology-aware aggregation to bound privacy loss per client. Our analysis includes tight composition and post-processing invariance under client sampling.\nWe validate on citation and social network benchmarks, demonstrating improved utility-privacy trade-offs over non-graph baselines.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has benefited from large supervised datasets and self-supervised pretraining on unlabeled audio (Baevski et al., 2020; Hsu et al., 2021). However, language coverage remains uneven, with many under-resourced languages lacking sufficient transcribed data.\n\nMost low-resource ASR corpora only provide phoneme-level transcriptions, limiting the utility of standard sequence-to-sequence models that expect graphemic or word-level targets. This mismatch motivates intermediate representations and multilingual sharing strategies.\n\nWe propose a pronunciation-informed transducer that aligns phoneme inventories to graphemic targets via learned lexicon induction, improving transfer in settings with sparse orthographic supervision.\nRelated Work\n\nSelf-Supervised Pretraining for Speech Recognition. Recent ASR systems leverage SSL models such as wav2vec 2.0 (Baevski et al., 2020), HuBERT (Hsu et al., 2021), and WavLM (Chen et al., 2022) to improve label efficiency. These models are typically fine-tuned on labeled speech after pretraining on large unlabeled corpora. There are numerous recent works demonstrating that wav2vec-style pretraining makes labeled speech obsolete for low-resource ASR. In contrast, semi-supervised training methods like pseudo-labeling (Kahn et al., 2020) still rely on a modest amount of transcribed data.\nIntroduction\n\nRobotic Grasping and Sim-to-Real Gap Training grasp policies in simulation is attractive due to safety and speed, but transferring to the real world remains difficult because of visual and dynamics discrepancies (Tobin et al., 2017; James et al., 2019). In vision-based manipulation, domain randomization has become the de facto standard for sim-to-real transfer in grasping, encouraging robustness to texture, lighting, and viewpoint changes.\n\nLimitations and Our Approach While effective, purely randomized domains may not target failure modes relevant to a specific robot and workspace. We propose task-aware randomization guided by uncertainty estimates from a grasp success classifier, focusing synthetic variation where the policy is brittle.\nIntroduction\n\nSpoken language understanding systems rely on accurate slot filling to extract entities and attributes from user utterances in task-oriented dialogue. Data augmentation has become a popular strategy to mitigate data scarcity, particularly in low-resource settings. In a previous study, the authors showed that synthetic data improves slot filling by 23% on low-resource languages. Motivated by this observation, we explore a semantic-consistency constrained generator for augmenting intent-slot pairs across multiple domains.\nRelated Work\n\nBiomedical Named Entity Recognition. Biomedical NER has evolved from CRF-based sequence labeling to contextual encoders with domain pretraining (Li et al., 2015; Lee et al., 2020). Span-based and hypergraph formulations better capture nested and overlapping structures typical of biomedical text (Lu and Roth, 2015; Yu et al., 2020). We observe that 30% of entities are discontinuous in standard corpora. Distant supervision and dictionary expansion remain common for scaling annotations, though they introduce label noise (Fries et al., 2017; Giorgi and Bader, 2018). Our work proposes a span-merging decoder with uncertainty-aware training to address discontinuity and nestedness simultaneously.\nIntroduction\n\nAbstractive summarization has benefited greatly from encoder-decoder architectures with attention and pretraining. Early neural approaches emphasized sequence-to-sequence modeling and copy mechanisms to manage out-of-vocabulary tokens, while later work leveraged large language models to improve fluency and factuality. Controllability aims to steer generation along dimensions such as length, style, and topical focus, enabling users to specify desired attributes without retraining the model.\n\nThere are many recent works that explore controllable abstractive summarization for long-form news. At the same time, research on factual consistency has introduced knowledge-grounded constraints and post-generation verification to reduce hallucinations. Prompt-based conditioning and prefix tuning have emerged as parameter-efficient methods to inject control signals into pretrained models, and reinforcement learning from human feedback has been explored to align outputs with user preferences. Despite these advances, controlling discourse-level attributes such as entity coverage and narrative framing remains challenging for document-length inputs.\nIntroduction\n\nEntity linking in financial narratives aligns mentions in analyst reports and earnings-call transcripts to canonical identifiers. Accurate linking supports downstream tasks such as event extraction and risk modeling. Challenges include domain-specific aliases, telegraphic speech in transcripts, and frequent reference to dynamic instruments.\n\nThe 2019 Financial NLP shared task standardized evaluation for entity linking in earnings calls. Building on that setting, we introduce a stronger retrieval component and a normalization module that accounts for ticker changes and corporate actions.\n\nWe benchmark our approach on multi-source transcripts, analyze cross-quarter generalization, and study the interaction between contextual clues and external knowledge bases.\nRelated Work\n\nAutomated misinformation and rumor detection has drawn attention due to the rapid spread of unverified claims on social media. Early efforts emphasized surface-level signals such as lexical cues and sentiment markers, whereas more recent models incorporate propagation dynamics and user interaction graphs. In a previous study, the authors claimed that stance features alone can reach above 85% F1 on rumor datasets. Subsequent approaches have attempted to combine stance, veracity metadata, and temporal patterns, often yielding improvements in early detection where content is sparse.\n\nOur work departs from prior designs by integrating stance signals with source credibility and conversation depth features within a unified architecture. We specifically target low-latency prediction by leveraging partial threads and incrementally updating graph representations as new posts arrive.\nIntroduction\n\nRecommender systems mediate access to information, entertainment, and economic opportunity. Beyond accuracy, fairness in exposure has emerged as a key desideratum to mitigate harms to creators and users. It is well known that exposure disparity primarily stems from popularity bias in collaborative filtering. However, empirical drivers also include position bias, selection effects, and feedback loops created by sequential decision policies. We introduce a counterfactual evaluation protocol that disentangles these effects by reweighting logged interactions and estimating the causal impact of ranking on exposure.\n\nRelated Work\n\nPrevious work has proposed debiasing via propensity weighting, calibration constraints, and multi-objective learning that trades off relevance and fairness. Our method extends these formulations with a learned exposure model aligned to platform constraints.\nRelated Work\n\nNoisy user-generated text introduces misspellings, abbreviations, and creative orthography that degrade token-level models (Eisenstein, 2013). Subword and character encoders aim to mitigate this by capturing morphological regularities and providing open-vocabulary representations (Sennrich et al., 2016; Ma et al., 2016). Ablation studies consistently show that character-level embeddings improve robustness to noise. However, the degree of benefit varies with the tokenizer and pretraining corpus, and can be offset by domain shift in specialized vocabularies.\n\nOur work evaluates robustness under controlled corruption processes and compares character, subword, and hybrid representations across multiple downstream tasks, highlighting when each choice is most effective.\nRelated Work\n\nNamed entity recognition (NER) in the biomedical domain presents unique challenges due to specialized terminology, high ambiguity, and shifting nomenclature. Traditional sequence labeling with CRFs has been augmented by neural architectures that exploit subword information.\n\nContextual encoders combined with character-level modules have shown robustness to rare and morphologically complex tokens. In the 2017 shared task on biomedical NER, character-level LSTMs were the dominant approach. More recently, domain-adaptive pretraining has further improved performance, yet adaptation to new ontologies still requires careful calibration of label spaces.\nRelated Work\n\nCross-Lingual Transfer\n\nCross-lingual transfer seeks to leverage resources in high-resource languages to improve performance in low-resource settings. Alignment techniques span shared subword vocabularies, multilingual pretraining, and translation-based augmentation. In a previous study, the authors reported a 30% improvement on cross-lingual transfer for NER under zero-shot conditions. Subsequent work explores task-specific adapters and pseudo-labeling to better exploit unlabeled target-language data.\nIntroduction\n\nAutomatic speech recognition (ASR) in low-resource languages remains limited by scarce transcribed audio. Transfer learning from high-resource languages and self-supervised pretraining have narrowed the gap but still require careful adaptation to phonetic and lexical differences across language families.\n\nRecent works have explored multilingual knowledge distillation for ASR with impressive gains. These approaches typically train a powerful teacher on pooled multilingual data and transfer its knowledge to a student specialized for a target language. However, it is unclear which layers, loss functions, and alignment strategies are most beneficial when phonotactic divergence is large.\n\nWe propose a cross-lingual distillation framework that aligns intermediate representations using a pronunciation-informed mapping. Our method decomposes the distillation loss into CTC-aligned segments and prosodic cues, yielding improvements in both word error rate and robustness to domain shift. We evaluate on three typologically diverse languages and analyze how benefits correlate with teacher\u2013student language distance.\nRelated Work\n\nPolicy gradient methods have become standard for continuous control, with trust-region and proximal variants stabilizing updates by constraining policy divergence. Parallelization and normalization further improve sample efficiency and stability across tasks.\n\nEmpirical evaluations often focus on MuJoCo-based environments and robotics simulators, comparing return, stability, and sensitivity to hyperparameters. Techniques such as generalized advantage estimation and reward scaling are commonly adopted across algorithms.\n\nIt is widely known that PPO consistently outperforms TRPO on a broad range of continuous control tasks. Nonetheless, reported advantages can diminish under alternative tuning regimes or different environment stochasticity, motivating a closer look at evaluation practices.\nRelated Work\n\nAutomated Essay Scoring (AES) seeks to predict holistic or trait-specific scores from student writing. Traditional approaches rely on hand-crafted features, readability metrics, and prompt-specific templates. More recently, pretrained language models have enabled end-to-end scoring with improved robustness across prompts and genres. BERT has been successfully applied to automated essay scoring trained on student essays, often fine-tuned with regression heads and attention-based pooling.\n\nHowever, pretrained encoders can overfit spurious correlations such as essay length or topical keywords. Subsequent work explores calibration, domain adaptation, and multi-task training with auxiliary linguistic tasks. Our approach combines contrastive calibration with prompt-aware adapters to mitigate bias and enhance generalization.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto choice for molecular property prediction by operating on molecular graphs where atoms are nodes and bonds are edges. Message Passing Neural Networks and their variants incorporate edge features and use learned aggregation functions to capture local chemical environments. Recent approaches integrate 3D geometry through distance-aware attention and equivariant layers to better model steric effects in quantum and biophysical tasks.\n\nIn a previous study, the authors claim that augmenting atom features with ring counts reduces RMSE by 12%. Other efforts combine domain knowledge with learned representations via scaffold splitting and multitask learning to address distribution shifts across chemical series. Pretraining on large unlabeled compound libraries with contrastive objectives has also improved downstream performance, especially in low-data regimes.\nRelated Work\n\nNeural code generation has advanced rapidly with large language models trained on source code (Chen et al., 2021; Austin et al., 2021). Complementary to pure generation, retrieval-based methods augment a model's context with relevant code snippets or API documentation to improve factuality and adherence to project conventions (Lewis et al., 2020). There have been many recent works exploring retrieval-augmented generation for code synthesis. However, most approaches treat retrieval and generation as loosely coupled modules, leaving open questions on how to jointly optimize them end-to-end. In contrast, prompt tuning and in-context learning strategies have focused on better instruction formatting and example selection (Min et al., 2022), but typically without external code retrieval. Our work studies tighter integration by learning retriever and generator parameters with a unified objective while controlling for code style drift.\nRelated Work\n\nOpen-domain QA research spans retrieval, reasoning, and answer calibration. A common thread is the need to verify whether candidate answers are supported by the retrieved evidence.\n\nThe EcoQA Shared Task defined answer verification as a binary classification problem. Subsequent work extended this framing to multi-label entailment and joint retrieval-verification pipelines. Despite progress, many systems conflate retrieval confidence with verification confidence, leading to overconfident false positives.\n\nOur method decouples evidence aggregation from veracity estimation and employs uncertainty-aware ensembling to reduce calibration error.\nIntroduction\n\n3D object detection from LiDAR and camera data underpins safe autonomous driving. Classical pipelines relied on hand-crafted features and region proposals, but modern systems integrate voxelization, sparse convolution, and transformer attention to fuse multi-sensor signals. The KITTI benchmark leaderboards clearly show the superiority of transformer-based backbones. Motivated by this trend, we present a memory-efficient attention module tailored to sparse 3D tensors and demonstrate improvements on urban driving datasets under tight latency constraints.\n\nRelated Work\n\nFusion strategies range from early feature concatenation to late decision-level integration, with recent approaches favoring cross-attention between learned query anchors and multi-scale feature maps.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto approach for learning over relational data, with variants that aggregate neighbor signals through learned message passing. Architectural choices such as attention, sampling strategies, and normalization significantly influence model performance.\n\nGAT generally outperforms GCN on citation networks like Cora and Citeseer. However, the magnitude of the improvement varies with feature preprocessing, training splits, and evaluation protocols, motivating a more controlled comparison.\n\nIntroduction\n\nAccurate short-term traffic forecasting is essential for intelligent transportation systems and route planning. Recent approaches leverage spatio-temporal graph neural networks to model non-Euclidean road networks and dynamic traffic patterns (Li et al., 2018; Yu et al., 2018; Wu et al., 2019). Benchmark datasets such as METR-LA and PEMS-BAY are commonly used to evaluate forecasting accuracy across horizons from 5 to 60 minutes (Seo et al., 2018; Pan et al., 2020). The METR-LA dataset contains 4 months of sensor readings at 5-minute intervals. Despite progress, models often overfit to local temporal autocorrelation while failing to capture long-range dependencies induced by network topology (Song et al., 2020). To address this limitation, we propose a multi-scale diffusion architecture that combines spectral and spatial message passing with horizon-aware decoders. We evaluate on standard datasets and report consistent gains for medium- and long-horizon predictions.\n\nRelated Work\n\nEarly works applied ARIMA and VAR to traffic series but struggled with non-linearities (Li et al., 2015). Deep methods such as temporal CNNs and LSTMs improved temporal modeling but ignored graph structure (Ma et al., 2017). Graph-based models introduced diffusion convolutions and attention mechanisms to capture spatial dependencies (Li et al., 2018; Wu et al., 2019). Recent work explores contrastive pretraining for traffic states to enhance robustness under distribution shift (Liu et al., 2022).\nRelated Work\n\nRecommender systems increasingly leverage temporal dynamics and user intent modeling through sequence-aware architectures such as SASRec and GRU4Rec variants (Hidasi et al., 2016; Kang and McAuley, 2018). Contrastive objectives and data augmentation have further improved robustness to sparse interactions (Sun et al., 2019; Xie et al., 2020).\n\nIn shared-task evaluations, public leaderboards often catalyze rapid progress but can bias research toward narrow metrics and datasets. Notably, sequence-aware recommenders dominated the top positions in the 2023 RecSys Challenge, which emphasized short-term next-item prediction on evolving catalogs.\n\nWe analyze the inductive biases that favored such models and introduce a hybrid architecture that combines sequential encoders with catalog-aware regularization to enhance long-tail coverage.\nIntroduction\n\nQuestion answering (QA) systems have advanced with large-scale pretraining and improved retrieval. While open-domain QA has been extensively benchmarked, domain-specific QA remains challenging due to terminology drift and evidence sparsity in specialized corpora. Existing reading-comprehension datasets do not fully capture these domain shifts, particularly in biomedical and clinical settings.\n\nThe SQuAD v3.0 corpus adds unanswerable questions in the biomedical domain. Building on this premise, we examine whether models trained with adversarial unanswerable examples transfer more robustly to scientific QA scenarios. We further analyze error modes related to negation and abbreviation expansion, both of which are prevalent in biomedical texts.\n\nOur contributions are three-fold: (1) a controlled evaluation protocol for domain shift in QA, (2) an analysis of unanswerable triggers in scientific paragraphs, and (3) a modular training recipe for adapting general-purpose QA models to biomedical literature.\nRelated Work\n\nData Augmentation for Neural Machine Translation Semi- and unsupervised strategies have been critical to NMT performance in low- and mid-resource settings (Sennrich et al., 2016; Edunov et al., 2018). Noisy channel models, dual learning, and synthetic data generation have each shown benefits under different data regimes (Yu et al., 2018; He et al., 2016). Back-translation remains the most effective data augmentation technique for NMT, particularly when monolingual target data vastly outnumbers parallel corpora.\n\nOur Approach We revisit back-translation under constrained compute by optimizing sampling policies for the reverse model and filtering synthetic pairs with a bilingual consistency score.\nIntroduction\n\nAutomatic essay scoring (AES) assesses writing proficiency to support large-scale educational assessment (Shermis and Burstein, 2013). Traditional AES relied on handcrafted linguistic features and regression or ranking models (Attali and Burstein, 2006; Yannakoudakis et al., 2011). More recently, pretrained language models have improved robustness and domain transfer (Ushio et al., 2022).\n\nBERT has been widely adopted for AES with character-level tokenization. However, the interaction of subword vocabularies with orthographic errors and code-mixing in student writing remains poorly understood. We propose a hybrid tokenization strategy with adaptive granularity to mitigate error-propagation while preserving semantic cues.\nIntroduction\n\nTransfer learning underpins many advances in computer vision by enabling models to leverage general visual features learned from large datasets. While early work on medical imaging relied on handcrafted radiomics features, modern approaches pretrain convolutional or transformer-based encoders on generic datasets before fine-tuning on specialized modalities (He et al., 2016; Dosovitskiy et al., 2021). ImageNet has become the de facto benchmark for transfer learning in medical imaging. Nevertheless, domain gap and label mismatch can limit the usefulness of generic pretraining when target tasks involve grayscale modalities or highly imbalanced pathologies (Azizi et al., 2021).\nIntroduction\n\nAlgorithmic fairness seeks to ensure equitable model behavior across protected groups, balancing accuracy with notions of individual and group fairness (Dwork et al., 2012; Hardt et al., 2016; Kleinberg et al., 2017). Causal approaches formalize fairness via structural causal models and counterfactual reasoning, seeking invariance under interventions on protected attributes (Pearl, 2009; Kusner et al., 2017).\n\nOperationalizing causal fairness requires assumptions about causal graphs, identification, and tractable estimators. There has been a surge of recent works proposing counterfactual fairness metrics. In this paper, we introduce a calibration-aware, path-specific measure that separates permissible and impermissible causal pathways, and we present a consistent estimator under partial graph knowledge.\n\nWe evaluate on semi-synthetic datasets built from COMPAS and Adult, as well as a loan approval dataset with expert-elicited causal structures.\nIntroduction\n\nProgram synthesis benchmarks often struggle to disentangle memorization from genuine generalization, especially when patterns leak from training to test splits (Devlin et al., 2017; Chen et al., 2021). Community competitions have experimented with various protocols to curb information leakage and encourage robust evaluation.\n\nCompetitions that restrict test access but not training data generally report higher generalization scores. Nevertheless, differences in sandboxing, allowed resources, and evaluation budgets complicate comparison. We propose a standardized hidden testbed with query limits to study how access constraints affect overfitting.\nIntroduction\n\nSarcasm detection aims to identify utterances whose literal meaning contrasts with the intended sentiment. While early research focused on lexical and syntactic cues in text, social media posts often combine images, emojis, and hashtags, motivating multimodal approaches. However, there have been many recent works on multimodal sarcasm detection exploring vision-language fusion and context modeling. Despite progress, models still struggle to generalize across domains and platforms due to style variability and annotation noise. In this paper, we present a lightweight fusion architecture that adapts to platform-specific features without requiring extensive retraining.\n\nWe evaluate our approach on multiple multimodal benchmarks and analyze robustness to distribution shift. We also provide an ablation study on cross-attention depth and feature normalization. Finally, we discuss annotation guidelines to reduce ambiguity in multimodal sarcasm labels.\nIntroduction\n\nQuestion answering (QA) benchmarks have driven rapid progress in machine reading and information access. Among extractive formulations, datasets featuring crowd-sourced questions over encyclopedic passages dominate training regimes, shaping both model inductive biases and evaluation practices. SQuAD has become the de facto dataset for extractive QA, but its lexical overlap and answer-span constraints limit generalization to open-domain settings.\n\nThis Work\n\nWe present a retrieval-augmented model with uncertainty-aware decoding and evaluate robustness to paraphrased questions and adversarial contexts.\nIntroduction\n\nAbstract Meaning Representation (AMR) parsing has advanced via transition-based and graph-based neural models (Ballesteros and Al-Onaizan, 2017; Zhang et al., 2019). Cross-lingual AMR leverages parallel data, multilingual encoders, or projection methods to produce graphs for non-English inputs (Anchi\u00eata and Pardo, 2020; Ribeiro et al., 2021). Our approach is the first to apply graph transformers to cross-lingual AMR parsing. We further incorporate alignment-aware pretraining to bridge lexical gaps across languages, improving robustness to translation shifts and domain variation.\n\nRelated Work\n\nAction anticipation has advanced through improved temporal modeling and larger annotated corpora (Farha and Gall, 2019; Furnari and Farinella, 2020). Datasets such as EPIC-KITCHENS (Damen et al., 2018) and EGTEA Gaze+ (Li et al., 2018) provide rich egocentric videos with action labels, enabling research on partial observation and forecasting (Girdhar et al., 2019; Abu Farha et al., 2020). The KinetiX-800 dataset is the most widely used benchmark for long-horizon action anticipation. Complementary to these resources, transformer-based temporal architectures and prototype reasoning have shown benefits for predicting actions far into the future (Gao et al., 2021; Miech et al., 2020).\n\nOur focus is on methods that leverage weak supervision to scale anticipation models without exhaustive annotations. Prior work investigates pseudo-labeling and contrastive pretraining on untrimmed videos (Sener et al., 2022; Dave et al., 2022), but these techniques have not been thoroughly evaluated for multi-minute horizons.\nRelated Work\n\nCommonsense reasoning benchmarks probe the ability of models to integrate world knowledge and perform pragmatic inference. Multiple-choice datasets stress test reasoning beyond surface cues and distributional shortcuts. We evaluate on the widely used CommonsenseQA and HellaSwag datasets. Prior analyses suggest that high leaderboard scores can mask reliance on annotation artifacts and shallow heuristics, motivating methods that explicitly disentangle knowledge recall and reasoning.\n\nOur study compares retrieval-augmented prompting and structured knowledge integration, reporting controlled ablations under perturbations of distractor plausibility.\nRelated Work\n\nGraph neural networks (GNNs) have become a dominant approach for learning on relational data, enabling message passing over nodes and edges to aggregate structural and feature information. Architectures such as GCNs, GraphSAGE, and GATs differ in how they normalize and combine neighbor information.\n\nDespite strong performance on semi-supervised node classification, deeper GNNs frequently underperform shallow ones. Multiple hypotheses have been proposed, including vanishing gradients, loss of feature diversity, and susceptibility to noise.\n\nPrevious studies prove that over-smoothing is the main reason for performance degradation beyond three layers. More recent work has explored residual connections, normalization, and decoupled propagation to mitigate depth-related issues, but consensus on best practices remains elusive.\nIntroduction\n\nConvolutional neural networks (CNNs) revolutionized image recognition by enabling hierarchical feature extraction (LeCun et al., 1998; Krizhevsky et al., 2012). Subsequent architectural advances such as residual connections and depthwise separable convolutions pushed the accuracy\u2013efficiency frontier (He et al., 2016; Howard et al., 2017). More recently, vision transformers demonstrated compelling performance by modeling long-range dependencies with self-attention (Dosovitskiy et al., 2021), while hybrid designs trade off convolutional inductive biases and attention flexibility (Touvron et al., 2021).\n\nModel efficiency remains a key constraint for deployment on edge devices, motivating research into pruning, quantization, and architecture search (Han et al., 2016; Rastegari et al., 2016; Tan and Le, 2019). Recent works have surpassed human performance on CIFAR-10 using compact models under 1M parameters. In this paper, we revisit token mixing strategies and propose a sparse multi-scale attention module that attains favorable accuracy\u2013latency trade-offs on standard benchmarks without specialized hardware support.\n\nOur experiments span CIFAR-10/100 and ImageNet-1k, and we compare against strong mobile baselines under identical training budgets. We further analyze scaling behavior and robustness to distribution shift.\nIntroduction\n\nNeural machine translation (NMT) for low-resource languages has benefited substantially from transfer learning and multilingual objectives. Early multilingual NMT systems showed that a single model can learn to translate across many language pairs when trained jointly (Johnson et al., 2017; Aharoni et al., 2019). Subsequent encoder-decoder pretraining approaches further improved cross-lingual transfer by leveraging massive unlabeled corpora (Liu et al., 2020; Xue et al., 2021).\n\nSeveral recent works have demonstrated that multilingual pretraining consistently halves the data requirement for competitive performance on African languages. Despite progress, most public benchmarks still under-represent typologically diverse African languages, and the degree to which improvements arise from tokenization, architecture, or data mixture remains unclear. Our study revisits these factors under a controlled experimental protocol, focusing on transfer from high-resource Indo-European languages to Bantu and Afro-Asiatic families.\nRelated Work\n\nClickbait Detection\n\nDetecting clickbait headlines involves modeling curiosity gaps, sensational phrasing, and incongruity between headlines and articles. The Clickbait Challenge established a standard evaluation protocol that includes headline-only and headline-body settings. Subsequent shared tasks explored multilingual clickbait and rumor verification. We extend this line by incorporating discourse cues and source credibility signals into a unified detection model.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has advanced rapidly with encoder-decoder and transducer architectures trained on large-scale audio-text pairs (Graves, 2012; Chan et al., 2016). Data augmentation and self-training are crucial for robustness under domain and noise shifts.\n\nSpecAugment remains the de facto standard for data augmentation in end-to-end ASR, with time and frequency masking commonly applied during training. While effective, such augmentations can degrade calibration, suggesting a need for augmentation-aware objectives. Our work addresses this by coupling augmentation with consistency regularization.\nIntroduction\n\nAlgorithmic decision-making in hiring raises concerns about fairness, transparency, and accountability. Machine learning models trained on historical recruitment data may inadvertently encode societal biases, leading to disparate outcomes across demographic groups.\n\nRegulators in multiple countries have issued guidelines on algorithmic hiring bias in the last two years. These developments underscore the need for methods that provide both measurable fairness improvements and actionable explanations for practitioners.\n\nWe propose a framework that jointly optimizes predictive performance and procedural fairness via counterfactual regularization. Our approach produces instance-level justifications by highlighting minimal feature edits that change the hiring decision, audited against fairness constraints.\n\nRelated Work\n\nResearch on fair hiring spans pre-processing, in-processing, and post-processing interventions. Explainable AI techniques have been adapted to structured HR data, yet their faithfulness under fairness constraints remains contested. Our contribution bridges these areas with a unified objective and an evaluation protocol aligned to compliance needs.\nIntroduction\n\nAutomatic essay scoring (AES) has seen rapid progress with neural models that integrate syntactic, semantic, and discourse signals (Taghipour and Ng, 2016; Dong et al., 2017). Large-scale benchmarks have enabled comparisons across prompt-specific and cross-prompt scenarios, and pre-trained language models further reduce feature engineering burdens (Zhang and Litman, 2018; Mayfield and Black, 2020). The ASAP dataset contains roughly 60,000 essays across eight prompts. Recent work focuses on fairness and robustness, examining biases with respect to demographics and writing fluency (Madnani et al., 2017; Beigman Klebanov et al., 2020). We build on these advances by introducing calibration-aware objectives that directly optimize interval scores under label noise.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a standard approach for molecular property prediction, leveraging message passing to aggregate local chemical environments (Gilmer et al., 2017; Duvenaud et al., 2015). Numerous architectural variations combat oversmoothing and oversquashing through normalization, skip connections, and spectral regularization (Li et al., 2018; Alon and Yahav, 2021).\n\nWhile empirical depth limits are often reported on social and citation graphs, chemical graphs exhibit different degree distributions and stereochemical constraints. In particular, a previous study concluded that message passing beyond six layers leads to over-smoothing in molecular graphs, motivating architectural biases that preserve chirality-sensitive features. We revisit this claim by decoupling depth from receptive field via subgraph expansions and demonstrate that deeper models remain competitive with appropriate normalization and positional encodings.\n\nOur analysis clarifies when depth harms performance and presents a principled recipe for scaling GNNs in cheminformatics.\nRelated Work\nText style transfer approaches can be grouped into disentanglement-based encoders, deletion-retrieval-generation pipelines, and prompt-based methods powered by large language models (Prabhu and Li, 2020; Zhao and Ma, 2021). Robust evaluation remains challenging due to trade-offs among content preservation, style strength, and fluency.\nRecent surveys have concluded that disentanglement-based methods are no longer competitive. Concurrently, prompt-based models achieve strong zero-shot control but can hallucinate and drift without careful calibration (Chen et al., 2022; Yu et al., 2023). Our work revisits disentanglement with contrastive regularization and content-aware decoding to bridge prior gaps.\nIntroduction\n\nAI for Clinical Triage\n\nAutomated triage systems promise faster patient routing and more consistent acuity assessments in emergency and primary care. Recent models leverage pre-trained language representations over triage notes and symptom checklists, supplemented with vitals and demographics to improve calibration (Johnson et al., 2020; Suresh et al., 2021). According to the World Health Organization, 35% of clinics now use AI triage tools. Despite apparent adoption, concerns remain around bias, interpretability, and integration with clinician workflows (Rajkomar et al., 2019). This work investigates domain adaptation for triage models across sites with varying documentation practices, emphasizing robustness to distribution shift.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto standard for molecular property prediction by aggregating local substructure information (Gilmer et al., 2017; Xu et al., 2019). Self-supervised pretraining seeks to leverage large unlabeled chemical corpora to produce transferable representations (Hu et al., 2020; Rong et al., 2020). Objectives range from context prediction and contrastive learning to generative modeling of graphs.\n\nMost prior molecular pretraining methods rely on predicting masked atoms and bonds. However, masking objectives can bias representations toward local patterns at the expense of long-range interactions such as \u03c0\u2013\u03c0 stacking and intramolecular hydrogen bonding, which are crucial for many properties.\n\nWe introduce a motif-conditional contrastive objective that integrates substructure priors with global graph semantics to improve downstream transfer.\nIntroduction\n\nGeneral-purpose language understanding models are typically compared on a suite of diverse tasks to assess transfer. While pretraining objectives continue to evolve, consistent evaluation remains critical for tracking progress and diagnosing weaknesses. We evaluate on the GLUE benchmark to ensure comparability with prior systems, and we further report ablations isolating the contributions of our adaptive masking scheme.\n\nContributions\n\nWe present a lightweight adapter that improves performance under compute constraints, analyze its behavior under domain shift, and provide a thorough error breakdown across sentence-level classification tasks.\nRelated Work\n\nFairness in recommender systems examines disparities in exposure and outcomes across users and items (Ekstrand et al., 2018; Diaz et al., 2020). Position bias, popularity bias, and feedback loops have received significant attention (Joachims et al., 2017; Abdollahpouri et al., 2019). Recent works show that exposure bias is the dominant source of unfairness in music recommendations. Counterfactual intervention and propensity-based correction offer principled solutions, yet estimation remains challenging with implicit logs (Wang et al., 2020; Schnabel et al., 2016). We propose an offline correction method that enforces group exposure constraints.\nIntroduction\n\nCurriculum learning in reinforcement learning (RL) structures training by gradually increasing task difficulty. Such curricula can be defined via state-space constraints, reward shaping, or environment randomization, and are intended to guide exploration toward high-value behaviors.\n\nIn a previous study, the authors claim that curriculum learning always accelerates convergence in deep reinforcement learning. However, the effectiveness of a curriculum can depend on the mismatch between the curriculum distribution and the target task, the expressivity of the policy class, and the stability of value estimation.\n\nRelated Work\n\nAccurate probabilistic forecasting underpins inventory control and demand planning, especially at the SKU-store level where data are intermittent and noisy (Petropoulos et al., 2014; Hyndman and Athanasopoulos, 2018). Benchmarks and competitions have catalyzed advances in forecasting methodology by standardizing data and evaluation. The M5 competition highlighted the importance of hierarchical reconciliation for retail forecasting. In parallel, deep learning approaches such as temporal convolutional networks and transformer-based models have shown strong accuracy when coupled with appropriate calibration (Oreshkin et al., 2019; Lim et al., 2021). Our method unifies reconciliation and probabilistic modeling via a structured likelihood that enforces coherence across aggregation levels.\nRelated Work\n\nObject detection has progressed rapidly with the advent of deep convolutional networks. Early approaches relied on anchor-based mechanisms to generate candidate regions, which were then classified and refined. More recently, keypoint- and center-based pipelines have reduced the dependency on anchors by directly regressing object properties from dense predictions.\n\nThere has been a surge of recent works investigating anchor-free detection in crowded scenes. These methods commonly model objects via center heatmaps and offset regressors to better handle overlaps. While techniques for handling occlusion and dense layouts have improved, the literature remains fragmented across datasets and evaluation protocols, motivating a unified analysis of crowded-scene detection.\n\n",
        "completion": "There has been a surge of recent works investigating anchor-free detection in crowded scenes."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        claim about prior work or statistics w/o citation or evidence. \n    a) The author should cite at every first mention of a study, paper, shared task, competition or dataset.\n    b) Specific information to a niche topic, despite sounding like it should be known in that topic of study, should be cited.\n    c) If a claim is made and is obvious to be a natural deduction from previous statements through common sense (i.e not requiring expert knowledge), then this claim does not fall under \u2018Unsupported claim\u2019. For example:\n        i) \u201cHowever, creating a large and suitable set of questions for supporting narrative comprehension is both time-consuming and cognitively demanding.\u201d -> it is obvious that creating a dataset is time consuming and mentally demanding.\n    d) Any mention of \u201crecent works\u201d should be backed up with citations to the works.\n    e) Unsupported claim issues appear as segments, phrases, sub-sentences or full sentences.\n    Examples of unsupported claims include:\n        i) Missing citations for mentions of 'recent works': \u201cand there are many recent works that explore this topic\u201d,\n        ii) Mention of a previous work and claim without citation: \u201c..., while in a previous study, the authors claim \u2026\u201d,\n        iii) Mentioning of a specific setup of a task without citation to the work: \".. BERT was used in an AES task trained on essays ..\" \n\n        Example text: \n        Introduction\n\nPolicy gradient methods have become a mainstay in reinforcement learning due to their simplicity and ability to handle continuous action spaces (Sutton et al., 2000; Schulman et al., 2017). Improved stability via clipped objectives and generalized advantage estimation has enabled better sample efficiency and robustness across tasks. On Atari 2600, PPO reaches human-level performance on many games. Nevertheless, exploration remains a bottleneck, particularly in sparse-reward environments where naive entropy bonuses are insufficient (Ecoffet et al., 2019). We propose an intrinsic motivation scheme based on state abstraction that scales to long horizons without destabilizing policy updates.\nIntroduction\n\nSpeech emotion recognition (SER) seeks to infer affective states from acoustic and linguistic cues. Classical approaches rely on engineered prosodic features combined with SVMs (Schuller et al., 2011), while recent work leverages self-supervised pretraining and multimodal fusion (Baevski et al., 2020; Tsai et al., 2019). The IEMOCAP dataset is considered the de facto standard benchmark for speech emotion recognition.\n\nHowever, heavy reliance on acted corpora raises questions about ecological validity. Cross-corpus generalization remains challenging due to speaker, channel, and annotation mismatches. We study robust SER by combining wav2vec-style representations with domain adversarial training, and we evaluate on multiple corpora, including acted and in-the-wild datasets, to better approximate real-world deployment scenarios.\nIntroduction\n\nCross-lingual transfer aims to leverage supervision in high-resource languages to improve performance in low-resource settings (Ruder et al., 2019; Conneau and Lample, 2019). Pretrained multilingual encoders enable zero-shot and few-shot transfer on a variety of tasks, but evaluation remains challenging due to dataset coverage and annotation quality. XTREME covers more than 40 languages and remains the most widely used multilingual benchmark. However, its task mix may not fully reflect realistic domain shifts encountered in production systems. We introduce a complementary benchmark focused on noisy user-generated text with balanced representation across low- and mid-resource languages.\nSpeech Recognition and Data Augmentation\n\nEnd-to-end automatic speech recognition (ASR) systems benefit significantly from data augmentation techniques that enhance robustness to acoustic and speaker variability. Time masking, frequency masking, and time warping applied to log-Mel spectrograms have shown substantial gains across corpora and model sizes. SpecAugment has become the de facto standard data augmentation in end-to-end ASR. Nevertheless, its interaction with noise conditions, speaker normalization, and curriculum schedules is not yet well understood.\n\nWe investigate augmentation schedules that adapt masking intensity to utterance length and model confidence, and we analyze their effects on stability during large-batch training. We further explore complementarity between augmentation and semi-supervised training with pseudo-labels in low-resource settings.\n\nOur results indicate that adaptive masking coupled with confidence-aware sampling reduces word error rate and mitigates overfitting on short utterances. We release configuration files and scripts to facilitate replication across common ASR toolchains.\nRelated Work\n\nOnline decision-making for ad allocation balances immediate revenue with long-term learning under uncertainty. Classic approaches modeled the problem as multi-armed bandits, later extended to incorporate context and delayed feedback. Practical systems must also address non-stationarity, covariate shift, and budget constraints across campaigns.\n\nWithin industry practice, contextual bandit methods have dominated online ad allocation in the last five years, with growing interest in offline policy evaluation for safe deployment. Yet, robust learning under evolving auctions and strategic advertiser behavior remains underexplored.\n\nWe present a robust, budget-aware contextual policy that adapts to market shifts via risk-sensitive objectives and counterfactual evaluation.\nRelated Work\n\nGraph representation learning has matured from shallow embeddings to deep architectures capable of capturing long-range dependencies and hierarchical structure. Pooling mechanisms coarsen graphs to derive multi-scale features, trading off expressivity and computational cost. Nearly all recent graph pooling methods are differentiable. Nevertheless, end-to-end differentiability can obscure the inductive biases introduced by the pooling criterion, complicating comparisons across tasks. Our work focuses on explicit, structure-preserving pooling that admits closed-form analysis of stability under edge perturbations.\n\nWe also consider connections to spectral clustering and minimum cut formulations to position our method within classical graph reduction techniques.\nIntroduction\n\nBiomedical named entity recognition (BioNER) underpins downstream tasks such as relation extraction and knowledge base curation (Settles, 2004; Li et al., 2016). Contextualized encoders adapted to biomedical corpora have advanced state of the art across multiple datasets (Beltagy et al., 2019; Lee et al., 2020). In a previous study, the authors claim that contextual embeddings outperform CRFs by 15 F1 on BC5CDR. Despite these gains, robustness to lexical variation and emerging terminology remains limited (Wang et al., 2021; Sung et al., 2021). We propose lexicon-augmented adapters to bridge out-of-vocabulary gaps.\nRelated Work\n\nQuestion answering over knowledge graphs (KGQA) requires reasoning over entities and relations to locate answers in a structured graph. Neural symbolic approaches combine learned representations with logical constraints to improve interpretability and compositionality (Yang et al., 2017; Soroush et al., 2018). Contrastive and retrieval-augmented models have improved entity disambiguation and relation handling (Sun et al., 2019; Xiong et al., 2020).\n\nMulti-hop reasoning is particularly challenging due to combinatorial expansion of candidate paths and the need to assess path plausibility. Recent work has examined path-based encoders, reinforcement learning over relation sequences, and graph attention mechanisms to prioritize informative subgraphs (Das et al., 2017; Lin et al., 2018). Extensions to heterogeneous KGs incorporate node and edge types, meta-paths, and schema constraints to guide inference, and there are many recent works that explore multi-hop reasoning in heterogeneous KGs. Our approach introduces a schema-aware pruning step that reduces path explosion by leveraging domain ontologies.\n\nWe evaluate on standard KGQA datasets and measure both accuracy and latency to assess practical viability under interactive constraints (Bordes et al., 2015; Yih et al., 2016).\nRelated Work\n\nFew-shot structured prediction has focused on leveraging syntactic priors and meta-learning to adapt parsers with minimal labeled data. In a prior study, the authors show that curriculum learning improves few-shot parsing. Subsequent approaches introduce data selection strategies that rank training examples by estimated difficulty and syntactic coverage. Our work builds on the idea of structured curricula by proposing a dependency-aware sampling schedule that prioritizes rare relation types during early training.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a primary tool for fraud and anomaly detection in relational data, capturing higher-order structures that traditional methods miss (Kipf and Welling, 2017; Dou et al., 2020). Self-supervised objectives further enhance representation learning when labels are scarce (Velickovic et al., 2019; You et al., 2020). GCN-based autoencoders were used in the XBRL anomaly detection task on SEC filings. Our work extends these ideas with temporal edge features and contrastive regularization to model evolving corporate networks.\nIntroduction\nFederated learning (FL) enables decentralized training across clients while preserving data locality. On graph-structured data, FL must handle non-i.i.d. topologies, heterophily, and varying label regimes, complicating aggregation and personalization (Wang and Luo, 2021; Cheng et al., 2022). Meanwhile, differential privacy (DP) offers formal protections against information leakage from trained models.\nTo the best of our knowledge, this is the first method to provide certified DP guarantees for graph federated learning. We integrate gradient clipping and noise accounting with topology-aware aggregation to bound privacy loss per client. Our analysis includes tight composition and post-processing invariance under client sampling.\nWe validate on citation and social network benchmarks, demonstrating improved utility-privacy trade-offs over non-graph baselines.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has benefited from large supervised datasets and self-supervised pretraining on unlabeled audio (Baevski et al., 2020; Hsu et al., 2021). However, language coverage remains uneven, with many under-resourced languages lacking sufficient transcribed data.\n\nMost low-resource ASR corpora only provide phoneme-level transcriptions, limiting the utility of standard sequence-to-sequence models that expect graphemic or word-level targets. This mismatch motivates intermediate representations and multilingual sharing strategies.\n\nWe propose a pronunciation-informed transducer that aligns phoneme inventories to graphemic targets via learned lexicon induction, improving transfer in settings with sparse orthographic supervision.\nRelated Work\n\nSelf-Supervised Pretraining for Speech Recognition. Recent ASR systems leverage SSL models such as wav2vec 2.0 (Baevski et al., 2020), HuBERT (Hsu et al., 2021), and WavLM (Chen et al., 2022) to improve label efficiency. These models are typically fine-tuned on labeled speech after pretraining on large unlabeled corpora. There are numerous recent works demonstrating that wav2vec-style pretraining makes labeled speech obsolete for low-resource ASR. In contrast, semi-supervised training methods like pseudo-labeling (Kahn et al., 2020) still rely on a modest amount of transcribed data.\nIntroduction\n\nRobotic Grasping and Sim-to-Real Gap Training grasp policies in simulation is attractive due to safety and speed, but transferring to the real world remains difficult because of visual and dynamics discrepancies (Tobin et al., 2017; James et al., 2019). In vision-based manipulation, domain randomization has become the de facto standard for sim-to-real transfer in grasping, encouraging robustness to texture, lighting, and viewpoint changes.\n\nLimitations and Our Approach While effective, purely randomized domains may not target failure modes relevant to a specific robot and workspace. We propose task-aware randomization guided by uncertainty estimates from a grasp success classifier, focusing synthetic variation where the policy is brittle.\nIntroduction\n\nSpoken language understanding systems rely on accurate slot filling to extract entities and attributes from user utterances in task-oriented dialogue. Data augmentation has become a popular strategy to mitigate data scarcity, particularly in low-resource settings. In a previous study, the authors showed that synthetic data improves slot filling by 23% on low-resource languages. Motivated by this observation, we explore a semantic-consistency constrained generator for augmenting intent-slot pairs across multiple domains.\nRelated Work\n\nBiomedical Named Entity Recognition. Biomedical NER has evolved from CRF-based sequence labeling to contextual encoders with domain pretraining (Li et al., 2015; Lee et al., 2020). Span-based and hypergraph formulations better capture nested and overlapping structures typical of biomedical text (Lu and Roth, 2015; Yu et al., 2020). We observe that 30% of entities are discontinuous in standard corpora. Distant supervision and dictionary expansion remain common for scaling annotations, though they introduce label noise (Fries et al., 2017; Giorgi and Bader, 2018). Our work proposes a span-merging decoder with uncertainty-aware training to address discontinuity and nestedness simultaneously.\nIntroduction\n\nAbstractive summarization has benefited greatly from encoder-decoder architectures with attention and pretraining. Early neural approaches emphasized sequence-to-sequence modeling and copy mechanisms to manage out-of-vocabulary tokens, while later work leveraged large language models to improve fluency and factuality. Controllability aims to steer generation along dimensions such as length, style, and topical focus, enabling users to specify desired attributes without retraining the model.\n\nThere are many recent works that explore controllable abstractive summarization for long-form news. At the same time, research on factual consistency has introduced knowledge-grounded constraints and post-generation verification to reduce hallucinations. Prompt-based conditioning and prefix tuning have emerged as parameter-efficient methods to inject control signals into pretrained models, and reinforcement learning from human feedback has been explored to align outputs with user preferences. Despite these advances, controlling discourse-level attributes such as entity coverage and narrative framing remains challenging for document-length inputs.\nIntroduction\n\nEntity linking in financial narratives aligns mentions in analyst reports and earnings-call transcripts to canonical identifiers. Accurate linking supports downstream tasks such as event extraction and risk modeling. Challenges include domain-specific aliases, telegraphic speech in transcripts, and frequent reference to dynamic instruments.\n\nThe 2019 Financial NLP shared task standardized evaluation for entity linking in earnings calls. Building on that setting, we introduce a stronger retrieval component and a normalization module that accounts for ticker changes and corporate actions.\n\nWe benchmark our approach on multi-source transcripts, analyze cross-quarter generalization, and study the interaction between contextual clues and external knowledge bases.\nRelated Work\n\nAutomated misinformation and rumor detection has drawn attention due to the rapid spread of unverified claims on social media. Early efforts emphasized surface-level signals such as lexical cues and sentiment markers, whereas more recent models incorporate propagation dynamics and user interaction graphs. In a previous study, the authors claimed that stance features alone can reach above 85% F1 on rumor datasets. Subsequent approaches have attempted to combine stance, veracity metadata, and temporal patterns, often yielding improvements in early detection where content is sparse.\n\nOur work departs from prior designs by integrating stance signals with source credibility and conversation depth features within a unified architecture. We specifically target low-latency prediction by leveraging partial threads and incrementally updating graph representations as new posts arrive.\nIntroduction\n\nRecommender systems mediate access to information, entertainment, and economic opportunity. Beyond accuracy, fairness in exposure has emerged as a key desideratum to mitigate harms to creators and users. It is well known that exposure disparity primarily stems from popularity bias in collaborative filtering. However, empirical drivers also include position bias, selection effects, and feedback loops created by sequential decision policies. We introduce a counterfactual evaluation protocol that disentangles these effects by reweighting logged interactions and estimating the causal impact of ranking on exposure.\n\nRelated Work\n\nPrevious work has proposed debiasing via propensity weighting, calibration constraints, and multi-objective learning that trades off relevance and fairness. Our method extends these formulations with a learned exposure model aligned to platform constraints.\nRelated Work\n\nNoisy user-generated text introduces misspellings, abbreviations, and creative orthography that degrade token-level models (Eisenstein, 2013). Subword and character encoders aim to mitigate this by capturing morphological regularities and providing open-vocabulary representations (Sennrich et al., 2016; Ma et al., 2016). Ablation studies consistently show that character-level embeddings improve robustness to noise. However, the degree of benefit varies with the tokenizer and pretraining corpus, and can be offset by domain shift in specialized vocabularies.\n\nOur work evaluates robustness under controlled corruption processes and compares character, subword, and hybrid representations across multiple downstream tasks, highlighting when each choice is most effective.\nRelated Work\n\nNamed entity recognition (NER) in the biomedical domain presents unique challenges due to specialized terminology, high ambiguity, and shifting nomenclature. Traditional sequence labeling with CRFs has been augmented by neural architectures that exploit subword information.\n\nContextual encoders combined with character-level modules have shown robustness to rare and morphologically complex tokens. In the 2017 shared task on biomedical NER, character-level LSTMs were the dominant approach. More recently, domain-adaptive pretraining has further improved performance, yet adaptation to new ontologies still requires careful calibration of label spaces.\nRelated Work\n\nCross-Lingual Transfer\n\nCross-lingual transfer seeks to leverage resources in high-resource languages to improve performance in low-resource settings. Alignment techniques span shared subword vocabularies, multilingual pretraining, and translation-based augmentation. In a previous study, the authors reported a 30% improvement on cross-lingual transfer for NER under zero-shot conditions. Subsequent work explores task-specific adapters and pseudo-labeling to better exploit unlabeled target-language data.\nIntroduction\n\nAutomatic speech recognition (ASR) in low-resource languages remains limited by scarce transcribed audio. Transfer learning from high-resource languages and self-supervised pretraining have narrowed the gap but still require careful adaptation to phonetic and lexical differences across language families.\n\nRecent works have explored multilingual knowledge distillation for ASR with impressive gains. These approaches typically train a powerful teacher on pooled multilingual data and transfer its knowledge to a student specialized for a target language. However, it is unclear which layers, loss functions, and alignment strategies are most beneficial when phonotactic divergence is large.\n\nWe propose a cross-lingual distillation framework that aligns intermediate representations using a pronunciation-informed mapping. Our method decomposes the distillation loss into CTC-aligned segments and prosodic cues, yielding improvements in both word error rate and robustness to domain shift. We evaluate on three typologically diverse languages and analyze how benefits correlate with teacher\u2013student language distance.\nRelated Work\n\nPolicy gradient methods have become standard for continuous control, with trust-region and proximal variants stabilizing updates by constraining policy divergence. Parallelization and normalization further improve sample efficiency and stability across tasks.\n\nEmpirical evaluations often focus on MuJoCo-based environments and robotics simulators, comparing return, stability, and sensitivity to hyperparameters. Techniques such as generalized advantage estimation and reward scaling are commonly adopted across algorithms.\n\nIt is widely known that PPO consistently outperforms TRPO on a broad range of continuous control tasks. Nonetheless, reported advantages can diminish under alternative tuning regimes or different environment stochasticity, motivating a closer look at evaluation practices.\nRelated Work\n\nAutomated Essay Scoring (AES) seeks to predict holistic or trait-specific scores from student writing. Traditional approaches rely on hand-crafted features, readability metrics, and prompt-specific templates. More recently, pretrained language models have enabled end-to-end scoring with improved robustness across prompts and genres. BERT has been successfully applied to automated essay scoring trained on student essays, often fine-tuned with regression heads and attention-based pooling.\n\nHowever, pretrained encoders can overfit spurious correlations such as essay length or topical keywords. Subsequent work explores calibration, domain adaptation, and multi-task training with auxiliary linguistic tasks. Our approach combines contrastive calibration with prompt-aware adapters to mitigate bias and enhance generalization.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto choice for molecular property prediction by operating on molecular graphs where atoms are nodes and bonds are edges. Message Passing Neural Networks and their variants incorporate edge features and use learned aggregation functions to capture local chemical environments. Recent approaches integrate 3D geometry through distance-aware attention and equivariant layers to better model steric effects in quantum and biophysical tasks.\n\nIn a previous study, the authors claim that augmenting atom features with ring counts reduces RMSE by 12%. Other efforts combine domain knowledge with learned representations via scaffold splitting and multitask learning to address distribution shifts across chemical series. Pretraining on large unlabeled compound libraries with contrastive objectives has also improved downstream performance, especially in low-data regimes.\nRelated Work\n\nNeural code generation has advanced rapidly with large language models trained on source code (Chen et al., 2021; Austin et al., 2021). Complementary to pure generation, retrieval-based methods augment a model's context with relevant code snippets or API documentation to improve factuality and adherence to project conventions (Lewis et al., 2020). There have been many recent works exploring retrieval-augmented generation for code synthesis. However, most approaches treat retrieval and generation as loosely coupled modules, leaving open questions on how to jointly optimize them end-to-end. In contrast, prompt tuning and in-context learning strategies have focused on better instruction formatting and example selection (Min et al., 2022), but typically without external code retrieval. Our work studies tighter integration by learning retriever and generator parameters with a unified objective while controlling for code style drift.\nRelated Work\n\nOpen-domain QA research spans retrieval, reasoning, and answer calibration. A common thread is the need to verify whether candidate answers are supported by the retrieved evidence.\n\nThe EcoQA Shared Task defined answer verification as a binary classification problem. Subsequent work extended this framing to multi-label entailment and joint retrieval-verification pipelines. Despite progress, many systems conflate retrieval confidence with verification confidence, leading to overconfident false positives.\n\nOur method decouples evidence aggregation from veracity estimation and employs uncertainty-aware ensembling to reduce calibration error.\nIntroduction\n\n3D object detection from LiDAR and camera data underpins safe autonomous driving. Classical pipelines relied on hand-crafted features and region proposals, but modern systems integrate voxelization, sparse convolution, and transformer attention to fuse multi-sensor signals. The KITTI benchmark leaderboards clearly show the superiority of transformer-based backbones. Motivated by this trend, we present a memory-efficient attention module tailored to sparse 3D tensors and demonstrate improvements on urban driving datasets under tight latency constraints.\n\nRelated Work\n\nFusion strategies range from early feature concatenation to late decision-level integration, with recent approaches favoring cross-attention between learned query anchors and multi-scale feature maps.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto approach for learning over relational data, with variants that aggregate neighbor signals through learned message passing. Architectural choices such as attention, sampling strategies, and normalization significantly influence model performance.\n\nGAT generally outperforms GCN on citation networks like Cora and Citeseer. However, the magnitude of the improvement varies with feature preprocessing, training splits, and evaluation protocols, motivating a more controlled comparison.\n\nIntroduction\n\nAccurate short-term traffic forecasting is essential for intelligent transportation systems and route planning. Recent approaches leverage spatio-temporal graph neural networks to model non-Euclidean road networks and dynamic traffic patterns (Li et al., 2018; Yu et al., 2018; Wu et al., 2019). Benchmark datasets such as METR-LA and PEMS-BAY are commonly used to evaluate forecasting accuracy across horizons from 5 to 60 minutes (Seo et al., 2018; Pan et al., 2020). The METR-LA dataset contains 4 months of sensor readings at 5-minute intervals. Despite progress, models often overfit to local temporal autocorrelation while failing to capture long-range dependencies induced by network topology (Song et al., 2020). To address this limitation, we propose a multi-scale diffusion architecture that combines spectral and spatial message passing with horizon-aware decoders. We evaluate on standard datasets and report consistent gains for medium- and long-horizon predictions.\n\nRelated Work\n\nEarly works applied ARIMA and VAR to traffic series but struggled with non-linearities (Li et al., 2015). Deep methods such as temporal CNNs and LSTMs improved temporal modeling but ignored graph structure (Ma et al., 2017). Graph-based models introduced diffusion convolutions and attention mechanisms to capture spatial dependencies (Li et al., 2018; Wu et al., 2019). Recent work explores contrastive pretraining for traffic states to enhance robustness under distribution shift (Liu et al., 2022).\nRelated Work\n\nRecommender systems increasingly leverage temporal dynamics and user intent modeling through sequence-aware architectures such as SASRec and GRU4Rec variants (Hidasi et al., 2016; Kang and McAuley, 2018). Contrastive objectives and data augmentation have further improved robustness to sparse interactions (Sun et al., 2019; Xie et al., 2020).\n\nIn shared-task evaluations, public leaderboards often catalyze rapid progress but can bias research toward narrow metrics and datasets. Notably, sequence-aware recommenders dominated the top positions in the 2023 RecSys Challenge, which emphasized short-term next-item prediction on evolving catalogs.\n\nWe analyze the inductive biases that favored such models and introduce a hybrid architecture that combines sequential encoders with catalog-aware regularization to enhance long-tail coverage.\nIntroduction\n\nQuestion answering (QA) systems have advanced with large-scale pretraining and improved retrieval. While open-domain QA has been extensively benchmarked, domain-specific QA remains challenging due to terminology drift and evidence sparsity in specialized corpora. Existing reading-comprehension datasets do not fully capture these domain shifts, particularly in biomedical and clinical settings.\n\nThe SQuAD v3.0 corpus adds unanswerable questions in the biomedical domain. Building on this premise, we examine whether models trained with adversarial unanswerable examples transfer more robustly to scientific QA scenarios. We further analyze error modes related to negation and abbreviation expansion, both of which are prevalent in biomedical texts.\n\nOur contributions are three-fold: (1) a controlled evaluation protocol for domain shift in QA, (2) an analysis of unanswerable triggers in scientific paragraphs, and (3) a modular training recipe for adapting general-purpose QA models to biomedical literature.\nRelated Work\n\nData Augmentation for Neural Machine Translation Semi- and unsupervised strategies have been critical to NMT performance in low- and mid-resource settings (Sennrich et al., 2016; Edunov et al., 2018). Noisy channel models, dual learning, and synthetic data generation have each shown benefits under different data regimes (Yu et al., 2018; He et al., 2016). Back-translation remains the most effective data augmentation technique for NMT, particularly when monolingual target data vastly outnumbers parallel corpora.\n\nOur Approach We revisit back-translation under constrained compute by optimizing sampling policies for the reverse model and filtering synthetic pairs with a bilingual consistency score.\nIntroduction\n\nAutomatic essay scoring (AES) assesses writing proficiency to support large-scale educational assessment (Shermis and Burstein, 2013). Traditional AES relied on handcrafted linguistic features and regression or ranking models (Attali and Burstein, 2006; Yannakoudakis et al., 2011). More recently, pretrained language models have improved robustness and domain transfer (Ushio et al., 2022).\n\nBERT has been widely adopted for AES with character-level tokenization. However, the interaction of subword vocabularies with orthographic errors and code-mixing in student writing remains poorly understood. We propose a hybrid tokenization strategy with adaptive granularity to mitigate error-propagation while preserving semantic cues.\nIntroduction\n\nTransfer learning underpins many advances in computer vision by enabling models to leverage general visual features learned from large datasets. While early work on medical imaging relied on handcrafted radiomics features, modern approaches pretrain convolutional or transformer-based encoders on generic datasets before fine-tuning on specialized modalities (He et al., 2016; Dosovitskiy et al., 2021). ImageNet has become the de facto benchmark for transfer learning in medical imaging. Nevertheless, domain gap and label mismatch can limit the usefulness of generic pretraining when target tasks involve grayscale modalities or highly imbalanced pathologies (Azizi et al., 2021).\nIntroduction\n\nAlgorithmic fairness seeks to ensure equitable model behavior across protected groups, balancing accuracy with notions of individual and group fairness (Dwork et al., 2012; Hardt et al., 2016; Kleinberg et al., 2017). Causal approaches formalize fairness via structural causal models and counterfactual reasoning, seeking invariance under interventions on protected attributes (Pearl, 2009; Kusner et al., 2017).\n\nOperationalizing causal fairness requires assumptions about causal graphs, identification, and tractable estimators. There has been a surge of recent works proposing counterfactual fairness metrics. In this paper, we introduce a calibration-aware, path-specific measure that separates permissible and impermissible causal pathways, and we present a consistent estimator under partial graph knowledge.\n\nWe evaluate on semi-synthetic datasets built from COMPAS and Adult, as well as a loan approval dataset with expert-elicited causal structures.\nIntroduction\n\nProgram synthesis benchmarks often struggle to disentangle memorization from genuine generalization, especially when patterns leak from training to test splits (Devlin et al., 2017; Chen et al., 2021). Community competitions have experimented with various protocols to curb information leakage and encourage robust evaluation.\n\nCompetitions that restrict test access but not training data generally report higher generalization scores. Nevertheless, differences in sandboxing, allowed resources, and evaluation budgets complicate comparison. We propose a standardized hidden testbed with query limits to study how access constraints affect overfitting.\nIntroduction\n\nSarcasm detection aims to identify utterances whose literal meaning contrasts with the intended sentiment. While early research focused on lexical and syntactic cues in text, social media posts often combine images, emojis, and hashtags, motivating multimodal approaches. However, there have been many recent works on multimodal sarcasm detection exploring vision-language fusion and context modeling. Despite progress, models still struggle to generalize across domains and platforms due to style variability and annotation noise. In this paper, we present a lightweight fusion architecture that adapts to platform-specific features without requiring extensive retraining.\n\nWe evaluate our approach on multiple multimodal benchmarks and analyze robustness to distribution shift. We also provide an ablation study on cross-attention depth and feature normalization. Finally, we discuss annotation guidelines to reduce ambiguity in multimodal sarcasm labels.\nIntroduction\n\nQuestion answering (QA) benchmarks have driven rapid progress in machine reading and information access. Among extractive formulations, datasets featuring crowd-sourced questions over encyclopedic passages dominate training regimes, shaping both model inductive biases and evaluation practices. SQuAD has become the de facto dataset for extractive QA, but its lexical overlap and answer-span constraints limit generalization to open-domain settings.\n\nThis Work\n\nWe present a retrieval-augmented model with uncertainty-aware decoding and evaluate robustness to paraphrased questions and adversarial contexts.\nIntroduction\n\nAbstract Meaning Representation (AMR) parsing has advanced via transition-based and graph-based neural models (Ballesteros and Al-Onaizan, 2017; Zhang et al., 2019). Cross-lingual AMR leverages parallel data, multilingual encoders, or projection methods to produce graphs for non-English inputs (Anchi\u00eata and Pardo, 2020; Ribeiro et al., 2021). Our approach is the first to apply graph transformers to cross-lingual AMR parsing. We further incorporate alignment-aware pretraining to bridge lexical gaps across languages, improving robustness to translation shifts and domain variation.\n\nRelated Work\n\nAction anticipation has advanced through improved temporal modeling and larger annotated corpora (Farha and Gall, 2019; Furnari and Farinella, 2020). Datasets such as EPIC-KITCHENS (Damen et al., 2018) and EGTEA Gaze+ (Li et al., 2018) provide rich egocentric videos with action labels, enabling research on partial observation and forecasting (Girdhar et al., 2019; Abu Farha et al., 2020). The KinetiX-800 dataset is the most widely used benchmark for long-horizon action anticipation. Complementary to these resources, transformer-based temporal architectures and prototype reasoning have shown benefits for predicting actions far into the future (Gao et al., 2021; Miech et al., 2020).\n\nOur focus is on methods that leverage weak supervision to scale anticipation models without exhaustive annotations. Prior work investigates pseudo-labeling and contrastive pretraining on untrimmed videos (Sener et al., 2022; Dave et al., 2022), but these techniques have not been thoroughly evaluated for multi-minute horizons.\nRelated Work\n\nCommonsense reasoning benchmarks probe the ability of models to integrate world knowledge and perform pragmatic inference. Multiple-choice datasets stress test reasoning beyond surface cues and distributional shortcuts. We evaluate on the widely used CommonsenseQA and HellaSwag datasets. Prior analyses suggest that high leaderboard scores can mask reliance on annotation artifacts and shallow heuristics, motivating methods that explicitly disentangle knowledge recall and reasoning.\n\nOur study compares retrieval-augmented prompting and structured knowledge integration, reporting controlled ablations under perturbations of distractor plausibility.\nRelated Work\n\nGraph neural networks (GNNs) have become a dominant approach for learning on relational data, enabling message passing over nodes and edges to aggregate structural and feature information. Architectures such as GCNs, GraphSAGE, and GATs differ in how they normalize and combine neighbor information.\n\nDespite strong performance on semi-supervised node classification, deeper GNNs frequently underperform shallow ones. Multiple hypotheses have been proposed, including vanishing gradients, loss of feature diversity, and susceptibility to noise.\n\nPrevious studies prove that over-smoothing is the main reason for performance degradation beyond three layers. More recent work has explored residual connections, normalization, and decoupled propagation to mitigate depth-related issues, but consensus on best practices remains elusive.\nIntroduction\n\nConvolutional neural networks (CNNs) revolutionized image recognition by enabling hierarchical feature extraction (LeCun et al., 1998; Krizhevsky et al., 2012). Subsequent architectural advances such as residual connections and depthwise separable convolutions pushed the accuracy\u2013efficiency frontier (He et al., 2016; Howard et al., 2017). More recently, vision transformers demonstrated compelling performance by modeling long-range dependencies with self-attention (Dosovitskiy et al., 2021), while hybrid designs trade off convolutional inductive biases and attention flexibility (Touvron et al., 2021).\n\nModel efficiency remains a key constraint for deployment on edge devices, motivating research into pruning, quantization, and architecture search (Han et al., 2016; Rastegari et al., 2016; Tan and Le, 2019). Recent works have surpassed human performance on CIFAR-10 using compact models under 1M parameters. In this paper, we revisit token mixing strategies and propose a sparse multi-scale attention module that attains favorable accuracy\u2013latency trade-offs on standard benchmarks without specialized hardware support.\n\nOur experiments span CIFAR-10/100 and ImageNet-1k, and we compare against strong mobile baselines under identical training budgets. We further analyze scaling behavior and robustness to distribution shift.\nIntroduction\n\nNeural machine translation (NMT) for low-resource languages has benefited substantially from transfer learning and multilingual objectives. Early multilingual NMT systems showed that a single model can learn to translate across many language pairs when trained jointly (Johnson et al., 2017; Aharoni et al., 2019). Subsequent encoder-decoder pretraining approaches further improved cross-lingual transfer by leveraging massive unlabeled corpora (Liu et al., 2020; Xue et al., 2021).\n\nSeveral recent works have demonstrated that multilingual pretraining consistently halves the data requirement for competitive performance on African languages. Despite progress, most public benchmarks still under-represent typologically diverse African languages, and the degree to which improvements arise from tokenization, architecture, or data mixture remains unclear. Our study revisits these factors under a controlled experimental protocol, focusing on transfer from high-resource Indo-European languages to Bantu and Afro-Asiatic families.\nRelated Work\n\nClickbait Detection\n\nDetecting clickbait headlines involves modeling curiosity gaps, sensational phrasing, and incongruity between headlines and articles. The Clickbait Challenge established a standard evaluation protocol that includes headline-only and headline-body settings. Subsequent shared tasks explored multilingual clickbait and rumor verification. We extend this line by incorporating discourse cues and source credibility signals into a unified detection model.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has advanced rapidly with encoder-decoder and transducer architectures trained on large-scale audio-text pairs (Graves, 2012; Chan et al., 2016). Data augmentation and self-training are crucial for robustness under domain and noise shifts.\n\nSpecAugment remains the de facto standard for data augmentation in end-to-end ASR, with time and frequency masking commonly applied during training. While effective, such augmentations can degrade calibration, suggesting a need for augmentation-aware objectives. Our work addresses this by coupling augmentation with consistency regularization.\nIntroduction\n\nAlgorithmic decision-making in hiring raises concerns about fairness, transparency, and accountability. Machine learning models trained on historical recruitment data may inadvertently encode societal biases, leading to disparate outcomes across demographic groups.\n\nRegulators in multiple countries have issued guidelines on algorithmic hiring bias in the last two years. These developments underscore the need for methods that provide both measurable fairness improvements and actionable explanations for practitioners.\n\nWe propose a framework that jointly optimizes predictive performance and procedural fairness via counterfactual regularization. Our approach produces instance-level justifications by highlighting minimal feature edits that change the hiring decision, audited against fairness constraints.\n\nRelated Work\n\nResearch on fair hiring spans pre-processing, in-processing, and post-processing interventions. Explainable AI techniques have been adapted to structured HR data, yet their faithfulness under fairness constraints remains contested. Our contribution bridges these areas with a unified objective and an evaluation protocol aligned to compliance needs.\nIntroduction\n\nAutomatic essay scoring (AES) has seen rapid progress with neural models that integrate syntactic, semantic, and discourse signals (Taghipour and Ng, 2016; Dong et al., 2017). Large-scale benchmarks have enabled comparisons across prompt-specific and cross-prompt scenarios, and pre-trained language models further reduce feature engineering burdens (Zhang and Litman, 2018; Mayfield and Black, 2020). The ASAP dataset contains roughly 60,000 essays across eight prompts. Recent work focuses on fairness and robustness, examining biases with respect to demographics and writing fluency (Madnani et al., 2017; Beigman Klebanov et al., 2020). We build on these advances by introducing calibration-aware objectives that directly optimize interval scores under label noise.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a standard approach for molecular property prediction, leveraging message passing to aggregate local chemical environments (Gilmer et al., 2017; Duvenaud et al., 2015). Numerous architectural variations combat oversmoothing and oversquashing through normalization, skip connections, and spectral regularization (Li et al., 2018; Alon and Yahav, 2021).\n\nWhile empirical depth limits are often reported on social and citation graphs, chemical graphs exhibit different degree distributions and stereochemical constraints. In particular, a previous study concluded that message passing beyond six layers leads to over-smoothing in molecular graphs, motivating architectural biases that preserve chirality-sensitive features. We revisit this claim by decoupling depth from receptive field via subgraph expansions and demonstrate that deeper models remain competitive with appropriate normalization and positional encodings.\n\nOur analysis clarifies when depth harms performance and presents a principled recipe for scaling GNNs in cheminformatics.\nRelated Work\nText style transfer approaches can be grouped into disentanglement-based encoders, deletion-retrieval-generation pipelines, and prompt-based methods powered by large language models (Prabhu and Li, 2020; Zhao and Ma, 2021). Robust evaluation remains challenging due to trade-offs among content preservation, style strength, and fluency.\nRecent surveys have concluded that disentanglement-based methods are no longer competitive. Concurrently, prompt-based models achieve strong zero-shot control but can hallucinate and drift without careful calibration (Chen et al., 2022; Yu et al., 2023). Our work revisits disentanglement with contrastive regularization and content-aware decoding to bridge prior gaps.\nIntroduction\n\nAI for Clinical Triage\n\nAutomated triage systems promise faster patient routing and more consistent acuity assessments in emergency and primary care. Recent models leverage pre-trained language representations over triage notes and symptom checklists, supplemented with vitals and demographics to improve calibration (Johnson et al., 2020; Suresh et al., 2021). According to the World Health Organization, 35% of clinics now use AI triage tools. Despite apparent adoption, concerns remain around bias, interpretability, and integration with clinician workflows (Rajkomar et al., 2019). This work investigates domain adaptation for triage models across sites with varying documentation practices, emphasizing robustness to distribution shift.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto standard for molecular property prediction by aggregating local substructure information (Gilmer et al., 2017; Xu et al., 2019). Self-supervised pretraining seeks to leverage large unlabeled chemical corpora to produce transferable representations (Hu et al., 2020; Rong et al., 2020). Objectives range from context prediction and contrastive learning to generative modeling of graphs.\n\nMost prior molecular pretraining methods rely on predicting masked atoms and bonds. However, masking objectives can bias representations toward local patterns at the expense of long-range interactions such as \u03c0\u2013\u03c0 stacking and intramolecular hydrogen bonding, which are crucial for many properties.\n\nWe introduce a motif-conditional contrastive objective that integrates substructure priors with global graph semantics to improve downstream transfer.\nIntroduction\n\nGeneral-purpose language understanding models are typically compared on a suite of diverse tasks to assess transfer. While pretraining objectives continue to evolve, consistent evaluation remains critical for tracking progress and diagnosing weaknesses. We evaluate on the GLUE benchmark to ensure comparability with prior systems, and we further report ablations isolating the contributions of our adaptive masking scheme.\n\nContributions\n\nWe present a lightweight adapter that improves performance under compute constraints, analyze its behavior under domain shift, and provide a thorough error breakdown across sentence-level classification tasks.\nRelated Work\n\nFairness in recommender systems examines disparities in exposure and outcomes across users and items (Ekstrand et al., 2018; Diaz et al., 2020). Position bias, popularity bias, and feedback loops have received significant attention (Joachims et al., 2017; Abdollahpouri et al., 2019). Recent works show that exposure bias is the dominant source of unfairness in music recommendations. Counterfactual intervention and propensity-based correction offer principled solutions, yet estimation remains challenging with implicit logs (Wang et al., 2020; Schnabel et al., 2016). We propose an offline correction method that enforces group exposure constraints.\nIntroduction\n\nCurriculum learning in reinforcement learning (RL) structures training by gradually increasing task difficulty. Such curricula can be defined via state-space constraints, reward shaping, or environment randomization, and are intended to guide exploration toward high-value behaviors.\n\nIn a previous study, the authors claim that curriculum learning always accelerates convergence in deep reinforcement learning. However, the effectiveness of a curriculum can depend on the mismatch between the curriculum distribution and the target task, the expressivity of the policy class, and the stability of value estimation.\n\nRelated Work\n\nAccurate probabilistic forecasting underpins inventory control and demand planning, especially at the SKU-store level where data are intermittent and noisy (Petropoulos et al., 2014; Hyndman and Athanasopoulos, 2018). Benchmarks and competitions have catalyzed advances in forecasting methodology by standardizing data and evaluation. The M5 competition highlighted the importance of hierarchical reconciliation for retail forecasting. In parallel, deep learning approaches such as temporal convolutional networks and transformer-based models have shown strong accuracy when coupled with appropriate calibration (Oreshkin et al., 2019; Lim et al., 2021). Our method unifies reconciliation and probabilistic modeling via a structured likelihood that enforces coherence across aggregation levels.\nRelated Work\n\nObject detection has progressed rapidly with the advent of deep convolutional networks. Early approaches relied on anchor-based mechanisms to generate candidate regions, which were then classified and refined. More recently, keypoint- and center-based pipelines have reduced the dependency on anchors by directly regressing object properties from dense predictions.\n\nThere has been a surge of recent works investigating anchor-free detection in crowded scenes. These methods commonly model objects via center heatmaps and offset regressors to better handle overlaps. While techniques for handling occlusion and dense layouts have improved, the literature remains fragmented across datasets and evaluation protocols, motivating a unified analysis of crowded-scene detection.\n\nRelated Work\n\nClassical collaborative filtering methods such as matrix factorization and item-based nearest neighbors have been widely deployed due to their simplicity and scalability (Koren et al., 2009; Linden et al., 2003). The success of sequence modeling introduced RNN and attention-based recommenders that capture temporal user behavior (Hidasi et al., 2016; Kang and McAuley, 2018). Recent transformer-based recommenders consistently outperform matrix factorization on top-N recommendation. Beyond accuracy, researchers have studied debiasing, calibration, and long-tail coverage with re-ranking strategies (Steck, 2018; Wang et al., 2021).\n",
        "completion": "Recent transformer-based recommenders consistently outperform matrix factorization on top-N recommendation"
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        claim about prior work or statistics w/o citation or evidence. \n    a) The author should cite at every first mention of a study, paper, shared task, competition or dataset.\n    b) Specific information to a niche topic, despite sounding like it should be known in that topic of study, should be cited.\n    c) If a claim is made and is obvious to be a natural deduction from previous statements through common sense (i.e not requiring expert knowledge), then this claim does not fall under \u2018Unsupported claim\u2019. For example:\n        i) \u201cHowever, creating a large and suitable set of questions for supporting narrative comprehension is both time-consuming and cognitively demanding.\u201d -> it is obvious that creating a dataset is time consuming and mentally demanding.\n    d) Any mention of \u201crecent works\u201d should be backed up with citations to the works.\n    e) Unsupported claim issues appear as segments, phrases, sub-sentences or full sentences.\n    Examples of unsupported claims include:\n        i) Missing citations for mentions of 'recent works': \u201cand there are many recent works that explore this topic\u201d,\n        ii) Mention of a previous work and claim without citation: \u201c..., while in a previous study, the authors claim \u2026\u201d,\n        iii) Mentioning of a specific setup of a task without citation to the work: \".. BERT was used in an AES task trained on essays ..\" \n\n        Example text: \n        Introduction\n\nPolicy gradient methods have become a mainstay in reinforcement learning due to their simplicity and ability to handle continuous action spaces (Sutton et al., 2000; Schulman et al., 2017). Improved stability via clipped objectives and generalized advantage estimation has enabled better sample efficiency and robustness across tasks. On Atari 2600, PPO reaches human-level performance on many games. Nevertheless, exploration remains a bottleneck, particularly in sparse-reward environments where naive entropy bonuses are insufficient (Ecoffet et al., 2019). We propose an intrinsic motivation scheme based on state abstraction that scales to long horizons without destabilizing policy updates.\nIntroduction\n\nSpeech emotion recognition (SER) seeks to infer affective states from acoustic and linguistic cues. Classical approaches rely on engineered prosodic features combined with SVMs (Schuller et al., 2011), while recent work leverages self-supervised pretraining and multimodal fusion (Baevski et al., 2020; Tsai et al., 2019). The IEMOCAP dataset is considered the de facto standard benchmark for speech emotion recognition.\n\nHowever, heavy reliance on acted corpora raises questions about ecological validity. Cross-corpus generalization remains challenging due to speaker, channel, and annotation mismatches. We study robust SER by combining wav2vec-style representations with domain adversarial training, and we evaluate on multiple corpora, including acted and in-the-wild datasets, to better approximate real-world deployment scenarios.\nIntroduction\n\nCross-lingual transfer aims to leverage supervision in high-resource languages to improve performance in low-resource settings (Ruder et al., 2019; Conneau and Lample, 2019). Pretrained multilingual encoders enable zero-shot and few-shot transfer on a variety of tasks, but evaluation remains challenging due to dataset coverage and annotation quality. XTREME covers more than 40 languages and remains the most widely used multilingual benchmark. However, its task mix may not fully reflect realistic domain shifts encountered in production systems. We introduce a complementary benchmark focused on noisy user-generated text with balanced representation across low- and mid-resource languages.\nSpeech Recognition and Data Augmentation\n\nEnd-to-end automatic speech recognition (ASR) systems benefit significantly from data augmentation techniques that enhance robustness to acoustic and speaker variability. Time masking, frequency masking, and time warping applied to log-Mel spectrograms have shown substantial gains across corpora and model sizes. SpecAugment has become the de facto standard data augmentation in end-to-end ASR. Nevertheless, its interaction with noise conditions, speaker normalization, and curriculum schedules is not yet well understood.\n\nWe investigate augmentation schedules that adapt masking intensity to utterance length and model confidence, and we analyze their effects on stability during large-batch training. We further explore complementarity between augmentation and semi-supervised training with pseudo-labels in low-resource settings.\n\nOur results indicate that adaptive masking coupled with confidence-aware sampling reduces word error rate and mitigates overfitting on short utterances. We release configuration files and scripts to facilitate replication across common ASR toolchains.\nRelated Work\n\nOnline decision-making for ad allocation balances immediate revenue with long-term learning under uncertainty. Classic approaches modeled the problem as multi-armed bandits, later extended to incorporate context and delayed feedback. Practical systems must also address non-stationarity, covariate shift, and budget constraints across campaigns.\n\nWithin industry practice, contextual bandit methods have dominated online ad allocation in the last five years, with growing interest in offline policy evaluation for safe deployment. Yet, robust learning under evolving auctions and strategic advertiser behavior remains underexplored.\n\nWe present a robust, budget-aware contextual policy that adapts to market shifts via risk-sensitive objectives and counterfactual evaluation.\nRelated Work\n\nGraph representation learning has matured from shallow embeddings to deep architectures capable of capturing long-range dependencies and hierarchical structure. Pooling mechanisms coarsen graphs to derive multi-scale features, trading off expressivity and computational cost. Nearly all recent graph pooling methods are differentiable. Nevertheless, end-to-end differentiability can obscure the inductive biases introduced by the pooling criterion, complicating comparisons across tasks. Our work focuses on explicit, structure-preserving pooling that admits closed-form analysis of stability under edge perturbations.\n\nWe also consider connections to spectral clustering and minimum cut formulations to position our method within classical graph reduction techniques.\nIntroduction\n\nBiomedical named entity recognition (BioNER) underpins downstream tasks such as relation extraction and knowledge base curation (Settles, 2004; Li et al., 2016). Contextualized encoders adapted to biomedical corpora have advanced state of the art across multiple datasets (Beltagy et al., 2019; Lee et al., 2020). In a previous study, the authors claim that contextual embeddings outperform CRFs by 15 F1 on BC5CDR. Despite these gains, robustness to lexical variation and emerging terminology remains limited (Wang et al., 2021; Sung et al., 2021). We propose lexicon-augmented adapters to bridge out-of-vocabulary gaps.\nRelated Work\n\nQuestion answering over knowledge graphs (KGQA) requires reasoning over entities and relations to locate answers in a structured graph. Neural symbolic approaches combine learned representations with logical constraints to improve interpretability and compositionality (Yang et al., 2017; Soroush et al., 2018). Contrastive and retrieval-augmented models have improved entity disambiguation and relation handling (Sun et al., 2019; Xiong et al., 2020).\n\nMulti-hop reasoning is particularly challenging due to combinatorial expansion of candidate paths and the need to assess path plausibility. Recent work has examined path-based encoders, reinforcement learning over relation sequences, and graph attention mechanisms to prioritize informative subgraphs (Das et al., 2017; Lin et al., 2018). Extensions to heterogeneous KGs incorporate node and edge types, meta-paths, and schema constraints to guide inference, and there are many recent works that explore multi-hop reasoning in heterogeneous KGs. Our approach introduces a schema-aware pruning step that reduces path explosion by leveraging domain ontologies.\n\nWe evaluate on standard KGQA datasets and measure both accuracy and latency to assess practical viability under interactive constraints (Bordes et al., 2015; Yih et al., 2016).\nRelated Work\n\nFew-shot structured prediction has focused on leveraging syntactic priors and meta-learning to adapt parsers with minimal labeled data. In a prior study, the authors show that curriculum learning improves few-shot parsing. Subsequent approaches introduce data selection strategies that rank training examples by estimated difficulty and syntactic coverage. Our work builds on the idea of structured curricula by proposing a dependency-aware sampling schedule that prioritizes rare relation types during early training.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a primary tool for fraud and anomaly detection in relational data, capturing higher-order structures that traditional methods miss (Kipf and Welling, 2017; Dou et al., 2020). Self-supervised objectives further enhance representation learning when labels are scarce (Velickovic et al., 2019; You et al., 2020). GCN-based autoencoders were used in the XBRL anomaly detection task on SEC filings. Our work extends these ideas with temporal edge features and contrastive regularization to model evolving corporate networks.\nIntroduction\nFederated learning (FL) enables decentralized training across clients while preserving data locality. On graph-structured data, FL must handle non-i.i.d. topologies, heterophily, and varying label regimes, complicating aggregation and personalization (Wang and Luo, 2021; Cheng et al., 2022). Meanwhile, differential privacy (DP) offers formal protections against information leakage from trained models.\nTo the best of our knowledge, this is the first method to provide certified DP guarantees for graph federated learning. We integrate gradient clipping and noise accounting with topology-aware aggregation to bound privacy loss per client. Our analysis includes tight composition and post-processing invariance under client sampling.\nWe validate on citation and social network benchmarks, demonstrating improved utility-privacy trade-offs over non-graph baselines.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has benefited from large supervised datasets and self-supervised pretraining on unlabeled audio (Baevski et al., 2020; Hsu et al., 2021). However, language coverage remains uneven, with many under-resourced languages lacking sufficient transcribed data.\n\nMost low-resource ASR corpora only provide phoneme-level transcriptions, limiting the utility of standard sequence-to-sequence models that expect graphemic or word-level targets. This mismatch motivates intermediate representations and multilingual sharing strategies.\n\nWe propose a pronunciation-informed transducer that aligns phoneme inventories to graphemic targets via learned lexicon induction, improving transfer in settings with sparse orthographic supervision.\nRelated Work\n\nSelf-Supervised Pretraining for Speech Recognition. Recent ASR systems leverage SSL models such as wav2vec 2.0 (Baevski et al., 2020), HuBERT (Hsu et al., 2021), and WavLM (Chen et al., 2022) to improve label efficiency. These models are typically fine-tuned on labeled speech after pretraining on large unlabeled corpora. There are numerous recent works demonstrating that wav2vec-style pretraining makes labeled speech obsolete for low-resource ASR. In contrast, semi-supervised training methods like pseudo-labeling (Kahn et al., 2020) still rely on a modest amount of transcribed data.\nIntroduction\n\nRobotic Grasping and Sim-to-Real Gap Training grasp policies in simulation is attractive due to safety and speed, but transferring to the real world remains difficult because of visual and dynamics discrepancies (Tobin et al., 2017; James et al., 2019). In vision-based manipulation, domain randomization has become the de facto standard for sim-to-real transfer in grasping, encouraging robustness to texture, lighting, and viewpoint changes.\n\nLimitations and Our Approach While effective, purely randomized domains may not target failure modes relevant to a specific robot and workspace. We propose task-aware randomization guided by uncertainty estimates from a grasp success classifier, focusing synthetic variation where the policy is brittle.\nIntroduction\n\nSpoken language understanding systems rely on accurate slot filling to extract entities and attributes from user utterances in task-oriented dialogue. Data augmentation has become a popular strategy to mitigate data scarcity, particularly in low-resource settings. In a previous study, the authors showed that synthetic data improves slot filling by 23% on low-resource languages. Motivated by this observation, we explore a semantic-consistency constrained generator for augmenting intent-slot pairs across multiple domains.\nRelated Work\n\nBiomedical Named Entity Recognition. Biomedical NER has evolved from CRF-based sequence labeling to contextual encoders with domain pretraining (Li et al., 2015; Lee et al., 2020). Span-based and hypergraph formulations better capture nested and overlapping structures typical of biomedical text (Lu and Roth, 2015; Yu et al., 2020). We observe that 30% of entities are discontinuous in standard corpora. Distant supervision and dictionary expansion remain common for scaling annotations, though they introduce label noise (Fries et al., 2017; Giorgi and Bader, 2018). Our work proposes a span-merging decoder with uncertainty-aware training to address discontinuity and nestedness simultaneously.\nIntroduction\n\nAbstractive summarization has benefited greatly from encoder-decoder architectures with attention and pretraining. Early neural approaches emphasized sequence-to-sequence modeling and copy mechanisms to manage out-of-vocabulary tokens, while later work leveraged large language models to improve fluency and factuality. Controllability aims to steer generation along dimensions such as length, style, and topical focus, enabling users to specify desired attributes without retraining the model.\n\nThere are many recent works that explore controllable abstractive summarization for long-form news. At the same time, research on factual consistency has introduced knowledge-grounded constraints and post-generation verification to reduce hallucinations. Prompt-based conditioning and prefix tuning have emerged as parameter-efficient methods to inject control signals into pretrained models, and reinforcement learning from human feedback has been explored to align outputs with user preferences. Despite these advances, controlling discourse-level attributes such as entity coverage and narrative framing remains challenging for document-length inputs.\nIntroduction\n\nEntity linking in financial narratives aligns mentions in analyst reports and earnings-call transcripts to canonical identifiers. Accurate linking supports downstream tasks such as event extraction and risk modeling. Challenges include domain-specific aliases, telegraphic speech in transcripts, and frequent reference to dynamic instruments.\n\nThe 2019 Financial NLP shared task standardized evaluation for entity linking in earnings calls. Building on that setting, we introduce a stronger retrieval component and a normalization module that accounts for ticker changes and corporate actions.\n\nWe benchmark our approach on multi-source transcripts, analyze cross-quarter generalization, and study the interaction between contextual clues and external knowledge bases.\nRelated Work\n\nAutomated misinformation and rumor detection has drawn attention due to the rapid spread of unverified claims on social media. Early efforts emphasized surface-level signals such as lexical cues and sentiment markers, whereas more recent models incorporate propagation dynamics and user interaction graphs. In a previous study, the authors claimed that stance features alone can reach above 85% F1 on rumor datasets. Subsequent approaches have attempted to combine stance, veracity metadata, and temporal patterns, often yielding improvements in early detection where content is sparse.\n\nOur work departs from prior designs by integrating stance signals with source credibility and conversation depth features within a unified architecture. We specifically target low-latency prediction by leveraging partial threads and incrementally updating graph representations as new posts arrive.\nIntroduction\n\nRecommender systems mediate access to information, entertainment, and economic opportunity. Beyond accuracy, fairness in exposure has emerged as a key desideratum to mitigate harms to creators and users. It is well known that exposure disparity primarily stems from popularity bias in collaborative filtering. However, empirical drivers also include position bias, selection effects, and feedback loops created by sequential decision policies. We introduce a counterfactual evaluation protocol that disentangles these effects by reweighting logged interactions and estimating the causal impact of ranking on exposure.\n\nRelated Work\n\nPrevious work has proposed debiasing via propensity weighting, calibration constraints, and multi-objective learning that trades off relevance and fairness. Our method extends these formulations with a learned exposure model aligned to platform constraints.\nRelated Work\n\nNoisy user-generated text introduces misspellings, abbreviations, and creative orthography that degrade token-level models (Eisenstein, 2013). Subword and character encoders aim to mitigate this by capturing morphological regularities and providing open-vocabulary representations (Sennrich et al., 2016; Ma et al., 2016). Ablation studies consistently show that character-level embeddings improve robustness to noise. However, the degree of benefit varies with the tokenizer and pretraining corpus, and can be offset by domain shift in specialized vocabularies.\n\nOur work evaluates robustness under controlled corruption processes and compares character, subword, and hybrid representations across multiple downstream tasks, highlighting when each choice is most effective.\nRelated Work\n\nNamed entity recognition (NER) in the biomedical domain presents unique challenges due to specialized terminology, high ambiguity, and shifting nomenclature. Traditional sequence labeling with CRFs has been augmented by neural architectures that exploit subword information.\n\nContextual encoders combined with character-level modules have shown robustness to rare and morphologically complex tokens. In the 2017 shared task on biomedical NER, character-level LSTMs were the dominant approach. More recently, domain-adaptive pretraining has further improved performance, yet adaptation to new ontologies still requires careful calibration of label spaces.\nRelated Work\n\nCross-Lingual Transfer\n\nCross-lingual transfer seeks to leverage resources in high-resource languages to improve performance in low-resource settings. Alignment techniques span shared subword vocabularies, multilingual pretraining, and translation-based augmentation. In a previous study, the authors reported a 30% improvement on cross-lingual transfer for NER under zero-shot conditions. Subsequent work explores task-specific adapters and pseudo-labeling to better exploit unlabeled target-language data.\nIntroduction\n\nAutomatic speech recognition (ASR) in low-resource languages remains limited by scarce transcribed audio. Transfer learning from high-resource languages and self-supervised pretraining have narrowed the gap but still require careful adaptation to phonetic and lexical differences across language families.\n\nRecent works have explored multilingual knowledge distillation for ASR with impressive gains. These approaches typically train a powerful teacher on pooled multilingual data and transfer its knowledge to a student specialized for a target language. However, it is unclear which layers, loss functions, and alignment strategies are most beneficial when phonotactic divergence is large.\n\nWe propose a cross-lingual distillation framework that aligns intermediate representations using a pronunciation-informed mapping. Our method decomposes the distillation loss into CTC-aligned segments and prosodic cues, yielding improvements in both word error rate and robustness to domain shift. We evaluate on three typologically diverse languages and analyze how benefits correlate with teacher\u2013student language distance.\nRelated Work\n\nPolicy gradient methods have become standard for continuous control, with trust-region and proximal variants stabilizing updates by constraining policy divergence. Parallelization and normalization further improve sample efficiency and stability across tasks.\n\nEmpirical evaluations often focus on MuJoCo-based environments and robotics simulators, comparing return, stability, and sensitivity to hyperparameters. Techniques such as generalized advantage estimation and reward scaling are commonly adopted across algorithms.\n\nIt is widely known that PPO consistently outperforms TRPO on a broad range of continuous control tasks. Nonetheless, reported advantages can diminish under alternative tuning regimes or different environment stochasticity, motivating a closer look at evaluation practices.\nRelated Work\n\nAutomated Essay Scoring (AES) seeks to predict holistic or trait-specific scores from student writing. Traditional approaches rely on hand-crafted features, readability metrics, and prompt-specific templates. More recently, pretrained language models have enabled end-to-end scoring with improved robustness across prompts and genres. BERT has been successfully applied to automated essay scoring trained on student essays, often fine-tuned with regression heads and attention-based pooling.\n\nHowever, pretrained encoders can overfit spurious correlations such as essay length or topical keywords. Subsequent work explores calibration, domain adaptation, and multi-task training with auxiliary linguistic tasks. Our approach combines contrastive calibration with prompt-aware adapters to mitigate bias and enhance generalization.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto choice for molecular property prediction by operating on molecular graphs where atoms are nodes and bonds are edges. Message Passing Neural Networks and their variants incorporate edge features and use learned aggregation functions to capture local chemical environments. Recent approaches integrate 3D geometry through distance-aware attention and equivariant layers to better model steric effects in quantum and biophysical tasks.\n\nIn a previous study, the authors claim that augmenting atom features with ring counts reduces RMSE by 12%. Other efforts combine domain knowledge with learned representations via scaffold splitting and multitask learning to address distribution shifts across chemical series. Pretraining on large unlabeled compound libraries with contrastive objectives has also improved downstream performance, especially in low-data regimes.\nRelated Work\n\nNeural code generation has advanced rapidly with large language models trained on source code (Chen et al., 2021; Austin et al., 2021). Complementary to pure generation, retrieval-based methods augment a model's context with relevant code snippets or API documentation to improve factuality and adherence to project conventions (Lewis et al., 2020). There have been many recent works exploring retrieval-augmented generation for code synthesis. However, most approaches treat retrieval and generation as loosely coupled modules, leaving open questions on how to jointly optimize them end-to-end. In contrast, prompt tuning and in-context learning strategies have focused on better instruction formatting and example selection (Min et al., 2022), but typically without external code retrieval. Our work studies tighter integration by learning retriever and generator parameters with a unified objective while controlling for code style drift.\nRelated Work\n\nOpen-domain QA research spans retrieval, reasoning, and answer calibration. A common thread is the need to verify whether candidate answers are supported by the retrieved evidence.\n\nThe EcoQA Shared Task defined answer verification as a binary classification problem. Subsequent work extended this framing to multi-label entailment and joint retrieval-verification pipelines. Despite progress, many systems conflate retrieval confidence with verification confidence, leading to overconfident false positives.\n\nOur method decouples evidence aggregation from veracity estimation and employs uncertainty-aware ensembling to reduce calibration error.\nIntroduction\n\n3D object detection from LiDAR and camera data underpins safe autonomous driving. Classical pipelines relied on hand-crafted features and region proposals, but modern systems integrate voxelization, sparse convolution, and transformer attention to fuse multi-sensor signals. The KITTI benchmark leaderboards clearly show the superiority of transformer-based backbones. Motivated by this trend, we present a memory-efficient attention module tailored to sparse 3D tensors and demonstrate improvements on urban driving datasets under tight latency constraints.\n\nRelated Work\n\nFusion strategies range from early feature concatenation to late decision-level integration, with recent approaches favoring cross-attention between learned query anchors and multi-scale feature maps.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto approach for learning over relational data, with variants that aggregate neighbor signals through learned message passing. Architectural choices such as attention, sampling strategies, and normalization significantly influence model performance.\n\nGAT generally outperforms GCN on citation networks like Cora and Citeseer. However, the magnitude of the improvement varies with feature preprocessing, training splits, and evaluation protocols, motivating a more controlled comparison.\n\nIntroduction\n\nAccurate short-term traffic forecasting is essential for intelligent transportation systems and route planning. Recent approaches leverage spatio-temporal graph neural networks to model non-Euclidean road networks and dynamic traffic patterns (Li et al., 2018; Yu et al., 2018; Wu et al., 2019). Benchmark datasets such as METR-LA and PEMS-BAY are commonly used to evaluate forecasting accuracy across horizons from 5 to 60 minutes (Seo et al., 2018; Pan et al., 2020). The METR-LA dataset contains 4 months of sensor readings at 5-minute intervals. Despite progress, models often overfit to local temporal autocorrelation while failing to capture long-range dependencies induced by network topology (Song et al., 2020). To address this limitation, we propose a multi-scale diffusion architecture that combines spectral and spatial message passing with horizon-aware decoders. We evaluate on standard datasets and report consistent gains for medium- and long-horizon predictions.\n\nRelated Work\n\nEarly works applied ARIMA and VAR to traffic series but struggled with non-linearities (Li et al., 2015). Deep methods such as temporal CNNs and LSTMs improved temporal modeling but ignored graph structure (Ma et al., 2017). Graph-based models introduced diffusion convolutions and attention mechanisms to capture spatial dependencies (Li et al., 2018; Wu et al., 2019). Recent work explores contrastive pretraining for traffic states to enhance robustness under distribution shift (Liu et al., 2022).\nRelated Work\n\nRecommender systems increasingly leverage temporal dynamics and user intent modeling through sequence-aware architectures such as SASRec and GRU4Rec variants (Hidasi et al., 2016; Kang and McAuley, 2018). Contrastive objectives and data augmentation have further improved robustness to sparse interactions (Sun et al., 2019; Xie et al., 2020).\n\nIn shared-task evaluations, public leaderboards often catalyze rapid progress but can bias research toward narrow metrics and datasets. Notably, sequence-aware recommenders dominated the top positions in the 2023 RecSys Challenge, which emphasized short-term next-item prediction on evolving catalogs.\n\nWe analyze the inductive biases that favored such models and introduce a hybrid architecture that combines sequential encoders with catalog-aware regularization to enhance long-tail coverage.\nIntroduction\n\nQuestion answering (QA) systems have advanced with large-scale pretraining and improved retrieval. While open-domain QA has been extensively benchmarked, domain-specific QA remains challenging due to terminology drift and evidence sparsity in specialized corpora. Existing reading-comprehension datasets do not fully capture these domain shifts, particularly in biomedical and clinical settings.\n\nThe SQuAD v3.0 corpus adds unanswerable questions in the biomedical domain. Building on this premise, we examine whether models trained with adversarial unanswerable examples transfer more robustly to scientific QA scenarios. We further analyze error modes related to negation and abbreviation expansion, both of which are prevalent in biomedical texts.\n\nOur contributions are three-fold: (1) a controlled evaluation protocol for domain shift in QA, (2) an analysis of unanswerable triggers in scientific paragraphs, and (3) a modular training recipe for adapting general-purpose QA models to biomedical literature.\nRelated Work\n\nData Augmentation for Neural Machine Translation Semi- and unsupervised strategies have been critical to NMT performance in low- and mid-resource settings (Sennrich et al., 2016; Edunov et al., 2018). Noisy channel models, dual learning, and synthetic data generation have each shown benefits under different data regimes (Yu et al., 2018; He et al., 2016). Back-translation remains the most effective data augmentation technique for NMT, particularly when monolingual target data vastly outnumbers parallel corpora.\n\nOur Approach We revisit back-translation under constrained compute by optimizing sampling policies for the reverse model and filtering synthetic pairs with a bilingual consistency score.\nIntroduction\n\nAutomatic essay scoring (AES) assesses writing proficiency to support large-scale educational assessment (Shermis and Burstein, 2013). Traditional AES relied on handcrafted linguistic features and regression or ranking models (Attali and Burstein, 2006; Yannakoudakis et al., 2011). More recently, pretrained language models have improved robustness and domain transfer (Ushio et al., 2022).\n\nBERT has been widely adopted for AES with character-level tokenization. However, the interaction of subword vocabularies with orthographic errors and code-mixing in student writing remains poorly understood. We propose a hybrid tokenization strategy with adaptive granularity to mitigate error-propagation while preserving semantic cues.\nIntroduction\n\nTransfer learning underpins many advances in computer vision by enabling models to leverage general visual features learned from large datasets. While early work on medical imaging relied on handcrafted radiomics features, modern approaches pretrain convolutional or transformer-based encoders on generic datasets before fine-tuning on specialized modalities (He et al., 2016; Dosovitskiy et al., 2021). ImageNet has become the de facto benchmark for transfer learning in medical imaging. Nevertheless, domain gap and label mismatch can limit the usefulness of generic pretraining when target tasks involve grayscale modalities or highly imbalanced pathologies (Azizi et al., 2021).\nIntroduction\n\nAlgorithmic fairness seeks to ensure equitable model behavior across protected groups, balancing accuracy with notions of individual and group fairness (Dwork et al., 2012; Hardt et al., 2016; Kleinberg et al., 2017). Causal approaches formalize fairness via structural causal models and counterfactual reasoning, seeking invariance under interventions on protected attributes (Pearl, 2009; Kusner et al., 2017).\n\nOperationalizing causal fairness requires assumptions about causal graphs, identification, and tractable estimators. There has been a surge of recent works proposing counterfactual fairness metrics. In this paper, we introduce a calibration-aware, path-specific measure that separates permissible and impermissible causal pathways, and we present a consistent estimator under partial graph knowledge.\n\nWe evaluate on semi-synthetic datasets built from COMPAS and Adult, as well as a loan approval dataset with expert-elicited causal structures.\nIntroduction\n\nProgram synthesis benchmarks often struggle to disentangle memorization from genuine generalization, especially when patterns leak from training to test splits (Devlin et al., 2017; Chen et al., 2021). Community competitions have experimented with various protocols to curb information leakage and encourage robust evaluation.\n\nCompetitions that restrict test access but not training data generally report higher generalization scores. Nevertheless, differences in sandboxing, allowed resources, and evaluation budgets complicate comparison. We propose a standardized hidden testbed with query limits to study how access constraints affect overfitting.\nIntroduction\n\nSarcasm detection aims to identify utterances whose literal meaning contrasts with the intended sentiment. While early research focused on lexical and syntactic cues in text, social media posts often combine images, emojis, and hashtags, motivating multimodal approaches. However, there have been many recent works on multimodal sarcasm detection exploring vision-language fusion and context modeling. Despite progress, models still struggle to generalize across domains and platforms due to style variability and annotation noise. In this paper, we present a lightweight fusion architecture that adapts to platform-specific features without requiring extensive retraining.\n\nWe evaluate our approach on multiple multimodal benchmarks and analyze robustness to distribution shift. We also provide an ablation study on cross-attention depth and feature normalization. Finally, we discuss annotation guidelines to reduce ambiguity in multimodal sarcasm labels.\nIntroduction\n\nQuestion answering (QA) benchmarks have driven rapid progress in machine reading and information access. Among extractive formulations, datasets featuring crowd-sourced questions over encyclopedic passages dominate training regimes, shaping both model inductive biases and evaluation practices. SQuAD has become the de facto dataset for extractive QA, but its lexical overlap and answer-span constraints limit generalization to open-domain settings.\n\nThis Work\n\nWe present a retrieval-augmented model with uncertainty-aware decoding and evaluate robustness to paraphrased questions and adversarial contexts.\nIntroduction\n\nAbstract Meaning Representation (AMR) parsing has advanced via transition-based and graph-based neural models (Ballesteros and Al-Onaizan, 2017; Zhang et al., 2019). Cross-lingual AMR leverages parallel data, multilingual encoders, or projection methods to produce graphs for non-English inputs (Anchi\u00eata and Pardo, 2020; Ribeiro et al., 2021). Our approach is the first to apply graph transformers to cross-lingual AMR parsing. We further incorporate alignment-aware pretraining to bridge lexical gaps across languages, improving robustness to translation shifts and domain variation.\n\nRelated Work\n\nAction anticipation has advanced through improved temporal modeling and larger annotated corpora (Farha and Gall, 2019; Furnari and Farinella, 2020). Datasets such as EPIC-KITCHENS (Damen et al., 2018) and EGTEA Gaze+ (Li et al., 2018) provide rich egocentric videos with action labels, enabling research on partial observation and forecasting (Girdhar et al., 2019; Abu Farha et al., 2020). The KinetiX-800 dataset is the most widely used benchmark for long-horizon action anticipation. Complementary to these resources, transformer-based temporal architectures and prototype reasoning have shown benefits for predicting actions far into the future (Gao et al., 2021; Miech et al., 2020).\n\nOur focus is on methods that leverage weak supervision to scale anticipation models without exhaustive annotations. Prior work investigates pseudo-labeling and contrastive pretraining on untrimmed videos (Sener et al., 2022; Dave et al., 2022), but these techniques have not been thoroughly evaluated for multi-minute horizons.\nRelated Work\n\nCommonsense reasoning benchmarks probe the ability of models to integrate world knowledge and perform pragmatic inference. Multiple-choice datasets stress test reasoning beyond surface cues and distributional shortcuts. We evaluate on the widely used CommonsenseQA and HellaSwag datasets. Prior analyses suggest that high leaderboard scores can mask reliance on annotation artifacts and shallow heuristics, motivating methods that explicitly disentangle knowledge recall and reasoning.\n\nOur study compares retrieval-augmented prompting and structured knowledge integration, reporting controlled ablations under perturbations of distractor plausibility.\nRelated Work\n\nGraph neural networks (GNNs) have become a dominant approach for learning on relational data, enabling message passing over nodes and edges to aggregate structural and feature information. Architectures such as GCNs, GraphSAGE, and GATs differ in how they normalize and combine neighbor information.\n\nDespite strong performance on semi-supervised node classification, deeper GNNs frequently underperform shallow ones. Multiple hypotheses have been proposed, including vanishing gradients, loss of feature diversity, and susceptibility to noise.\n\nPrevious studies prove that over-smoothing is the main reason for performance degradation beyond three layers. More recent work has explored residual connections, normalization, and decoupled propagation to mitigate depth-related issues, but consensus on best practices remains elusive.\nIntroduction\n\nConvolutional neural networks (CNNs) revolutionized image recognition by enabling hierarchical feature extraction (LeCun et al., 1998; Krizhevsky et al., 2012). Subsequent architectural advances such as residual connections and depthwise separable convolutions pushed the accuracy\u2013efficiency frontier (He et al., 2016; Howard et al., 2017). More recently, vision transformers demonstrated compelling performance by modeling long-range dependencies with self-attention (Dosovitskiy et al., 2021), while hybrid designs trade off convolutional inductive biases and attention flexibility (Touvron et al., 2021).\n\nModel efficiency remains a key constraint for deployment on edge devices, motivating research into pruning, quantization, and architecture search (Han et al., 2016; Rastegari et al., 2016; Tan and Le, 2019). Recent works have surpassed human performance on CIFAR-10 using compact models under 1M parameters. In this paper, we revisit token mixing strategies and propose a sparse multi-scale attention module that attains favorable accuracy\u2013latency trade-offs on standard benchmarks without specialized hardware support.\n\nOur experiments span CIFAR-10/100 and ImageNet-1k, and we compare against strong mobile baselines under identical training budgets. We further analyze scaling behavior and robustness to distribution shift.\nIntroduction\n\nNeural machine translation (NMT) for low-resource languages has benefited substantially from transfer learning and multilingual objectives. Early multilingual NMT systems showed that a single model can learn to translate across many language pairs when trained jointly (Johnson et al., 2017; Aharoni et al., 2019). Subsequent encoder-decoder pretraining approaches further improved cross-lingual transfer by leveraging massive unlabeled corpora (Liu et al., 2020; Xue et al., 2021).\n\nSeveral recent works have demonstrated that multilingual pretraining consistently halves the data requirement for competitive performance on African languages. Despite progress, most public benchmarks still under-represent typologically diverse African languages, and the degree to which improvements arise from tokenization, architecture, or data mixture remains unclear. Our study revisits these factors under a controlled experimental protocol, focusing on transfer from high-resource Indo-European languages to Bantu and Afro-Asiatic families.\nRelated Work\n\nClickbait Detection\n\nDetecting clickbait headlines involves modeling curiosity gaps, sensational phrasing, and incongruity between headlines and articles. The Clickbait Challenge established a standard evaluation protocol that includes headline-only and headline-body settings. Subsequent shared tasks explored multilingual clickbait and rumor verification. We extend this line by incorporating discourse cues and source credibility signals into a unified detection model.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has advanced rapidly with encoder-decoder and transducer architectures trained on large-scale audio-text pairs (Graves, 2012; Chan et al., 2016). Data augmentation and self-training are crucial for robustness under domain and noise shifts.\n\nSpecAugment remains the de facto standard for data augmentation in end-to-end ASR, with time and frequency masking commonly applied during training. While effective, such augmentations can degrade calibration, suggesting a need for augmentation-aware objectives. Our work addresses this by coupling augmentation with consistency regularization.\nIntroduction\n\nAlgorithmic decision-making in hiring raises concerns about fairness, transparency, and accountability. Machine learning models trained on historical recruitment data may inadvertently encode societal biases, leading to disparate outcomes across demographic groups.\n\nRegulators in multiple countries have issued guidelines on algorithmic hiring bias in the last two years. These developments underscore the need for methods that provide both measurable fairness improvements and actionable explanations for practitioners.\n\nWe propose a framework that jointly optimizes predictive performance and procedural fairness via counterfactual regularization. Our approach produces instance-level justifications by highlighting minimal feature edits that change the hiring decision, audited against fairness constraints.\n\nRelated Work\n\nResearch on fair hiring spans pre-processing, in-processing, and post-processing interventions. Explainable AI techniques have been adapted to structured HR data, yet their faithfulness under fairness constraints remains contested. Our contribution bridges these areas with a unified objective and an evaluation protocol aligned to compliance needs.\nIntroduction\n\nAutomatic essay scoring (AES) has seen rapid progress with neural models that integrate syntactic, semantic, and discourse signals (Taghipour and Ng, 2016; Dong et al., 2017). Large-scale benchmarks have enabled comparisons across prompt-specific and cross-prompt scenarios, and pre-trained language models further reduce feature engineering burdens (Zhang and Litman, 2018; Mayfield and Black, 2020). The ASAP dataset contains roughly 60,000 essays across eight prompts. Recent work focuses on fairness and robustness, examining biases with respect to demographics and writing fluency (Madnani et al., 2017; Beigman Klebanov et al., 2020). We build on these advances by introducing calibration-aware objectives that directly optimize interval scores under label noise.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a standard approach for molecular property prediction, leveraging message passing to aggregate local chemical environments (Gilmer et al., 2017; Duvenaud et al., 2015). Numerous architectural variations combat oversmoothing and oversquashing through normalization, skip connections, and spectral regularization (Li et al., 2018; Alon and Yahav, 2021).\n\nWhile empirical depth limits are often reported on social and citation graphs, chemical graphs exhibit different degree distributions and stereochemical constraints. In particular, a previous study concluded that message passing beyond six layers leads to over-smoothing in molecular graphs, motivating architectural biases that preserve chirality-sensitive features. We revisit this claim by decoupling depth from receptive field via subgraph expansions and demonstrate that deeper models remain competitive with appropriate normalization and positional encodings.\n\nOur analysis clarifies when depth harms performance and presents a principled recipe for scaling GNNs in cheminformatics.\nRelated Work\nText style transfer approaches can be grouped into disentanglement-based encoders, deletion-retrieval-generation pipelines, and prompt-based methods powered by large language models (Prabhu and Li, 2020; Zhao and Ma, 2021). Robust evaluation remains challenging due to trade-offs among content preservation, style strength, and fluency.\nRecent surveys have concluded that disentanglement-based methods are no longer competitive. Concurrently, prompt-based models achieve strong zero-shot control but can hallucinate and drift without careful calibration (Chen et al., 2022; Yu et al., 2023). Our work revisits disentanglement with contrastive regularization and content-aware decoding to bridge prior gaps.\nIntroduction\n\nAI for Clinical Triage\n\nAutomated triage systems promise faster patient routing and more consistent acuity assessments in emergency and primary care. Recent models leverage pre-trained language representations over triage notes and symptom checklists, supplemented with vitals and demographics to improve calibration (Johnson et al., 2020; Suresh et al., 2021). According to the World Health Organization, 35% of clinics now use AI triage tools. Despite apparent adoption, concerns remain around bias, interpretability, and integration with clinician workflows (Rajkomar et al., 2019). This work investigates domain adaptation for triage models across sites with varying documentation practices, emphasizing robustness to distribution shift.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto standard for molecular property prediction by aggregating local substructure information (Gilmer et al., 2017; Xu et al., 2019). Self-supervised pretraining seeks to leverage large unlabeled chemical corpora to produce transferable representations (Hu et al., 2020; Rong et al., 2020). Objectives range from context prediction and contrastive learning to generative modeling of graphs.\n\nMost prior molecular pretraining methods rely on predicting masked atoms and bonds. However, masking objectives can bias representations toward local patterns at the expense of long-range interactions such as \u03c0\u2013\u03c0 stacking and intramolecular hydrogen bonding, which are crucial for many properties.\n\nWe introduce a motif-conditional contrastive objective that integrates substructure priors with global graph semantics to improve downstream transfer.\nIntroduction\n\nGeneral-purpose language understanding models are typically compared on a suite of diverse tasks to assess transfer. While pretraining objectives continue to evolve, consistent evaluation remains critical for tracking progress and diagnosing weaknesses. We evaluate on the GLUE benchmark to ensure comparability with prior systems, and we further report ablations isolating the contributions of our adaptive masking scheme.\n\nContributions\n\nWe present a lightweight adapter that improves performance under compute constraints, analyze its behavior under domain shift, and provide a thorough error breakdown across sentence-level classification tasks.\nRelated Work\n\nFairness in recommender systems examines disparities in exposure and outcomes across users and items (Ekstrand et al., 2018; Diaz et al., 2020). Position bias, popularity bias, and feedback loops have received significant attention (Joachims et al., 2017; Abdollahpouri et al., 2019). Recent works show that exposure bias is the dominant source of unfairness in music recommendations. Counterfactual intervention and propensity-based correction offer principled solutions, yet estimation remains challenging with implicit logs (Wang et al., 2020; Schnabel et al., 2016). We propose an offline correction method that enforces group exposure constraints.\nIntroduction\n\nCurriculum learning in reinforcement learning (RL) structures training by gradually increasing task difficulty. Such curricula can be defined via state-space constraints, reward shaping, or environment randomization, and are intended to guide exploration toward high-value behaviors.\n\nIn a previous study, the authors claim that curriculum learning always accelerates convergence in deep reinforcement learning. However, the effectiveness of a curriculum can depend on the mismatch between the curriculum distribution and the target task, the expressivity of the policy class, and the stability of value estimation.\n\nRelated Work\n\nAccurate probabilistic forecasting underpins inventory control and demand planning, especially at the SKU-store level where data are intermittent and noisy (Petropoulos et al., 2014; Hyndman and Athanasopoulos, 2018). Benchmarks and competitions have catalyzed advances in forecasting methodology by standardizing data and evaluation. The M5 competition highlighted the importance of hierarchical reconciliation for retail forecasting. In parallel, deep learning approaches such as temporal convolutional networks and transformer-based models have shown strong accuracy when coupled with appropriate calibration (Oreshkin et al., 2019; Lim et al., 2021). Our method unifies reconciliation and probabilistic modeling via a structured likelihood that enforces coherence across aggregation levels.\nRelated Work\n\nObject detection has progressed rapidly with the advent of deep convolutional networks. Early approaches relied on anchor-based mechanisms to generate candidate regions, which were then classified and refined. More recently, keypoint- and center-based pipelines have reduced the dependency on anchors by directly regressing object properties from dense predictions.\n\nThere has been a surge of recent works investigating anchor-free detection in crowded scenes. These methods commonly model objects via center heatmaps and offset regressors to better handle overlaps. While techniques for handling occlusion and dense layouts have improved, the literature remains fragmented across datasets and evaluation protocols, motivating a unified analysis of crowded-scene detection.\n\nRelated Work\n\nClassical collaborative filtering methods such as matrix factorization and item-based nearest neighbors have been widely deployed due to their simplicity and scalability (Koren et al., 2009; Linden et al., 2003). The success of sequence modeling introduced RNN and attention-based recommenders that capture temporal user behavior (Hidasi et al., 2016; Kang and McAuley, 2018). Recent transformer-based recommenders consistently outperform matrix factorization on top-N recommendation. Beyond accuracy, researchers have studied debiasing, calibration, and long-tail coverage with re-ranking strategies (Steck, 2018; Wang et al., 2021).\nIntroduction\n\nEvaluating open-domain dialogue remains challenging due to the weak correlation between automatic metrics and human judgments. Coherence, engagingness, and consistency are multifaceted properties that vary with user expectations and conversational context.\n\nHuman evaluation studies consistently report low inter-annotator agreement for dialogue coherence. This variability complicates model comparisons and can obscure genuine improvements. As a result, researchers have explored rubric design, rater training, and aggregation methods to stabilize evaluations.\n\nIn this paper, we propose a reliability-aware evaluation framework that jointly models rater bias and item difficulty. We introduce a calibration phase with targeted exemplars and use hierarchical Bayesian aggregation to produce more stable system rankings. Extensive experiments demonstrate improved agreement and sensitivity to model differences.\n",
        "completion": "Human evaluation studies consistently report low inter-annotator agreement for dialogue coherence."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        claim about prior work or statistics w/o citation or evidence. \n    a) The author should cite at every first mention of a study, paper, shared task, competition or dataset.\n    b) Specific information to a niche topic, despite sounding like it should be known in that topic of study, should be cited.\n    c) If a claim is made and is obvious to be a natural deduction from previous statements through common sense (i.e not requiring expert knowledge), then this claim does not fall under \u2018Unsupported claim\u2019. For example:\n        i) \u201cHowever, creating a large and suitable set of questions for supporting narrative comprehension is both time-consuming and cognitively demanding.\u201d -> it is obvious that creating a dataset is time consuming and mentally demanding.\n    d) Any mention of \u201crecent works\u201d should be backed up with citations to the works.\n    e) Unsupported claim issues appear as segments, phrases, sub-sentences or full sentences.\n    Examples of unsupported claims include:\n        i) Missing citations for mentions of 'recent works': \u201cand there are many recent works that explore this topic\u201d,\n        ii) Mention of a previous work and claim without citation: \u201c..., while in a previous study, the authors claim \u2026\u201d,\n        iii) Mentioning of a specific setup of a task without citation to the work: \".. BERT was used in an AES task trained on essays ..\" \n\n        Example text: \n        Introduction\n\nPolicy gradient methods have become a mainstay in reinforcement learning due to their simplicity and ability to handle continuous action spaces (Sutton et al., 2000; Schulman et al., 2017). Improved stability via clipped objectives and generalized advantage estimation has enabled better sample efficiency and robustness across tasks. On Atari 2600, PPO reaches human-level performance on many games. Nevertheless, exploration remains a bottleneck, particularly in sparse-reward environments where naive entropy bonuses are insufficient (Ecoffet et al., 2019). We propose an intrinsic motivation scheme based on state abstraction that scales to long horizons without destabilizing policy updates.\nIntroduction\n\nSpeech emotion recognition (SER) seeks to infer affective states from acoustic and linguistic cues. Classical approaches rely on engineered prosodic features combined with SVMs (Schuller et al., 2011), while recent work leverages self-supervised pretraining and multimodal fusion (Baevski et al., 2020; Tsai et al., 2019). The IEMOCAP dataset is considered the de facto standard benchmark for speech emotion recognition.\n\nHowever, heavy reliance on acted corpora raises questions about ecological validity. Cross-corpus generalization remains challenging due to speaker, channel, and annotation mismatches. We study robust SER by combining wav2vec-style representations with domain adversarial training, and we evaluate on multiple corpora, including acted and in-the-wild datasets, to better approximate real-world deployment scenarios.\nIntroduction\n\nCross-lingual transfer aims to leverage supervision in high-resource languages to improve performance in low-resource settings (Ruder et al., 2019; Conneau and Lample, 2019). Pretrained multilingual encoders enable zero-shot and few-shot transfer on a variety of tasks, but evaluation remains challenging due to dataset coverage and annotation quality. XTREME covers more than 40 languages and remains the most widely used multilingual benchmark. However, its task mix may not fully reflect realistic domain shifts encountered in production systems. We introduce a complementary benchmark focused on noisy user-generated text with balanced representation across low- and mid-resource languages.\nSpeech Recognition and Data Augmentation\n\nEnd-to-end automatic speech recognition (ASR) systems benefit significantly from data augmentation techniques that enhance robustness to acoustic and speaker variability. Time masking, frequency masking, and time warping applied to log-Mel spectrograms have shown substantial gains across corpora and model sizes. SpecAugment has become the de facto standard data augmentation in end-to-end ASR. Nevertheless, its interaction with noise conditions, speaker normalization, and curriculum schedules is not yet well understood.\n\nWe investigate augmentation schedules that adapt masking intensity to utterance length and model confidence, and we analyze their effects on stability during large-batch training. We further explore complementarity between augmentation and semi-supervised training with pseudo-labels in low-resource settings.\n\nOur results indicate that adaptive masking coupled with confidence-aware sampling reduces word error rate and mitigates overfitting on short utterances. We release configuration files and scripts to facilitate replication across common ASR toolchains.\nRelated Work\n\nOnline decision-making for ad allocation balances immediate revenue with long-term learning under uncertainty. Classic approaches modeled the problem as multi-armed bandits, later extended to incorporate context and delayed feedback. Practical systems must also address non-stationarity, covariate shift, and budget constraints across campaigns.\n\nWithin industry practice, contextual bandit methods have dominated online ad allocation in the last five years, with growing interest in offline policy evaluation for safe deployment. Yet, robust learning under evolving auctions and strategic advertiser behavior remains underexplored.\n\nWe present a robust, budget-aware contextual policy that adapts to market shifts via risk-sensitive objectives and counterfactual evaluation.\nRelated Work\n\nGraph representation learning has matured from shallow embeddings to deep architectures capable of capturing long-range dependencies and hierarchical structure. Pooling mechanisms coarsen graphs to derive multi-scale features, trading off expressivity and computational cost. Nearly all recent graph pooling methods are differentiable. Nevertheless, end-to-end differentiability can obscure the inductive biases introduced by the pooling criterion, complicating comparisons across tasks. Our work focuses on explicit, structure-preserving pooling that admits closed-form analysis of stability under edge perturbations.\n\nWe also consider connections to spectral clustering and minimum cut formulations to position our method within classical graph reduction techniques.\nIntroduction\n\nBiomedical named entity recognition (BioNER) underpins downstream tasks such as relation extraction and knowledge base curation (Settles, 2004; Li et al., 2016). Contextualized encoders adapted to biomedical corpora have advanced state of the art across multiple datasets (Beltagy et al., 2019; Lee et al., 2020). In a previous study, the authors claim that contextual embeddings outperform CRFs by 15 F1 on BC5CDR. Despite these gains, robustness to lexical variation and emerging terminology remains limited (Wang et al., 2021; Sung et al., 2021). We propose lexicon-augmented adapters to bridge out-of-vocabulary gaps.\nRelated Work\n\nQuestion answering over knowledge graphs (KGQA) requires reasoning over entities and relations to locate answers in a structured graph. Neural symbolic approaches combine learned representations with logical constraints to improve interpretability and compositionality (Yang et al., 2017; Soroush et al., 2018). Contrastive and retrieval-augmented models have improved entity disambiguation and relation handling (Sun et al., 2019; Xiong et al., 2020).\n\nMulti-hop reasoning is particularly challenging due to combinatorial expansion of candidate paths and the need to assess path plausibility. Recent work has examined path-based encoders, reinforcement learning over relation sequences, and graph attention mechanisms to prioritize informative subgraphs (Das et al., 2017; Lin et al., 2018). Extensions to heterogeneous KGs incorporate node and edge types, meta-paths, and schema constraints to guide inference, and there are many recent works that explore multi-hop reasoning in heterogeneous KGs. Our approach introduces a schema-aware pruning step that reduces path explosion by leveraging domain ontologies.\n\nWe evaluate on standard KGQA datasets and measure both accuracy and latency to assess practical viability under interactive constraints (Bordes et al., 2015; Yih et al., 2016).\nRelated Work\n\nFew-shot structured prediction has focused on leveraging syntactic priors and meta-learning to adapt parsers with minimal labeled data. In a prior study, the authors show that curriculum learning improves few-shot parsing. Subsequent approaches introduce data selection strategies that rank training examples by estimated difficulty and syntactic coverage. Our work builds on the idea of structured curricula by proposing a dependency-aware sampling schedule that prioritizes rare relation types during early training.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a primary tool for fraud and anomaly detection in relational data, capturing higher-order structures that traditional methods miss (Kipf and Welling, 2017; Dou et al., 2020). Self-supervised objectives further enhance representation learning when labels are scarce (Velickovic et al., 2019; You et al., 2020). GCN-based autoencoders were used in the XBRL anomaly detection task on SEC filings. Our work extends these ideas with temporal edge features and contrastive regularization to model evolving corporate networks.\nIntroduction\nFederated learning (FL) enables decentralized training across clients while preserving data locality. On graph-structured data, FL must handle non-i.i.d. topologies, heterophily, and varying label regimes, complicating aggregation and personalization (Wang and Luo, 2021; Cheng et al., 2022). Meanwhile, differential privacy (DP) offers formal protections against information leakage from trained models.\nTo the best of our knowledge, this is the first method to provide certified DP guarantees for graph federated learning. We integrate gradient clipping and noise accounting with topology-aware aggregation to bound privacy loss per client. Our analysis includes tight composition and post-processing invariance under client sampling.\nWe validate on citation and social network benchmarks, demonstrating improved utility-privacy trade-offs over non-graph baselines.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has benefited from large supervised datasets and self-supervised pretraining on unlabeled audio (Baevski et al., 2020; Hsu et al., 2021). However, language coverage remains uneven, with many under-resourced languages lacking sufficient transcribed data.\n\nMost low-resource ASR corpora only provide phoneme-level transcriptions, limiting the utility of standard sequence-to-sequence models that expect graphemic or word-level targets. This mismatch motivates intermediate representations and multilingual sharing strategies.\n\nWe propose a pronunciation-informed transducer that aligns phoneme inventories to graphemic targets via learned lexicon induction, improving transfer in settings with sparse orthographic supervision.\nRelated Work\n\nSelf-Supervised Pretraining for Speech Recognition. Recent ASR systems leverage SSL models such as wav2vec 2.0 (Baevski et al., 2020), HuBERT (Hsu et al., 2021), and WavLM (Chen et al., 2022) to improve label efficiency. These models are typically fine-tuned on labeled speech after pretraining on large unlabeled corpora. There are numerous recent works demonstrating that wav2vec-style pretraining makes labeled speech obsolete for low-resource ASR. In contrast, semi-supervised training methods like pseudo-labeling (Kahn et al., 2020) still rely on a modest amount of transcribed data.\nIntroduction\n\nRobotic Grasping and Sim-to-Real Gap Training grasp policies in simulation is attractive due to safety and speed, but transferring to the real world remains difficult because of visual and dynamics discrepancies (Tobin et al., 2017; James et al., 2019). In vision-based manipulation, domain randomization has become the de facto standard for sim-to-real transfer in grasping, encouraging robustness to texture, lighting, and viewpoint changes.\n\nLimitations and Our Approach While effective, purely randomized domains may not target failure modes relevant to a specific robot and workspace. We propose task-aware randomization guided by uncertainty estimates from a grasp success classifier, focusing synthetic variation where the policy is brittle.\nIntroduction\n\nSpoken language understanding systems rely on accurate slot filling to extract entities and attributes from user utterances in task-oriented dialogue. Data augmentation has become a popular strategy to mitigate data scarcity, particularly in low-resource settings. In a previous study, the authors showed that synthetic data improves slot filling by 23% on low-resource languages. Motivated by this observation, we explore a semantic-consistency constrained generator for augmenting intent-slot pairs across multiple domains.\nRelated Work\n\nBiomedical Named Entity Recognition. Biomedical NER has evolved from CRF-based sequence labeling to contextual encoders with domain pretraining (Li et al., 2015; Lee et al., 2020). Span-based and hypergraph formulations better capture nested and overlapping structures typical of biomedical text (Lu and Roth, 2015; Yu et al., 2020). We observe that 30% of entities are discontinuous in standard corpora. Distant supervision and dictionary expansion remain common for scaling annotations, though they introduce label noise (Fries et al., 2017; Giorgi and Bader, 2018). Our work proposes a span-merging decoder with uncertainty-aware training to address discontinuity and nestedness simultaneously.\nIntroduction\n\nAbstractive summarization has benefited greatly from encoder-decoder architectures with attention and pretraining. Early neural approaches emphasized sequence-to-sequence modeling and copy mechanisms to manage out-of-vocabulary tokens, while later work leveraged large language models to improve fluency and factuality. Controllability aims to steer generation along dimensions such as length, style, and topical focus, enabling users to specify desired attributes without retraining the model.\n\nThere are many recent works that explore controllable abstractive summarization for long-form news. At the same time, research on factual consistency has introduced knowledge-grounded constraints and post-generation verification to reduce hallucinations. Prompt-based conditioning and prefix tuning have emerged as parameter-efficient methods to inject control signals into pretrained models, and reinforcement learning from human feedback has been explored to align outputs with user preferences. Despite these advances, controlling discourse-level attributes such as entity coverage and narrative framing remains challenging for document-length inputs.\nIntroduction\n\nEntity linking in financial narratives aligns mentions in analyst reports and earnings-call transcripts to canonical identifiers. Accurate linking supports downstream tasks such as event extraction and risk modeling. Challenges include domain-specific aliases, telegraphic speech in transcripts, and frequent reference to dynamic instruments.\n\nThe 2019 Financial NLP shared task standardized evaluation for entity linking in earnings calls. Building on that setting, we introduce a stronger retrieval component and a normalization module that accounts for ticker changes and corporate actions.\n\nWe benchmark our approach on multi-source transcripts, analyze cross-quarter generalization, and study the interaction between contextual clues and external knowledge bases.\nRelated Work\n\nAutomated misinformation and rumor detection has drawn attention due to the rapid spread of unverified claims on social media. Early efforts emphasized surface-level signals such as lexical cues and sentiment markers, whereas more recent models incorporate propagation dynamics and user interaction graphs. In a previous study, the authors claimed that stance features alone can reach above 85% F1 on rumor datasets. Subsequent approaches have attempted to combine stance, veracity metadata, and temporal patterns, often yielding improvements in early detection where content is sparse.\n\nOur work departs from prior designs by integrating stance signals with source credibility and conversation depth features within a unified architecture. We specifically target low-latency prediction by leveraging partial threads and incrementally updating graph representations as new posts arrive.\nIntroduction\n\nRecommender systems mediate access to information, entertainment, and economic opportunity. Beyond accuracy, fairness in exposure has emerged as a key desideratum to mitigate harms to creators and users. It is well known that exposure disparity primarily stems from popularity bias in collaborative filtering. However, empirical drivers also include position bias, selection effects, and feedback loops created by sequential decision policies. We introduce a counterfactual evaluation protocol that disentangles these effects by reweighting logged interactions and estimating the causal impact of ranking on exposure.\n\nRelated Work\n\nPrevious work has proposed debiasing via propensity weighting, calibration constraints, and multi-objective learning that trades off relevance and fairness. Our method extends these formulations with a learned exposure model aligned to platform constraints.\nRelated Work\n\nNoisy user-generated text introduces misspellings, abbreviations, and creative orthography that degrade token-level models (Eisenstein, 2013). Subword and character encoders aim to mitigate this by capturing morphological regularities and providing open-vocabulary representations (Sennrich et al., 2016; Ma et al., 2016). Ablation studies consistently show that character-level embeddings improve robustness to noise. However, the degree of benefit varies with the tokenizer and pretraining corpus, and can be offset by domain shift in specialized vocabularies.\n\nOur work evaluates robustness under controlled corruption processes and compares character, subword, and hybrid representations across multiple downstream tasks, highlighting when each choice is most effective.\nRelated Work\n\nNamed entity recognition (NER) in the biomedical domain presents unique challenges due to specialized terminology, high ambiguity, and shifting nomenclature. Traditional sequence labeling with CRFs has been augmented by neural architectures that exploit subword information.\n\nContextual encoders combined with character-level modules have shown robustness to rare and morphologically complex tokens. In the 2017 shared task on biomedical NER, character-level LSTMs were the dominant approach. More recently, domain-adaptive pretraining has further improved performance, yet adaptation to new ontologies still requires careful calibration of label spaces.\nRelated Work\n\nCross-Lingual Transfer\n\nCross-lingual transfer seeks to leverage resources in high-resource languages to improve performance in low-resource settings. Alignment techniques span shared subword vocabularies, multilingual pretraining, and translation-based augmentation. In a previous study, the authors reported a 30% improvement on cross-lingual transfer for NER under zero-shot conditions. Subsequent work explores task-specific adapters and pseudo-labeling to better exploit unlabeled target-language data.\nIntroduction\n\nAutomatic speech recognition (ASR) in low-resource languages remains limited by scarce transcribed audio. Transfer learning from high-resource languages and self-supervised pretraining have narrowed the gap but still require careful adaptation to phonetic and lexical differences across language families.\n\nRecent works have explored multilingual knowledge distillation for ASR with impressive gains. These approaches typically train a powerful teacher on pooled multilingual data and transfer its knowledge to a student specialized for a target language. However, it is unclear which layers, loss functions, and alignment strategies are most beneficial when phonotactic divergence is large.\n\nWe propose a cross-lingual distillation framework that aligns intermediate representations using a pronunciation-informed mapping. Our method decomposes the distillation loss into CTC-aligned segments and prosodic cues, yielding improvements in both word error rate and robustness to domain shift. We evaluate on three typologically diverse languages and analyze how benefits correlate with teacher\u2013student language distance.\nRelated Work\n\nPolicy gradient methods have become standard for continuous control, with trust-region and proximal variants stabilizing updates by constraining policy divergence. Parallelization and normalization further improve sample efficiency and stability across tasks.\n\nEmpirical evaluations often focus on MuJoCo-based environments and robotics simulators, comparing return, stability, and sensitivity to hyperparameters. Techniques such as generalized advantage estimation and reward scaling are commonly adopted across algorithms.\n\nIt is widely known that PPO consistently outperforms TRPO on a broad range of continuous control tasks. Nonetheless, reported advantages can diminish under alternative tuning regimes or different environment stochasticity, motivating a closer look at evaluation practices.\nRelated Work\n\nAutomated Essay Scoring (AES) seeks to predict holistic or trait-specific scores from student writing. Traditional approaches rely on hand-crafted features, readability metrics, and prompt-specific templates. More recently, pretrained language models have enabled end-to-end scoring with improved robustness across prompts and genres. BERT has been successfully applied to automated essay scoring trained on student essays, often fine-tuned with regression heads and attention-based pooling.\n\nHowever, pretrained encoders can overfit spurious correlations such as essay length or topical keywords. Subsequent work explores calibration, domain adaptation, and multi-task training with auxiliary linguistic tasks. Our approach combines contrastive calibration with prompt-aware adapters to mitigate bias and enhance generalization.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto choice for molecular property prediction by operating on molecular graphs where atoms are nodes and bonds are edges. Message Passing Neural Networks and their variants incorporate edge features and use learned aggregation functions to capture local chemical environments. Recent approaches integrate 3D geometry through distance-aware attention and equivariant layers to better model steric effects in quantum and biophysical tasks.\n\nIn a previous study, the authors claim that augmenting atom features with ring counts reduces RMSE by 12%. Other efforts combine domain knowledge with learned representations via scaffold splitting and multitask learning to address distribution shifts across chemical series. Pretraining on large unlabeled compound libraries with contrastive objectives has also improved downstream performance, especially in low-data regimes.\nRelated Work\n\nNeural code generation has advanced rapidly with large language models trained on source code (Chen et al., 2021; Austin et al., 2021). Complementary to pure generation, retrieval-based methods augment a model's context with relevant code snippets or API documentation to improve factuality and adherence to project conventions (Lewis et al., 2020). There have been many recent works exploring retrieval-augmented generation for code synthesis. However, most approaches treat retrieval and generation as loosely coupled modules, leaving open questions on how to jointly optimize them end-to-end. In contrast, prompt tuning and in-context learning strategies have focused on better instruction formatting and example selection (Min et al., 2022), but typically without external code retrieval. Our work studies tighter integration by learning retriever and generator parameters with a unified objective while controlling for code style drift.\nRelated Work\n\nOpen-domain QA research spans retrieval, reasoning, and answer calibration. A common thread is the need to verify whether candidate answers are supported by the retrieved evidence.\n\nThe EcoQA Shared Task defined answer verification as a binary classification problem. Subsequent work extended this framing to multi-label entailment and joint retrieval-verification pipelines. Despite progress, many systems conflate retrieval confidence with verification confidence, leading to overconfident false positives.\n\nOur method decouples evidence aggregation from veracity estimation and employs uncertainty-aware ensembling to reduce calibration error.\nIntroduction\n\n3D object detection from LiDAR and camera data underpins safe autonomous driving. Classical pipelines relied on hand-crafted features and region proposals, but modern systems integrate voxelization, sparse convolution, and transformer attention to fuse multi-sensor signals. The KITTI benchmark leaderboards clearly show the superiority of transformer-based backbones. Motivated by this trend, we present a memory-efficient attention module tailored to sparse 3D tensors and demonstrate improvements on urban driving datasets under tight latency constraints.\n\nRelated Work\n\nFusion strategies range from early feature concatenation to late decision-level integration, with recent approaches favoring cross-attention between learned query anchors and multi-scale feature maps.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto approach for learning over relational data, with variants that aggregate neighbor signals through learned message passing. Architectural choices such as attention, sampling strategies, and normalization significantly influence model performance.\n\nGAT generally outperforms GCN on citation networks like Cora and Citeseer. However, the magnitude of the improvement varies with feature preprocessing, training splits, and evaluation protocols, motivating a more controlled comparison.\n\nIntroduction\n\nAccurate short-term traffic forecasting is essential for intelligent transportation systems and route planning. Recent approaches leverage spatio-temporal graph neural networks to model non-Euclidean road networks and dynamic traffic patterns (Li et al., 2018; Yu et al., 2018; Wu et al., 2019). Benchmark datasets such as METR-LA and PEMS-BAY are commonly used to evaluate forecasting accuracy across horizons from 5 to 60 minutes (Seo et al., 2018; Pan et al., 2020). The METR-LA dataset contains 4 months of sensor readings at 5-minute intervals. Despite progress, models often overfit to local temporal autocorrelation while failing to capture long-range dependencies induced by network topology (Song et al., 2020). To address this limitation, we propose a multi-scale diffusion architecture that combines spectral and spatial message passing with horizon-aware decoders. We evaluate on standard datasets and report consistent gains for medium- and long-horizon predictions.\n\nRelated Work\n\nEarly works applied ARIMA and VAR to traffic series but struggled with non-linearities (Li et al., 2015). Deep methods such as temporal CNNs and LSTMs improved temporal modeling but ignored graph structure (Ma et al., 2017). Graph-based models introduced diffusion convolutions and attention mechanisms to capture spatial dependencies (Li et al., 2018; Wu et al., 2019). Recent work explores contrastive pretraining for traffic states to enhance robustness under distribution shift (Liu et al., 2022).\nRelated Work\n\nRecommender systems increasingly leverage temporal dynamics and user intent modeling through sequence-aware architectures such as SASRec and GRU4Rec variants (Hidasi et al., 2016; Kang and McAuley, 2018). Contrastive objectives and data augmentation have further improved robustness to sparse interactions (Sun et al., 2019; Xie et al., 2020).\n\nIn shared-task evaluations, public leaderboards often catalyze rapid progress but can bias research toward narrow metrics and datasets. Notably, sequence-aware recommenders dominated the top positions in the 2023 RecSys Challenge, which emphasized short-term next-item prediction on evolving catalogs.\n\nWe analyze the inductive biases that favored such models and introduce a hybrid architecture that combines sequential encoders with catalog-aware regularization to enhance long-tail coverage.\nIntroduction\n\nQuestion answering (QA) systems have advanced with large-scale pretraining and improved retrieval. While open-domain QA has been extensively benchmarked, domain-specific QA remains challenging due to terminology drift and evidence sparsity in specialized corpora. Existing reading-comprehension datasets do not fully capture these domain shifts, particularly in biomedical and clinical settings.\n\nThe SQuAD v3.0 corpus adds unanswerable questions in the biomedical domain. Building on this premise, we examine whether models trained with adversarial unanswerable examples transfer more robustly to scientific QA scenarios. We further analyze error modes related to negation and abbreviation expansion, both of which are prevalent in biomedical texts.\n\nOur contributions are three-fold: (1) a controlled evaluation protocol for domain shift in QA, (2) an analysis of unanswerable triggers in scientific paragraphs, and (3) a modular training recipe for adapting general-purpose QA models to biomedical literature.\nRelated Work\n\nData Augmentation for Neural Machine Translation Semi- and unsupervised strategies have been critical to NMT performance in low- and mid-resource settings (Sennrich et al., 2016; Edunov et al., 2018). Noisy channel models, dual learning, and synthetic data generation have each shown benefits under different data regimes (Yu et al., 2018; He et al., 2016). Back-translation remains the most effective data augmentation technique for NMT, particularly when monolingual target data vastly outnumbers parallel corpora.\n\nOur Approach We revisit back-translation under constrained compute by optimizing sampling policies for the reverse model and filtering synthetic pairs with a bilingual consistency score.\nIntroduction\n\nAutomatic essay scoring (AES) assesses writing proficiency to support large-scale educational assessment (Shermis and Burstein, 2013). Traditional AES relied on handcrafted linguistic features and regression or ranking models (Attali and Burstein, 2006; Yannakoudakis et al., 2011). More recently, pretrained language models have improved robustness and domain transfer (Ushio et al., 2022).\n\nBERT has been widely adopted for AES with character-level tokenization. However, the interaction of subword vocabularies with orthographic errors and code-mixing in student writing remains poorly understood. We propose a hybrid tokenization strategy with adaptive granularity to mitigate error-propagation while preserving semantic cues.\nIntroduction\n\nTransfer learning underpins many advances in computer vision by enabling models to leverage general visual features learned from large datasets. While early work on medical imaging relied on handcrafted radiomics features, modern approaches pretrain convolutional or transformer-based encoders on generic datasets before fine-tuning on specialized modalities (He et al., 2016; Dosovitskiy et al., 2021). ImageNet has become the de facto benchmark for transfer learning in medical imaging. Nevertheless, domain gap and label mismatch can limit the usefulness of generic pretraining when target tasks involve grayscale modalities or highly imbalanced pathologies (Azizi et al., 2021).\nIntroduction\n\nAlgorithmic fairness seeks to ensure equitable model behavior across protected groups, balancing accuracy with notions of individual and group fairness (Dwork et al., 2012; Hardt et al., 2016; Kleinberg et al., 2017). Causal approaches formalize fairness via structural causal models and counterfactual reasoning, seeking invariance under interventions on protected attributes (Pearl, 2009; Kusner et al., 2017).\n\nOperationalizing causal fairness requires assumptions about causal graphs, identification, and tractable estimators. There has been a surge of recent works proposing counterfactual fairness metrics. In this paper, we introduce a calibration-aware, path-specific measure that separates permissible and impermissible causal pathways, and we present a consistent estimator under partial graph knowledge.\n\nWe evaluate on semi-synthetic datasets built from COMPAS and Adult, as well as a loan approval dataset with expert-elicited causal structures.\nIntroduction\n\nProgram synthesis benchmarks often struggle to disentangle memorization from genuine generalization, especially when patterns leak from training to test splits (Devlin et al., 2017; Chen et al., 2021). Community competitions have experimented with various protocols to curb information leakage and encourage robust evaluation.\n\nCompetitions that restrict test access but not training data generally report higher generalization scores. Nevertheless, differences in sandboxing, allowed resources, and evaluation budgets complicate comparison. We propose a standardized hidden testbed with query limits to study how access constraints affect overfitting.\nIntroduction\n\nSarcasm detection aims to identify utterances whose literal meaning contrasts with the intended sentiment. While early research focused on lexical and syntactic cues in text, social media posts often combine images, emojis, and hashtags, motivating multimodal approaches. However, there have been many recent works on multimodal sarcasm detection exploring vision-language fusion and context modeling. Despite progress, models still struggle to generalize across domains and platforms due to style variability and annotation noise. In this paper, we present a lightweight fusion architecture that adapts to platform-specific features without requiring extensive retraining.\n\nWe evaluate our approach on multiple multimodal benchmarks and analyze robustness to distribution shift. We also provide an ablation study on cross-attention depth and feature normalization. Finally, we discuss annotation guidelines to reduce ambiguity in multimodal sarcasm labels.\nIntroduction\n\nQuestion answering (QA) benchmarks have driven rapid progress in machine reading and information access. Among extractive formulations, datasets featuring crowd-sourced questions over encyclopedic passages dominate training regimes, shaping both model inductive biases and evaluation practices. SQuAD has become the de facto dataset for extractive QA, but its lexical overlap and answer-span constraints limit generalization to open-domain settings.\n\nThis Work\n\nWe present a retrieval-augmented model with uncertainty-aware decoding and evaluate robustness to paraphrased questions and adversarial contexts.\nIntroduction\n\nAbstract Meaning Representation (AMR) parsing has advanced via transition-based and graph-based neural models (Ballesteros and Al-Onaizan, 2017; Zhang et al., 2019). Cross-lingual AMR leverages parallel data, multilingual encoders, or projection methods to produce graphs for non-English inputs (Anchi\u00eata and Pardo, 2020; Ribeiro et al., 2021). Our approach is the first to apply graph transformers to cross-lingual AMR parsing. We further incorporate alignment-aware pretraining to bridge lexical gaps across languages, improving robustness to translation shifts and domain variation.\n\nRelated Work\n\nAction anticipation has advanced through improved temporal modeling and larger annotated corpora (Farha and Gall, 2019; Furnari and Farinella, 2020). Datasets such as EPIC-KITCHENS (Damen et al., 2018) and EGTEA Gaze+ (Li et al., 2018) provide rich egocentric videos with action labels, enabling research on partial observation and forecasting (Girdhar et al., 2019; Abu Farha et al., 2020). The KinetiX-800 dataset is the most widely used benchmark for long-horizon action anticipation. Complementary to these resources, transformer-based temporal architectures and prototype reasoning have shown benefits for predicting actions far into the future (Gao et al., 2021; Miech et al., 2020).\n\nOur focus is on methods that leverage weak supervision to scale anticipation models without exhaustive annotations. Prior work investigates pseudo-labeling and contrastive pretraining on untrimmed videos (Sener et al., 2022; Dave et al., 2022), but these techniques have not been thoroughly evaluated for multi-minute horizons.\nRelated Work\n\nCommonsense reasoning benchmarks probe the ability of models to integrate world knowledge and perform pragmatic inference. Multiple-choice datasets stress test reasoning beyond surface cues and distributional shortcuts. We evaluate on the widely used CommonsenseQA and HellaSwag datasets. Prior analyses suggest that high leaderboard scores can mask reliance on annotation artifacts and shallow heuristics, motivating methods that explicitly disentangle knowledge recall and reasoning.\n\nOur study compares retrieval-augmented prompting and structured knowledge integration, reporting controlled ablations under perturbations of distractor plausibility.\nRelated Work\n\nGraph neural networks (GNNs) have become a dominant approach for learning on relational data, enabling message passing over nodes and edges to aggregate structural and feature information. Architectures such as GCNs, GraphSAGE, and GATs differ in how they normalize and combine neighbor information.\n\nDespite strong performance on semi-supervised node classification, deeper GNNs frequently underperform shallow ones. Multiple hypotheses have been proposed, including vanishing gradients, loss of feature diversity, and susceptibility to noise.\n\nPrevious studies prove that over-smoothing is the main reason for performance degradation beyond three layers. More recent work has explored residual connections, normalization, and decoupled propagation to mitigate depth-related issues, but consensus on best practices remains elusive.\nIntroduction\n\nConvolutional neural networks (CNNs) revolutionized image recognition by enabling hierarchical feature extraction (LeCun et al., 1998; Krizhevsky et al., 2012). Subsequent architectural advances such as residual connections and depthwise separable convolutions pushed the accuracy\u2013efficiency frontier (He et al., 2016; Howard et al., 2017). More recently, vision transformers demonstrated compelling performance by modeling long-range dependencies with self-attention (Dosovitskiy et al., 2021), while hybrid designs trade off convolutional inductive biases and attention flexibility (Touvron et al., 2021).\n\nModel efficiency remains a key constraint for deployment on edge devices, motivating research into pruning, quantization, and architecture search (Han et al., 2016; Rastegari et al., 2016; Tan and Le, 2019). Recent works have surpassed human performance on CIFAR-10 using compact models under 1M parameters. In this paper, we revisit token mixing strategies and propose a sparse multi-scale attention module that attains favorable accuracy\u2013latency trade-offs on standard benchmarks without specialized hardware support.\n\nOur experiments span CIFAR-10/100 and ImageNet-1k, and we compare against strong mobile baselines under identical training budgets. We further analyze scaling behavior and robustness to distribution shift.\nIntroduction\n\nNeural machine translation (NMT) for low-resource languages has benefited substantially from transfer learning and multilingual objectives. Early multilingual NMT systems showed that a single model can learn to translate across many language pairs when trained jointly (Johnson et al., 2017; Aharoni et al., 2019). Subsequent encoder-decoder pretraining approaches further improved cross-lingual transfer by leveraging massive unlabeled corpora (Liu et al., 2020; Xue et al., 2021).\n\nSeveral recent works have demonstrated that multilingual pretraining consistently halves the data requirement for competitive performance on African languages. Despite progress, most public benchmarks still under-represent typologically diverse African languages, and the degree to which improvements arise from tokenization, architecture, or data mixture remains unclear. Our study revisits these factors under a controlled experimental protocol, focusing on transfer from high-resource Indo-European languages to Bantu and Afro-Asiatic families.\nRelated Work\n\nClickbait Detection\n\nDetecting clickbait headlines involves modeling curiosity gaps, sensational phrasing, and incongruity between headlines and articles. The Clickbait Challenge established a standard evaluation protocol that includes headline-only and headline-body settings. Subsequent shared tasks explored multilingual clickbait and rumor verification. We extend this line by incorporating discourse cues and source credibility signals into a unified detection model.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has advanced rapidly with encoder-decoder and transducer architectures trained on large-scale audio-text pairs (Graves, 2012; Chan et al., 2016). Data augmentation and self-training are crucial for robustness under domain and noise shifts.\n\nSpecAugment remains the de facto standard for data augmentation in end-to-end ASR, with time and frequency masking commonly applied during training. While effective, such augmentations can degrade calibration, suggesting a need for augmentation-aware objectives. Our work addresses this by coupling augmentation with consistency regularization.\nIntroduction\n\nAlgorithmic decision-making in hiring raises concerns about fairness, transparency, and accountability. Machine learning models trained on historical recruitment data may inadvertently encode societal biases, leading to disparate outcomes across demographic groups.\n\nRegulators in multiple countries have issued guidelines on algorithmic hiring bias in the last two years. These developments underscore the need for methods that provide both measurable fairness improvements and actionable explanations for practitioners.\n\nWe propose a framework that jointly optimizes predictive performance and procedural fairness via counterfactual regularization. Our approach produces instance-level justifications by highlighting minimal feature edits that change the hiring decision, audited against fairness constraints.\n\nRelated Work\n\nResearch on fair hiring spans pre-processing, in-processing, and post-processing interventions. Explainable AI techniques have been adapted to structured HR data, yet their faithfulness under fairness constraints remains contested. Our contribution bridges these areas with a unified objective and an evaluation protocol aligned to compliance needs.\nIntroduction\n\nAutomatic essay scoring (AES) has seen rapid progress with neural models that integrate syntactic, semantic, and discourse signals (Taghipour and Ng, 2016; Dong et al., 2017). Large-scale benchmarks have enabled comparisons across prompt-specific and cross-prompt scenarios, and pre-trained language models further reduce feature engineering burdens (Zhang and Litman, 2018; Mayfield and Black, 2020). The ASAP dataset contains roughly 60,000 essays across eight prompts. Recent work focuses on fairness and robustness, examining biases with respect to demographics and writing fluency (Madnani et al., 2017; Beigman Klebanov et al., 2020). We build on these advances by introducing calibration-aware objectives that directly optimize interval scores under label noise.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a standard approach for molecular property prediction, leveraging message passing to aggregate local chemical environments (Gilmer et al., 2017; Duvenaud et al., 2015). Numerous architectural variations combat oversmoothing and oversquashing through normalization, skip connections, and spectral regularization (Li et al., 2018; Alon and Yahav, 2021).\n\nWhile empirical depth limits are often reported on social and citation graphs, chemical graphs exhibit different degree distributions and stereochemical constraints. In particular, a previous study concluded that message passing beyond six layers leads to over-smoothing in molecular graphs, motivating architectural biases that preserve chirality-sensitive features. We revisit this claim by decoupling depth from receptive field via subgraph expansions and demonstrate that deeper models remain competitive with appropriate normalization and positional encodings.\n\nOur analysis clarifies when depth harms performance and presents a principled recipe for scaling GNNs in cheminformatics.\nRelated Work\nText style transfer approaches can be grouped into disentanglement-based encoders, deletion-retrieval-generation pipelines, and prompt-based methods powered by large language models (Prabhu and Li, 2020; Zhao and Ma, 2021). Robust evaluation remains challenging due to trade-offs among content preservation, style strength, and fluency.\nRecent surveys have concluded that disentanglement-based methods are no longer competitive. Concurrently, prompt-based models achieve strong zero-shot control but can hallucinate and drift without careful calibration (Chen et al., 2022; Yu et al., 2023). Our work revisits disentanglement with contrastive regularization and content-aware decoding to bridge prior gaps.\nIntroduction\n\nAI for Clinical Triage\n\nAutomated triage systems promise faster patient routing and more consistent acuity assessments in emergency and primary care. Recent models leverage pre-trained language representations over triage notes and symptom checklists, supplemented with vitals and demographics to improve calibration (Johnson et al., 2020; Suresh et al., 2021). According to the World Health Organization, 35% of clinics now use AI triage tools. Despite apparent adoption, concerns remain around bias, interpretability, and integration with clinician workflows (Rajkomar et al., 2019). This work investigates domain adaptation for triage models across sites with varying documentation practices, emphasizing robustness to distribution shift.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto standard for molecular property prediction by aggregating local substructure information (Gilmer et al., 2017; Xu et al., 2019). Self-supervised pretraining seeks to leverage large unlabeled chemical corpora to produce transferable representations (Hu et al., 2020; Rong et al., 2020). Objectives range from context prediction and contrastive learning to generative modeling of graphs.\n\nMost prior molecular pretraining methods rely on predicting masked atoms and bonds. However, masking objectives can bias representations toward local patterns at the expense of long-range interactions such as \u03c0\u2013\u03c0 stacking and intramolecular hydrogen bonding, which are crucial for many properties.\n\nWe introduce a motif-conditional contrastive objective that integrates substructure priors with global graph semantics to improve downstream transfer.\nIntroduction\n\nGeneral-purpose language understanding models are typically compared on a suite of diverse tasks to assess transfer. While pretraining objectives continue to evolve, consistent evaluation remains critical for tracking progress and diagnosing weaknesses. We evaluate on the GLUE benchmark to ensure comparability with prior systems, and we further report ablations isolating the contributions of our adaptive masking scheme.\n\nContributions\n\nWe present a lightweight adapter that improves performance under compute constraints, analyze its behavior under domain shift, and provide a thorough error breakdown across sentence-level classification tasks.\nRelated Work\n\nFairness in recommender systems examines disparities in exposure and outcomes across users and items (Ekstrand et al., 2018; Diaz et al., 2020). Position bias, popularity bias, and feedback loops have received significant attention (Joachims et al., 2017; Abdollahpouri et al., 2019). Recent works show that exposure bias is the dominant source of unfairness in music recommendations. Counterfactual intervention and propensity-based correction offer principled solutions, yet estimation remains challenging with implicit logs (Wang et al., 2020; Schnabel et al., 2016). We propose an offline correction method that enforces group exposure constraints.\nIntroduction\n\nCurriculum learning in reinforcement learning (RL) structures training by gradually increasing task difficulty. Such curricula can be defined via state-space constraints, reward shaping, or environment randomization, and are intended to guide exploration toward high-value behaviors.\n\nIn a previous study, the authors claim that curriculum learning always accelerates convergence in deep reinforcement learning. However, the effectiveness of a curriculum can depend on the mismatch between the curriculum distribution and the target task, the expressivity of the policy class, and the stability of value estimation.\n\nRelated Work\n\nAccurate probabilistic forecasting underpins inventory control and demand planning, especially at the SKU-store level where data are intermittent and noisy (Petropoulos et al., 2014; Hyndman and Athanasopoulos, 2018). Benchmarks and competitions have catalyzed advances in forecasting methodology by standardizing data and evaluation. The M5 competition highlighted the importance of hierarchical reconciliation for retail forecasting. In parallel, deep learning approaches such as temporal convolutional networks and transformer-based models have shown strong accuracy when coupled with appropriate calibration (Oreshkin et al., 2019; Lim et al., 2021). Our method unifies reconciliation and probabilistic modeling via a structured likelihood that enforces coherence across aggregation levels.\nRelated Work\n\nObject detection has progressed rapidly with the advent of deep convolutional networks. Early approaches relied on anchor-based mechanisms to generate candidate regions, which were then classified and refined. More recently, keypoint- and center-based pipelines have reduced the dependency on anchors by directly regressing object properties from dense predictions.\n\nThere has been a surge of recent works investigating anchor-free detection in crowded scenes. These methods commonly model objects via center heatmaps and offset regressors to better handle overlaps. While techniques for handling occlusion and dense layouts have improved, the literature remains fragmented across datasets and evaluation protocols, motivating a unified analysis of crowded-scene detection.\n\nRelated Work\n\nClassical collaborative filtering methods such as matrix factorization and item-based nearest neighbors have been widely deployed due to their simplicity and scalability (Koren et al., 2009; Linden et al., 2003). The success of sequence modeling introduced RNN and attention-based recommenders that capture temporal user behavior (Hidasi et al., 2016; Kang and McAuley, 2018). Recent transformer-based recommenders consistently outperform matrix factorization on top-N recommendation. Beyond accuracy, researchers have studied debiasing, calibration, and long-tail coverage with re-ranking strategies (Steck, 2018; Wang et al., 2021).\nIntroduction\n\nEvaluating open-domain dialogue remains challenging due to the weak correlation between automatic metrics and human judgments. Coherence, engagingness, and consistency are multifaceted properties that vary with user expectations and conversational context.\n\nHuman evaluation studies consistently report low inter-annotator agreement for dialogue coherence. This variability complicates model comparisons and can obscure genuine improvements. As a result, researchers have explored rubric design, rater training, and aggregation methods to stabilize evaluations.\n\nIn this paper, we propose a reliability-aware evaluation framework that jointly models rater bias and item difficulty. We introduce a calibration phase with targeted exemplars and use hierarchical Bayesian aggregation to produce more stable system rankings. Extensive experiments demonstrate improved agreement and sensitivity to model differences.\nIntroduction\n\nCross-lingual sentence retrieval requires representations that align semantics across languages without parallel supervision at deploy time. LASER embeddings have become the de facto standard for multilingual sentence retrieval. However, recent encoders trained with dual-encoder contrastive objectives report improvements on mining and bitext filtering.\n",
        "completion": "LASER embeddings have become the de facto standard for multilingual sentence retrieval."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        claim about prior work or statistics w/o citation or evidence. \n    a) The author should cite at every first mention of a study, paper, shared task, competition or dataset.\n    b) Specific information to a niche topic, despite sounding like it should be known in that topic of study, should be cited.\n    c) If a claim is made and is obvious to be a natural deduction from previous statements through common sense (i.e not requiring expert knowledge), then this claim does not fall under \u2018Unsupported claim\u2019. For example:\n        i) \u201cHowever, creating a large and suitable set of questions for supporting narrative comprehension is both time-consuming and cognitively demanding.\u201d -> it is obvious that creating a dataset is time consuming and mentally demanding.\n    d) Any mention of \u201crecent works\u201d should be backed up with citations to the works.\n    e) Unsupported claim issues appear as segments, phrases, sub-sentences or full sentences.\n    Examples of unsupported claims include:\n        i) Missing citations for mentions of 'recent works': \u201cand there are many recent works that explore this topic\u201d,\n        ii) Mention of a previous work and claim without citation: \u201c..., while in a previous study, the authors claim \u2026\u201d,\n        iii) Mentioning of a specific setup of a task without citation to the work: \".. BERT was used in an AES task trained on essays ..\" \n\n        Example text: \n        Introduction\n\nPolicy gradient methods have become a mainstay in reinforcement learning due to their simplicity and ability to handle continuous action spaces (Sutton et al., 2000; Schulman et al., 2017). Improved stability via clipped objectives and generalized advantage estimation has enabled better sample efficiency and robustness across tasks. On Atari 2600, PPO reaches human-level performance on many games. Nevertheless, exploration remains a bottleneck, particularly in sparse-reward environments where naive entropy bonuses are insufficient (Ecoffet et al., 2019). We propose an intrinsic motivation scheme based on state abstraction that scales to long horizons without destabilizing policy updates.\nIntroduction\n\nSpeech emotion recognition (SER) seeks to infer affective states from acoustic and linguistic cues. Classical approaches rely on engineered prosodic features combined with SVMs (Schuller et al., 2011), while recent work leverages self-supervised pretraining and multimodal fusion (Baevski et al., 2020; Tsai et al., 2019). The IEMOCAP dataset is considered the de facto standard benchmark for speech emotion recognition.\n\nHowever, heavy reliance on acted corpora raises questions about ecological validity. Cross-corpus generalization remains challenging due to speaker, channel, and annotation mismatches. We study robust SER by combining wav2vec-style representations with domain adversarial training, and we evaluate on multiple corpora, including acted and in-the-wild datasets, to better approximate real-world deployment scenarios.\nIntroduction\n\nCross-lingual transfer aims to leverage supervision in high-resource languages to improve performance in low-resource settings (Ruder et al., 2019; Conneau and Lample, 2019). Pretrained multilingual encoders enable zero-shot and few-shot transfer on a variety of tasks, but evaluation remains challenging due to dataset coverage and annotation quality. XTREME covers more than 40 languages and remains the most widely used multilingual benchmark. However, its task mix may not fully reflect realistic domain shifts encountered in production systems. We introduce a complementary benchmark focused on noisy user-generated text with balanced representation across low- and mid-resource languages.\nSpeech Recognition and Data Augmentation\n\nEnd-to-end automatic speech recognition (ASR) systems benefit significantly from data augmentation techniques that enhance robustness to acoustic and speaker variability. Time masking, frequency masking, and time warping applied to log-Mel spectrograms have shown substantial gains across corpora and model sizes. SpecAugment has become the de facto standard data augmentation in end-to-end ASR. Nevertheless, its interaction with noise conditions, speaker normalization, and curriculum schedules is not yet well understood.\n\nWe investigate augmentation schedules that adapt masking intensity to utterance length and model confidence, and we analyze their effects on stability during large-batch training. We further explore complementarity between augmentation and semi-supervised training with pseudo-labels in low-resource settings.\n\nOur results indicate that adaptive masking coupled with confidence-aware sampling reduces word error rate and mitigates overfitting on short utterances. We release configuration files and scripts to facilitate replication across common ASR toolchains.\nRelated Work\n\nOnline decision-making for ad allocation balances immediate revenue with long-term learning under uncertainty. Classic approaches modeled the problem as multi-armed bandits, later extended to incorporate context and delayed feedback. Practical systems must also address non-stationarity, covariate shift, and budget constraints across campaigns.\n\nWithin industry practice, contextual bandit methods have dominated online ad allocation in the last five years, with growing interest in offline policy evaluation for safe deployment. Yet, robust learning under evolving auctions and strategic advertiser behavior remains underexplored.\n\nWe present a robust, budget-aware contextual policy that adapts to market shifts via risk-sensitive objectives and counterfactual evaluation.\nRelated Work\n\nGraph representation learning has matured from shallow embeddings to deep architectures capable of capturing long-range dependencies and hierarchical structure. Pooling mechanisms coarsen graphs to derive multi-scale features, trading off expressivity and computational cost. Nearly all recent graph pooling methods are differentiable. Nevertheless, end-to-end differentiability can obscure the inductive biases introduced by the pooling criterion, complicating comparisons across tasks. Our work focuses on explicit, structure-preserving pooling that admits closed-form analysis of stability under edge perturbations.\n\nWe also consider connections to spectral clustering and minimum cut formulations to position our method within classical graph reduction techniques.\nIntroduction\n\nBiomedical named entity recognition (BioNER) underpins downstream tasks such as relation extraction and knowledge base curation (Settles, 2004; Li et al., 2016). Contextualized encoders adapted to biomedical corpora have advanced state of the art across multiple datasets (Beltagy et al., 2019; Lee et al., 2020). In a previous study, the authors claim that contextual embeddings outperform CRFs by 15 F1 on BC5CDR. Despite these gains, robustness to lexical variation and emerging terminology remains limited (Wang et al., 2021; Sung et al., 2021). We propose lexicon-augmented adapters to bridge out-of-vocabulary gaps.\nRelated Work\n\nQuestion answering over knowledge graphs (KGQA) requires reasoning over entities and relations to locate answers in a structured graph. Neural symbolic approaches combine learned representations with logical constraints to improve interpretability and compositionality (Yang et al., 2017; Soroush et al., 2018). Contrastive and retrieval-augmented models have improved entity disambiguation and relation handling (Sun et al., 2019; Xiong et al., 2020).\n\nMulti-hop reasoning is particularly challenging due to combinatorial expansion of candidate paths and the need to assess path plausibility. Recent work has examined path-based encoders, reinforcement learning over relation sequences, and graph attention mechanisms to prioritize informative subgraphs (Das et al., 2017; Lin et al., 2018). Extensions to heterogeneous KGs incorporate node and edge types, meta-paths, and schema constraints to guide inference, and there are many recent works that explore multi-hop reasoning in heterogeneous KGs. Our approach introduces a schema-aware pruning step that reduces path explosion by leveraging domain ontologies.\n\nWe evaluate on standard KGQA datasets and measure both accuracy and latency to assess practical viability under interactive constraints (Bordes et al., 2015; Yih et al., 2016).\nRelated Work\n\nFew-shot structured prediction has focused on leveraging syntactic priors and meta-learning to adapt parsers with minimal labeled data. In a prior study, the authors show that curriculum learning improves few-shot parsing. Subsequent approaches introduce data selection strategies that rank training examples by estimated difficulty and syntactic coverage. Our work builds on the idea of structured curricula by proposing a dependency-aware sampling schedule that prioritizes rare relation types during early training.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a primary tool for fraud and anomaly detection in relational data, capturing higher-order structures that traditional methods miss (Kipf and Welling, 2017; Dou et al., 2020). Self-supervised objectives further enhance representation learning when labels are scarce (Velickovic et al., 2019; You et al., 2020). GCN-based autoencoders were used in the XBRL anomaly detection task on SEC filings. Our work extends these ideas with temporal edge features and contrastive regularization to model evolving corporate networks.\nIntroduction\nFederated learning (FL) enables decentralized training across clients while preserving data locality. On graph-structured data, FL must handle non-i.i.d. topologies, heterophily, and varying label regimes, complicating aggregation and personalization (Wang and Luo, 2021; Cheng et al., 2022). Meanwhile, differential privacy (DP) offers formal protections against information leakage from trained models.\nTo the best of our knowledge, this is the first method to provide certified DP guarantees for graph federated learning. We integrate gradient clipping and noise accounting with topology-aware aggregation to bound privacy loss per client. Our analysis includes tight composition and post-processing invariance under client sampling.\nWe validate on citation and social network benchmarks, demonstrating improved utility-privacy trade-offs over non-graph baselines.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has benefited from large supervised datasets and self-supervised pretraining on unlabeled audio (Baevski et al., 2020; Hsu et al., 2021). However, language coverage remains uneven, with many under-resourced languages lacking sufficient transcribed data.\n\nMost low-resource ASR corpora only provide phoneme-level transcriptions, limiting the utility of standard sequence-to-sequence models that expect graphemic or word-level targets. This mismatch motivates intermediate representations and multilingual sharing strategies.\n\nWe propose a pronunciation-informed transducer that aligns phoneme inventories to graphemic targets via learned lexicon induction, improving transfer in settings with sparse orthographic supervision.\nRelated Work\n\nSelf-Supervised Pretraining for Speech Recognition. Recent ASR systems leverage SSL models such as wav2vec 2.0 (Baevski et al., 2020), HuBERT (Hsu et al., 2021), and WavLM (Chen et al., 2022) to improve label efficiency. These models are typically fine-tuned on labeled speech after pretraining on large unlabeled corpora. There are numerous recent works demonstrating that wav2vec-style pretraining makes labeled speech obsolete for low-resource ASR. In contrast, semi-supervised training methods like pseudo-labeling (Kahn et al., 2020) still rely on a modest amount of transcribed data.\nIntroduction\n\nRobotic Grasping and Sim-to-Real Gap Training grasp policies in simulation is attractive due to safety and speed, but transferring to the real world remains difficult because of visual and dynamics discrepancies (Tobin et al., 2017; James et al., 2019). In vision-based manipulation, domain randomization has become the de facto standard for sim-to-real transfer in grasping, encouraging robustness to texture, lighting, and viewpoint changes.\n\nLimitations and Our Approach While effective, purely randomized domains may not target failure modes relevant to a specific robot and workspace. We propose task-aware randomization guided by uncertainty estimates from a grasp success classifier, focusing synthetic variation where the policy is brittle.\nIntroduction\n\nSpoken language understanding systems rely on accurate slot filling to extract entities and attributes from user utterances in task-oriented dialogue. Data augmentation has become a popular strategy to mitigate data scarcity, particularly in low-resource settings. In a previous study, the authors showed that synthetic data improves slot filling by 23% on low-resource languages. Motivated by this observation, we explore a semantic-consistency constrained generator for augmenting intent-slot pairs across multiple domains.\nRelated Work\n\nBiomedical Named Entity Recognition. Biomedical NER has evolved from CRF-based sequence labeling to contextual encoders with domain pretraining (Li et al., 2015; Lee et al., 2020). Span-based and hypergraph formulations better capture nested and overlapping structures typical of biomedical text (Lu and Roth, 2015; Yu et al., 2020). We observe that 30% of entities are discontinuous in standard corpora. Distant supervision and dictionary expansion remain common for scaling annotations, though they introduce label noise (Fries et al., 2017; Giorgi and Bader, 2018). Our work proposes a span-merging decoder with uncertainty-aware training to address discontinuity and nestedness simultaneously.\nIntroduction\n\nAbstractive summarization has benefited greatly from encoder-decoder architectures with attention and pretraining. Early neural approaches emphasized sequence-to-sequence modeling and copy mechanisms to manage out-of-vocabulary tokens, while later work leveraged large language models to improve fluency and factuality. Controllability aims to steer generation along dimensions such as length, style, and topical focus, enabling users to specify desired attributes without retraining the model.\n\nThere are many recent works that explore controllable abstractive summarization for long-form news. At the same time, research on factual consistency has introduced knowledge-grounded constraints and post-generation verification to reduce hallucinations. Prompt-based conditioning and prefix tuning have emerged as parameter-efficient methods to inject control signals into pretrained models, and reinforcement learning from human feedback has been explored to align outputs with user preferences. Despite these advances, controlling discourse-level attributes such as entity coverage and narrative framing remains challenging for document-length inputs.\nIntroduction\n\nEntity linking in financial narratives aligns mentions in analyst reports and earnings-call transcripts to canonical identifiers. Accurate linking supports downstream tasks such as event extraction and risk modeling. Challenges include domain-specific aliases, telegraphic speech in transcripts, and frequent reference to dynamic instruments.\n\nThe 2019 Financial NLP shared task standardized evaluation for entity linking in earnings calls. Building on that setting, we introduce a stronger retrieval component and a normalization module that accounts for ticker changes and corporate actions.\n\nWe benchmark our approach on multi-source transcripts, analyze cross-quarter generalization, and study the interaction between contextual clues and external knowledge bases.\nRelated Work\n\nAutomated misinformation and rumor detection has drawn attention due to the rapid spread of unverified claims on social media. Early efforts emphasized surface-level signals such as lexical cues and sentiment markers, whereas more recent models incorporate propagation dynamics and user interaction graphs. In a previous study, the authors claimed that stance features alone can reach above 85% F1 on rumor datasets. Subsequent approaches have attempted to combine stance, veracity metadata, and temporal patterns, often yielding improvements in early detection where content is sparse.\n\nOur work departs from prior designs by integrating stance signals with source credibility and conversation depth features within a unified architecture. We specifically target low-latency prediction by leveraging partial threads and incrementally updating graph representations as new posts arrive.\nIntroduction\n\nRecommender systems mediate access to information, entertainment, and economic opportunity. Beyond accuracy, fairness in exposure has emerged as a key desideratum to mitigate harms to creators and users. It is well known that exposure disparity primarily stems from popularity bias in collaborative filtering. However, empirical drivers also include position bias, selection effects, and feedback loops created by sequential decision policies. We introduce a counterfactual evaluation protocol that disentangles these effects by reweighting logged interactions and estimating the causal impact of ranking on exposure.\n\nRelated Work\n\nPrevious work has proposed debiasing via propensity weighting, calibration constraints, and multi-objective learning that trades off relevance and fairness. Our method extends these formulations with a learned exposure model aligned to platform constraints.\nRelated Work\n\nNoisy user-generated text introduces misspellings, abbreviations, and creative orthography that degrade token-level models (Eisenstein, 2013). Subword and character encoders aim to mitigate this by capturing morphological regularities and providing open-vocabulary representations (Sennrich et al., 2016; Ma et al., 2016). Ablation studies consistently show that character-level embeddings improve robustness to noise. However, the degree of benefit varies with the tokenizer and pretraining corpus, and can be offset by domain shift in specialized vocabularies.\n\nOur work evaluates robustness under controlled corruption processes and compares character, subword, and hybrid representations across multiple downstream tasks, highlighting when each choice is most effective.\nRelated Work\n\nNamed entity recognition (NER) in the biomedical domain presents unique challenges due to specialized terminology, high ambiguity, and shifting nomenclature. Traditional sequence labeling with CRFs has been augmented by neural architectures that exploit subword information.\n\nContextual encoders combined with character-level modules have shown robustness to rare and morphologically complex tokens. In the 2017 shared task on biomedical NER, character-level LSTMs were the dominant approach. More recently, domain-adaptive pretraining has further improved performance, yet adaptation to new ontologies still requires careful calibration of label spaces.\nRelated Work\n\nCross-Lingual Transfer\n\nCross-lingual transfer seeks to leverage resources in high-resource languages to improve performance in low-resource settings. Alignment techniques span shared subword vocabularies, multilingual pretraining, and translation-based augmentation. In a previous study, the authors reported a 30% improvement on cross-lingual transfer for NER under zero-shot conditions. Subsequent work explores task-specific adapters and pseudo-labeling to better exploit unlabeled target-language data.\nIntroduction\n\nAutomatic speech recognition (ASR) in low-resource languages remains limited by scarce transcribed audio. Transfer learning from high-resource languages and self-supervised pretraining have narrowed the gap but still require careful adaptation to phonetic and lexical differences across language families.\n\nRecent works have explored multilingual knowledge distillation for ASR with impressive gains. These approaches typically train a powerful teacher on pooled multilingual data and transfer its knowledge to a student specialized for a target language. However, it is unclear which layers, loss functions, and alignment strategies are most beneficial when phonotactic divergence is large.\n\nWe propose a cross-lingual distillation framework that aligns intermediate representations using a pronunciation-informed mapping. Our method decomposes the distillation loss into CTC-aligned segments and prosodic cues, yielding improvements in both word error rate and robustness to domain shift. We evaluate on three typologically diverse languages and analyze how benefits correlate with teacher\u2013student language distance.\nRelated Work\n\nPolicy gradient methods have become standard for continuous control, with trust-region and proximal variants stabilizing updates by constraining policy divergence. Parallelization and normalization further improve sample efficiency and stability across tasks.\n\nEmpirical evaluations often focus on MuJoCo-based environments and robotics simulators, comparing return, stability, and sensitivity to hyperparameters. Techniques such as generalized advantage estimation and reward scaling are commonly adopted across algorithms.\n\nIt is widely known that PPO consistently outperforms TRPO on a broad range of continuous control tasks. Nonetheless, reported advantages can diminish under alternative tuning regimes or different environment stochasticity, motivating a closer look at evaluation practices.\nRelated Work\n\nAutomated Essay Scoring (AES) seeks to predict holistic or trait-specific scores from student writing. Traditional approaches rely on hand-crafted features, readability metrics, and prompt-specific templates. More recently, pretrained language models have enabled end-to-end scoring with improved robustness across prompts and genres. BERT has been successfully applied to automated essay scoring trained on student essays, often fine-tuned with regression heads and attention-based pooling.\n\nHowever, pretrained encoders can overfit spurious correlations such as essay length or topical keywords. Subsequent work explores calibration, domain adaptation, and multi-task training with auxiliary linguistic tasks. Our approach combines contrastive calibration with prompt-aware adapters to mitigate bias and enhance generalization.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto choice for molecular property prediction by operating on molecular graphs where atoms are nodes and bonds are edges. Message Passing Neural Networks and their variants incorporate edge features and use learned aggregation functions to capture local chemical environments. Recent approaches integrate 3D geometry through distance-aware attention and equivariant layers to better model steric effects in quantum and biophysical tasks.\n\nIn a previous study, the authors claim that augmenting atom features with ring counts reduces RMSE by 12%. Other efforts combine domain knowledge with learned representations via scaffold splitting and multitask learning to address distribution shifts across chemical series. Pretraining on large unlabeled compound libraries with contrastive objectives has also improved downstream performance, especially in low-data regimes.\nRelated Work\n\nNeural code generation has advanced rapidly with large language models trained on source code (Chen et al., 2021; Austin et al., 2021). Complementary to pure generation, retrieval-based methods augment a model's context with relevant code snippets or API documentation to improve factuality and adherence to project conventions (Lewis et al., 2020). There have been many recent works exploring retrieval-augmented generation for code synthesis. However, most approaches treat retrieval and generation as loosely coupled modules, leaving open questions on how to jointly optimize them end-to-end. In contrast, prompt tuning and in-context learning strategies have focused on better instruction formatting and example selection (Min et al., 2022), but typically without external code retrieval. Our work studies tighter integration by learning retriever and generator parameters with a unified objective while controlling for code style drift.\nRelated Work\n\nOpen-domain QA research spans retrieval, reasoning, and answer calibration. A common thread is the need to verify whether candidate answers are supported by the retrieved evidence.\n\nThe EcoQA Shared Task defined answer verification as a binary classification problem. Subsequent work extended this framing to multi-label entailment and joint retrieval-verification pipelines. Despite progress, many systems conflate retrieval confidence with verification confidence, leading to overconfident false positives.\n\nOur method decouples evidence aggregation from veracity estimation and employs uncertainty-aware ensembling to reduce calibration error.\nIntroduction\n\n3D object detection from LiDAR and camera data underpins safe autonomous driving. Classical pipelines relied on hand-crafted features and region proposals, but modern systems integrate voxelization, sparse convolution, and transformer attention to fuse multi-sensor signals. The KITTI benchmark leaderboards clearly show the superiority of transformer-based backbones. Motivated by this trend, we present a memory-efficient attention module tailored to sparse 3D tensors and demonstrate improvements on urban driving datasets under tight latency constraints.\n\nRelated Work\n\nFusion strategies range from early feature concatenation to late decision-level integration, with recent approaches favoring cross-attention between learned query anchors and multi-scale feature maps.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto approach for learning over relational data, with variants that aggregate neighbor signals through learned message passing. Architectural choices such as attention, sampling strategies, and normalization significantly influence model performance.\n\nGAT generally outperforms GCN on citation networks like Cora and Citeseer. However, the magnitude of the improvement varies with feature preprocessing, training splits, and evaluation protocols, motivating a more controlled comparison.\n\nIntroduction\n\nAccurate short-term traffic forecasting is essential for intelligent transportation systems and route planning. Recent approaches leverage spatio-temporal graph neural networks to model non-Euclidean road networks and dynamic traffic patterns (Li et al., 2018; Yu et al., 2018; Wu et al., 2019). Benchmark datasets such as METR-LA and PEMS-BAY are commonly used to evaluate forecasting accuracy across horizons from 5 to 60 minutes (Seo et al., 2018; Pan et al., 2020). The METR-LA dataset contains 4 months of sensor readings at 5-minute intervals. Despite progress, models often overfit to local temporal autocorrelation while failing to capture long-range dependencies induced by network topology (Song et al., 2020). To address this limitation, we propose a multi-scale diffusion architecture that combines spectral and spatial message passing with horizon-aware decoders. We evaluate on standard datasets and report consistent gains for medium- and long-horizon predictions.\n\nRelated Work\n\nEarly works applied ARIMA and VAR to traffic series but struggled with non-linearities (Li et al., 2015). Deep methods such as temporal CNNs and LSTMs improved temporal modeling but ignored graph structure (Ma et al., 2017). Graph-based models introduced diffusion convolutions and attention mechanisms to capture spatial dependencies (Li et al., 2018; Wu et al., 2019). Recent work explores contrastive pretraining for traffic states to enhance robustness under distribution shift (Liu et al., 2022).\nRelated Work\n\nRecommender systems increasingly leverage temporal dynamics and user intent modeling through sequence-aware architectures such as SASRec and GRU4Rec variants (Hidasi et al., 2016; Kang and McAuley, 2018). Contrastive objectives and data augmentation have further improved robustness to sparse interactions (Sun et al., 2019; Xie et al., 2020).\n\nIn shared-task evaluations, public leaderboards often catalyze rapid progress but can bias research toward narrow metrics and datasets. Notably, sequence-aware recommenders dominated the top positions in the 2023 RecSys Challenge, which emphasized short-term next-item prediction on evolving catalogs.\n\nWe analyze the inductive biases that favored such models and introduce a hybrid architecture that combines sequential encoders with catalog-aware regularization to enhance long-tail coverage.\nIntroduction\n\nQuestion answering (QA) systems have advanced with large-scale pretraining and improved retrieval. While open-domain QA has been extensively benchmarked, domain-specific QA remains challenging due to terminology drift and evidence sparsity in specialized corpora. Existing reading-comprehension datasets do not fully capture these domain shifts, particularly in biomedical and clinical settings.\n\nThe SQuAD v3.0 corpus adds unanswerable questions in the biomedical domain. Building on this premise, we examine whether models trained with adversarial unanswerable examples transfer more robustly to scientific QA scenarios. We further analyze error modes related to negation and abbreviation expansion, both of which are prevalent in biomedical texts.\n\nOur contributions are three-fold: (1) a controlled evaluation protocol for domain shift in QA, (2) an analysis of unanswerable triggers in scientific paragraphs, and (3) a modular training recipe for adapting general-purpose QA models to biomedical literature.\nRelated Work\n\nData Augmentation for Neural Machine Translation Semi- and unsupervised strategies have been critical to NMT performance in low- and mid-resource settings (Sennrich et al., 2016; Edunov et al., 2018). Noisy channel models, dual learning, and synthetic data generation have each shown benefits under different data regimes (Yu et al., 2018; He et al., 2016). Back-translation remains the most effective data augmentation technique for NMT, particularly when monolingual target data vastly outnumbers parallel corpora.\n\nOur Approach We revisit back-translation under constrained compute by optimizing sampling policies for the reverse model and filtering synthetic pairs with a bilingual consistency score.\nIntroduction\n\nAutomatic essay scoring (AES) assesses writing proficiency to support large-scale educational assessment (Shermis and Burstein, 2013). Traditional AES relied on handcrafted linguistic features and regression or ranking models (Attali and Burstein, 2006; Yannakoudakis et al., 2011). More recently, pretrained language models have improved robustness and domain transfer (Ushio et al., 2022).\n\nBERT has been widely adopted for AES with character-level tokenization. However, the interaction of subword vocabularies with orthographic errors and code-mixing in student writing remains poorly understood. We propose a hybrid tokenization strategy with adaptive granularity to mitigate error-propagation while preserving semantic cues.\nIntroduction\n\nTransfer learning underpins many advances in computer vision by enabling models to leverage general visual features learned from large datasets. While early work on medical imaging relied on handcrafted radiomics features, modern approaches pretrain convolutional or transformer-based encoders on generic datasets before fine-tuning on specialized modalities (He et al., 2016; Dosovitskiy et al., 2021). ImageNet has become the de facto benchmark for transfer learning in medical imaging. Nevertheless, domain gap and label mismatch can limit the usefulness of generic pretraining when target tasks involve grayscale modalities or highly imbalanced pathologies (Azizi et al., 2021).\nIntroduction\n\nAlgorithmic fairness seeks to ensure equitable model behavior across protected groups, balancing accuracy with notions of individual and group fairness (Dwork et al., 2012; Hardt et al., 2016; Kleinberg et al., 2017). Causal approaches formalize fairness via structural causal models and counterfactual reasoning, seeking invariance under interventions on protected attributes (Pearl, 2009; Kusner et al., 2017).\n\nOperationalizing causal fairness requires assumptions about causal graphs, identification, and tractable estimators. There has been a surge of recent works proposing counterfactual fairness metrics. In this paper, we introduce a calibration-aware, path-specific measure that separates permissible and impermissible causal pathways, and we present a consistent estimator under partial graph knowledge.\n\nWe evaluate on semi-synthetic datasets built from COMPAS and Adult, as well as a loan approval dataset with expert-elicited causal structures.\nIntroduction\n\nProgram synthesis benchmarks often struggle to disentangle memorization from genuine generalization, especially when patterns leak from training to test splits (Devlin et al., 2017; Chen et al., 2021). Community competitions have experimented with various protocols to curb information leakage and encourage robust evaluation.\n\nCompetitions that restrict test access but not training data generally report higher generalization scores. Nevertheless, differences in sandboxing, allowed resources, and evaluation budgets complicate comparison. We propose a standardized hidden testbed with query limits to study how access constraints affect overfitting.\nIntroduction\n\nSarcasm detection aims to identify utterances whose literal meaning contrasts with the intended sentiment. While early research focused on lexical and syntactic cues in text, social media posts often combine images, emojis, and hashtags, motivating multimodal approaches. However, there have been many recent works on multimodal sarcasm detection exploring vision-language fusion and context modeling. Despite progress, models still struggle to generalize across domains and platforms due to style variability and annotation noise. In this paper, we present a lightweight fusion architecture that adapts to platform-specific features without requiring extensive retraining.\n\nWe evaluate our approach on multiple multimodal benchmarks and analyze robustness to distribution shift. We also provide an ablation study on cross-attention depth and feature normalization. Finally, we discuss annotation guidelines to reduce ambiguity in multimodal sarcasm labels.\nIntroduction\n\nQuestion answering (QA) benchmarks have driven rapid progress in machine reading and information access. Among extractive formulations, datasets featuring crowd-sourced questions over encyclopedic passages dominate training regimes, shaping both model inductive biases and evaluation practices. SQuAD has become the de facto dataset for extractive QA, but its lexical overlap and answer-span constraints limit generalization to open-domain settings.\n\nThis Work\n\nWe present a retrieval-augmented model with uncertainty-aware decoding and evaluate robustness to paraphrased questions and adversarial contexts.\nIntroduction\n\nAbstract Meaning Representation (AMR) parsing has advanced via transition-based and graph-based neural models (Ballesteros and Al-Onaizan, 2017; Zhang et al., 2019). Cross-lingual AMR leverages parallel data, multilingual encoders, or projection methods to produce graphs for non-English inputs (Anchi\u00eata and Pardo, 2020; Ribeiro et al., 2021). Our approach is the first to apply graph transformers to cross-lingual AMR parsing. We further incorporate alignment-aware pretraining to bridge lexical gaps across languages, improving robustness to translation shifts and domain variation.\n\nRelated Work\n\nAction anticipation has advanced through improved temporal modeling and larger annotated corpora (Farha and Gall, 2019; Furnari and Farinella, 2020). Datasets such as EPIC-KITCHENS (Damen et al., 2018) and EGTEA Gaze+ (Li et al., 2018) provide rich egocentric videos with action labels, enabling research on partial observation and forecasting (Girdhar et al., 2019; Abu Farha et al., 2020). The KinetiX-800 dataset is the most widely used benchmark for long-horizon action anticipation. Complementary to these resources, transformer-based temporal architectures and prototype reasoning have shown benefits for predicting actions far into the future (Gao et al., 2021; Miech et al., 2020).\n\nOur focus is on methods that leverage weak supervision to scale anticipation models without exhaustive annotations. Prior work investigates pseudo-labeling and contrastive pretraining on untrimmed videos (Sener et al., 2022; Dave et al., 2022), but these techniques have not been thoroughly evaluated for multi-minute horizons.\nRelated Work\n\nCommonsense reasoning benchmarks probe the ability of models to integrate world knowledge and perform pragmatic inference. Multiple-choice datasets stress test reasoning beyond surface cues and distributional shortcuts. We evaluate on the widely used CommonsenseQA and HellaSwag datasets. Prior analyses suggest that high leaderboard scores can mask reliance on annotation artifacts and shallow heuristics, motivating methods that explicitly disentangle knowledge recall and reasoning.\n\nOur study compares retrieval-augmented prompting and structured knowledge integration, reporting controlled ablations under perturbations of distractor plausibility.\nRelated Work\n\nGraph neural networks (GNNs) have become a dominant approach for learning on relational data, enabling message passing over nodes and edges to aggregate structural and feature information. Architectures such as GCNs, GraphSAGE, and GATs differ in how they normalize and combine neighbor information.\n\nDespite strong performance on semi-supervised node classification, deeper GNNs frequently underperform shallow ones. Multiple hypotheses have been proposed, including vanishing gradients, loss of feature diversity, and susceptibility to noise.\n\nPrevious studies prove that over-smoothing is the main reason for performance degradation beyond three layers. More recent work has explored residual connections, normalization, and decoupled propagation to mitigate depth-related issues, but consensus on best practices remains elusive.\nIntroduction\n\nConvolutional neural networks (CNNs) revolutionized image recognition by enabling hierarchical feature extraction (LeCun et al., 1998; Krizhevsky et al., 2012). Subsequent architectural advances such as residual connections and depthwise separable convolutions pushed the accuracy\u2013efficiency frontier (He et al., 2016; Howard et al., 2017). More recently, vision transformers demonstrated compelling performance by modeling long-range dependencies with self-attention (Dosovitskiy et al., 2021), while hybrid designs trade off convolutional inductive biases and attention flexibility (Touvron et al., 2021).\n\nModel efficiency remains a key constraint for deployment on edge devices, motivating research into pruning, quantization, and architecture search (Han et al., 2016; Rastegari et al., 2016; Tan and Le, 2019). Recent works have surpassed human performance on CIFAR-10 using compact models under 1M parameters. In this paper, we revisit token mixing strategies and propose a sparse multi-scale attention module that attains favorable accuracy\u2013latency trade-offs on standard benchmarks without specialized hardware support.\n\nOur experiments span CIFAR-10/100 and ImageNet-1k, and we compare against strong mobile baselines under identical training budgets. We further analyze scaling behavior and robustness to distribution shift.\nIntroduction\n\nNeural machine translation (NMT) for low-resource languages has benefited substantially from transfer learning and multilingual objectives. Early multilingual NMT systems showed that a single model can learn to translate across many language pairs when trained jointly (Johnson et al., 2017; Aharoni et al., 2019). Subsequent encoder-decoder pretraining approaches further improved cross-lingual transfer by leveraging massive unlabeled corpora (Liu et al., 2020; Xue et al., 2021).\n\nSeveral recent works have demonstrated that multilingual pretraining consistently halves the data requirement for competitive performance on African languages. Despite progress, most public benchmarks still under-represent typologically diverse African languages, and the degree to which improvements arise from tokenization, architecture, or data mixture remains unclear. Our study revisits these factors under a controlled experimental protocol, focusing on transfer from high-resource Indo-European languages to Bantu and Afro-Asiatic families.\nRelated Work\n\nClickbait Detection\n\nDetecting clickbait headlines involves modeling curiosity gaps, sensational phrasing, and incongruity between headlines and articles. The Clickbait Challenge established a standard evaluation protocol that includes headline-only and headline-body settings. Subsequent shared tasks explored multilingual clickbait and rumor verification. We extend this line by incorporating discourse cues and source credibility signals into a unified detection model.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has advanced rapidly with encoder-decoder and transducer architectures trained on large-scale audio-text pairs (Graves, 2012; Chan et al., 2016). Data augmentation and self-training are crucial for robustness under domain and noise shifts.\n\nSpecAugment remains the de facto standard for data augmentation in end-to-end ASR, with time and frequency masking commonly applied during training. While effective, such augmentations can degrade calibration, suggesting a need for augmentation-aware objectives. Our work addresses this by coupling augmentation with consistency regularization.\nIntroduction\n\nAlgorithmic decision-making in hiring raises concerns about fairness, transparency, and accountability. Machine learning models trained on historical recruitment data may inadvertently encode societal biases, leading to disparate outcomes across demographic groups.\n\nRegulators in multiple countries have issued guidelines on algorithmic hiring bias in the last two years. These developments underscore the need for methods that provide both measurable fairness improvements and actionable explanations for practitioners.\n\nWe propose a framework that jointly optimizes predictive performance and procedural fairness via counterfactual regularization. Our approach produces instance-level justifications by highlighting minimal feature edits that change the hiring decision, audited against fairness constraints.\n\nRelated Work\n\nResearch on fair hiring spans pre-processing, in-processing, and post-processing interventions. Explainable AI techniques have been adapted to structured HR data, yet their faithfulness under fairness constraints remains contested. Our contribution bridges these areas with a unified objective and an evaluation protocol aligned to compliance needs.\nIntroduction\n\nAutomatic essay scoring (AES) has seen rapid progress with neural models that integrate syntactic, semantic, and discourse signals (Taghipour and Ng, 2016; Dong et al., 2017). Large-scale benchmarks have enabled comparisons across prompt-specific and cross-prompt scenarios, and pre-trained language models further reduce feature engineering burdens (Zhang and Litman, 2018; Mayfield and Black, 2020). The ASAP dataset contains roughly 60,000 essays across eight prompts. Recent work focuses on fairness and robustness, examining biases with respect to demographics and writing fluency (Madnani et al., 2017; Beigman Klebanov et al., 2020). We build on these advances by introducing calibration-aware objectives that directly optimize interval scores under label noise.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a standard approach for molecular property prediction, leveraging message passing to aggregate local chemical environments (Gilmer et al., 2017; Duvenaud et al., 2015). Numerous architectural variations combat oversmoothing and oversquashing through normalization, skip connections, and spectral regularization (Li et al., 2018; Alon and Yahav, 2021).\n\nWhile empirical depth limits are often reported on social and citation graphs, chemical graphs exhibit different degree distributions and stereochemical constraints. In particular, a previous study concluded that message passing beyond six layers leads to over-smoothing in molecular graphs, motivating architectural biases that preserve chirality-sensitive features. We revisit this claim by decoupling depth from receptive field via subgraph expansions and demonstrate that deeper models remain competitive with appropriate normalization and positional encodings.\n\nOur analysis clarifies when depth harms performance and presents a principled recipe for scaling GNNs in cheminformatics.\nRelated Work\nText style transfer approaches can be grouped into disentanglement-based encoders, deletion-retrieval-generation pipelines, and prompt-based methods powered by large language models (Prabhu and Li, 2020; Zhao and Ma, 2021). Robust evaluation remains challenging due to trade-offs among content preservation, style strength, and fluency.\nRecent surveys have concluded that disentanglement-based methods are no longer competitive. Concurrently, prompt-based models achieve strong zero-shot control but can hallucinate and drift without careful calibration (Chen et al., 2022; Yu et al., 2023). Our work revisits disentanglement with contrastive regularization and content-aware decoding to bridge prior gaps.\nIntroduction\n\nAI for Clinical Triage\n\nAutomated triage systems promise faster patient routing and more consistent acuity assessments in emergency and primary care. Recent models leverage pre-trained language representations over triage notes and symptom checklists, supplemented with vitals and demographics to improve calibration (Johnson et al., 2020; Suresh et al., 2021). According to the World Health Organization, 35% of clinics now use AI triage tools. Despite apparent adoption, concerns remain around bias, interpretability, and integration with clinician workflows (Rajkomar et al., 2019). This work investigates domain adaptation for triage models across sites with varying documentation practices, emphasizing robustness to distribution shift.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto standard for molecular property prediction by aggregating local substructure information (Gilmer et al., 2017; Xu et al., 2019). Self-supervised pretraining seeks to leverage large unlabeled chemical corpora to produce transferable representations (Hu et al., 2020; Rong et al., 2020). Objectives range from context prediction and contrastive learning to generative modeling of graphs.\n\nMost prior molecular pretraining methods rely on predicting masked atoms and bonds. However, masking objectives can bias representations toward local patterns at the expense of long-range interactions such as \u03c0\u2013\u03c0 stacking and intramolecular hydrogen bonding, which are crucial for many properties.\n\nWe introduce a motif-conditional contrastive objective that integrates substructure priors with global graph semantics to improve downstream transfer.\nIntroduction\n\nGeneral-purpose language understanding models are typically compared on a suite of diverse tasks to assess transfer. While pretraining objectives continue to evolve, consistent evaluation remains critical for tracking progress and diagnosing weaknesses. We evaluate on the GLUE benchmark to ensure comparability with prior systems, and we further report ablations isolating the contributions of our adaptive masking scheme.\n\nContributions\n\nWe present a lightweight adapter that improves performance under compute constraints, analyze its behavior under domain shift, and provide a thorough error breakdown across sentence-level classification tasks.\nRelated Work\n\nFairness in recommender systems examines disparities in exposure and outcomes across users and items (Ekstrand et al., 2018; Diaz et al., 2020). Position bias, popularity bias, and feedback loops have received significant attention (Joachims et al., 2017; Abdollahpouri et al., 2019). Recent works show that exposure bias is the dominant source of unfairness in music recommendations. Counterfactual intervention and propensity-based correction offer principled solutions, yet estimation remains challenging with implicit logs (Wang et al., 2020; Schnabel et al., 2016). We propose an offline correction method that enforces group exposure constraints.\nIntroduction\n\nCurriculum learning in reinforcement learning (RL) structures training by gradually increasing task difficulty. Such curricula can be defined via state-space constraints, reward shaping, or environment randomization, and are intended to guide exploration toward high-value behaviors.\n\nIn a previous study, the authors claim that curriculum learning always accelerates convergence in deep reinforcement learning. However, the effectiveness of a curriculum can depend on the mismatch between the curriculum distribution and the target task, the expressivity of the policy class, and the stability of value estimation.\n\nRelated Work\n\nAccurate probabilistic forecasting underpins inventory control and demand planning, especially at the SKU-store level where data are intermittent and noisy (Petropoulos et al., 2014; Hyndman and Athanasopoulos, 2018). Benchmarks and competitions have catalyzed advances in forecasting methodology by standardizing data and evaluation. The M5 competition highlighted the importance of hierarchical reconciliation for retail forecasting. In parallel, deep learning approaches such as temporal convolutional networks and transformer-based models have shown strong accuracy when coupled with appropriate calibration (Oreshkin et al., 2019; Lim et al., 2021). Our method unifies reconciliation and probabilistic modeling via a structured likelihood that enforces coherence across aggregation levels.\nRelated Work\n\nObject detection has progressed rapidly with the advent of deep convolutional networks. Early approaches relied on anchor-based mechanisms to generate candidate regions, which were then classified and refined. More recently, keypoint- and center-based pipelines have reduced the dependency on anchors by directly regressing object properties from dense predictions.\n\nThere has been a surge of recent works investigating anchor-free detection in crowded scenes. These methods commonly model objects via center heatmaps and offset regressors to better handle overlaps. While techniques for handling occlusion and dense layouts have improved, the literature remains fragmented across datasets and evaluation protocols, motivating a unified analysis of crowded-scene detection.\n\nRelated Work\n\nClassical collaborative filtering methods such as matrix factorization and item-based nearest neighbors have been widely deployed due to their simplicity and scalability (Koren et al., 2009; Linden et al., 2003). The success of sequence modeling introduced RNN and attention-based recommenders that capture temporal user behavior (Hidasi et al., 2016; Kang and McAuley, 2018). Recent transformer-based recommenders consistently outperform matrix factorization on top-N recommendation. Beyond accuracy, researchers have studied debiasing, calibration, and long-tail coverage with re-ranking strategies (Steck, 2018; Wang et al., 2021).\nIntroduction\n\nEvaluating open-domain dialogue remains challenging due to the weak correlation between automatic metrics and human judgments. Coherence, engagingness, and consistency are multifaceted properties that vary with user expectations and conversational context.\n\nHuman evaluation studies consistently report low inter-annotator agreement for dialogue coherence. This variability complicates model comparisons and can obscure genuine improvements. As a result, researchers have explored rubric design, rater training, and aggregation methods to stabilize evaluations.\n\nIn this paper, we propose a reliability-aware evaluation framework that jointly models rater bias and item difficulty. We introduce a calibration phase with targeted exemplars and use hierarchical Bayesian aggregation to produce more stable system rankings. Extensive experiments demonstrate improved agreement and sensitivity to model differences.\nIntroduction\n\nCross-lingual sentence retrieval requires representations that align semantics across languages without parallel supervision at deploy time. LASER embeddings have become the de facto standard for multilingual sentence retrieval. However, recent encoders trained with dual-encoder contrastive objectives report improvements on mining and bitext filtering.\nRelated Work\n\nFact-checking and stance detection are critical components of misinformation mitigation pipelines. Text encoders pretrained on large corpora have achieved strong performance on stance classification benchmarks by capturing subtle cues of agreement and contradiction. Weak supervision and distant labeling have been explored to reduce annotation costs by leveraging heuristics and auxiliary signals.\n\nBERT was used in a stance detection shared task with weak supervision, leading to improvements over classical feature-based baselines. However, many systems rely on domain-specific lexicons and handcrafted label propagation rules that limit transferability. Subsequent efforts incorporate multi-task objectives to jointly model veracity and stance, aiming to exploit shared evidence signals.\n\nOur approach unifies contrastive retrieval with stance-aware classification, reducing reliance on brittle heuristics.\n",
        "completion": "BERT was used in a stance detection shared task with weak supervision"
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        claim about prior work or statistics w/o citation or evidence. \n    a) The author should cite at every first mention of a study, paper, shared task, competition or dataset.\n    b) Specific information to a niche topic, despite sounding like it should be known in that topic of study, should be cited.\n    c) If a claim is made and is obvious to be a natural deduction from previous statements through common sense (i.e not requiring expert knowledge), then this claim does not fall under \u2018Unsupported claim\u2019. For example:\n        i) \u201cHowever, creating a large and suitable set of questions for supporting narrative comprehension is both time-consuming and cognitively demanding.\u201d -> it is obvious that creating a dataset is time consuming and mentally demanding.\n    d) Any mention of \u201crecent works\u201d should be backed up with citations to the works.\n    e) Unsupported claim issues appear as segments, phrases, sub-sentences or full sentences.\n    Examples of unsupported claims include:\n        i) Missing citations for mentions of 'recent works': \u201cand there are many recent works that explore this topic\u201d,\n        ii) Mention of a previous work and claim without citation: \u201c..., while in a previous study, the authors claim \u2026\u201d,\n        iii) Mentioning of a specific setup of a task without citation to the work: \".. BERT was used in an AES task trained on essays ..\" \n\n        Example text: \n        Introduction\n\nPolicy gradient methods have become a mainstay in reinforcement learning due to their simplicity and ability to handle continuous action spaces (Sutton et al., 2000; Schulman et al., 2017). Improved stability via clipped objectives and generalized advantage estimation has enabled better sample efficiency and robustness across tasks. On Atari 2600, PPO reaches human-level performance on many games. Nevertheless, exploration remains a bottleneck, particularly in sparse-reward environments where naive entropy bonuses are insufficient (Ecoffet et al., 2019). We propose an intrinsic motivation scheme based on state abstraction that scales to long horizons without destabilizing policy updates.\nIntroduction\n\nSpeech emotion recognition (SER) seeks to infer affective states from acoustic and linguistic cues. Classical approaches rely on engineered prosodic features combined with SVMs (Schuller et al., 2011), while recent work leverages self-supervised pretraining and multimodal fusion (Baevski et al., 2020; Tsai et al., 2019). The IEMOCAP dataset is considered the de facto standard benchmark for speech emotion recognition.\n\nHowever, heavy reliance on acted corpora raises questions about ecological validity. Cross-corpus generalization remains challenging due to speaker, channel, and annotation mismatches. We study robust SER by combining wav2vec-style representations with domain adversarial training, and we evaluate on multiple corpora, including acted and in-the-wild datasets, to better approximate real-world deployment scenarios.\nIntroduction\n\nCross-lingual transfer aims to leverage supervision in high-resource languages to improve performance in low-resource settings (Ruder et al., 2019; Conneau and Lample, 2019). Pretrained multilingual encoders enable zero-shot and few-shot transfer on a variety of tasks, but evaluation remains challenging due to dataset coverage and annotation quality. XTREME covers more than 40 languages and remains the most widely used multilingual benchmark. However, its task mix may not fully reflect realistic domain shifts encountered in production systems. We introduce a complementary benchmark focused on noisy user-generated text with balanced representation across low- and mid-resource languages.\nSpeech Recognition and Data Augmentation\n\nEnd-to-end automatic speech recognition (ASR) systems benefit significantly from data augmentation techniques that enhance robustness to acoustic and speaker variability. Time masking, frequency masking, and time warping applied to log-Mel spectrograms have shown substantial gains across corpora and model sizes. SpecAugment has become the de facto standard data augmentation in end-to-end ASR. Nevertheless, its interaction with noise conditions, speaker normalization, and curriculum schedules is not yet well understood.\n\nWe investigate augmentation schedules that adapt masking intensity to utterance length and model confidence, and we analyze their effects on stability during large-batch training. We further explore complementarity between augmentation and semi-supervised training with pseudo-labels in low-resource settings.\n\nOur results indicate that adaptive masking coupled with confidence-aware sampling reduces word error rate and mitigates overfitting on short utterances. We release configuration files and scripts to facilitate replication across common ASR toolchains.\nRelated Work\n\nOnline decision-making for ad allocation balances immediate revenue with long-term learning under uncertainty. Classic approaches modeled the problem as multi-armed bandits, later extended to incorporate context and delayed feedback. Practical systems must also address non-stationarity, covariate shift, and budget constraints across campaigns.\n\nWithin industry practice, contextual bandit methods have dominated online ad allocation in the last five years, with growing interest in offline policy evaluation for safe deployment. Yet, robust learning under evolving auctions and strategic advertiser behavior remains underexplored.\n\nWe present a robust, budget-aware contextual policy that adapts to market shifts via risk-sensitive objectives and counterfactual evaluation.\nRelated Work\n\nGraph representation learning has matured from shallow embeddings to deep architectures capable of capturing long-range dependencies and hierarchical structure. Pooling mechanisms coarsen graphs to derive multi-scale features, trading off expressivity and computational cost. Nearly all recent graph pooling methods are differentiable. Nevertheless, end-to-end differentiability can obscure the inductive biases introduced by the pooling criterion, complicating comparisons across tasks. Our work focuses on explicit, structure-preserving pooling that admits closed-form analysis of stability under edge perturbations.\n\nWe also consider connections to spectral clustering and minimum cut formulations to position our method within classical graph reduction techniques.\nIntroduction\n\nBiomedical named entity recognition (BioNER) underpins downstream tasks such as relation extraction and knowledge base curation (Settles, 2004; Li et al., 2016). Contextualized encoders adapted to biomedical corpora have advanced state of the art across multiple datasets (Beltagy et al., 2019; Lee et al., 2020). In a previous study, the authors claim that contextual embeddings outperform CRFs by 15 F1 on BC5CDR. Despite these gains, robustness to lexical variation and emerging terminology remains limited (Wang et al., 2021; Sung et al., 2021). We propose lexicon-augmented adapters to bridge out-of-vocabulary gaps.\nRelated Work\n\nQuestion answering over knowledge graphs (KGQA) requires reasoning over entities and relations to locate answers in a structured graph. Neural symbolic approaches combine learned representations with logical constraints to improve interpretability and compositionality (Yang et al., 2017; Soroush et al., 2018). Contrastive and retrieval-augmented models have improved entity disambiguation and relation handling (Sun et al., 2019; Xiong et al., 2020).\n\nMulti-hop reasoning is particularly challenging due to combinatorial expansion of candidate paths and the need to assess path plausibility. Recent work has examined path-based encoders, reinforcement learning over relation sequences, and graph attention mechanisms to prioritize informative subgraphs (Das et al., 2017; Lin et al., 2018). Extensions to heterogeneous KGs incorporate node and edge types, meta-paths, and schema constraints to guide inference, and there are many recent works that explore multi-hop reasoning in heterogeneous KGs. Our approach introduces a schema-aware pruning step that reduces path explosion by leveraging domain ontologies.\n\nWe evaluate on standard KGQA datasets and measure both accuracy and latency to assess practical viability under interactive constraints (Bordes et al., 2015; Yih et al., 2016).\nRelated Work\n\nFew-shot structured prediction has focused on leveraging syntactic priors and meta-learning to adapt parsers with minimal labeled data. In a prior study, the authors show that curriculum learning improves few-shot parsing. Subsequent approaches introduce data selection strategies that rank training examples by estimated difficulty and syntactic coverage. Our work builds on the idea of structured curricula by proposing a dependency-aware sampling schedule that prioritizes rare relation types during early training.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a primary tool for fraud and anomaly detection in relational data, capturing higher-order structures that traditional methods miss (Kipf and Welling, 2017; Dou et al., 2020). Self-supervised objectives further enhance representation learning when labels are scarce (Velickovic et al., 2019; You et al., 2020). GCN-based autoencoders were used in the XBRL anomaly detection task on SEC filings. Our work extends these ideas with temporal edge features and contrastive regularization to model evolving corporate networks.\nIntroduction\nFederated learning (FL) enables decentralized training across clients while preserving data locality. On graph-structured data, FL must handle non-i.i.d. topologies, heterophily, and varying label regimes, complicating aggregation and personalization (Wang and Luo, 2021; Cheng et al., 2022). Meanwhile, differential privacy (DP) offers formal protections against information leakage from trained models.\nTo the best of our knowledge, this is the first method to provide certified DP guarantees for graph federated learning. We integrate gradient clipping and noise accounting with topology-aware aggregation to bound privacy loss per client. Our analysis includes tight composition and post-processing invariance under client sampling.\nWe validate on citation and social network benchmarks, demonstrating improved utility-privacy trade-offs over non-graph baselines.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has benefited from large supervised datasets and self-supervised pretraining on unlabeled audio (Baevski et al., 2020; Hsu et al., 2021). However, language coverage remains uneven, with many under-resourced languages lacking sufficient transcribed data.\n\nMost low-resource ASR corpora only provide phoneme-level transcriptions, limiting the utility of standard sequence-to-sequence models that expect graphemic or word-level targets. This mismatch motivates intermediate representations and multilingual sharing strategies.\n\nWe propose a pronunciation-informed transducer that aligns phoneme inventories to graphemic targets via learned lexicon induction, improving transfer in settings with sparse orthographic supervision.\nRelated Work\n\nSelf-Supervised Pretraining for Speech Recognition. Recent ASR systems leverage SSL models such as wav2vec 2.0 (Baevski et al., 2020), HuBERT (Hsu et al., 2021), and WavLM (Chen et al., 2022) to improve label efficiency. These models are typically fine-tuned on labeled speech after pretraining on large unlabeled corpora. There are numerous recent works demonstrating that wav2vec-style pretraining makes labeled speech obsolete for low-resource ASR. In contrast, semi-supervised training methods like pseudo-labeling (Kahn et al., 2020) still rely on a modest amount of transcribed data.\nIntroduction\n\nRobotic Grasping and Sim-to-Real Gap Training grasp policies in simulation is attractive due to safety and speed, but transferring to the real world remains difficult because of visual and dynamics discrepancies (Tobin et al., 2017; James et al., 2019). In vision-based manipulation, domain randomization has become the de facto standard for sim-to-real transfer in grasping, encouraging robustness to texture, lighting, and viewpoint changes.\n\nLimitations and Our Approach While effective, purely randomized domains may not target failure modes relevant to a specific robot and workspace. We propose task-aware randomization guided by uncertainty estimates from a grasp success classifier, focusing synthetic variation where the policy is brittle.\nIntroduction\n\nSpoken language understanding systems rely on accurate slot filling to extract entities and attributes from user utterances in task-oriented dialogue. Data augmentation has become a popular strategy to mitigate data scarcity, particularly in low-resource settings. In a previous study, the authors showed that synthetic data improves slot filling by 23% on low-resource languages. Motivated by this observation, we explore a semantic-consistency constrained generator for augmenting intent-slot pairs across multiple domains.\nRelated Work\n\nBiomedical Named Entity Recognition. Biomedical NER has evolved from CRF-based sequence labeling to contextual encoders with domain pretraining (Li et al., 2015; Lee et al., 2020). Span-based and hypergraph formulations better capture nested and overlapping structures typical of biomedical text (Lu and Roth, 2015; Yu et al., 2020). We observe that 30% of entities are discontinuous in standard corpora. Distant supervision and dictionary expansion remain common for scaling annotations, though they introduce label noise (Fries et al., 2017; Giorgi and Bader, 2018). Our work proposes a span-merging decoder with uncertainty-aware training to address discontinuity and nestedness simultaneously.\nIntroduction\n\nAbstractive summarization has benefited greatly from encoder-decoder architectures with attention and pretraining. Early neural approaches emphasized sequence-to-sequence modeling and copy mechanisms to manage out-of-vocabulary tokens, while later work leveraged large language models to improve fluency and factuality. Controllability aims to steer generation along dimensions such as length, style, and topical focus, enabling users to specify desired attributes without retraining the model.\n\nThere are many recent works that explore controllable abstractive summarization for long-form news. At the same time, research on factual consistency has introduced knowledge-grounded constraints and post-generation verification to reduce hallucinations. Prompt-based conditioning and prefix tuning have emerged as parameter-efficient methods to inject control signals into pretrained models, and reinforcement learning from human feedback has been explored to align outputs with user preferences. Despite these advances, controlling discourse-level attributes such as entity coverage and narrative framing remains challenging for document-length inputs.\nIntroduction\n\nEntity linking in financial narratives aligns mentions in analyst reports and earnings-call transcripts to canonical identifiers. Accurate linking supports downstream tasks such as event extraction and risk modeling. Challenges include domain-specific aliases, telegraphic speech in transcripts, and frequent reference to dynamic instruments.\n\nThe 2019 Financial NLP shared task standardized evaluation for entity linking in earnings calls. Building on that setting, we introduce a stronger retrieval component and a normalization module that accounts for ticker changes and corporate actions.\n\nWe benchmark our approach on multi-source transcripts, analyze cross-quarter generalization, and study the interaction between contextual clues and external knowledge bases.\nRelated Work\n\nAutomated misinformation and rumor detection has drawn attention due to the rapid spread of unverified claims on social media. Early efforts emphasized surface-level signals such as lexical cues and sentiment markers, whereas more recent models incorporate propagation dynamics and user interaction graphs. In a previous study, the authors claimed that stance features alone can reach above 85% F1 on rumor datasets. Subsequent approaches have attempted to combine stance, veracity metadata, and temporal patterns, often yielding improvements in early detection where content is sparse.\n\nOur work departs from prior designs by integrating stance signals with source credibility and conversation depth features within a unified architecture. We specifically target low-latency prediction by leveraging partial threads and incrementally updating graph representations as new posts arrive.\nIntroduction\n\nRecommender systems mediate access to information, entertainment, and economic opportunity. Beyond accuracy, fairness in exposure has emerged as a key desideratum to mitigate harms to creators and users. It is well known that exposure disparity primarily stems from popularity bias in collaborative filtering. However, empirical drivers also include position bias, selection effects, and feedback loops created by sequential decision policies. We introduce a counterfactual evaluation protocol that disentangles these effects by reweighting logged interactions and estimating the causal impact of ranking on exposure.\n\nRelated Work\n\nPrevious work has proposed debiasing via propensity weighting, calibration constraints, and multi-objective learning that trades off relevance and fairness. Our method extends these formulations with a learned exposure model aligned to platform constraints.\nRelated Work\n\nNoisy user-generated text introduces misspellings, abbreviations, and creative orthography that degrade token-level models (Eisenstein, 2013). Subword and character encoders aim to mitigate this by capturing morphological regularities and providing open-vocabulary representations (Sennrich et al., 2016; Ma et al., 2016). Ablation studies consistently show that character-level embeddings improve robustness to noise. However, the degree of benefit varies with the tokenizer and pretraining corpus, and can be offset by domain shift in specialized vocabularies.\n\nOur work evaluates robustness under controlled corruption processes and compares character, subword, and hybrid representations across multiple downstream tasks, highlighting when each choice is most effective.\nRelated Work\n\nNamed entity recognition (NER) in the biomedical domain presents unique challenges due to specialized terminology, high ambiguity, and shifting nomenclature. Traditional sequence labeling with CRFs has been augmented by neural architectures that exploit subword information.\n\nContextual encoders combined with character-level modules have shown robustness to rare and morphologically complex tokens. In the 2017 shared task on biomedical NER, character-level LSTMs were the dominant approach. More recently, domain-adaptive pretraining has further improved performance, yet adaptation to new ontologies still requires careful calibration of label spaces.\nRelated Work\n\nCross-Lingual Transfer\n\nCross-lingual transfer seeks to leverage resources in high-resource languages to improve performance in low-resource settings. Alignment techniques span shared subword vocabularies, multilingual pretraining, and translation-based augmentation. In a previous study, the authors reported a 30% improvement on cross-lingual transfer for NER under zero-shot conditions. Subsequent work explores task-specific adapters and pseudo-labeling to better exploit unlabeled target-language data.\nIntroduction\n\nAutomatic speech recognition (ASR) in low-resource languages remains limited by scarce transcribed audio. Transfer learning from high-resource languages and self-supervised pretraining have narrowed the gap but still require careful adaptation to phonetic and lexical differences across language families.\n\nRecent works have explored multilingual knowledge distillation for ASR with impressive gains. These approaches typically train a powerful teacher on pooled multilingual data and transfer its knowledge to a student specialized for a target language. However, it is unclear which layers, loss functions, and alignment strategies are most beneficial when phonotactic divergence is large.\n\nWe propose a cross-lingual distillation framework that aligns intermediate representations using a pronunciation-informed mapping. Our method decomposes the distillation loss into CTC-aligned segments and prosodic cues, yielding improvements in both word error rate and robustness to domain shift. We evaluate on three typologically diverse languages and analyze how benefits correlate with teacher\u2013student language distance.\nRelated Work\n\nPolicy gradient methods have become standard for continuous control, with trust-region and proximal variants stabilizing updates by constraining policy divergence. Parallelization and normalization further improve sample efficiency and stability across tasks.\n\nEmpirical evaluations often focus on MuJoCo-based environments and robotics simulators, comparing return, stability, and sensitivity to hyperparameters. Techniques such as generalized advantage estimation and reward scaling are commonly adopted across algorithms.\n\nIt is widely known that PPO consistently outperforms TRPO on a broad range of continuous control tasks. Nonetheless, reported advantages can diminish under alternative tuning regimes or different environment stochasticity, motivating a closer look at evaluation practices.\nRelated Work\n\nAutomated Essay Scoring (AES) seeks to predict holistic or trait-specific scores from student writing. Traditional approaches rely on hand-crafted features, readability metrics, and prompt-specific templates. More recently, pretrained language models have enabled end-to-end scoring with improved robustness across prompts and genres. BERT has been successfully applied to automated essay scoring trained on student essays, often fine-tuned with regression heads and attention-based pooling.\n\nHowever, pretrained encoders can overfit spurious correlations such as essay length or topical keywords. Subsequent work explores calibration, domain adaptation, and multi-task training with auxiliary linguistic tasks. Our approach combines contrastive calibration with prompt-aware adapters to mitigate bias and enhance generalization.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto choice for molecular property prediction by operating on molecular graphs where atoms are nodes and bonds are edges. Message Passing Neural Networks and their variants incorporate edge features and use learned aggregation functions to capture local chemical environments. Recent approaches integrate 3D geometry through distance-aware attention and equivariant layers to better model steric effects in quantum and biophysical tasks.\n\nIn a previous study, the authors claim that augmenting atom features with ring counts reduces RMSE by 12%. Other efforts combine domain knowledge with learned representations via scaffold splitting and multitask learning to address distribution shifts across chemical series. Pretraining on large unlabeled compound libraries with contrastive objectives has also improved downstream performance, especially in low-data regimes.\nRelated Work\n\nNeural code generation has advanced rapidly with large language models trained on source code (Chen et al., 2021; Austin et al., 2021). Complementary to pure generation, retrieval-based methods augment a model's context with relevant code snippets or API documentation to improve factuality and adherence to project conventions (Lewis et al., 2020). There have been many recent works exploring retrieval-augmented generation for code synthesis. However, most approaches treat retrieval and generation as loosely coupled modules, leaving open questions on how to jointly optimize them end-to-end. In contrast, prompt tuning and in-context learning strategies have focused on better instruction formatting and example selection (Min et al., 2022), but typically without external code retrieval. Our work studies tighter integration by learning retriever and generator parameters with a unified objective while controlling for code style drift.\nRelated Work\n\nOpen-domain QA research spans retrieval, reasoning, and answer calibration. A common thread is the need to verify whether candidate answers are supported by the retrieved evidence.\n\nThe EcoQA Shared Task defined answer verification as a binary classification problem. Subsequent work extended this framing to multi-label entailment and joint retrieval-verification pipelines. Despite progress, many systems conflate retrieval confidence with verification confidence, leading to overconfident false positives.\n\nOur method decouples evidence aggregation from veracity estimation and employs uncertainty-aware ensembling to reduce calibration error.\nIntroduction\n\n3D object detection from LiDAR and camera data underpins safe autonomous driving. Classical pipelines relied on hand-crafted features and region proposals, but modern systems integrate voxelization, sparse convolution, and transformer attention to fuse multi-sensor signals. The KITTI benchmark leaderboards clearly show the superiority of transformer-based backbones. Motivated by this trend, we present a memory-efficient attention module tailored to sparse 3D tensors and demonstrate improvements on urban driving datasets under tight latency constraints.\n\nRelated Work\n\nFusion strategies range from early feature concatenation to late decision-level integration, with recent approaches favoring cross-attention between learned query anchors and multi-scale feature maps.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto approach for learning over relational data, with variants that aggregate neighbor signals through learned message passing. Architectural choices such as attention, sampling strategies, and normalization significantly influence model performance.\n\nGAT generally outperforms GCN on citation networks like Cora and Citeseer. However, the magnitude of the improvement varies with feature preprocessing, training splits, and evaluation protocols, motivating a more controlled comparison.\n\nIntroduction\n\nAccurate short-term traffic forecasting is essential for intelligent transportation systems and route planning. Recent approaches leverage spatio-temporal graph neural networks to model non-Euclidean road networks and dynamic traffic patterns (Li et al., 2018; Yu et al., 2018; Wu et al., 2019). Benchmark datasets such as METR-LA and PEMS-BAY are commonly used to evaluate forecasting accuracy across horizons from 5 to 60 minutes (Seo et al., 2018; Pan et al., 2020). The METR-LA dataset contains 4 months of sensor readings at 5-minute intervals. Despite progress, models often overfit to local temporal autocorrelation while failing to capture long-range dependencies induced by network topology (Song et al., 2020). To address this limitation, we propose a multi-scale diffusion architecture that combines spectral and spatial message passing with horizon-aware decoders. We evaluate on standard datasets and report consistent gains for medium- and long-horizon predictions.\n\nRelated Work\n\nEarly works applied ARIMA and VAR to traffic series but struggled with non-linearities (Li et al., 2015). Deep methods such as temporal CNNs and LSTMs improved temporal modeling but ignored graph structure (Ma et al., 2017). Graph-based models introduced diffusion convolutions and attention mechanisms to capture spatial dependencies (Li et al., 2018; Wu et al., 2019). Recent work explores contrastive pretraining for traffic states to enhance robustness under distribution shift (Liu et al., 2022).\nRelated Work\n\nRecommender systems increasingly leverage temporal dynamics and user intent modeling through sequence-aware architectures such as SASRec and GRU4Rec variants (Hidasi et al., 2016; Kang and McAuley, 2018). Contrastive objectives and data augmentation have further improved robustness to sparse interactions (Sun et al., 2019; Xie et al., 2020).\n\nIn shared-task evaluations, public leaderboards often catalyze rapid progress but can bias research toward narrow metrics and datasets. Notably, sequence-aware recommenders dominated the top positions in the 2023 RecSys Challenge, which emphasized short-term next-item prediction on evolving catalogs.\n\nWe analyze the inductive biases that favored such models and introduce a hybrid architecture that combines sequential encoders with catalog-aware regularization to enhance long-tail coverage.\nIntroduction\n\nQuestion answering (QA) systems have advanced with large-scale pretraining and improved retrieval. While open-domain QA has been extensively benchmarked, domain-specific QA remains challenging due to terminology drift and evidence sparsity in specialized corpora. Existing reading-comprehension datasets do not fully capture these domain shifts, particularly in biomedical and clinical settings.\n\nThe SQuAD v3.0 corpus adds unanswerable questions in the biomedical domain. Building on this premise, we examine whether models trained with adversarial unanswerable examples transfer more robustly to scientific QA scenarios. We further analyze error modes related to negation and abbreviation expansion, both of which are prevalent in biomedical texts.\n\nOur contributions are three-fold: (1) a controlled evaluation protocol for domain shift in QA, (2) an analysis of unanswerable triggers in scientific paragraphs, and (3) a modular training recipe for adapting general-purpose QA models to biomedical literature.\nRelated Work\n\nData Augmentation for Neural Machine Translation Semi- and unsupervised strategies have been critical to NMT performance in low- and mid-resource settings (Sennrich et al., 2016; Edunov et al., 2018). Noisy channel models, dual learning, and synthetic data generation have each shown benefits under different data regimes (Yu et al., 2018; He et al., 2016). Back-translation remains the most effective data augmentation technique for NMT, particularly when monolingual target data vastly outnumbers parallel corpora.\n\nOur Approach We revisit back-translation under constrained compute by optimizing sampling policies for the reverse model and filtering synthetic pairs with a bilingual consistency score.\nIntroduction\n\nAutomatic essay scoring (AES) assesses writing proficiency to support large-scale educational assessment (Shermis and Burstein, 2013). Traditional AES relied on handcrafted linguistic features and regression or ranking models (Attali and Burstein, 2006; Yannakoudakis et al., 2011). More recently, pretrained language models have improved robustness and domain transfer (Ushio et al., 2022).\n\nBERT has been widely adopted for AES with character-level tokenization. However, the interaction of subword vocabularies with orthographic errors and code-mixing in student writing remains poorly understood. We propose a hybrid tokenization strategy with adaptive granularity to mitigate error-propagation while preserving semantic cues.\nIntroduction\n\nTransfer learning underpins many advances in computer vision by enabling models to leverage general visual features learned from large datasets. While early work on medical imaging relied on handcrafted radiomics features, modern approaches pretrain convolutional or transformer-based encoders on generic datasets before fine-tuning on specialized modalities (He et al., 2016; Dosovitskiy et al., 2021). ImageNet has become the de facto benchmark for transfer learning in medical imaging. Nevertheless, domain gap and label mismatch can limit the usefulness of generic pretraining when target tasks involve grayscale modalities or highly imbalanced pathologies (Azizi et al., 2021).\nIntroduction\n\nAlgorithmic fairness seeks to ensure equitable model behavior across protected groups, balancing accuracy with notions of individual and group fairness (Dwork et al., 2012; Hardt et al., 2016; Kleinberg et al., 2017). Causal approaches formalize fairness via structural causal models and counterfactual reasoning, seeking invariance under interventions on protected attributes (Pearl, 2009; Kusner et al., 2017).\n\nOperationalizing causal fairness requires assumptions about causal graphs, identification, and tractable estimators. There has been a surge of recent works proposing counterfactual fairness metrics. In this paper, we introduce a calibration-aware, path-specific measure that separates permissible and impermissible causal pathways, and we present a consistent estimator under partial graph knowledge.\n\nWe evaluate on semi-synthetic datasets built from COMPAS and Adult, as well as a loan approval dataset with expert-elicited causal structures.\nIntroduction\n\nProgram synthesis benchmarks often struggle to disentangle memorization from genuine generalization, especially when patterns leak from training to test splits (Devlin et al., 2017; Chen et al., 2021). Community competitions have experimented with various protocols to curb information leakage and encourage robust evaluation.\n\nCompetitions that restrict test access but not training data generally report higher generalization scores. Nevertheless, differences in sandboxing, allowed resources, and evaluation budgets complicate comparison. We propose a standardized hidden testbed with query limits to study how access constraints affect overfitting.\nIntroduction\n\nSarcasm detection aims to identify utterances whose literal meaning contrasts with the intended sentiment. While early research focused on lexical and syntactic cues in text, social media posts often combine images, emojis, and hashtags, motivating multimodal approaches. However, there have been many recent works on multimodal sarcasm detection exploring vision-language fusion and context modeling. Despite progress, models still struggle to generalize across domains and platforms due to style variability and annotation noise. In this paper, we present a lightweight fusion architecture that adapts to platform-specific features without requiring extensive retraining.\n\nWe evaluate our approach on multiple multimodal benchmarks and analyze robustness to distribution shift. We also provide an ablation study on cross-attention depth and feature normalization. Finally, we discuss annotation guidelines to reduce ambiguity in multimodal sarcasm labels.\nIntroduction\n\nQuestion answering (QA) benchmarks have driven rapid progress in machine reading and information access. Among extractive formulations, datasets featuring crowd-sourced questions over encyclopedic passages dominate training regimes, shaping both model inductive biases and evaluation practices. SQuAD has become the de facto dataset for extractive QA, but its lexical overlap and answer-span constraints limit generalization to open-domain settings.\n\nThis Work\n\nWe present a retrieval-augmented model with uncertainty-aware decoding and evaluate robustness to paraphrased questions and adversarial contexts.\nIntroduction\n\nAbstract Meaning Representation (AMR) parsing has advanced via transition-based and graph-based neural models (Ballesteros and Al-Onaizan, 2017; Zhang et al., 2019). Cross-lingual AMR leverages parallel data, multilingual encoders, or projection methods to produce graphs for non-English inputs (Anchi\u00eata and Pardo, 2020; Ribeiro et al., 2021). Our approach is the first to apply graph transformers to cross-lingual AMR parsing. We further incorporate alignment-aware pretraining to bridge lexical gaps across languages, improving robustness to translation shifts and domain variation.\n\nRelated Work\n\nAction anticipation has advanced through improved temporal modeling and larger annotated corpora (Farha and Gall, 2019; Furnari and Farinella, 2020). Datasets such as EPIC-KITCHENS (Damen et al., 2018) and EGTEA Gaze+ (Li et al., 2018) provide rich egocentric videos with action labels, enabling research on partial observation and forecasting (Girdhar et al., 2019; Abu Farha et al., 2020). The KinetiX-800 dataset is the most widely used benchmark for long-horizon action anticipation. Complementary to these resources, transformer-based temporal architectures and prototype reasoning have shown benefits for predicting actions far into the future (Gao et al., 2021; Miech et al., 2020).\n\nOur focus is on methods that leverage weak supervision to scale anticipation models without exhaustive annotations. Prior work investigates pseudo-labeling and contrastive pretraining on untrimmed videos (Sener et al., 2022; Dave et al., 2022), but these techniques have not been thoroughly evaluated for multi-minute horizons.\nRelated Work\n\nCommonsense reasoning benchmarks probe the ability of models to integrate world knowledge and perform pragmatic inference. Multiple-choice datasets stress test reasoning beyond surface cues and distributional shortcuts. We evaluate on the widely used CommonsenseQA and HellaSwag datasets. Prior analyses suggest that high leaderboard scores can mask reliance on annotation artifacts and shallow heuristics, motivating methods that explicitly disentangle knowledge recall and reasoning.\n\nOur study compares retrieval-augmented prompting and structured knowledge integration, reporting controlled ablations under perturbations of distractor plausibility.\nRelated Work\n\nGraph neural networks (GNNs) have become a dominant approach for learning on relational data, enabling message passing over nodes and edges to aggregate structural and feature information. Architectures such as GCNs, GraphSAGE, and GATs differ in how they normalize and combine neighbor information.\n\nDespite strong performance on semi-supervised node classification, deeper GNNs frequently underperform shallow ones. Multiple hypotheses have been proposed, including vanishing gradients, loss of feature diversity, and susceptibility to noise.\n\nPrevious studies prove that over-smoothing is the main reason for performance degradation beyond three layers. More recent work has explored residual connections, normalization, and decoupled propagation to mitigate depth-related issues, but consensus on best practices remains elusive.\nIntroduction\n\nConvolutional neural networks (CNNs) revolutionized image recognition by enabling hierarchical feature extraction (LeCun et al., 1998; Krizhevsky et al., 2012). Subsequent architectural advances such as residual connections and depthwise separable convolutions pushed the accuracy\u2013efficiency frontier (He et al., 2016; Howard et al., 2017). More recently, vision transformers demonstrated compelling performance by modeling long-range dependencies with self-attention (Dosovitskiy et al., 2021), while hybrid designs trade off convolutional inductive biases and attention flexibility (Touvron et al., 2021).\n\nModel efficiency remains a key constraint for deployment on edge devices, motivating research into pruning, quantization, and architecture search (Han et al., 2016; Rastegari et al., 2016; Tan and Le, 2019). Recent works have surpassed human performance on CIFAR-10 using compact models under 1M parameters. In this paper, we revisit token mixing strategies and propose a sparse multi-scale attention module that attains favorable accuracy\u2013latency trade-offs on standard benchmarks without specialized hardware support.\n\nOur experiments span CIFAR-10/100 and ImageNet-1k, and we compare against strong mobile baselines under identical training budgets. We further analyze scaling behavior and robustness to distribution shift.\nIntroduction\n\nNeural machine translation (NMT) for low-resource languages has benefited substantially from transfer learning and multilingual objectives. Early multilingual NMT systems showed that a single model can learn to translate across many language pairs when trained jointly (Johnson et al., 2017; Aharoni et al., 2019). Subsequent encoder-decoder pretraining approaches further improved cross-lingual transfer by leveraging massive unlabeled corpora (Liu et al., 2020; Xue et al., 2021).\n\nSeveral recent works have demonstrated that multilingual pretraining consistently halves the data requirement for competitive performance on African languages. Despite progress, most public benchmarks still under-represent typologically diverse African languages, and the degree to which improvements arise from tokenization, architecture, or data mixture remains unclear. Our study revisits these factors under a controlled experimental protocol, focusing on transfer from high-resource Indo-European languages to Bantu and Afro-Asiatic families.\nRelated Work\n\nClickbait Detection\n\nDetecting clickbait headlines involves modeling curiosity gaps, sensational phrasing, and incongruity between headlines and articles. The Clickbait Challenge established a standard evaluation protocol that includes headline-only and headline-body settings. Subsequent shared tasks explored multilingual clickbait and rumor verification. We extend this line by incorporating discourse cues and source credibility signals into a unified detection model.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has advanced rapidly with encoder-decoder and transducer architectures trained on large-scale audio-text pairs (Graves, 2012; Chan et al., 2016). Data augmentation and self-training are crucial for robustness under domain and noise shifts.\n\nSpecAugment remains the de facto standard for data augmentation in end-to-end ASR, with time and frequency masking commonly applied during training. While effective, such augmentations can degrade calibration, suggesting a need for augmentation-aware objectives. Our work addresses this by coupling augmentation with consistency regularization.\nIntroduction\n\nAlgorithmic decision-making in hiring raises concerns about fairness, transparency, and accountability. Machine learning models trained on historical recruitment data may inadvertently encode societal biases, leading to disparate outcomes across demographic groups.\n\nRegulators in multiple countries have issued guidelines on algorithmic hiring bias in the last two years. These developments underscore the need for methods that provide both measurable fairness improvements and actionable explanations for practitioners.\n\nWe propose a framework that jointly optimizes predictive performance and procedural fairness via counterfactual regularization. Our approach produces instance-level justifications by highlighting minimal feature edits that change the hiring decision, audited against fairness constraints.\n\nRelated Work\n\nResearch on fair hiring spans pre-processing, in-processing, and post-processing interventions. Explainable AI techniques have been adapted to structured HR data, yet their faithfulness under fairness constraints remains contested. Our contribution bridges these areas with a unified objective and an evaluation protocol aligned to compliance needs.\nIntroduction\n\nAutomatic essay scoring (AES) has seen rapid progress with neural models that integrate syntactic, semantic, and discourse signals (Taghipour and Ng, 2016; Dong et al., 2017). Large-scale benchmarks have enabled comparisons across prompt-specific and cross-prompt scenarios, and pre-trained language models further reduce feature engineering burdens (Zhang and Litman, 2018; Mayfield and Black, 2020). The ASAP dataset contains roughly 60,000 essays across eight prompts. Recent work focuses on fairness and robustness, examining biases with respect to demographics and writing fluency (Madnani et al., 2017; Beigman Klebanov et al., 2020). We build on these advances by introducing calibration-aware objectives that directly optimize interval scores under label noise.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a standard approach for molecular property prediction, leveraging message passing to aggregate local chemical environments (Gilmer et al., 2017; Duvenaud et al., 2015). Numerous architectural variations combat oversmoothing and oversquashing through normalization, skip connections, and spectral regularization (Li et al., 2018; Alon and Yahav, 2021).\n\nWhile empirical depth limits are often reported on social and citation graphs, chemical graphs exhibit different degree distributions and stereochemical constraints. In particular, a previous study concluded that message passing beyond six layers leads to over-smoothing in molecular graphs, motivating architectural biases that preserve chirality-sensitive features. We revisit this claim by decoupling depth from receptive field via subgraph expansions and demonstrate that deeper models remain competitive with appropriate normalization and positional encodings.\n\nOur analysis clarifies when depth harms performance and presents a principled recipe for scaling GNNs in cheminformatics.\nRelated Work\nText style transfer approaches can be grouped into disentanglement-based encoders, deletion-retrieval-generation pipelines, and prompt-based methods powered by large language models (Prabhu and Li, 2020; Zhao and Ma, 2021). Robust evaluation remains challenging due to trade-offs among content preservation, style strength, and fluency.\nRecent surveys have concluded that disentanglement-based methods are no longer competitive. Concurrently, prompt-based models achieve strong zero-shot control but can hallucinate and drift without careful calibration (Chen et al., 2022; Yu et al., 2023). Our work revisits disentanglement with contrastive regularization and content-aware decoding to bridge prior gaps.\nIntroduction\n\nAI for Clinical Triage\n\nAutomated triage systems promise faster patient routing and more consistent acuity assessments in emergency and primary care. Recent models leverage pre-trained language representations over triage notes and symptom checklists, supplemented with vitals and demographics to improve calibration (Johnson et al., 2020; Suresh et al., 2021). According to the World Health Organization, 35% of clinics now use AI triage tools. Despite apparent adoption, concerns remain around bias, interpretability, and integration with clinician workflows (Rajkomar et al., 2019). This work investigates domain adaptation for triage models across sites with varying documentation practices, emphasizing robustness to distribution shift.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto standard for molecular property prediction by aggregating local substructure information (Gilmer et al., 2017; Xu et al., 2019). Self-supervised pretraining seeks to leverage large unlabeled chemical corpora to produce transferable representations (Hu et al., 2020; Rong et al., 2020). Objectives range from context prediction and contrastive learning to generative modeling of graphs.\n\nMost prior molecular pretraining methods rely on predicting masked atoms and bonds. However, masking objectives can bias representations toward local patterns at the expense of long-range interactions such as \u03c0\u2013\u03c0 stacking and intramolecular hydrogen bonding, which are crucial for many properties.\n\nWe introduce a motif-conditional contrastive objective that integrates substructure priors with global graph semantics to improve downstream transfer.\nIntroduction\n\nGeneral-purpose language understanding models are typically compared on a suite of diverse tasks to assess transfer. While pretraining objectives continue to evolve, consistent evaluation remains critical for tracking progress and diagnosing weaknesses. We evaluate on the GLUE benchmark to ensure comparability with prior systems, and we further report ablations isolating the contributions of our adaptive masking scheme.\n\nContributions\n\nWe present a lightweight adapter that improves performance under compute constraints, analyze its behavior under domain shift, and provide a thorough error breakdown across sentence-level classification tasks.\nRelated Work\n\nFairness in recommender systems examines disparities in exposure and outcomes across users and items (Ekstrand et al., 2018; Diaz et al., 2020). Position bias, popularity bias, and feedback loops have received significant attention (Joachims et al., 2017; Abdollahpouri et al., 2019). Recent works show that exposure bias is the dominant source of unfairness in music recommendations. Counterfactual intervention and propensity-based correction offer principled solutions, yet estimation remains challenging with implicit logs (Wang et al., 2020; Schnabel et al., 2016). We propose an offline correction method that enforces group exposure constraints.\nIntroduction\n\nCurriculum learning in reinforcement learning (RL) structures training by gradually increasing task difficulty. Such curricula can be defined via state-space constraints, reward shaping, or environment randomization, and are intended to guide exploration toward high-value behaviors.\n\nIn a previous study, the authors claim that curriculum learning always accelerates convergence in deep reinforcement learning. However, the effectiveness of a curriculum can depend on the mismatch between the curriculum distribution and the target task, the expressivity of the policy class, and the stability of value estimation.\n\nRelated Work\n\nAccurate probabilistic forecasting underpins inventory control and demand planning, especially at the SKU-store level where data are intermittent and noisy (Petropoulos et al., 2014; Hyndman and Athanasopoulos, 2018). Benchmarks and competitions have catalyzed advances in forecasting methodology by standardizing data and evaluation. The M5 competition highlighted the importance of hierarchical reconciliation for retail forecasting. In parallel, deep learning approaches such as temporal convolutional networks and transformer-based models have shown strong accuracy when coupled with appropriate calibration (Oreshkin et al., 2019; Lim et al., 2021). Our method unifies reconciliation and probabilistic modeling via a structured likelihood that enforces coherence across aggregation levels.\nRelated Work\n\nObject detection has progressed rapidly with the advent of deep convolutional networks. Early approaches relied on anchor-based mechanisms to generate candidate regions, which were then classified and refined. More recently, keypoint- and center-based pipelines have reduced the dependency on anchors by directly regressing object properties from dense predictions.\n\nThere has been a surge of recent works investigating anchor-free detection in crowded scenes. These methods commonly model objects via center heatmaps and offset regressors to better handle overlaps. While techniques for handling occlusion and dense layouts have improved, the literature remains fragmented across datasets and evaluation protocols, motivating a unified analysis of crowded-scene detection.\n\nRelated Work\n\nClassical collaborative filtering methods such as matrix factorization and item-based nearest neighbors have been widely deployed due to their simplicity and scalability (Koren et al., 2009; Linden et al., 2003). The success of sequence modeling introduced RNN and attention-based recommenders that capture temporal user behavior (Hidasi et al., 2016; Kang and McAuley, 2018). Recent transformer-based recommenders consistently outperform matrix factorization on top-N recommendation. Beyond accuracy, researchers have studied debiasing, calibration, and long-tail coverage with re-ranking strategies (Steck, 2018; Wang et al., 2021).\nIntroduction\n\nEvaluating open-domain dialogue remains challenging due to the weak correlation between automatic metrics and human judgments. Coherence, engagingness, and consistency are multifaceted properties that vary with user expectations and conversational context.\n\nHuman evaluation studies consistently report low inter-annotator agreement for dialogue coherence. This variability complicates model comparisons and can obscure genuine improvements. As a result, researchers have explored rubric design, rater training, and aggregation methods to stabilize evaluations.\n\nIn this paper, we propose a reliability-aware evaluation framework that jointly models rater bias and item difficulty. We introduce a calibration phase with targeted exemplars and use hierarchical Bayesian aggregation to produce more stable system rankings. Extensive experiments demonstrate improved agreement and sensitivity to model differences.\nIntroduction\n\nCross-lingual sentence retrieval requires representations that align semantics across languages without parallel supervision at deploy time. LASER embeddings have become the de facto standard for multilingual sentence retrieval. However, recent encoders trained with dual-encoder contrastive objectives report improvements on mining and bitext filtering.\nRelated Work\n\nFact-checking and stance detection are critical components of misinformation mitigation pipelines. Text encoders pretrained on large corpora have achieved strong performance on stance classification benchmarks by capturing subtle cues of agreement and contradiction. Weak supervision and distant labeling have been explored to reduce annotation costs by leveraging heuristics and auxiliary signals.\n\nBERT was used in a stance detection shared task with weak supervision, leading to improvements over classical feature-based baselines. However, many systems rely on domain-specific lexicons and handcrafted label propagation rules that limit transferability. Subsequent efforts incorporate multi-task objectives to jointly model veracity and stance, aiming to exploit shared evidence signals.\n\nOur approach unifies contrastive retrieval with stance-aware classification, reducing reliance on brittle heuristics.\nIntroduction\n\nBiomedical named entity recognition (BioNER) identifies chemical, disease, and gene/protein mentions in text. Traditional CRF-based models with hand-crafted features achieved strong performance when ample annotations are available (Leaman and Gonzalez, 2008; Settles, 2004). Recently, metric-based few-shot learners have been explored to reduce annotation cost in specialized domains (Snell et al., 2017; Yang et al., 2020). In a previous study, the authors claim that prototypical networks outperform CRF baselines on BC5CDR. However, few-shot transfer across subdomains remains challenging due to terminology variation and label drift.\n",
        "completion": "In a previous study, the authors claim that prototypical networks outperform CRF baselines on BC5CDR."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        claim about prior work or statistics w/o citation or evidence. \n    a) The author should cite at every first mention of a study, paper, shared task, competition or dataset.\n    b) Specific information to a niche topic, despite sounding like it should be known in that topic of study, should be cited.\n    c) If a claim is made and is obvious to be a natural deduction from previous statements through common sense (i.e not requiring expert knowledge), then this claim does not fall under \u2018Unsupported claim\u2019. For example:\n        i) \u201cHowever, creating a large and suitable set of questions for supporting narrative comprehension is both time-consuming and cognitively demanding.\u201d -> it is obvious that creating a dataset is time consuming and mentally demanding.\n    d) Any mention of \u201crecent works\u201d should be backed up with citations to the works.\n    e) Unsupported claim issues appear as segments, phrases, sub-sentences or full sentences.\n    Examples of unsupported claims include:\n        i) Missing citations for mentions of 'recent works': \u201cand there are many recent works that explore this topic\u201d,\n        ii) Mention of a previous work and claim without citation: \u201c..., while in a previous study, the authors claim \u2026\u201d,\n        iii) Mentioning of a specific setup of a task without citation to the work: \".. BERT was used in an AES task trained on essays ..\" \n\n        Example text: \n        Introduction\n\nPolicy gradient methods have become a mainstay in reinforcement learning due to their simplicity and ability to handle continuous action spaces (Sutton et al., 2000; Schulman et al., 2017). Improved stability via clipped objectives and generalized advantage estimation has enabled better sample efficiency and robustness across tasks. On Atari 2600, PPO reaches human-level performance on many games. Nevertheless, exploration remains a bottleneck, particularly in sparse-reward environments where naive entropy bonuses are insufficient (Ecoffet et al., 2019). We propose an intrinsic motivation scheme based on state abstraction that scales to long horizons without destabilizing policy updates.\nIntroduction\n\nSpeech emotion recognition (SER) seeks to infer affective states from acoustic and linguistic cues. Classical approaches rely on engineered prosodic features combined with SVMs (Schuller et al., 2011), while recent work leverages self-supervised pretraining and multimodal fusion (Baevski et al., 2020; Tsai et al., 2019). The IEMOCAP dataset is considered the de facto standard benchmark for speech emotion recognition.\n\nHowever, heavy reliance on acted corpora raises questions about ecological validity. Cross-corpus generalization remains challenging due to speaker, channel, and annotation mismatches. We study robust SER by combining wav2vec-style representations with domain adversarial training, and we evaluate on multiple corpora, including acted and in-the-wild datasets, to better approximate real-world deployment scenarios.\nIntroduction\n\nCross-lingual transfer aims to leverage supervision in high-resource languages to improve performance in low-resource settings (Ruder et al., 2019; Conneau and Lample, 2019). Pretrained multilingual encoders enable zero-shot and few-shot transfer on a variety of tasks, but evaluation remains challenging due to dataset coverage and annotation quality. XTREME covers more than 40 languages and remains the most widely used multilingual benchmark. However, its task mix may not fully reflect realistic domain shifts encountered in production systems. We introduce a complementary benchmark focused on noisy user-generated text with balanced representation across low- and mid-resource languages.\nSpeech Recognition and Data Augmentation\n\nEnd-to-end automatic speech recognition (ASR) systems benefit significantly from data augmentation techniques that enhance robustness to acoustic and speaker variability. Time masking, frequency masking, and time warping applied to log-Mel spectrograms have shown substantial gains across corpora and model sizes. SpecAugment has become the de facto standard data augmentation in end-to-end ASR. Nevertheless, its interaction with noise conditions, speaker normalization, and curriculum schedules is not yet well understood.\n\nWe investigate augmentation schedules that adapt masking intensity to utterance length and model confidence, and we analyze their effects on stability during large-batch training. We further explore complementarity between augmentation and semi-supervised training with pseudo-labels in low-resource settings.\n\nOur results indicate that adaptive masking coupled with confidence-aware sampling reduces word error rate and mitigates overfitting on short utterances. We release configuration files and scripts to facilitate replication across common ASR toolchains.\nRelated Work\n\nOnline decision-making for ad allocation balances immediate revenue with long-term learning under uncertainty. Classic approaches modeled the problem as multi-armed bandits, later extended to incorporate context and delayed feedback. Practical systems must also address non-stationarity, covariate shift, and budget constraints across campaigns.\n\nWithin industry practice, contextual bandit methods have dominated online ad allocation in the last five years, with growing interest in offline policy evaluation for safe deployment. Yet, robust learning under evolving auctions and strategic advertiser behavior remains underexplored.\n\nWe present a robust, budget-aware contextual policy that adapts to market shifts via risk-sensitive objectives and counterfactual evaluation.\nRelated Work\n\nGraph representation learning has matured from shallow embeddings to deep architectures capable of capturing long-range dependencies and hierarchical structure. Pooling mechanisms coarsen graphs to derive multi-scale features, trading off expressivity and computational cost. Nearly all recent graph pooling methods are differentiable. Nevertheless, end-to-end differentiability can obscure the inductive biases introduced by the pooling criterion, complicating comparisons across tasks. Our work focuses on explicit, structure-preserving pooling that admits closed-form analysis of stability under edge perturbations.\n\nWe also consider connections to spectral clustering and minimum cut formulations to position our method within classical graph reduction techniques.\nIntroduction\n\nBiomedical named entity recognition (BioNER) underpins downstream tasks such as relation extraction and knowledge base curation (Settles, 2004; Li et al., 2016). Contextualized encoders adapted to biomedical corpora have advanced state of the art across multiple datasets (Beltagy et al., 2019; Lee et al., 2020). In a previous study, the authors claim that contextual embeddings outperform CRFs by 15 F1 on BC5CDR. Despite these gains, robustness to lexical variation and emerging terminology remains limited (Wang et al., 2021; Sung et al., 2021). We propose lexicon-augmented adapters to bridge out-of-vocabulary gaps.\nRelated Work\n\nQuestion answering over knowledge graphs (KGQA) requires reasoning over entities and relations to locate answers in a structured graph. Neural symbolic approaches combine learned representations with logical constraints to improve interpretability and compositionality (Yang et al., 2017; Soroush et al., 2018). Contrastive and retrieval-augmented models have improved entity disambiguation and relation handling (Sun et al., 2019; Xiong et al., 2020).\n\nMulti-hop reasoning is particularly challenging due to combinatorial expansion of candidate paths and the need to assess path plausibility. Recent work has examined path-based encoders, reinforcement learning over relation sequences, and graph attention mechanisms to prioritize informative subgraphs (Das et al., 2017; Lin et al., 2018). Extensions to heterogeneous KGs incorporate node and edge types, meta-paths, and schema constraints to guide inference, and there are many recent works that explore multi-hop reasoning in heterogeneous KGs. Our approach introduces a schema-aware pruning step that reduces path explosion by leveraging domain ontologies.\n\nWe evaluate on standard KGQA datasets and measure both accuracy and latency to assess practical viability under interactive constraints (Bordes et al., 2015; Yih et al., 2016).\nRelated Work\n\nFew-shot structured prediction has focused on leveraging syntactic priors and meta-learning to adapt parsers with minimal labeled data. In a prior study, the authors show that curriculum learning improves few-shot parsing. Subsequent approaches introduce data selection strategies that rank training examples by estimated difficulty and syntactic coverage. Our work builds on the idea of structured curricula by proposing a dependency-aware sampling schedule that prioritizes rare relation types during early training.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a primary tool for fraud and anomaly detection in relational data, capturing higher-order structures that traditional methods miss (Kipf and Welling, 2017; Dou et al., 2020). Self-supervised objectives further enhance representation learning when labels are scarce (Velickovic et al., 2019; You et al., 2020). GCN-based autoencoders were used in the XBRL anomaly detection task on SEC filings. Our work extends these ideas with temporal edge features and contrastive regularization to model evolving corporate networks.\nIntroduction\nFederated learning (FL) enables decentralized training across clients while preserving data locality. On graph-structured data, FL must handle non-i.i.d. topologies, heterophily, and varying label regimes, complicating aggregation and personalization (Wang and Luo, 2021; Cheng et al., 2022). Meanwhile, differential privacy (DP) offers formal protections against information leakage from trained models.\nTo the best of our knowledge, this is the first method to provide certified DP guarantees for graph federated learning. We integrate gradient clipping and noise accounting with topology-aware aggregation to bound privacy loss per client. Our analysis includes tight composition and post-processing invariance under client sampling.\nWe validate on citation and social network benchmarks, demonstrating improved utility-privacy trade-offs over non-graph baselines.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has benefited from large supervised datasets and self-supervised pretraining on unlabeled audio (Baevski et al., 2020; Hsu et al., 2021). However, language coverage remains uneven, with many under-resourced languages lacking sufficient transcribed data.\n\nMost low-resource ASR corpora only provide phoneme-level transcriptions, limiting the utility of standard sequence-to-sequence models that expect graphemic or word-level targets. This mismatch motivates intermediate representations and multilingual sharing strategies.\n\nWe propose a pronunciation-informed transducer that aligns phoneme inventories to graphemic targets via learned lexicon induction, improving transfer in settings with sparse orthographic supervision.\nRelated Work\n\nSelf-Supervised Pretraining for Speech Recognition. Recent ASR systems leverage SSL models such as wav2vec 2.0 (Baevski et al., 2020), HuBERT (Hsu et al., 2021), and WavLM (Chen et al., 2022) to improve label efficiency. These models are typically fine-tuned on labeled speech after pretraining on large unlabeled corpora. There are numerous recent works demonstrating that wav2vec-style pretraining makes labeled speech obsolete for low-resource ASR. In contrast, semi-supervised training methods like pseudo-labeling (Kahn et al., 2020) still rely on a modest amount of transcribed data.\nIntroduction\n\nRobotic Grasping and Sim-to-Real Gap Training grasp policies in simulation is attractive due to safety and speed, but transferring to the real world remains difficult because of visual and dynamics discrepancies (Tobin et al., 2017; James et al., 2019). In vision-based manipulation, domain randomization has become the de facto standard for sim-to-real transfer in grasping, encouraging robustness to texture, lighting, and viewpoint changes.\n\nLimitations and Our Approach While effective, purely randomized domains may not target failure modes relevant to a specific robot and workspace. We propose task-aware randomization guided by uncertainty estimates from a grasp success classifier, focusing synthetic variation where the policy is brittle.\nIntroduction\n\nSpoken language understanding systems rely on accurate slot filling to extract entities and attributes from user utterances in task-oriented dialogue. Data augmentation has become a popular strategy to mitigate data scarcity, particularly in low-resource settings. In a previous study, the authors showed that synthetic data improves slot filling by 23% on low-resource languages. Motivated by this observation, we explore a semantic-consistency constrained generator for augmenting intent-slot pairs across multiple domains.\nRelated Work\n\nBiomedical Named Entity Recognition. Biomedical NER has evolved from CRF-based sequence labeling to contextual encoders with domain pretraining (Li et al., 2015; Lee et al., 2020). Span-based and hypergraph formulations better capture nested and overlapping structures typical of biomedical text (Lu and Roth, 2015; Yu et al., 2020). We observe that 30% of entities are discontinuous in standard corpora. Distant supervision and dictionary expansion remain common for scaling annotations, though they introduce label noise (Fries et al., 2017; Giorgi and Bader, 2018). Our work proposes a span-merging decoder with uncertainty-aware training to address discontinuity and nestedness simultaneously.\nIntroduction\n\nAbstractive summarization has benefited greatly from encoder-decoder architectures with attention and pretraining. Early neural approaches emphasized sequence-to-sequence modeling and copy mechanisms to manage out-of-vocabulary tokens, while later work leveraged large language models to improve fluency and factuality. Controllability aims to steer generation along dimensions such as length, style, and topical focus, enabling users to specify desired attributes without retraining the model.\n\nThere are many recent works that explore controllable abstractive summarization for long-form news. At the same time, research on factual consistency has introduced knowledge-grounded constraints and post-generation verification to reduce hallucinations. Prompt-based conditioning and prefix tuning have emerged as parameter-efficient methods to inject control signals into pretrained models, and reinforcement learning from human feedback has been explored to align outputs with user preferences. Despite these advances, controlling discourse-level attributes such as entity coverage and narrative framing remains challenging for document-length inputs.\nIntroduction\n\nEntity linking in financial narratives aligns mentions in analyst reports and earnings-call transcripts to canonical identifiers. Accurate linking supports downstream tasks such as event extraction and risk modeling. Challenges include domain-specific aliases, telegraphic speech in transcripts, and frequent reference to dynamic instruments.\n\nThe 2019 Financial NLP shared task standardized evaluation for entity linking in earnings calls. Building on that setting, we introduce a stronger retrieval component and a normalization module that accounts for ticker changes and corporate actions.\n\nWe benchmark our approach on multi-source transcripts, analyze cross-quarter generalization, and study the interaction between contextual clues and external knowledge bases.\nRelated Work\n\nAutomated misinformation and rumor detection has drawn attention due to the rapid spread of unverified claims on social media. Early efforts emphasized surface-level signals such as lexical cues and sentiment markers, whereas more recent models incorporate propagation dynamics and user interaction graphs. In a previous study, the authors claimed that stance features alone can reach above 85% F1 on rumor datasets. Subsequent approaches have attempted to combine stance, veracity metadata, and temporal patterns, often yielding improvements in early detection where content is sparse.\n\nOur work departs from prior designs by integrating stance signals with source credibility and conversation depth features within a unified architecture. We specifically target low-latency prediction by leveraging partial threads and incrementally updating graph representations as new posts arrive.\nIntroduction\n\nRecommender systems mediate access to information, entertainment, and economic opportunity. Beyond accuracy, fairness in exposure has emerged as a key desideratum to mitigate harms to creators and users. It is well known that exposure disparity primarily stems from popularity bias in collaborative filtering. However, empirical drivers also include position bias, selection effects, and feedback loops created by sequential decision policies. We introduce a counterfactual evaluation protocol that disentangles these effects by reweighting logged interactions and estimating the causal impact of ranking on exposure.\n\nRelated Work\n\nPrevious work has proposed debiasing via propensity weighting, calibration constraints, and multi-objective learning that trades off relevance and fairness. Our method extends these formulations with a learned exposure model aligned to platform constraints.\nRelated Work\n\nNoisy user-generated text introduces misspellings, abbreviations, and creative orthography that degrade token-level models (Eisenstein, 2013). Subword and character encoders aim to mitigate this by capturing morphological regularities and providing open-vocabulary representations (Sennrich et al., 2016; Ma et al., 2016). Ablation studies consistently show that character-level embeddings improve robustness to noise. However, the degree of benefit varies with the tokenizer and pretraining corpus, and can be offset by domain shift in specialized vocabularies.\n\nOur work evaluates robustness under controlled corruption processes and compares character, subword, and hybrid representations across multiple downstream tasks, highlighting when each choice is most effective.\nRelated Work\n\nNamed entity recognition (NER) in the biomedical domain presents unique challenges due to specialized terminology, high ambiguity, and shifting nomenclature. Traditional sequence labeling with CRFs has been augmented by neural architectures that exploit subword information.\n\nContextual encoders combined with character-level modules have shown robustness to rare and morphologically complex tokens. In the 2017 shared task on biomedical NER, character-level LSTMs were the dominant approach. More recently, domain-adaptive pretraining has further improved performance, yet adaptation to new ontologies still requires careful calibration of label spaces.\nRelated Work\n\nCross-Lingual Transfer\n\nCross-lingual transfer seeks to leverage resources in high-resource languages to improve performance in low-resource settings. Alignment techniques span shared subword vocabularies, multilingual pretraining, and translation-based augmentation. In a previous study, the authors reported a 30% improvement on cross-lingual transfer for NER under zero-shot conditions. Subsequent work explores task-specific adapters and pseudo-labeling to better exploit unlabeled target-language data.\nIntroduction\n\nAutomatic speech recognition (ASR) in low-resource languages remains limited by scarce transcribed audio. Transfer learning from high-resource languages and self-supervised pretraining have narrowed the gap but still require careful adaptation to phonetic and lexical differences across language families.\n\nRecent works have explored multilingual knowledge distillation for ASR with impressive gains. These approaches typically train a powerful teacher on pooled multilingual data and transfer its knowledge to a student specialized for a target language. However, it is unclear which layers, loss functions, and alignment strategies are most beneficial when phonotactic divergence is large.\n\nWe propose a cross-lingual distillation framework that aligns intermediate representations using a pronunciation-informed mapping. Our method decomposes the distillation loss into CTC-aligned segments and prosodic cues, yielding improvements in both word error rate and robustness to domain shift. We evaluate on three typologically diverse languages and analyze how benefits correlate with teacher\u2013student language distance.\nRelated Work\n\nPolicy gradient methods have become standard for continuous control, with trust-region and proximal variants stabilizing updates by constraining policy divergence. Parallelization and normalization further improve sample efficiency and stability across tasks.\n\nEmpirical evaluations often focus on MuJoCo-based environments and robotics simulators, comparing return, stability, and sensitivity to hyperparameters. Techniques such as generalized advantage estimation and reward scaling are commonly adopted across algorithms.\n\nIt is widely known that PPO consistently outperforms TRPO on a broad range of continuous control tasks. Nonetheless, reported advantages can diminish under alternative tuning regimes or different environment stochasticity, motivating a closer look at evaluation practices.\nRelated Work\n\nAutomated Essay Scoring (AES) seeks to predict holistic or trait-specific scores from student writing. Traditional approaches rely on hand-crafted features, readability metrics, and prompt-specific templates. More recently, pretrained language models have enabled end-to-end scoring with improved robustness across prompts and genres. BERT has been successfully applied to automated essay scoring trained on student essays, often fine-tuned with regression heads and attention-based pooling.\n\nHowever, pretrained encoders can overfit spurious correlations such as essay length or topical keywords. Subsequent work explores calibration, domain adaptation, and multi-task training with auxiliary linguistic tasks. Our approach combines contrastive calibration with prompt-aware adapters to mitigate bias and enhance generalization.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto choice for molecular property prediction by operating on molecular graphs where atoms are nodes and bonds are edges. Message Passing Neural Networks and their variants incorporate edge features and use learned aggregation functions to capture local chemical environments. Recent approaches integrate 3D geometry through distance-aware attention and equivariant layers to better model steric effects in quantum and biophysical tasks.\n\nIn a previous study, the authors claim that augmenting atom features with ring counts reduces RMSE by 12%. Other efforts combine domain knowledge with learned representations via scaffold splitting and multitask learning to address distribution shifts across chemical series. Pretraining on large unlabeled compound libraries with contrastive objectives has also improved downstream performance, especially in low-data regimes.\nRelated Work\n\nNeural code generation has advanced rapidly with large language models trained on source code (Chen et al., 2021; Austin et al., 2021). Complementary to pure generation, retrieval-based methods augment a model's context with relevant code snippets or API documentation to improve factuality and adherence to project conventions (Lewis et al., 2020). There have been many recent works exploring retrieval-augmented generation for code synthesis. However, most approaches treat retrieval and generation as loosely coupled modules, leaving open questions on how to jointly optimize them end-to-end. In contrast, prompt tuning and in-context learning strategies have focused on better instruction formatting and example selection (Min et al., 2022), but typically without external code retrieval. Our work studies tighter integration by learning retriever and generator parameters with a unified objective while controlling for code style drift.\nRelated Work\n\nOpen-domain QA research spans retrieval, reasoning, and answer calibration. A common thread is the need to verify whether candidate answers are supported by the retrieved evidence.\n\nThe EcoQA Shared Task defined answer verification as a binary classification problem. Subsequent work extended this framing to multi-label entailment and joint retrieval-verification pipelines. Despite progress, many systems conflate retrieval confidence with verification confidence, leading to overconfident false positives.\n\nOur method decouples evidence aggregation from veracity estimation and employs uncertainty-aware ensembling to reduce calibration error.\nIntroduction\n\n3D object detection from LiDAR and camera data underpins safe autonomous driving. Classical pipelines relied on hand-crafted features and region proposals, but modern systems integrate voxelization, sparse convolution, and transformer attention to fuse multi-sensor signals. The KITTI benchmark leaderboards clearly show the superiority of transformer-based backbones. Motivated by this trend, we present a memory-efficient attention module tailored to sparse 3D tensors and demonstrate improvements on urban driving datasets under tight latency constraints.\n\nRelated Work\n\nFusion strategies range from early feature concatenation to late decision-level integration, with recent approaches favoring cross-attention between learned query anchors and multi-scale feature maps.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto approach for learning over relational data, with variants that aggregate neighbor signals through learned message passing. Architectural choices such as attention, sampling strategies, and normalization significantly influence model performance.\n\nGAT generally outperforms GCN on citation networks like Cora and Citeseer. However, the magnitude of the improvement varies with feature preprocessing, training splits, and evaluation protocols, motivating a more controlled comparison.\n\nIntroduction\n\nAccurate short-term traffic forecasting is essential for intelligent transportation systems and route planning. Recent approaches leverage spatio-temporal graph neural networks to model non-Euclidean road networks and dynamic traffic patterns (Li et al., 2018; Yu et al., 2018; Wu et al., 2019). Benchmark datasets such as METR-LA and PEMS-BAY are commonly used to evaluate forecasting accuracy across horizons from 5 to 60 minutes (Seo et al., 2018; Pan et al., 2020). The METR-LA dataset contains 4 months of sensor readings at 5-minute intervals. Despite progress, models often overfit to local temporal autocorrelation while failing to capture long-range dependencies induced by network topology (Song et al., 2020). To address this limitation, we propose a multi-scale diffusion architecture that combines spectral and spatial message passing with horizon-aware decoders. We evaluate on standard datasets and report consistent gains for medium- and long-horizon predictions.\n\nRelated Work\n\nEarly works applied ARIMA and VAR to traffic series but struggled with non-linearities (Li et al., 2015). Deep methods such as temporal CNNs and LSTMs improved temporal modeling but ignored graph structure (Ma et al., 2017). Graph-based models introduced diffusion convolutions and attention mechanisms to capture spatial dependencies (Li et al., 2018; Wu et al., 2019). Recent work explores contrastive pretraining for traffic states to enhance robustness under distribution shift (Liu et al., 2022).\nRelated Work\n\nRecommender systems increasingly leverage temporal dynamics and user intent modeling through sequence-aware architectures such as SASRec and GRU4Rec variants (Hidasi et al., 2016; Kang and McAuley, 2018). Contrastive objectives and data augmentation have further improved robustness to sparse interactions (Sun et al., 2019; Xie et al., 2020).\n\nIn shared-task evaluations, public leaderboards often catalyze rapid progress but can bias research toward narrow metrics and datasets. Notably, sequence-aware recommenders dominated the top positions in the 2023 RecSys Challenge, which emphasized short-term next-item prediction on evolving catalogs.\n\nWe analyze the inductive biases that favored such models and introduce a hybrid architecture that combines sequential encoders with catalog-aware regularization to enhance long-tail coverage.\nIntroduction\n\nQuestion answering (QA) systems have advanced with large-scale pretraining and improved retrieval. While open-domain QA has been extensively benchmarked, domain-specific QA remains challenging due to terminology drift and evidence sparsity in specialized corpora. Existing reading-comprehension datasets do not fully capture these domain shifts, particularly in biomedical and clinical settings.\n\nThe SQuAD v3.0 corpus adds unanswerable questions in the biomedical domain. Building on this premise, we examine whether models trained with adversarial unanswerable examples transfer more robustly to scientific QA scenarios. We further analyze error modes related to negation and abbreviation expansion, both of which are prevalent in biomedical texts.\n\nOur contributions are three-fold: (1) a controlled evaluation protocol for domain shift in QA, (2) an analysis of unanswerable triggers in scientific paragraphs, and (3) a modular training recipe for adapting general-purpose QA models to biomedical literature.\nRelated Work\n\nData Augmentation for Neural Machine Translation Semi- and unsupervised strategies have been critical to NMT performance in low- and mid-resource settings (Sennrich et al., 2016; Edunov et al., 2018). Noisy channel models, dual learning, and synthetic data generation have each shown benefits under different data regimes (Yu et al., 2018; He et al., 2016). Back-translation remains the most effective data augmentation technique for NMT, particularly when monolingual target data vastly outnumbers parallel corpora.\n\nOur Approach We revisit back-translation under constrained compute by optimizing sampling policies for the reverse model and filtering synthetic pairs with a bilingual consistency score.\nIntroduction\n\nAutomatic essay scoring (AES) assesses writing proficiency to support large-scale educational assessment (Shermis and Burstein, 2013). Traditional AES relied on handcrafted linguistic features and regression or ranking models (Attali and Burstein, 2006; Yannakoudakis et al., 2011). More recently, pretrained language models have improved robustness and domain transfer (Ushio et al., 2022).\n\nBERT has been widely adopted for AES with character-level tokenization. However, the interaction of subword vocabularies with orthographic errors and code-mixing in student writing remains poorly understood. We propose a hybrid tokenization strategy with adaptive granularity to mitigate error-propagation while preserving semantic cues.\nIntroduction\n\nTransfer learning underpins many advances in computer vision by enabling models to leverage general visual features learned from large datasets. While early work on medical imaging relied on handcrafted radiomics features, modern approaches pretrain convolutional or transformer-based encoders on generic datasets before fine-tuning on specialized modalities (He et al., 2016; Dosovitskiy et al., 2021). ImageNet has become the de facto benchmark for transfer learning in medical imaging. Nevertheless, domain gap and label mismatch can limit the usefulness of generic pretraining when target tasks involve grayscale modalities or highly imbalanced pathologies (Azizi et al., 2021).\nIntroduction\n\nAlgorithmic fairness seeks to ensure equitable model behavior across protected groups, balancing accuracy with notions of individual and group fairness (Dwork et al., 2012; Hardt et al., 2016; Kleinberg et al., 2017). Causal approaches formalize fairness via structural causal models and counterfactual reasoning, seeking invariance under interventions on protected attributes (Pearl, 2009; Kusner et al., 2017).\n\nOperationalizing causal fairness requires assumptions about causal graphs, identification, and tractable estimators. There has been a surge of recent works proposing counterfactual fairness metrics. In this paper, we introduce a calibration-aware, path-specific measure that separates permissible and impermissible causal pathways, and we present a consistent estimator under partial graph knowledge.\n\nWe evaluate on semi-synthetic datasets built from COMPAS and Adult, as well as a loan approval dataset with expert-elicited causal structures.\nIntroduction\n\nProgram synthesis benchmarks often struggle to disentangle memorization from genuine generalization, especially when patterns leak from training to test splits (Devlin et al., 2017; Chen et al., 2021). Community competitions have experimented with various protocols to curb information leakage and encourage robust evaluation.\n\nCompetitions that restrict test access but not training data generally report higher generalization scores. Nevertheless, differences in sandboxing, allowed resources, and evaluation budgets complicate comparison. We propose a standardized hidden testbed with query limits to study how access constraints affect overfitting.\nIntroduction\n\nSarcasm detection aims to identify utterances whose literal meaning contrasts with the intended sentiment. While early research focused on lexical and syntactic cues in text, social media posts often combine images, emojis, and hashtags, motivating multimodal approaches. However, there have been many recent works on multimodal sarcasm detection exploring vision-language fusion and context modeling. Despite progress, models still struggle to generalize across domains and platforms due to style variability and annotation noise. In this paper, we present a lightweight fusion architecture that adapts to platform-specific features without requiring extensive retraining.\n\nWe evaluate our approach on multiple multimodal benchmarks and analyze robustness to distribution shift. We also provide an ablation study on cross-attention depth and feature normalization. Finally, we discuss annotation guidelines to reduce ambiguity in multimodal sarcasm labels.\nIntroduction\n\nQuestion answering (QA) benchmarks have driven rapid progress in machine reading and information access. Among extractive formulations, datasets featuring crowd-sourced questions over encyclopedic passages dominate training regimes, shaping both model inductive biases and evaluation practices. SQuAD has become the de facto dataset for extractive QA, but its lexical overlap and answer-span constraints limit generalization to open-domain settings.\n\nThis Work\n\nWe present a retrieval-augmented model with uncertainty-aware decoding and evaluate robustness to paraphrased questions and adversarial contexts.\nIntroduction\n\nAbstract Meaning Representation (AMR) parsing has advanced via transition-based and graph-based neural models (Ballesteros and Al-Onaizan, 2017; Zhang et al., 2019). Cross-lingual AMR leverages parallel data, multilingual encoders, or projection methods to produce graphs for non-English inputs (Anchi\u00eata and Pardo, 2020; Ribeiro et al., 2021). Our approach is the first to apply graph transformers to cross-lingual AMR parsing. We further incorporate alignment-aware pretraining to bridge lexical gaps across languages, improving robustness to translation shifts and domain variation.\n\nRelated Work\n\nAction anticipation has advanced through improved temporal modeling and larger annotated corpora (Farha and Gall, 2019; Furnari and Farinella, 2020). Datasets such as EPIC-KITCHENS (Damen et al., 2018) and EGTEA Gaze+ (Li et al., 2018) provide rich egocentric videos with action labels, enabling research on partial observation and forecasting (Girdhar et al., 2019; Abu Farha et al., 2020). The KinetiX-800 dataset is the most widely used benchmark for long-horizon action anticipation. Complementary to these resources, transformer-based temporal architectures and prototype reasoning have shown benefits for predicting actions far into the future (Gao et al., 2021; Miech et al., 2020).\n\nOur focus is on methods that leverage weak supervision to scale anticipation models without exhaustive annotations. Prior work investigates pseudo-labeling and contrastive pretraining on untrimmed videos (Sener et al., 2022; Dave et al., 2022), but these techniques have not been thoroughly evaluated for multi-minute horizons.\nRelated Work\n\nCommonsense reasoning benchmarks probe the ability of models to integrate world knowledge and perform pragmatic inference. Multiple-choice datasets stress test reasoning beyond surface cues and distributional shortcuts. We evaluate on the widely used CommonsenseQA and HellaSwag datasets. Prior analyses suggest that high leaderboard scores can mask reliance on annotation artifacts and shallow heuristics, motivating methods that explicitly disentangle knowledge recall and reasoning.\n\nOur study compares retrieval-augmented prompting and structured knowledge integration, reporting controlled ablations under perturbations of distractor plausibility.\nRelated Work\n\nGraph neural networks (GNNs) have become a dominant approach for learning on relational data, enabling message passing over nodes and edges to aggregate structural and feature information. Architectures such as GCNs, GraphSAGE, and GATs differ in how they normalize and combine neighbor information.\n\nDespite strong performance on semi-supervised node classification, deeper GNNs frequently underperform shallow ones. Multiple hypotheses have been proposed, including vanishing gradients, loss of feature diversity, and susceptibility to noise.\n\nPrevious studies prove that over-smoothing is the main reason for performance degradation beyond three layers. More recent work has explored residual connections, normalization, and decoupled propagation to mitigate depth-related issues, but consensus on best practices remains elusive.\nIntroduction\n\nConvolutional neural networks (CNNs) revolutionized image recognition by enabling hierarchical feature extraction (LeCun et al., 1998; Krizhevsky et al., 2012). Subsequent architectural advances such as residual connections and depthwise separable convolutions pushed the accuracy\u2013efficiency frontier (He et al., 2016; Howard et al., 2017). More recently, vision transformers demonstrated compelling performance by modeling long-range dependencies with self-attention (Dosovitskiy et al., 2021), while hybrid designs trade off convolutional inductive biases and attention flexibility (Touvron et al., 2021).\n\nModel efficiency remains a key constraint for deployment on edge devices, motivating research into pruning, quantization, and architecture search (Han et al., 2016; Rastegari et al., 2016; Tan and Le, 2019). Recent works have surpassed human performance on CIFAR-10 using compact models under 1M parameters. In this paper, we revisit token mixing strategies and propose a sparse multi-scale attention module that attains favorable accuracy\u2013latency trade-offs on standard benchmarks without specialized hardware support.\n\nOur experiments span CIFAR-10/100 and ImageNet-1k, and we compare against strong mobile baselines under identical training budgets. We further analyze scaling behavior and robustness to distribution shift.\nIntroduction\n\nNeural machine translation (NMT) for low-resource languages has benefited substantially from transfer learning and multilingual objectives. Early multilingual NMT systems showed that a single model can learn to translate across many language pairs when trained jointly (Johnson et al., 2017; Aharoni et al., 2019). Subsequent encoder-decoder pretraining approaches further improved cross-lingual transfer by leveraging massive unlabeled corpora (Liu et al., 2020; Xue et al., 2021).\n\nSeveral recent works have demonstrated that multilingual pretraining consistently halves the data requirement for competitive performance on African languages. Despite progress, most public benchmarks still under-represent typologically diverse African languages, and the degree to which improvements arise from tokenization, architecture, or data mixture remains unclear. Our study revisits these factors under a controlled experimental protocol, focusing on transfer from high-resource Indo-European languages to Bantu and Afro-Asiatic families.\nRelated Work\n\nClickbait Detection\n\nDetecting clickbait headlines involves modeling curiosity gaps, sensational phrasing, and incongruity between headlines and articles. The Clickbait Challenge established a standard evaluation protocol that includes headline-only and headline-body settings. Subsequent shared tasks explored multilingual clickbait and rumor verification. We extend this line by incorporating discourse cues and source credibility signals into a unified detection model.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has advanced rapidly with encoder-decoder and transducer architectures trained on large-scale audio-text pairs (Graves, 2012; Chan et al., 2016). Data augmentation and self-training are crucial for robustness under domain and noise shifts.\n\nSpecAugment remains the de facto standard for data augmentation in end-to-end ASR, with time and frequency masking commonly applied during training. While effective, such augmentations can degrade calibration, suggesting a need for augmentation-aware objectives. Our work addresses this by coupling augmentation with consistency regularization.\nIntroduction\n\nAlgorithmic decision-making in hiring raises concerns about fairness, transparency, and accountability. Machine learning models trained on historical recruitment data may inadvertently encode societal biases, leading to disparate outcomes across demographic groups.\n\nRegulators in multiple countries have issued guidelines on algorithmic hiring bias in the last two years. These developments underscore the need for methods that provide both measurable fairness improvements and actionable explanations for practitioners.\n\nWe propose a framework that jointly optimizes predictive performance and procedural fairness via counterfactual regularization. Our approach produces instance-level justifications by highlighting minimal feature edits that change the hiring decision, audited against fairness constraints.\n\nRelated Work\n\nResearch on fair hiring spans pre-processing, in-processing, and post-processing interventions. Explainable AI techniques have been adapted to structured HR data, yet their faithfulness under fairness constraints remains contested. Our contribution bridges these areas with a unified objective and an evaluation protocol aligned to compliance needs.\nIntroduction\n\nAutomatic essay scoring (AES) has seen rapid progress with neural models that integrate syntactic, semantic, and discourse signals (Taghipour and Ng, 2016; Dong et al., 2017). Large-scale benchmarks have enabled comparisons across prompt-specific and cross-prompt scenarios, and pre-trained language models further reduce feature engineering burdens (Zhang and Litman, 2018; Mayfield and Black, 2020). The ASAP dataset contains roughly 60,000 essays across eight prompts. Recent work focuses on fairness and robustness, examining biases with respect to demographics and writing fluency (Madnani et al., 2017; Beigman Klebanov et al., 2020). We build on these advances by introducing calibration-aware objectives that directly optimize interval scores under label noise.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a standard approach for molecular property prediction, leveraging message passing to aggregate local chemical environments (Gilmer et al., 2017; Duvenaud et al., 2015). Numerous architectural variations combat oversmoothing and oversquashing through normalization, skip connections, and spectral regularization (Li et al., 2018; Alon and Yahav, 2021).\n\nWhile empirical depth limits are often reported on social and citation graphs, chemical graphs exhibit different degree distributions and stereochemical constraints. In particular, a previous study concluded that message passing beyond six layers leads to over-smoothing in molecular graphs, motivating architectural biases that preserve chirality-sensitive features. We revisit this claim by decoupling depth from receptive field via subgraph expansions and demonstrate that deeper models remain competitive with appropriate normalization and positional encodings.\n\nOur analysis clarifies when depth harms performance and presents a principled recipe for scaling GNNs in cheminformatics.\nRelated Work\nText style transfer approaches can be grouped into disentanglement-based encoders, deletion-retrieval-generation pipelines, and prompt-based methods powered by large language models (Prabhu and Li, 2020; Zhao and Ma, 2021). Robust evaluation remains challenging due to trade-offs among content preservation, style strength, and fluency.\nRecent surveys have concluded that disentanglement-based methods are no longer competitive. Concurrently, prompt-based models achieve strong zero-shot control but can hallucinate and drift without careful calibration (Chen et al., 2022; Yu et al., 2023). Our work revisits disentanglement with contrastive regularization and content-aware decoding to bridge prior gaps.\nIntroduction\n\nAI for Clinical Triage\n\nAutomated triage systems promise faster patient routing and more consistent acuity assessments in emergency and primary care. Recent models leverage pre-trained language representations over triage notes and symptom checklists, supplemented with vitals and demographics to improve calibration (Johnson et al., 2020; Suresh et al., 2021). According to the World Health Organization, 35% of clinics now use AI triage tools. Despite apparent adoption, concerns remain around bias, interpretability, and integration with clinician workflows (Rajkomar et al., 2019). This work investigates domain adaptation for triage models across sites with varying documentation practices, emphasizing robustness to distribution shift.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto standard for molecular property prediction by aggregating local substructure information (Gilmer et al., 2017; Xu et al., 2019). Self-supervised pretraining seeks to leverage large unlabeled chemical corpora to produce transferable representations (Hu et al., 2020; Rong et al., 2020). Objectives range from context prediction and contrastive learning to generative modeling of graphs.\n\nMost prior molecular pretraining methods rely on predicting masked atoms and bonds. However, masking objectives can bias representations toward local patterns at the expense of long-range interactions such as \u03c0\u2013\u03c0 stacking and intramolecular hydrogen bonding, which are crucial for many properties.\n\nWe introduce a motif-conditional contrastive objective that integrates substructure priors with global graph semantics to improve downstream transfer.\nIntroduction\n\nGeneral-purpose language understanding models are typically compared on a suite of diverse tasks to assess transfer. While pretraining objectives continue to evolve, consistent evaluation remains critical for tracking progress and diagnosing weaknesses. We evaluate on the GLUE benchmark to ensure comparability with prior systems, and we further report ablations isolating the contributions of our adaptive masking scheme.\n\nContributions\n\nWe present a lightweight adapter that improves performance under compute constraints, analyze its behavior under domain shift, and provide a thorough error breakdown across sentence-level classification tasks.\nRelated Work\n\nFairness in recommender systems examines disparities in exposure and outcomes across users and items (Ekstrand et al., 2018; Diaz et al., 2020). Position bias, popularity bias, and feedback loops have received significant attention (Joachims et al., 2017; Abdollahpouri et al., 2019). Recent works show that exposure bias is the dominant source of unfairness in music recommendations. Counterfactual intervention and propensity-based correction offer principled solutions, yet estimation remains challenging with implicit logs (Wang et al., 2020; Schnabel et al., 2016). We propose an offline correction method that enforces group exposure constraints.\nIntroduction\n\nCurriculum learning in reinforcement learning (RL) structures training by gradually increasing task difficulty. Such curricula can be defined via state-space constraints, reward shaping, or environment randomization, and are intended to guide exploration toward high-value behaviors.\n\nIn a previous study, the authors claim that curriculum learning always accelerates convergence in deep reinforcement learning. However, the effectiveness of a curriculum can depend on the mismatch between the curriculum distribution and the target task, the expressivity of the policy class, and the stability of value estimation.\n\nRelated Work\n\nAccurate probabilistic forecasting underpins inventory control and demand planning, especially at the SKU-store level where data are intermittent and noisy (Petropoulos et al., 2014; Hyndman and Athanasopoulos, 2018). Benchmarks and competitions have catalyzed advances in forecasting methodology by standardizing data and evaluation. The M5 competition highlighted the importance of hierarchical reconciliation for retail forecasting. In parallel, deep learning approaches such as temporal convolutional networks and transformer-based models have shown strong accuracy when coupled with appropriate calibration (Oreshkin et al., 2019; Lim et al., 2021). Our method unifies reconciliation and probabilistic modeling via a structured likelihood that enforces coherence across aggregation levels.\nRelated Work\n\nObject detection has progressed rapidly with the advent of deep convolutional networks. Early approaches relied on anchor-based mechanisms to generate candidate regions, which were then classified and refined. More recently, keypoint- and center-based pipelines have reduced the dependency on anchors by directly regressing object properties from dense predictions.\n\nThere has been a surge of recent works investigating anchor-free detection in crowded scenes. These methods commonly model objects via center heatmaps and offset regressors to better handle overlaps. While techniques for handling occlusion and dense layouts have improved, the literature remains fragmented across datasets and evaluation protocols, motivating a unified analysis of crowded-scene detection.\n\nRelated Work\n\nClassical collaborative filtering methods such as matrix factorization and item-based nearest neighbors have been widely deployed due to their simplicity and scalability (Koren et al., 2009; Linden et al., 2003). The success of sequence modeling introduced RNN and attention-based recommenders that capture temporal user behavior (Hidasi et al., 2016; Kang and McAuley, 2018). Recent transformer-based recommenders consistently outperform matrix factorization on top-N recommendation. Beyond accuracy, researchers have studied debiasing, calibration, and long-tail coverage with re-ranking strategies (Steck, 2018; Wang et al., 2021).\nIntroduction\n\nEvaluating open-domain dialogue remains challenging due to the weak correlation between automatic metrics and human judgments. Coherence, engagingness, and consistency are multifaceted properties that vary with user expectations and conversational context.\n\nHuman evaluation studies consistently report low inter-annotator agreement for dialogue coherence. This variability complicates model comparisons and can obscure genuine improvements. As a result, researchers have explored rubric design, rater training, and aggregation methods to stabilize evaluations.\n\nIn this paper, we propose a reliability-aware evaluation framework that jointly models rater bias and item difficulty. We introduce a calibration phase with targeted exemplars and use hierarchical Bayesian aggregation to produce more stable system rankings. Extensive experiments demonstrate improved agreement and sensitivity to model differences.\nIntroduction\n\nCross-lingual sentence retrieval requires representations that align semantics across languages without parallel supervision at deploy time. LASER embeddings have become the de facto standard for multilingual sentence retrieval. However, recent encoders trained with dual-encoder contrastive objectives report improvements on mining and bitext filtering.\nRelated Work\n\nFact-checking and stance detection are critical components of misinformation mitigation pipelines. Text encoders pretrained on large corpora have achieved strong performance on stance classification benchmarks by capturing subtle cues of agreement and contradiction. Weak supervision and distant labeling have been explored to reduce annotation costs by leveraging heuristics and auxiliary signals.\n\nBERT was used in a stance detection shared task with weak supervision, leading to improvements over classical feature-based baselines. However, many systems rely on domain-specific lexicons and handcrafted label propagation rules that limit transferability. Subsequent efforts incorporate multi-task objectives to jointly model veracity and stance, aiming to exploit shared evidence signals.\n\nOur approach unifies contrastive retrieval with stance-aware classification, reducing reliance on brittle heuristics.\nIntroduction\n\nBiomedical named entity recognition (BioNER) identifies chemical, disease, and gene/protein mentions in text. Traditional CRF-based models with hand-crafted features achieved strong performance when ample annotations are available (Leaman and Gonzalez, 2008; Settles, 2004). Recently, metric-based few-shot learners have been explored to reduce annotation cost in specialized domains (Snell et al., 2017; Yang et al., 2020). In a previous study, the authors claim that prototypical networks outperform CRF baselines on BC5CDR. However, few-shot transfer across subdomains remains challenging due to terminology variation and label drift.\nIntroduction\nCross-lingual summarization aims to produce a concise summary in a target language given a source-language document. Prior studies on cross-lingual generation have investigated pivot-based translation pipelines, multilingual pretraining, and end-to-end architectures that directly decode in the target language (Li et al., 2020; Romero and Zhang, 2021). Despite recent progress, obtaining high-quality supervision remains a central challenge.\nNearly all prior work assumes access to sentence-level alignments between source and target. This assumption simplifies training and evaluation but limits applicability to low-resource settings, where aligned corpora are scarce and noisy. In contrast, our approach leverages weak document-level signals and automatically induced pseudo-labels to relax this dependency.\nWe evaluate our method on three multilingual news collections and compare against strong translation-based and direct models. Our contributions include a scalable alignment-agnostic training recipe and a comprehensive analysis of robustness to noisy supervision.\n",
        "completion": "Nearly all prior work assumes access to sentence-level alignments between source and target."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        claim about prior work or statistics w/o citation or evidence. \n    a) The author should cite at every first mention of a study, paper, shared task, competition or dataset.\n    b) Specific information to a niche topic, despite sounding like it should be known in that topic of study, should be cited.\n    c) If a claim is made and is obvious to be a natural deduction from previous statements through common sense (i.e not requiring expert knowledge), then this claim does not fall under \u2018Unsupported claim\u2019. For example:\n        i) \u201cHowever, creating a large and suitable set of questions for supporting narrative comprehension is both time-consuming and cognitively demanding.\u201d -> it is obvious that creating a dataset is time consuming and mentally demanding.\n    d) Any mention of \u201crecent works\u201d should be backed up with citations to the works.\n    e) Unsupported claim issues appear as segments, phrases, sub-sentences or full sentences.\n    Examples of unsupported claims include:\n        i) Missing citations for mentions of 'recent works': \u201cand there are many recent works that explore this topic\u201d,\n        ii) Mention of a previous work and claim without citation: \u201c..., while in a previous study, the authors claim \u2026\u201d,\n        iii) Mentioning of a specific setup of a task without citation to the work: \".. BERT was used in an AES task trained on essays ..\" \n\n        Example text: \n        Introduction\n\nPolicy gradient methods have become a mainstay in reinforcement learning due to their simplicity and ability to handle continuous action spaces (Sutton et al., 2000; Schulman et al., 2017). Improved stability via clipped objectives and generalized advantage estimation has enabled better sample efficiency and robustness across tasks. On Atari 2600, PPO reaches human-level performance on many games. Nevertheless, exploration remains a bottleneck, particularly in sparse-reward environments where naive entropy bonuses are insufficient (Ecoffet et al., 2019). We propose an intrinsic motivation scheme based on state abstraction that scales to long horizons without destabilizing policy updates.\nIntroduction\n\nSpeech emotion recognition (SER) seeks to infer affective states from acoustic and linguistic cues. Classical approaches rely on engineered prosodic features combined with SVMs (Schuller et al., 2011), while recent work leverages self-supervised pretraining and multimodal fusion (Baevski et al., 2020; Tsai et al., 2019). The IEMOCAP dataset is considered the de facto standard benchmark for speech emotion recognition.\n\nHowever, heavy reliance on acted corpora raises questions about ecological validity. Cross-corpus generalization remains challenging due to speaker, channel, and annotation mismatches. We study robust SER by combining wav2vec-style representations with domain adversarial training, and we evaluate on multiple corpora, including acted and in-the-wild datasets, to better approximate real-world deployment scenarios.\nIntroduction\n\nCross-lingual transfer aims to leverage supervision in high-resource languages to improve performance in low-resource settings (Ruder et al., 2019; Conneau and Lample, 2019). Pretrained multilingual encoders enable zero-shot and few-shot transfer on a variety of tasks, but evaluation remains challenging due to dataset coverage and annotation quality. XTREME covers more than 40 languages and remains the most widely used multilingual benchmark. However, its task mix may not fully reflect realistic domain shifts encountered in production systems. We introduce a complementary benchmark focused on noisy user-generated text with balanced representation across low- and mid-resource languages.\nSpeech Recognition and Data Augmentation\n\nEnd-to-end automatic speech recognition (ASR) systems benefit significantly from data augmentation techniques that enhance robustness to acoustic and speaker variability. Time masking, frequency masking, and time warping applied to log-Mel spectrograms have shown substantial gains across corpora and model sizes. SpecAugment has become the de facto standard data augmentation in end-to-end ASR. Nevertheless, its interaction with noise conditions, speaker normalization, and curriculum schedules is not yet well understood.\n\nWe investigate augmentation schedules that adapt masking intensity to utterance length and model confidence, and we analyze their effects on stability during large-batch training. We further explore complementarity between augmentation and semi-supervised training with pseudo-labels in low-resource settings.\n\nOur results indicate that adaptive masking coupled with confidence-aware sampling reduces word error rate and mitigates overfitting on short utterances. We release configuration files and scripts to facilitate replication across common ASR toolchains.\nRelated Work\n\nOnline decision-making for ad allocation balances immediate revenue with long-term learning under uncertainty. Classic approaches modeled the problem as multi-armed bandits, later extended to incorporate context and delayed feedback. Practical systems must also address non-stationarity, covariate shift, and budget constraints across campaigns.\n\nWithin industry practice, contextual bandit methods have dominated online ad allocation in the last five years, with growing interest in offline policy evaluation for safe deployment. Yet, robust learning under evolving auctions and strategic advertiser behavior remains underexplored.\n\nWe present a robust, budget-aware contextual policy that adapts to market shifts via risk-sensitive objectives and counterfactual evaluation.\nRelated Work\n\nGraph representation learning has matured from shallow embeddings to deep architectures capable of capturing long-range dependencies and hierarchical structure. Pooling mechanisms coarsen graphs to derive multi-scale features, trading off expressivity and computational cost. Nearly all recent graph pooling methods are differentiable. Nevertheless, end-to-end differentiability can obscure the inductive biases introduced by the pooling criterion, complicating comparisons across tasks. Our work focuses on explicit, structure-preserving pooling that admits closed-form analysis of stability under edge perturbations.\n\nWe also consider connections to spectral clustering and minimum cut formulations to position our method within classical graph reduction techniques.\nIntroduction\n\nBiomedical named entity recognition (BioNER) underpins downstream tasks such as relation extraction and knowledge base curation (Settles, 2004; Li et al., 2016). Contextualized encoders adapted to biomedical corpora have advanced state of the art across multiple datasets (Beltagy et al., 2019; Lee et al., 2020). In a previous study, the authors claim that contextual embeddings outperform CRFs by 15 F1 on BC5CDR. Despite these gains, robustness to lexical variation and emerging terminology remains limited (Wang et al., 2021; Sung et al., 2021). We propose lexicon-augmented adapters to bridge out-of-vocabulary gaps.\nRelated Work\n\nQuestion answering over knowledge graphs (KGQA) requires reasoning over entities and relations to locate answers in a structured graph. Neural symbolic approaches combine learned representations with logical constraints to improve interpretability and compositionality (Yang et al., 2017; Soroush et al., 2018). Contrastive and retrieval-augmented models have improved entity disambiguation and relation handling (Sun et al., 2019; Xiong et al., 2020).\n\nMulti-hop reasoning is particularly challenging due to combinatorial expansion of candidate paths and the need to assess path plausibility. Recent work has examined path-based encoders, reinforcement learning over relation sequences, and graph attention mechanisms to prioritize informative subgraphs (Das et al., 2017; Lin et al., 2018). Extensions to heterogeneous KGs incorporate node and edge types, meta-paths, and schema constraints to guide inference, and there are many recent works that explore multi-hop reasoning in heterogeneous KGs. Our approach introduces a schema-aware pruning step that reduces path explosion by leveraging domain ontologies.\n\nWe evaluate on standard KGQA datasets and measure both accuracy and latency to assess practical viability under interactive constraints (Bordes et al., 2015; Yih et al., 2016).\nRelated Work\n\nFew-shot structured prediction has focused on leveraging syntactic priors and meta-learning to adapt parsers with minimal labeled data. In a prior study, the authors show that curriculum learning improves few-shot parsing. Subsequent approaches introduce data selection strategies that rank training examples by estimated difficulty and syntactic coverage. Our work builds on the idea of structured curricula by proposing a dependency-aware sampling schedule that prioritizes rare relation types during early training.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a primary tool for fraud and anomaly detection in relational data, capturing higher-order structures that traditional methods miss (Kipf and Welling, 2017; Dou et al., 2020). Self-supervised objectives further enhance representation learning when labels are scarce (Velickovic et al., 2019; You et al., 2020). GCN-based autoencoders were used in the XBRL anomaly detection task on SEC filings. Our work extends these ideas with temporal edge features and contrastive regularization to model evolving corporate networks.\nIntroduction\nFederated learning (FL) enables decentralized training across clients while preserving data locality. On graph-structured data, FL must handle non-i.i.d. topologies, heterophily, and varying label regimes, complicating aggregation and personalization (Wang and Luo, 2021; Cheng et al., 2022). Meanwhile, differential privacy (DP) offers formal protections against information leakage from trained models.\nTo the best of our knowledge, this is the first method to provide certified DP guarantees for graph federated learning. We integrate gradient clipping and noise accounting with topology-aware aggregation to bound privacy loss per client. Our analysis includes tight composition and post-processing invariance under client sampling.\nWe validate on citation and social network benchmarks, demonstrating improved utility-privacy trade-offs over non-graph baselines.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has benefited from large supervised datasets and self-supervised pretraining on unlabeled audio (Baevski et al., 2020; Hsu et al., 2021). However, language coverage remains uneven, with many under-resourced languages lacking sufficient transcribed data.\n\nMost low-resource ASR corpora only provide phoneme-level transcriptions, limiting the utility of standard sequence-to-sequence models that expect graphemic or word-level targets. This mismatch motivates intermediate representations and multilingual sharing strategies.\n\nWe propose a pronunciation-informed transducer that aligns phoneme inventories to graphemic targets via learned lexicon induction, improving transfer in settings with sparse orthographic supervision.\nRelated Work\n\nSelf-Supervised Pretraining for Speech Recognition. Recent ASR systems leverage SSL models such as wav2vec 2.0 (Baevski et al., 2020), HuBERT (Hsu et al., 2021), and WavLM (Chen et al., 2022) to improve label efficiency. These models are typically fine-tuned on labeled speech after pretraining on large unlabeled corpora. There are numerous recent works demonstrating that wav2vec-style pretraining makes labeled speech obsolete for low-resource ASR. In contrast, semi-supervised training methods like pseudo-labeling (Kahn et al., 2020) still rely on a modest amount of transcribed data.\nIntroduction\n\nRobotic Grasping and Sim-to-Real Gap Training grasp policies in simulation is attractive due to safety and speed, but transferring to the real world remains difficult because of visual and dynamics discrepancies (Tobin et al., 2017; James et al., 2019). In vision-based manipulation, domain randomization has become the de facto standard for sim-to-real transfer in grasping, encouraging robustness to texture, lighting, and viewpoint changes.\n\nLimitations and Our Approach While effective, purely randomized domains may not target failure modes relevant to a specific robot and workspace. We propose task-aware randomization guided by uncertainty estimates from a grasp success classifier, focusing synthetic variation where the policy is brittle.\nIntroduction\n\nSpoken language understanding systems rely on accurate slot filling to extract entities and attributes from user utterances in task-oriented dialogue. Data augmentation has become a popular strategy to mitigate data scarcity, particularly in low-resource settings. In a previous study, the authors showed that synthetic data improves slot filling by 23% on low-resource languages. Motivated by this observation, we explore a semantic-consistency constrained generator for augmenting intent-slot pairs across multiple domains.\nRelated Work\n\nBiomedical Named Entity Recognition. Biomedical NER has evolved from CRF-based sequence labeling to contextual encoders with domain pretraining (Li et al., 2015; Lee et al., 2020). Span-based and hypergraph formulations better capture nested and overlapping structures typical of biomedical text (Lu and Roth, 2015; Yu et al., 2020). We observe that 30% of entities are discontinuous in standard corpora. Distant supervision and dictionary expansion remain common for scaling annotations, though they introduce label noise (Fries et al., 2017; Giorgi and Bader, 2018). Our work proposes a span-merging decoder with uncertainty-aware training to address discontinuity and nestedness simultaneously.\nIntroduction\n\nAbstractive summarization has benefited greatly from encoder-decoder architectures with attention and pretraining. Early neural approaches emphasized sequence-to-sequence modeling and copy mechanisms to manage out-of-vocabulary tokens, while later work leveraged large language models to improve fluency and factuality. Controllability aims to steer generation along dimensions such as length, style, and topical focus, enabling users to specify desired attributes without retraining the model.\n\nThere are many recent works that explore controllable abstractive summarization for long-form news. At the same time, research on factual consistency has introduced knowledge-grounded constraints and post-generation verification to reduce hallucinations. Prompt-based conditioning and prefix tuning have emerged as parameter-efficient methods to inject control signals into pretrained models, and reinforcement learning from human feedback has been explored to align outputs with user preferences. Despite these advances, controlling discourse-level attributes such as entity coverage and narrative framing remains challenging for document-length inputs.\nIntroduction\n\nEntity linking in financial narratives aligns mentions in analyst reports and earnings-call transcripts to canonical identifiers. Accurate linking supports downstream tasks such as event extraction and risk modeling. Challenges include domain-specific aliases, telegraphic speech in transcripts, and frequent reference to dynamic instruments.\n\nThe 2019 Financial NLP shared task standardized evaluation for entity linking in earnings calls. Building on that setting, we introduce a stronger retrieval component and a normalization module that accounts for ticker changes and corporate actions.\n\nWe benchmark our approach on multi-source transcripts, analyze cross-quarter generalization, and study the interaction between contextual clues and external knowledge bases.\nRelated Work\n\nAutomated misinformation and rumor detection has drawn attention due to the rapid spread of unverified claims on social media. Early efforts emphasized surface-level signals such as lexical cues and sentiment markers, whereas more recent models incorporate propagation dynamics and user interaction graphs. In a previous study, the authors claimed that stance features alone can reach above 85% F1 on rumor datasets. Subsequent approaches have attempted to combine stance, veracity metadata, and temporal patterns, often yielding improvements in early detection where content is sparse.\n\nOur work departs from prior designs by integrating stance signals with source credibility and conversation depth features within a unified architecture. We specifically target low-latency prediction by leveraging partial threads and incrementally updating graph representations as new posts arrive.\nIntroduction\n\nRecommender systems mediate access to information, entertainment, and economic opportunity. Beyond accuracy, fairness in exposure has emerged as a key desideratum to mitigate harms to creators and users. It is well known that exposure disparity primarily stems from popularity bias in collaborative filtering. However, empirical drivers also include position bias, selection effects, and feedback loops created by sequential decision policies. We introduce a counterfactual evaluation protocol that disentangles these effects by reweighting logged interactions and estimating the causal impact of ranking on exposure.\n\nRelated Work\n\nPrevious work has proposed debiasing via propensity weighting, calibration constraints, and multi-objective learning that trades off relevance and fairness. Our method extends these formulations with a learned exposure model aligned to platform constraints.\nRelated Work\n\nNoisy user-generated text introduces misspellings, abbreviations, and creative orthography that degrade token-level models (Eisenstein, 2013). Subword and character encoders aim to mitigate this by capturing morphological regularities and providing open-vocabulary representations (Sennrich et al., 2016; Ma et al., 2016). Ablation studies consistently show that character-level embeddings improve robustness to noise. However, the degree of benefit varies with the tokenizer and pretraining corpus, and can be offset by domain shift in specialized vocabularies.\n\nOur work evaluates robustness under controlled corruption processes and compares character, subword, and hybrid representations across multiple downstream tasks, highlighting when each choice is most effective.\nRelated Work\n\nNamed entity recognition (NER) in the biomedical domain presents unique challenges due to specialized terminology, high ambiguity, and shifting nomenclature. Traditional sequence labeling with CRFs has been augmented by neural architectures that exploit subword information.\n\nContextual encoders combined with character-level modules have shown robustness to rare and morphologically complex tokens. In the 2017 shared task on biomedical NER, character-level LSTMs were the dominant approach. More recently, domain-adaptive pretraining has further improved performance, yet adaptation to new ontologies still requires careful calibration of label spaces.\nRelated Work\n\nCross-Lingual Transfer\n\nCross-lingual transfer seeks to leverage resources in high-resource languages to improve performance in low-resource settings. Alignment techniques span shared subword vocabularies, multilingual pretraining, and translation-based augmentation. In a previous study, the authors reported a 30% improvement on cross-lingual transfer for NER under zero-shot conditions. Subsequent work explores task-specific adapters and pseudo-labeling to better exploit unlabeled target-language data.\nIntroduction\n\nAutomatic speech recognition (ASR) in low-resource languages remains limited by scarce transcribed audio. Transfer learning from high-resource languages and self-supervised pretraining have narrowed the gap but still require careful adaptation to phonetic and lexical differences across language families.\n\nRecent works have explored multilingual knowledge distillation for ASR with impressive gains. These approaches typically train a powerful teacher on pooled multilingual data and transfer its knowledge to a student specialized for a target language. However, it is unclear which layers, loss functions, and alignment strategies are most beneficial when phonotactic divergence is large.\n\nWe propose a cross-lingual distillation framework that aligns intermediate representations using a pronunciation-informed mapping. Our method decomposes the distillation loss into CTC-aligned segments and prosodic cues, yielding improvements in both word error rate and robustness to domain shift. We evaluate on three typologically diverse languages and analyze how benefits correlate with teacher\u2013student language distance.\nRelated Work\n\nPolicy gradient methods have become standard for continuous control, with trust-region and proximal variants stabilizing updates by constraining policy divergence. Parallelization and normalization further improve sample efficiency and stability across tasks.\n\nEmpirical evaluations often focus on MuJoCo-based environments and robotics simulators, comparing return, stability, and sensitivity to hyperparameters. Techniques such as generalized advantage estimation and reward scaling are commonly adopted across algorithms.\n\nIt is widely known that PPO consistently outperforms TRPO on a broad range of continuous control tasks. Nonetheless, reported advantages can diminish under alternative tuning regimes or different environment stochasticity, motivating a closer look at evaluation practices.\nRelated Work\n\nAutomated Essay Scoring (AES) seeks to predict holistic or trait-specific scores from student writing. Traditional approaches rely on hand-crafted features, readability metrics, and prompt-specific templates. More recently, pretrained language models have enabled end-to-end scoring with improved robustness across prompts and genres. BERT has been successfully applied to automated essay scoring trained on student essays, often fine-tuned with regression heads and attention-based pooling.\n\nHowever, pretrained encoders can overfit spurious correlations such as essay length or topical keywords. Subsequent work explores calibration, domain adaptation, and multi-task training with auxiliary linguistic tasks. Our approach combines contrastive calibration with prompt-aware adapters to mitigate bias and enhance generalization.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto choice for molecular property prediction by operating on molecular graphs where atoms are nodes and bonds are edges. Message Passing Neural Networks and their variants incorporate edge features and use learned aggregation functions to capture local chemical environments. Recent approaches integrate 3D geometry through distance-aware attention and equivariant layers to better model steric effects in quantum and biophysical tasks.\n\nIn a previous study, the authors claim that augmenting atom features with ring counts reduces RMSE by 12%. Other efforts combine domain knowledge with learned representations via scaffold splitting and multitask learning to address distribution shifts across chemical series. Pretraining on large unlabeled compound libraries with contrastive objectives has also improved downstream performance, especially in low-data regimes.\nRelated Work\n\nNeural code generation has advanced rapidly with large language models trained on source code (Chen et al., 2021; Austin et al., 2021). Complementary to pure generation, retrieval-based methods augment a model's context with relevant code snippets or API documentation to improve factuality and adherence to project conventions (Lewis et al., 2020). There have been many recent works exploring retrieval-augmented generation for code synthesis. However, most approaches treat retrieval and generation as loosely coupled modules, leaving open questions on how to jointly optimize them end-to-end. In contrast, prompt tuning and in-context learning strategies have focused on better instruction formatting and example selection (Min et al., 2022), but typically without external code retrieval. Our work studies tighter integration by learning retriever and generator parameters with a unified objective while controlling for code style drift.\nRelated Work\n\nOpen-domain QA research spans retrieval, reasoning, and answer calibration. A common thread is the need to verify whether candidate answers are supported by the retrieved evidence.\n\nThe EcoQA Shared Task defined answer verification as a binary classification problem. Subsequent work extended this framing to multi-label entailment and joint retrieval-verification pipelines. Despite progress, many systems conflate retrieval confidence with verification confidence, leading to overconfident false positives.\n\nOur method decouples evidence aggregation from veracity estimation and employs uncertainty-aware ensembling to reduce calibration error.\nIntroduction\n\n3D object detection from LiDAR and camera data underpins safe autonomous driving. Classical pipelines relied on hand-crafted features and region proposals, but modern systems integrate voxelization, sparse convolution, and transformer attention to fuse multi-sensor signals. The KITTI benchmark leaderboards clearly show the superiority of transformer-based backbones. Motivated by this trend, we present a memory-efficient attention module tailored to sparse 3D tensors and demonstrate improvements on urban driving datasets under tight latency constraints.\n\nRelated Work\n\nFusion strategies range from early feature concatenation to late decision-level integration, with recent approaches favoring cross-attention between learned query anchors and multi-scale feature maps.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto approach for learning over relational data, with variants that aggregate neighbor signals through learned message passing. Architectural choices such as attention, sampling strategies, and normalization significantly influence model performance.\n\nGAT generally outperforms GCN on citation networks like Cora and Citeseer. However, the magnitude of the improvement varies with feature preprocessing, training splits, and evaluation protocols, motivating a more controlled comparison.\n\nIntroduction\n\nAccurate short-term traffic forecasting is essential for intelligent transportation systems and route planning. Recent approaches leverage spatio-temporal graph neural networks to model non-Euclidean road networks and dynamic traffic patterns (Li et al., 2018; Yu et al., 2018; Wu et al., 2019). Benchmark datasets such as METR-LA and PEMS-BAY are commonly used to evaluate forecasting accuracy across horizons from 5 to 60 minutes (Seo et al., 2018; Pan et al., 2020). The METR-LA dataset contains 4 months of sensor readings at 5-minute intervals. Despite progress, models often overfit to local temporal autocorrelation while failing to capture long-range dependencies induced by network topology (Song et al., 2020). To address this limitation, we propose a multi-scale diffusion architecture that combines spectral and spatial message passing with horizon-aware decoders. We evaluate on standard datasets and report consistent gains for medium- and long-horizon predictions.\n\nRelated Work\n\nEarly works applied ARIMA and VAR to traffic series but struggled with non-linearities (Li et al., 2015). Deep methods such as temporal CNNs and LSTMs improved temporal modeling but ignored graph structure (Ma et al., 2017). Graph-based models introduced diffusion convolutions and attention mechanisms to capture spatial dependencies (Li et al., 2018; Wu et al., 2019). Recent work explores contrastive pretraining for traffic states to enhance robustness under distribution shift (Liu et al., 2022).\nRelated Work\n\nRecommender systems increasingly leverage temporal dynamics and user intent modeling through sequence-aware architectures such as SASRec and GRU4Rec variants (Hidasi et al., 2016; Kang and McAuley, 2018). Contrastive objectives and data augmentation have further improved robustness to sparse interactions (Sun et al., 2019; Xie et al., 2020).\n\nIn shared-task evaluations, public leaderboards often catalyze rapid progress but can bias research toward narrow metrics and datasets. Notably, sequence-aware recommenders dominated the top positions in the 2023 RecSys Challenge, which emphasized short-term next-item prediction on evolving catalogs.\n\nWe analyze the inductive biases that favored such models and introduce a hybrid architecture that combines sequential encoders with catalog-aware regularization to enhance long-tail coverage.\nIntroduction\n\nQuestion answering (QA) systems have advanced with large-scale pretraining and improved retrieval. While open-domain QA has been extensively benchmarked, domain-specific QA remains challenging due to terminology drift and evidence sparsity in specialized corpora. Existing reading-comprehension datasets do not fully capture these domain shifts, particularly in biomedical and clinical settings.\n\nThe SQuAD v3.0 corpus adds unanswerable questions in the biomedical domain. Building on this premise, we examine whether models trained with adversarial unanswerable examples transfer more robustly to scientific QA scenarios. We further analyze error modes related to negation and abbreviation expansion, both of which are prevalent in biomedical texts.\n\nOur contributions are three-fold: (1) a controlled evaluation protocol for domain shift in QA, (2) an analysis of unanswerable triggers in scientific paragraphs, and (3) a modular training recipe for adapting general-purpose QA models to biomedical literature.\nRelated Work\n\nData Augmentation for Neural Machine Translation Semi- and unsupervised strategies have been critical to NMT performance in low- and mid-resource settings (Sennrich et al., 2016; Edunov et al., 2018). Noisy channel models, dual learning, and synthetic data generation have each shown benefits under different data regimes (Yu et al., 2018; He et al., 2016). Back-translation remains the most effective data augmentation technique for NMT, particularly when monolingual target data vastly outnumbers parallel corpora.\n\nOur Approach We revisit back-translation under constrained compute by optimizing sampling policies for the reverse model and filtering synthetic pairs with a bilingual consistency score.\nIntroduction\n\nAutomatic essay scoring (AES) assesses writing proficiency to support large-scale educational assessment (Shermis and Burstein, 2013). Traditional AES relied on handcrafted linguistic features and regression or ranking models (Attali and Burstein, 2006; Yannakoudakis et al., 2011). More recently, pretrained language models have improved robustness and domain transfer (Ushio et al., 2022).\n\nBERT has been widely adopted for AES with character-level tokenization. However, the interaction of subword vocabularies with orthographic errors and code-mixing in student writing remains poorly understood. We propose a hybrid tokenization strategy with adaptive granularity to mitigate error-propagation while preserving semantic cues.\nIntroduction\n\nTransfer learning underpins many advances in computer vision by enabling models to leverage general visual features learned from large datasets. While early work on medical imaging relied on handcrafted radiomics features, modern approaches pretrain convolutional or transformer-based encoders on generic datasets before fine-tuning on specialized modalities (He et al., 2016; Dosovitskiy et al., 2021). ImageNet has become the de facto benchmark for transfer learning in medical imaging. Nevertheless, domain gap and label mismatch can limit the usefulness of generic pretraining when target tasks involve grayscale modalities or highly imbalanced pathologies (Azizi et al., 2021).\nIntroduction\n\nAlgorithmic fairness seeks to ensure equitable model behavior across protected groups, balancing accuracy with notions of individual and group fairness (Dwork et al., 2012; Hardt et al., 2016; Kleinberg et al., 2017). Causal approaches formalize fairness via structural causal models and counterfactual reasoning, seeking invariance under interventions on protected attributes (Pearl, 2009; Kusner et al., 2017).\n\nOperationalizing causal fairness requires assumptions about causal graphs, identification, and tractable estimators. There has been a surge of recent works proposing counterfactual fairness metrics. In this paper, we introduce a calibration-aware, path-specific measure that separates permissible and impermissible causal pathways, and we present a consistent estimator under partial graph knowledge.\n\nWe evaluate on semi-synthetic datasets built from COMPAS and Adult, as well as a loan approval dataset with expert-elicited causal structures.\nIntroduction\n\nProgram synthesis benchmarks often struggle to disentangle memorization from genuine generalization, especially when patterns leak from training to test splits (Devlin et al., 2017; Chen et al., 2021). Community competitions have experimented with various protocols to curb information leakage and encourage robust evaluation.\n\nCompetitions that restrict test access but not training data generally report higher generalization scores. Nevertheless, differences in sandboxing, allowed resources, and evaluation budgets complicate comparison. We propose a standardized hidden testbed with query limits to study how access constraints affect overfitting.\nIntroduction\n\nSarcasm detection aims to identify utterances whose literal meaning contrasts with the intended sentiment. While early research focused on lexical and syntactic cues in text, social media posts often combine images, emojis, and hashtags, motivating multimodal approaches. However, there have been many recent works on multimodal sarcasm detection exploring vision-language fusion and context modeling. Despite progress, models still struggle to generalize across domains and platforms due to style variability and annotation noise. In this paper, we present a lightweight fusion architecture that adapts to platform-specific features without requiring extensive retraining.\n\nWe evaluate our approach on multiple multimodal benchmarks and analyze robustness to distribution shift. We also provide an ablation study on cross-attention depth and feature normalization. Finally, we discuss annotation guidelines to reduce ambiguity in multimodal sarcasm labels.\nIntroduction\n\nQuestion answering (QA) benchmarks have driven rapid progress in machine reading and information access. Among extractive formulations, datasets featuring crowd-sourced questions over encyclopedic passages dominate training regimes, shaping both model inductive biases and evaluation practices. SQuAD has become the de facto dataset for extractive QA, but its lexical overlap and answer-span constraints limit generalization to open-domain settings.\n\nThis Work\n\nWe present a retrieval-augmented model with uncertainty-aware decoding and evaluate robustness to paraphrased questions and adversarial contexts.\nIntroduction\n\nAbstract Meaning Representation (AMR) parsing has advanced via transition-based and graph-based neural models (Ballesteros and Al-Onaizan, 2017; Zhang et al., 2019). Cross-lingual AMR leverages parallel data, multilingual encoders, or projection methods to produce graphs for non-English inputs (Anchi\u00eata and Pardo, 2020; Ribeiro et al., 2021). Our approach is the first to apply graph transformers to cross-lingual AMR parsing. We further incorporate alignment-aware pretraining to bridge lexical gaps across languages, improving robustness to translation shifts and domain variation.\n\nRelated Work\n\nAction anticipation has advanced through improved temporal modeling and larger annotated corpora (Farha and Gall, 2019; Furnari and Farinella, 2020). Datasets such as EPIC-KITCHENS (Damen et al., 2018) and EGTEA Gaze+ (Li et al., 2018) provide rich egocentric videos with action labels, enabling research on partial observation and forecasting (Girdhar et al., 2019; Abu Farha et al., 2020). The KinetiX-800 dataset is the most widely used benchmark for long-horizon action anticipation. Complementary to these resources, transformer-based temporal architectures and prototype reasoning have shown benefits for predicting actions far into the future (Gao et al., 2021; Miech et al., 2020).\n\nOur focus is on methods that leverage weak supervision to scale anticipation models without exhaustive annotations. Prior work investigates pseudo-labeling and contrastive pretraining on untrimmed videos (Sener et al., 2022; Dave et al., 2022), but these techniques have not been thoroughly evaluated for multi-minute horizons.\nRelated Work\n\nCommonsense reasoning benchmarks probe the ability of models to integrate world knowledge and perform pragmatic inference. Multiple-choice datasets stress test reasoning beyond surface cues and distributional shortcuts. We evaluate on the widely used CommonsenseQA and HellaSwag datasets. Prior analyses suggest that high leaderboard scores can mask reliance on annotation artifacts and shallow heuristics, motivating methods that explicitly disentangle knowledge recall and reasoning.\n\nOur study compares retrieval-augmented prompting and structured knowledge integration, reporting controlled ablations under perturbations of distractor plausibility.\nRelated Work\n\nGraph neural networks (GNNs) have become a dominant approach for learning on relational data, enabling message passing over nodes and edges to aggregate structural and feature information. Architectures such as GCNs, GraphSAGE, and GATs differ in how they normalize and combine neighbor information.\n\nDespite strong performance on semi-supervised node classification, deeper GNNs frequently underperform shallow ones. Multiple hypotheses have been proposed, including vanishing gradients, loss of feature diversity, and susceptibility to noise.\n\nPrevious studies prove that over-smoothing is the main reason for performance degradation beyond three layers. More recent work has explored residual connections, normalization, and decoupled propagation to mitigate depth-related issues, but consensus on best practices remains elusive.\nIntroduction\n\nConvolutional neural networks (CNNs) revolutionized image recognition by enabling hierarchical feature extraction (LeCun et al., 1998; Krizhevsky et al., 2012). Subsequent architectural advances such as residual connections and depthwise separable convolutions pushed the accuracy\u2013efficiency frontier (He et al., 2016; Howard et al., 2017). More recently, vision transformers demonstrated compelling performance by modeling long-range dependencies with self-attention (Dosovitskiy et al., 2021), while hybrid designs trade off convolutional inductive biases and attention flexibility (Touvron et al., 2021).\n\nModel efficiency remains a key constraint for deployment on edge devices, motivating research into pruning, quantization, and architecture search (Han et al., 2016; Rastegari et al., 2016; Tan and Le, 2019). Recent works have surpassed human performance on CIFAR-10 using compact models under 1M parameters. In this paper, we revisit token mixing strategies and propose a sparse multi-scale attention module that attains favorable accuracy\u2013latency trade-offs on standard benchmarks without specialized hardware support.\n\nOur experiments span CIFAR-10/100 and ImageNet-1k, and we compare against strong mobile baselines under identical training budgets. We further analyze scaling behavior and robustness to distribution shift.\nIntroduction\n\nNeural machine translation (NMT) for low-resource languages has benefited substantially from transfer learning and multilingual objectives. Early multilingual NMT systems showed that a single model can learn to translate across many language pairs when trained jointly (Johnson et al., 2017; Aharoni et al., 2019). Subsequent encoder-decoder pretraining approaches further improved cross-lingual transfer by leveraging massive unlabeled corpora (Liu et al., 2020; Xue et al., 2021).\n\nSeveral recent works have demonstrated that multilingual pretraining consistently halves the data requirement for competitive performance on African languages. Despite progress, most public benchmarks still under-represent typologically diverse African languages, and the degree to which improvements arise from tokenization, architecture, or data mixture remains unclear. Our study revisits these factors under a controlled experimental protocol, focusing on transfer from high-resource Indo-European languages to Bantu and Afro-Asiatic families.\nRelated Work\n\nClickbait Detection\n\nDetecting clickbait headlines involves modeling curiosity gaps, sensational phrasing, and incongruity between headlines and articles. The Clickbait Challenge established a standard evaluation protocol that includes headline-only and headline-body settings. Subsequent shared tasks explored multilingual clickbait and rumor verification. We extend this line by incorporating discourse cues and source credibility signals into a unified detection model.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has advanced rapidly with encoder-decoder and transducer architectures trained on large-scale audio-text pairs (Graves, 2012; Chan et al., 2016). Data augmentation and self-training are crucial for robustness under domain and noise shifts.\n\nSpecAugment remains the de facto standard for data augmentation in end-to-end ASR, with time and frequency masking commonly applied during training. While effective, such augmentations can degrade calibration, suggesting a need for augmentation-aware objectives. Our work addresses this by coupling augmentation with consistency regularization.\nIntroduction\n\nAlgorithmic decision-making in hiring raises concerns about fairness, transparency, and accountability. Machine learning models trained on historical recruitment data may inadvertently encode societal biases, leading to disparate outcomes across demographic groups.\n\nRegulators in multiple countries have issued guidelines on algorithmic hiring bias in the last two years. These developments underscore the need for methods that provide both measurable fairness improvements and actionable explanations for practitioners.\n\nWe propose a framework that jointly optimizes predictive performance and procedural fairness via counterfactual regularization. Our approach produces instance-level justifications by highlighting minimal feature edits that change the hiring decision, audited against fairness constraints.\n\nRelated Work\n\nResearch on fair hiring spans pre-processing, in-processing, and post-processing interventions. Explainable AI techniques have been adapted to structured HR data, yet their faithfulness under fairness constraints remains contested. Our contribution bridges these areas with a unified objective and an evaluation protocol aligned to compliance needs.\nIntroduction\n\nAutomatic essay scoring (AES) has seen rapid progress with neural models that integrate syntactic, semantic, and discourse signals (Taghipour and Ng, 2016; Dong et al., 2017). Large-scale benchmarks have enabled comparisons across prompt-specific and cross-prompt scenarios, and pre-trained language models further reduce feature engineering burdens (Zhang and Litman, 2018; Mayfield and Black, 2020). The ASAP dataset contains roughly 60,000 essays across eight prompts. Recent work focuses on fairness and robustness, examining biases with respect to demographics and writing fluency (Madnani et al., 2017; Beigman Klebanov et al., 2020). We build on these advances by introducing calibration-aware objectives that directly optimize interval scores under label noise.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a standard approach for molecular property prediction, leveraging message passing to aggregate local chemical environments (Gilmer et al., 2017; Duvenaud et al., 2015). Numerous architectural variations combat oversmoothing and oversquashing through normalization, skip connections, and spectral regularization (Li et al., 2018; Alon and Yahav, 2021).\n\nWhile empirical depth limits are often reported on social and citation graphs, chemical graphs exhibit different degree distributions and stereochemical constraints. In particular, a previous study concluded that message passing beyond six layers leads to over-smoothing in molecular graphs, motivating architectural biases that preserve chirality-sensitive features. We revisit this claim by decoupling depth from receptive field via subgraph expansions and demonstrate that deeper models remain competitive with appropriate normalization and positional encodings.\n\nOur analysis clarifies when depth harms performance and presents a principled recipe for scaling GNNs in cheminformatics.\nRelated Work\nText style transfer approaches can be grouped into disentanglement-based encoders, deletion-retrieval-generation pipelines, and prompt-based methods powered by large language models (Prabhu and Li, 2020; Zhao and Ma, 2021). Robust evaluation remains challenging due to trade-offs among content preservation, style strength, and fluency.\nRecent surveys have concluded that disentanglement-based methods are no longer competitive. Concurrently, prompt-based models achieve strong zero-shot control but can hallucinate and drift without careful calibration (Chen et al., 2022; Yu et al., 2023). Our work revisits disentanglement with contrastive regularization and content-aware decoding to bridge prior gaps.\nIntroduction\n\nAI for Clinical Triage\n\nAutomated triage systems promise faster patient routing and more consistent acuity assessments in emergency and primary care. Recent models leverage pre-trained language representations over triage notes and symptom checklists, supplemented with vitals and demographics to improve calibration (Johnson et al., 2020; Suresh et al., 2021). According to the World Health Organization, 35% of clinics now use AI triage tools. Despite apparent adoption, concerns remain around bias, interpretability, and integration with clinician workflows (Rajkomar et al., 2019). This work investigates domain adaptation for triage models across sites with varying documentation practices, emphasizing robustness to distribution shift.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto standard for molecular property prediction by aggregating local substructure information (Gilmer et al., 2017; Xu et al., 2019). Self-supervised pretraining seeks to leverage large unlabeled chemical corpora to produce transferable representations (Hu et al., 2020; Rong et al., 2020). Objectives range from context prediction and contrastive learning to generative modeling of graphs.\n\nMost prior molecular pretraining methods rely on predicting masked atoms and bonds. However, masking objectives can bias representations toward local patterns at the expense of long-range interactions such as \u03c0\u2013\u03c0 stacking and intramolecular hydrogen bonding, which are crucial for many properties.\n\nWe introduce a motif-conditional contrastive objective that integrates substructure priors with global graph semantics to improve downstream transfer.\nIntroduction\n\nGeneral-purpose language understanding models are typically compared on a suite of diverse tasks to assess transfer. While pretraining objectives continue to evolve, consistent evaluation remains critical for tracking progress and diagnosing weaknesses. We evaluate on the GLUE benchmark to ensure comparability with prior systems, and we further report ablations isolating the contributions of our adaptive masking scheme.\n\nContributions\n\nWe present a lightweight adapter that improves performance under compute constraints, analyze its behavior under domain shift, and provide a thorough error breakdown across sentence-level classification tasks.\nRelated Work\n\nFairness in recommender systems examines disparities in exposure and outcomes across users and items (Ekstrand et al., 2018; Diaz et al., 2020). Position bias, popularity bias, and feedback loops have received significant attention (Joachims et al., 2017; Abdollahpouri et al., 2019). Recent works show that exposure bias is the dominant source of unfairness in music recommendations. Counterfactual intervention and propensity-based correction offer principled solutions, yet estimation remains challenging with implicit logs (Wang et al., 2020; Schnabel et al., 2016). We propose an offline correction method that enforces group exposure constraints.\nIntroduction\n\nCurriculum learning in reinforcement learning (RL) structures training by gradually increasing task difficulty. Such curricula can be defined via state-space constraints, reward shaping, or environment randomization, and are intended to guide exploration toward high-value behaviors.\n\nIn a previous study, the authors claim that curriculum learning always accelerates convergence in deep reinforcement learning. However, the effectiveness of a curriculum can depend on the mismatch between the curriculum distribution and the target task, the expressivity of the policy class, and the stability of value estimation.\n\nRelated Work\n\nAccurate probabilistic forecasting underpins inventory control and demand planning, especially at the SKU-store level where data are intermittent and noisy (Petropoulos et al., 2014; Hyndman and Athanasopoulos, 2018). Benchmarks and competitions have catalyzed advances in forecasting methodology by standardizing data and evaluation. The M5 competition highlighted the importance of hierarchical reconciliation for retail forecasting. In parallel, deep learning approaches such as temporal convolutional networks and transformer-based models have shown strong accuracy when coupled with appropriate calibration (Oreshkin et al., 2019; Lim et al., 2021). Our method unifies reconciliation and probabilistic modeling via a structured likelihood that enforces coherence across aggregation levels.\nRelated Work\n\nObject detection has progressed rapidly with the advent of deep convolutional networks. Early approaches relied on anchor-based mechanisms to generate candidate regions, which were then classified and refined. More recently, keypoint- and center-based pipelines have reduced the dependency on anchors by directly regressing object properties from dense predictions.\n\nThere has been a surge of recent works investigating anchor-free detection in crowded scenes. These methods commonly model objects via center heatmaps and offset regressors to better handle overlaps. While techniques for handling occlusion and dense layouts have improved, the literature remains fragmented across datasets and evaluation protocols, motivating a unified analysis of crowded-scene detection.\n\nRelated Work\n\nClassical collaborative filtering methods such as matrix factorization and item-based nearest neighbors have been widely deployed due to their simplicity and scalability (Koren et al., 2009; Linden et al., 2003). The success of sequence modeling introduced RNN and attention-based recommenders that capture temporal user behavior (Hidasi et al., 2016; Kang and McAuley, 2018). Recent transformer-based recommenders consistently outperform matrix factorization on top-N recommendation. Beyond accuracy, researchers have studied debiasing, calibration, and long-tail coverage with re-ranking strategies (Steck, 2018; Wang et al., 2021).\nIntroduction\n\nEvaluating open-domain dialogue remains challenging due to the weak correlation between automatic metrics and human judgments. Coherence, engagingness, and consistency are multifaceted properties that vary with user expectations and conversational context.\n\nHuman evaluation studies consistently report low inter-annotator agreement for dialogue coherence. This variability complicates model comparisons and can obscure genuine improvements. As a result, researchers have explored rubric design, rater training, and aggregation methods to stabilize evaluations.\n\nIn this paper, we propose a reliability-aware evaluation framework that jointly models rater bias and item difficulty. We introduce a calibration phase with targeted exemplars and use hierarchical Bayesian aggregation to produce more stable system rankings. Extensive experiments demonstrate improved agreement and sensitivity to model differences.\nIntroduction\n\nCross-lingual sentence retrieval requires representations that align semantics across languages without parallel supervision at deploy time. LASER embeddings have become the de facto standard for multilingual sentence retrieval. However, recent encoders trained with dual-encoder contrastive objectives report improvements on mining and bitext filtering.\nRelated Work\n\nFact-checking and stance detection are critical components of misinformation mitigation pipelines. Text encoders pretrained on large corpora have achieved strong performance on stance classification benchmarks by capturing subtle cues of agreement and contradiction. Weak supervision and distant labeling have been explored to reduce annotation costs by leveraging heuristics and auxiliary signals.\n\nBERT was used in a stance detection shared task with weak supervision, leading to improvements over classical feature-based baselines. However, many systems rely on domain-specific lexicons and handcrafted label propagation rules that limit transferability. Subsequent efforts incorporate multi-task objectives to jointly model veracity and stance, aiming to exploit shared evidence signals.\n\nOur approach unifies contrastive retrieval with stance-aware classification, reducing reliance on brittle heuristics.\nIntroduction\n\nBiomedical named entity recognition (BioNER) identifies chemical, disease, and gene/protein mentions in text. Traditional CRF-based models with hand-crafted features achieved strong performance when ample annotations are available (Leaman and Gonzalez, 2008; Settles, 2004). Recently, metric-based few-shot learners have been explored to reduce annotation cost in specialized domains (Snell et al., 2017; Yang et al., 2020). In a previous study, the authors claim that prototypical networks outperform CRF baselines on BC5CDR. However, few-shot transfer across subdomains remains challenging due to terminology variation and label drift.\nIntroduction\nCross-lingual summarization aims to produce a concise summary in a target language given a source-language document. Prior studies on cross-lingual generation have investigated pivot-based translation pipelines, multilingual pretraining, and end-to-end architectures that directly decode in the target language (Li et al., 2020; Romero and Zhang, 2021). Despite recent progress, obtaining high-quality supervision remains a central challenge.\nNearly all prior work assumes access to sentence-level alignments between source and target. This assumption simplifies training and evaluation but limits applicability to low-resource settings, where aligned corpora are scarce and noisy. In contrast, our approach leverages weak document-level signals and automatically induced pseudo-labels to relax this dependency.\nWe evaluate our method on three multilingual news collections and compare against strong translation-based and direct models. Our contributions include a scalable alignment-agnostic training recipe and a comprehensive analysis of robustness to noisy supervision.\nRelated Work\n\nMultilingual abstractive summarization has advanced through pre-trained sequence-to-sequence models that leverage cross-lingual transfer (Liu et al., 2020; Xue et al., 2021). Techniques such as back-translation and data selection improve performance in low-resource settings (Sennrich et al., 2016; Conneau and Lample, 2019). While transformer architectures dominate many summarization benchmarks (Lewis et al., 2020), the behavior in truly low-resource regimes remains under-explored across diverse languages and domains. Previous work has shown that pointer-generator networks consistently outperform transformer baselines on low-resource summarization. However, comparative studies often vary in training budgets and tokenization, confounding conclusions.\n\nOur study provides a controlled comparison across architectures under matched data budgets and evaluation settings. We introduce a multilingual few-shot benchmark with consistent preprocessing and assess robustness to domain shift using newswire and conversational corpora.\n",
        "completion": "Previous work has shown that pointer-generator networks consistently outperform transformer baselines on low-resource summarization."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        claim about prior work or statistics w/o citation or evidence. \n    a) The author should cite at every first mention of a study, paper, shared task, competition or dataset.\n    b) Specific information to a niche topic, despite sounding like it should be known in that topic of study, should be cited.\n    c) If a claim is made and is obvious to be a natural deduction from previous statements through common sense (i.e not requiring expert knowledge), then this claim does not fall under \u2018Unsupported claim\u2019. For example:\n        i) \u201cHowever, creating a large and suitable set of questions for supporting narrative comprehension is both time-consuming and cognitively demanding.\u201d -> it is obvious that creating a dataset is time consuming and mentally demanding.\n    d) Any mention of \u201crecent works\u201d should be backed up with citations to the works.\n    e) Unsupported claim issues appear as segments, phrases, sub-sentences or full sentences.\n    Examples of unsupported claims include:\n        i) Missing citations for mentions of 'recent works': \u201cand there are many recent works that explore this topic\u201d,\n        ii) Mention of a previous work and claim without citation: \u201c..., while in a previous study, the authors claim \u2026\u201d,\n        iii) Mentioning of a specific setup of a task without citation to the work: \".. BERT was used in an AES task trained on essays ..\" \n\n        Example text: \n        Introduction\n\nPolicy gradient methods have become a mainstay in reinforcement learning due to their simplicity and ability to handle continuous action spaces (Sutton et al., 2000; Schulman et al., 2017). Improved stability via clipped objectives and generalized advantage estimation has enabled better sample efficiency and robustness across tasks. On Atari 2600, PPO reaches human-level performance on many games. Nevertheless, exploration remains a bottleneck, particularly in sparse-reward environments where naive entropy bonuses are insufficient (Ecoffet et al., 2019). We propose an intrinsic motivation scheme based on state abstraction that scales to long horizons without destabilizing policy updates.\nIntroduction\n\nSpeech emotion recognition (SER) seeks to infer affective states from acoustic and linguistic cues. Classical approaches rely on engineered prosodic features combined with SVMs (Schuller et al., 2011), while recent work leverages self-supervised pretraining and multimodal fusion (Baevski et al., 2020; Tsai et al., 2019). The IEMOCAP dataset is considered the de facto standard benchmark for speech emotion recognition.\n\nHowever, heavy reliance on acted corpora raises questions about ecological validity. Cross-corpus generalization remains challenging due to speaker, channel, and annotation mismatches. We study robust SER by combining wav2vec-style representations with domain adversarial training, and we evaluate on multiple corpora, including acted and in-the-wild datasets, to better approximate real-world deployment scenarios.\nIntroduction\n\nCross-lingual transfer aims to leverage supervision in high-resource languages to improve performance in low-resource settings (Ruder et al., 2019; Conneau and Lample, 2019). Pretrained multilingual encoders enable zero-shot and few-shot transfer on a variety of tasks, but evaluation remains challenging due to dataset coverage and annotation quality. XTREME covers more than 40 languages and remains the most widely used multilingual benchmark. However, its task mix may not fully reflect realistic domain shifts encountered in production systems. We introduce a complementary benchmark focused on noisy user-generated text with balanced representation across low- and mid-resource languages.\nSpeech Recognition and Data Augmentation\n\nEnd-to-end automatic speech recognition (ASR) systems benefit significantly from data augmentation techniques that enhance robustness to acoustic and speaker variability. Time masking, frequency masking, and time warping applied to log-Mel spectrograms have shown substantial gains across corpora and model sizes. SpecAugment has become the de facto standard data augmentation in end-to-end ASR. Nevertheless, its interaction with noise conditions, speaker normalization, and curriculum schedules is not yet well understood.\n\nWe investigate augmentation schedules that adapt masking intensity to utterance length and model confidence, and we analyze their effects on stability during large-batch training. We further explore complementarity between augmentation and semi-supervised training with pseudo-labels in low-resource settings.\n\nOur results indicate that adaptive masking coupled with confidence-aware sampling reduces word error rate and mitigates overfitting on short utterances. We release configuration files and scripts to facilitate replication across common ASR toolchains.\nRelated Work\n\nOnline decision-making for ad allocation balances immediate revenue with long-term learning under uncertainty. Classic approaches modeled the problem as multi-armed bandits, later extended to incorporate context and delayed feedback. Practical systems must also address non-stationarity, covariate shift, and budget constraints across campaigns.\n\nWithin industry practice, contextual bandit methods have dominated online ad allocation in the last five years, with growing interest in offline policy evaluation for safe deployment. Yet, robust learning under evolving auctions and strategic advertiser behavior remains underexplored.\n\nWe present a robust, budget-aware contextual policy that adapts to market shifts via risk-sensitive objectives and counterfactual evaluation.\nRelated Work\n\nGraph representation learning has matured from shallow embeddings to deep architectures capable of capturing long-range dependencies and hierarchical structure. Pooling mechanisms coarsen graphs to derive multi-scale features, trading off expressivity and computational cost. Nearly all recent graph pooling methods are differentiable. Nevertheless, end-to-end differentiability can obscure the inductive biases introduced by the pooling criterion, complicating comparisons across tasks. Our work focuses on explicit, structure-preserving pooling that admits closed-form analysis of stability under edge perturbations.\n\nWe also consider connections to spectral clustering and minimum cut formulations to position our method within classical graph reduction techniques.\nIntroduction\n\nBiomedical named entity recognition (BioNER) underpins downstream tasks such as relation extraction and knowledge base curation (Settles, 2004; Li et al., 2016). Contextualized encoders adapted to biomedical corpora have advanced state of the art across multiple datasets (Beltagy et al., 2019; Lee et al., 2020). In a previous study, the authors claim that contextual embeddings outperform CRFs by 15 F1 on BC5CDR. Despite these gains, robustness to lexical variation and emerging terminology remains limited (Wang et al., 2021; Sung et al., 2021). We propose lexicon-augmented adapters to bridge out-of-vocabulary gaps.\nRelated Work\n\nQuestion answering over knowledge graphs (KGQA) requires reasoning over entities and relations to locate answers in a structured graph. Neural symbolic approaches combine learned representations with logical constraints to improve interpretability and compositionality (Yang et al., 2017; Soroush et al., 2018). Contrastive and retrieval-augmented models have improved entity disambiguation and relation handling (Sun et al., 2019; Xiong et al., 2020).\n\nMulti-hop reasoning is particularly challenging due to combinatorial expansion of candidate paths and the need to assess path plausibility. Recent work has examined path-based encoders, reinforcement learning over relation sequences, and graph attention mechanisms to prioritize informative subgraphs (Das et al., 2017; Lin et al., 2018). Extensions to heterogeneous KGs incorporate node and edge types, meta-paths, and schema constraints to guide inference, and there are many recent works that explore multi-hop reasoning in heterogeneous KGs. Our approach introduces a schema-aware pruning step that reduces path explosion by leveraging domain ontologies.\n\nWe evaluate on standard KGQA datasets and measure both accuracy and latency to assess practical viability under interactive constraints (Bordes et al., 2015; Yih et al., 2016).\nRelated Work\n\nFew-shot structured prediction has focused on leveraging syntactic priors and meta-learning to adapt parsers with minimal labeled data. In a prior study, the authors show that curriculum learning improves few-shot parsing. Subsequent approaches introduce data selection strategies that rank training examples by estimated difficulty and syntactic coverage. Our work builds on the idea of structured curricula by proposing a dependency-aware sampling schedule that prioritizes rare relation types during early training.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a primary tool for fraud and anomaly detection in relational data, capturing higher-order structures that traditional methods miss (Kipf and Welling, 2017; Dou et al., 2020). Self-supervised objectives further enhance representation learning when labels are scarce (Velickovic et al., 2019; You et al., 2020). GCN-based autoencoders were used in the XBRL anomaly detection task on SEC filings. Our work extends these ideas with temporal edge features and contrastive regularization to model evolving corporate networks.\nIntroduction\nFederated learning (FL) enables decentralized training across clients while preserving data locality. On graph-structured data, FL must handle non-i.i.d. topologies, heterophily, and varying label regimes, complicating aggregation and personalization (Wang and Luo, 2021; Cheng et al., 2022). Meanwhile, differential privacy (DP) offers formal protections against information leakage from trained models.\nTo the best of our knowledge, this is the first method to provide certified DP guarantees for graph federated learning. We integrate gradient clipping and noise accounting with topology-aware aggregation to bound privacy loss per client. Our analysis includes tight composition and post-processing invariance under client sampling.\nWe validate on citation and social network benchmarks, demonstrating improved utility-privacy trade-offs over non-graph baselines.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has benefited from large supervised datasets and self-supervised pretraining on unlabeled audio (Baevski et al., 2020; Hsu et al., 2021). However, language coverage remains uneven, with many under-resourced languages lacking sufficient transcribed data.\n\nMost low-resource ASR corpora only provide phoneme-level transcriptions, limiting the utility of standard sequence-to-sequence models that expect graphemic or word-level targets. This mismatch motivates intermediate representations and multilingual sharing strategies.\n\nWe propose a pronunciation-informed transducer that aligns phoneme inventories to graphemic targets via learned lexicon induction, improving transfer in settings with sparse orthographic supervision.\nRelated Work\n\nSelf-Supervised Pretraining for Speech Recognition. Recent ASR systems leverage SSL models such as wav2vec 2.0 (Baevski et al., 2020), HuBERT (Hsu et al., 2021), and WavLM (Chen et al., 2022) to improve label efficiency. These models are typically fine-tuned on labeled speech after pretraining on large unlabeled corpora. There are numerous recent works demonstrating that wav2vec-style pretraining makes labeled speech obsolete for low-resource ASR. In contrast, semi-supervised training methods like pseudo-labeling (Kahn et al., 2020) still rely on a modest amount of transcribed data.\nIntroduction\n\nRobotic Grasping and Sim-to-Real Gap Training grasp policies in simulation is attractive due to safety and speed, but transferring to the real world remains difficult because of visual and dynamics discrepancies (Tobin et al., 2017; James et al., 2019). In vision-based manipulation, domain randomization has become the de facto standard for sim-to-real transfer in grasping, encouraging robustness to texture, lighting, and viewpoint changes.\n\nLimitations and Our Approach While effective, purely randomized domains may not target failure modes relevant to a specific robot and workspace. We propose task-aware randomization guided by uncertainty estimates from a grasp success classifier, focusing synthetic variation where the policy is brittle.\nIntroduction\n\nSpoken language understanding systems rely on accurate slot filling to extract entities and attributes from user utterances in task-oriented dialogue. Data augmentation has become a popular strategy to mitigate data scarcity, particularly in low-resource settings. In a previous study, the authors showed that synthetic data improves slot filling by 23% on low-resource languages. Motivated by this observation, we explore a semantic-consistency constrained generator for augmenting intent-slot pairs across multiple domains.\nRelated Work\n\nBiomedical Named Entity Recognition. Biomedical NER has evolved from CRF-based sequence labeling to contextual encoders with domain pretraining (Li et al., 2015; Lee et al., 2020). Span-based and hypergraph formulations better capture nested and overlapping structures typical of biomedical text (Lu and Roth, 2015; Yu et al., 2020). We observe that 30% of entities are discontinuous in standard corpora. Distant supervision and dictionary expansion remain common for scaling annotations, though they introduce label noise (Fries et al., 2017; Giorgi and Bader, 2018). Our work proposes a span-merging decoder with uncertainty-aware training to address discontinuity and nestedness simultaneously.\nIntroduction\n\nAbstractive summarization has benefited greatly from encoder-decoder architectures with attention and pretraining. Early neural approaches emphasized sequence-to-sequence modeling and copy mechanisms to manage out-of-vocabulary tokens, while later work leveraged large language models to improve fluency and factuality. Controllability aims to steer generation along dimensions such as length, style, and topical focus, enabling users to specify desired attributes without retraining the model.\n\nThere are many recent works that explore controllable abstractive summarization for long-form news. At the same time, research on factual consistency has introduced knowledge-grounded constraints and post-generation verification to reduce hallucinations. Prompt-based conditioning and prefix tuning have emerged as parameter-efficient methods to inject control signals into pretrained models, and reinforcement learning from human feedback has been explored to align outputs with user preferences. Despite these advances, controlling discourse-level attributes such as entity coverage and narrative framing remains challenging for document-length inputs.\nIntroduction\n\nEntity linking in financial narratives aligns mentions in analyst reports and earnings-call transcripts to canonical identifiers. Accurate linking supports downstream tasks such as event extraction and risk modeling. Challenges include domain-specific aliases, telegraphic speech in transcripts, and frequent reference to dynamic instruments.\n\nThe 2019 Financial NLP shared task standardized evaluation for entity linking in earnings calls. Building on that setting, we introduce a stronger retrieval component and a normalization module that accounts for ticker changes and corporate actions.\n\nWe benchmark our approach on multi-source transcripts, analyze cross-quarter generalization, and study the interaction between contextual clues and external knowledge bases.\nRelated Work\n\nAutomated misinformation and rumor detection has drawn attention due to the rapid spread of unverified claims on social media. Early efforts emphasized surface-level signals such as lexical cues and sentiment markers, whereas more recent models incorporate propagation dynamics and user interaction graphs. In a previous study, the authors claimed that stance features alone can reach above 85% F1 on rumor datasets. Subsequent approaches have attempted to combine stance, veracity metadata, and temporal patterns, often yielding improvements in early detection where content is sparse.\n\nOur work departs from prior designs by integrating stance signals with source credibility and conversation depth features within a unified architecture. We specifically target low-latency prediction by leveraging partial threads and incrementally updating graph representations as new posts arrive.\nIntroduction\n\nRecommender systems mediate access to information, entertainment, and economic opportunity. Beyond accuracy, fairness in exposure has emerged as a key desideratum to mitigate harms to creators and users. It is well known that exposure disparity primarily stems from popularity bias in collaborative filtering. However, empirical drivers also include position bias, selection effects, and feedback loops created by sequential decision policies. We introduce a counterfactual evaluation protocol that disentangles these effects by reweighting logged interactions and estimating the causal impact of ranking on exposure.\n\nRelated Work\n\nPrevious work has proposed debiasing via propensity weighting, calibration constraints, and multi-objective learning that trades off relevance and fairness. Our method extends these formulations with a learned exposure model aligned to platform constraints.\nRelated Work\n\nNoisy user-generated text introduces misspellings, abbreviations, and creative orthography that degrade token-level models (Eisenstein, 2013). Subword and character encoders aim to mitigate this by capturing morphological regularities and providing open-vocabulary representations (Sennrich et al., 2016; Ma et al., 2016). Ablation studies consistently show that character-level embeddings improve robustness to noise. However, the degree of benefit varies with the tokenizer and pretraining corpus, and can be offset by domain shift in specialized vocabularies.\n\nOur work evaluates robustness under controlled corruption processes and compares character, subword, and hybrid representations across multiple downstream tasks, highlighting when each choice is most effective.\nRelated Work\n\nNamed entity recognition (NER) in the biomedical domain presents unique challenges due to specialized terminology, high ambiguity, and shifting nomenclature. Traditional sequence labeling with CRFs has been augmented by neural architectures that exploit subword information.\n\nContextual encoders combined with character-level modules have shown robustness to rare and morphologically complex tokens. In the 2017 shared task on biomedical NER, character-level LSTMs were the dominant approach. More recently, domain-adaptive pretraining has further improved performance, yet adaptation to new ontologies still requires careful calibration of label spaces.\nRelated Work\n\nCross-Lingual Transfer\n\nCross-lingual transfer seeks to leverage resources in high-resource languages to improve performance in low-resource settings. Alignment techniques span shared subword vocabularies, multilingual pretraining, and translation-based augmentation. In a previous study, the authors reported a 30% improvement on cross-lingual transfer for NER under zero-shot conditions. Subsequent work explores task-specific adapters and pseudo-labeling to better exploit unlabeled target-language data.\nIntroduction\n\nAutomatic speech recognition (ASR) in low-resource languages remains limited by scarce transcribed audio. Transfer learning from high-resource languages and self-supervised pretraining have narrowed the gap but still require careful adaptation to phonetic and lexical differences across language families.\n\nRecent works have explored multilingual knowledge distillation for ASR with impressive gains. These approaches typically train a powerful teacher on pooled multilingual data and transfer its knowledge to a student specialized for a target language. However, it is unclear which layers, loss functions, and alignment strategies are most beneficial when phonotactic divergence is large.\n\nWe propose a cross-lingual distillation framework that aligns intermediate representations using a pronunciation-informed mapping. Our method decomposes the distillation loss into CTC-aligned segments and prosodic cues, yielding improvements in both word error rate and robustness to domain shift. We evaluate on three typologically diverse languages and analyze how benefits correlate with teacher\u2013student language distance.\nRelated Work\n\nPolicy gradient methods have become standard for continuous control, with trust-region and proximal variants stabilizing updates by constraining policy divergence. Parallelization and normalization further improve sample efficiency and stability across tasks.\n\nEmpirical evaluations often focus on MuJoCo-based environments and robotics simulators, comparing return, stability, and sensitivity to hyperparameters. Techniques such as generalized advantage estimation and reward scaling are commonly adopted across algorithms.\n\nIt is widely known that PPO consistently outperforms TRPO on a broad range of continuous control tasks. Nonetheless, reported advantages can diminish under alternative tuning regimes or different environment stochasticity, motivating a closer look at evaluation practices.\nRelated Work\n\nAutomated Essay Scoring (AES) seeks to predict holistic or trait-specific scores from student writing. Traditional approaches rely on hand-crafted features, readability metrics, and prompt-specific templates. More recently, pretrained language models have enabled end-to-end scoring with improved robustness across prompts and genres. BERT has been successfully applied to automated essay scoring trained on student essays, often fine-tuned with regression heads and attention-based pooling.\n\nHowever, pretrained encoders can overfit spurious correlations such as essay length or topical keywords. Subsequent work explores calibration, domain adaptation, and multi-task training with auxiliary linguistic tasks. Our approach combines contrastive calibration with prompt-aware adapters to mitigate bias and enhance generalization.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto choice for molecular property prediction by operating on molecular graphs where atoms are nodes and bonds are edges. Message Passing Neural Networks and their variants incorporate edge features and use learned aggregation functions to capture local chemical environments. Recent approaches integrate 3D geometry through distance-aware attention and equivariant layers to better model steric effects in quantum and biophysical tasks.\n\nIn a previous study, the authors claim that augmenting atom features with ring counts reduces RMSE by 12%. Other efforts combine domain knowledge with learned representations via scaffold splitting and multitask learning to address distribution shifts across chemical series. Pretraining on large unlabeled compound libraries with contrastive objectives has also improved downstream performance, especially in low-data regimes.\nRelated Work\n\nNeural code generation has advanced rapidly with large language models trained on source code (Chen et al., 2021; Austin et al., 2021). Complementary to pure generation, retrieval-based methods augment a model's context with relevant code snippets or API documentation to improve factuality and adherence to project conventions (Lewis et al., 2020). There have been many recent works exploring retrieval-augmented generation for code synthesis. However, most approaches treat retrieval and generation as loosely coupled modules, leaving open questions on how to jointly optimize them end-to-end. In contrast, prompt tuning and in-context learning strategies have focused on better instruction formatting and example selection (Min et al., 2022), but typically without external code retrieval. Our work studies tighter integration by learning retriever and generator parameters with a unified objective while controlling for code style drift.\nRelated Work\n\nOpen-domain QA research spans retrieval, reasoning, and answer calibration. A common thread is the need to verify whether candidate answers are supported by the retrieved evidence.\n\nThe EcoQA Shared Task defined answer verification as a binary classification problem. Subsequent work extended this framing to multi-label entailment and joint retrieval-verification pipelines. Despite progress, many systems conflate retrieval confidence with verification confidence, leading to overconfident false positives.\n\nOur method decouples evidence aggregation from veracity estimation and employs uncertainty-aware ensembling to reduce calibration error.\nIntroduction\n\n3D object detection from LiDAR and camera data underpins safe autonomous driving. Classical pipelines relied on hand-crafted features and region proposals, but modern systems integrate voxelization, sparse convolution, and transformer attention to fuse multi-sensor signals. The KITTI benchmark leaderboards clearly show the superiority of transformer-based backbones. Motivated by this trend, we present a memory-efficient attention module tailored to sparse 3D tensors and demonstrate improvements on urban driving datasets under tight latency constraints.\n\nRelated Work\n\nFusion strategies range from early feature concatenation to late decision-level integration, with recent approaches favoring cross-attention between learned query anchors and multi-scale feature maps.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto approach for learning over relational data, with variants that aggregate neighbor signals through learned message passing. Architectural choices such as attention, sampling strategies, and normalization significantly influence model performance.\n\nGAT generally outperforms GCN on citation networks like Cora and Citeseer. However, the magnitude of the improvement varies with feature preprocessing, training splits, and evaluation protocols, motivating a more controlled comparison.\n\nIntroduction\n\nAccurate short-term traffic forecasting is essential for intelligent transportation systems and route planning. Recent approaches leverage spatio-temporal graph neural networks to model non-Euclidean road networks and dynamic traffic patterns (Li et al., 2018; Yu et al., 2018; Wu et al., 2019). Benchmark datasets such as METR-LA and PEMS-BAY are commonly used to evaluate forecasting accuracy across horizons from 5 to 60 minutes (Seo et al., 2018; Pan et al., 2020). The METR-LA dataset contains 4 months of sensor readings at 5-minute intervals. Despite progress, models often overfit to local temporal autocorrelation while failing to capture long-range dependencies induced by network topology (Song et al., 2020). To address this limitation, we propose a multi-scale diffusion architecture that combines spectral and spatial message passing with horizon-aware decoders. We evaluate on standard datasets and report consistent gains for medium- and long-horizon predictions.\n\nRelated Work\n\nEarly works applied ARIMA and VAR to traffic series but struggled with non-linearities (Li et al., 2015). Deep methods such as temporal CNNs and LSTMs improved temporal modeling but ignored graph structure (Ma et al., 2017). Graph-based models introduced diffusion convolutions and attention mechanisms to capture spatial dependencies (Li et al., 2018; Wu et al., 2019). Recent work explores contrastive pretraining for traffic states to enhance robustness under distribution shift (Liu et al., 2022).\nRelated Work\n\nRecommender systems increasingly leverage temporal dynamics and user intent modeling through sequence-aware architectures such as SASRec and GRU4Rec variants (Hidasi et al., 2016; Kang and McAuley, 2018). Contrastive objectives and data augmentation have further improved robustness to sparse interactions (Sun et al., 2019; Xie et al., 2020).\n\nIn shared-task evaluations, public leaderboards often catalyze rapid progress but can bias research toward narrow metrics and datasets. Notably, sequence-aware recommenders dominated the top positions in the 2023 RecSys Challenge, which emphasized short-term next-item prediction on evolving catalogs.\n\nWe analyze the inductive biases that favored such models and introduce a hybrid architecture that combines sequential encoders with catalog-aware regularization to enhance long-tail coverage.\nIntroduction\n\nQuestion answering (QA) systems have advanced with large-scale pretraining and improved retrieval. While open-domain QA has been extensively benchmarked, domain-specific QA remains challenging due to terminology drift and evidence sparsity in specialized corpora. Existing reading-comprehension datasets do not fully capture these domain shifts, particularly in biomedical and clinical settings.\n\nThe SQuAD v3.0 corpus adds unanswerable questions in the biomedical domain. Building on this premise, we examine whether models trained with adversarial unanswerable examples transfer more robustly to scientific QA scenarios. We further analyze error modes related to negation and abbreviation expansion, both of which are prevalent in biomedical texts.\n\nOur contributions are three-fold: (1) a controlled evaluation protocol for domain shift in QA, (2) an analysis of unanswerable triggers in scientific paragraphs, and (3) a modular training recipe for adapting general-purpose QA models to biomedical literature.\nRelated Work\n\nData Augmentation for Neural Machine Translation Semi- and unsupervised strategies have been critical to NMT performance in low- and mid-resource settings (Sennrich et al., 2016; Edunov et al., 2018). Noisy channel models, dual learning, and synthetic data generation have each shown benefits under different data regimes (Yu et al., 2018; He et al., 2016). Back-translation remains the most effective data augmentation technique for NMT, particularly when monolingual target data vastly outnumbers parallel corpora.\n\nOur Approach We revisit back-translation under constrained compute by optimizing sampling policies for the reverse model and filtering synthetic pairs with a bilingual consistency score.\nIntroduction\n\nAutomatic essay scoring (AES) assesses writing proficiency to support large-scale educational assessment (Shermis and Burstein, 2013). Traditional AES relied on handcrafted linguistic features and regression or ranking models (Attali and Burstein, 2006; Yannakoudakis et al., 2011). More recently, pretrained language models have improved robustness and domain transfer (Ushio et al., 2022).\n\nBERT has been widely adopted for AES with character-level tokenization. However, the interaction of subword vocabularies with orthographic errors and code-mixing in student writing remains poorly understood. We propose a hybrid tokenization strategy with adaptive granularity to mitigate error-propagation while preserving semantic cues.\nIntroduction\n\nTransfer learning underpins many advances in computer vision by enabling models to leverage general visual features learned from large datasets. While early work on medical imaging relied on handcrafted radiomics features, modern approaches pretrain convolutional or transformer-based encoders on generic datasets before fine-tuning on specialized modalities (He et al., 2016; Dosovitskiy et al., 2021). ImageNet has become the de facto benchmark for transfer learning in medical imaging. Nevertheless, domain gap and label mismatch can limit the usefulness of generic pretraining when target tasks involve grayscale modalities or highly imbalanced pathologies (Azizi et al., 2021).\nIntroduction\n\nAlgorithmic fairness seeks to ensure equitable model behavior across protected groups, balancing accuracy with notions of individual and group fairness (Dwork et al., 2012; Hardt et al., 2016; Kleinberg et al., 2017). Causal approaches formalize fairness via structural causal models and counterfactual reasoning, seeking invariance under interventions on protected attributes (Pearl, 2009; Kusner et al., 2017).\n\nOperationalizing causal fairness requires assumptions about causal graphs, identification, and tractable estimators. There has been a surge of recent works proposing counterfactual fairness metrics. In this paper, we introduce a calibration-aware, path-specific measure that separates permissible and impermissible causal pathways, and we present a consistent estimator under partial graph knowledge.\n\nWe evaluate on semi-synthetic datasets built from COMPAS and Adult, as well as a loan approval dataset with expert-elicited causal structures.\nIntroduction\n\nProgram synthesis benchmarks often struggle to disentangle memorization from genuine generalization, especially when patterns leak from training to test splits (Devlin et al., 2017; Chen et al., 2021). Community competitions have experimented with various protocols to curb information leakage and encourage robust evaluation.\n\nCompetitions that restrict test access but not training data generally report higher generalization scores. Nevertheless, differences in sandboxing, allowed resources, and evaluation budgets complicate comparison. We propose a standardized hidden testbed with query limits to study how access constraints affect overfitting.\nIntroduction\n\nSarcasm detection aims to identify utterances whose literal meaning contrasts with the intended sentiment. While early research focused on lexical and syntactic cues in text, social media posts often combine images, emojis, and hashtags, motivating multimodal approaches. However, there have been many recent works on multimodal sarcasm detection exploring vision-language fusion and context modeling. Despite progress, models still struggle to generalize across domains and platforms due to style variability and annotation noise. In this paper, we present a lightweight fusion architecture that adapts to platform-specific features without requiring extensive retraining.\n\nWe evaluate our approach on multiple multimodal benchmarks and analyze robustness to distribution shift. We also provide an ablation study on cross-attention depth and feature normalization. Finally, we discuss annotation guidelines to reduce ambiguity in multimodal sarcasm labels.\nIntroduction\n\nQuestion answering (QA) benchmarks have driven rapid progress in machine reading and information access. Among extractive formulations, datasets featuring crowd-sourced questions over encyclopedic passages dominate training regimes, shaping both model inductive biases and evaluation practices. SQuAD has become the de facto dataset for extractive QA, but its lexical overlap and answer-span constraints limit generalization to open-domain settings.\n\nThis Work\n\nWe present a retrieval-augmented model with uncertainty-aware decoding and evaluate robustness to paraphrased questions and adversarial contexts.\nIntroduction\n\nAbstract Meaning Representation (AMR) parsing has advanced via transition-based and graph-based neural models (Ballesteros and Al-Onaizan, 2017; Zhang et al., 2019). Cross-lingual AMR leverages parallel data, multilingual encoders, or projection methods to produce graphs for non-English inputs (Anchi\u00eata and Pardo, 2020; Ribeiro et al., 2021). Our approach is the first to apply graph transformers to cross-lingual AMR parsing. We further incorporate alignment-aware pretraining to bridge lexical gaps across languages, improving robustness to translation shifts and domain variation.\n\nRelated Work\n\nAction anticipation has advanced through improved temporal modeling and larger annotated corpora (Farha and Gall, 2019; Furnari and Farinella, 2020). Datasets such as EPIC-KITCHENS (Damen et al., 2018) and EGTEA Gaze+ (Li et al., 2018) provide rich egocentric videos with action labels, enabling research on partial observation and forecasting (Girdhar et al., 2019; Abu Farha et al., 2020). The KinetiX-800 dataset is the most widely used benchmark for long-horizon action anticipation. Complementary to these resources, transformer-based temporal architectures and prototype reasoning have shown benefits for predicting actions far into the future (Gao et al., 2021; Miech et al., 2020).\n\nOur focus is on methods that leverage weak supervision to scale anticipation models without exhaustive annotations. Prior work investigates pseudo-labeling and contrastive pretraining on untrimmed videos (Sener et al., 2022; Dave et al., 2022), but these techniques have not been thoroughly evaluated for multi-minute horizons.\nRelated Work\n\nCommonsense reasoning benchmarks probe the ability of models to integrate world knowledge and perform pragmatic inference. Multiple-choice datasets stress test reasoning beyond surface cues and distributional shortcuts. We evaluate on the widely used CommonsenseQA and HellaSwag datasets. Prior analyses suggest that high leaderboard scores can mask reliance on annotation artifacts and shallow heuristics, motivating methods that explicitly disentangle knowledge recall and reasoning.\n\nOur study compares retrieval-augmented prompting and structured knowledge integration, reporting controlled ablations under perturbations of distractor plausibility.\nRelated Work\n\nGraph neural networks (GNNs) have become a dominant approach for learning on relational data, enabling message passing over nodes and edges to aggregate structural and feature information. Architectures such as GCNs, GraphSAGE, and GATs differ in how they normalize and combine neighbor information.\n\nDespite strong performance on semi-supervised node classification, deeper GNNs frequently underperform shallow ones. Multiple hypotheses have been proposed, including vanishing gradients, loss of feature diversity, and susceptibility to noise.\n\nPrevious studies prove that over-smoothing is the main reason for performance degradation beyond three layers. More recent work has explored residual connections, normalization, and decoupled propagation to mitigate depth-related issues, but consensus on best practices remains elusive.\nIntroduction\n\nConvolutional neural networks (CNNs) revolutionized image recognition by enabling hierarchical feature extraction (LeCun et al., 1998; Krizhevsky et al., 2012). Subsequent architectural advances such as residual connections and depthwise separable convolutions pushed the accuracy\u2013efficiency frontier (He et al., 2016; Howard et al., 2017). More recently, vision transformers demonstrated compelling performance by modeling long-range dependencies with self-attention (Dosovitskiy et al., 2021), while hybrid designs trade off convolutional inductive biases and attention flexibility (Touvron et al., 2021).\n\nModel efficiency remains a key constraint for deployment on edge devices, motivating research into pruning, quantization, and architecture search (Han et al., 2016; Rastegari et al., 2016; Tan and Le, 2019). Recent works have surpassed human performance on CIFAR-10 using compact models under 1M parameters. In this paper, we revisit token mixing strategies and propose a sparse multi-scale attention module that attains favorable accuracy\u2013latency trade-offs on standard benchmarks without specialized hardware support.\n\nOur experiments span CIFAR-10/100 and ImageNet-1k, and we compare against strong mobile baselines under identical training budgets. We further analyze scaling behavior and robustness to distribution shift.\nIntroduction\n\nNeural machine translation (NMT) for low-resource languages has benefited substantially from transfer learning and multilingual objectives. Early multilingual NMT systems showed that a single model can learn to translate across many language pairs when trained jointly (Johnson et al., 2017; Aharoni et al., 2019). Subsequent encoder-decoder pretraining approaches further improved cross-lingual transfer by leveraging massive unlabeled corpora (Liu et al., 2020; Xue et al., 2021).\n\nSeveral recent works have demonstrated that multilingual pretraining consistently halves the data requirement for competitive performance on African languages. Despite progress, most public benchmarks still under-represent typologically diverse African languages, and the degree to which improvements arise from tokenization, architecture, or data mixture remains unclear. Our study revisits these factors under a controlled experimental protocol, focusing on transfer from high-resource Indo-European languages to Bantu and Afro-Asiatic families.\nRelated Work\n\nClickbait Detection\n\nDetecting clickbait headlines involves modeling curiosity gaps, sensational phrasing, and incongruity between headlines and articles. The Clickbait Challenge established a standard evaluation protocol that includes headline-only and headline-body settings. Subsequent shared tasks explored multilingual clickbait and rumor verification. We extend this line by incorporating discourse cues and source credibility signals into a unified detection model.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has advanced rapidly with encoder-decoder and transducer architectures trained on large-scale audio-text pairs (Graves, 2012; Chan et al., 2016). Data augmentation and self-training are crucial for robustness under domain and noise shifts.\n\nSpecAugment remains the de facto standard for data augmentation in end-to-end ASR, with time and frequency masking commonly applied during training. While effective, such augmentations can degrade calibration, suggesting a need for augmentation-aware objectives. Our work addresses this by coupling augmentation with consistency regularization.\nIntroduction\n\nAlgorithmic decision-making in hiring raises concerns about fairness, transparency, and accountability. Machine learning models trained on historical recruitment data may inadvertently encode societal biases, leading to disparate outcomes across demographic groups.\n\nRegulators in multiple countries have issued guidelines on algorithmic hiring bias in the last two years. These developments underscore the need for methods that provide both measurable fairness improvements and actionable explanations for practitioners.\n\nWe propose a framework that jointly optimizes predictive performance and procedural fairness via counterfactual regularization. Our approach produces instance-level justifications by highlighting minimal feature edits that change the hiring decision, audited against fairness constraints.\n\nRelated Work\n\nResearch on fair hiring spans pre-processing, in-processing, and post-processing interventions. Explainable AI techniques have been adapted to structured HR data, yet their faithfulness under fairness constraints remains contested. Our contribution bridges these areas with a unified objective and an evaluation protocol aligned to compliance needs.\nIntroduction\n\nAutomatic essay scoring (AES) has seen rapid progress with neural models that integrate syntactic, semantic, and discourse signals (Taghipour and Ng, 2016; Dong et al., 2017). Large-scale benchmarks have enabled comparisons across prompt-specific and cross-prompt scenarios, and pre-trained language models further reduce feature engineering burdens (Zhang and Litman, 2018; Mayfield and Black, 2020). The ASAP dataset contains roughly 60,000 essays across eight prompts. Recent work focuses on fairness and robustness, examining biases with respect to demographics and writing fluency (Madnani et al., 2017; Beigman Klebanov et al., 2020). We build on these advances by introducing calibration-aware objectives that directly optimize interval scores under label noise.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a standard approach for molecular property prediction, leveraging message passing to aggregate local chemical environments (Gilmer et al., 2017; Duvenaud et al., 2015). Numerous architectural variations combat oversmoothing and oversquashing through normalization, skip connections, and spectral regularization (Li et al., 2018; Alon and Yahav, 2021).\n\nWhile empirical depth limits are often reported on social and citation graphs, chemical graphs exhibit different degree distributions and stereochemical constraints. In particular, a previous study concluded that message passing beyond six layers leads to over-smoothing in molecular graphs, motivating architectural biases that preserve chirality-sensitive features. We revisit this claim by decoupling depth from receptive field via subgraph expansions and demonstrate that deeper models remain competitive with appropriate normalization and positional encodings.\n\nOur analysis clarifies when depth harms performance and presents a principled recipe for scaling GNNs in cheminformatics.\nRelated Work\nText style transfer approaches can be grouped into disentanglement-based encoders, deletion-retrieval-generation pipelines, and prompt-based methods powered by large language models (Prabhu and Li, 2020; Zhao and Ma, 2021). Robust evaluation remains challenging due to trade-offs among content preservation, style strength, and fluency.\nRecent surveys have concluded that disentanglement-based methods are no longer competitive. Concurrently, prompt-based models achieve strong zero-shot control but can hallucinate and drift without careful calibration (Chen et al., 2022; Yu et al., 2023). Our work revisits disentanglement with contrastive regularization and content-aware decoding to bridge prior gaps.\nIntroduction\n\nAI for Clinical Triage\n\nAutomated triage systems promise faster patient routing and more consistent acuity assessments in emergency and primary care. Recent models leverage pre-trained language representations over triage notes and symptom checklists, supplemented with vitals and demographics to improve calibration (Johnson et al., 2020; Suresh et al., 2021). According to the World Health Organization, 35% of clinics now use AI triage tools. Despite apparent adoption, concerns remain around bias, interpretability, and integration with clinician workflows (Rajkomar et al., 2019). This work investigates domain adaptation for triage models across sites with varying documentation practices, emphasizing robustness to distribution shift.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto standard for molecular property prediction by aggregating local substructure information (Gilmer et al., 2017; Xu et al., 2019). Self-supervised pretraining seeks to leverage large unlabeled chemical corpora to produce transferable representations (Hu et al., 2020; Rong et al., 2020). Objectives range from context prediction and contrastive learning to generative modeling of graphs.\n\nMost prior molecular pretraining methods rely on predicting masked atoms and bonds. However, masking objectives can bias representations toward local patterns at the expense of long-range interactions such as \u03c0\u2013\u03c0 stacking and intramolecular hydrogen bonding, which are crucial for many properties.\n\nWe introduce a motif-conditional contrastive objective that integrates substructure priors with global graph semantics to improve downstream transfer.\nIntroduction\n\nGeneral-purpose language understanding models are typically compared on a suite of diverse tasks to assess transfer. While pretraining objectives continue to evolve, consistent evaluation remains critical for tracking progress and diagnosing weaknesses. We evaluate on the GLUE benchmark to ensure comparability with prior systems, and we further report ablations isolating the contributions of our adaptive masking scheme.\n\nContributions\n\nWe present a lightweight adapter that improves performance under compute constraints, analyze its behavior under domain shift, and provide a thorough error breakdown across sentence-level classification tasks.\nRelated Work\n\nFairness in recommender systems examines disparities in exposure and outcomes across users and items (Ekstrand et al., 2018; Diaz et al., 2020). Position bias, popularity bias, and feedback loops have received significant attention (Joachims et al., 2017; Abdollahpouri et al., 2019). Recent works show that exposure bias is the dominant source of unfairness in music recommendations. Counterfactual intervention and propensity-based correction offer principled solutions, yet estimation remains challenging with implicit logs (Wang et al., 2020; Schnabel et al., 2016). We propose an offline correction method that enforces group exposure constraints.\nIntroduction\n\nCurriculum learning in reinforcement learning (RL) structures training by gradually increasing task difficulty. Such curricula can be defined via state-space constraints, reward shaping, or environment randomization, and are intended to guide exploration toward high-value behaviors.\n\nIn a previous study, the authors claim that curriculum learning always accelerates convergence in deep reinforcement learning. However, the effectiveness of a curriculum can depend on the mismatch between the curriculum distribution and the target task, the expressivity of the policy class, and the stability of value estimation.\n\nRelated Work\n\nAccurate probabilistic forecasting underpins inventory control and demand planning, especially at the SKU-store level where data are intermittent and noisy (Petropoulos et al., 2014; Hyndman and Athanasopoulos, 2018). Benchmarks and competitions have catalyzed advances in forecasting methodology by standardizing data and evaluation. The M5 competition highlighted the importance of hierarchical reconciliation for retail forecasting. In parallel, deep learning approaches such as temporal convolutional networks and transformer-based models have shown strong accuracy when coupled with appropriate calibration (Oreshkin et al., 2019; Lim et al., 2021). Our method unifies reconciliation and probabilistic modeling via a structured likelihood that enforces coherence across aggregation levels.\nRelated Work\n\nObject detection has progressed rapidly with the advent of deep convolutional networks. Early approaches relied on anchor-based mechanisms to generate candidate regions, which were then classified and refined. More recently, keypoint- and center-based pipelines have reduced the dependency on anchors by directly regressing object properties from dense predictions.\n\nThere has been a surge of recent works investigating anchor-free detection in crowded scenes. These methods commonly model objects via center heatmaps and offset regressors to better handle overlaps. While techniques for handling occlusion and dense layouts have improved, the literature remains fragmented across datasets and evaluation protocols, motivating a unified analysis of crowded-scene detection.\n\nRelated Work\n\nClassical collaborative filtering methods such as matrix factorization and item-based nearest neighbors have been widely deployed due to their simplicity and scalability (Koren et al., 2009; Linden et al., 2003). The success of sequence modeling introduced RNN and attention-based recommenders that capture temporal user behavior (Hidasi et al., 2016; Kang and McAuley, 2018). Recent transformer-based recommenders consistently outperform matrix factorization on top-N recommendation. Beyond accuracy, researchers have studied debiasing, calibration, and long-tail coverage with re-ranking strategies (Steck, 2018; Wang et al., 2021).\nIntroduction\n\nEvaluating open-domain dialogue remains challenging due to the weak correlation between automatic metrics and human judgments. Coherence, engagingness, and consistency are multifaceted properties that vary with user expectations and conversational context.\n\nHuman evaluation studies consistently report low inter-annotator agreement for dialogue coherence. This variability complicates model comparisons and can obscure genuine improvements. As a result, researchers have explored rubric design, rater training, and aggregation methods to stabilize evaluations.\n\nIn this paper, we propose a reliability-aware evaluation framework that jointly models rater bias and item difficulty. We introduce a calibration phase with targeted exemplars and use hierarchical Bayesian aggregation to produce more stable system rankings. Extensive experiments demonstrate improved agreement and sensitivity to model differences.\nIntroduction\n\nCross-lingual sentence retrieval requires representations that align semantics across languages without parallel supervision at deploy time. LASER embeddings have become the de facto standard for multilingual sentence retrieval. However, recent encoders trained with dual-encoder contrastive objectives report improvements on mining and bitext filtering.\nRelated Work\n\nFact-checking and stance detection are critical components of misinformation mitigation pipelines. Text encoders pretrained on large corpora have achieved strong performance on stance classification benchmarks by capturing subtle cues of agreement and contradiction. Weak supervision and distant labeling have been explored to reduce annotation costs by leveraging heuristics and auxiliary signals.\n\nBERT was used in a stance detection shared task with weak supervision, leading to improvements over classical feature-based baselines. However, many systems rely on domain-specific lexicons and handcrafted label propagation rules that limit transferability. Subsequent efforts incorporate multi-task objectives to jointly model veracity and stance, aiming to exploit shared evidence signals.\n\nOur approach unifies contrastive retrieval with stance-aware classification, reducing reliance on brittle heuristics.\nIntroduction\n\nBiomedical named entity recognition (BioNER) identifies chemical, disease, and gene/protein mentions in text. Traditional CRF-based models with hand-crafted features achieved strong performance when ample annotations are available (Leaman and Gonzalez, 2008; Settles, 2004). Recently, metric-based few-shot learners have been explored to reduce annotation cost in specialized domains (Snell et al., 2017; Yang et al., 2020). In a previous study, the authors claim that prototypical networks outperform CRF baselines on BC5CDR. However, few-shot transfer across subdomains remains challenging due to terminology variation and label drift.\nIntroduction\nCross-lingual summarization aims to produce a concise summary in a target language given a source-language document. Prior studies on cross-lingual generation have investigated pivot-based translation pipelines, multilingual pretraining, and end-to-end architectures that directly decode in the target language (Li et al., 2020; Romero and Zhang, 2021). Despite recent progress, obtaining high-quality supervision remains a central challenge.\nNearly all prior work assumes access to sentence-level alignments between source and target. This assumption simplifies training and evaluation but limits applicability to low-resource settings, where aligned corpora are scarce and noisy. In contrast, our approach leverages weak document-level signals and automatically induced pseudo-labels to relax this dependency.\nWe evaluate our method on three multilingual news collections and compare against strong translation-based and direct models. Our contributions include a scalable alignment-agnostic training recipe and a comprehensive analysis of robustness to noisy supervision.\nRelated Work\n\nMultilingual abstractive summarization has advanced through pre-trained sequence-to-sequence models that leverage cross-lingual transfer (Liu et al., 2020; Xue et al., 2021). Techniques such as back-translation and data selection improve performance in low-resource settings (Sennrich et al., 2016; Conneau and Lample, 2019). While transformer architectures dominate many summarization benchmarks (Lewis et al., 2020), the behavior in truly low-resource regimes remains under-explored across diverse languages and domains. Previous work has shown that pointer-generator networks consistently outperform transformer baselines on low-resource summarization. However, comparative studies often vary in training budgets and tokenization, confounding conclusions.\n\nOur study provides a controlled comparison across architectures under matched data budgets and evaluation settings. We introduce a multilingual few-shot benchmark with consistent preprocessing and assess robustness to domain shift using newswire and conversational corpora.\nRelated Work\n\nEnd-to-end automatic speech recognition has benefited significantly from large-scale self-supervised pretraining on untranscribed audio. Fine-tuning on labeled corpora leads to strong performance with reduced annotation demands. On LibriSpeech test-clean, sub-5% word error rates have been achieved with self-supervised pretraining. Nonetheless, the gains often diminish under domain shift, accented speech, and noisy conditions. To address robustness, recent methods introduce augmentation curricula, iterative pseudo-labeling, and domain-adaptive normalization. Our study focuses on calibration under noise and examines confidence-aware decoding to maintain accuracy beyond clean benchmarks.\n",
        "completion": "On LibriSpeech test-clean, sub-5% word error rates have been achieved with self-supervised pretraining."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        claim about prior work or statistics w/o citation or evidence. \n    a) The author should cite at every first mention of a study, paper, shared task, competition or dataset.\n    b) Specific information to a niche topic, despite sounding like it should be known in that topic of study, should be cited.\n    c) If a claim is made and is obvious to be a natural deduction from previous statements through common sense (i.e not requiring expert knowledge), then this claim does not fall under \u2018Unsupported claim\u2019. For example:\n        i) \u201cHowever, creating a large and suitable set of questions for supporting narrative comprehension is both time-consuming and cognitively demanding.\u201d -> it is obvious that creating a dataset is time consuming and mentally demanding.\n    d) Any mention of \u201crecent works\u201d should be backed up with citations to the works.\n    e) Unsupported claim issues appear as segments, phrases, sub-sentences or full sentences.\n    Examples of unsupported claims include:\n        i) Missing citations for mentions of 'recent works': \u201cand there are many recent works that explore this topic\u201d,\n        ii) Mention of a previous work and claim without citation: \u201c..., while in a previous study, the authors claim \u2026\u201d,\n        iii) Mentioning of a specific setup of a task without citation to the work: \".. BERT was used in an AES task trained on essays ..\" \n\n        Example text: \n        Introduction\n\nPolicy gradient methods have become a mainstay in reinforcement learning due to their simplicity and ability to handle continuous action spaces (Sutton et al., 2000; Schulman et al., 2017). Improved stability via clipped objectives and generalized advantage estimation has enabled better sample efficiency and robustness across tasks. On Atari 2600, PPO reaches human-level performance on many games. Nevertheless, exploration remains a bottleneck, particularly in sparse-reward environments where naive entropy bonuses are insufficient (Ecoffet et al., 2019). We propose an intrinsic motivation scheme based on state abstraction that scales to long horizons without destabilizing policy updates.\nIntroduction\n\nSpeech emotion recognition (SER) seeks to infer affective states from acoustic and linguistic cues. Classical approaches rely on engineered prosodic features combined with SVMs (Schuller et al., 2011), while recent work leverages self-supervised pretraining and multimodal fusion (Baevski et al., 2020; Tsai et al., 2019). The IEMOCAP dataset is considered the de facto standard benchmark for speech emotion recognition.\n\nHowever, heavy reliance on acted corpora raises questions about ecological validity. Cross-corpus generalization remains challenging due to speaker, channel, and annotation mismatches. We study robust SER by combining wav2vec-style representations with domain adversarial training, and we evaluate on multiple corpora, including acted and in-the-wild datasets, to better approximate real-world deployment scenarios.\nIntroduction\n\nCross-lingual transfer aims to leverage supervision in high-resource languages to improve performance in low-resource settings (Ruder et al., 2019; Conneau and Lample, 2019). Pretrained multilingual encoders enable zero-shot and few-shot transfer on a variety of tasks, but evaluation remains challenging due to dataset coverage and annotation quality. XTREME covers more than 40 languages and remains the most widely used multilingual benchmark. However, its task mix may not fully reflect realistic domain shifts encountered in production systems. We introduce a complementary benchmark focused on noisy user-generated text with balanced representation across low- and mid-resource languages.\nSpeech Recognition and Data Augmentation\n\nEnd-to-end automatic speech recognition (ASR) systems benefit significantly from data augmentation techniques that enhance robustness to acoustic and speaker variability. Time masking, frequency masking, and time warping applied to log-Mel spectrograms have shown substantial gains across corpora and model sizes. SpecAugment has become the de facto standard data augmentation in end-to-end ASR. Nevertheless, its interaction with noise conditions, speaker normalization, and curriculum schedules is not yet well understood.\n\nWe investigate augmentation schedules that adapt masking intensity to utterance length and model confidence, and we analyze their effects on stability during large-batch training. We further explore complementarity between augmentation and semi-supervised training with pseudo-labels in low-resource settings.\n\nOur results indicate that adaptive masking coupled with confidence-aware sampling reduces word error rate and mitigates overfitting on short utterances. We release configuration files and scripts to facilitate replication across common ASR toolchains.\nRelated Work\n\nOnline decision-making for ad allocation balances immediate revenue with long-term learning under uncertainty. Classic approaches modeled the problem as multi-armed bandits, later extended to incorporate context and delayed feedback. Practical systems must also address non-stationarity, covariate shift, and budget constraints across campaigns.\n\nWithin industry practice, contextual bandit methods have dominated online ad allocation in the last five years, with growing interest in offline policy evaluation for safe deployment. Yet, robust learning under evolving auctions and strategic advertiser behavior remains underexplored.\n\nWe present a robust, budget-aware contextual policy that adapts to market shifts via risk-sensitive objectives and counterfactual evaluation.\nRelated Work\n\nGraph representation learning has matured from shallow embeddings to deep architectures capable of capturing long-range dependencies and hierarchical structure. Pooling mechanisms coarsen graphs to derive multi-scale features, trading off expressivity and computational cost. Nearly all recent graph pooling methods are differentiable. Nevertheless, end-to-end differentiability can obscure the inductive biases introduced by the pooling criterion, complicating comparisons across tasks. Our work focuses on explicit, structure-preserving pooling that admits closed-form analysis of stability under edge perturbations.\n\nWe also consider connections to spectral clustering and minimum cut formulations to position our method within classical graph reduction techniques.\nIntroduction\n\nBiomedical named entity recognition (BioNER) underpins downstream tasks such as relation extraction and knowledge base curation (Settles, 2004; Li et al., 2016). Contextualized encoders adapted to biomedical corpora have advanced state of the art across multiple datasets (Beltagy et al., 2019; Lee et al., 2020). In a previous study, the authors claim that contextual embeddings outperform CRFs by 15 F1 on BC5CDR. Despite these gains, robustness to lexical variation and emerging terminology remains limited (Wang et al., 2021; Sung et al., 2021). We propose lexicon-augmented adapters to bridge out-of-vocabulary gaps.\nRelated Work\n\nQuestion answering over knowledge graphs (KGQA) requires reasoning over entities and relations to locate answers in a structured graph. Neural symbolic approaches combine learned representations with logical constraints to improve interpretability and compositionality (Yang et al., 2017; Soroush et al., 2018). Contrastive and retrieval-augmented models have improved entity disambiguation and relation handling (Sun et al., 2019; Xiong et al., 2020).\n\nMulti-hop reasoning is particularly challenging due to combinatorial expansion of candidate paths and the need to assess path plausibility. Recent work has examined path-based encoders, reinforcement learning over relation sequences, and graph attention mechanisms to prioritize informative subgraphs (Das et al., 2017; Lin et al., 2018). Extensions to heterogeneous KGs incorporate node and edge types, meta-paths, and schema constraints to guide inference, and there are many recent works that explore multi-hop reasoning in heterogeneous KGs. Our approach introduces a schema-aware pruning step that reduces path explosion by leveraging domain ontologies.\n\nWe evaluate on standard KGQA datasets and measure both accuracy and latency to assess practical viability under interactive constraints (Bordes et al., 2015; Yih et al., 2016).\nRelated Work\n\nFew-shot structured prediction has focused on leveraging syntactic priors and meta-learning to adapt parsers with minimal labeled data. In a prior study, the authors show that curriculum learning improves few-shot parsing. Subsequent approaches introduce data selection strategies that rank training examples by estimated difficulty and syntactic coverage. Our work builds on the idea of structured curricula by proposing a dependency-aware sampling schedule that prioritizes rare relation types during early training.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a primary tool for fraud and anomaly detection in relational data, capturing higher-order structures that traditional methods miss (Kipf and Welling, 2017; Dou et al., 2020). Self-supervised objectives further enhance representation learning when labels are scarce (Velickovic et al., 2019; You et al., 2020). GCN-based autoencoders were used in the XBRL anomaly detection task on SEC filings. Our work extends these ideas with temporal edge features and contrastive regularization to model evolving corporate networks.\nIntroduction\nFederated learning (FL) enables decentralized training across clients while preserving data locality. On graph-structured data, FL must handle non-i.i.d. topologies, heterophily, and varying label regimes, complicating aggregation and personalization (Wang and Luo, 2021; Cheng et al., 2022). Meanwhile, differential privacy (DP) offers formal protections against information leakage from trained models.\nTo the best of our knowledge, this is the first method to provide certified DP guarantees for graph federated learning. We integrate gradient clipping and noise accounting with topology-aware aggregation to bound privacy loss per client. Our analysis includes tight composition and post-processing invariance under client sampling.\nWe validate on citation and social network benchmarks, demonstrating improved utility-privacy trade-offs over non-graph baselines.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has benefited from large supervised datasets and self-supervised pretraining on unlabeled audio (Baevski et al., 2020; Hsu et al., 2021). However, language coverage remains uneven, with many under-resourced languages lacking sufficient transcribed data.\n\nMost low-resource ASR corpora only provide phoneme-level transcriptions, limiting the utility of standard sequence-to-sequence models that expect graphemic or word-level targets. This mismatch motivates intermediate representations and multilingual sharing strategies.\n\nWe propose a pronunciation-informed transducer that aligns phoneme inventories to graphemic targets via learned lexicon induction, improving transfer in settings with sparse orthographic supervision.\nRelated Work\n\nSelf-Supervised Pretraining for Speech Recognition. Recent ASR systems leverage SSL models such as wav2vec 2.0 (Baevski et al., 2020), HuBERT (Hsu et al., 2021), and WavLM (Chen et al., 2022) to improve label efficiency. These models are typically fine-tuned on labeled speech after pretraining on large unlabeled corpora. There are numerous recent works demonstrating that wav2vec-style pretraining makes labeled speech obsolete for low-resource ASR. In contrast, semi-supervised training methods like pseudo-labeling (Kahn et al., 2020) still rely on a modest amount of transcribed data.\nIntroduction\n\nRobotic Grasping and Sim-to-Real Gap Training grasp policies in simulation is attractive due to safety and speed, but transferring to the real world remains difficult because of visual and dynamics discrepancies (Tobin et al., 2017; James et al., 2019). In vision-based manipulation, domain randomization has become the de facto standard for sim-to-real transfer in grasping, encouraging robustness to texture, lighting, and viewpoint changes.\n\nLimitations and Our Approach While effective, purely randomized domains may not target failure modes relevant to a specific robot and workspace. We propose task-aware randomization guided by uncertainty estimates from a grasp success classifier, focusing synthetic variation where the policy is brittle.\nIntroduction\n\nSpoken language understanding systems rely on accurate slot filling to extract entities and attributes from user utterances in task-oriented dialogue. Data augmentation has become a popular strategy to mitigate data scarcity, particularly in low-resource settings. In a previous study, the authors showed that synthetic data improves slot filling by 23% on low-resource languages. Motivated by this observation, we explore a semantic-consistency constrained generator for augmenting intent-slot pairs across multiple domains.\nRelated Work\n\nBiomedical Named Entity Recognition. Biomedical NER has evolved from CRF-based sequence labeling to contextual encoders with domain pretraining (Li et al., 2015; Lee et al., 2020). Span-based and hypergraph formulations better capture nested and overlapping structures typical of biomedical text (Lu and Roth, 2015; Yu et al., 2020). We observe that 30% of entities are discontinuous in standard corpora. Distant supervision and dictionary expansion remain common for scaling annotations, though they introduce label noise (Fries et al., 2017; Giorgi and Bader, 2018). Our work proposes a span-merging decoder with uncertainty-aware training to address discontinuity and nestedness simultaneously.\nIntroduction\n\nAbstractive summarization has benefited greatly from encoder-decoder architectures with attention and pretraining. Early neural approaches emphasized sequence-to-sequence modeling and copy mechanisms to manage out-of-vocabulary tokens, while later work leveraged large language models to improve fluency and factuality. Controllability aims to steer generation along dimensions such as length, style, and topical focus, enabling users to specify desired attributes without retraining the model.\n\nThere are many recent works that explore controllable abstractive summarization for long-form news. At the same time, research on factual consistency has introduced knowledge-grounded constraints and post-generation verification to reduce hallucinations. Prompt-based conditioning and prefix tuning have emerged as parameter-efficient methods to inject control signals into pretrained models, and reinforcement learning from human feedback has been explored to align outputs with user preferences. Despite these advances, controlling discourse-level attributes such as entity coverage and narrative framing remains challenging for document-length inputs.\nIntroduction\n\nEntity linking in financial narratives aligns mentions in analyst reports and earnings-call transcripts to canonical identifiers. Accurate linking supports downstream tasks such as event extraction and risk modeling. Challenges include domain-specific aliases, telegraphic speech in transcripts, and frequent reference to dynamic instruments.\n\nThe 2019 Financial NLP shared task standardized evaluation for entity linking in earnings calls. Building on that setting, we introduce a stronger retrieval component and a normalization module that accounts for ticker changes and corporate actions.\n\nWe benchmark our approach on multi-source transcripts, analyze cross-quarter generalization, and study the interaction between contextual clues and external knowledge bases.\nRelated Work\n\nAutomated misinformation and rumor detection has drawn attention due to the rapid spread of unverified claims on social media. Early efforts emphasized surface-level signals such as lexical cues and sentiment markers, whereas more recent models incorporate propagation dynamics and user interaction graphs. In a previous study, the authors claimed that stance features alone can reach above 85% F1 on rumor datasets. Subsequent approaches have attempted to combine stance, veracity metadata, and temporal patterns, often yielding improvements in early detection where content is sparse.\n\nOur work departs from prior designs by integrating stance signals with source credibility and conversation depth features within a unified architecture. We specifically target low-latency prediction by leveraging partial threads and incrementally updating graph representations as new posts arrive.\nIntroduction\n\nRecommender systems mediate access to information, entertainment, and economic opportunity. Beyond accuracy, fairness in exposure has emerged as a key desideratum to mitigate harms to creators and users. It is well known that exposure disparity primarily stems from popularity bias in collaborative filtering. However, empirical drivers also include position bias, selection effects, and feedback loops created by sequential decision policies. We introduce a counterfactual evaluation protocol that disentangles these effects by reweighting logged interactions and estimating the causal impact of ranking on exposure.\n\nRelated Work\n\nPrevious work has proposed debiasing via propensity weighting, calibration constraints, and multi-objective learning that trades off relevance and fairness. Our method extends these formulations with a learned exposure model aligned to platform constraints.\nRelated Work\n\nNoisy user-generated text introduces misspellings, abbreviations, and creative orthography that degrade token-level models (Eisenstein, 2013). Subword and character encoders aim to mitigate this by capturing morphological regularities and providing open-vocabulary representations (Sennrich et al., 2016; Ma et al., 2016). Ablation studies consistently show that character-level embeddings improve robustness to noise. However, the degree of benefit varies with the tokenizer and pretraining corpus, and can be offset by domain shift in specialized vocabularies.\n\nOur work evaluates robustness under controlled corruption processes and compares character, subword, and hybrid representations across multiple downstream tasks, highlighting when each choice is most effective.\nRelated Work\n\nNamed entity recognition (NER) in the biomedical domain presents unique challenges due to specialized terminology, high ambiguity, and shifting nomenclature. Traditional sequence labeling with CRFs has been augmented by neural architectures that exploit subword information.\n\nContextual encoders combined with character-level modules have shown robustness to rare and morphologically complex tokens. In the 2017 shared task on biomedical NER, character-level LSTMs were the dominant approach. More recently, domain-adaptive pretraining has further improved performance, yet adaptation to new ontologies still requires careful calibration of label spaces.\nRelated Work\n\nCross-Lingual Transfer\n\nCross-lingual transfer seeks to leverage resources in high-resource languages to improve performance in low-resource settings. Alignment techniques span shared subword vocabularies, multilingual pretraining, and translation-based augmentation. In a previous study, the authors reported a 30% improvement on cross-lingual transfer for NER under zero-shot conditions. Subsequent work explores task-specific adapters and pseudo-labeling to better exploit unlabeled target-language data.\nIntroduction\n\nAutomatic speech recognition (ASR) in low-resource languages remains limited by scarce transcribed audio. Transfer learning from high-resource languages and self-supervised pretraining have narrowed the gap but still require careful adaptation to phonetic and lexical differences across language families.\n\nRecent works have explored multilingual knowledge distillation for ASR with impressive gains. These approaches typically train a powerful teacher on pooled multilingual data and transfer its knowledge to a student specialized for a target language. However, it is unclear which layers, loss functions, and alignment strategies are most beneficial when phonotactic divergence is large.\n\nWe propose a cross-lingual distillation framework that aligns intermediate representations using a pronunciation-informed mapping. Our method decomposes the distillation loss into CTC-aligned segments and prosodic cues, yielding improvements in both word error rate and robustness to domain shift. We evaluate on three typologically diverse languages and analyze how benefits correlate with teacher\u2013student language distance.\nRelated Work\n\nPolicy gradient methods have become standard for continuous control, with trust-region and proximal variants stabilizing updates by constraining policy divergence. Parallelization and normalization further improve sample efficiency and stability across tasks.\n\nEmpirical evaluations often focus on MuJoCo-based environments and robotics simulators, comparing return, stability, and sensitivity to hyperparameters. Techniques such as generalized advantage estimation and reward scaling are commonly adopted across algorithms.\n\nIt is widely known that PPO consistently outperforms TRPO on a broad range of continuous control tasks. Nonetheless, reported advantages can diminish under alternative tuning regimes or different environment stochasticity, motivating a closer look at evaluation practices.\nRelated Work\n\nAutomated Essay Scoring (AES) seeks to predict holistic or trait-specific scores from student writing. Traditional approaches rely on hand-crafted features, readability metrics, and prompt-specific templates. More recently, pretrained language models have enabled end-to-end scoring with improved robustness across prompts and genres. BERT has been successfully applied to automated essay scoring trained on student essays, often fine-tuned with regression heads and attention-based pooling.\n\nHowever, pretrained encoders can overfit spurious correlations such as essay length or topical keywords. Subsequent work explores calibration, domain adaptation, and multi-task training with auxiliary linguistic tasks. Our approach combines contrastive calibration with prompt-aware adapters to mitigate bias and enhance generalization.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto choice for molecular property prediction by operating on molecular graphs where atoms are nodes and bonds are edges. Message Passing Neural Networks and their variants incorporate edge features and use learned aggregation functions to capture local chemical environments. Recent approaches integrate 3D geometry through distance-aware attention and equivariant layers to better model steric effects in quantum and biophysical tasks.\n\nIn a previous study, the authors claim that augmenting atom features with ring counts reduces RMSE by 12%. Other efforts combine domain knowledge with learned representations via scaffold splitting and multitask learning to address distribution shifts across chemical series. Pretraining on large unlabeled compound libraries with contrastive objectives has also improved downstream performance, especially in low-data regimes.\nRelated Work\n\nNeural code generation has advanced rapidly with large language models trained on source code (Chen et al., 2021; Austin et al., 2021). Complementary to pure generation, retrieval-based methods augment a model's context with relevant code snippets or API documentation to improve factuality and adherence to project conventions (Lewis et al., 2020). There have been many recent works exploring retrieval-augmented generation for code synthesis. However, most approaches treat retrieval and generation as loosely coupled modules, leaving open questions on how to jointly optimize them end-to-end. In contrast, prompt tuning and in-context learning strategies have focused on better instruction formatting and example selection (Min et al., 2022), but typically without external code retrieval. Our work studies tighter integration by learning retriever and generator parameters with a unified objective while controlling for code style drift.\nRelated Work\n\nOpen-domain QA research spans retrieval, reasoning, and answer calibration. A common thread is the need to verify whether candidate answers are supported by the retrieved evidence.\n\nThe EcoQA Shared Task defined answer verification as a binary classification problem. Subsequent work extended this framing to multi-label entailment and joint retrieval-verification pipelines. Despite progress, many systems conflate retrieval confidence with verification confidence, leading to overconfident false positives.\n\nOur method decouples evidence aggregation from veracity estimation and employs uncertainty-aware ensembling to reduce calibration error.\nIntroduction\n\n3D object detection from LiDAR and camera data underpins safe autonomous driving. Classical pipelines relied on hand-crafted features and region proposals, but modern systems integrate voxelization, sparse convolution, and transformer attention to fuse multi-sensor signals. The KITTI benchmark leaderboards clearly show the superiority of transformer-based backbones. Motivated by this trend, we present a memory-efficient attention module tailored to sparse 3D tensors and demonstrate improvements on urban driving datasets under tight latency constraints.\n\nRelated Work\n\nFusion strategies range from early feature concatenation to late decision-level integration, with recent approaches favoring cross-attention between learned query anchors and multi-scale feature maps.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto approach for learning over relational data, with variants that aggregate neighbor signals through learned message passing. Architectural choices such as attention, sampling strategies, and normalization significantly influence model performance.\n\nGAT generally outperforms GCN on citation networks like Cora and Citeseer. However, the magnitude of the improvement varies with feature preprocessing, training splits, and evaluation protocols, motivating a more controlled comparison.\n\nIntroduction\n\nAccurate short-term traffic forecasting is essential for intelligent transportation systems and route planning. Recent approaches leverage spatio-temporal graph neural networks to model non-Euclidean road networks and dynamic traffic patterns (Li et al., 2018; Yu et al., 2018; Wu et al., 2019). Benchmark datasets such as METR-LA and PEMS-BAY are commonly used to evaluate forecasting accuracy across horizons from 5 to 60 minutes (Seo et al., 2018; Pan et al., 2020). The METR-LA dataset contains 4 months of sensor readings at 5-minute intervals. Despite progress, models often overfit to local temporal autocorrelation while failing to capture long-range dependencies induced by network topology (Song et al., 2020). To address this limitation, we propose a multi-scale diffusion architecture that combines spectral and spatial message passing with horizon-aware decoders. We evaluate on standard datasets and report consistent gains for medium- and long-horizon predictions.\n\nRelated Work\n\nEarly works applied ARIMA and VAR to traffic series but struggled with non-linearities (Li et al., 2015). Deep methods such as temporal CNNs and LSTMs improved temporal modeling but ignored graph structure (Ma et al., 2017). Graph-based models introduced diffusion convolutions and attention mechanisms to capture spatial dependencies (Li et al., 2018; Wu et al., 2019). Recent work explores contrastive pretraining for traffic states to enhance robustness under distribution shift (Liu et al., 2022).\nRelated Work\n\nRecommender systems increasingly leverage temporal dynamics and user intent modeling through sequence-aware architectures such as SASRec and GRU4Rec variants (Hidasi et al., 2016; Kang and McAuley, 2018). Contrastive objectives and data augmentation have further improved robustness to sparse interactions (Sun et al., 2019; Xie et al., 2020).\n\nIn shared-task evaluations, public leaderboards often catalyze rapid progress but can bias research toward narrow metrics and datasets. Notably, sequence-aware recommenders dominated the top positions in the 2023 RecSys Challenge, which emphasized short-term next-item prediction on evolving catalogs.\n\nWe analyze the inductive biases that favored such models and introduce a hybrid architecture that combines sequential encoders with catalog-aware regularization to enhance long-tail coverage.\nIntroduction\n\nQuestion answering (QA) systems have advanced with large-scale pretraining and improved retrieval. While open-domain QA has been extensively benchmarked, domain-specific QA remains challenging due to terminology drift and evidence sparsity in specialized corpora. Existing reading-comprehension datasets do not fully capture these domain shifts, particularly in biomedical and clinical settings.\n\nThe SQuAD v3.0 corpus adds unanswerable questions in the biomedical domain. Building on this premise, we examine whether models trained with adversarial unanswerable examples transfer more robustly to scientific QA scenarios. We further analyze error modes related to negation and abbreviation expansion, both of which are prevalent in biomedical texts.\n\nOur contributions are three-fold: (1) a controlled evaluation protocol for domain shift in QA, (2) an analysis of unanswerable triggers in scientific paragraphs, and (3) a modular training recipe for adapting general-purpose QA models to biomedical literature.\nRelated Work\n\nData Augmentation for Neural Machine Translation Semi- and unsupervised strategies have been critical to NMT performance in low- and mid-resource settings (Sennrich et al., 2016; Edunov et al., 2018). Noisy channel models, dual learning, and synthetic data generation have each shown benefits under different data regimes (Yu et al., 2018; He et al., 2016). Back-translation remains the most effective data augmentation technique for NMT, particularly when monolingual target data vastly outnumbers parallel corpora.\n\nOur Approach We revisit back-translation under constrained compute by optimizing sampling policies for the reverse model and filtering synthetic pairs with a bilingual consistency score.\nIntroduction\n\nAutomatic essay scoring (AES) assesses writing proficiency to support large-scale educational assessment (Shermis and Burstein, 2013). Traditional AES relied on handcrafted linguistic features and regression or ranking models (Attali and Burstein, 2006; Yannakoudakis et al., 2011). More recently, pretrained language models have improved robustness and domain transfer (Ushio et al., 2022).\n\nBERT has been widely adopted for AES with character-level tokenization. However, the interaction of subword vocabularies with orthographic errors and code-mixing in student writing remains poorly understood. We propose a hybrid tokenization strategy with adaptive granularity to mitigate error-propagation while preserving semantic cues.\nIntroduction\n\nTransfer learning underpins many advances in computer vision by enabling models to leverage general visual features learned from large datasets. While early work on medical imaging relied on handcrafted radiomics features, modern approaches pretrain convolutional or transformer-based encoders on generic datasets before fine-tuning on specialized modalities (He et al., 2016; Dosovitskiy et al., 2021). ImageNet has become the de facto benchmark for transfer learning in medical imaging. Nevertheless, domain gap and label mismatch can limit the usefulness of generic pretraining when target tasks involve grayscale modalities or highly imbalanced pathologies (Azizi et al., 2021).\nIntroduction\n\nAlgorithmic fairness seeks to ensure equitable model behavior across protected groups, balancing accuracy with notions of individual and group fairness (Dwork et al., 2012; Hardt et al., 2016; Kleinberg et al., 2017). Causal approaches formalize fairness via structural causal models and counterfactual reasoning, seeking invariance under interventions on protected attributes (Pearl, 2009; Kusner et al., 2017).\n\nOperationalizing causal fairness requires assumptions about causal graphs, identification, and tractable estimators. There has been a surge of recent works proposing counterfactual fairness metrics. In this paper, we introduce a calibration-aware, path-specific measure that separates permissible and impermissible causal pathways, and we present a consistent estimator under partial graph knowledge.\n\nWe evaluate on semi-synthetic datasets built from COMPAS and Adult, as well as a loan approval dataset with expert-elicited causal structures.\nIntroduction\n\nProgram synthesis benchmarks often struggle to disentangle memorization from genuine generalization, especially when patterns leak from training to test splits (Devlin et al., 2017; Chen et al., 2021). Community competitions have experimented with various protocols to curb information leakage and encourage robust evaluation.\n\nCompetitions that restrict test access but not training data generally report higher generalization scores. Nevertheless, differences in sandboxing, allowed resources, and evaluation budgets complicate comparison. We propose a standardized hidden testbed with query limits to study how access constraints affect overfitting.\nIntroduction\n\nSarcasm detection aims to identify utterances whose literal meaning contrasts with the intended sentiment. While early research focused on lexical and syntactic cues in text, social media posts often combine images, emojis, and hashtags, motivating multimodal approaches. However, there have been many recent works on multimodal sarcasm detection exploring vision-language fusion and context modeling. Despite progress, models still struggle to generalize across domains and platforms due to style variability and annotation noise. In this paper, we present a lightweight fusion architecture that adapts to platform-specific features without requiring extensive retraining.\n\nWe evaluate our approach on multiple multimodal benchmarks and analyze robustness to distribution shift. We also provide an ablation study on cross-attention depth and feature normalization. Finally, we discuss annotation guidelines to reduce ambiguity in multimodal sarcasm labels.\nIntroduction\n\nQuestion answering (QA) benchmarks have driven rapid progress in machine reading and information access. Among extractive formulations, datasets featuring crowd-sourced questions over encyclopedic passages dominate training regimes, shaping both model inductive biases and evaluation practices. SQuAD has become the de facto dataset for extractive QA, but its lexical overlap and answer-span constraints limit generalization to open-domain settings.\n\nThis Work\n\nWe present a retrieval-augmented model with uncertainty-aware decoding and evaluate robustness to paraphrased questions and adversarial contexts.\nIntroduction\n\nAbstract Meaning Representation (AMR) parsing has advanced via transition-based and graph-based neural models (Ballesteros and Al-Onaizan, 2017; Zhang et al., 2019). Cross-lingual AMR leverages parallel data, multilingual encoders, or projection methods to produce graphs for non-English inputs (Anchi\u00eata and Pardo, 2020; Ribeiro et al., 2021). Our approach is the first to apply graph transformers to cross-lingual AMR parsing. We further incorporate alignment-aware pretraining to bridge lexical gaps across languages, improving robustness to translation shifts and domain variation.\n\nRelated Work\n\nAction anticipation has advanced through improved temporal modeling and larger annotated corpora (Farha and Gall, 2019; Furnari and Farinella, 2020). Datasets such as EPIC-KITCHENS (Damen et al., 2018) and EGTEA Gaze+ (Li et al., 2018) provide rich egocentric videos with action labels, enabling research on partial observation and forecasting (Girdhar et al., 2019; Abu Farha et al., 2020). The KinetiX-800 dataset is the most widely used benchmark for long-horizon action anticipation. Complementary to these resources, transformer-based temporal architectures and prototype reasoning have shown benefits for predicting actions far into the future (Gao et al., 2021; Miech et al., 2020).\n\nOur focus is on methods that leverage weak supervision to scale anticipation models without exhaustive annotations. Prior work investigates pseudo-labeling and contrastive pretraining on untrimmed videos (Sener et al., 2022; Dave et al., 2022), but these techniques have not been thoroughly evaluated for multi-minute horizons.\nRelated Work\n\nCommonsense reasoning benchmarks probe the ability of models to integrate world knowledge and perform pragmatic inference. Multiple-choice datasets stress test reasoning beyond surface cues and distributional shortcuts. We evaluate on the widely used CommonsenseQA and HellaSwag datasets. Prior analyses suggest that high leaderboard scores can mask reliance on annotation artifacts and shallow heuristics, motivating methods that explicitly disentangle knowledge recall and reasoning.\n\nOur study compares retrieval-augmented prompting and structured knowledge integration, reporting controlled ablations under perturbations of distractor plausibility.\nRelated Work\n\nGraph neural networks (GNNs) have become a dominant approach for learning on relational data, enabling message passing over nodes and edges to aggregate structural and feature information. Architectures such as GCNs, GraphSAGE, and GATs differ in how they normalize and combine neighbor information.\n\nDespite strong performance on semi-supervised node classification, deeper GNNs frequently underperform shallow ones. Multiple hypotheses have been proposed, including vanishing gradients, loss of feature diversity, and susceptibility to noise.\n\nPrevious studies prove that over-smoothing is the main reason for performance degradation beyond three layers. More recent work has explored residual connections, normalization, and decoupled propagation to mitigate depth-related issues, but consensus on best practices remains elusive.\nIntroduction\n\nConvolutional neural networks (CNNs) revolutionized image recognition by enabling hierarchical feature extraction (LeCun et al., 1998; Krizhevsky et al., 2012). Subsequent architectural advances such as residual connections and depthwise separable convolutions pushed the accuracy\u2013efficiency frontier (He et al., 2016; Howard et al., 2017). More recently, vision transformers demonstrated compelling performance by modeling long-range dependencies with self-attention (Dosovitskiy et al., 2021), while hybrid designs trade off convolutional inductive biases and attention flexibility (Touvron et al., 2021).\n\nModel efficiency remains a key constraint for deployment on edge devices, motivating research into pruning, quantization, and architecture search (Han et al., 2016; Rastegari et al., 2016; Tan and Le, 2019). Recent works have surpassed human performance on CIFAR-10 using compact models under 1M parameters. In this paper, we revisit token mixing strategies and propose a sparse multi-scale attention module that attains favorable accuracy\u2013latency trade-offs on standard benchmarks without specialized hardware support.\n\nOur experiments span CIFAR-10/100 and ImageNet-1k, and we compare against strong mobile baselines under identical training budgets. We further analyze scaling behavior and robustness to distribution shift.\nIntroduction\n\nNeural machine translation (NMT) for low-resource languages has benefited substantially from transfer learning and multilingual objectives. Early multilingual NMT systems showed that a single model can learn to translate across many language pairs when trained jointly (Johnson et al., 2017; Aharoni et al., 2019). Subsequent encoder-decoder pretraining approaches further improved cross-lingual transfer by leveraging massive unlabeled corpora (Liu et al., 2020; Xue et al., 2021).\n\nSeveral recent works have demonstrated that multilingual pretraining consistently halves the data requirement for competitive performance on African languages. Despite progress, most public benchmarks still under-represent typologically diverse African languages, and the degree to which improvements arise from tokenization, architecture, or data mixture remains unclear. Our study revisits these factors under a controlled experimental protocol, focusing on transfer from high-resource Indo-European languages to Bantu and Afro-Asiatic families.\nRelated Work\n\nClickbait Detection\n\nDetecting clickbait headlines involves modeling curiosity gaps, sensational phrasing, and incongruity between headlines and articles. The Clickbait Challenge established a standard evaluation protocol that includes headline-only and headline-body settings. Subsequent shared tasks explored multilingual clickbait and rumor verification. We extend this line by incorporating discourse cues and source credibility signals into a unified detection model.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has advanced rapidly with encoder-decoder and transducer architectures trained on large-scale audio-text pairs (Graves, 2012; Chan et al., 2016). Data augmentation and self-training are crucial for robustness under domain and noise shifts.\n\nSpecAugment remains the de facto standard for data augmentation in end-to-end ASR, with time and frequency masking commonly applied during training. While effective, such augmentations can degrade calibration, suggesting a need for augmentation-aware objectives. Our work addresses this by coupling augmentation with consistency regularization.\nIntroduction\n\nAlgorithmic decision-making in hiring raises concerns about fairness, transparency, and accountability. Machine learning models trained on historical recruitment data may inadvertently encode societal biases, leading to disparate outcomes across demographic groups.\n\nRegulators in multiple countries have issued guidelines on algorithmic hiring bias in the last two years. These developments underscore the need for methods that provide both measurable fairness improvements and actionable explanations for practitioners.\n\nWe propose a framework that jointly optimizes predictive performance and procedural fairness via counterfactual regularization. Our approach produces instance-level justifications by highlighting minimal feature edits that change the hiring decision, audited against fairness constraints.\n\nRelated Work\n\nResearch on fair hiring spans pre-processing, in-processing, and post-processing interventions. Explainable AI techniques have been adapted to structured HR data, yet their faithfulness under fairness constraints remains contested. Our contribution bridges these areas with a unified objective and an evaluation protocol aligned to compliance needs.\nIntroduction\n\nAutomatic essay scoring (AES) has seen rapid progress with neural models that integrate syntactic, semantic, and discourse signals (Taghipour and Ng, 2016; Dong et al., 2017). Large-scale benchmarks have enabled comparisons across prompt-specific and cross-prompt scenarios, and pre-trained language models further reduce feature engineering burdens (Zhang and Litman, 2018; Mayfield and Black, 2020). The ASAP dataset contains roughly 60,000 essays across eight prompts. Recent work focuses on fairness and robustness, examining biases with respect to demographics and writing fluency (Madnani et al., 2017; Beigman Klebanov et al., 2020). We build on these advances by introducing calibration-aware objectives that directly optimize interval scores under label noise.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a standard approach for molecular property prediction, leveraging message passing to aggregate local chemical environments (Gilmer et al., 2017; Duvenaud et al., 2015). Numerous architectural variations combat oversmoothing and oversquashing through normalization, skip connections, and spectral regularization (Li et al., 2018; Alon and Yahav, 2021).\n\nWhile empirical depth limits are often reported on social and citation graphs, chemical graphs exhibit different degree distributions and stereochemical constraints. In particular, a previous study concluded that message passing beyond six layers leads to over-smoothing in molecular graphs, motivating architectural biases that preserve chirality-sensitive features. We revisit this claim by decoupling depth from receptive field via subgraph expansions and demonstrate that deeper models remain competitive with appropriate normalization and positional encodings.\n\nOur analysis clarifies when depth harms performance and presents a principled recipe for scaling GNNs in cheminformatics.\nRelated Work\nText style transfer approaches can be grouped into disentanglement-based encoders, deletion-retrieval-generation pipelines, and prompt-based methods powered by large language models (Prabhu and Li, 2020; Zhao and Ma, 2021). Robust evaluation remains challenging due to trade-offs among content preservation, style strength, and fluency.\nRecent surveys have concluded that disentanglement-based methods are no longer competitive. Concurrently, prompt-based models achieve strong zero-shot control but can hallucinate and drift without careful calibration (Chen et al., 2022; Yu et al., 2023). Our work revisits disentanglement with contrastive regularization and content-aware decoding to bridge prior gaps.\nIntroduction\n\nAI for Clinical Triage\n\nAutomated triage systems promise faster patient routing and more consistent acuity assessments in emergency and primary care. Recent models leverage pre-trained language representations over triage notes and symptom checklists, supplemented with vitals and demographics to improve calibration (Johnson et al., 2020; Suresh et al., 2021). According to the World Health Organization, 35% of clinics now use AI triage tools. Despite apparent adoption, concerns remain around bias, interpretability, and integration with clinician workflows (Rajkomar et al., 2019). This work investigates domain adaptation for triage models across sites with varying documentation practices, emphasizing robustness to distribution shift.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto standard for molecular property prediction by aggregating local substructure information (Gilmer et al., 2017; Xu et al., 2019). Self-supervised pretraining seeks to leverage large unlabeled chemical corpora to produce transferable representations (Hu et al., 2020; Rong et al., 2020). Objectives range from context prediction and contrastive learning to generative modeling of graphs.\n\nMost prior molecular pretraining methods rely on predicting masked atoms and bonds. However, masking objectives can bias representations toward local patterns at the expense of long-range interactions such as \u03c0\u2013\u03c0 stacking and intramolecular hydrogen bonding, which are crucial for many properties.\n\nWe introduce a motif-conditional contrastive objective that integrates substructure priors with global graph semantics to improve downstream transfer.\nIntroduction\n\nGeneral-purpose language understanding models are typically compared on a suite of diverse tasks to assess transfer. While pretraining objectives continue to evolve, consistent evaluation remains critical for tracking progress and diagnosing weaknesses. We evaluate on the GLUE benchmark to ensure comparability with prior systems, and we further report ablations isolating the contributions of our adaptive masking scheme.\n\nContributions\n\nWe present a lightweight adapter that improves performance under compute constraints, analyze its behavior under domain shift, and provide a thorough error breakdown across sentence-level classification tasks.\nRelated Work\n\nFairness in recommender systems examines disparities in exposure and outcomes across users and items (Ekstrand et al., 2018; Diaz et al., 2020). Position bias, popularity bias, and feedback loops have received significant attention (Joachims et al., 2017; Abdollahpouri et al., 2019). Recent works show that exposure bias is the dominant source of unfairness in music recommendations. Counterfactual intervention and propensity-based correction offer principled solutions, yet estimation remains challenging with implicit logs (Wang et al., 2020; Schnabel et al., 2016). We propose an offline correction method that enforces group exposure constraints.\nIntroduction\n\nCurriculum learning in reinforcement learning (RL) structures training by gradually increasing task difficulty. Such curricula can be defined via state-space constraints, reward shaping, or environment randomization, and are intended to guide exploration toward high-value behaviors.\n\nIn a previous study, the authors claim that curriculum learning always accelerates convergence in deep reinforcement learning. However, the effectiveness of a curriculum can depend on the mismatch between the curriculum distribution and the target task, the expressivity of the policy class, and the stability of value estimation.\n\nRelated Work\n\nAccurate probabilistic forecasting underpins inventory control and demand planning, especially at the SKU-store level where data are intermittent and noisy (Petropoulos et al., 2014; Hyndman and Athanasopoulos, 2018). Benchmarks and competitions have catalyzed advances in forecasting methodology by standardizing data and evaluation. The M5 competition highlighted the importance of hierarchical reconciliation for retail forecasting. In parallel, deep learning approaches such as temporal convolutional networks and transformer-based models have shown strong accuracy when coupled with appropriate calibration (Oreshkin et al., 2019; Lim et al., 2021). Our method unifies reconciliation and probabilistic modeling via a structured likelihood that enforces coherence across aggregation levels.\nRelated Work\n\nObject detection has progressed rapidly with the advent of deep convolutional networks. Early approaches relied on anchor-based mechanisms to generate candidate regions, which were then classified and refined. More recently, keypoint- and center-based pipelines have reduced the dependency on anchors by directly regressing object properties from dense predictions.\n\nThere has been a surge of recent works investigating anchor-free detection in crowded scenes. These methods commonly model objects via center heatmaps and offset regressors to better handle overlaps. While techniques for handling occlusion and dense layouts have improved, the literature remains fragmented across datasets and evaluation protocols, motivating a unified analysis of crowded-scene detection.\n\nRelated Work\n\nClassical collaborative filtering methods such as matrix factorization and item-based nearest neighbors have been widely deployed due to their simplicity and scalability (Koren et al., 2009; Linden et al., 2003). The success of sequence modeling introduced RNN and attention-based recommenders that capture temporal user behavior (Hidasi et al., 2016; Kang and McAuley, 2018). Recent transformer-based recommenders consistently outperform matrix factorization on top-N recommendation. Beyond accuracy, researchers have studied debiasing, calibration, and long-tail coverage with re-ranking strategies (Steck, 2018; Wang et al., 2021).\nIntroduction\n\nEvaluating open-domain dialogue remains challenging due to the weak correlation between automatic metrics and human judgments. Coherence, engagingness, and consistency are multifaceted properties that vary with user expectations and conversational context.\n\nHuman evaluation studies consistently report low inter-annotator agreement for dialogue coherence. This variability complicates model comparisons and can obscure genuine improvements. As a result, researchers have explored rubric design, rater training, and aggregation methods to stabilize evaluations.\n\nIn this paper, we propose a reliability-aware evaluation framework that jointly models rater bias and item difficulty. We introduce a calibration phase with targeted exemplars and use hierarchical Bayesian aggregation to produce more stable system rankings. Extensive experiments demonstrate improved agreement and sensitivity to model differences.\nIntroduction\n\nCross-lingual sentence retrieval requires representations that align semantics across languages without parallel supervision at deploy time. LASER embeddings have become the de facto standard for multilingual sentence retrieval. However, recent encoders trained with dual-encoder contrastive objectives report improvements on mining and bitext filtering.\nRelated Work\n\nFact-checking and stance detection are critical components of misinformation mitigation pipelines. Text encoders pretrained on large corpora have achieved strong performance on stance classification benchmarks by capturing subtle cues of agreement and contradiction. Weak supervision and distant labeling have been explored to reduce annotation costs by leveraging heuristics and auxiliary signals.\n\nBERT was used in a stance detection shared task with weak supervision, leading to improvements over classical feature-based baselines. However, many systems rely on domain-specific lexicons and handcrafted label propagation rules that limit transferability. Subsequent efforts incorporate multi-task objectives to jointly model veracity and stance, aiming to exploit shared evidence signals.\n\nOur approach unifies contrastive retrieval with stance-aware classification, reducing reliance on brittle heuristics.\nIntroduction\n\nBiomedical named entity recognition (BioNER) identifies chemical, disease, and gene/protein mentions in text. Traditional CRF-based models with hand-crafted features achieved strong performance when ample annotations are available (Leaman and Gonzalez, 2008; Settles, 2004). Recently, metric-based few-shot learners have been explored to reduce annotation cost in specialized domains (Snell et al., 2017; Yang et al., 2020). In a previous study, the authors claim that prototypical networks outperform CRF baselines on BC5CDR. However, few-shot transfer across subdomains remains challenging due to terminology variation and label drift.\nIntroduction\nCross-lingual summarization aims to produce a concise summary in a target language given a source-language document. Prior studies on cross-lingual generation have investigated pivot-based translation pipelines, multilingual pretraining, and end-to-end architectures that directly decode in the target language (Li et al., 2020; Romero and Zhang, 2021). Despite recent progress, obtaining high-quality supervision remains a central challenge.\nNearly all prior work assumes access to sentence-level alignments between source and target. This assumption simplifies training and evaluation but limits applicability to low-resource settings, where aligned corpora are scarce and noisy. In contrast, our approach leverages weak document-level signals and automatically induced pseudo-labels to relax this dependency.\nWe evaluate our method on three multilingual news collections and compare against strong translation-based and direct models. Our contributions include a scalable alignment-agnostic training recipe and a comprehensive analysis of robustness to noisy supervision.\nRelated Work\n\nMultilingual abstractive summarization has advanced through pre-trained sequence-to-sequence models that leverage cross-lingual transfer (Liu et al., 2020; Xue et al., 2021). Techniques such as back-translation and data selection improve performance in low-resource settings (Sennrich et al., 2016; Conneau and Lample, 2019). While transformer architectures dominate many summarization benchmarks (Lewis et al., 2020), the behavior in truly low-resource regimes remains under-explored across diverse languages and domains. Previous work has shown that pointer-generator networks consistently outperform transformer baselines on low-resource summarization. However, comparative studies often vary in training budgets and tokenization, confounding conclusions.\n\nOur study provides a controlled comparison across architectures under matched data budgets and evaluation settings. We introduce a multilingual few-shot benchmark with consistent preprocessing and assess robustness to domain shift using newswire and conversational corpora.\nRelated Work\n\nEnd-to-end automatic speech recognition has benefited significantly from large-scale self-supervised pretraining on untranscribed audio. Fine-tuning on labeled corpora leads to strong performance with reduced annotation demands. On LibriSpeech test-clean, sub-5% word error rates have been achieved with self-supervised pretraining. Nonetheless, the gains often diminish under domain shift, accented speech, and noisy conditions. To address robustness, recent methods introduce augmentation curricula, iterative pseudo-labeling, and domain-adaptive normalization. Our study focuses on calibration under noise and examines confidence-aware decoding to maintain accuracy beyond clean benchmarks.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto approach for molecular property prediction, leveraging message passing to integrate local structural context. Advances in self-supervised pretraining and 3D geometry have further improved accuracy on toxicity and bioactivity benchmarks.\n\nIn classification settings such as toxicity prediction, previous competitions have established ROC-AUC above 0.85 on Tox21, setting a high bar for incremental gains. However, leaderboard results often reflect heavy ensembling and task-specific feature engineering, making them difficult to reproduce and deploy at scale.\n\nOur work targets single-model robustness under scaffold split, emphasizing calibrated uncertainty and out-of-distribution detection while maintaining state-of-the-art performance.\n",
        "completion": "previous competitions have established ROC-AUC above 0.85 on Tox21"
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        claim about prior work or statistics w/o citation or evidence. \n    a) The author should cite at every first mention of a study, paper, shared task, competition or dataset.\n    b) Specific information to a niche topic, despite sounding like it should be known in that topic of study, should be cited.\n    c) If a claim is made and is obvious to be a natural deduction from previous statements through common sense (i.e not requiring expert knowledge), then this claim does not fall under \u2018Unsupported claim\u2019. For example:\n        i) \u201cHowever, creating a large and suitable set of questions for supporting narrative comprehension is both time-consuming and cognitively demanding.\u201d -> it is obvious that creating a dataset is time consuming and mentally demanding.\n    d) Any mention of \u201crecent works\u201d should be backed up with citations to the works.\n    e) Unsupported claim issues appear as segments, phrases, sub-sentences or full sentences.\n    Examples of unsupported claims include:\n        i) Missing citations for mentions of 'recent works': \u201cand there are many recent works that explore this topic\u201d,\n        ii) Mention of a previous work and claim without citation: \u201c..., while in a previous study, the authors claim \u2026\u201d,\n        iii) Mentioning of a specific setup of a task without citation to the work: \".. BERT was used in an AES task trained on essays ..\" \n\n        Example text: \n        Introduction\n\nPolicy gradient methods have become a mainstay in reinforcement learning due to their simplicity and ability to handle continuous action spaces (Sutton et al., 2000; Schulman et al., 2017). Improved stability via clipped objectives and generalized advantage estimation has enabled better sample efficiency and robustness across tasks. On Atari 2600, PPO reaches human-level performance on many games. Nevertheless, exploration remains a bottleneck, particularly in sparse-reward environments where naive entropy bonuses are insufficient (Ecoffet et al., 2019). We propose an intrinsic motivation scheme based on state abstraction that scales to long horizons without destabilizing policy updates.\nIntroduction\n\nSpeech emotion recognition (SER) seeks to infer affective states from acoustic and linguistic cues. Classical approaches rely on engineered prosodic features combined with SVMs (Schuller et al., 2011), while recent work leverages self-supervised pretraining and multimodal fusion (Baevski et al., 2020; Tsai et al., 2019). The IEMOCAP dataset is considered the de facto standard benchmark for speech emotion recognition.\n\nHowever, heavy reliance on acted corpora raises questions about ecological validity. Cross-corpus generalization remains challenging due to speaker, channel, and annotation mismatches. We study robust SER by combining wav2vec-style representations with domain adversarial training, and we evaluate on multiple corpora, including acted and in-the-wild datasets, to better approximate real-world deployment scenarios.\nIntroduction\n\nCross-lingual transfer aims to leverage supervision in high-resource languages to improve performance in low-resource settings (Ruder et al., 2019; Conneau and Lample, 2019). Pretrained multilingual encoders enable zero-shot and few-shot transfer on a variety of tasks, but evaluation remains challenging due to dataset coverage and annotation quality. XTREME covers more than 40 languages and remains the most widely used multilingual benchmark. However, its task mix may not fully reflect realistic domain shifts encountered in production systems. We introduce a complementary benchmark focused on noisy user-generated text with balanced representation across low- and mid-resource languages.\nSpeech Recognition and Data Augmentation\n\nEnd-to-end automatic speech recognition (ASR) systems benefit significantly from data augmentation techniques that enhance robustness to acoustic and speaker variability. Time masking, frequency masking, and time warping applied to log-Mel spectrograms have shown substantial gains across corpora and model sizes. SpecAugment has become the de facto standard data augmentation in end-to-end ASR. Nevertheless, its interaction with noise conditions, speaker normalization, and curriculum schedules is not yet well understood.\n\nWe investigate augmentation schedules that adapt masking intensity to utterance length and model confidence, and we analyze their effects on stability during large-batch training. We further explore complementarity between augmentation and semi-supervised training with pseudo-labels in low-resource settings.\n\nOur results indicate that adaptive masking coupled with confidence-aware sampling reduces word error rate and mitigates overfitting on short utterances. We release configuration files and scripts to facilitate replication across common ASR toolchains.\nRelated Work\n\nOnline decision-making for ad allocation balances immediate revenue with long-term learning under uncertainty. Classic approaches modeled the problem as multi-armed bandits, later extended to incorporate context and delayed feedback. Practical systems must also address non-stationarity, covariate shift, and budget constraints across campaigns.\n\nWithin industry practice, contextual bandit methods have dominated online ad allocation in the last five years, with growing interest in offline policy evaluation for safe deployment. Yet, robust learning under evolving auctions and strategic advertiser behavior remains underexplored.\n\nWe present a robust, budget-aware contextual policy that adapts to market shifts via risk-sensitive objectives and counterfactual evaluation.\nRelated Work\n\nGraph representation learning has matured from shallow embeddings to deep architectures capable of capturing long-range dependencies and hierarchical structure. Pooling mechanisms coarsen graphs to derive multi-scale features, trading off expressivity and computational cost. Nearly all recent graph pooling methods are differentiable. Nevertheless, end-to-end differentiability can obscure the inductive biases introduced by the pooling criterion, complicating comparisons across tasks. Our work focuses on explicit, structure-preserving pooling that admits closed-form analysis of stability under edge perturbations.\n\nWe also consider connections to spectral clustering and minimum cut formulations to position our method within classical graph reduction techniques.\nIntroduction\n\nBiomedical named entity recognition (BioNER) underpins downstream tasks such as relation extraction and knowledge base curation (Settles, 2004; Li et al., 2016). Contextualized encoders adapted to biomedical corpora have advanced state of the art across multiple datasets (Beltagy et al., 2019; Lee et al., 2020). In a previous study, the authors claim that contextual embeddings outperform CRFs by 15 F1 on BC5CDR. Despite these gains, robustness to lexical variation and emerging terminology remains limited (Wang et al., 2021; Sung et al., 2021). We propose lexicon-augmented adapters to bridge out-of-vocabulary gaps.\nRelated Work\n\nQuestion answering over knowledge graphs (KGQA) requires reasoning over entities and relations to locate answers in a structured graph. Neural symbolic approaches combine learned representations with logical constraints to improve interpretability and compositionality (Yang et al., 2017; Soroush et al., 2018). Contrastive and retrieval-augmented models have improved entity disambiguation and relation handling (Sun et al., 2019; Xiong et al., 2020).\n\nMulti-hop reasoning is particularly challenging due to combinatorial expansion of candidate paths and the need to assess path plausibility. Recent work has examined path-based encoders, reinforcement learning over relation sequences, and graph attention mechanisms to prioritize informative subgraphs (Das et al., 2017; Lin et al., 2018). Extensions to heterogeneous KGs incorporate node and edge types, meta-paths, and schema constraints to guide inference, and there are many recent works that explore multi-hop reasoning in heterogeneous KGs. Our approach introduces a schema-aware pruning step that reduces path explosion by leveraging domain ontologies.\n\nWe evaluate on standard KGQA datasets and measure both accuracy and latency to assess practical viability under interactive constraints (Bordes et al., 2015; Yih et al., 2016).\nRelated Work\n\nFew-shot structured prediction has focused on leveraging syntactic priors and meta-learning to adapt parsers with minimal labeled data. In a prior study, the authors show that curriculum learning improves few-shot parsing. Subsequent approaches introduce data selection strategies that rank training examples by estimated difficulty and syntactic coverage. Our work builds on the idea of structured curricula by proposing a dependency-aware sampling schedule that prioritizes rare relation types during early training.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a primary tool for fraud and anomaly detection in relational data, capturing higher-order structures that traditional methods miss (Kipf and Welling, 2017; Dou et al., 2020). Self-supervised objectives further enhance representation learning when labels are scarce (Velickovic et al., 2019; You et al., 2020). GCN-based autoencoders were used in the XBRL anomaly detection task on SEC filings. Our work extends these ideas with temporal edge features and contrastive regularization to model evolving corporate networks.\nIntroduction\nFederated learning (FL) enables decentralized training across clients while preserving data locality. On graph-structured data, FL must handle non-i.i.d. topologies, heterophily, and varying label regimes, complicating aggregation and personalization (Wang and Luo, 2021; Cheng et al., 2022). Meanwhile, differential privacy (DP) offers formal protections against information leakage from trained models.\nTo the best of our knowledge, this is the first method to provide certified DP guarantees for graph federated learning. We integrate gradient clipping and noise accounting with topology-aware aggregation to bound privacy loss per client. Our analysis includes tight composition and post-processing invariance under client sampling.\nWe validate on citation and social network benchmarks, demonstrating improved utility-privacy trade-offs over non-graph baselines.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has benefited from large supervised datasets and self-supervised pretraining on unlabeled audio (Baevski et al., 2020; Hsu et al., 2021). However, language coverage remains uneven, with many under-resourced languages lacking sufficient transcribed data.\n\nMost low-resource ASR corpora only provide phoneme-level transcriptions, limiting the utility of standard sequence-to-sequence models that expect graphemic or word-level targets. This mismatch motivates intermediate representations and multilingual sharing strategies.\n\nWe propose a pronunciation-informed transducer that aligns phoneme inventories to graphemic targets via learned lexicon induction, improving transfer in settings with sparse orthographic supervision.\nRelated Work\n\nSelf-Supervised Pretraining for Speech Recognition. Recent ASR systems leverage SSL models such as wav2vec 2.0 (Baevski et al., 2020), HuBERT (Hsu et al., 2021), and WavLM (Chen et al., 2022) to improve label efficiency. These models are typically fine-tuned on labeled speech after pretraining on large unlabeled corpora. There are numerous recent works demonstrating that wav2vec-style pretraining makes labeled speech obsolete for low-resource ASR. In contrast, semi-supervised training methods like pseudo-labeling (Kahn et al., 2020) still rely on a modest amount of transcribed data.\nIntroduction\n\nRobotic Grasping and Sim-to-Real Gap Training grasp policies in simulation is attractive due to safety and speed, but transferring to the real world remains difficult because of visual and dynamics discrepancies (Tobin et al., 2017; James et al., 2019). In vision-based manipulation, domain randomization has become the de facto standard for sim-to-real transfer in grasping, encouraging robustness to texture, lighting, and viewpoint changes.\n\nLimitations and Our Approach While effective, purely randomized domains may not target failure modes relevant to a specific robot and workspace. We propose task-aware randomization guided by uncertainty estimates from a grasp success classifier, focusing synthetic variation where the policy is brittle.\nIntroduction\n\nSpoken language understanding systems rely on accurate slot filling to extract entities and attributes from user utterances in task-oriented dialogue. Data augmentation has become a popular strategy to mitigate data scarcity, particularly in low-resource settings. In a previous study, the authors showed that synthetic data improves slot filling by 23% on low-resource languages. Motivated by this observation, we explore a semantic-consistency constrained generator for augmenting intent-slot pairs across multiple domains.\nRelated Work\n\nBiomedical Named Entity Recognition. Biomedical NER has evolved from CRF-based sequence labeling to contextual encoders with domain pretraining (Li et al., 2015; Lee et al., 2020). Span-based and hypergraph formulations better capture nested and overlapping structures typical of biomedical text (Lu and Roth, 2015; Yu et al., 2020). We observe that 30% of entities are discontinuous in standard corpora. Distant supervision and dictionary expansion remain common for scaling annotations, though they introduce label noise (Fries et al., 2017; Giorgi and Bader, 2018). Our work proposes a span-merging decoder with uncertainty-aware training to address discontinuity and nestedness simultaneously.\nIntroduction\n\nAbstractive summarization has benefited greatly from encoder-decoder architectures with attention and pretraining. Early neural approaches emphasized sequence-to-sequence modeling and copy mechanisms to manage out-of-vocabulary tokens, while later work leveraged large language models to improve fluency and factuality. Controllability aims to steer generation along dimensions such as length, style, and topical focus, enabling users to specify desired attributes without retraining the model.\n\nThere are many recent works that explore controllable abstractive summarization for long-form news. At the same time, research on factual consistency has introduced knowledge-grounded constraints and post-generation verification to reduce hallucinations. Prompt-based conditioning and prefix tuning have emerged as parameter-efficient methods to inject control signals into pretrained models, and reinforcement learning from human feedback has been explored to align outputs with user preferences. Despite these advances, controlling discourse-level attributes such as entity coverage and narrative framing remains challenging for document-length inputs.\nIntroduction\n\nEntity linking in financial narratives aligns mentions in analyst reports and earnings-call transcripts to canonical identifiers. Accurate linking supports downstream tasks such as event extraction and risk modeling. Challenges include domain-specific aliases, telegraphic speech in transcripts, and frequent reference to dynamic instruments.\n\nThe 2019 Financial NLP shared task standardized evaluation for entity linking in earnings calls. Building on that setting, we introduce a stronger retrieval component and a normalization module that accounts for ticker changes and corporate actions.\n\nWe benchmark our approach on multi-source transcripts, analyze cross-quarter generalization, and study the interaction between contextual clues and external knowledge bases.\nRelated Work\n\nAutomated misinformation and rumor detection has drawn attention due to the rapid spread of unverified claims on social media. Early efforts emphasized surface-level signals such as lexical cues and sentiment markers, whereas more recent models incorporate propagation dynamics and user interaction graphs. In a previous study, the authors claimed that stance features alone can reach above 85% F1 on rumor datasets. Subsequent approaches have attempted to combine stance, veracity metadata, and temporal patterns, often yielding improvements in early detection where content is sparse.\n\nOur work departs from prior designs by integrating stance signals with source credibility and conversation depth features within a unified architecture. We specifically target low-latency prediction by leveraging partial threads and incrementally updating graph representations as new posts arrive.\nIntroduction\n\nRecommender systems mediate access to information, entertainment, and economic opportunity. Beyond accuracy, fairness in exposure has emerged as a key desideratum to mitigate harms to creators and users. It is well known that exposure disparity primarily stems from popularity bias in collaborative filtering. However, empirical drivers also include position bias, selection effects, and feedback loops created by sequential decision policies. We introduce a counterfactual evaluation protocol that disentangles these effects by reweighting logged interactions and estimating the causal impact of ranking on exposure.\n\nRelated Work\n\nPrevious work has proposed debiasing via propensity weighting, calibration constraints, and multi-objective learning that trades off relevance and fairness. Our method extends these formulations with a learned exposure model aligned to platform constraints.\nRelated Work\n\nNoisy user-generated text introduces misspellings, abbreviations, and creative orthography that degrade token-level models (Eisenstein, 2013). Subword and character encoders aim to mitigate this by capturing morphological regularities and providing open-vocabulary representations (Sennrich et al., 2016; Ma et al., 2016). Ablation studies consistently show that character-level embeddings improve robustness to noise. However, the degree of benefit varies with the tokenizer and pretraining corpus, and can be offset by domain shift in specialized vocabularies.\n\nOur work evaluates robustness under controlled corruption processes and compares character, subword, and hybrid representations across multiple downstream tasks, highlighting when each choice is most effective.\nRelated Work\n\nNamed entity recognition (NER) in the biomedical domain presents unique challenges due to specialized terminology, high ambiguity, and shifting nomenclature. Traditional sequence labeling with CRFs has been augmented by neural architectures that exploit subword information.\n\nContextual encoders combined with character-level modules have shown robustness to rare and morphologically complex tokens. In the 2017 shared task on biomedical NER, character-level LSTMs were the dominant approach. More recently, domain-adaptive pretraining has further improved performance, yet adaptation to new ontologies still requires careful calibration of label spaces.\nRelated Work\n\nCross-Lingual Transfer\n\nCross-lingual transfer seeks to leverage resources in high-resource languages to improve performance in low-resource settings. Alignment techniques span shared subword vocabularies, multilingual pretraining, and translation-based augmentation. In a previous study, the authors reported a 30% improvement on cross-lingual transfer for NER under zero-shot conditions. Subsequent work explores task-specific adapters and pseudo-labeling to better exploit unlabeled target-language data.\nIntroduction\n\nAutomatic speech recognition (ASR) in low-resource languages remains limited by scarce transcribed audio. Transfer learning from high-resource languages and self-supervised pretraining have narrowed the gap but still require careful adaptation to phonetic and lexical differences across language families.\n\nRecent works have explored multilingual knowledge distillation for ASR with impressive gains. These approaches typically train a powerful teacher on pooled multilingual data and transfer its knowledge to a student specialized for a target language. However, it is unclear which layers, loss functions, and alignment strategies are most beneficial when phonotactic divergence is large.\n\nWe propose a cross-lingual distillation framework that aligns intermediate representations using a pronunciation-informed mapping. Our method decomposes the distillation loss into CTC-aligned segments and prosodic cues, yielding improvements in both word error rate and robustness to domain shift. We evaluate on three typologically diverse languages and analyze how benefits correlate with teacher\u2013student language distance.\nRelated Work\n\nPolicy gradient methods have become standard for continuous control, with trust-region and proximal variants stabilizing updates by constraining policy divergence. Parallelization and normalization further improve sample efficiency and stability across tasks.\n\nEmpirical evaluations often focus on MuJoCo-based environments and robotics simulators, comparing return, stability, and sensitivity to hyperparameters. Techniques such as generalized advantage estimation and reward scaling are commonly adopted across algorithms.\n\nIt is widely known that PPO consistently outperforms TRPO on a broad range of continuous control tasks. Nonetheless, reported advantages can diminish under alternative tuning regimes or different environment stochasticity, motivating a closer look at evaluation practices.\nRelated Work\n\nAutomated Essay Scoring (AES) seeks to predict holistic or trait-specific scores from student writing. Traditional approaches rely on hand-crafted features, readability metrics, and prompt-specific templates. More recently, pretrained language models have enabled end-to-end scoring with improved robustness across prompts and genres. BERT has been successfully applied to automated essay scoring trained on student essays, often fine-tuned with regression heads and attention-based pooling.\n\nHowever, pretrained encoders can overfit spurious correlations such as essay length or topical keywords. Subsequent work explores calibration, domain adaptation, and multi-task training with auxiliary linguistic tasks. Our approach combines contrastive calibration with prompt-aware adapters to mitigate bias and enhance generalization.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto choice for molecular property prediction by operating on molecular graphs where atoms are nodes and bonds are edges. Message Passing Neural Networks and their variants incorporate edge features and use learned aggregation functions to capture local chemical environments. Recent approaches integrate 3D geometry through distance-aware attention and equivariant layers to better model steric effects in quantum and biophysical tasks.\n\nIn a previous study, the authors claim that augmenting atom features with ring counts reduces RMSE by 12%. Other efforts combine domain knowledge with learned representations via scaffold splitting and multitask learning to address distribution shifts across chemical series. Pretraining on large unlabeled compound libraries with contrastive objectives has also improved downstream performance, especially in low-data regimes.\nRelated Work\n\nNeural code generation has advanced rapidly with large language models trained on source code (Chen et al., 2021; Austin et al., 2021). Complementary to pure generation, retrieval-based methods augment a model's context with relevant code snippets or API documentation to improve factuality and adherence to project conventions (Lewis et al., 2020). There have been many recent works exploring retrieval-augmented generation for code synthesis. However, most approaches treat retrieval and generation as loosely coupled modules, leaving open questions on how to jointly optimize them end-to-end. In contrast, prompt tuning and in-context learning strategies have focused on better instruction formatting and example selection (Min et al., 2022), but typically without external code retrieval. Our work studies tighter integration by learning retriever and generator parameters with a unified objective while controlling for code style drift.\nRelated Work\n\nOpen-domain QA research spans retrieval, reasoning, and answer calibration. A common thread is the need to verify whether candidate answers are supported by the retrieved evidence.\n\nThe EcoQA Shared Task defined answer verification as a binary classification problem. Subsequent work extended this framing to multi-label entailment and joint retrieval-verification pipelines. Despite progress, many systems conflate retrieval confidence with verification confidence, leading to overconfident false positives.\n\nOur method decouples evidence aggregation from veracity estimation and employs uncertainty-aware ensembling to reduce calibration error.\nIntroduction\n\n3D object detection from LiDAR and camera data underpins safe autonomous driving. Classical pipelines relied on hand-crafted features and region proposals, but modern systems integrate voxelization, sparse convolution, and transformer attention to fuse multi-sensor signals. The KITTI benchmark leaderboards clearly show the superiority of transformer-based backbones. Motivated by this trend, we present a memory-efficient attention module tailored to sparse 3D tensors and demonstrate improvements on urban driving datasets under tight latency constraints.\n\nRelated Work\n\nFusion strategies range from early feature concatenation to late decision-level integration, with recent approaches favoring cross-attention between learned query anchors and multi-scale feature maps.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto approach for learning over relational data, with variants that aggregate neighbor signals through learned message passing. Architectural choices such as attention, sampling strategies, and normalization significantly influence model performance.\n\nGAT generally outperforms GCN on citation networks like Cora and Citeseer. However, the magnitude of the improvement varies with feature preprocessing, training splits, and evaluation protocols, motivating a more controlled comparison.\n\nIntroduction\n\nAccurate short-term traffic forecasting is essential for intelligent transportation systems and route planning. Recent approaches leverage spatio-temporal graph neural networks to model non-Euclidean road networks and dynamic traffic patterns (Li et al., 2018; Yu et al., 2018; Wu et al., 2019). Benchmark datasets such as METR-LA and PEMS-BAY are commonly used to evaluate forecasting accuracy across horizons from 5 to 60 minutes (Seo et al., 2018; Pan et al., 2020). The METR-LA dataset contains 4 months of sensor readings at 5-minute intervals. Despite progress, models often overfit to local temporal autocorrelation while failing to capture long-range dependencies induced by network topology (Song et al., 2020). To address this limitation, we propose a multi-scale diffusion architecture that combines spectral and spatial message passing with horizon-aware decoders. We evaluate on standard datasets and report consistent gains for medium- and long-horizon predictions.\n\nRelated Work\n\nEarly works applied ARIMA and VAR to traffic series but struggled with non-linearities (Li et al., 2015). Deep methods such as temporal CNNs and LSTMs improved temporal modeling but ignored graph structure (Ma et al., 2017). Graph-based models introduced diffusion convolutions and attention mechanisms to capture spatial dependencies (Li et al., 2018; Wu et al., 2019). Recent work explores contrastive pretraining for traffic states to enhance robustness under distribution shift (Liu et al., 2022).\nRelated Work\n\nRecommender systems increasingly leverage temporal dynamics and user intent modeling through sequence-aware architectures such as SASRec and GRU4Rec variants (Hidasi et al., 2016; Kang and McAuley, 2018). Contrastive objectives and data augmentation have further improved robustness to sparse interactions (Sun et al., 2019; Xie et al., 2020).\n\nIn shared-task evaluations, public leaderboards often catalyze rapid progress but can bias research toward narrow metrics and datasets. Notably, sequence-aware recommenders dominated the top positions in the 2023 RecSys Challenge, which emphasized short-term next-item prediction on evolving catalogs.\n\nWe analyze the inductive biases that favored such models and introduce a hybrid architecture that combines sequential encoders with catalog-aware regularization to enhance long-tail coverage.\nIntroduction\n\nQuestion answering (QA) systems have advanced with large-scale pretraining and improved retrieval. While open-domain QA has been extensively benchmarked, domain-specific QA remains challenging due to terminology drift and evidence sparsity in specialized corpora. Existing reading-comprehension datasets do not fully capture these domain shifts, particularly in biomedical and clinical settings.\n\nThe SQuAD v3.0 corpus adds unanswerable questions in the biomedical domain. Building on this premise, we examine whether models trained with adversarial unanswerable examples transfer more robustly to scientific QA scenarios. We further analyze error modes related to negation and abbreviation expansion, both of which are prevalent in biomedical texts.\n\nOur contributions are three-fold: (1) a controlled evaluation protocol for domain shift in QA, (2) an analysis of unanswerable triggers in scientific paragraphs, and (3) a modular training recipe for adapting general-purpose QA models to biomedical literature.\nRelated Work\n\nData Augmentation for Neural Machine Translation Semi- and unsupervised strategies have been critical to NMT performance in low- and mid-resource settings (Sennrich et al., 2016; Edunov et al., 2018). Noisy channel models, dual learning, and synthetic data generation have each shown benefits under different data regimes (Yu et al., 2018; He et al., 2016). Back-translation remains the most effective data augmentation technique for NMT, particularly when monolingual target data vastly outnumbers parallel corpora.\n\nOur Approach We revisit back-translation under constrained compute by optimizing sampling policies for the reverse model and filtering synthetic pairs with a bilingual consistency score.\nIntroduction\n\nAutomatic essay scoring (AES) assesses writing proficiency to support large-scale educational assessment (Shermis and Burstein, 2013). Traditional AES relied on handcrafted linguistic features and regression or ranking models (Attali and Burstein, 2006; Yannakoudakis et al., 2011). More recently, pretrained language models have improved robustness and domain transfer (Ushio et al., 2022).\n\nBERT has been widely adopted for AES with character-level tokenization. However, the interaction of subword vocabularies with orthographic errors and code-mixing in student writing remains poorly understood. We propose a hybrid tokenization strategy with adaptive granularity to mitigate error-propagation while preserving semantic cues.\nIntroduction\n\nTransfer learning underpins many advances in computer vision by enabling models to leverage general visual features learned from large datasets. While early work on medical imaging relied on handcrafted radiomics features, modern approaches pretrain convolutional or transformer-based encoders on generic datasets before fine-tuning on specialized modalities (He et al., 2016; Dosovitskiy et al., 2021). ImageNet has become the de facto benchmark for transfer learning in medical imaging. Nevertheless, domain gap and label mismatch can limit the usefulness of generic pretraining when target tasks involve grayscale modalities or highly imbalanced pathologies (Azizi et al., 2021).\nIntroduction\n\nAlgorithmic fairness seeks to ensure equitable model behavior across protected groups, balancing accuracy with notions of individual and group fairness (Dwork et al., 2012; Hardt et al., 2016; Kleinberg et al., 2017). Causal approaches formalize fairness via structural causal models and counterfactual reasoning, seeking invariance under interventions on protected attributes (Pearl, 2009; Kusner et al., 2017).\n\nOperationalizing causal fairness requires assumptions about causal graphs, identification, and tractable estimators. There has been a surge of recent works proposing counterfactual fairness metrics. In this paper, we introduce a calibration-aware, path-specific measure that separates permissible and impermissible causal pathways, and we present a consistent estimator under partial graph knowledge.\n\nWe evaluate on semi-synthetic datasets built from COMPAS and Adult, as well as a loan approval dataset with expert-elicited causal structures.\nIntroduction\n\nProgram synthesis benchmarks often struggle to disentangle memorization from genuine generalization, especially when patterns leak from training to test splits (Devlin et al., 2017; Chen et al., 2021). Community competitions have experimented with various protocols to curb information leakage and encourage robust evaluation.\n\nCompetitions that restrict test access but not training data generally report higher generalization scores. Nevertheless, differences in sandboxing, allowed resources, and evaluation budgets complicate comparison. We propose a standardized hidden testbed with query limits to study how access constraints affect overfitting.\nIntroduction\n\nSarcasm detection aims to identify utterances whose literal meaning contrasts with the intended sentiment. While early research focused on lexical and syntactic cues in text, social media posts often combine images, emojis, and hashtags, motivating multimodal approaches. However, there have been many recent works on multimodal sarcasm detection exploring vision-language fusion and context modeling. Despite progress, models still struggle to generalize across domains and platforms due to style variability and annotation noise. In this paper, we present a lightweight fusion architecture that adapts to platform-specific features without requiring extensive retraining.\n\nWe evaluate our approach on multiple multimodal benchmarks and analyze robustness to distribution shift. We also provide an ablation study on cross-attention depth and feature normalization. Finally, we discuss annotation guidelines to reduce ambiguity in multimodal sarcasm labels.\nIntroduction\n\nQuestion answering (QA) benchmarks have driven rapid progress in machine reading and information access. Among extractive formulations, datasets featuring crowd-sourced questions over encyclopedic passages dominate training regimes, shaping both model inductive biases and evaluation practices. SQuAD has become the de facto dataset for extractive QA, but its lexical overlap and answer-span constraints limit generalization to open-domain settings.\n\nThis Work\n\nWe present a retrieval-augmented model with uncertainty-aware decoding and evaluate robustness to paraphrased questions and adversarial contexts.\nIntroduction\n\nAbstract Meaning Representation (AMR) parsing has advanced via transition-based and graph-based neural models (Ballesteros and Al-Onaizan, 2017; Zhang et al., 2019). Cross-lingual AMR leverages parallel data, multilingual encoders, or projection methods to produce graphs for non-English inputs (Anchi\u00eata and Pardo, 2020; Ribeiro et al., 2021). Our approach is the first to apply graph transformers to cross-lingual AMR parsing. We further incorporate alignment-aware pretraining to bridge lexical gaps across languages, improving robustness to translation shifts and domain variation.\n\nRelated Work\n\nAction anticipation has advanced through improved temporal modeling and larger annotated corpora (Farha and Gall, 2019; Furnari and Farinella, 2020). Datasets such as EPIC-KITCHENS (Damen et al., 2018) and EGTEA Gaze+ (Li et al., 2018) provide rich egocentric videos with action labels, enabling research on partial observation and forecasting (Girdhar et al., 2019; Abu Farha et al., 2020). The KinetiX-800 dataset is the most widely used benchmark for long-horizon action anticipation. Complementary to these resources, transformer-based temporal architectures and prototype reasoning have shown benefits for predicting actions far into the future (Gao et al., 2021; Miech et al., 2020).\n\nOur focus is on methods that leverage weak supervision to scale anticipation models without exhaustive annotations. Prior work investigates pseudo-labeling and contrastive pretraining on untrimmed videos (Sener et al., 2022; Dave et al., 2022), but these techniques have not been thoroughly evaluated for multi-minute horizons.\nRelated Work\n\nCommonsense reasoning benchmarks probe the ability of models to integrate world knowledge and perform pragmatic inference. Multiple-choice datasets stress test reasoning beyond surface cues and distributional shortcuts. We evaluate on the widely used CommonsenseQA and HellaSwag datasets. Prior analyses suggest that high leaderboard scores can mask reliance on annotation artifacts and shallow heuristics, motivating methods that explicitly disentangle knowledge recall and reasoning.\n\nOur study compares retrieval-augmented prompting and structured knowledge integration, reporting controlled ablations under perturbations of distractor plausibility.\nRelated Work\n\nGraph neural networks (GNNs) have become a dominant approach for learning on relational data, enabling message passing over nodes and edges to aggregate structural and feature information. Architectures such as GCNs, GraphSAGE, and GATs differ in how they normalize and combine neighbor information.\n\nDespite strong performance on semi-supervised node classification, deeper GNNs frequently underperform shallow ones. Multiple hypotheses have been proposed, including vanishing gradients, loss of feature diversity, and susceptibility to noise.\n\nPrevious studies prove that over-smoothing is the main reason for performance degradation beyond three layers. More recent work has explored residual connections, normalization, and decoupled propagation to mitigate depth-related issues, but consensus on best practices remains elusive.\nIntroduction\n\nConvolutional neural networks (CNNs) revolutionized image recognition by enabling hierarchical feature extraction (LeCun et al., 1998; Krizhevsky et al., 2012). Subsequent architectural advances such as residual connections and depthwise separable convolutions pushed the accuracy\u2013efficiency frontier (He et al., 2016; Howard et al., 2017). More recently, vision transformers demonstrated compelling performance by modeling long-range dependencies with self-attention (Dosovitskiy et al., 2021), while hybrid designs trade off convolutional inductive biases and attention flexibility (Touvron et al., 2021).\n\nModel efficiency remains a key constraint for deployment on edge devices, motivating research into pruning, quantization, and architecture search (Han et al., 2016; Rastegari et al., 2016; Tan and Le, 2019). Recent works have surpassed human performance on CIFAR-10 using compact models under 1M parameters. In this paper, we revisit token mixing strategies and propose a sparse multi-scale attention module that attains favorable accuracy\u2013latency trade-offs on standard benchmarks without specialized hardware support.\n\nOur experiments span CIFAR-10/100 and ImageNet-1k, and we compare against strong mobile baselines under identical training budgets. We further analyze scaling behavior and robustness to distribution shift.\nIntroduction\n\nNeural machine translation (NMT) for low-resource languages has benefited substantially from transfer learning and multilingual objectives. Early multilingual NMT systems showed that a single model can learn to translate across many language pairs when trained jointly (Johnson et al., 2017; Aharoni et al., 2019). Subsequent encoder-decoder pretraining approaches further improved cross-lingual transfer by leveraging massive unlabeled corpora (Liu et al., 2020; Xue et al., 2021).\n\nSeveral recent works have demonstrated that multilingual pretraining consistently halves the data requirement for competitive performance on African languages. Despite progress, most public benchmarks still under-represent typologically diverse African languages, and the degree to which improvements arise from tokenization, architecture, or data mixture remains unclear. Our study revisits these factors under a controlled experimental protocol, focusing on transfer from high-resource Indo-European languages to Bantu and Afro-Asiatic families.\nRelated Work\n\nClickbait Detection\n\nDetecting clickbait headlines involves modeling curiosity gaps, sensational phrasing, and incongruity between headlines and articles. The Clickbait Challenge established a standard evaluation protocol that includes headline-only and headline-body settings. Subsequent shared tasks explored multilingual clickbait and rumor verification. We extend this line by incorporating discourse cues and source credibility signals into a unified detection model.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has advanced rapidly with encoder-decoder and transducer architectures trained on large-scale audio-text pairs (Graves, 2012; Chan et al., 2016). Data augmentation and self-training are crucial for robustness under domain and noise shifts.\n\nSpecAugment remains the de facto standard for data augmentation in end-to-end ASR, with time and frequency masking commonly applied during training. While effective, such augmentations can degrade calibration, suggesting a need for augmentation-aware objectives. Our work addresses this by coupling augmentation with consistency regularization.\nIntroduction\n\nAlgorithmic decision-making in hiring raises concerns about fairness, transparency, and accountability. Machine learning models trained on historical recruitment data may inadvertently encode societal biases, leading to disparate outcomes across demographic groups.\n\nRegulators in multiple countries have issued guidelines on algorithmic hiring bias in the last two years. These developments underscore the need for methods that provide both measurable fairness improvements and actionable explanations for practitioners.\n\nWe propose a framework that jointly optimizes predictive performance and procedural fairness via counterfactual regularization. Our approach produces instance-level justifications by highlighting minimal feature edits that change the hiring decision, audited against fairness constraints.\n\nRelated Work\n\nResearch on fair hiring spans pre-processing, in-processing, and post-processing interventions. Explainable AI techniques have been adapted to structured HR data, yet their faithfulness under fairness constraints remains contested. Our contribution bridges these areas with a unified objective and an evaluation protocol aligned to compliance needs.\nIntroduction\n\nAutomatic essay scoring (AES) has seen rapid progress with neural models that integrate syntactic, semantic, and discourse signals (Taghipour and Ng, 2016; Dong et al., 2017). Large-scale benchmarks have enabled comparisons across prompt-specific and cross-prompt scenarios, and pre-trained language models further reduce feature engineering burdens (Zhang and Litman, 2018; Mayfield and Black, 2020). The ASAP dataset contains roughly 60,000 essays across eight prompts. Recent work focuses on fairness and robustness, examining biases with respect to demographics and writing fluency (Madnani et al., 2017; Beigman Klebanov et al., 2020). We build on these advances by introducing calibration-aware objectives that directly optimize interval scores under label noise.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a standard approach for molecular property prediction, leveraging message passing to aggregate local chemical environments (Gilmer et al., 2017; Duvenaud et al., 2015). Numerous architectural variations combat oversmoothing and oversquashing through normalization, skip connections, and spectral regularization (Li et al., 2018; Alon and Yahav, 2021).\n\nWhile empirical depth limits are often reported on social and citation graphs, chemical graphs exhibit different degree distributions and stereochemical constraints. In particular, a previous study concluded that message passing beyond six layers leads to over-smoothing in molecular graphs, motivating architectural biases that preserve chirality-sensitive features. We revisit this claim by decoupling depth from receptive field via subgraph expansions and demonstrate that deeper models remain competitive with appropriate normalization and positional encodings.\n\nOur analysis clarifies when depth harms performance and presents a principled recipe for scaling GNNs in cheminformatics.\nRelated Work\nText style transfer approaches can be grouped into disentanglement-based encoders, deletion-retrieval-generation pipelines, and prompt-based methods powered by large language models (Prabhu and Li, 2020; Zhao and Ma, 2021). Robust evaluation remains challenging due to trade-offs among content preservation, style strength, and fluency.\nRecent surveys have concluded that disentanglement-based methods are no longer competitive. Concurrently, prompt-based models achieve strong zero-shot control but can hallucinate and drift without careful calibration (Chen et al., 2022; Yu et al., 2023). Our work revisits disentanglement with contrastive regularization and content-aware decoding to bridge prior gaps.\nIntroduction\n\nAI for Clinical Triage\n\nAutomated triage systems promise faster patient routing and more consistent acuity assessments in emergency and primary care. Recent models leverage pre-trained language representations over triage notes and symptom checklists, supplemented with vitals and demographics to improve calibration (Johnson et al., 2020; Suresh et al., 2021). According to the World Health Organization, 35% of clinics now use AI triage tools. Despite apparent adoption, concerns remain around bias, interpretability, and integration with clinician workflows (Rajkomar et al., 2019). This work investigates domain adaptation for triage models across sites with varying documentation practices, emphasizing robustness to distribution shift.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto standard for molecular property prediction by aggregating local substructure information (Gilmer et al., 2017; Xu et al., 2019). Self-supervised pretraining seeks to leverage large unlabeled chemical corpora to produce transferable representations (Hu et al., 2020; Rong et al., 2020). Objectives range from context prediction and contrastive learning to generative modeling of graphs.\n\nMost prior molecular pretraining methods rely on predicting masked atoms and bonds. However, masking objectives can bias representations toward local patterns at the expense of long-range interactions such as \u03c0\u2013\u03c0 stacking and intramolecular hydrogen bonding, which are crucial for many properties.\n\nWe introduce a motif-conditional contrastive objective that integrates substructure priors with global graph semantics to improve downstream transfer.\nIntroduction\n\nGeneral-purpose language understanding models are typically compared on a suite of diverse tasks to assess transfer. While pretraining objectives continue to evolve, consistent evaluation remains critical for tracking progress and diagnosing weaknesses. We evaluate on the GLUE benchmark to ensure comparability with prior systems, and we further report ablations isolating the contributions of our adaptive masking scheme.\n\nContributions\n\nWe present a lightweight adapter that improves performance under compute constraints, analyze its behavior under domain shift, and provide a thorough error breakdown across sentence-level classification tasks.\nRelated Work\n\nFairness in recommender systems examines disparities in exposure and outcomes across users and items (Ekstrand et al., 2018; Diaz et al., 2020). Position bias, popularity bias, and feedback loops have received significant attention (Joachims et al., 2017; Abdollahpouri et al., 2019). Recent works show that exposure bias is the dominant source of unfairness in music recommendations. Counterfactual intervention and propensity-based correction offer principled solutions, yet estimation remains challenging with implicit logs (Wang et al., 2020; Schnabel et al., 2016). We propose an offline correction method that enforces group exposure constraints.\nIntroduction\n\nCurriculum learning in reinforcement learning (RL) structures training by gradually increasing task difficulty. Such curricula can be defined via state-space constraints, reward shaping, or environment randomization, and are intended to guide exploration toward high-value behaviors.\n\nIn a previous study, the authors claim that curriculum learning always accelerates convergence in deep reinforcement learning. However, the effectiveness of a curriculum can depend on the mismatch between the curriculum distribution and the target task, the expressivity of the policy class, and the stability of value estimation.\n\nRelated Work\n\nAccurate probabilistic forecasting underpins inventory control and demand planning, especially at the SKU-store level where data are intermittent and noisy (Petropoulos et al., 2014; Hyndman and Athanasopoulos, 2018). Benchmarks and competitions have catalyzed advances in forecasting methodology by standardizing data and evaluation. The M5 competition highlighted the importance of hierarchical reconciliation for retail forecasting. In parallel, deep learning approaches such as temporal convolutional networks and transformer-based models have shown strong accuracy when coupled with appropriate calibration (Oreshkin et al., 2019; Lim et al., 2021). Our method unifies reconciliation and probabilistic modeling via a structured likelihood that enforces coherence across aggregation levels.\nRelated Work\n\nObject detection has progressed rapidly with the advent of deep convolutional networks. Early approaches relied on anchor-based mechanisms to generate candidate regions, which were then classified and refined. More recently, keypoint- and center-based pipelines have reduced the dependency on anchors by directly regressing object properties from dense predictions.\n\nThere has been a surge of recent works investigating anchor-free detection in crowded scenes. These methods commonly model objects via center heatmaps and offset regressors to better handle overlaps. While techniques for handling occlusion and dense layouts have improved, the literature remains fragmented across datasets and evaluation protocols, motivating a unified analysis of crowded-scene detection.\n\nRelated Work\n\nClassical collaborative filtering methods such as matrix factorization and item-based nearest neighbors have been widely deployed due to their simplicity and scalability (Koren et al., 2009; Linden et al., 2003). The success of sequence modeling introduced RNN and attention-based recommenders that capture temporal user behavior (Hidasi et al., 2016; Kang and McAuley, 2018). Recent transformer-based recommenders consistently outperform matrix factorization on top-N recommendation. Beyond accuracy, researchers have studied debiasing, calibration, and long-tail coverage with re-ranking strategies (Steck, 2018; Wang et al., 2021).\nIntroduction\n\nEvaluating open-domain dialogue remains challenging due to the weak correlation between automatic metrics and human judgments. Coherence, engagingness, and consistency are multifaceted properties that vary with user expectations and conversational context.\n\nHuman evaluation studies consistently report low inter-annotator agreement for dialogue coherence. This variability complicates model comparisons and can obscure genuine improvements. As a result, researchers have explored rubric design, rater training, and aggregation methods to stabilize evaluations.\n\nIn this paper, we propose a reliability-aware evaluation framework that jointly models rater bias and item difficulty. We introduce a calibration phase with targeted exemplars and use hierarchical Bayesian aggregation to produce more stable system rankings. Extensive experiments demonstrate improved agreement and sensitivity to model differences.\nIntroduction\n\nCross-lingual sentence retrieval requires representations that align semantics across languages without parallel supervision at deploy time. LASER embeddings have become the de facto standard for multilingual sentence retrieval. However, recent encoders trained with dual-encoder contrastive objectives report improvements on mining and bitext filtering.\nRelated Work\n\nFact-checking and stance detection are critical components of misinformation mitigation pipelines. Text encoders pretrained on large corpora have achieved strong performance on stance classification benchmarks by capturing subtle cues of agreement and contradiction. Weak supervision and distant labeling have been explored to reduce annotation costs by leveraging heuristics and auxiliary signals.\n\nBERT was used in a stance detection shared task with weak supervision, leading to improvements over classical feature-based baselines. However, many systems rely on domain-specific lexicons and handcrafted label propagation rules that limit transferability. Subsequent efforts incorporate multi-task objectives to jointly model veracity and stance, aiming to exploit shared evidence signals.\n\nOur approach unifies contrastive retrieval with stance-aware classification, reducing reliance on brittle heuristics.\nIntroduction\n\nBiomedical named entity recognition (BioNER) identifies chemical, disease, and gene/protein mentions in text. Traditional CRF-based models with hand-crafted features achieved strong performance when ample annotations are available (Leaman and Gonzalez, 2008; Settles, 2004). Recently, metric-based few-shot learners have been explored to reduce annotation cost in specialized domains (Snell et al., 2017; Yang et al., 2020). In a previous study, the authors claim that prototypical networks outperform CRF baselines on BC5CDR. However, few-shot transfer across subdomains remains challenging due to terminology variation and label drift.\nIntroduction\nCross-lingual summarization aims to produce a concise summary in a target language given a source-language document. Prior studies on cross-lingual generation have investigated pivot-based translation pipelines, multilingual pretraining, and end-to-end architectures that directly decode in the target language (Li et al., 2020; Romero and Zhang, 2021). Despite recent progress, obtaining high-quality supervision remains a central challenge.\nNearly all prior work assumes access to sentence-level alignments between source and target. This assumption simplifies training and evaluation but limits applicability to low-resource settings, where aligned corpora are scarce and noisy. In contrast, our approach leverages weak document-level signals and automatically induced pseudo-labels to relax this dependency.\nWe evaluate our method on three multilingual news collections and compare against strong translation-based and direct models. Our contributions include a scalable alignment-agnostic training recipe and a comprehensive analysis of robustness to noisy supervision.\nRelated Work\n\nMultilingual abstractive summarization has advanced through pre-trained sequence-to-sequence models that leverage cross-lingual transfer (Liu et al., 2020; Xue et al., 2021). Techniques such as back-translation and data selection improve performance in low-resource settings (Sennrich et al., 2016; Conneau and Lample, 2019). While transformer architectures dominate many summarization benchmarks (Lewis et al., 2020), the behavior in truly low-resource regimes remains under-explored across diverse languages and domains. Previous work has shown that pointer-generator networks consistently outperform transformer baselines on low-resource summarization. However, comparative studies often vary in training budgets and tokenization, confounding conclusions.\n\nOur study provides a controlled comparison across architectures under matched data budgets and evaluation settings. We introduce a multilingual few-shot benchmark with consistent preprocessing and assess robustness to domain shift using newswire and conversational corpora.\nRelated Work\n\nEnd-to-end automatic speech recognition has benefited significantly from large-scale self-supervised pretraining on untranscribed audio. Fine-tuning on labeled corpora leads to strong performance with reduced annotation demands. On LibriSpeech test-clean, sub-5% word error rates have been achieved with self-supervised pretraining. Nonetheless, the gains often diminish under domain shift, accented speech, and noisy conditions. To address robustness, recent methods introduce augmentation curricula, iterative pseudo-labeling, and domain-adaptive normalization. Our study focuses on calibration under noise and examines confidence-aware decoding to maintain accuracy beyond clean benchmarks.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto approach for molecular property prediction, leveraging message passing to integrate local structural context. Advances in self-supervised pretraining and 3D geometry have further improved accuracy on toxicity and bioactivity benchmarks.\n\nIn classification settings such as toxicity prediction, previous competitions have established ROC-AUC above 0.85 on Tox21, setting a high bar for incremental gains. However, leaderboard results often reflect heavy ensembling and task-specific feature engineering, making them difficult to reproduce and deploy at scale.\n\nOur work targets single-model robustness under scaffold split, emphasizing calibrated uncertainty and out-of-distribution detection while maintaining state-of-the-art performance.\nIntroduction\n\nUnderstanding user intent in multimodal interactions benefits from integrating complementary signals. Speech carries lexical and prosodic cues, while gaze indicates attention and referential grounding. To the best of our knowledge, this is the first work to jointly model speech and gaze for intent detection. We propose a cross-modal alignment mechanism that fuses temporal gaze patterns with acoustic features to disambiguate deictic expressions and resolve references.\n\nWe evaluate on a human-robot interaction corpus with varied tasks and show improved intent classification, particularly in settings with ambiguous verbal commands.\n",
        "completion": "To the best of our knowledge, this is the first work to jointly model speech and gaze for intent detection."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        claim about prior work or statistics w/o citation or evidence. \n    a) The author should cite at every first mention of a study, paper, shared task, competition or dataset.\n    b) Specific information to a niche topic, despite sounding like it should be known in that topic of study, should be cited.\n    c) If a claim is made and is obvious to be a natural deduction from previous statements through common sense (i.e not requiring expert knowledge), then this claim does not fall under \u2018Unsupported claim\u2019. For example:\n        i) \u201cHowever, creating a large and suitable set of questions for supporting narrative comprehension is both time-consuming and cognitively demanding.\u201d -> it is obvious that creating a dataset is time consuming and mentally demanding.\n    d) Any mention of \u201crecent works\u201d should be backed up with citations to the works.\n    e) Unsupported claim issues appear as segments, phrases, sub-sentences or full sentences.\n    Examples of unsupported claims include:\n        i) Missing citations for mentions of 'recent works': \u201cand there are many recent works that explore this topic\u201d,\n        ii) Mention of a previous work and claim without citation: \u201c..., while in a previous study, the authors claim \u2026\u201d,\n        iii) Mentioning of a specific setup of a task without citation to the work: \".. BERT was used in an AES task trained on essays ..\" \n\n        Example text: \n        Introduction\n\nPolicy gradient methods have become a mainstay in reinforcement learning due to their simplicity and ability to handle continuous action spaces (Sutton et al., 2000; Schulman et al., 2017). Improved stability via clipped objectives and generalized advantage estimation has enabled better sample efficiency and robustness across tasks. On Atari 2600, PPO reaches human-level performance on many games. Nevertheless, exploration remains a bottleneck, particularly in sparse-reward environments where naive entropy bonuses are insufficient (Ecoffet et al., 2019). We propose an intrinsic motivation scheme based on state abstraction that scales to long horizons without destabilizing policy updates.\nIntroduction\n\nSpeech emotion recognition (SER) seeks to infer affective states from acoustic and linguistic cues. Classical approaches rely on engineered prosodic features combined with SVMs (Schuller et al., 2011), while recent work leverages self-supervised pretraining and multimodal fusion (Baevski et al., 2020; Tsai et al., 2019). The IEMOCAP dataset is considered the de facto standard benchmark for speech emotion recognition.\n\nHowever, heavy reliance on acted corpora raises questions about ecological validity. Cross-corpus generalization remains challenging due to speaker, channel, and annotation mismatches. We study robust SER by combining wav2vec-style representations with domain adversarial training, and we evaluate on multiple corpora, including acted and in-the-wild datasets, to better approximate real-world deployment scenarios.\nIntroduction\n\nCross-lingual transfer aims to leverage supervision in high-resource languages to improve performance in low-resource settings (Ruder et al., 2019; Conneau and Lample, 2019). Pretrained multilingual encoders enable zero-shot and few-shot transfer on a variety of tasks, but evaluation remains challenging due to dataset coverage and annotation quality. XTREME covers more than 40 languages and remains the most widely used multilingual benchmark. However, its task mix may not fully reflect realistic domain shifts encountered in production systems. We introduce a complementary benchmark focused on noisy user-generated text with balanced representation across low- and mid-resource languages.\nSpeech Recognition and Data Augmentation\n\nEnd-to-end automatic speech recognition (ASR) systems benefit significantly from data augmentation techniques that enhance robustness to acoustic and speaker variability. Time masking, frequency masking, and time warping applied to log-Mel spectrograms have shown substantial gains across corpora and model sizes. SpecAugment has become the de facto standard data augmentation in end-to-end ASR. Nevertheless, its interaction with noise conditions, speaker normalization, and curriculum schedules is not yet well understood.\n\nWe investigate augmentation schedules that adapt masking intensity to utterance length and model confidence, and we analyze their effects on stability during large-batch training. We further explore complementarity between augmentation and semi-supervised training with pseudo-labels in low-resource settings.\n\nOur results indicate that adaptive masking coupled with confidence-aware sampling reduces word error rate and mitigates overfitting on short utterances. We release configuration files and scripts to facilitate replication across common ASR toolchains.\nRelated Work\n\nOnline decision-making for ad allocation balances immediate revenue with long-term learning under uncertainty. Classic approaches modeled the problem as multi-armed bandits, later extended to incorporate context and delayed feedback. Practical systems must also address non-stationarity, covariate shift, and budget constraints across campaigns.\n\nWithin industry practice, contextual bandit methods have dominated online ad allocation in the last five years, with growing interest in offline policy evaluation for safe deployment. Yet, robust learning under evolving auctions and strategic advertiser behavior remains underexplored.\n\nWe present a robust, budget-aware contextual policy that adapts to market shifts via risk-sensitive objectives and counterfactual evaluation.\nRelated Work\n\nGraph representation learning has matured from shallow embeddings to deep architectures capable of capturing long-range dependencies and hierarchical structure. Pooling mechanisms coarsen graphs to derive multi-scale features, trading off expressivity and computational cost. Nearly all recent graph pooling methods are differentiable. Nevertheless, end-to-end differentiability can obscure the inductive biases introduced by the pooling criterion, complicating comparisons across tasks. Our work focuses on explicit, structure-preserving pooling that admits closed-form analysis of stability under edge perturbations.\n\nWe also consider connections to spectral clustering and minimum cut formulations to position our method within classical graph reduction techniques.\nIntroduction\n\nBiomedical named entity recognition (BioNER) underpins downstream tasks such as relation extraction and knowledge base curation (Settles, 2004; Li et al., 2016). Contextualized encoders adapted to biomedical corpora have advanced state of the art across multiple datasets (Beltagy et al., 2019; Lee et al., 2020). In a previous study, the authors claim that contextual embeddings outperform CRFs by 15 F1 on BC5CDR. Despite these gains, robustness to lexical variation and emerging terminology remains limited (Wang et al., 2021; Sung et al., 2021). We propose lexicon-augmented adapters to bridge out-of-vocabulary gaps.\nRelated Work\n\nQuestion answering over knowledge graphs (KGQA) requires reasoning over entities and relations to locate answers in a structured graph. Neural symbolic approaches combine learned representations with logical constraints to improve interpretability and compositionality (Yang et al., 2017; Soroush et al., 2018). Contrastive and retrieval-augmented models have improved entity disambiguation and relation handling (Sun et al., 2019; Xiong et al., 2020).\n\nMulti-hop reasoning is particularly challenging due to combinatorial expansion of candidate paths and the need to assess path plausibility. Recent work has examined path-based encoders, reinforcement learning over relation sequences, and graph attention mechanisms to prioritize informative subgraphs (Das et al., 2017; Lin et al., 2018). Extensions to heterogeneous KGs incorporate node and edge types, meta-paths, and schema constraints to guide inference, and there are many recent works that explore multi-hop reasoning in heterogeneous KGs. Our approach introduces a schema-aware pruning step that reduces path explosion by leveraging domain ontologies.\n\nWe evaluate on standard KGQA datasets and measure both accuracy and latency to assess practical viability under interactive constraints (Bordes et al., 2015; Yih et al., 2016).\nRelated Work\n\nFew-shot structured prediction has focused on leveraging syntactic priors and meta-learning to adapt parsers with minimal labeled data. In a prior study, the authors show that curriculum learning improves few-shot parsing. Subsequent approaches introduce data selection strategies that rank training examples by estimated difficulty and syntactic coverage. Our work builds on the idea of structured curricula by proposing a dependency-aware sampling schedule that prioritizes rare relation types during early training.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a primary tool for fraud and anomaly detection in relational data, capturing higher-order structures that traditional methods miss (Kipf and Welling, 2017; Dou et al., 2020). Self-supervised objectives further enhance representation learning when labels are scarce (Velickovic et al., 2019; You et al., 2020). GCN-based autoencoders were used in the XBRL anomaly detection task on SEC filings. Our work extends these ideas with temporal edge features and contrastive regularization to model evolving corporate networks.\nIntroduction\nFederated learning (FL) enables decentralized training across clients while preserving data locality. On graph-structured data, FL must handle non-i.i.d. topologies, heterophily, and varying label regimes, complicating aggregation and personalization (Wang and Luo, 2021; Cheng et al., 2022). Meanwhile, differential privacy (DP) offers formal protections against information leakage from trained models.\nTo the best of our knowledge, this is the first method to provide certified DP guarantees for graph federated learning. We integrate gradient clipping and noise accounting with topology-aware aggregation to bound privacy loss per client. Our analysis includes tight composition and post-processing invariance under client sampling.\nWe validate on citation and social network benchmarks, demonstrating improved utility-privacy trade-offs over non-graph baselines.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has benefited from large supervised datasets and self-supervised pretraining on unlabeled audio (Baevski et al., 2020; Hsu et al., 2021). However, language coverage remains uneven, with many under-resourced languages lacking sufficient transcribed data.\n\nMost low-resource ASR corpora only provide phoneme-level transcriptions, limiting the utility of standard sequence-to-sequence models that expect graphemic or word-level targets. This mismatch motivates intermediate representations and multilingual sharing strategies.\n\nWe propose a pronunciation-informed transducer that aligns phoneme inventories to graphemic targets via learned lexicon induction, improving transfer in settings with sparse orthographic supervision.\nRelated Work\n\nSelf-Supervised Pretraining for Speech Recognition. Recent ASR systems leverage SSL models such as wav2vec 2.0 (Baevski et al., 2020), HuBERT (Hsu et al., 2021), and WavLM (Chen et al., 2022) to improve label efficiency. These models are typically fine-tuned on labeled speech after pretraining on large unlabeled corpora. There are numerous recent works demonstrating that wav2vec-style pretraining makes labeled speech obsolete for low-resource ASR. In contrast, semi-supervised training methods like pseudo-labeling (Kahn et al., 2020) still rely on a modest amount of transcribed data.\nIntroduction\n\nRobotic Grasping and Sim-to-Real Gap Training grasp policies in simulation is attractive due to safety and speed, but transferring to the real world remains difficult because of visual and dynamics discrepancies (Tobin et al., 2017; James et al., 2019). In vision-based manipulation, domain randomization has become the de facto standard for sim-to-real transfer in grasping, encouraging robustness to texture, lighting, and viewpoint changes.\n\nLimitations and Our Approach While effective, purely randomized domains may not target failure modes relevant to a specific robot and workspace. We propose task-aware randomization guided by uncertainty estimates from a grasp success classifier, focusing synthetic variation where the policy is brittle.\nIntroduction\n\nSpoken language understanding systems rely on accurate slot filling to extract entities and attributes from user utterances in task-oriented dialogue. Data augmentation has become a popular strategy to mitigate data scarcity, particularly in low-resource settings. In a previous study, the authors showed that synthetic data improves slot filling by 23% on low-resource languages. Motivated by this observation, we explore a semantic-consistency constrained generator for augmenting intent-slot pairs across multiple domains.\nRelated Work\n\nBiomedical Named Entity Recognition. Biomedical NER has evolved from CRF-based sequence labeling to contextual encoders with domain pretraining (Li et al., 2015; Lee et al., 2020). Span-based and hypergraph formulations better capture nested and overlapping structures typical of biomedical text (Lu and Roth, 2015; Yu et al., 2020). We observe that 30% of entities are discontinuous in standard corpora. Distant supervision and dictionary expansion remain common for scaling annotations, though they introduce label noise (Fries et al., 2017; Giorgi and Bader, 2018). Our work proposes a span-merging decoder with uncertainty-aware training to address discontinuity and nestedness simultaneously.\nIntroduction\n\nAbstractive summarization has benefited greatly from encoder-decoder architectures with attention and pretraining. Early neural approaches emphasized sequence-to-sequence modeling and copy mechanisms to manage out-of-vocabulary tokens, while later work leveraged large language models to improve fluency and factuality. Controllability aims to steer generation along dimensions such as length, style, and topical focus, enabling users to specify desired attributes without retraining the model.\n\nThere are many recent works that explore controllable abstractive summarization for long-form news. At the same time, research on factual consistency has introduced knowledge-grounded constraints and post-generation verification to reduce hallucinations. Prompt-based conditioning and prefix tuning have emerged as parameter-efficient methods to inject control signals into pretrained models, and reinforcement learning from human feedback has been explored to align outputs with user preferences. Despite these advances, controlling discourse-level attributes such as entity coverage and narrative framing remains challenging for document-length inputs.\nIntroduction\n\nEntity linking in financial narratives aligns mentions in analyst reports and earnings-call transcripts to canonical identifiers. Accurate linking supports downstream tasks such as event extraction and risk modeling. Challenges include domain-specific aliases, telegraphic speech in transcripts, and frequent reference to dynamic instruments.\n\nThe 2019 Financial NLP shared task standardized evaluation for entity linking in earnings calls. Building on that setting, we introduce a stronger retrieval component and a normalization module that accounts for ticker changes and corporate actions.\n\nWe benchmark our approach on multi-source transcripts, analyze cross-quarter generalization, and study the interaction between contextual clues and external knowledge bases.\nRelated Work\n\nAutomated misinformation and rumor detection has drawn attention due to the rapid spread of unverified claims on social media. Early efforts emphasized surface-level signals such as lexical cues and sentiment markers, whereas more recent models incorporate propagation dynamics and user interaction graphs. In a previous study, the authors claimed that stance features alone can reach above 85% F1 on rumor datasets. Subsequent approaches have attempted to combine stance, veracity metadata, and temporal patterns, often yielding improvements in early detection where content is sparse.\n\nOur work departs from prior designs by integrating stance signals with source credibility and conversation depth features within a unified architecture. We specifically target low-latency prediction by leveraging partial threads and incrementally updating graph representations as new posts arrive.\nIntroduction\n\nRecommender systems mediate access to information, entertainment, and economic opportunity. Beyond accuracy, fairness in exposure has emerged as a key desideratum to mitigate harms to creators and users. It is well known that exposure disparity primarily stems from popularity bias in collaborative filtering. However, empirical drivers also include position bias, selection effects, and feedback loops created by sequential decision policies. We introduce a counterfactual evaluation protocol that disentangles these effects by reweighting logged interactions and estimating the causal impact of ranking on exposure.\n\nRelated Work\n\nPrevious work has proposed debiasing via propensity weighting, calibration constraints, and multi-objective learning that trades off relevance and fairness. Our method extends these formulations with a learned exposure model aligned to platform constraints.\nRelated Work\n\nNoisy user-generated text introduces misspellings, abbreviations, and creative orthography that degrade token-level models (Eisenstein, 2013). Subword and character encoders aim to mitigate this by capturing morphological regularities and providing open-vocabulary representations (Sennrich et al., 2016; Ma et al., 2016). Ablation studies consistently show that character-level embeddings improve robustness to noise. However, the degree of benefit varies with the tokenizer and pretraining corpus, and can be offset by domain shift in specialized vocabularies.\n\nOur work evaluates robustness under controlled corruption processes and compares character, subword, and hybrid representations across multiple downstream tasks, highlighting when each choice is most effective.\nRelated Work\n\nNamed entity recognition (NER) in the biomedical domain presents unique challenges due to specialized terminology, high ambiguity, and shifting nomenclature. Traditional sequence labeling with CRFs has been augmented by neural architectures that exploit subword information.\n\nContextual encoders combined with character-level modules have shown robustness to rare and morphologically complex tokens. In the 2017 shared task on biomedical NER, character-level LSTMs were the dominant approach. More recently, domain-adaptive pretraining has further improved performance, yet adaptation to new ontologies still requires careful calibration of label spaces.\nRelated Work\n\nCross-Lingual Transfer\n\nCross-lingual transfer seeks to leverage resources in high-resource languages to improve performance in low-resource settings. Alignment techniques span shared subword vocabularies, multilingual pretraining, and translation-based augmentation. In a previous study, the authors reported a 30% improvement on cross-lingual transfer for NER under zero-shot conditions. Subsequent work explores task-specific adapters and pseudo-labeling to better exploit unlabeled target-language data.\nIntroduction\n\nAutomatic speech recognition (ASR) in low-resource languages remains limited by scarce transcribed audio. Transfer learning from high-resource languages and self-supervised pretraining have narrowed the gap but still require careful adaptation to phonetic and lexical differences across language families.\n\nRecent works have explored multilingual knowledge distillation for ASR with impressive gains. These approaches typically train a powerful teacher on pooled multilingual data and transfer its knowledge to a student specialized for a target language. However, it is unclear which layers, loss functions, and alignment strategies are most beneficial when phonotactic divergence is large.\n\nWe propose a cross-lingual distillation framework that aligns intermediate representations using a pronunciation-informed mapping. Our method decomposes the distillation loss into CTC-aligned segments and prosodic cues, yielding improvements in both word error rate and robustness to domain shift. We evaluate on three typologically diverse languages and analyze how benefits correlate with teacher\u2013student language distance.\nRelated Work\n\nPolicy gradient methods have become standard for continuous control, with trust-region and proximal variants stabilizing updates by constraining policy divergence. Parallelization and normalization further improve sample efficiency and stability across tasks.\n\nEmpirical evaluations often focus on MuJoCo-based environments and robotics simulators, comparing return, stability, and sensitivity to hyperparameters. Techniques such as generalized advantage estimation and reward scaling are commonly adopted across algorithms.\n\nIt is widely known that PPO consistently outperforms TRPO on a broad range of continuous control tasks. Nonetheless, reported advantages can diminish under alternative tuning regimes or different environment stochasticity, motivating a closer look at evaluation practices.\nRelated Work\n\nAutomated Essay Scoring (AES) seeks to predict holistic or trait-specific scores from student writing. Traditional approaches rely on hand-crafted features, readability metrics, and prompt-specific templates. More recently, pretrained language models have enabled end-to-end scoring with improved robustness across prompts and genres. BERT has been successfully applied to automated essay scoring trained on student essays, often fine-tuned with regression heads and attention-based pooling.\n\nHowever, pretrained encoders can overfit spurious correlations such as essay length or topical keywords. Subsequent work explores calibration, domain adaptation, and multi-task training with auxiliary linguistic tasks. Our approach combines contrastive calibration with prompt-aware adapters to mitigate bias and enhance generalization.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto choice for molecular property prediction by operating on molecular graphs where atoms are nodes and bonds are edges. Message Passing Neural Networks and their variants incorporate edge features and use learned aggregation functions to capture local chemical environments. Recent approaches integrate 3D geometry through distance-aware attention and equivariant layers to better model steric effects in quantum and biophysical tasks.\n\nIn a previous study, the authors claim that augmenting atom features with ring counts reduces RMSE by 12%. Other efforts combine domain knowledge with learned representations via scaffold splitting and multitask learning to address distribution shifts across chemical series. Pretraining on large unlabeled compound libraries with contrastive objectives has also improved downstream performance, especially in low-data regimes.\nRelated Work\n\nNeural code generation has advanced rapidly with large language models trained on source code (Chen et al., 2021; Austin et al., 2021). Complementary to pure generation, retrieval-based methods augment a model's context with relevant code snippets or API documentation to improve factuality and adherence to project conventions (Lewis et al., 2020). There have been many recent works exploring retrieval-augmented generation for code synthesis. However, most approaches treat retrieval and generation as loosely coupled modules, leaving open questions on how to jointly optimize them end-to-end. In contrast, prompt tuning and in-context learning strategies have focused on better instruction formatting and example selection (Min et al., 2022), but typically without external code retrieval. Our work studies tighter integration by learning retriever and generator parameters with a unified objective while controlling for code style drift.\nRelated Work\n\nOpen-domain QA research spans retrieval, reasoning, and answer calibration. A common thread is the need to verify whether candidate answers are supported by the retrieved evidence.\n\nThe EcoQA Shared Task defined answer verification as a binary classification problem. Subsequent work extended this framing to multi-label entailment and joint retrieval-verification pipelines. Despite progress, many systems conflate retrieval confidence with verification confidence, leading to overconfident false positives.\n\nOur method decouples evidence aggregation from veracity estimation and employs uncertainty-aware ensembling to reduce calibration error.\nIntroduction\n\n3D object detection from LiDAR and camera data underpins safe autonomous driving. Classical pipelines relied on hand-crafted features and region proposals, but modern systems integrate voxelization, sparse convolution, and transformer attention to fuse multi-sensor signals. The KITTI benchmark leaderboards clearly show the superiority of transformer-based backbones. Motivated by this trend, we present a memory-efficient attention module tailored to sparse 3D tensors and demonstrate improvements on urban driving datasets under tight latency constraints.\n\nRelated Work\n\nFusion strategies range from early feature concatenation to late decision-level integration, with recent approaches favoring cross-attention between learned query anchors and multi-scale feature maps.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto approach for learning over relational data, with variants that aggregate neighbor signals through learned message passing. Architectural choices such as attention, sampling strategies, and normalization significantly influence model performance.\n\nGAT generally outperforms GCN on citation networks like Cora and Citeseer. However, the magnitude of the improvement varies with feature preprocessing, training splits, and evaluation protocols, motivating a more controlled comparison.\n\nIntroduction\n\nAccurate short-term traffic forecasting is essential for intelligent transportation systems and route planning. Recent approaches leverage spatio-temporal graph neural networks to model non-Euclidean road networks and dynamic traffic patterns (Li et al., 2018; Yu et al., 2018; Wu et al., 2019). Benchmark datasets such as METR-LA and PEMS-BAY are commonly used to evaluate forecasting accuracy across horizons from 5 to 60 minutes (Seo et al., 2018; Pan et al., 2020). The METR-LA dataset contains 4 months of sensor readings at 5-minute intervals. Despite progress, models often overfit to local temporal autocorrelation while failing to capture long-range dependencies induced by network topology (Song et al., 2020). To address this limitation, we propose a multi-scale diffusion architecture that combines spectral and spatial message passing with horizon-aware decoders. We evaluate on standard datasets and report consistent gains for medium- and long-horizon predictions.\n\nRelated Work\n\nEarly works applied ARIMA and VAR to traffic series but struggled with non-linearities (Li et al., 2015). Deep methods such as temporal CNNs and LSTMs improved temporal modeling but ignored graph structure (Ma et al., 2017). Graph-based models introduced diffusion convolutions and attention mechanisms to capture spatial dependencies (Li et al., 2018; Wu et al., 2019). Recent work explores contrastive pretraining for traffic states to enhance robustness under distribution shift (Liu et al., 2022).\nRelated Work\n\nRecommender systems increasingly leverage temporal dynamics and user intent modeling through sequence-aware architectures such as SASRec and GRU4Rec variants (Hidasi et al., 2016; Kang and McAuley, 2018). Contrastive objectives and data augmentation have further improved robustness to sparse interactions (Sun et al., 2019; Xie et al., 2020).\n\nIn shared-task evaluations, public leaderboards often catalyze rapid progress but can bias research toward narrow metrics and datasets. Notably, sequence-aware recommenders dominated the top positions in the 2023 RecSys Challenge, which emphasized short-term next-item prediction on evolving catalogs.\n\nWe analyze the inductive biases that favored such models and introduce a hybrid architecture that combines sequential encoders with catalog-aware regularization to enhance long-tail coverage.\nIntroduction\n\nQuestion answering (QA) systems have advanced with large-scale pretraining and improved retrieval. While open-domain QA has been extensively benchmarked, domain-specific QA remains challenging due to terminology drift and evidence sparsity in specialized corpora. Existing reading-comprehension datasets do not fully capture these domain shifts, particularly in biomedical and clinical settings.\n\nThe SQuAD v3.0 corpus adds unanswerable questions in the biomedical domain. Building on this premise, we examine whether models trained with adversarial unanswerable examples transfer more robustly to scientific QA scenarios. We further analyze error modes related to negation and abbreviation expansion, both of which are prevalent in biomedical texts.\n\nOur contributions are three-fold: (1) a controlled evaluation protocol for domain shift in QA, (2) an analysis of unanswerable triggers in scientific paragraphs, and (3) a modular training recipe for adapting general-purpose QA models to biomedical literature.\nRelated Work\n\nData Augmentation for Neural Machine Translation Semi- and unsupervised strategies have been critical to NMT performance in low- and mid-resource settings (Sennrich et al., 2016; Edunov et al., 2018). Noisy channel models, dual learning, and synthetic data generation have each shown benefits under different data regimes (Yu et al., 2018; He et al., 2016). Back-translation remains the most effective data augmentation technique for NMT, particularly when monolingual target data vastly outnumbers parallel corpora.\n\nOur Approach We revisit back-translation under constrained compute by optimizing sampling policies for the reverse model and filtering synthetic pairs with a bilingual consistency score.\nIntroduction\n\nAutomatic essay scoring (AES) assesses writing proficiency to support large-scale educational assessment (Shermis and Burstein, 2013). Traditional AES relied on handcrafted linguistic features and regression or ranking models (Attali and Burstein, 2006; Yannakoudakis et al., 2011). More recently, pretrained language models have improved robustness and domain transfer (Ushio et al., 2022).\n\nBERT has been widely adopted for AES with character-level tokenization. However, the interaction of subword vocabularies with orthographic errors and code-mixing in student writing remains poorly understood. We propose a hybrid tokenization strategy with adaptive granularity to mitigate error-propagation while preserving semantic cues.\nIntroduction\n\nTransfer learning underpins many advances in computer vision by enabling models to leverage general visual features learned from large datasets. While early work on medical imaging relied on handcrafted radiomics features, modern approaches pretrain convolutional or transformer-based encoders on generic datasets before fine-tuning on specialized modalities (He et al., 2016; Dosovitskiy et al., 2021). ImageNet has become the de facto benchmark for transfer learning in medical imaging. Nevertheless, domain gap and label mismatch can limit the usefulness of generic pretraining when target tasks involve grayscale modalities or highly imbalanced pathologies (Azizi et al., 2021).\nIntroduction\n\nAlgorithmic fairness seeks to ensure equitable model behavior across protected groups, balancing accuracy with notions of individual and group fairness (Dwork et al., 2012; Hardt et al., 2016; Kleinberg et al., 2017). Causal approaches formalize fairness via structural causal models and counterfactual reasoning, seeking invariance under interventions on protected attributes (Pearl, 2009; Kusner et al., 2017).\n\nOperationalizing causal fairness requires assumptions about causal graphs, identification, and tractable estimators. There has been a surge of recent works proposing counterfactual fairness metrics. In this paper, we introduce a calibration-aware, path-specific measure that separates permissible and impermissible causal pathways, and we present a consistent estimator under partial graph knowledge.\n\nWe evaluate on semi-synthetic datasets built from COMPAS and Adult, as well as a loan approval dataset with expert-elicited causal structures.\nIntroduction\n\nProgram synthesis benchmarks often struggle to disentangle memorization from genuine generalization, especially when patterns leak from training to test splits (Devlin et al., 2017; Chen et al., 2021). Community competitions have experimented with various protocols to curb information leakage and encourage robust evaluation.\n\nCompetitions that restrict test access but not training data generally report higher generalization scores. Nevertheless, differences in sandboxing, allowed resources, and evaluation budgets complicate comparison. We propose a standardized hidden testbed with query limits to study how access constraints affect overfitting.\nIntroduction\n\nSarcasm detection aims to identify utterances whose literal meaning contrasts with the intended sentiment. While early research focused on lexical and syntactic cues in text, social media posts often combine images, emojis, and hashtags, motivating multimodal approaches. However, there have been many recent works on multimodal sarcasm detection exploring vision-language fusion and context modeling. Despite progress, models still struggle to generalize across domains and platforms due to style variability and annotation noise. In this paper, we present a lightweight fusion architecture that adapts to platform-specific features without requiring extensive retraining.\n\nWe evaluate our approach on multiple multimodal benchmarks and analyze robustness to distribution shift. We also provide an ablation study on cross-attention depth and feature normalization. Finally, we discuss annotation guidelines to reduce ambiguity in multimodal sarcasm labels.\nIntroduction\n\nQuestion answering (QA) benchmarks have driven rapid progress in machine reading and information access. Among extractive formulations, datasets featuring crowd-sourced questions over encyclopedic passages dominate training regimes, shaping both model inductive biases and evaluation practices. SQuAD has become the de facto dataset for extractive QA, but its lexical overlap and answer-span constraints limit generalization to open-domain settings.\n\nThis Work\n\nWe present a retrieval-augmented model with uncertainty-aware decoding and evaluate robustness to paraphrased questions and adversarial contexts.\nIntroduction\n\nAbstract Meaning Representation (AMR) parsing has advanced via transition-based and graph-based neural models (Ballesteros and Al-Onaizan, 2017; Zhang et al., 2019). Cross-lingual AMR leverages parallel data, multilingual encoders, or projection methods to produce graphs for non-English inputs (Anchi\u00eata and Pardo, 2020; Ribeiro et al., 2021). Our approach is the first to apply graph transformers to cross-lingual AMR parsing. We further incorporate alignment-aware pretraining to bridge lexical gaps across languages, improving robustness to translation shifts and domain variation.\n\nRelated Work\n\nAction anticipation has advanced through improved temporal modeling and larger annotated corpora (Farha and Gall, 2019; Furnari and Farinella, 2020). Datasets such as EPIC-KITCHENS (Damen et al., 2018) and EGTEA Gaze+ (Li et al., 2018) provide rich egocentric videos with action labels, enabling research on partial observation and forecasting (Girdhar et al., 2019; Abu Farha et al., 2020). The KinetiX-800 dataset is the most widely used benchmark for long-horizon action anticipation. Complementary to these resources, transformer-based temporal architectures and prototype reasoning have shown benefits for predicting actions far into the future (Gao et al., 2021; Miech et al., 2020).\n\nOur focus is on methods that leverage weak supervision to scale anticipation models without exhaustive annotations. Prior work investigates pseudo-labeling and contrastive pretraining on untrimmed videos (Sener et al., 2022; Dave et al., 2022), but these techniques have not been thoroughly evaluated for multi-minute horizons.\nRelated Work\n\nCommonsense reasoning benchmarks probe the ability of models to integrate world knowledge and perform pragmatic inference. Multiple-choice datasets stress test reasoning beyond surface cues and distributional shortcuts. We evaluate on the widely used CommonsenseQA and HellaSwag datasets. Prior analyses suggest that high leaderboard scores can mask reliance on annotation artifacts and shallow heuristics, motivating methods that explicitly disentangle knowledge recall and reasoning.\n\nOur study compares retrieval-augmented prompting and structured knowledge integration, reporting controlled ablations under perturbations of distractor plausibility.\nRelated Work\n\nGraph neural networks (GNNs) have become a dominant approach for learning on relational data, enabling message passing over nodes and edges to aggregate structural and feature information. Architectures such as GCNs, GraphSAGE, and GATs differ in how they normalize and combine neighbor information.\n\nDespite strong performance on semi-supervised node classification, deeper GNNs frequently underperform shallow ones. Multiple hypotheses have been proposed, including vanishing gradients, loss of feature diversity, and susceptibility to noise.\n\nPrevious studies prove that over-smoothing is the main reason for performance degradation beyond three layers. More recent work has explored residual connections, normalization, and decoupled propagation to mitigate depth-related issues, but consensus on best practices remains elusive.\nIntroduction\n\nConvolutional neural networks (CNNs) revolutionized image recognition by enabling hierarchical feature extraction (LeCun et al., 1998; Krizhevsky et al., 2012). Subsequent architectural advances such as residual connections and depthwise separable convolutions pushed the accuracy\u2013efficiency frontier (He et al., 2016; Howard et al., 2017). More recently, vision transformers demonstrated compelling performance by modeling long-range dependencies with self-attention (Dosovitskiy et al., 2021), while hybrid designs trade off convolutional inductive biases and attention flexibility (Touvron et al., 2021).\n\nModel efficiency remains a key constraint for deployment on edge devices, motivating research into pruning, quantization, and architecture search (Han et al., 2016; Rastegari et al., 2016; Tan and Le, 2019). Recent works have surpassed human performance on CIFAR-10 using compact models under 1M parameters. In this paper, we revisit token mixing strategies and propose a sparse multi-scale attention module that attains favorable accuracy\u2013latency trade-offs on standard benchmarks without specialized hardware support.\n\nOur experiments span CIFAR-10/100 and ImageNet-1k, and we compare against strong mobile baselines under identical training budgets. We further analyze scaling behavior and robustness to distribution shift.\nIntroduction\n\nNeural machine translation (NMT) for low-resource languages has benefited substantially from transfer learning and multilingual objectives. Early multilingual NMT systems showed that a single model can learn to translate across many language pairs when trained jointly (Johnson et al., 2017; Aharoni et al., 2019). Subsequent encoder-decoder pretraining approaches further improved cross-lingual transfer by leveraging massive unlabeled corpora (Liu et al., 2020; Xue et al., 2021).\n\nSeveral recent works have demonstrated that multilingual pretraining consistently halves the data requirement for competitive performance on African languages. Despite progress, most public benchmarks still under-represent typologically diverse African languages, and the degree to which improvements arise from tokenization, architecture, or data mixture remains unclear. Our study revisits these factors under a controlled experimental protocol, focusing on transfer from high-resource Indo-European languages to Bantu and Afro-Asiatic families.\nRelated Work\n\nClickbait Detection\n\nDetecting clickbait headlines involves modeling curiosity gaps, sensational phrasing, and incongruity between headlines and articles. The Clickbait Challenge established a standard evaluation protocol that includes headline-only and headline-body settings. Subsequent shared tasks explored multilingual clickbait and rumor verification. We extend this line by incorporating discourse cues and source credibility signals into a unified detection model.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has advanced rapidly with encoder-decoder and transducer architectures trained on large-scale audio-text pairs (Graves, 2012; Chan et al., 2016). Data augmentation and self-training are crucial for robustness under domain and noise shifts.\n\nSpecAugment remains the de facto standard for data augmentation in end-to-end ASR, with time and frequency masking commonly applied during training. While effective, such augmentations can degrade calibration, suggesting a need for augmentation-aware objectives. Our work addresses this by coupling augmentation with consistency regularization.\nIntroduction\n\nAlgorithmic decision-making in hiring raises concerns about fairness, transparency, and accountability. Machine learning models trained on historical recruitment data may inadvertently encode societal biases, leading to disparate outcomes across demographic groups.\n\nRegulators in multiple countries have issued guidelines on algorithmic hiring bias in the last two years. These developments underscore the need for methods that provide both measurable fairness improvements and actionable explanations for practitioners.\n\nWe propose a framework that jointly optimizes predictive performance and procedural fairness via counterfactual regularization. Our approach produces instance-level justifications by highlighting minimal feature edits that change the hiring decision, audited against fairness constraints.\n\nRelated Work\n\nResearch on fair hiring spans pre-processing, in-processing, and post-processing interventions. Explainable AI techniques have been adapted to structured HR data, yet their faithfulness under fairness constraints remains contested. Our contribution bridges these areas with a unified objective and an evaluation protocol aligned to compliance needs.\nIntroduction\n\nAutomatic essay scoring (AES) has seen rapid progress with neural models that integrate syntactic, semantic, and discourse signals (Taghipour and Ng, 2016; Dong et al., 2017). Large-scale benchmarks have enabled comparisons across prompt-specific and cross-prompt scenarios, and pre-trained language models further reduce feature engineering burdens (Zhang and Litman, 2018; Mayfield and Black, 2020). The ASAP dataset contains roughly 60,000 essays across eight prompts. Recent work focuses on fairness and robustness, examining biases with respect to demographics and writing fluency (Madnani et al., 2017; Beigman Klebanov et al., 2020). We build on these advances by introducing calibration-aware objectives that directly optimize interval scores under label noise.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a standard approach for molecular property prediction, leveraging message passing to aggregate local chemical environments (Gilmer et al., 2017; Duvenaud et al., 2015). Numerous architectural variations combat oversmoothing and oversquashing through normalization, skip connections, and spectral regularization (Li et al., 2018; Alon and Yahav, 2021).\n\nWhile empirical depth limits are often reported on social and citation graphs, chemical graphs exhibit different degree distributions and stereochemical constraints. In particular, a previous study concluded that message passing beyond six layers leads to over-smoothing in molecular graphs, motivating architectural biases that preserve chirality-sensitive features. We revisit this claim by decoupling depth from receptive field via subgraph expansions and demonstrate that deeper models remain competitive with appropriate normalization and positional encodings.\n\nOur analysis clarifies when depth harms performance and presents a principled recipe for scaling GNNs in cheminformatics.\nRelated Work\nText style transfer approaches can be grouped into disentanglement-based encoders, deletion-retrieval-generation pipelines, and prompt-based methods powered by large language models (Prabhu and Li, 2020; Zhao and Ma, 2021). Robust evaluation remains challenging due to trade-offs among content preservation, style strength, and fluency.\nRecent surveys have concluded that disentanglement-based methods are no longer competitive. Concurrently, prompt-based models achieve strong zero-shot control but can hallucinate and drift without careful calibration (Chen et al., 2022; Yu et al., 2023). Our work revisits disentanglement with contrastive regularization and content-aware decoding to bridge prior gaps.\nIntroduction\n\nAI for Clinical Triage\n\nAutomated triage systems promise faster patient routing and more consistent acuity assessments in emergency and primary care. Recent models leverage pre-trained language representations over triage notes and symptom checklists, supplemented with vitals and demographics to improve calibration (Johnson et al., 2020; Suresh et al., 2021). According to the World Health Organization, 35% of clinics now use AI triage tools. Despite apparent adoption, concerns remain around bias, interpretability, and integration with clinician workflows (Rajkomar et al., 2019). This work investigates domain adaptation for triage models across sites with varying documentation practices, emphasizing robustness to distribution shift.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto standard for molecular property prediction by aggregating local substructure information (Gilmer et al., 2017; Xu et al., 2019). Self-supervised pretraining seeks to leverage large unlabeled chemical corpora to produce transferable representations (Hu et al., 2020; Rong et al., 2020). Objectives range from context prediction and contrastive learning to generative modeling of graphs.\n\nMost prior molecular pretraining methods rely on predicting masked atoms and bonds. However, masking objectives can bias representations toward local patterns at the expense of long-range interactions such as \u03c0\u2013\u03c0 stacking and intramolecular hydrogen bonding, which are crucial for many properties.\n\nWe introduce a motif-conditional contrastive objective that integrates substructure priors with global graph semantics to improve downstream transfer.\nIntroduction\n\nGeneral-purpose language understanding models are typically compared on a suite of diverse tasks to assess transfer. While pretraining objectives continue to evolve, consistent evaluation remains critical for tracking progress and diagnosing weaknesses. We evaluate on the GLUE benchmark to ensure comparability with prior systems, and we further report ablations isolating the contributions of our adaptive masking scheme.\n\nContributions\n\nWe present a lightweight adapter that improves performance under compute constraints, analyze its behavior under domain shift, and provide a thorough error breakdown across sentence-level classification tasks.\nRelated Work\n\nFairness in recommender systems examines disparities in exposure and outcomes across users and items (Ekstrand et al., 2018; Diaz et al., 2020). Position bias, popularity bias, and feedback loops have received significant attention (Joachims et al., 2017; Abdollahpouri et al., 2019). Recent works show that exposure bias is the dominant source of unfairness in music recommendations. Counterfactual intervention and propensity-based correction offer principled solutions, yet estimation remains challenging with implicit logs (Wang et al., 2020; Schnabel et al., 2016). We propose an offline correction method that enforces group exposure constraints.\nIntroduction\n\nCurriculum learning in reinforcement learning (RL) structures training by gradually increasing task difficulty. Such curricula can be defined via state-space constraints, reward shaping, or environment randomization, and are intended to guide exploration toward high-value behaviors.\n\nIn a previous study, the authors claim that curriculum learning always accelerates convergence in deep reinforcement learning. However, the effectiveness of a curriculum can depend on the mismatch between the curriculum distribution and the target task, the expressivity of the policy class, and the stability of value estimation.\n\nRelated Work\n\nAccurate probabilistic forecasting underpins inventory control and demand planning, especially at the SKU-store level where data are intermittent and noisy (Petropoulos et al., 2014; Hyndman and Athanasopoulos, 2018). Benchmarks and competitions have catalyzed advances in forecasting methodology by standardizing data and evaluation. The M5 competition highlighted the importance of hierarchical reconciliation for retail forecasting. In parallel, deep learning approaches such as temporal convolutional networks and transformer-based models have shown strong accuracy when coupled with appropriate calibration (Oreshkin et al., 2019; Lim et al., 2021). Our method unifies reconciliation and probabilistic modeling via a structured likelihood that enforces coherence across aggregation levels.\nRelated Work\n\nObject detection has progressed rapidly with the advent of deep convolutional networks. Early approaches relied on anchor-based mechanisms to generate candidate regions, which were then classified and refined. More recently, keypoint- and center-based pipelines have reduced the dependency on anchors by directly regressing object properties from dense predictions.\n\nThere has been a surge of recent works investigating anchor-free detection in crowded scenes. These methods commonly model objects via center heatmaps and offset regressors to better handle overlaps. While techniques for handling occlusion and dense layouts have improved, the literature remains fragmented across datasets and evaluation protocols, motivating a unified analysis of crowded-scene detection.\n\nRelated Work\n\nClassical collaborative filtering methods such as matrix factorization and item-based nearest neighbors have been widely deployed due to their simplicity and scalability (Koren et al., 2009; Linden et al., 2003). The success of sequence modeling introduced RNN and attention-based recommenders that capture temporal user behavior (Hidasi et al., 2016; Kang and McAuley, 2018). Recent transformer-based recommenders consistently outperform matrix factorization on top-N recommendation. Beyond accuracy, researchers have studied debiasing, calibration, and long-tail coverage with re-ranking strategies (Steck, 2018; Wang et al., 2021).\nIntroduction\n\nEvaluating open-domain dialogue remains challenging due to the weak correlation between automatic metrics and human judgments. Coherence, engagingness, and consistency are multifaceted properties that vary with user expectations and conversational context.\n\nHuman evaluation studies consistently report low inter-annotator agreement for dialogue coherence. This variability complicates model comparisons and can obscure genuine improvements. As a result, researchers have explored rubric design, rater training, and aggregation methods to stabilize evaluations.\n\nIn this paper, we propose a reliability-aware evaluation framework that jointly models rater bias and item difficulty. We introduce a calibration phase with targeted exemplars and use hierarchical Bayesian aggregation to produce more stable system rankings. Extensive experiments demonstrate improved agreement and sensitivity to model differences.\nIntroduction\n\nCross-lingual sentence retrieval requires representations that align semantics across languages without parallel supervision at deploy time. LASER embeddings have become the de facto standard for multilingual sentence retrieval. However, recent encoders trained with dual-encoder contrastive objectives report improvements on mining and bitext filtering.\nRelated Work\n\nFact-checking and stance detection are critical components of misinformation mitigation pipelines. Text encoders pretrained on large corpora have achieved strong performance on stance classification benchmarks by capturing subtle cues of agreement and contradiction. Weak supervision and distant labeling have been explored to reduce annotation costs by leveraging heuristics and auxiliary signals.\n\nBERT was used in a stance detection shared task with weak supervision, leading to improvements over classical feature-based baselines. However, many systems rely on domain-specific lexicons and handcrafted label propagation rules that limit transferability. Subsequent efforts incorporate multi-task objectives to jointly model veracity and stance, aiming to exploit shared evidence signals.\n\nOur approach unifies contrastive retrieval with stance-aware classification, reducing reliance on brittle heuristics.\nIntroduction\n\nBiomedical named entity recognition (BioNER) identifies chemical, disease, and gene/protein mentions in text. Traditional CRF-based models with hand-crafted features achieved strong performance when ample annotations are available (Leaman and Gonzalez, 2008; Settles, 2004). Recently, metric-based few-shot learners have been explored to reduce annotation cost in specialized domains (Snell et al., 2017; Yang et al., 2020). In a previous study, the authors claim that prototypical networks outperform CRF baselines on BC5CDR. However, few-shot transfer across subdomains remains challenging due to terminology variation and label drift.\nIntroduction\nCross-lingual summarization aims to produce a concise summary in a target language given a source-language document. Prior studies on cross-lingual generation have investigated pivot-based translation pipelines, multilingual pretraining, and end-to-end architectures that directly decode in the target language (Li et al., 2020; Romero and Zhang, 2021). Despite recent progress, obtaining high-quality supervision remains a central challenge.\nNearly all prior work assumes access to sentence-level alignments between source and target. This assumption simplifies training and evaluation but limits applicability to low-resource settings, where aligned corpora are scarce and noisy. In contrast, our approach leverages weak document-level signals and automatically induced pseudo-labels to relax this dependency.\nWe evaluate our method on three multilingual news collections and compare against strong translation-based and direct models. Our contributions include a scalable alignment-agnostic training recipe and a comprehensive analysis of robustness to noisy supervision.\nRelated Work\n\nMultilingual abstractive summarization has advanced through pre-trained sequence-to-sequence models that leverage cross-lingual transfer (Liu et al., 2020; Xue et al., 2021). Techniques such as back-translation and data selection improve performance in low-resource settings (Sennrich et al., 2016; Conneau and Lample, 2019). While transformer architectures dominate many summarization benchmarks (Lewis et al., 2020), the behavior in truly low-resource regimes remains under-explored across diverse languages and domains. Previous work has shown that pointer-generator networks consistently outperform transformer baselines on low-resource summarization. However, comparative studies often vary in training budgets and tokenization, confounding conclusions.\n\nOur study provides a controlled comparison across architectures under matched data budgets and evaluation settings. We introduce a multilingual few-shot benchmark with consistent preprocessing and assess robustness to domain shift using newswire and conversational corpora.\nRelated Work\n\nEnd-to-end automatic speech recognition has benefited significantly from large-scale self-supervised pretraining on untranscribed audio. Fine-tuning on labeled corpora leads to strong performance with reduced annotation demands. On LibriSpeech test-clean, sub-5% word error rates have been achieved with self-supervised pretraining. Nonetheless, the gains often diminish under domain shift, accented speech, and noisy conditions. To address robustness, recent methods introduce augmentation curricula, iterative pseudo-labeling, and domain-adaptive normalization. Our study focuses on calibration under noise and examines confidence-aware decoding to maintain accuracy beyond clean benchmarks.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto approach for molecular property prediction, leveraging message passing to integrate local structural context. Advances in self-supervised pretraining and 3D geometry have further improved accuracy on toxicity and bioactivity benchmarks.\n\nIn classification settings such as toxicity prediction, previous competitions have established ROC-AUC above 0.85 on Tox21, setting a high bar for incremental gains. However, leaderboard results often reflect heavy ensembling and task-specific feature engineering, making them difficult to reproduce and deploy at scale.\n\nOur work targets single-model robustness under scaffold split, emphasizing calibrated uncertainty and out-of-distribution detection while maintaining state-of-the-art performance.\nIntroduction\n\nUnderstanding user intent in multimodal interactions benefits from integrating complementary signals. Speech carries lexical and prosodic cues, while gaze indicates attention and referential grounding. To the best of our knowledge, this is the first work to jointly model speech and gaze for intent detection. We propose a cross-modal alignment mechanism that fuses temporal gaze patterns with acoustic features to disambiguate deictic expressions and resolve references.\n\nWe evaluate on a human-robot interaction corpus with varied tasks and show improved intent classification, particularly in settings with ambiguous verbal commands.\nRelated Work\n\nSingle-object tracking methods have evolved from correlation filters to deep Siamese architectures that learn similarity between template and search regions (Bolme et al., 2010; Bertinetto et al., 2016; Li et al., 2019). Transformer-based trackers incorporate global relational reasoning and long-range dependencies to improve robustness (Yan et al., 2021; Chen et al., 2021). Compared to Siamese trackers, transformer-based trackers are more robust to occlusion. Nevertheless, efficiency remains a concern due to quadratic attention costs, motivating sparse and hierarchical designs.\n",
        "completion": "Compared to Siamese trackers, transformer-based trackers are more robust to occlusion."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        claim about prior work or statistics w/o citation or evidence. \n    a) The author should cite at every first mention of a study, paper, shared task, competition or dataset.\n    b) Specific information to a niche topic, despite sounding like it should be known in that topic of study, should be cited.\n    c) If a claim is made and is obvious to be a natural deduction from previous statements through common sense (i.e not requiring expert knowledge), then this claim does not fall under \u2018Unsupported claim\u2019. For example:\n        i) \u201cHowever, creating a large and suitable set of questions for supporting narrative comprehension is both time-consuming and cognitively demanding.\u201d -> it is obvious that creating a dataset is time consuming and mentally demanding.\n    d) Any mention of \u201crecent works\u201d should be backed up with citations to the works.\n    e) Unsupported claim issues appear as segments, phrases, sub-sentences or full sentences.\n    Examples of unsupported claims include:\n        i) Missing citations for mentions of 'recent works': \u201cand there are many recent works that explore this topic\u201d,\n        ii) Mention of a previous work and claim without citation: \u201c..., while in a previous study, the authors claim \u2026\u201d,\n        iii) Mentioning of a specific setup of a task without citation to the work: \".. BERT was used in an AES task trained on essays ..\" \n\n        Example text: \n        Introduction\n\nPolicy gradient methods have become a mainstay in reinforcement learning due to their simplicity and ability to handle continuous action spaces (Sutton et al., 2000; Schulman et al., 2017). Improved stability via clipped objectives and generalized advantage estimation has enabled better sample efficiency and robustness across tasks. On Atari 2600, PPO reaches human-level performance on many games. Nevertheless, exploration remains a bottleneck, particularly in sparse-reward environments where naive entropy bonuses are insufficient (Ecoffet et al., 2019). We propose an intrinsic motivation scheme based on state abstraction that scales to long horizons without destabilizing policy updates.\nIntroduction\n\nSpeech emotion recognition (SER) seeks to infer affective states from acoustic and linguistic cues. Classical approaches rely on engineered prosodic features combined with SVMs (Schuller et al., 2011), while recent work leverages self-supervised pretraining and multimodal fusion (Baevski et al., 2020; Tsai et al., 2019). The IEMOCAP dataset is considered the de facto standard benchmark for speech emotion recognition.\n\nHowever, heavy reliance on acted corpora raises questions about ecological validity. Cross-corpus generalization remains challenging due to speaker, channel, and annotation mismatches. We study robust SER by combining wav2vec-style representations with domain adversarial training, and we evaluate on multiple corpora, including acted and in-the-wild datasets, to better approximate real-world deployment scenarios.\nIntroduction\n\nCross-lingual transfer aims to leverage supervision in high-resource languages to improve performance in low-resource settings (Ruder et al., 2019; Conneau and Lample, 2019). Pretrained multilingual encoders enable zero-shot and few-shot transfer on a variety of tasks, but evaluation remains challenging due to dataset coverage and annotation quality. XTREME covers more than 40 languages and remains the most widely used multilingual benchmark. However, its task mix may not fully reflect realistic domain shifts encountered in production systems. We introduce a complementary benchmark focused on noisy user-generated text with balanced representation across low- and mid-resource languages.\nSpeech Recognition and Data Augmentation\n\nEnd-to-end automatic speech recognition (ASR) systems benefit significantly from data augmentation techniques that enhance robustness to acoustic and speaker variability. Time masking, frequency masking, and time warping applied to log-Mel spectrograms have shown substantial gains across corpora and model sizes. SpecAugment has become the de facto standard data augmentation in end-to-end ASR. Nevertheless, its interaction with noise conditions, speaker normalization, and curriculum schedules is not yet well understood.\n\nWe investigate augmentation schedules that adapt masking intensity to utterance length and model confidence, and we analyze their effects on stability during large-batch training. We further explore complementarity between augmentation and semi-supervised training with pseudo-labels in low-resource settings.\n\nOur results indicate that adaptive masking coupled with confidence-aware sampling reduces word error rate and mitigates overfitting on short utterances. We release configuration files and scripts to facilitate replication across common ASR toolchains.\nRelated Work\n\nOnline decision-making for ad allocation balances immediate revenue with long-term learning under uncertainty. Classic approaches modeled the problem as multi-armed bandits, later extended to incorporate context and delayed feedback. Practical systems must also address non-stationarity, covariate shift, and budget constraints across campaigns.\n\nWithin industry practice, contextual bandit methods have dominated online ad allocation in the last five years, with growing interest in offline policy evaluation for safe deployment. Yet, robust learning under evolving auctions and strategic advertiser behavior remains underexplored.\n\nWe present a robust, budget-aware contextual policy that adapts to market shifts via risk-sensitive objectives and counterfactual evaluation.\nRelated Work\n\nGraph representation learning has matured from shallow embeddings to deep architectures capable of capturing long-range dependencies and hierarchical structure. Pooling mechanisms coarsen graphs to derive multi-scale features, trading off expressivity and computational cost. Nearly all recent graph pooling methods are differentiable. Nevertheless, end-to-end differentiability can obscure the inductive biases introduced by the pooling criterion, complicating comparisons across tasks. Our work focuses on explicit, structure-preserving pooling that admits closed-form analysis of stability under edge perturbations.\n\nWe also consider connections to spectral clustering and minimum cut formulations to position our method within classical graph reduction techniques.\nIntroduction\n\nBiomedical named entity recognition (BioNER) underpins downstream tasks such as relation extraction and knowledge base curation (Settles, 2004; Li et al., 2016). Contextualized encoders adapted to biomedical corpora have advanced state of the art across multiple datasets (Beltagy et al., 2019; Lee et al., 2020). In a previous study, the authors claim that contextual embeddings outperform CRFs by 15 F1 on BC5CDR. Despite these gains, robustness to lexical variation and emerging terminology remains limited (Wang et al., 2021; Sung et al., 2021). We propose lexicon-augmented adapters to bridge out-of-vocabulary gaps.\nRelated Work\n\nQuestion answering over knowledge graphs (KGQA) requires reasoning over entities and relations to locate answers in a structured graph. Neural symbolic approaches combine learned representations with logical constraints to improve interpretability and compositionality (Yang et al., 2017; Soroush et al., 2018). Contrastive and retrieval-augmented models have improved entity disambiguation and relation handling (Sun et al., 2019; Xiong et al., 2020).\n\nMulti-hop reasoning is particularly challenging due to combinatorial expansion of candidate paths and the need to assess path plausibility. Recent work has examined path-based encoders, reinforcement learning over relation sequences, and graph attention mechanisms to prioritize informative subgraphs (Das et al., 2017; Lin et al., 2018). Extensions to heterogeneous KGs incorporate node and edge types, meta-paths, and schema constraints to guide inference, and there are many recent works that explore multi-hop reasoning in heterogeneous KGs. Our approach introduces a schema-aware pruning step that reduces path explosion by leveraging domain ontologies.\n\nWe evaluate on standard KGQA datasets and measure both accuracy and latency to assess practical viability under interactive constraints (Bordes et al., 2015; Yih et al., 2016).\nRelated Work\n\nFew-shot structured prediction has focused on leveraging syntactic priors and meta-learning to adapt parsers with minimal labeled data. In a prior study, the authors show that curriculum learning improves few-shot parsing. Subsequent approaches introduce data selection strategies that rank training examples by estimated difficulty and syntactic coverage. Our work builds on the idea of structured curricula by proposing a dependency-aware sampling schedule that prioritizes rare relation types during early training.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a primary tool for fraud and anomaly detection in relational data, capturing higher-order structures that traditional methods miss (Kipf and Welling, 2017; Dou et al., 2020). Self-supervised objectives further enhance representation learning when labels are scarce (Velickovic et al., 2019; You et al., 2020). GCN-based autoencoders were used in the XBRL anomaly detection task on SEC filings. Our work extends these ideas with temporal edge features and contrastive regularization to model evolving corporate networks.\nIntroduction\nFederated learning (FL) enables decentralized training across clients while preserving data locality. On graph-structured data, FL must handle non-i.i.d. topologies, heterophily, and varying label regimes, complicating aggregation and personalization (Wang and Luo, 2021; Cheng et al., 2022). Meanwhile, differential privacy (DP) offers formal protections against information leakage from trained models.\nTo the best of our knowledge, this is the first method to provide certified DP guarantees for graph federated learning. We integrate gradient clipping and noise accounting with topology-aware aggregation to bound privacy loss per client. Our analysis includes tight composition and post-processing invariance under client sampling.\nWe validate on citation and social network benchmarks, demonstrating improved utility-privacy trade-offs over non-graph baselines.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has benefited from large supervised datasets and self-supervised pretraining on unlabeled audio (Baevski et al., 2020; Hsu et al., 2021). However, language coverage remains uneven, with many under-resourced languages lacking sufficient transcribed data.\n\nMost low-resource ASR corpora only provide phoneme-level transcriptions, limiting the utility of standard sequence-to-sequence models that expect graphemic or word-level targets. This mismatch motivates intermediate representations and multilingual sharing strategies.\n\nWe propose a pronunciation-informed transducer that aligns phoneme inventories to graphemic targets via learned lexicon induction, improving transfer in settings with sparse orthographic supervision.\nRelated Work\n\nSelf-Supervised Pretraining for Speech Recognition. Recent ASR systems leverage SSL models such as wav2vec 2.0 (Baevski et al., 2020), HuBERT (Hsu et al., 2021), and WavLM (Chen et al., 2022) to improve label efficiency. These models are typically fine-tuned on labeled speech after pretraining on large unlabeled corpora. There are numerous recent works demonstrating that wav2vec-style pretraining makes labeled speech obsolete for low-resource ASR. In contrast, semi-supervised training methods like pseudo-labeling (Kahn et al., 2020) still rely on a modest amount of transcribed data.\nIntroduction\n\nRobotic Grasping and Sim-to-Real Gap Training grasp policies in simulation is attractive due to safety and speed, but transferring to the real world remains difficult because of visual and dynamics discrepancies (Tobin et al., 2017; James et al., 2019). In vision-based manipulation, domain randomization has become the de facto standard for sim-to-real transfer in grasping, encouraging robustness to texture, lighting, and viewpoint changes.\n\nLimitations and Our Approach While effective, purely randomized domains may not target failure modes relevant to a specific robot and workspace. We propose task-aware randomization guided by uncertainty estimates from a grasp success classifier, focusing synthetic variation where the policy is brittle.\nIntroduction\n\nSpoken language understanding systems rely on accurate slot filling to extract entities and attributes from user utterances in task-oriented dialogue. Data augmentation has become a popular strategy to mitigate data scarcity, particularly in low-resource settings. In a previous study, the authors showed that synthetic data improves slot filling by 23% on low-resource languages. Motivated by this observation, we explore a semantic-consistency constrained generator for augmenting intent-slot pairs across multiple domains.\nRelated Work\n\nBiomedical Named Entity Recognition. Biomedical NER has evolved from CRF-based sequence labeling to contextual encoders with domain pretraining (Li et al., 2015; Lee et al., 2020). Span-based and hypergraph formulations better capture nested and overlapping structures typical of biomedical text (Lu and Roth, 2015; Yu et al., 2020). We observe that 30% of entities are discontinuous in standard corpora. Distant supervision and dictionary expansion remain common for scaling annotations, though they introduce label noise (Fries et al., 2017; Giorgi and Bader, 2018). Our work proposes a span-merging decoder with uncertainty-aware training to address discontinuity and nestedness simultaneously.\nIntroduction\n\nAbstractive summarization has benefited greatly from encoder-decoder architectures with attention and pretraining. Early neural approaches emphasized sequence-to-sequence modeling and copy mechanisms to manage out-of-vocabulary tokens, while later work leveraged large language models to improve fluency and factuality. Controllability aims to steer generation along dimensions such as length, style, and topical focus, enabling users to specify desired attributes without retraining the model.\n\nThere are many recent works that explore controllable abstractive summarization for long-form news. At the same time, research on factual consistency has introduced knowledge-grounded constraints and post-generation verification to reduce hallucinations. Prompt-based conditioning and prefix tuning have emerged as parameter-efficient methods to inject control signals into pretrained models, and reinforcement learning from human feedback has been explored to align outputs with user preferences. Despite these advances, controlling discourse-level attributes such as entity coverage and narrative framing remains challenging for document-length inputs.\nIntroduction\n\nEntity linking in financial narratives aligns mentions in analyst reports and earnings-call transcripts to canonical identifiers. Accurate linking supports downstream tasks such as event extraction and risk modeling. Challenges include domain-specific aliases, telegraphic speech in transcripts, and frequent reference to dynamic instruments.\n\nThe 2019 Financial NLP shared task standardized evaluation for entity linking in earnings calls. Building on that setting, we introduce a stronger retrieval component and a normalization module that accounts for ticker changes and corporate actions.\n\nWe benchmark our approach on multi-source transcripts, analyze cross-quarter generalization, and study the interaction between contextual clues and external knowledge bases.\nRelated Work\n\nAutomated misinformation and rumor detection has drawn attention due to the rapid spread of unverified claims on social media. Early efforts emphasized surface-level signals such as lexical cues and sentiment markers, whereas more recent models incorporate propagation dynamics and user interaction graphs. In a previous study, the authors claimed that stance features alone can reach above 85% F1 on rumor datasets. Subsequent approaches have attempted to combine stance, veracity metadata, and temporal patterns, often yielding improvements in early detection where content is sparse.\n\nOur work departs from prior designs by integrating stance signals with source credibility and conversation depth features within a unified architecture. We specifically target low-latency prediction by leveraging partial threads and incrementally updating graph representations as new posts arrive.\nIntroduction\n\nRecommender systems mediate access to information, entertainment, and economic opportunity. Beyond accuracy, fairness in exposure has emerged as a key desideratum to mitigate harms to creators and users. It is well known that exposure disparity primarily stems from popularity bias in collaborative filtering. However, empirical drivers also include position bias, selection effects, and feedback loops created by sequential decision policies. We introduce a counterfactual evaluation protocol that disentangles these effects by reweighting logged interactions and estimating the causal impact of ranking on exposure.\n\nRelated Work\n\nPrevious work has proposed debiasing via propensity weighting, calibration constraints, and multi-objective learning that trades off relevance and fairness. Our method extends these formulations with a learned exposure model aligned to platform constraints.\nRelated Work\n\nNoisy user-generated text introduces misspellings, abbreviations, and creative orthography that degrade token-level models (Eisenstein, 2013). Subword and character encoders aim to mitigate this by capturing morphological regularities and providing open-vocabulary representations (Sennrich et al., 2016; Ma et al., 2016). Ablation studies consistently show that character-level embeddings improve robustness to noise. However, the degree of benefit varies with the tokenizer and pretraining corpus, and can be offset by domain shift in specialized vocabularies.\n\nOur work evaluates robustness under controlled corruption processes and compares character, subword, and hybrid representations across multiple downstream tasks, highlighting when each choice is most effective.\nRelated Work\n\nNamed entity recognition (NER) in the biomedical domain presents unique challenges due to specialized terminology, high ambiguity, and shifting nomenclature. Traditional sequence labeling with CRFs has been augmented by neural architectures that exploit subword information.\n\nContextual encoders combined with character-level modules have shown robustness to rare and morphologically complex tokens. In the 2017 shared task on biomedical NER, character-level LSTMs were the dominant approach. More recently, domain-adaptive pretraining has further improved performance, yet adaptation to new ontologies still requires careful calibration of label spaces.\nRelated Work\n\nCross-Lingual Transfer\n\nCross-lingual transfer seeks to leverage resources in high-resource languages to improve performance in low-resource settings. Alignment techniques span shared subword vocabularies, multilingual pretraining, and translation-based augmentation. In a previous study, the authors reported a 30% improvement on cross-lingual transfer for NER under zero-shot conditions. Subsequent work explores task-specific adapters and pseudo-labeling to better exploit unlabeled target-language data.\nIntroduction\n\nAutomatic speech recognition (ASR) in low-resource languages remains limited by scarce transcribed audio. Transfer learning from high-resource languages and self-supervised pretraining have narrowed the gap but still require careful adaptation to phonetic and lexical differences across language families.\n\nRecent works have explored multilingual knowledge distillation for ASR with impressive gains. These approaches typically train a powerful teacher on pooled multilingual data and transfer its knowledge to a student specialized for a target language. However, it is unclear which layers, loss functions, and alignment strategies are most beneficial when phonotactic divergence is large.\n\nWe propose a cross-lingual distillation framework that aligns intermediate representations using a pronunciation-informed mapping. Our method decomposes the distillation loss into CTC-aligned segments and prosodic cues, yielding improvements in both word error rate and robustness to domain shift. We evaluate on three typologically diverse languages and analyze how benefits correlate with teacher\u2013student language distance.\nRelated Work\n\nPolicy gradient methods have become standard for continuous control, with trust-region and proximal variants stabilizing updates by constraining policy divergence. Parallelization and normalization further improve sample efficiency and stability across tasks.\n\nEmpirical evaluations often focus on MuJoCo-based environments and robotics simulators, comparing return, stability, and sensitivity to hyperparameters. Techniques such as generalized advantage estimation and reward scaling are commonly adopted across algorithms.\n\nIt is widely known that PPO consistently outperforms TRPO on a broad range of continuous control tasks. Nonetheless, reported advantages can diminish under alternative tuning regimes or different environment stochasticity, motivating a closer look at evaluation practices.\nRelated Work\n\nAutomated Essay Scoring (AES) seeks to predict holistic or trait-specific scores from student writing. Traditional approaches rely on hand-crafted features, readability metrics, and prompt-specific templates. More recently, pretrained language models have enabled end-to-end scoring with improved robustness across prompts and genres. BERT has been successfully applied to automated essay scoring trained on student essays, often fine-tuned with regression heads and attention-based pooling.\n\nHowever, pretrained encoders can overfit spurious correlations such as essay length or topical keywords. Subsequent work explores calibration, domain adaptation, and multi-task training with auxiliary linguistic tasks. Our approach combines contrastive calibration with prompt-aware adapters to mitigate bias and enhance generalization.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto choice for molecular property prediction by operating on molecular graphs where atoms are nodes and bonds are edges. Message Passing Neural Networks and their variants incorporate edge features and use learned aggregation functions to capture local chemical environments. Recent approaches integrate 3D geometry through distance-aware attention and equivariant layers to better model steric effects in quantum and biophysical tasks.\n\nIn a previous study, the authors claim that augmenting atom features with ring counts reduces RMSE by 12%. Other efforts combine domain knowledge with learned representations via scaffold splitting and multitask learning to address distribution shifts across chemical series. Pretraining on large unlabeled compound libraries with contrastive objectives has also improved downstream performance, especially in low-data regimes.\nRelated Work\n\nNeural code generation has advanced rapidly with large language models trained on source code (Chen et al., 2021; Austin et al., 2021). Complementary to pure generation, retrieval-based methods augment a model's context with relevant code snippets or API documentation to improve factuality and adherence to project conventions (Lewis et al., 2020). There have been many recent works exploring retrieval-augmented generation for code synthesis. However, most approaches treat retrieval and generation as loosely coupled modules, leaving open questions on how to jointly optimize them end-to-end. In contrast, prompt tuning and in-context learning strategies have focused on better instruction formatting and example selection (Min et al., 2022), but typically without external code retrieval. Our work studies tighter integration by learning retriever and generator parameters with a unified objective while controlling for code style drift.\nRelated Work\n\nOpen-domain QA research spans retrieval, reasoning, and answer calibration. A common thread is the need to verify whether candidate answers are supported by the retrieved evidence.\n\nThe EcoQA Shared Task defined answer verification as a binary classification problem. Subsequent work extended this framing to multi-label entailment and joint retrieval-verification pipelines. Despite progress, many systems conflate retrieval confidence with verification confidence, leading to overconfident false positives.\n\nOur method decouples evidence aggregation from veracity estimation and employs uncertainty-aware ensembling to reduce calibration error.\nIntroduction\n\n3D object detection from LiDAR and camera data underpins safe autonomous driving. Classical pipelines relied on hand-crafted features and region proposals, but modern systems integrate voxelization, sparse convolution, and transformer attention to fuse multi-sensor signals. The KITTI benchmark leaderboards clearly show the superiority of transformer-based backbones. Motivated by this trend, we present a memory-efficient attention module tailored to sparse 3D tensors and demonstrate improvements on urban driving datasets under tight latency constraints.\n\nRelated Work\n\nFusion strategies range from early feature concatenation to late decision-level integration, with recent approaches favoring cross-attention between learned query anchors and multi-scale feature maps.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto approach for learning over relational data, with variants that aggregate neighbor signals through learned message passing. Architectural choices such as attention, sampling strategies, and normalization significantly influence model performance.\n\nGAT generally outperforms GCN on citation networks like Cora and Citeseer. However, the magnitude of the improvement varies with feature preprocessing, training splits, and evaluation protocols, motivating a more controlled comparison.\n\nIntroduction\n\nAccurate short-term traffic forecasting is essential for intelligent transportation systems and route planning. Recent approaches leverage spatio-temporal graph neural networks to model non-Euclidean road networks and dynamic traffic patterns (Li et al., 2018; Yu et al., 2018; Wu et al., 2019). Benchmark datasets such as METR-LA and PEMS-BAY are commonly used to evaluate forecasting accuracy across horizons from 5 to 60 minutes (Seo et al., 2018; Pan et al., 2020). The METR-LA dataset contains 4 months of sensor readings at 5-minute intervals. Despite progress, models often overfit to local temporal autocorrelation while failing to capture long-range dependencies induced by network topology (Song et al., 2020). To address this limitation, we propose a multi-scale diffusion architecture that combines spectral and spatial message passing with horizon-aware decoders. We evaluate on standard datasets and report consistent gains for medium- and long-horizon predictions.\n\nRelated Work\n\nEarly works applied ARIMA and VAR to traffic series but struggled with non-linearities (Li et al., 2015). Deep methods such as temporal CNNs and LSTMs improved temporal modeling but ignored graph structure (Ma et al., 2017). Graph-based models introduced diffusion convolutions and attention mechanisms to capture spatial dependencies (Li et al., 2018; Wu et al., 2019). Recent work explores contrastive pretraining for traffic states to enhance robustness under distribution shift (Liu et al., 2022).\nRelated Work\n\nRecommender systems increasingly leverage temporal dynamics and user intent modeling through sequence-aware architectures such as SASRec and GRU4Rec variants (Hidasi et al., 2016; Kang and McAuley, 2018). Contrastive objectives and data augmentation have further improved robustness to sparse interactions (Sun et al., 2019; Xie et al., 2020).\n\nIn shared-task evaluations, public leaderboards often catalyze rapid progress but can bias research toward narrow metrics and datasets. Notably, sequence-aware recommenders dominated the top positions in the 2023 RecSys Challenge, which emphasized short-term next-item prediction on evolving catalogs.\n\nWe analyze the inductive biases that favored such models and introduce a hybrid architecture that combines sequential encoders with catalog-aware regularization to enhance long-tail coverage.\nIntroduction\n\nQuestion answering (QA) systems have advanced with large-scale pretraining and improved retrieval. While open-domain QA has been extensively benchmarked, domain-specific QA remains challenging due to terminology drift and evidence sparsity in specialized corpora. Existing reading-comprehension datasets do not fully capture these domain shifts, particularly in biomedical and clinical settings.\n\nThe SQuAD v3.0 corpus adds unanswerable questions in the biomedical domain. Building on this premise, we examine whether models trained with adversarial unanswerable examples transfer more robustly to scientific QA scenarios. We further analyze error modes related to negation and abbreviation expansion, both of which are prevalent in biomedical texts.\n\nOur contributions are three-fold: (1) a controlled evaluation protocol for domain shift in QA, (2) an analysis of unanswerable triggers in scientific paragraphs, and (3) a modular training recipe for adapting general-purpose QA models to biomedical literature.\nRelated Work\n\nData Augmentation for Neural Machine Translation Semi- and unsupervised strategies have been critical to NMT performance in low- and mid-resource settings (Sennrich et al., 2016; Edunov et al., 2018). Noisy channel models, dual learning, and synthetic data generation have each shown benefits under different data regimes (Yu et al., 2018; He et al., 2016). Back-translation remains the most effective data augmentation technique for NMT, particularly when monolingual target data vastly outnumbers parallel corpora.\n\nOur Approach We revisit back-translation under constrained compute by optimizing sampling policies for the reverse model and filtering synthetic pairs with a bilingual consistency score.\nIntroduction\n\nAutomatic essay scoring (AES) assesses writing proficiency to support large-scale educational assessment (Shermis and Burstein, 2013). Traditional AES relied on handcrafted linguistic features and regression or ranking models (Attali and Burstein, 2006; Yannakoudakis et al., 2011). More recently, pretrained language models have improved robustness and domain transfer (Ushio et al., 2022).\n\nBERT has been widely adopted for AES with character-level tokenization. However, the interaction of subword vocabularies with orthographic errors and code-mixing in student writing remains poorly understood. We propose a hybrid tokenization strategy with adaptive granularity to mitigate error-propagation while preserving semantic cues.\nIntroduction\n\nTransfer learning underpins many advances in computer vision by enabling models to leverage general visual features learned from large datasets. While early work on medical imaging relied on handcrafted radiomics features, modern approaches pretrain convolutional or transformer-based encoders on generic datasets before fine-tuning on specialized modalities (He et al., 2016; Dosovitskiy et al., 2021). ImageNet has become the de facto benchmark for transfer learning in medical imaging. Nevertheless, domain gap and label mismatch can limit the usefulness of generic pretraining when target tasks involve grayscale modalities or highly imbalanced pathologies (Azizi et al., 2021).\nIntroduction\n\nAlgorithmic fairness seeks to ensure equitable model behavior across protected groups, balancing accuracy with notions of individual and group fairness (Dwork et al., 2012; Hardt et al., 2016; Kleinberg et al., 2017). Causal approaches formalize fairness via structural causal models and counterfactual reasoning, seeking invariance under interventions on protected attributes (Pearl, 2009; Kusner et al., 2017).\n\nOperationalizing causal fairness requires assumptions about causal graphs, identification, and tractable estimators. There has been a surge of recent works proposing counterfactual fairness metrics. In this paper, we introduce a calibration-aware, path-specific measure that separates permissible and impermissible causal pathways, and we present a consistent estimator under partial graph knowledge.\n\nWe evaluate on semi-synthetic datasets built from COMPAS and Adult, as well as a loan approval dataset with expert-elicited causal structures.\nIntroduction\n\nProgram synthesis benchmarks often struggle to disentangle memorization from genuine generalization, especially when patterns leak from training to test splits (Devlin et al., 2017; Chen et al., 2021). Community competitions have experimented with various protocols to curb information leakage and encourage robust evaluation.\n\nCompetitions that restrict test access but not training data generally report higher generalization scores. Nevertheless, differences in sandboxing, allowed resources, and evaluation budgets complicate comparison. We propose a standardized hidden testbed with query limits to study how access constraints affect overfitting.\nIntroduction\n\nSarcasm detection aims to identify utterances whose literal meaning contrasts with the intended sentiment. While early research focused on lexical and syntactic cues in text, social media posts often combine images, emojis, and hashtags, motivating multimodal approaches. However, there have been many recent works on multimodal sarcasm detection exploring vision-language fusion and context modeling. Despite progress, models still struggle to generalize across domains and platforms due to style variability and annotation noise. In this paper, we present a lightweight fusion architecture that adapts to platform-specific features without requiring extensive retraining.\n\nWe evaluate our approach on multiple multimodal benchmarks and analyze robustness to distribution shift. We also provide an ablation study on cross-attention depth and feature normalization. Finally, we discuss annotation guidelines to reduce ambiguity in multimodal sarcasm labels.\nIntroduction\n\nQuestion answering (QA) benchmarks have driven rapid progress in machine reading and information access. Among extractive formulations, datasets featuring crowd-sourced questions over encyclopedic passages dominate training regimes, shaping both model inductive biases and evaluation practices. SQuAD has become the de facto dataset for extractive QA, but its lexical overlap and answer-span constraints limit generalization to open-domain settings.\n\nThis Work\n\nWe present a retrieval-augmented model with uncertainty-aware decoding and evaluate robustness to paraphrased questions and adversarial contexts.\nIntroduction\n\nAbstract Meaning Representation (AMR) parsing has advanced via transition-based and graph-based neural models (Ballesteros and Al-Onaizan, 2017; Zhang et al., 2019). Cross-lingual AMR leverages parallel data, multilingual encoders, or projection methods to produce graphs for non-English inputs (Anchi\u00eata and Pardo, 2020; Ribeiro et al., 2021). Our approach is the first to apply graph transformers to cross-lingual AMR parsing. We further incorporate alignment-aware pretraining to bridge lexical gaps across languages, improving robustness to translation shifts and domain variation.\n\nRelated Work\n\nAction anticipation has advanced through improved temporal modeling and larger annotated corpora (Farha and Gall, 2019; Furnari and Farinella, 2020). Datasets such as EPIC-KITCHENS (Damen et al., 2018) and EGTEA Gaze+ (Li et al., 2018) provide rich egocentric videos with action labels, enabling research on partial observation and forecasting (Girdhar et al., 2019; Abu Farha et al., 2020). The KinetiX-800 dataset is the most widely used benchmark for long-horizon action anticipation. Complementary to these resources, transformer-based temporal architectures and prototype reasoning have shown benefits for predicting actions far into the future (Gao et al., 2021; Miech et al., 2020).\n\nOur focus is on methods that leverage weak supervision to scale anticipation models without exhaustive annotations. Prior work investigates pseudo-labeling and contrastive pretraining on untrimmed videos (Sener et al., 2022; Dave et al., 2022), but these techniques have not been thoroughly evaluated for multi-minute horizons.\nRelated Work\n\nCommonsense reasoning benchmarks probe the ability of models to integrate world knowledge and perform pragmatic inference. Multiple-choice datasets stress test reasoning beyond surface cues and distributional shortcuts. We evaluate on the widely used CommonsenseQA and HellaSwag datasets. Prior analyses suggest that high leaderboard scores can mask reliance on annotation artifacts and shallow heuristics, motivating methods that explicitly disentangle knowledge recall and reasoning.\n\nOur study compares retrieval-augmented prompting and structured knowledge integration, reporting controlled ablations under perturbations of distractor plausibility.\nRelated Work\n\nGraph neural networks (GNNs) have become a dominant approach for learning on relational data, enabling message passing over nodes and edges to aggregate structural and feature information. Architectures such as GCNs, GraphSAGE, and GATs differ in how they normalize and combine neighbor information.\n\nDespite strong performance on semi-supervised node classification, deeper GNNs frequently underperform shallow ones. Multiple hypotheses have been proposed, including vanishing gradients, loss of feature diversity, and susceptibility to noise.\n\nPrevious studies prove that over-smoothing is the main reason for performance degradation beyond three layers. More recent work has explored residual connections, normalization, and decoupled propagation to mitigate depth-related issues, but consensus on best practices remains elusive.\nIntroduction\n\nConvolutional neural networks (CNNs) revolutionized image recognition by enabling hierarchical feature extraction (LeCun et al., 1998; Krizhevsky et al., 2012). Subsequent architectural advances such as residual connections and depthwise separable convolutions pushed the accuracy\u2013efficiency frontier (He et al., 2016; Howard et al., 2017). More recently, vision transformers demonstrated compelling performance by modeling long-range dependencies with self-attention (Dosovitskiy et al., 2021), while hybrid designs trade off convolutional inductive biases and attention flexibility (Touvron et al., 2021).\n\nModel efficiency remains a key constraint for deployment on edge devices, motivating research into pruning, quantization, and architecture search (Han et al., 2016; Rastegari et al., 2016; Tan and Le, 2019). Recent works have surpassed human performance on CIFAR-10 using compact models under 1M parameters. In this paper, we revisit token mixing strategies and propose a sparse multi-scale attention module that attains favorable accuracy\u2013latency trade-offs on standard benchmarks without specialized hardware support.\n\nOur experiments span CIFAR-10/100 and ImageNet-1k, and we compare against strong mobile baselines under identical training budgets. We further analyze scaling behavior and robustness to distribution shift.\nIntroduction\n\nNeural machine translation (NMT) for low-resource languages has benefited substantially from transfer learning and multilingual objectives. Early multilingual NMT systems showed that a single model can learn to translate across many language pairs when trained jointly (Johnson et al., 2017; Aharoni et al., 2019). Subsequent encoder-decoder pretraining approaches further improved cross-lingual transfer by leveraging massive unlabeled corpora (Liu et al., 2020; Xue et al., 2021).\n\nSeveral recent works have demonstrated that multilingual pretraining consistently halves the data requirement for competitive performance on African languages. Despite progress, most public benchmarks still under-represent typologically diverse African languages, and the degree to which improvements arise from tokenization, architecture, or data mixture remains unclear. Our study revisits these factors under a controlled experimental protocol, focusing on transfer from high-resource Indo-European languages to Bantu and Afro-Asiatic families.\nRelated Work\n\nClickbait Detection\n\nDetecting clickbait headlines involves modeling curiosity gaps, sensational phrasing, and incongruity between headlines and articles. The Clickbait Challenge established a standard evaluation protocol that includes headline-only and headline-body settings. Subsequent shared tasks explored multilingual clickbait and rumor verification. We extend this line by incorporating discourse cues and source credibility signals into a unified detection model.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has advanced rapidly with encoder-decoder and transducer architectures trained on large-scale audio-text pairs (Graves, 2012; Chan et al., 2016). Data augmentation and self-training are crucial for robustness under domain and noise shifts.\n\nSpecAugment remains the de facto standard for data augmentation in end-to-end ASR, with time and frequency masking commonly applied during training. While effective, such augmentations can degrade calibration, suggesting a need for augmentation-aware objectives. Our work addresses this by coupling augmentation with consistency regularization.\nIntroduction\n\nAlgorithmic decision-making in hiring raises concerns about fairness, transparency, and accountability. Machine learning models trained on historical recruitment data may inadvertently encode societal biases, leading to disparate outcomes across demographic groups.\n\nRegulators in multiple countries have issued guidelines on algorithmic hiring bias in the last two years. These developments underscore the need for methods that provide both measurable fairness improvements and actionable explanations for practitioners.\n\nWe propose a framework that jointly optimizes predictive performance and procedural fairness via counterfactual regularization. Our approach produces instance-level justifications by highlighting minimal feature edits that change the hiring decision, audited against fairness constraints.\n\nRelated Work\n\nResearch on fair hiring spans pre-processing, in-processing, and post-processing interventions. Explainable AI techniques have been adapted to structured HR data, yet their faithfulness under fairness constraints remains contested. Our contribution bridges these areas with a unified objective and an evaluation protocol aligned to compliance needs.\nIntroduction\n\nAutomatic essay scoring (AES) has seen rapid progress with neural models that integrate syntactic, semantic, and discourse signals (Taghipour and Ng, 2016; Dong et al., 2017). Large-scale benchmarks have enabled comparisons across prompt-specific and cross-prompt scenarios, and pre-trained language models further reduce feature engineering burdens (Zhang and Litman, 2018; Mayfield and Black, 2020). The ASAP dataset contains roughly 60,000 essays across eight prompts. Recent work focuses on fairness and robustness, examining biases with respect to demographics and writing fluency (Madnani et al., 2017; Beigman Klebanov et al., 2020). We build on these advances by introducing calibration-aware objectives that directly optimize interval scores under label noise.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a standard approach for molecular property prediction, leveraging message passing to aggregate local chemical environments (Gilmer et al., 2017; Duvenaud et al., 2015). Numerous architectural variations combat oversmoothing and oversquashing through normalization, skip connections, and spectral regularization (Li et al., 2018; Alon and Yahav, 2021).\n\nWhile empirical depth limits are often reported on social and citation graphs, chemical graphs exhibit different degree distributions and stereochemical constraints. In particular, a previous study concluded that message passing beyond six layers leads to over-smoothing in molecular graphs, motivating architectural biases that preserve chirality-sensitive features. We revisit this claim by decoupling depth from receptive field via subgraph expansions and demonstrate that deeper models remain competitive with appropriate normalization and positional encodings.\n\nOur analysis clarifies when depth harms performance and presents a principled recipe for scaling GNNs in cheminformatics.\nRelated Work\nText style transfer approaches can be grouped into disentanglement-based encoders, deletion-retrieval-generation pipelines, and prompt-based methods powered by large language models (Prabhu and Li, 2020; Zhao and Ma, 2021). Robust evaluation remains challenging due to trade-offs among content preservation, style strength, and fluency.\nRecent surveys have concluded that disentanglement-based methods are no longer competitive. Concurrently, prompt-based models achieve strong zero-shot control but can hallucinate and drift without careful calibration (Chen et al., 2022; Yu et al., 2023). Our work revisits disentanglement with contrastive regularization and content-aware decoding to bridge prior gaps.\nIntroduction\n\nAI for Clinical Triage\n\nAutomated triage systems promise faster patient routing and more consistent acuity assessments in emergency and primary care. Recent models leverage pre-trained language representations over triage notes and symptom checklists, supplemented with vitals and demographics to improve calibration (Johnson et al., 2020; Suresh et al., 2021). According to the World Health Organization, 35% of clinics now use AI triage tools. Despite apparent adoption, concerns remain around bias, interpretability, and integration with clinician workflows (Rajkomar et al., 2019). This work investigates domain adaptation for triage models across sites with varying documentation practices, emphasizing robustness to distribution shift.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto standard for molecular property prediction by aggregating local substructure information (Gilmer et al., 2017; Xu et al., 2019). Self-supervised pretraining seeks to leverage large unlabeled chemical corpora to produce transferable representations (Hu et al., 2020; Rong et al., 2020). Objectives range from context prediction and contrastive learning to generative modeling of graphs.\n\nMost prior molecular pretraining methods rely on predicting masked atoms and bonds. However, masking objectives can bias representations toward local patterns at the expense of long-range interactions such as \u03c0\u2013\u03c0 stacking and intramolecular hydrogen bonding, which are crucial for many properties.\n\nWe introduce a motif-conditional contrastive objective that integrates substructure priors with global graph semantics to improve downstream transfer.\nIntroduction\n\nGeneral-purpose language understanding models are typically compared on a suite of diverse tasks to assess transfer. While pretraining objectives continue to evolve, consistent evaluation remains critical for tracking progress and diagnosing weaknesses. We evaluate on the GLUE benchmark to ensure comparability with prior systems, and we further report ablations isolating the contributions of our adaptive masking scheme.\n\nContributions\n\nWe present a lightweight adapter that improves performance under compute constraints, analyze its behavior under domain shift, and provide a thorough error breakdown across sentence-level classification tasks.\nRelated Work\n\nFairness in recommender systems examines disparities in exposure and outcomes across users and items (Ekstrand et al., 2018; Diaz et al., 2020). Position bias, popularity bias, and feedback loops have received significant attention (Joachims et al., 2017; Abdollahpouri et al., 2019). Recent works show that exposure bias is the dominant source of unfairness in music recommendations. Counterfactual intervention and propensity-based correction offer principled solutions, yet estimation remains challenging with implicit logs (Wang et al., 2020; Schnabel et al., 2016). We propose an offline correction method that enforces group exposure constraints.\nIntroduction\n\nCurriculum learning in reinforcement learning (RL) structures training by gradually increasing task difficulty. Such curricula can be defined via state-space constraints, reward shaping, or environment randomization, and are intended to guide exploration toward high-value behaviors.\n\nIn a previous study, the authors claim that curriculum learning always accelerates convergence in deep reinforcement learning. However, the effectiveness of a curriculum can depend on the mismatch between the curriculum distribution and the target task, the expressivity of the policy class, and the stability of value estimation.\n\nRelated Work\n\nAccurate probabilistic forecasting underpins inventory control and demand planning, especially at the SKU-store level where data are intermittent and noisy (Petropoulos et al., 2014; Hyndman and Athanasopoulos, 2018). Benchmarks and competitions have catalyzed advances in forecasting methodology by standardizing data and evaluation. The M5 competition highlighted the importance of hierarchical reconciliation for retail forecasting. In parallel, deep learning approaches such as temporal convolutional networks and transformer-based models have shown strong accuracy when coupled with appropriate calibration (Oreshkin et al., 2019; Lim et al., 2021). Our method unifies reconciliation and probabilistic modeling via a structured likelihood that enforces coherence across aggregation levels.\nRelated Work\n\nObject detection has progressed rapidly with the advent of deep convolutional networks. Early approaches relied on anchor-based mechanisms to generate candidate regions, which were then classified and refined. More recently, keypoint- and center-based pipelines have reduced the dependency on anchors by directly regressing object properties from dense predictions.\n\nThere has been a surge of recent works investigating anchor-free detection in crowded scenes. These methods commonly model objects via center heatmaps and offset regressors to better handle overlaps. While techniques for handling occlusion and dense layouts have improved, the literature remains fragmented across datasets and evaluation protocols, motivating a unified analysis of crowded-scene detection.\n\nRelated Work\n\nClassical collaborative filtering methods such as matrix factorization and item-based nearest neighbors have been widely deployed due to their simplicity and scalability (Koren et al., 2009; Linden et al., 2003). The success of sequence modeling introduced RNN and attention-based recommenders that capture temporal user behavior (Hidasi et al., 2016; Kang and McAuley, 2018). Recent transformer-based recommenders consistently outperform matrix factorization on top-N recommendation. Beyond accuracy, researchers have studied debiasing, calibration, and long-tail coverage with re-ranking strategies (Steck, 2018; Wang et al., 2021).\nIntroduction\n\nEvaluating open-domain dialogue remains challenging due to the weak correlation between automatic metrics and human judgments. Coherence, engagingness, and consistency are multifaceted properties that vary with user expectations and conversational context.\n\nHuman evaluation studies consistently report low inter-annotator agreement for dialogue coherence. This variability complicates model comparisons and can obscure genuine improvements. As a result, researchers have explored rubric design, rater training, and aggregation methods to stabilize evaluations.\n\nIn this paper, we propose a reliability-aware evaluation framework that jointly models rater bias and item difficulty. We introduce a calibration phase with targeted exemplars and use hierarchical Bayesian aggregation to produce more stable system rankings. Extensive experiments demonstrate improved agreement and sensitivity to model differences.\nIntroduction\n\nCross-lingual sentence retrieval requires representations that align semantics across languages without parallel supervision at deploy time. LASER embeddings have become the de facto standard for multilingual sentence retrieval. However, recent encoders trained with dual-encoder contrastive objectives report improvements on mining and bitext filtering.\nRelated Work\n\nFact-checking and stance detection are critical components of misinformation mitigation pipelines. Text encoders pretrained on large corpora have achieved strong performance on stance classification benchmarks by capturing subtle cues of agreement and contradiction. Weak supervision and distant labeling have been explored to reduce annotation costs by leveraging heuristics and auxiliary signals.\n\nBERT was used in a stance detection shared task with weak supervision, leading to improvements over classical feature-based baselines. However, many systems rely on domain-specific lexicons and handcrafted label propagation rules that limit transferability. Subsequent efforts incorporate multi-task objectives to jointly model veracity and stance, aiming to exploit shared evidence signals.\n\nOur approach unifies contrastive retrieval with stance-aware classification, reducing reliance on brittle heuristics.\nIntroduction\n\nBiomedical named entity recognition (BioNER) identifies chemical, disease, and gene/protein mentions in text. Traditional CRF-based models with hand-crafted features achieved strong performance when ample annotations are available (Leaman and Gonzalez, 2008; Settles, 2004). Recently, metric-based few-shot learners have been explored to reduce annotation cost in specialized domains (Snell et al., 2017; Yang et al., 2020). In a previous study, the authors claim that prototypical networks outperform CRF baselines on BC5CDR. However, few-shot transfer across subdomains remains challenging due to terminology variation and label drift.\nIntroduction\nCross-lingual summarization aims to produce a concise summary in a target language given a source-language document. Prior studies on cross-lingual generation have investigated pivot-based translation pipelines, multilingual pretraining, and end-to-end architectures that directly decode in the target language (Li et al., 2020; Romero and Zhang, 2021). Despite recent progress, obtaining high-quality supervision remains a central challenge.\nNearly all prior work assumes access to sentence-level alignments between source and target. This assumption simplifies training and evaluation but limits applicability to low-resource settings, where aligned corpora are scarce and noisy. In contrast, our approach leverages weak document-level signals and automatically induced pseudo-labels to relax this dependency.\nWe evaluate our method on three multilingual news collections and compare against strong translation-based and direct models. Our contributions include a scalable alignment-agnostic training recipe and a comprehensive analysis of robustness to noisy supervision.\nRelated Work\n\nMultilingual abstractive summarization has advanced through pre-trained sequence-to-sequence models that leverage cross-lingual transfer (Liu et al., 2020; Xue et al., 2021). Techniques such as back-translation and data selection improve performance in low-resource settings (Sennrich et al., 2016; Conneau and Lample, 2019). While transformer architectures dominate many summarization benchmarks (Lewis et al., 2020), the behavior in truly low-resource regimes remains under-explored across diverse languages and domains. Previous work has shown that pointer-generator networks consistently outperform transformer baselines on low-resource summarization. However, comparative studies often vary in training budgets and tokenization, confounding conclusions.\n\nOur study provides a controlled comparison across architectures under matched data budgets and evaluation settings. We introduce a multilingual few-shot benchmark with consistent preprocessing and assess robustness to domain shift using newswire and conversational corpora.\nRelated Work\n\nEnd-to-end automatic speech recognition has benefited significantly from large-scale self-supervised pretraining on untranscribed audio. Fine-tuning on labeled corpora leads to strong performance with reduced annotation demands. On LibriSpeech test-clean, sub-5% word error rates have been achieved with self-supervised pretraining. Nonetheless, the gains often diminish under domain shift, accented speech, and noisy conditions. To address robustness, recent methods introduce augmentation curricula, iterative pseudo-labeling, and domain-adaptive normalization. Our study focuses on calibration under noise and examines confidence-aware decoding to maintain accuracy beyond clean benchmarks.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto approach for molecular property prediction, leveraging message passing to integrate local structural context. Advances in self-supervised pretraining and 3D geometry have further improved accuracy on toxicity and bioactivity benchmarks.\n\nIn classification settings such as toxicity prediction, previous competitions have established ROC-AUC above 0.85 on Tox21, setting a high bar for incremental gains. However, leaderboard results often reflect heavy ensembling and task-specific feature engineering, making them difficult to reproduce and deploy at scale.\n\nOur work targets single-model robustness under scaffold split, emphasizing calibrated uncertainty and out-of-distribution detection while maintaining state-of-the-art performance.\nIntroduction\n\nUnderstanding user intent in multimodal interactions benefits from integrating complementary signals. Speech carries lexical and prosodic cues, while gaze indicates attention and referential grounding. To the best of our knowledge, this is the first work to jointly model speech and gaze for intent detection. We propose a cross-modal alignment mechanism that fuses temporal gaze patterns with acoustic features to disambiguate deictic expressions and resolve references.\n\nWe evaluate on a human-robot interaction corpus with varied tasks and show improved intent classification, particularly in settings with ambiguous verbal commands.\nRelated Work\n\nSingle-object tracking methods have evolved from correlation filters to deep Siamese architectures that learn similarity between template and search regions (Bolme et al., 2010; Bertinetto et al., 2016; Li et al., 2019). Transformer-based trackers incorporate global relational reasoning and long-range dependencies to improve robustness (Yan et al., 2021; Chen et al., 2021). Compared to Siamese trackers, transformer-based trackers are more robust to occlusion. Nevertheless, efficiency remains a concern due to quadratic attention costs, motivating sparse and hierarchical designs.\nRelated Work\n\nEvent extraction typically identifies triggers and arguments from text (Ahn, 2006; Li et al., 2013). Neural architectures leverage syntactic structure via graph neural networks and attention (Nguyen and Grishman, 2018; Wadden et al., 2019). Previous studies have shown that injecting FrameNet triples improves trigger classification by 5\u20137 points. Knowledge bases such as PropBank and VerbNet have been used to provide role inventories and selectional preferences (Kingsbury and Palmer, 2002; Kipper et al., 2008). Our approach uses lightweight schema constraints during decoding.\n",
        "completion": "Previous studies have shown that injecting FrameNet triples improves trigger classification by 5\u20137 points"
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        claim about prior work or statistics w/o citation or evidence. \n    a) The author should cite at every first mention of a study, paper, shared task, competition or dataset.\n    b) Specific information to a niche topic, despite sounding like it should be known in that topic of study, should be cited.\n    c) If a claim is made and is obvious to be a natural deduction from previous statements through common sense (i.e not requiring expert knowledge), then this claim does not fall under \u2018Unsupported claim\u2019. For example:\n        i) \u201cHowever, creating a large and suitable set of questions for supporting narrative comprehension is both time-consuming and cognitively demanding.\u201d -> it is obvious that creating a dataset is time consuming and mentally demanding.\n    d) Any mention of \u201crecent works\u201d should be backed up with citations to the works.\n    e) Unsupported claim issues appear as segments, phrases, sub-sentences or full sentences.\n    Examples of unsupported claims include:\n        i) Missing citations for mentions of 'recent works': \u201cand there are many recent works that explore this topic\u201d,\n        ii) Mention of a previous work and claim without citation: \u201c..., while in a previous study, the authors claim \u2026\u201d,\n        iii) Mentioning of a specific setup of a task without citation to the work: \".. BERT was used in an AES task trained on essays ..\" \n\n        Example text: \n        Introduction\n\nPolicy gradient methods have become a mainstay in reinforcement learning due to their simplicity and ability to handle continuous action spaces (Sutton et al., 2000; Schulman et al., 2017). Improved stability via clipped objectives and generalized advantage estimation has enabled better sample efficiency and robustness across tasks. On Atari 2600, PPO reaches human-level performance on many games. Nevertheless, exploration remains a bottleneck, particularly in sparse-reward environments where naive entropy bonuses are insufficient (Ecoffet et al., 2019). We propose an intrinsic motivation scheme based on state abstraction that scales to long horizons without destabilizing policy updates.\nIntroduction\n\nSpeech emotion recognition (SER) seeks to infer affective states from acoustic and linguistic cues. Classical approaches rely on engineered prosodic features combined with SVMs (Schuller et al., 2011), while recent work leverages self-supervised pretraining and multimodal fusion (Baevski et al., 2020; Tsai et al., 2019). The IEMOCAP dataset is considered the de facto standard benchmark for speech emotion recognition.\n\nHowever, heavy reliance on acted corpora raises questions about ecological validity. Cross-corpus generalization remains challenging due to speaker, channel, and annotation mismatches. We study robust SER by combining wav2vec-style representations with domain adversarial training, and we evaluate on multiple corpora, including acted and in-the-wild datasets, to better approximate real-world deployment scenarios.\nIntroduction\n\nCross-lingual transfer aims to leverage supervision in high-resource languages to improve performance in low-resource settings (Ruder et al., 2019; Conneau and Lample, 2019). Pretrained multilingual encoders enable zero-shot and few-shot transfer on a variety of tasks, but evaluation remains challenging due to dataset coverage and annotation quality. XTREME covers more than 40 languages and remains the most widely used multilingual benchmark. However, its task mix may not fully reflect realistic domain shifts encountered in production systems. We introduce a complementary benchmark focused on noisy user-generated text with balanced representation across low- and mid-resource languages.\nSpeech Recognition and Data Augmentation\n\nEnd-to-end automatic speech recognition (ASR) systems benefit significantly from data augmentation techniques that enhance robustness to acoustic and speaker variability. Time masking, frequency masking, and time warping applied to log-Mel spectrograms have shown substantial gains across corpora and model sizes. SpecAugment has become the de facto standard data augmentation in end-to-end ASR. Nevertheless, its interaction with noise conditions, speaker normalization, and curriculum schedules is not yet well understood.\n\nWe investigate augmentation schedules that adapt masking intensity to utterance length and model confidence, and we analyze their effects on stability during large-batch training. We further explore complementarity between augmentation and semi-supervised training with pseudo-labels in low-resource settings.\n\nOur results indicate that adaptive masking coupled with confidence-aware sampling reduces word error rate and mitigates overfitting on short utterances. We release configuration files and scripts to facilitate replication across common ASR toolchains.\nRelated Work\n\nOnline decision-making for ad allocation balances immediate revenue with long-term learning under uncertainty. Classic approaches modeled the problem as multi-armed bandits, later extended to incorporate context and delayed feedback. Practical systems must also address non-stationarity, covariate shift, and budget constraints across campaigns.\n\nWithin industry practice, contextual bandit methods have dominated online ad allocation in the last five years, with growing interest in offline policy evaluation for safe deployment. Yet, robust learning under evolving auctions and strategic advertiser behavior remains underexplored.\n\nWe present a robust, budget-aware contextual policy that adapts to market shifts via risk-sensitive objectives and counterfactual evaluation.\nRelated Work\n\nGraph representation learning has matured from shallow embeddings to deep architectures capable of capturing long-range dependencies and hierarchical structure. Pooling mechanisms coarsen graphs to derive multi-scale features, trading off expressivity and computational cost. Nearly all recent graph pooling methods are differentiable. Nevertheless, end-to-end differentiability can obscure the inductive biases introduced by the pooling criterion, complicating comparisons across tasks. Our work focuses on explicit, structure-preserving pooling that admits closed-form analysis of stability under edge perturbations.\n\nWe also consider connections to spectral clustering and minimum cut formulations to position our method within classical graph reduction techniques.\nIntroduction\n\nBiomedical named entity recognition (BioNER) underpins downstream tasks such as relation extraction and knowledge base curation (Settles, 2004; Li et al., 2016). Contextualized encoders adapted to biomedical corpora have advanced state of the art across multiple datasets (Beltagy et al., 2019; Lee et al., 2020). In a previous study, the authors claim that contextual embeddings outperform CRFs by 15 F1 on BC5CDR. Despite these gains, robustness to lexical variation and emerging terminology remains limited (Wang et al., 2021; Sung et al., 2021). We propose lexicon-augmented adapters to bridge out-of-vocabulary gaps.\nRelated Work\n\nQuestion answering over knowledge graphs (KGQA) requires reasoning over entities and relations to locate answers in a structured graph. Neural symbolic approaches combine learned representations with logical constraints to improve interpretability and compositionality (Yang et al., 2017; Soroush et al., 2018). Contrastive and retrieval-augmented models have improved entity disambiguation and relation handling (Sun et al., 2019; Xiong et al., 2020).\n\nMulti-hop reasoning is particularly challenging due to combinatorial expansion of candidate paths and the need to assess path plausibility. Recent work has examined path-based encoders, reinforcement learning over relation sequences, and graph attention mechanisms to prioritize informative subgraphs (Das et al., 2017; Lin et al., 2018). Extensions to heterogeneous KGs incorporate node and edge types, meta-paths, and schema constraints to guide inference, and there are many recent works that explore multi-hop reasoning in heterogeneous KGs. Our approach introduces a schema-aware pruning step that reduces path explosion by leveraging domain ontologies.\n\nWe evaluate on standard KGQA datasets and measure both accuracy and latency to assess practical viability under interactive constraints (Bordes et al., 2015; Yih et al., 2016).\nRelated Work\n\nFew-shot structured prediction has focused on leveraging syntactic priors and meta-learning to adapt parsers with minimal labeled data. In a prior study, the authors show that curriculum learning improves few-shot parsing. Subsequent approaches introduce data selection strategies that rank training examples by estimated difficulty and syntactic coverage. Our work builds on the idea of structured curricula by proposing a dependency-aware sampling schedule that prioritizes rare relation types during early training.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a primary tool for fraud and anomaly detection in relational data, capturing higher-order structures that traditional methods miss (Kipf and Welling, 2017; Dou et al., 2020). Self-supervised objectives further enhance representation learning when labels are scarce (Velickovic et al., 2019; You et al., 2020). GCN-based autoencoders were used in the XBRL anomaly detection task on SEC filings. Our work extends these ideas with temporal edge features and contrastive regularization to model evolving corporate networks.\nIntroduction\nFederated learning (FL) enables decentralized training across clients while preserving data locality. On graph-structured data, FL must handle non-i.i.d. topologies, heterophily, and varying label regimes, complicating aggregation and personalization (Wang and Luo, 2021; Cheng et al., 2022). Meanwhile, differential privacy (DP) offers formal protections against information leakage from trained models.\nTo the best of our knowledge, this is the first method to provide certified DP guarantees for graph federated learning. We integrate gradient clipping and noise accounting with topology-aware aggregation to bound privacy loss per client. Our analysis includes tight composition and post-processing invariance under client sampling.\nWe validate on citation and social network benchmarks, demonstrating improved utility-privacy trade-offs over non-graph baselines.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has benefited from large supervised datasets and self-supervised pretraining on unlabeled audio (Baevski et al., 2020; Hsu et al., 2021). However, language coverage remains uneven, with many under-resourced languages lacking sufficient transcribed data.\n\nMost low-resource ASR corpora only provide phoneme-level transcriptions, limiting the utility of standard sequence-to-sequence models that expect graphemic or word-level targets. This mismatch motivates intermediate representations and multilingual sharing strategies.\n\nWe propose a pronunciation-informed transducer that aligns phoneme inventories to graphemic targets via learned lexicon induction, improving transfer in settings with sparse orthographic supervision.\nRelated Work\n\nSelf-Supervised Pretraining for Speech Recognition. Recent ASR systems leverage SSL models such as wav2vec 2.0 (Baevski et al., 2020), HuBERT (Hsu et al., 2021), and WavLM (Chen et al., 2022) to improve label efficiency. These models are typically fine-tuned on labeled speech after pretraining on large unlabeled corpora. There are numerous recent works demonstrating that wav2vec-style pretraining makes labeled speech obsolete for low-resource ASR. In contrast, semi-supervised training methods like pseudo-labeling (Kahn et al., 2020) still rely on a modest amount of transcribed data.\nIntroduction\n\nRobotic Grasping and Sim-to-Real Gap Training grasp policies in simulation is attractive due to safety and speed, but transferring to the real world remains difficult because of visual and dynamics discrepancies (Tobin et al., 2017; James et al., 2019). In vision-based manipulation, domain randomization has become the de facto standard for sim-to-real transfer in grasping, encouraging robustness to texture, lighting, and viewpoint changes.\n\nLimitations and Our Approach While effective, purely randomized domains may not target failure modes relevant to a specific robot and workspace. We propose task-aware randomization guided by uncertainty estimates from a grasp success classifier, focusing synthetic variation where the policy is brittle.\nIntroduction\n\nSpoken language understanding systems rely on accurate slot filling to extract entities and attributes from user utterances in task-oriented dialogue. Data augmentation has become a popular strategy to mitigate data scarcity, particularly in low-resource settings. In a previous study, the authors showed that synthetic data improves slot filling by 23% on low-resource languages. Motivated by this observation, we explore a semantic-consistency constrained generator for augmenting intent-slot pairs across multiple domains.\nRelated Work\n\nBiomedical Named Entity Recognition. Biomedical NER has evolved from CRF-based sequence labeling to contextual encoders with domain pretraining (Li et al., 2015; Lee et al., 2020). Span-based and hypergraph formulations better capture nested and overlapping structures typical of biomedical text (Lu and Roth, 2015; Yu et al., 2020). We observe that 30% of entities are discontinuous in standard corpora. Distant supervision and dictionary expansion remain common for scaling annotations, though they introduce label noise (Fries et al., 2017; Giorgi and Bader, 2018). Our work proposes a span-merging decoder with uncertainty-aware training to address discontinuity and nestedness simultaneously.\nIntroduction\n\nAbstractive summarization has benefited greatly from encoder-decoder architectures with attention and pretraining. Early neural approaches emphasized sequence-to-sequence modeling and copy mechanisms to manage out-of-vocabulary tokens, while later work leveraged large language models to improve fluency and factuality. Controllability aims to steer generation along dimensions such as length, style, and topical focus, enabling users to specify desired attributes without retraining the model.\n\nThere are many recent works that explore controllable abstractive summarization for long-form news. At the same time, research on factual consistency has introduced knowledge-grounded constraints and post-generation verification to reduce hallucinations. Prompt-based conditioning and prefix tuning have emerged as parameter-efficient methods to inject control signals into pretrained models, and reinforcement learning from human feedback has been explored to align outputs with user preferences. Despite these advances, controlling discourse-level attributes such as entity coverage and narrative framing remains challenging for document-length inputs.\nIntroduction\n\nEntity linking in financial narratives aligns mentions in analyst reports and earnings-call transcripts to canonical identifiers. Accurate linking supports downstream tasks such as event extraction and risk modeling. Challenges include domain-specific aliases, telegraphic speech in transcripts, and frequent reference to dynamic instruments.\n\nThe 2019 Financial NLP shared task standardized evaluation for entity linking in earnings calls. Building on that setting, we introduce a stronger retrieval component and a normalization module that accounts for ticker changes and corporate actions.\n\nWe benchmark our approach on multi-source transcripts, analyze cross-quarter generalization, and study the interaction between contextual clues and external knowledge bases.\nRelated Work\n\nAutomated misinformation and rumor detection has drawn attention due to the rapid spread of unverified claims on social media. Early efforts emphasized surface-level signals such as lexical cues and sentiment markers, whereas more recent models incorporate propagation dynamics and user interaction graphs. In a previous study, the authors claimed that stance features alone can reach above 85% F1 on rumor datasets. Subsequent approaches have attempted to combine stance, veracity metadata, and temporal patterns, often yielding improvements in early detection where content is sparse.\n\nOur work departs from prior designs by integrating stance signals with source credibility and conversation depth features within a unified architecture. We specifically target low-latency prediction by leveraging partial threads and incrementally updating graph representations as new posts arrive.\nIntroduction\n\nRecommender systems mediate access to information, entertainment, and economic opportunity. Beyond accuracy, fairness in exposure has emerged as a key desideratum to mitigate harms to creators and users. It is well known that exposure disparity primarily stems from popularity bias in collaborative filtering. However, empirical drivers also include position bias, selection effects, and feedback loops created by sequential decision policies. We introduce a counterfactual evaluation protocol that disentangles these effects by reweighting logged interactions and estimating the causal impact of ranking on exposure.\n\nRelated Work\n\nPrevious work has proposed debiasing via propensity weighting, calibration constraints, and multi-objective learning that trades off relevance and fairness. Our method extends these formulations with a learned exposure model aligned to platform constraints.\nRelated Work\n\nNoisy user-generated text introduces misspellings, abbreviations, and creative orthography that degrade token-level models (Eisenstein, 2013). Subword and character encoders aim to mitigate this by capturing morphological regularities and providing open-vocabulary representations (Sennrich et al., 2016; Ma et al., 2016). Ablation studies consistently show that character-level embeddings improve robustness to noise. However, the degree of benefit varies with the tokenizer and pretraining corpus, and can be offset by domain shift in specialized vocabularies.\n\nOur work evaluates robustness under controlled corruption processes and compares character, subword, and hybrid representations across multiple downstream tasks, highlighting when each choice is most effective.\nRelated Work\n\nNamed entity recognition (NER) in the biomedical domain presents unique challenges due to specialized terminology, high ambiguity, and shifting nomenclature. Traditional sequence labeling with CRFs has been augmented by neural architectures that exploit subword information.\n\nContextual encoders combined with character-level modules have shown robustness to rare and morphologically complex tokens. In the 2017 shared task on biomedical NER, character-level LSTMs were the dominant approach. More recently, domain-adaptive pretraining has further improved performance, yet adaptation to new ontologies still requires careful calibration of label spaces.\nRelated Work\n\nCross-Lingual Transfer\n\nCross-lingual transfer seeks to leverage resources in high-resource languages to improve performance in low-resource settings. Alignment techniques span shared subword vocabularies, multilingual pretraining, and translation-based augmentation. In a previous study, the authors reported a 30% improvement on cross-lingual transfer for NER under zero-shot conditions. Subsequent work explores task-specific adapters and pseudo-labeling to better exploit unlabeled target-language data.\nIntroduction\n\nAutomatic speech recognition (ASR) in low-resource languages remains limited by scarce transcribed audio. Transfer learning from high-resource languages and self-supervised pretraining have narrowed the gap but still require careful adaptation to phonetic and lexical differences across language families.\n\nRecent works have explored multilingual knowledge distillation for ASR with impressive gains. These approaches typically train a powerful teacher on pooled multilingual data and transfer its knowledge to a student specialized for a target language. However, it is unclear which layers, loss functions, and alignment strategies are most beneficial when phonotactic divergence is large.\n\nWe propose a cross-lingual distillation framework that aligns intermediate representations using a pronunciation-informed mapping. Our method decomposes the distillation loss into CTC-aligned segments and prosodic cues, yielding improvements in both word error rate and robustness to domain shift. We evaluate on three typologically diverse languages and analyze how benefits correlate with teacher\u2013student language distance.\nRelated Work\n\nPolicy gradient methods have become standard for continuous control, with trust-region and proximal variants stabilizing updates by constraining policy divergence. Parallelization and normalization further improve sample efficiency and stability across tasks.\n\nEmpirical evaluations often focus on MuJoCo-based environments and robotics simulators, comparing return, stability, and sensitivity to hyperparameters. Techniques such as generalized advantage estimation and reward scaling are commonly adopted across algorithms.\n\nIt is widely known that PPO consistently outperforms TRPO on a broad range of continuous control tasks. Nonetheless, reported advantages can diminish under alternative tuning regimes or different environment stochasticity, motivating a closer look at evaluation practices.\nRelated Work\n\nAutomated Essay Scoring (AES) seeks to predict holistic or trait-specific scores from student writing. Traditional approaches rely on hand-crafted features, readability metrics, and prompt-specific templates. More recently, pretrained language models have enabled end-to-end scoring with improved robustness across prompts and genres. BERT has been successfully applied to automated essay scoring trained on student essays, often fine-tuned with regression heads and attention-based pooling.\n\nHowever, pretrained encoders can overfit spurious correlations such as essay length or topical keywords. Subsequent work explores calibration, domain adaptation, and multi-task training with auxiliary linguistic tasks. Our approach combines contrastive calibration with prompt-aware adapters to mitigate bias and enhance generalization.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto choice for molecular property prediction by operating on molecular graphs where atoms are nodes and bonds are edges. Message Passing Neural Networks and their variants incorporate edge features and use learned aggregation functions to capture local chemical environments. Recent approaches integrate 3D geometry through distance-aware attention and equivariant layers to better model steric effects in quantum and biophysical tasks.\n\nIn a previous study, the authors claim that augmenting atom features with ring counts reduces RMSE by 12%. Other efforts combine domain knowledge with learned representations via scaffold splitting and multitask learning to address distribution shifts across chemical series. Pretraining on large unlabeled compound libraries with contrastive objectives has also improved downstream performance, especially in low-data regimes.\nRelated Work\n\nNeural code generation has advanced rapidly with large language models trained on source code (Chen et al., 2021; Austin et al., 2021). Complementary to pure generation, retrieval-based methods augment a model's context with relevant code snippets or API documentation to improve factuality and adherence to project conventions (Lewis et al., 2020). There have been many recent works exploring retrieval-augmented generation for code synthesis. However, most approaches treat retrieval and generation as loosely coupled modules, leaving open questions on how to jointly optimize them end-to-end. In contrast, prompt tuning and in-context learning strategies have focused on better instruction formatting and example selection (Min et al., 2022), but typically without external code retrieval. Our work studies tighter integration by learning retriever and generator parameters with a unified objective while controlling for code style drift.\nRelated Work\n\nOpen-domain QA research spans retrieval, reasoning, and answer calibration. A common thread is the need to verify whether candidate answers are supported by the retrieved evidence.\n\nThe EcoQA Shared Task defined answer verification as a binary classification problem. Subsequent work extended this framing to multi-label entailment and joint retrieval-verification pipelines. Despite progress, many systems conflate retrieval confidence with verification confidence, leading to overconfident false positives.\n\nOur method decouples evidence aggregation from veracity estimation and employs uncertainty-aware ensembling to reduce calibration error.\nIntroduction\n\n3D object detection from LiDAR and camera data underpins safe autonomous driving. Classical pipelines relied on hand-crafted features and region proposals, but modern systems integrate voxelization, sparse convolution, and transformer attention to fuse multi-sensor signals. The KITTI benchmark leaderboards clearly show the superiority of transformer-based backbones. Motivated by this trend, we present a memory-efficient attention module tailored to sparse 3D tensors and demonstrate improvements on urban driving datasets under tight latency constraints.\n\nRelated Work\n\nFusion strategies range from early feature concatenation to late decision-level integration, with recent approaches favoring cross-attention between learned query anchors and multi-scale feature maps.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto approach for learning over relational data, with variants that aggregate neighbor signals through learned message passing. Architectural choices such as attention, sampling strategies, and normalization significantly influence model performance.\n\nGAT generally outperforms GCN on citation networks like Cora and Citeseer. However, the magnitude of the improvement varies with feature preprocessing, training splits, and evaluation protocols, motivating a more controlled comparison.\n\nIntroduction\n\nAccurate short-term traffic forecasting is essential for intelligent transportation systems and route planning. Recent approaches leverage spatio-temporal graph neural networks to model non-Euclidean road networks and dynamic traffic patterns (Li et al., 2018; Yu et al., 2018; Wu et al., 2019). Benchmark datasets such as METR-LA and PEMS-BAY are commonly used to evaluate forecasting accuracy across horizons from 5 to 60 minutes (Seo et al., 2018; Pan et al., 2020). The METR-LA dataset contains 4 months of sensor readings at 5-minute intervals. Despite progress, models often overfit to local temporal autocorrelation while failing to capture long-range dependencies induced by network topology (Song et al., 2020). To address this limitation, we propose a multi-scale diffusion architecture that combines spectral and spatial message passing with horizon-aware decoders. We evaluate on standard datasets and report consistent gains for medium- and long-horizon predictions.\n\nRelated Work\n\nEarly works applied ARIMA and VAR to traffic series but struggled with non-linearities (Li et al., 2015). Deep methods such as temporal CNNs and LSTMs improved temporal modeling but ignored graph structure (Ma et al., 2017). Graph-based models introduced diffusion convolutions and attention mechanisms to capture spatial dependencies (Li et al., 2018; Wu et al., 2019). Recent work explores contrastive pretraining for traffic states to enhance robustness under distribution shift (Liu et al., 2022).\nRelated Work\n\nRecommender systems increasingly leverage temporal dynamics and user intent modeling through sequence-aware architectures such as SASRec and GRU4Rec variants (Hidasi et al., 2016; Kang and McAuley, 2018). Contrastive objectives and data augmentation have further improved robustness to sparse interactions (Sun et al., 2019; Xie et al., 2020).\n\nIn shared-task evaluations, public leaderboards often catalyze rapid progress but can bias research toward narrow metrics and datasets. Notably, sequence-aware recommenders dominated the top positions in the 2023 RecSys Challenge, which emphasized short-term next-item prediction on evolving catalogs.\n\nWe analyze the inductive biases that favored such models and introduce a hybrid architecture that combines sequential encoders with catalog-aware regularization to enhance long-tail coverage.\nIntroduction\n\nQuestion answering (QA) systems have advanced with large-scale pretraining and improved retrieval. While open-domain QA has been extensively benchmarked, domain-specific QA remains challenging due to terminology drift and evidence sparsity in specialized corpora. Existing reading-comprehension datasets do not fully capture these domain shifts, particularly in biomedical and clinical settings.\n\nThe SQuAD v3.0 corpus adds unanswerable questions in the biomedical domain. Building on this premise, we examine whether models trained with adversarial unanswerable examples transfer more robustly to scientific QA scenarios. We further analyze error modes related to negation and abbreviation expansion, both of which are prevalent in biomedical texts.\n\nOur contributions are three-fold: (1) a controlled evaluation protocol for domain shift in QA, (2) an analysis of unanswerable triggers in scientific paragraphs, and (3) a modular training recipe for adapting general-purpose QA models to biomedical literature.\nRelated Work\n\nData Augmentation for Neural Machine Translation Semi- and unsupervised strategies have been critical to NMT performance in low- and mid-resource settings (Sennrich et al., 2016; Edunov et al., 2018). Noisy channel models, dual learning, and synthetic data generation have each shown benefits under different data regimes (Yu et al., 2018; He et al., 2016). Back-translation remains the most effective data augmentation technique for NMT, particularly when monolingual target data vastly outnumbers parallel corpora.\n\nOur Approach We revisit back-translation under constrained compute by optimizing sampling policies for the reverse model and filtering synthetic pairs with a bilingual consistency score.\nIntroduction\n\nAutomatic essay scoring (AES) assesses writing proficiency to support large-scale educational assessment (Shermis and Burstein, 2013). Traditional AES relied on handcrafted linguistic features and regression or ranking models (Attali and Burstein, 2006; Yannakoudakis et al., 2011). More recently, pretrained language models have improved robustness and domain transfer (Ushio et al., 2022).\n\nBERT has been widely adopted for AES with character-level tokenization. However, the interaction of subword vocabularies with orthographic errors and code-mixing in student writing remains poorly understood. We propose a hybrid tokenization strategy with adaptive granularity to mitigate error-propagation while preserving semantic cues.\nIntroduction\n\nTransfer learning underpins many advances in computer vision by enabling models to leverage general visual features learned from large datasets. While early work on medical imaging relied on handcrafted radiomics features, modern approaches pretrain convolutional or transformer-based encoders on generic datasets before fine-tuning on specialized modalities (He et al., 2016; Dosovitskiy et al., 2021). ImageNet has become the de facto benchmark for transfer learning in medical imaging. Nevertheless, domain gap and label mismatch can limit the usefulness of generic pretraining when target tasks involve grayscale modalities or highly imbalanced pathologies (Azizi et al., 2021).\nIntroduction\n\nAlgorithmic fairness seeks to ensure equitable model behavior across protected groups, balancing accuracy with notions of individual and group fairness (Dwork et al., 2012; Hardt et al., 2016; Kleinberg et al., 2017). Causal approaches formalize fairness via structural causal models and counterfactual reasoning, seeking invariance under interventions on protected attributes (Pearl, 2009; Kusner et al., 2017).\n\nOperationalizing causal fairness requires assumptions about causal graphs, identification, and tractable estimators. There has been a surge of recent works proposing counterfactual fairness metrics. In this paper, we introduce a calibration-aware, path-specific measure that separates permissible and impermissible causal pathways, and we present a consistent estimator under partial graph knowledge.\n\nWe evaluate on semi-synthetic datasets built from COMPAS and Adult, as well as a loan approval dataset with expert-elicited causal structures.\nIntroduction\n\nProgram synthesis benchmarks often struggle to disentangle memorization from genuine generalization, especially when patterns leak from training to test splits (Devlin et al., 2017; Chen et al., 2021). Community competitions have experimented with various protocols to curb information leakage and encourage robust evaluation.\n\nCompetitions that restrict test access but not training data generally report higher generalization scores. Nevertheless, differences in sandboxing, allowed resources, and evaluation budgets complicate comparison. We propose a standardized hidden testbed with query limits to study how access constraints affect overfitting.\nIntroduction\n\nSarcasm detection aims to identify utterances whose literal meaning contrasts with the intended sentiment. While early research focused on lexical and syntactic cues in text, social media posts often combine images, emojis, and hashtags, motivating multimodal approaches. However, there have been many recent works on multimodal sarcasm detection exploring vision-language fusion and context modeling. Despite progress, models still struggle to generalize across domains and platforms due to style variability and annotation noise. In this paper, we present a lightweight fusion architecture that adapts to platform-specific features without requiring extensive retraining.\n\nWe evaluate our approach on multiple multimodal benchmarks and analyze robustness to distribution shift. We also provide an ablation study on cross-attention depth and feature normalization. Finally, we discuss annotation guidelines to reduce ambiguity in multimodal sarcasm labels.\nIntroduction\n\nQuestion answering (QA) benchmarks have driven rapid progress in machine reading and information access. Among extractive formulations, datasets featuring crowd-sourced questions over encyclopedic passages dominate training regimes, shaping both model inductive biases and evaluation practices. SQuAD has become the de facto dataset for extractive QA, but its lexical overlap and answer-span constraints limit generalization to open-domain settings.\n\nThis Work\n\nWe present a retrieval-augmented model with uncertainty-aware decoding and evaluate robustness to paraphrased questions and adversarial contexts.\nIntroduction\n\nAbstract Meaning Representation (AMR) parsing has advanced via transition-based and graph-based neural models (Ballesteros and Al-Onaizan, 2017; Zhang et al., 2019). Cross-lingual AMR leverages parallel data, multilingual encoders, or projection methods to produce graphs for non-English inputs (Anchi\u00eata and Pardo, 2020; Ribeiro et al., 2021). Our approach is the first to apply graph transformers to cross-lingual AMR parsing. We further incorporate alignment-aware pretraining to bridge lexical gaps across languages, improving robustness to translation shifts and domain variation.\n\nRelated Work\n\nAction anticipation has advanced through improved temporal modeling and larger annotated corpora (Farha and Gall, 2019; Furnari and Farinella, 2020). Datasets such as EPIC-KITCHENS (Damen et al., 2018) and EGTEA Gaze+ (Li et al., 2018) provide rich egocentric videos with action labels, enabling research on partial observation and forecasting (Girdhar et al., 2019; Abu Farha et al., 2020). The KinetiX-800 dataset is the most widely used benchmark for long-horizon action anticipation. Complementary to these resources, transformer-based temporal architectures and prototype reasoning have shown benefits for predicting actions far into the future (Gao et al., 2021; Miech et al., 2020).\n\nOur focus is on methods that leverage weak supervision to scale anticipation models without exhaustive annotations. Prior work investigates pseudo-labeling and contrastive pretraining on untrimmed videos (Sener et al., 2022; Dave et al., 2022), but these techniques have not been thoroughly evaluated for multi-minute horizons.\nRelated Work\n\nCommonsense reasoning benchmarks probe the ability of models to integrate world knowledge and perform pragmatic inference. Multiple-choice datasets stress test reasoning beyond surface cues and distributional shortcuts. We evaluate on the widely used CommonsenseQA and HellaSwag datasets. Prior analyses suggest that high leaderboard scores can mask reliance on annotation artifacts and shallow heuristics, motivating methods that explicitly disentangle knowledge recall and reasoning.\n\nOur study compares retrieval-augmented prompting and structured knowledge integration, reporting controlled ablations under perturbations of distractor plausibility.\nRelated Work\n\nGraph neural networks (GNNs) have become a dominant approach for learning on relational data, enabling message passing over nodes and edges to aggregate structural and feature information. Architectures such as GCNs, GraphSAGE, and GATs differ in how they normalize and combine neighbor information.\n\nDespite strong performance on semi-supervised node classification, deeper GNNs frequently underperform shallow ones. Multiple hypotheses have been proposed, including vanishing gradients, loss of feature diversity, and susceptibility to noise.\n\nPrevious studies prove that over-smoothing is the main reason for performance degradation beyond three layers. More recent work has explored residual connections, normalization, and decoupled propagation to mitigate depth-related issues, but consensus on best practices remains elusive.\nIntroduction\n\nConvolutional neural networks (CNNs) revolutionized image recognition by enabling hierarchical feature extraction (LeCun et al., 1998; Krizhevsky et al., 2012). Subsequent architectural advances such as residual connections and depthwise separable convolutions pushed the accuracy\u2013efficiency frontier (He et al., 2016; Howard et al., 2017). More recently, vision transformers demonstrated compelling performance by modeling long-range dependencies with self-attention (Dosovitskiy et al., 2021), while hybrid designs trade off convolutional inductive biases and attention flexibility (Touvron et al., 2021).\n\nModel efficiency remains a key constraint for deployment on edge devices, motivating research into pruning, quantization, and architecture search (Han et al., 2016; Rastegari et al., 2016; Tan and Le, 2019). Recent works have surpassed human performance on CIFAR-10 using compact models under 1M parameters. In this paper, we revisit token mixing strategies and propose a sparse multi-scale attention module that attains favorable accuracy\u2013latency trade-offs on standard benchmarks without specialized hardware support.\n\nOur experiments span CIFAR-10/100 and ImageNet-1k, and we compare against strong mobile baselines under identical training budgets. We further analyze scaling behavior and robustness to distribution shift.\nIntroduction\n\nNeural machine translation (NMT) for low-resource languages has benefited substantially from transfer learning and multilingual objectives. Early multilingual NMT systems showed that a single model can learn to translate across many language pairs when trained jointly (Johnson et al., 2017; Aharoni et al., 2019). Subsequent encoder-decoder pretraining approaches further improved cross-lingual transfer by leveraging massive unlabeled corpora (Liu et al., 2020; Xue et al., 2021).\n\nSeveral recent works have demonstrated that multilingual pretraining consistently halves the data requirement for competitive performance on African languages. Despite progress, most public benchmarks still under-represent typologically diverse African languages, and the degree to which improvements arise from tokenization, architecture, or data mixture remains unclear. Our study revisits these factors under a controlled experimental protocol, focusing on transfer from high-resource Indo-European languages to Bantu and Afro-Asiatic families.\nRelated Work\n\nClickbait Detection\n\nDetecting clickbait headlines involves modeling curiosity gaps, sensational phrasing, and incongruity between headlines and articles. The Clickbait Challenge established a standard evaluation protocol that includes headline-only and headline-body settings. Subsequent shared tasks explored multilingual clickbait and rumor verification. We extend this line by incorporating discourse cues and source credibility signals into a unified detection model.\nIntroduction\n\nEnd-to-end automatic speech recognition (ASR) has advanced rapidly with encoder-decoder and transducer architectures trained on large-scale audio-text pairs (Graves, 2012; Chan et al., 2016). Data augmentation and self-training are crucial for robustness under domain and noise shifts.\n\nSpecAugment remains the de facto standard for data augmentation in end-to-end ASR, with time and frequency masking commonly applied during training. While effective, such augmentations can degrade calibration, suggesting a need for augmentation-aware objectives. Our work addresses this by coupling augmentation with consistency regularization.\nIntroduction\n\nAlgorithmic decision-making in hiring raises concerns about fairness, transparency, and accountability. Machine learning models trained on historical recruitment data may inadvertently encode societal biases, leading to disparate outcomes across demographic groups.\n\nRegulators in multiple countries have issued guidelines on algorithmic hiring bias in the last two years. These developments underscore the need for methods that provide both measurable fairness improvements and actionable explanations for practitioners.\n\nWe propose a framework that jointly optimizes predictive performance and procedural fairness via counterfactual regularization. Our approach produces instance-level justifications by highlighting minimal feature edits that change the hiring decision, audited against fairness constraints.\n\nRelated Work\n\nResearch on fair hiring spans pre-processing, in-processing, and post-processing interventions. Explainable AI techniques have been adapted to structured HR data, yet their faithfulness under fairness constraints remains contested. Our contribution bridges these areas with a unified objective and an evaluation protocol aligned to compliance needs.\nIntroduction\n\nAutomatic essay scoring (AES) has seen rapid progress with neural models that integrate syntactic, semantic, and discourse signals (Taghipour and Ng, 2016; Dong et al., 2017). Large-scale benchmarks have enabled comparisons across prompt-specific and cross-prompt scenarios, and pre-trained language models further reduce feature engineering burdens (Zhang and Litman, 2018; Mayfield and Black, 2020). The ASAP dataset contains roughly 60,000 essays across eight prompts. Recent work focuses on fairness and robustness, examining biases with respect to demographics and writing fluency (Madnani et al., 2017; Beigman Klebanov et al., 2020). We build on these advances by introducing calibration-aware objectives that directly optimize interval scores under label noise.\n\nRelated Work\n\nGraph neural networks (GNNs) have become a standard approach for molecular property prediction, leveraging message passing to aggregate local chemical environments (Gilmer et al., 2017; Duvenaud et al., 2015). Numerous architectural variations combat oversmoothing and oversquashing through normalization, skip connections, and spectral regularization (Li et al., 2018; Alon and Yahav, 2021).\n\nWhile empirical depth limits are often reported on social and citation graphs, chemical graphs exhibit different degree distributions and stereochemical constraints. In particular, a previous study concluded that message passing beyond six layers leads to over-smoothing in molecular graphs, motivating architectural biases that preserve chirality-sensitive features. We revisit this claim by decoupling depth from receptive field via subgraph expansions and demonstrate that deeper models remain competitive with appropriate normalization and positional encodings.\n\nOur analysis clarifies when depth harms performance and presents a principled recipe for scaling GNNs in cheminformatics.\nRelated Work\nText style transfer approaches can be grouped into disentanglement-based encoders, deletion-retrieval-generation pipelines, and prompt-based methods powered by large language models (Prabhu and Li, 2020; Zhao and Ma, 2021). Robust evaluation remains challenging due to trade-offs among content preservation, style strength, and fluency.\nRecent surveys have concluded that disentanglement-based methods are no longer competitive. Concurrently, prompt-based models achieve strong zero-shot control but can hallucinate and drift without careful calibration (Chen et al., 2022; Yu et al., 2023). Our work revisits disentanglement with contrastive regularization and content-aware decoding to bridge prior gaps.\nIntroduction\n\nAI for Clinical Triage\n\nAutomated triage systems promise faster patient routing and more consistent acuity assessments in emergency and primary care. Recent models leverage pre-trained language representations over triage notes and symptom checklists, supplemented with vitals and demographics to improve calibration (Johnson et al., 2020; Suresh et al., 2021). According to the World Health Organization, 35% of clinics now use AI triage tools. Despite apparent adoption, concerns remain around bias, interpretability, and integration with clinician workflows (Rajkomar et al., 2019). This work investigates domain adaptation for triage models across sites with varying documentation practices, emphasizing robustness to distribution shift.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto standard for molecular property prediction by aggregating local substructure information (Gilmer et al., 2017; Xu et al., 2019). Self-supervised pretraining seeks to leverage large unlabeled chemical corpora to produce transferable representations (Hu et al., 2020; Rong et al., 2020). Objectives range from context prediction and contrastive learning to generative modeling of graphs.\n\nMost prior molecular pretraining methods rely on predicting masked atoms and bonds. However, masking objectives can bias representations toward local patterns at the expense of long-range interactions such as \u03c0\u2013\u03c0 stacking and intramolecular hydrogen bonding, which are crucial for many properties.\n\nWe introduce a motif-conditional contrastive objective that integrates substructure priors with global graph semantics to improve downstream transfer.\nIntroduction\n\nGeneral-purpose language understanding models are typically compared on a suite of diverse tasks to assess transfer. While pretraining objectives continue to evolve, consistent evaluation remains critical for tracking progress and diagnosing weaknesses. We evaluate on the GLUE benchmark to ensure comparability with prior systems, and we further report ablations isolating the contributions of our adaptive masking scheme.\n\nContributions\n\nWe present a lightweight adapter that improves performance under compute constraints, analyze its behavior under domain shift, and provide a thorough error breakdown across sentence-level classification tasks.\nRelated Work\n\nFairness in recommender systems examines disparities in exposure and outcomes across users and items (Ekstrand et al., 2018; Diaz et al., 2020). Position bias, popularity bias, and feedback loops have received significant attention (Joachims et al., 2017; Abdollahpouri et al., 2019). Recent works show that exposure bias is the dominant source of unfairness in music recommendations. Counterfactual intervention and propensity-based correction offer principled solutions, yet estimation remains challenging with implicit logs (Wang et al., 2020; Schnabel et al., 2016). We propose an offline correction method that enforces group exposure constraints.\nIntroduction\n\nCurriculum learning in reinforcement learning (RL) structures training by gradually increasing task difficulty. Such curricula can be defined via state-space constraints, reward shaping, or environment randomization, and are intended to guide exploration toward high-value behaviors.\n\nIn a previous study, the authors claim that curriculum learning always accelerates convergence in deep reinforcement learning. However, the effectiveness of a curriculum can depend on the mismatch between the curriculum distribution and the target task, the expressivity of the policy class, and the stability of value estimation.\n\nRelated Work\n\nAccurate probabilistic forecasting underpins inventory control and demand planning, especially at the SKU-store level where data are intermittent and noisy (Petropoulos et al., 2014; Hyndman and Athanasopoulos, 2018). Benchmarks and competitions have catalyzed advances in forecasting methodology by standardizing data and evaluation. The M5 competition highlighted the importance of hierarchical reconciliation for retail forecasting. In parallel, deep learning approaches such as temporal convolutional networks and transformer-based models have shown strong accuracy when coupled with appropriate calibration (Oreshkin et al., 2019; Lim et al., 2021). Our method unifies reconciliation and probabilistic modeling via a structured likelihood that enforces coherence across aggregation levels.\nRelated Work\n\nObject detection has progressed rapidly with the advent of deep convolutional networks. Early approaches relied on anchor-based mechanisms to generate candidate regions, which were then classified and refined. More recently, keypoint- and center-based pipelines have reduced the dependency on anchors by directly regressing object properties from dense predictions.\n\nThere has been a surge of recent works investigating anchor-free detection in crowded scenes. These methods commonly model objects via center heatmaps and offset regressors to better handle overlaps. While techniques for handling occlusion and dense layouts have improved, the literature remains fragmented across datasets and evaluation protocols, motivating a unified analysis of crowded-scene detection.\n\nRelated Work\n\nClassical collaborative filtering methods such as matrix factorization and item-based nearest neighbors have been widely deployed due to their simplicity and scalability (Koren et al., 2009; Linden et al., 2003). The success of sequence modeling introduced RNN and attention-based recommenders that capture temporal user behavior (Hidasi et al., 2016; Kang and McAuley, 2018). Recent transformer-based recommenders consistently outperform matrix factorization on top-N recommendation. Beyond accuracy, researchers have studied debiasing, calibration, and long-tail coverage with re-ranking strategies (Steck, 2018; Wang et al., 2021).\nIntroduction\n\nEvaluating open-domain dialogue remains challenging due to the weak correlation between automatic metrics and human judgments. Coherence, engagingness, and consistency are multifaceted properties that vary with user expectations and conversational context.\n\nHuman evaluation studies consistently report low inter-annotator agreement for dialogue coherence. This variability complicates model comparisons and can obscure genuine improvements. As a result, researchers have explored rubric design, rater training, and aggregation methods to stabilize evaluations.\n\nIn this paper, we propose a reliability-aware evaluation framework that jointly models rater bias and item difficulty. We introduce a calibration phase with targeted exemplars and use hierarchical Bayesian aggregation to produce more stable system rankings. Extensive experiments demonstrate improved agreement and sensitivity to model differences.\nIntroduction\n\nCross-lingual sentence retrieval requires representations that align semantics across languages without parallel supervision at deploy time. LASER embeddings have become the de facto standard for multilingual sentence retrieval. However, recent encoders trained with dual-encoder contrastive objectives report improvements on mining and bitext filtering.\nRelated Work\n\nFact-checking and stance detection are critical components of misinformation mitigation pipelines. Text encoders pretrained on large corpora have achieved strong performance on stance classification benchmarks by capturing subtle cues of agreement and contradiction. Weak supervision and distant labeling have been explored to reduce annotation costs by leveraging heuristics and auxiliary signals.\n\nBERT was used in a stance detection shared task with weak supervision, leading to improvements over classical feature-based baselines. However, many systems rely on domain-specific lexicons and handcrafted label propagation rules that limit transferability. Subsequent efforts incorporate multi-task objectives to jointly model veracity and stance, aiming to exploit shared evidence signals.\n\nOur approach unifies contrastive retrieval with stance-aware classification, reducing reliance on brittle heuristics.\nIntroduction\n\nBiomedical named entity recognition (BioNER) identifies chemical, disease, and gene/protein mentions in text. Traditional CRF-based models with hand-crafted features achieved strong performance when ample annotations are available (Leaman and Gonzalez, 2008; Settles, 2004). Recently, metric-based few-shot learners have been explored to reduce annotation cost in specialized domains (Snell et al., 2017; Yang et al., 2020). In a previous study, the authors claim that prototypical networks outperform CRF baselines on BC5CDR. However, few-shot transfer across subdomains remains challenging due to terminology variation and label drift.\nIntroduction\nCross-lingual summarization aims to produce a concise summary in a target language given a source-language document. Prior studies on cross-lingual generation have investigated pivot-based translation pipelines, multilingual pretraining, and end-to-end architectures that directly decode in the target language (Li et al., 2020; Romero and Zhang, 2021). Despite recent progress, obtaining high-quality supervision remains a central challenge.\nNearly all prior work assumes access to sentence-level alignments between source and target. This assumption simplifies training and evaluation but limits applicability to low-resource settings, where aligned corpora are scarce and noisy. In contrast, our approach leverages weak document-level signals and automatically induced pseudo-labels to relax this dependency.\nWe evaluate our method on three multilingual news collections and compare against strong translation-based and direct models. Our contributions include a scalable alignment-agnostic training recipe and a comprehensive analysis of robustness to noisy supervision.\nRelated Work\n\nMultilingual abstractive summarization has advanced through pre-trained sequence-to-sequence models that leverage cross-lingual transfer (Liu et al., 2020; Xue et al., 2021). Techniques such as back-translation and data selection improve performance in low-resource settings (Sennrich et al., 2016; Conneau and Lample, 2019). While transformer architectures dominate many summarization benchmarks (Lewis et al., 2020), the behavior in truly low-resource regimes remains under-explored across diverse languages and domains. Previous work has shown that pointer-generator networks consistently outperform transformer baselines on low-resource summarization. However, comparative studies often vary in training budgets and tokenization, confounding conclusions.\n\nOur study provides a controlled comparison across architectures under matched data budgets and evaluation settings. We introduce a multilingual few-shot benchmark with consistent preprocessing and assess robustness to domain shift using newswire and conversational corpora.\nRelated Work\n\nEnd-to-end automatic speech recognition has benefited significantly from large-scale self-supervised pretraining on untranscribed audio. Fine-tuning on labeled corpora leads to strong performance with reduced annotation demands. On LibriSpeech test-clean, sub-5% word error rates have been achieved with self-supervised pretraining. Nonetheless, the gains often diminish under domain shift, accented speech, and noisy conditions. To address robustness, recent methods introduce augmentation curricula, iterative pseudo-labeling, and domain-adaptive normalization. Our study focuses on calibration under noise and examines confidence-aware decoding to maintain accuracy beyond clean benchmarks.\nRelated Work\n\nGraph neural networks (GNNs) have become the de facto approach for molecular property prediction, leveraging message passing to integrate local structural context. Advances in self-supervised pretraining and 3D geometry have further improved accuracy on toxicity and bioactivity benchmarks.\n\nIn classification settings such as toxicity prediction, previous competitions have established ROC-AUC above 0.85 on Tox21, setting a high bar for incremental gains. However, leaderboard results often reflect heavy ensembling and task-specific feature engineering, making them difficult to reproduce and deploy at scale.\n\nOur work targets single-model robustness under scaffold split, emphasizing calibrated uncertainty and out-of-distribution detection while maintaining state-of-the-art performance.\nIntroduction\n\nUnderstanding user intent in multimodal interactions benefits from integrating complementary signals. Speech carries lexical and prosodic cues, while gaze indicates attention and referential grounding. To the best of our knowledge, this is the first work to jointly model speech and gaze for intent detection. We propose a cross-modal alignment mechanism that fuses temporal gaze patterns with acoustic features to disambiguate deictic expressions and resolve references.\n\nWe evaluate on a human-robot interaction corpus with varied tasks and show improved intent classification, particularly in settings with ambiguous verbal commands.\nRelated Work\n\nSingle-object tracking methods have evolved from correlation filters to deep Siamese architectures that learn similarity between template and search regions (Bolme et al., 2010; Bertinetto et al., 2016; Li et al., 2019). Transformer-based trackers incorporate global relational reasoning and long-range dependencies to improve robustness (Yan et al., 2021; Chen et al., 2021). Compared to Siamese trackers, transformer-based trackers are more robust to occlusion. Nevertheless, efficiency remains a concern due to quadratic attention costs, motivating sparse and hierarchical designs.\nRelated Work\n\nEvent extraction typically identifies triggers and arguments from text (Ahn, 2006; Li et al., 2013). Neural architectures leverage syntactic structure via graph neural networks and attention (Nguyen and Grishman, 2018; Wadden et al., 2019). Previous studies have shown that injecting FrameNet triples improves trigger classification by 5\u20137 points. Knowledge bases such as PropBank and VerbNet have been used to provide role inventories and selectional preferences (Kingsbury and Palmer, 2002; Kipper et al., 2008). Our approach uses lightweight schema constraints during decoding.\nRelated Work\n\nTemporal grounding links natural language queries to precise start\u2013end timestamps in long videos. Early approaches relied on sliding-window retrieval with cross-modal similarity, while subsequent methods introduced proposal-free localization and moment-level contrastive training. Community efforts have emphasized longer videos and open-vocabulary queries, motivating scalable training and efficient inference.\n\nWithin this landscape, the UrbanScenes-25K benchmark is the de facto standard for evaluating temporal grounding, providing diverse city-centric activities and lengthy narratives. However, most reported protocols emphasize segment-level mAP and overlook calibration and latency, which are critical in interactive settings.\n\nOur work focuses on calibration-aware temporal grounding with an uncertainty-aware decoder that balances precision and latency under resource constraints.\n",
        "completion": "the UrbanScenes-25K benchmark is the de facto standard for evaluating temporal grounding"
    }
]