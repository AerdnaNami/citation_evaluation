[
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        occurs when either:\n    a) The author describes or cites papers without connecting them to their own work/argument \n    b) Or only follows up the summary of previous works with their own contribution without explicitly highlighting the gap their work intends to research.\n    c) It does not articulate the author's perspective or motivation.\n    d) A lack of argument/opinion in the first paragraph is permissible as it serves to be the foundation of the author's argument \n    e) Lacks synthesis issues appear either as single sentences or multiple sentences.\n    Examples of lack of synthesis include:\n        i) No elaboration of own contribution/argument:\"Following early neural approaches to question answering, many subsequent studies adopt a pipeline architecture consisting of retrieval and comprehension components. The retrieval component focuses on identifying relevant documents or passages from a large corpus, while the comprehension component extracts an answer span from the retrieved text. Initial models relied on recurrent neural networks with attention mechanisms to encode questions and contexts (Seo et al., 2017; Wang et al., 2017).\"\n        ii)  No explanation of the cited works and relation to their own work: \u201cRecently, several studies have explored the use of prompting techniques with pre-trained language models to influence model outputs or access latent knowledge (Brown et al., 2020; Gao et al., 2021; Liu et al., 2021; Wei et al., 2022).\u201d \n\n        Example text: \n        Related Work\n\nDevelopers rely on code search to find relevant snippets, APIs, or examples. Unlike general document retrieval, code search must bridge natural language intent and program structure.\n\nNeural code search has been addressed with bi-encoders, cross-encoders, and dual learning (Gu et al., 2018; Husain et al., 2019; Feng et al., 2020). Structural representations incorporate ASTs, control flow, and data flow (Alon et al., 2019; Wang et al., 2020; Liu et al., 2021). Pretraining on code and NL improves retrieval metrics across languages (Ahmad et al., 2021; Guo et al., 2021).\n\nIn this paper, we introduce a language-agnostic retriever with compositional queries.\n\nWe evaluate zero-shot transfer across four programming languages.\n",
        "completion": "Neural code search has been addressed with bi-encoders, cross-encoders, and dual learning (Gu et al., 2018; Husain et al., 2019; Feng et al., 2020). Structural representations incorporate ASTs, control flow, and data flow (Alon et al., 2019; Wang et al., 2020; Liu et al., 2021). Pretraining on code and NL improves retrieval metrics across languages (Ahmad et al., 2021; Guo et al., 2021)."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        occurs when either:\n    a) The author describes or cites papers without connecting them to their own work/argument \n    b) Or only follows up the summary of previous works with their own contribution without explicitly highlighting the gap their work intends to research.\n    c) It does not articulate the author's perspective or motivation.\n    d) A lack of argument/opinion in the first paragraph is permissible as it serves to be the foundation of the author's argument \n    e) Lacks synthesis issues appear either as single sentences or multiple sentences.\n    Examples of lack of synthesis include:\n        i) No elaboration of own contribution/argument:\"Following early neural approaches to question answering, many subsequent studies adopt a pipeline architecture consisting of retrieval and comprehension components. The retrieval component focuses on identifying relevant documents or passages from a large corpus, while the comprehension component extracts an answer span from the retrieved text. Initial models relied on recurrent neural networks with attention mechanisms to encode questions and contexts (Seo et al., 2017; Wang et al., 2017).\"\n        ii)  No explanation of the cited works and relation to their own work: \u201cRecently, several studies have explored the use of prompting techniques with pre-trained language models to influence model outputs or access latent knowledge (Brown et al., 2020; Gao et al., 2021; Liu et al., 2021; Wei et al., 2022).\u201d \n\n        Example text: \n        Related Work\n\nDevelopers rely on code search to find relevant snippets, APIs, or examples. Unlike general document retrieval, code search must bridge natural language intent and program structure.\n\nNeural code search has been addressed with bi-encoders, cross-encoders, and dual learning (Gu et al., 2018; Husain et al., 2019; Feng et al., 2020). Structural representations incorporate ASTs, control flow, and data flow (Alon et al., 2019; Wang et al., 2020; Liu et al., 2021). Pretraining on code and NL improves retrieval metrics across languages (Ahmad et al., 2021; Guo et al., 2021).\n\nIn this paper, we introduce a language-agnostic retriever with compositional queries.\n\nWe evaluate zero-shot transfer across four programming languages.\nIntroduction\n\nGeneralization in text classification can be improved with data augmentation, especially when labeled data are scarce or imbalanced. Approaches range from rule-based edits to model-driven paraphrasing and representation-space mixing.\n\nText augmentation techniques include synonym replacement, random insertion/deletion, back-translation, paraphrase generation, and mixup in embedding or hidden spaces (Wei and Zou, 2019; Sennrich et al., 2016; Kobayashi, 2018; Guo et al., 2020). Recent work explores task-adaptive augmentation policies learned by reinforcement learning (Xie et al., 2020).\n\nEvaluation typically considers robustness to domain shift, label noise, and distributional skew across multiple benchmarks (Pruksachatkun et al., 2020; Hendrycks et al., 2020).\n",
        "completion": "Text augmentation techniques include synonym replacement, random insertion/deletion, back-translation, paraphrase generation, and mixup in embedding or hidden spaces (Wei and Zou, 2019; Sennrich et al., 2016; Kobayashi, 2018; Guo et al., 2020). Recent work explores task-adaptive augmentation policies learned by reinforcement learning (Xie et al., 2020)."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        occurs when either:\n    a) The author describes or cites papers without connecting them to their own work/argument \n    b) Or only follows up the summary of previous works with their own contribution without explicitly highlighting the gap their work intends to research.\n    c) It does not articulate the author's perspective or motivation.\n    d) A lack of argument/opinion in the first paragraph is permissible as it serves to be the foundation of the author's argument \n    e) Lacks synthesis issues appear either as single sentences or multiple sentences.\n    Examples of lack of synthesis include:\n        i) No elaboration of own contribution/argument:\"Following early neural approaches to question answering, many subsequent studies adopt a pipeline architecture consisting of retrieval and comprehension components. The retrieval component focuses on identifying relevant documents or passages from a large corpus, while the comprehension component extracts an answer span from the retrieved text. Initial models relied on recurrent neural networks with attention mechanisms to encode questions and contexts (Seo et al., 2017; Wang et al., 2017).\"\n        ii)  No explanation of the cited works and relation to their own work: \u201cRecently, several studies have explored the use of prompting techniques with pre-trained language models to influence model outputs or access latent knowledge (Brown et al., 2020; Gao et al., 2021; Liu et al., 2021; Wei et al., 2022).\u201d \n\n        Example text: \n        Related Work\n\nDevelopers rely on code search to find relevant snippets, APIs, or examples. Unlike general document retrieval, code search must bridge natural language intent and program structure.\n\nNeural code search has been addressed with bi-encoders, cross-encoders, and dual learning (Gu et al., 2018; Husain et al., 2019; Feng et al., 2020). Structural representations incorporate ASTs, control flow, and data flow (Alon et al., 2019; Wang et al., 2020; Liu et al., 2021). Pretraining on code and NL improves retrieval metrics across languages (Ahmad et al., 2021; Guo et al., 2021).\n\nIn this paper, we introduce a language-agnostic retriever with compositional queries.\n\nWe evaluate zero-shot transfer across four programming languages.\nIntroduction\n\nGeneralization in text classification can be improved with data augmentation, especially when labeled data are scarce or imbalanced. Approaches range from rule-based edits to model-driven paraphrasing and representation-space mixing.\n\nText augmentation techniques include synonym replacement, random insertion/deletion, back-translation, paraphrase generation, and mixup in embedding or hidden spaces (Wei and Zou, 2019; Sennrich et al., 2016; Kobayashi, 2018; Guo et al., 2020). Recent work explores task-adaptive augmentation policies learned by reinforcement learning (Xie et al., 2020).\n\nEvaluation typically considers robustness to domain shift, label noise, and distributional skew across multiple benchmarks (Pruksachatkun et al., 2020; Hendrycks et al., 2020).\nRelated Work\n\nKnowledge graph completion predicts missing links by learning entity and relation representations. Methods vary in how they encode semantics and handle patterns like symmetry, hierarchy, and composition.\n\nTranslation-based knowledge graph embeddings model relations as translations in vector space (Bordes et al., 2013; Wang et al., 2014), while bilinear and neural models capture more complex interactions (Nickel et al., 2011; Trouillon et al., 2016; Sun et al., 2019). Regularization and rule-guided approaches improve inductive bias and data efficiency (Rockt\u00e4schel et al., 2015; Minervini et al., 2017).\n\nWe introduce a lightweight compositional constraint for hierarchical relations and evaluate on three benchmarks and an industry dataset.\n",
        "completion": "Translation-based knowledge graph embeddings model relations as translations in vector space (Bordes et al., 2013; Wang et al., 2014), while bilinear and neural models capture more complex interactions (Nickel et al., 2011; Trouillon et al., 2016; Sun et al., 2019)."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        occurs when either:\n    a) The author describes or cites papers without connecting them to their own work/argument \n    b) Or only follows up the summary of previous works with their own contribution without explicitly highlighting the gap their work intends to research.\n    c) It does not articulate the author's perspective or motivation.\n    d) A lack of argument/opinion in the first paragraph is permissible as it serves to be the foundation of the author's argument \n    e) Lacks synthesis issues appear either as single sentences or multiple sentences.\n    Examples of lack of synthesis include:\n        i) No elaboration of own contribution/argument:\"Following early neural approaches to question answering, many subsequent studies adopt a pipeline architecture consisting of retrieval and comprehension components. The retrieval component focuses on identifying relevant documents or passages from a large corpus, while the comprehension component extracts an answer span from the retrieved text. Initial models relied on recurrent neural networks with attention mechanisms to encode questions and contexts (Seo et al., 2017; Wang et al., 2017).\"\n        ii)  No explanation of the cited works and relation to their own work: \u201cRecently, several studies have explored the use of prompting techniques with pre-trained language models to influence model outputs or access latent knowledge (Brown et al., 2020; Gao et al., 2021; Liu et al., 2021; Wei et al., 2022).\u201d \n\n        Example text: \n        Related Work\n\nDevelopers rely on code search to find relevant snippets, APIs, or examples. Unlike general document retrieval, code search must bridge natural language intent and program structure.\n\nNeural code search has been addressed with bi-encoders, cross-encoders, and dual learning (Gu et al., 2018; Husain et al., 2019; Feng et al., 2020). Structural representations incorporate ASTs, control flow, and data flow (Alon et al., 2019; Wang et al., 2020; Liu et al., 2021). Pretraining on code and NL improves retrieval metrics across languages (Ahmad et al., 2021; Guo et al., 2021).\n\nIn this paper, we introduce a language-agnostic retriever with compositional queries.\n\nWe evaluate zero-shot transfer across four programming languages.\nIntroduction\n\nGeneralization in text classification can be improved with data augmentation, especially when labeled data are scarce or imbalanced. Approaches range from rule-based edits to model-driven paraphrasing and representation-space mixing.\n\nText augmentation techniques include synonym replacement, random insertion/deletion, back-translation, paraphrase generation, and mixup in embedding or hidden spaces (Wei and Zou, 2019; Sennrich et al., 2016; Kobayashi, 2018; Guo et al., 2020). Recent work explores task-adaptive augmentation policies learned by reinforcement learning (Xie et al., 2020).\n\nEvaluation typically considers robustness to domain shift, label noise, and distributional skew across multiple benchmarks (Pruksachatkun et al., 2020; Hendrycks et al., 2020).\nRelated Work\n\nKnowledge graph completion predicts missing links by learning entity and relation representations. Methods vary in how they encode semantics and handle patterns like symmetry, hierarchy, and composition.\n\nTranslation-based knowledge graph embeddings model relations as translations in vector space (Bordes et al., 2013; Wang et al., 2014), while bilinear and neural models capture more complex interactions (Nickel et al., 2011; Trouillon et al., 2016; Sun et al., 2019). Regularization and rule-guided approaches improve inductive bias and data efficiency (Rockt\u00e4schel et al., 2015; Minervini et al., 2017).\n\nWe introduce a lightweight compositional constraint for hierarchical relations and evaluate on three benchmarks and an industry dataset.\nRelated Work\n\nEnsuring safety during reinforcement learning is critical in real-world control where violations can be costly. Research has proposed both objective-level and mechanism-level solutions.\n\nSafe reinforcement learning approaches include risk-sensitive objectives such as CVaR optimization (Tamar et al., 2015; Chow et al., 2018), constrained policy optimization with safety budgets (Achiam et al., 2017; Yang et al., 2020), and shielding based on model-checking or supervisors (Alshiekh et al., 2018; Dalal et al., 2018). We develop a method that integrates model-predictive constraints with policy gradients.\n\nBenchmarks often evaluate safety in simulated robotics or navigation with cost functions approximating constraint violations (Ray et al., 2019; Bharadhwaj et al., 2021).\n",
        "completion": "Safe reinforcement learning approaches include risk-sensitive objectives such as CVaR optimization (Tamar et al., 2015; Chow et al., 2018), constrained policy optimization with safety budgets (Achiam et al., 2017; Yang et al., 2020), and shielding based on model-checking or supervisors (Alshiekh et al., 2018; Dalal et al., 2018). We develop a method that integrates model-predictive constraints with policy gradients."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        occurs when either:\n    a) The author describes or cites papers without connecting them to their own work/argument \n    b) Or only follows up the summary of previous works with their own contribution without explicitly highlighting the gap their work intends to research.\n    c) It does not articulate the author's perspective or motivation.\n    d) A lack of argument/opinion in the first paragraph is permissible as it serves to be the foundation of the author's argument \n    e) Lacks synthesis issues appear either as single sentences or multiple sentences.\n    Examples of lack of synthesis include:\n        i) No elaboration of own contribution/argument:\"Following early neural approaches to question answering, many subsequent studies adopt a pipeline architecture consisting of retrieval and comprehension components. The retrieval component focuses on identifying relevant documents or passages from a large corpus, while the comprehension component extracts an answer span from the retrieved text. Initial models relied on recurrent neural networks with attention mechanisms to encode questions and contexts (Seo et al., 2017; Wang et al., 2017).\"\n        ii)  No explanation of the cited works and relation to their own work: \u201cRecently, several studies have explored the use of prompting techniques with pre-trained language models to influence model outputs or access latent knowledge (Brown et al., 2020; Gao et al., 2021; Liu et al., 2021; Wei et al., 2022).\u201d \n\n        Example text: \n        Related Work\n\nDevelopers rely on code search to find relevant snippets, APIs, or examples. Unlike general document retrieval, code search must bridge natural language intent and program structure.\n\nNeural code search has been addressed with bi-encoders, cross-encoders, and dual learning (Gu et al., 2018; Husain et al., 2019; Feng et al., 2020). Structural representations incorporate ASTs, control flow, and data flow (Alon et al., 2019; Wang et al., 2020; Liu et al., 2021). Pretraining on code and NL improves retrieval metrics across languages (Ahmad et al., 2021; Guo et al., 2021).\n\nIn this paper, we introduce a language-agnostic retriever with compositional queries.\n\nWe evaluate zero-shot transfer across four programming languages.\nIntroduction\n\nGeneralization in text classification can be improved with data augmentation, especially when labeled data are scarce or imbalanced. Approaches range from rule-based edits to model-driven paraphrasing and representation-space mixing.\n\nText augmentation techniques include synonym replacement, random insertion/deletion, back-translation, paraphrase generation, and mixup in embedding or hidden spaces (Wei and Zou, 2019; Sennrich et al., 2016; Kobayashi, 2018; Guo et al., 2020). Recent work explores task-adaptive augmentation policies learned by reinforcement learning (Xie et al., 2020).\n\nEvaluation typically considers robustness to domain shift, label noise, and distributional skew across multiple benchmarks (Pruksachatkun et al., 2020; Hendrycks et al., 2020).\nRelated Work\n\nKnowledge graph completion predicts missing links by learning entity and relation representations. Methods vary in how they encode semantics and handle patterns like symmetry, hierarchy, and composition.\n\nTranslation-based knowledge graph embeddings model relations as translations in vector space (Bordes et al., 2013; Wang et al., 2014), while bilinear and neural models capture more complex interactions (Nickel et al., 2011; Trouillon et al., 2016; Sun et al., 2019). Regularization and rule-guided approaches improve inductive bias and data efficiency (Rockt\u00e4schel et al., 2015; Minervini et al., 2017).\n\nWe introduce a lightweight compositional constraint for hierarchical relations and evaluate on three benchmarks and an industry dataset.\nRelated Work\n\nEnsuring safety during reinforcement learning is critical in real-world control where violations can be costly. Research has proposed both objective-level and mechanism-level solutions.\n\nSafe reinforcement learning approaches include risk-sensitive objectives such as CVaR optimization (Tamar et al., 2015; Chow et al., 2018), constrained policy optimization with safety budgets (Achiam et al., 2017; Yang et al., 2020), and shielding based on model-checking or supervisors (Alshiekh et al., 2018; Dalal et al., 2018). We develop a method that integrates model-predictive constraints with policy gradients.\n\nBenchmarks often evaluate safety in simulated robotics or navigation with cost functions approximating constraint violations (Ray et al., 2019; Bharadhwaj et al., 2021).\nRelated Work\n\nDialog state tracking (DST) has evolved from rule-based slot filling to neural architectures that jointly infer belief states across turns. Early pipeline models used hand-crafted lexicons and semantic frames (Singh and Patel, 2015), but suffered from brittleness to paraphrase and noise. Neural encoders introduced robustness by contextualizing utterances, incorporating attention over dialog history, and modeling slot-value dependencies (Lee et al., 2018; Choe and Kim, 2019).\n\nPretrained language models have further shifted the landscape by enabling few-shot generalization and open-vocabulary slot values. Fine-tuning BERT-like encoders for DST improved cross-domain transfer (Rao et al., 2020), while generative formulations cast state tracking as text-to-text prediction (Mendez et al., 2021).\n\nPrompting-based approaches have also been explored for dialog modeling (Kumar et al., 2021; Ortega and Lin, 2022; Park et al., 2023). These methods condition large language models on task instructions or few-shot exemplars to elicit latent conversational knowledge. Recent variants incorporate calibration or self-consistency to stabilize outputs (Fang et al., 2023; Zhou et al., 2023).\n\nPosition relative to this paper While we also employ pretrained sequence-to-sequence models, our focus is on handling ontology drift in long-running deployments. Specifically, we introduce an adaptive slot schema encoder that aligns evolving taxonomies with dialog evidence, and a contrastive consistency objective to mitigate spurious slot co-activations across domains.\n",
        "completion": "Prompting-based approaches have also been explored for dialog modeling (Kumar et al., 2021; Ortega and Lin, 2022; Park et al., 2023). These methods condition large language models on task instructions or few-shot exemplars to elicit latent conversational knowledge. Recent variants incorporate calibration or self-consistency to stabilize outputs (Fang et al., 2023; Zhou et al., 2023)."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        occurs when either:\n    a) The author describes or cites papers without connecting them to their own work/argument \n    b) Or only follows up the summary of previous works with their own contribution without explicitly highlighting the gap their work intends to research.\n    c) It does not articulate the author's perspective or motivation.\n    d) A lack of argument/opinion in the first paragraph is permissible as it serves to be the foundation of the author's argument \n    e) Lacks synthesis issues appear either as single sentences or multiple sentences.\n    Examples of lack of synthesis include:\n        i) No elaboration of own contribution/argument:\"Following early neural approaches to question answering, many subsequent studies adopt a pipeline architecture consisting of retrieval and comprehension components. The retrieval component focuses on identifying relevant documents or passages from a large corpus, while the comprehension component extracts an answer span from the retrieved text. Initial models relied on recurrent neural networks with attention mechanisms to encode questions and contexts (Seo et al., 2017; Wang et al., 2017).\"\n        ii)  No explanation of the cited works and relation to their own work: \u201cRecently, several studies have explored the use of prompting techniques with pre-trained language models to influence model outputs or access latent knowledge (Brown et al., 2020; Gao et al., 2021; Liu et al., 2021; Wei et al., 2022).\u201d \n\n        Example text: \n        Related Work\n\nDevelopers rely on code search to find relevant snippets, APIs, or examples. Unlike general document retrieval, code search must bridge natural language intent and program structure.\n\nNeural code search has been addressed with bi-encoders, cross-encoders, and dual learning (Gu et al., 2018; Husain et al., 2019; Feng et al., 2020). Structural representations incorporate ASTs, control flow, and data flow (Alon et al., 2019; Wang et al., 2020; Liu et al., 2021). Pretraining on code and NL improves retrieval metrics across languages (Ahmad et al., 2021; Guo et al., 2021).\n\nIn this paper, we introduce a language-agnostic retriever with compositional queries.\n\nWe evaluate zero-shot transfer across four programming languages.\nIntroduction\n\nGeneralization in text classification can be improved with data augmentation, especially when labeled data are scarce or imbalanced. Approaches range from rule-based edits to model-driven paraphrasing and representation-space mixing.\n\nText augmentation techniques include synonym replacement, random insertion/deletion, back-translation, paraphrase generation, and mixup in embedding or hidden spaces (Wei and Zou, 2019; Sennrich et al., 2016; Kobayashi, 2018; Guo et al., 2020). Recent work explores task-adaptive augmentation policies learned by reinforcement learning (Xie et al., 2020).\n\nEvaluation typically considers robustness to domain shift, label noise, and distributional skew across multiple benchmarks (Pruksachatkun et al., 2020; Hendrycks et al., 2020).\nRelated Work\n\nKnowledge graph completion predicts missing links by learning entity and relation representations. Methods vary in how they encode semantics and handle patterns like symmetry, hierarchy, and composition.\n\nTranslation-based knowledge graph embeddings model relations as translations in vector space (Bordes et al., 2013; Wang et al., 2014), while bilinear and neural models capture more complex interactions (Nickel et al., 2011; Trouillon et al., 2016; Sun et al., 2019). Regularization and rule-guided approaches improve inductive bias and data efficiency (Rockt\u00e4schel et al., 2015; Minervini et al., 2017).\n\nWe introduce a lightweight compositional constraint for hierarchical relations and evaluate on three benchmarks and an industry dataset.\nRelated Work\n\nEnsuring safety during reinforcement learning is critical in real-world control where violations can be costly. Research has proposed both objective-level and mechanism-level solutions.\n\nSafe reinforcement learning approaches include risk-sensitive objectives such as CVaR optimization (Tamar et al., 2015; Chow et al., 2018), constrained policy optimization with safety budgets (Achiam et al., 2017; Yang et al., 2020), and shielding based on model-checking or supervisors (Alshiekh et al., 2018; Dalal et al., 2018). We develop a method that integrates model-predictive constraints with policy gradients.\n\nBenchmarks often evaluate safety in simulated robotics or navigation with cost functions approximating constraint violations (Ray et al., 2019; Bharadhwaj et al., 2021).\nRelated Work\n\nDialog state tracking (DST) has evolved from rule-based slot filling to neural architectures that jointly infer belief states across turns. Early pipeline models used hand-crafted lexicons and semantic frames (Singh and Patel, 2015), but suffered from brittleness to paraphrase and noise. Neural encoders introduced robustness by contextualizing utterances, incorporating attention over dialog history, and modeling slot-value dependencies (Lee et al., 2018; Choe and Kim, 2019).\n\nPretrained language models have further shifted the landscape by enabling few-shot generalization and open-vocabulary slot values. Fine-tuning BERT-like encoders for DST improved cross-domain transfer (Rao et al., 2020), while generative formulations cast state tracking as text-to-text prediction (Mendez et al., 2021).\n\nPrompting-based approaches have also been explored for dialog modeling (Kumar et al., 2021; Ortega and Lin, 2022; Park et al., 2023). These methods condition large language models on task instructions or few-shot exemplars to elicit latent conversational knowledge. Recent variants incorporate calibration or self-consistency to stabilize outputs (Fang et al., 2023; Zhou et al., 2023).\n\nPosition relative to this paper While we also employ pretrained sequence-to-sequence models, our focus is on handling ontology drift in long-running deployments. Specifically, we introduce an adaptive slot schema encoder that aligns evolving taxonomies with dialog evidence, and a contrastive consistency objective to mitigate spurious slot co-activations across domains.\nIntroduction\n\nSelf-supervised learning (SSL) has become the dominant paradigm for learning transferable visual features without labels. By constructing pretext tasks that expose invariances and structure inherent in data, SSL models can match or surpass supervised baselines on many downstream tasks.\n\nContrastive pretraining has been widely adopted for visual representations (Chen et al., 2020; He et al., 2020; Xie and Xu, 2021). Non-contrastive methods remove negative pairs and rely on architectural or objective asymmetries (Grill et al., 2020; Tian et al., 2021). Clustering-based methods jointly learn assignments and embeddings (Caron et al., 2018; Li and Gao, 2022).\n\nDespite these advances, industrial applications often operate under strict memory budgets and latency constraints. In this paper, we investigate compute-aware pretraining objectives that couple multi-crop augmentation with a token-subsampled backbone. We present a latency-regularized alignment loss that preserves downstream accuracy while reducing FLOPs during both pretraining and fine-tuning.\n",
        "completion": "Contrastive pretraining has been widely adopted for visual representations (Chen et al., 2020; He et al., 2020; Xie and Xu, 2021). Non-contrastive methods remove negative pairs and rely on architectural or objective asymmetries (Grill et al., 2020; Tian et al., 2021). Clustering-based methods jointly learn assignments and embeddings (Caron et al., 2018; Li and Gao, 2022)."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        occurs when either:\n    a) The author describes or cites papers without connecting them to their own work/argument \n    b) Or only follows up the summary of previous works with their own contribution without explicitly highlighting the gap their work intends to research.\n    c) It does not articulate the author's perspective or motivation.\n    d) A lack of argument/opinion in the first paragraph is permissible as it serves to be the foundation of the author's argument \n    e) Lacks synthesis issues appear either as single sentences or multiple sentences.\n    Examples of lack of synthesis include:\n        i) No elaboration of own contribution/argument:\"Following early neural approaches to question answering, many subsequent studies adopt a pipeline architecture consisting of retrieval and comprehension components. The retrieval component focuses on identifying relevant documents or passages from a large corpus, while the comprehension component extracts an answer span from the retrieved text. Initial models relied on recurrent neural networks with attention mechanisms to encode questions and contexts (Seo et al., 2017; Wang et al., 2017).\"\n        ii)  No explanation of the cited works and relation to their own work: \u201cRecently, several studies have explored the use of prompting techniques with pre-trained language models to influence model outputs or access latent knowledge (Brown et al., 2020; Gao et al., 2021; Liu et al., 2021; Wei et al., 2022).\u201d \n\n        Example text: \n        Related Work\n\nDevelopers rely on code search to find relevant snippets, APIs, or examples. Unlike general document retrieval, code search must bridge natural language intent and program structure.\n\nNeural code search has been addressed with bi-encoders, cross-encoders, and dual learning (Gu et al., 2018; Husain et al., 2019; Feng et al., 2020). Structural representations incorporate ASTs, control flow, and data flow (Alon et al., 2019; Wang et al., 2020; Liu et al., 2021). Pretraining on code and NL improves retrieval metrics across languages (Ahmad et al., 2021; Guo et al., 2021).\n\nIn this paper, we introduce a language-agnostic retriever with compositional queries.\n\nWe evaluate zero-shot transfer across four programming languages.\nIntroduction\n\nGeneralization in text classification can be improved with data augmentation, especially when labeled data are scarce or imbalanced. Approaches range from rule-based edits to model-driven paraphrasing and representation-space mixing.\n\nText augmentation techniques include synonym replacement, random insertion/deletion, back-translation, paraphrase generation, and mixup in embedding or hidden spaces (Wei and Zou, 2019; Sennrich et al., 2016; Kobayashi, 2018; Guo et al., 2020). Recent work explores task-adaptive augmentation policies learned by reinforcement learning (Xie et al., 2020).\n\nEvaluation typically considers robustness to domain shift, label noise, and distributional skew across multiple benchmarks (Pruksachatkun et al., 2020; Hendrycks et al., 2020).\nRelated Work\n\nKnowledge graph completion predicts missing links by learning entity and relation representations. Methods vary in how they encode semantics and handle patterns like symmetry, hierarchy, and composition.\n\nTranslation-based knowledge graph embeddings model relations as translations in vector space (Bordes et al., 2013; Wang et al., 2014), while bilinear and neural models capture more complex interactions (Nickel et al., 2011; Trouillon et al., 2016; Sun et al., 2019). Regularization and rule-guided approaches improve inductive bias and data efficiency (Rockt\u00e4schel et al., 2015; Minervini et al., 2017).\n\nWe introduce a lightweight compositional constraint for hierarchical relations and evaluate on three benchmarks and an industry dataset.\nRelated Work\n\nEnsuring safety during reinforcement learning is critical in real-world control where violations can be costly. Research has proposed both objective-level and mechanism-level solutions.\n\nSafe reinforcement learning approaches include risk-sensitive objectives such as CVaR optimization (Tamar et al., 2015; Chow et al., 2018), constrained policy optimization with safety budgets (Achiam et al., 2017; Yang et al., 2020), and shielding based on model-checking or supervisors (Alshiekh et al., 2018; Dalal et al., 2018). We develop a method that integrates model-predictive constraints with policy gradients.\n\nBenchmarks often evaluate safety in simulated robotics or navigation with cost functions approximating constraint violations (Ray et al., 2019; Bharadhwaj et al., 2021).\nRelated Work\n\nDialog state tracking (DST) has evolved from rule-based slot filling to neural architectures that jointly infer belief states across turns. Early pipeline models used hand-crafted lexicons and semantic frames (Singh and Patel, 2015), but suffered from brittleness to paraphrase and noise. Neural encoders introduced robustness by contextualizing utterances, incorporating attention over dialog history, and modeling slot-value dependencies (Lee et al., 2018; Choe and Kim, 2019).\n\nPretrained language models have further shifted the landscape by enabling few-shot generalization and open-vocabulary slot values. Fine-tuning BERT-like encoders for DST improved cross-domain transfer (Rao et al., 2020), while generative formulations cast state tracking as text-to-text prediction (Mendez et al., 2021).\n\nPrompting-based approaches have also been explored for dialog modeling (Kumar et al., 2021; Ortega and Lin, 2022; Park et al., 2023). These methods condition large language models on task instructions or few-shot exemplars to elicit latent conversational knowledge. Recent variants incorporate calibration or self-consistency to stabilize outputs (Fang et al., 2023; Zhou et al., 2023).\n\nPosition relative to this paper While we also employ pretrained sequence-to-sequence models, our focus is on handling ontology drift in long-running deployments. Specifically, we introduce an adaptive slot schema encoder that aligns evolving taxonomies with dialog evidence, and a contrastive consistency objective to mitigate spurious slot co-activations across domains.\nIntroduction\n\nSelf-supervised learning (SSL) has become the dominant paradigm for learning transferable visual features without labels. By constructing pretext tasks that expose invariances and structure inherent in data, SSL models can match or surpass supervised baselines on many downstream tasks.\n\nContrastive pretraining has been widely adopted for visual representations (Chen et al., 2020; He et al., 2020; Xie and Xu, 2021). Non-contrastive methods remove negative pairs and rely on architectural or objective asymmetries (Grill et al., 2020; Tian et al., 2021). Clustering-based methods jointly learn assignments and embeddings (Caron et al., 2018; Li and Gao, 2022).\n\nDespite these advances, industrial applications often operate under strict memory budgets and latency constraints. In this paper, we investigate compute-aware pretraining objectives that couple multi-crop augmentation with a token-subsampled backbone. We present a latency-regularized alignment loss that preserves downstream accuracy while reducing FLOPs during both pretraining and fine-tuning.\nIntroduction\n\nEfficient exploration remains a central challenge in reinforcement learning (RL), particularly in sparse-reward environments where naive strategies fail to discover rewarding states. Over-exploration, however, can waste samples and destabilize learning.\n\nExploration in reinforcement learning has been advanced by count-based bonuses, intrinsic motivation, curiosity-driven prediction error, and information-theoretic objectives (Bellemare et al., 2016; Pathak et al., 2017; Houthooft et al., 2016; Burda et al., 2019; Ta\u00efga et al., 2020).\n\nYet, when environment dynamics change over time, stale novelty estimates can encourage revisiting obsolete states. We propose a recency-aware intrinsic reward that discounts outdated novelty and couples it with conservative policy updates.\n\nAcross Atari and continuous-control domains with drifting dynamics, our method achieves superior sample efficiency and stability, and ablations confirm the role of recency in balancing exploration and exploitation.\n",
        "completion": "Exploration in reinforcement learning has been advanced by count-based bonuses, intrinsic motivation, curiosity-driven prediction error, and information-theoretic objectives (Bellemare et al., 2016; Pathak et al., 2017; Houthooft et al., 2016; Burda et al., 2019; Ta\u00efga et al., 2020)."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        occurs when either:\n    a) The author describes or cites papers without connecting them to their own work/argument \n    b) Or only follows up the summary of previous works with their own contribution without explicitly highlighting the gap their work intends to research.\n    c) It does not articulate the author's perspective or motivation.\n    d) A lack of argument/opinion in the first paragraph is permissible as it serves to be the foundation of the author's argument \n    e) Lacks synthesis issues appear either as single sentences or multiple sentences.\n    Examples of lack of synthesis include:\n        i) No elaboration of own contribution/argument:\"Following early neural approaches to question answering, many subsequent studies adopt a pipeline architecture consisting of retrieval and comprehension components. The retrieval component focuses on identifying relevant documents or passages from a large corpus, while the comprehension component extracts an answer span from the retrieved text. Initial models relied on recurrent neural networks with attention mechanisms to encode questions and contexts (Seo et al., 2017; Wang et al., 2017).\"\n        ii)  No explanation of the cited works and relation to their own work: \u201cRecently, several studies have explored the use of prompting techniques with pre-trained language models to influence model outputs or access latent knowledge (Brown et al., 2020; Gao et al., 2021; Liu et al., 2021; Wei et al., 2022).\u201d \n\n        Example text: \n        Related Work\n\nDevelopers rely on code search to find relevant snippets, APIs, or examples. Unlike general document retrieval, code search must bridge natural language intent and program structure.\n\nNeural code search has been addressed with bi-encoders, cross-encoders, and dual learning (Gu et al., 2018; Husain et al., 2019; Feng et al., 2020). Structural representations incorporate ASTs, control flow, and data flow (Alon et al., 2019; Wang et al., 2020; Liu et al., 2021). Pretraining on code and NL improves retrieval metrics across languages (Ahmad et al., 2021; Guo et al., 2021).\n\nIn this paper, we introduce a language-agnostic retriever with compositional queries.\n\nWe evaluate zero-shot transfer across four programming languages.\nIntroduction\n\nGeneralization in text classification can be improved with data augmentation, especially when labeled data are scarce or imbalanced. Approaches range from rule-based edits to model-driven paraphrasing and representation-space mixing.\n\nText augmentation techniques include synonym replacement, random insertion/deletion, back-translation, paraphrase generation, and mixup in embedding or hidden spaces (Wei and Zou, 2019; Sennrich et al., 2016; Kobayashi, 2018; Guo et al., 2020). Recent work explores task-adaptive augmentation policies learned by reinforcement learning (Xie et al., 2020).\n\nEvaluation typically considers robustness to domain shift, label noise, and distributional skew across multiple benchmarks (Pruksachatkun et al., 2020; Hendrycks et al., 2020).\nRelated Work\n\nKnowledge graph completion predicts missing links by learning entity and relation representations. Methods vary in how they encode semantics and handle patterns like symmetry, hierarchy, and composition.\n\nTranslation-based knowledge graph embeddings model relations as translations in vector space (Bordes et al., 2013; Wang et al., 2014), while bilinear and neural models capture more complex interactions (Nickel et al., 2011; Trouillon et al., 2016; Sun et al., 2019). Regularization and rule-guided approaches improve inductive bias and data efficiency (Rockt\u00e4schel et al., 2015; Minervini et al., 2017).\n\nWe introduce a lightweight compositional constraint for hierarchical relations and evaluate on three benchmarks and an industry dataset.\nRelated Work\n\nEnsuring safety during reinforcement learning is critical in real-world control where violations can be costly. Research has proposed both objective-level and mechanism-level solutions.\n\nSafe reinforcement learning approaches include risk-sensitive objectives such as CVaR optimization (Tamar et al., 2015; Chow et al., 2018), constrained policy optimization with safety budgets (Achiam et al., 2017; Yang et al., 2020), and shielding based on model-checking or supervisors (Alshiekh et al., 2018; Dalal et al., 2018). We develop a method that integrates model-predictive constraints with policy gradients.\n\nBenchmarks often evaluate safety in simulated robotics or navigation with cost functions approximating constraint violations (Ray et al., 2019; Bharadhwaj et al., 2021).\nRelated Work\n\nDialog state tracking (DST) has evolved from rule-based slot filling to neural architectures that jointly infer belief states across turns. Early pipeline models used hand-crafted lexicons and semantic frames (Singh and Patel, 2015), but suffered from brittleness to paraphrase and noise. Neural encoders introduced robustness by contextualizing utterances, incorporating attention over dialog history, and modeling slot-value dependencies (Lee et al., 2018; Choe and Kim, 2019).\n\nPretrained language models have further shifted the landscape by enabling few-shot generalization and open-vocabulary slot values. Fine-tuning BERT-like encoders for DST improved cross-domain transfer (Rao et al., 2020), while generative formulations cast state tracking as text-to-text prediction (Mendez et al., 2021).\n\nPrompting-based approaches have also been explored for dialog modeling (Kumar et al., 2021; Ortega and Lin, 2022; Park et al., 2023). These methods condition large language models on task instructions or few-shot exemplars to elicit latent conversational knowledge. Recent variants incorporate calibration or self-consistency to stabilize outputs (Fang et al., 2023; Zhou et al., 2023).\n\nPosition relative to this paper While we also employ pretrained sequence-to-sequence models, our focus is on handling ontology drift in long-running deployments. Specifically, we introduce an adaptive slot schema encoder that aligns evolving taxonomies with dialog evidence, and a contrastive consistency objective to mitigate spurious slot co-activations across domains.\nIntroduction\n\nSelf-supervised learning (SSL) has become the dominant paradigm for learning transferable visual features without labels. By constructing pretext tasks that expose invariances and structure inherent in data, SSL models can match or surpass supervised baselines on many downstream tasks.\n\nContrastive pretraining has been widely adopted for visual representations (Chen et al., 2020; He et al., 2020; Xie and Xu, 2021). Non-contrastive methods remove negative pairs and rely on architectural or objective asymmetries (Grill et al., 2020; Tian et al., 2021). Clustering-based methods jointly learn assignments and embeddings (Caron et al., 2018; Li and Gao, 2022).\n\nDespite these advances, industrial applications often operate under strict memory budgets and latency constraints. In this paper, we investigate compute-aware pretraining objectives that couple multi-crop augmentation with a token-subsampled backbone. We present a latency-regularized alignment loss that preserves downstream accuracy while reducing FLOPs during both pretraining and fine-tuning.\nIntroduction\n\nEfficient exploration remains a central challenge in reinforcement learning (RL), particularly in sparse-reward environments where naive strategies fail to discover rewarding states. Over-exploration, however, can waste samples and destabilize learning.\n\nExploration in reinforcement learning has been advanced by count-based bonuses, intrinsic motivation, curiosity-driven prediction error, and information-theoretic objectives (Bellemare et al., 2016; Pathak et al., 2017; Houthooft et al., 2016; Burda et al., 2019; Ta\u00efga et al., 2020).\n\nYet, when environment dynamics change over time, stale novelty estimates can encourage revisiting obsolete states. We propose a recency-aware intrinsic reward that discounts outdated novelty and couples it with conservative policy updates.\n\nAcross Atari and continuous-control domains with drifting dynamics, our method achieves superior sample efficiency and stability, and ablations confirm the role of recency in balancing exploration and exploitation.\nRelated Work\n\nDetecting anomalies in multivariate time series is vital for monitoring industrial systems and cloud services. The challenge lies in handling seasonality, rare events, and inter-variable dependencies.\n\nClassical anomaly detection leverages ARIMA residual tests, STL decomposition, and control charts, while deep methods introduce autoencoders, VAEs, GANs, LSTMs, and Transformers for reconstruction or prediction errors (Tsay, 2010; Malhotra et al., 2015; An and Cho, 2015; Li et al., 2019; Xu et al., 2021).\n\nWe present Contrastive Forecasting with Graph Priors (CFGP), which learns structure-aware representations via self-supervised objectives and uses calibrated predictive intervals to flag anomalies.\n",
        "completion": "Classical anomaly detection leverages ARIMA residual tests, STL decomposition, and control charts, while deep methods introduce autoencoders, VAEs, GANs, LSTMs, and Transformers for reconstruction or prediction errors (Tsay, 2010; Malhotra et al., 2015; An and Cho, 2015; Li et al., 2019; Xu et al., 2021)."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        occurs when either:\n    a) The author describes or cites papers without connecting them to their own work/argument \n    b) Or only follows up the summary of previous works with their own contribution without explicitly highlighting the gap their work intends to research.\n    c) It does not articulate the author's perspective or motivation.\n    d) A lack of argument/opinion in the first paragraph is permissible as it serves to be the foundation of the author's argument \n    e) Lacks synthesis issues appear either as single sentences or multiple sentences.\n    Examples of lack of synthesis include:\n        i) No elaboration of own contribution/argument:\"Following early neural approaches to question answering, many subsequent studies adopt a pipeline architecture consisting of retrieval and comprehension components. The retrieval component focuses on identifying relevant documents or passages from a large corpus, while the comprehension component extracts an answer span from the retrieved text. Initial models relied on recurrent neural networks with attention mechanisms to encode questions and contexts (Seo et al., 2017; Wang et al., 2017).\"\n        ii)  No explanation of the cited works and relation to their own work: \u201cRecently, several studies have explored the use of prompting techniques with pre-trained language models to influence model outputs or access latent knowledge (Brown et al., 2020; Gao et al., 2021; Liu et al., 2021; Wei et al., 2022).\u201d \n\n        Example text: \n        Related Work\n\nDevelopers rely on code search to find relevant snippets, APIs, or examples. Unlike general document retrieval, code search must bridge natural language intent and program structure.\n\nNeural code search has been addressed with bi-encoders, cross-encoders, and dual learning (Gu et al., 2018; Husain et al., 2019; Feng et al., 2020). Structural representations incorporate ASTs, control flow, and data flow (Alon et al., 2019; Wang et al., 2020; Liu et al., 2021). Pretraining on code and NL improves retrieval metrics across languages (Ahmad et al., 2021; Guo et al., 2021).\n\nIn this paper, we introduce a language-agnostic retriever with compositional queries.\n\nWe evaluate zero-shot transfer across four programming languages.\nIntroduction\n\nGeneralization in text classification can be improved with data augmentation, especially when labeled data are scarce or imbalanced. Approaches range from rule-based edits to model-driven paraphrasing and representation-space mixing.\n\nText augmentation techniques include synonym replacement, random insertion/deletion, back-translation, paraphrase generation, and mixup in embedding or hidden spaces (Wei and Zou, 2019; Sennrich et al., 2016; Kobayashi, 2018; Guo et al., 2020). Recent work explores task-adaptive augmentation policies learned by reinforcement learning (Xie et al., 2020).\n\nEvaluation typically considers robustness to domain shift, label noise, and distributional skew across multiple benchmarks (Pruksachatkun et al., 2020; Hendrycks et al., 2020).\nRelated Work\n\nKnowledge graph completion predicts missing links by learning entity and relation representations. Methods vary in how they encode semantics and handle patterns like symmetry, hierarchy, and composition.\n\nTranslation-based knowledge graph embeddings model relations as translations in vector space (Bordes et al., 2013; Wang et al., 2014), while bilinear and neural models capture more complex interactions (Nickel et al., 2011; Trouillon et al., 2016; Sun et al., 2019). Regularization and rule-guided approaches improve inductive bias and data efficiency (Rockt\u00e4schel et al., 2015; Minervini et al., 2017).\n\nWe introduce a lightweight compositional constraint for hierarchical relations and evaluate on three benchmarks and an industry dataset.\nRelated Work\n\nEnsuring safety during reinforcement learning is critical in real-world control where violations can be costly. Research has proposed both objective-level and mechanism-level solutions.\n\nSafe reinforcement learning approaches include risk-sensitive objectives such as CVaR optimization (Tamar et al., 2015; Chow et al., 2018), constrained policy optimization with safety budgets (Achiam et al., 2017; Yang et al., 2020), and shielding based on model-checking or supervisors (Alshiekh et al., 2018; Dalal et al., 2018). We develop a method that integrates model-predictive constraints with policy gradients.\n\nBenchmarks often evaluate safety in simulated robotics or navigation with cost functions approximating constraint violations (Ray et al., 2019; Bharadhwaj et al., 2021).\nRelated Work\n\nDialog state tracking (DST) has evolved from rule-based slot filling to neural architectures that jointly infer belief states across turns. Early pipeline models used hand-crafted lexicons and semantic frames (Singh and Patel, 2015), but suffered from brittleness to paraphrase and noise. Neural encoders introduced robustness by contextualizing utterances, incorporating attention over dialog history, and modeling slot-value dependencies (Lee et al., 2018; Choe and Kim, 2019).\n\nPretrained language models have further shifted the landscape by enabling few-shot generalization and open-vocabulary slot values. Fine-tuning BERT-like encoders for DST improved cross-domain transfer (Rao et al., 2020), while generative formulations cast state tracking as text-to-text prediction (Mendez et al., 2021).\n\nPrompting-based approaches have also been explored for dialog modeling (Kumar et al., 2021; Ortega and Lin, 2022; Park et al., 2023). These methods condition large language models on task instructions or few-shot exemplars to elicit latent conversational knowledge. Recent variants incorporate calibration or self-consistency to stabilize outputs (Fang et al., 2023; Zhou et al., 2023).\n\nPosition relative to this paper While we also employ pretrained sequence-to-sequence models, our focus is on handling ontology drift in long-running deployments. Specifically, we introduce an adaptive slot schema encoder that aligns evolving taxonomies with dialog evidence, and a contrastive consistency objective to mitigate spurious slot co-activations across domains.\nIntroduction\n\nSelf-supervised learning (SSL) has become the dominant paradigm for learning transferable visual features without labels. By constructing pretext tasks that expose invariances and structure inherent in data, SSL models can match or surpass supervised baselines on many downstream tasks.\n\nContrastive pretraining has been widely adopted for visual representations (Chen et al., 2020; He et al., 2020; Xie and Xu, 2021). Non-contrastive methods remove negative pairs and rely on architectural or objective asymmetries (Grill et al., 2020; Tian et al., 2021). Clustering-based methods jointly learn assignments and embeddings (Caron et al., 2018; Li and Gao, 2022).\n\nDespite these advances, industrial applications often operate under strict memory budgets and latency constraints. In this paper, we investigate compute-aware pretraining objectives that couple multi-crop augmentation with a token-subsampled backbone. We present a latency-regularized alignment loss that preserves downstream accuracy while reducing FLOPs during both pretraining and fine-tuning.\nIntroduction\n\nEfficient exploration remains a central challenge in reinforcement learning (RL), particularly in sparse-reward environments where naive strategies fail to discover rewarding states. Over-exploration, however, can waste samples and destabilize learning.\n\nExploration in reinforcement learning has been advanced by count-based bonuses, intrinsic motivation, curiosity-driven prediction error, and information-theoretic objectives (Bellemare et al., 2016; Pathak et al., 2017; Houthooft et al., 2016; Burda et al., 2019; Ta\u00efga et al., 2020).\n\nYet, when environment dynamics change over time, stale novelty estimates can encourage revisiting obsolete states. We propose a recency-aware intrinsic reward that discounts outdated novelty and couples it with conservative policy updates.\n\nAcross Atari and continuous-control domains with drifting dynamics, our method achieves superior sample efficiency and stability, and ablations confirm the role of recency in balancing exploration and exploitation.\nRelated Work\n\nDetecting anomalies in multivariate time series is vital for monitoring industrial systems and cloud services. The challenge lies in handling seasonality, rare events, and inter-variable dependencies.\n\nClassical anomaly detection leverages ARIMA residual tests, STL decomposition, and control charts, while deep methods introduce autoencoders, VAEs, GANs, LSTMs, and Transformers for reconstruction or prediction errors (Tsay, 2010; Malhotra et al., 2015; An and Cho, 2015; Li et al., 2019; Xu et al., 2021).\n\nWe present Contrastive Forecasting with Graph Priors (CFGP), which learns structure-aware representations via self-supervised objectives and uses calibrated predictive intervals to flag anomalies.\nIntroduction\n\nGeneralizing manipulation skills across objects, tasks, and environments remains a central challenge in robotics. Sparse rewards, safety constraints, and hardware variability complicate learning on physical systems. Recent work studies imitation learning, offline RL, and model-based control for dexterous manipulation (Rajeswaran et al., 2018; Lynch et al., 2020; Nagabandi et al., 2019; Ahn et al., 2022). Despite these advances, scaling data collection and ensuring sim-to-real transfer continue to be bottlenecks.\n\nWe explore a curriculum that interleaves skill discovery from teleoperation logs with conservative online updates, targeting stable improvements under limited interaction budgets.\n",
        "completion": "Recent work studies imitation learning, offline RL, and model-based control for dexterous manipulation (Rajeswaran et al., 2018; Lynch et al., 2020; Nagabandi et al., 2019; Ahn et al., 2022)."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        occurs when either:\n    a) The author describes or cites papers without connecting them to their own work/argument \n    b) Or only follows up the summary of previous works with their own contribution without explicitly highlighting the gap their work intends to research.\n    c) It does not articulate the author's perspective or motivation.\n    d) A lack of argument/opinion in the first paragraph is permissible as it serves to be the foundation of the author's argument \n    e) Lacks synthesis issues appear either as single sentences or multiple sentences.\n    Examples of lack of synthesis include:\n        i) No elaboration of own contribution/argument:\"Following early neural approaches to question answering, many subsequent studies adopt a pipeline architecture consisting of retrieval and comprehension components. The retrieval component focuses on identifying relevant documents or passages from a large corpus, while the comprehension component extracts an answer span from the retrieved text. Initial models relied on recurrent neural networks with attention mechanisms to encode questions and contexts (Seo et al., 2017; Wang et al., 2017).\"\n        ii)  No explanation of the cited works and relation to their own work: \u201cRecently, several studies have explored the use of prompting techniques with pre-trained language models to influence model outputs or access latent knowledge (Brown et al., 2020; Gao et al., 2021; Liu et al., 2021; Wei et al., 2022).\u201d \n\n        Example text: \n        Related Work\n\nDevelopers rely on code search to find relevant snippets, APIs, or examples. Unlike general document retrieval, code search must bridge natural language intent and program structure.\n\nNeural code search has been addressed with bi-encoders, cross-encoders, and dual learning (Gu et al., 2018; Husain et al., 2019; Feng et al., 2020). Structural representations incorporate ASTs, control flow, and data flow (Alon et al., 2019; Wang et al., 2020; Liu et al., 2021). Pretraining on code and NL improves retrieval metrics across languages (Ahmad et al., 2021; Guo et al., 2021).\n\nIn this paper, we introduce a language-agnostic retriever with compositional queries.\n\nWe evaluate zero-shot transfer across four programming languages.\nIntroduction\n\nGeneralization in text classification can be improved with data augmentation, especially when labeled data are scarce or imbalanced. Approaches range from rule-based edits to model-driven paraphrasing and representation-space mixing.\n\nText augmentation techniques include synonym replacement, random insertion/deletion, back-translation, paraphrase generation, and mixup in embedding or hidden spaces (Wei and Zou, 2019; Sennrich et al., 2016; Kobayashi, 2018; Guo et al., 2020). Recent work explores task-adaptive augmentation policies learned by reinforcement learning (Xie et al., 2020).\n\nEvaluation typically considers robustness to domain shift, label noise, and distributional skew across multiple benchmarks (Pruksachatkun et al., 2020; Hendrycks et al., 2020).\nRelated Work\n\nKnowledge graph completion predicts missing links by learning entity and relation representations. Methods vary in how they encode semantics and handle patterns like symmetry, hierarchy, and composition.\n\nTranslation-based knowledge graph embeddings model relations as translations in vector space (Bordes et al., 2013; Wang et al., 2014), while bilinear and neural models capture more complex interactions (Nickel et al., 2011; Trouillon et al., 2016; Sun et al., 2019). Regularization and rule-guided approaches improve inductive bias and data efficiency (Rockt\u00e4schel et al., 2015; Minervini et al., 2017).\n\nWe introduce a lightweight compositional constraint for hierarchical relations and evaluate on three benchmarks and an industry dataset.\nRelated Work\n\nEnsuring safety during reinforcement learning is critical in real-world control where violations can be costly. Research has proposed both objective-level and mechanism-level solutions.\n\nSafe reinforcement learning approaches include risk-sensitive objectives such as CVaR optimization (Tamar et al., 2015; Chow et al., 2018), constrained policy optimization with safety budgets (Achiam et al., 2017; Yang et al., 2020), and shielding based on model-checking or supervisors (Alshiekh et al., 2018; Dalal et al., 2018). We develop a method that integrates model-predictive constraints with policy gradients.\n\nBenchmarks often evaluate safety in simulated robotics or navigation with cost functions approximating constraint violations (Ray et al., 2019; Bharadhwaj et al., 2021).\nRelated Work\n\nDialog state tracking (DST) has evolved from rule-based slot filling to neural architectures that jointly infer belief states across turns. Early pipeline models used hand-crafted lexicons and semantic frames (Singh and Patel, 2015), but suffered from brittleness to paraphrase and noise. Neural encoders introduced robustness by contextualizing utterances, incorporating attention over dialog history, and modeling slot-value dependencies (Lee et al., 2018; Choe and Kim, 2019).\n\nPretrained language models have further shifted the landscape by enabling few-shot generalization and open-vocabulary slot values. Fine-tuning BERT-like encoders for DST improved cross-domain transfer (Rao et al., 2020), while generative formulations cast state tracking as text-to-text prediction (Mendez et al., 2021).\n\nPrompting-based approaches have also been explored for dialog modeling (Kumar et al., 2021; Ortega and Lin, 2022; Park et al., 2023). These methods condition large language models on task instructions or few-shot exemplars to elicit latent conversational knowledge. Recent variants incorporate calibration or self-consistency to stabilize outputs (Fang et al., 2023; Zhou et al., 2023).\n\nPosition relative to this paper While we also employ pretrained sequence-to-sequence models, our focus is on handling ontology drift in long-running deployments. Specifically, we introduce an adaptive slot schema encoder that aligns evolving taxonomies with dialog evidence, and a contrastive consistency objective to mitigate spurious slot co-activations across domains.\nIntroduction\n\nSelf-supervised learning (SSL) has become the dominant paradigm for learning transferable visual features without labels. By constructing pretext tasks that expose invariances and structure inherent in data, SSL models can match or surpass supervised baselines on many downstream tasks.\n\nContrastive pretraining has been widely adopted for visual representations (Chen et al., 2020; He et al., 2020; Xie and Xu, 2021). Non-contrastive methods remove negative pairs and rely on architectural or objective asymmetries (Grill et al., 2020; Tian et al., 2021). Clustering-based methods jointly learn assignments and embeddings (Caron et al., 2018; Li and Gao, 2022).\n\nDespite these advances, industrial applications often operate under strict memory budgets and latency constraints. In this paper, we investigate compute-aware pretraining objectives that couple multi-crop augmentation with a token-subsampled backbone. We present a latency-regularized alignment loss that preserves downstream accuracy while reducing FLOPs during both pretraining and fine-tuning.\nIntroduction\n\nEfficient exploration remains a central challenge in reinforcement learning (RL), particularly in sparse-reward environments where naive strategies fail to discover rewarding states. Over-exploration, however, can waste samples and destabilize learning.\n\nExploration in reinforcement learning has been advanced by count-based bonuses, intrinsic motivation, curiosity-driven prediction error, and information-theoretic objectives (Bellemare et al., 2016; Pathak et al., 2017; Houthooft et al., 2016; Burda et al., 2019; Ta\u00efga et al., 2020).\n\nYet, when environment dynamics change over time, stale novelty estimates can encourage revisiting obsolete states. We propose a recency-aware intrinsic reward that discounts outdated novelty and couples it with conservative policy updates.\n\nAcross Atari and continuous-control domains with drifting dynamics, our method achieves superior sample efficiency and stability, and ablations confirm the role of recency in balancing exploration and exploitation.\nRelated Work\n\nDetecting anomalies in multivariate time series is vital for monitoring industrial systems and cloud services. The challenge lies in handling seasonality, rare events, and inter-variable dependencies.\n\nClassical anomaly detection leverages ARIMA residual tests, STL decomposition, and control charts, while deep methods introduce autoencoders, VAEs, GANs, LSTMs, and Transformers for reconstruction or prediction errors (Tsay, 2010; Malhotra et al., 2015; An and Cho, 2015; Li et al., 2019; Xu et al., 2021).\n\nWe present Contrastive Forecasting with Graph Priors (CFGP), which learns structure-aware representations via self-supervised objectives and uses calibrated predictive intervals to flag anomalies.\nIntroduction\n\nGeneralizing manipulation skills across objects, tasks, and environments remains a central challenge in robotics. Sparse rewards, safety constraints, and hardware variability complicate learning on physical systems. Recent work studies imitation learning, offline RL, and model-based control for dexterous manipulation (Rajeswaran et al., 2018; Lynch et al., 2020; Nagabandi et al., 2019; Ahn et al., 2022). Despite these advances, scaling data collection and ensuring sim-to-real transfer continue to be bottlenecks.\n\nWe explore a curriculum that interleaves skill discovery from teleoperation logs with conservative online updates, targeting stable improvements under limited interaction budgets.\nRelated Work\n\nConversational recommenders. Systems that interactively elicit user preferences can reduce cold-start and improve satisfaction (Sun and Zhang, 2018). Dialog policy learning for conversational recommendation has explored supervised learning, reinforcement learning, and bandit methods (Christakopoulou et al., 2016; Lei et al., 2020; Chen et al., 2019). User simulators and counterfactual logging have been proposed to address data scarcity and evaluation challenges (Li et al., 2017; Chi et al., 2020).\n\nOur study investigates preference drift over long-horizon sessions and proposes a state representation that explicitly tracks uncertainty and recency effects.\n",
        "completion": "Dialog policy learning for conversational recommendation has explored supervised learning, reinforcement learning, and bandit methods (Christakopoulou et al., 2016; Lei et al., 2020; Chen et al., 2019)."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        occurs when either:\n    a) The author describes or cites papers without connecting them to their own work/argument \n    b) Or only follows up the summary of previous works with their own contribution without explicitly highlighting the gap their work intends to research.\n    c) It does not articulate the author's perspective or motivation.\n    d) A lack of argument/opinion in the first paragraph is permissible as it serves to be the foundation of the author's argument \n    e) Lacks synthesis issues appear either as single sentences or multiple sentences.\n    Examples of lack of synthesis include:\n        i) No elaboration of own contribution/argument:\"Following early neural approaches to question answering, many subsequent studies adopt a pipeline architecture consisting of retrieval and comprehension components. The retrieval component focuses on identifying relevant documents or passages from a large corpus, while the comprehension component extracts an answer span from the retrieved text. Initial models relied on recurrent neural networks with attention mechanisms to encode questions and contexts (Seo et al., 2017; Wang et al., 2017).\"\n        ii)  No explanation of the cited works and relation to their own work: \u201cRecently, several studies have explored the use of prompting techniques with pre-trained language models to influence model outputs or access latent knowledge (Brown et al., 2020; Gao et al., 2021; Liu et al., 2021; Wei et al., 2022).\u201d \n\n        Example text: \n        Related Work\n\nDevelopers rely on code search to find relevant snippets, APIs, or examples. Unlike general document retrieval, code search must bridge natural language intent and program structure.\n\nNeural code search has been addressed with bi-encoders, cross-encoders, and dual learning (Gu et al., 2018; Husain et al., 2019; Feng et al., 2020). Structural representations incorporate ASTs, control flow, and data flow (Alon et al., 2019; Wang et al., 2020; Liu et al., 2021). Pretraining on code and NL improves retrieval metrics across languages (Ahmad et al., 2021; Guo et al., 2021).\n\nIn this paper, we introduce a language-agnostic retriever with compositional queries.\n\nWe evaluate zero-shot transfer across four programming languages.\nIntroduction\n\nGeneralization in text classification can be improved with data augmentation, especially when labeled data are scarce or imbalanced. Approaches range from rule-based edits to model-driven paraphrasing and representation-space mixing.\n\nText augmentation techniques include synonym replacement, random insertion/deletion, back-translation, paraphrase generation, and mixup in embedding or hidden spaces (Wei and Zou, 2019; Sennrich et al., 2016; Kobayashi, 2018; Guo et al., 2020). Recent work explores task-adaptive augmentation policies learned by reinforcement learning (Xie et al., 2020).\n\nEvaluation typically considers robustness to domain shift, label noise, and distributional skew across multiple benchmarks (Pruksachatkun et al., 2020; Hendrycks et al., 2020).\nRelated Work\n\nKnowledge graph completion predicts missing links by learning entity and relation representations. Methods vary in how they encode semantics and handle patterns like symmetry, hierarchy, and composition.\n\nTranslation-based knowledge graph embeddings model relations as translations in vector space (Bordes et al., 2013; Wang et al., 2014), while bilinear and neural models capture more complex interactions (Nickel et al., 2011; Trouillon et al., 2016; Sun et al., 2019). Regularization and rule-guided approaches improve inductive bias and data efficiency (Rockt\u00e4schel et al., 2015; Minervini et al., 2017).\n\nWe introduce a lightweight compositional constraint for hierarchical relations and evaluate on three benchmarks and an industry dataset.\nRelated Work\n\nEnsuring safety during reinforcement learning is critical in real-world control where violations can be costly. Research has proposed both objective-level and mechanism-level solutions.\n\nSafe reinforcement learning approaches include risk-sensitive objectives such as CVaR optimization (Tamar et al., 2015; Chow et al., 2018), constrained policy optimization with safety budgets (Achiam et al., 2017; Yang et al., 2020), and shielding based on model-checking or supervisors (Alshiekh et al., 2018; Dalal et al., 2018). We develop a method that integrates model-predictive constraints with policy gradients.\n\nBenchmarks often evaluate safety in simulated robotics or navigation with cost functions approximating constraint violations (Ray et al., 2019; Bharadhwaj et al., 2021).\nRelated Work\n\nDialog state tracking (DST) has evolved from rule-based slot filling to neural architectures that jointly infer belief states across turns. Early pipeline models used hand-crafted lexicons and semantic frames (Singh and Patel, 2015), but suffered from brittleness to paraphrase and noise. Neural encoders introduced robustness by contextualizing utterances, incorporating attention over dialog history, and modeling slot-value dependencies (Lee et al., 2018; Choe and Kim, 2019).\n\nPretrained language models have further shifted the landscape by enabling few-shot generalization and open-vocabulary slot values. Fine-tuning BERT-like encoders for DST improved cross-domain transfer (Rao et al., 2020), while generative formulations cast state tracking as text-to-text prediction (Mendez et al., 2021).\n\nPrompting-based approaches have also been explored for dialog modeling (Kumar et al., 2021; Ortega and Lin, 2022; Park et al., 2023). These methods condition large language models on task instructions or few-shot exemplars to elicit latent conversational knowledge. Recent variants incorporate calibration or self-consistency to stabilize outputs (Fang et al., 2023; Zhou et al., 2023).\n\nPosition relative to this paper While we also employ pretrained sequence-to-sequence models, our focus is on handling ontology drift in long-running deployments. Specifically, we introduce an adaptive slot schema encoder that aligns evolving taxonomies with dialog evidence, and a contrastive consistency objective to mitigate spurious slot co-activations across domains.\nIntroduction\n\nSelf-supervised learning (SSL) has become the dominant paradigm for learning transferable visual features without labels. By constructing pretext tasks that expose invariances and structure inherent in data, SSL models can match or surpass supervised baselines on many downstream tasks.\n\nContrastive pretraining has been widely adopted for visual representations (Chen et al., 2020; He et al., 2020; Xie and Xu, 2021). Non-contrastive methods remove negative pairs and rely on architectural or objective asymmetries (Grill et al., 2020; Tian et al., 2021). Clustering-based methods jointly learn assignments and embeddings (Caron et al., 2018; Li and Gao, 2022).\n\nDespite these advances, industrial applications often operate under strict memory budgets and latency constraints. In this paper, we investigate compute-aware pretraining objectives that couple multi-crop augmentation with a token-subsampled backbone. We present a latency-regularized alignment loss that preserves downstream accuracy while reducing FLOPs during both pretraining and fine-tuning.\nIntroduction\n\nEfficient exploration remains a central challenge in reinforcement learning (RL), particularly in sparse-reward environments where naive strategies fail to discover rewarding states. Over-exploration, however, can waste samples and destabilize learning.\n\nExploration in reinforcement learning has been advanced by count-based bonuses, intrinsic motivation, curiosity-driven prediction error, and information-theoretic objectives (Bellemare et al., 2016; Pathak et al., 2017; Houthooft et al., 2016; Burda et al., 2019; Ta\u00efga et al., 2020).\n\nYet, when environment dynamics change over time, stale novelty estimates can encourage revisiting obsolete states. We propose a recency-aware intrinsic reward that discounts outdated novelty and couples it with conservative policy updates.\n\nAcross Atari and continuous-control domains with drifting dynamics, our method achieves superior sample efficiency and stability, and ablations confirm the role of recency in balancing exploration and exploitation.\nRelated Work\n\nDetecting anomalies in multivariate time series is vital for monitoring industrial systems and cloud services. The challenge lies in handling seasonality, rare events, and inter-variable dependencies.\n\nClassical anomaly detection leverages ARIMA residual tests, STL decomposition, and control charts, while deep methods introduce autoencoders, VAEs, GANs, LSTMs, and Transformers for reconstruction or prediction errors (Tsay, 2010; Malhotra et al., 2015; An and Cho, 2015; Li et al., 2019; Xu et al., 2021).\n\nWe present Contrastive Forecasting with Graph Priors (CFGP), which learns structure-aware representations via self-supervised objectives and uses calibrated predictive intervals to flag anomalies.\nIntroduction\n\nGeneralizing manipulation skills across objects, tasks, and environments remains a central challenge in robotics. Sparse rewards, safety constraints, and hardware variability complicate learning on physical systems. Recent work studies imitation learning, offline RL, and model-based control for dexterous manipulation (Rajeswaran et al., 2018; Lynch et al., 2020; Nagabandi et al., 2019; Ahn et al., 2022). Despite these advances, scaling data collection and ensuring sim-to-real transfer continue to be bottlenecks.\n\nWe explore a curriculum that interleaves skill discovery from teleoperation logs with conservative online updates, targeting stable improvements under limited interaction budgets.\nRelated Work\n\nConversational recommenders. Systems that interactively elicit user preferences can reduce cold-start and improve satisfaction (Sun and Zhang, 2018). Dialog policy learning for conversational recommendation has explored supervised learning, reinforcement learning, and bandit methods (Christakopoulou et al., 2016; Lei et al., 2020; Chen et al., 2019). User simulators and counterfactual logging have been proposed to address data scarcity and evaluation challenges (Li et al., 2017; Chi et al., 2020).\n\nOur study investigates preference drift over long-horizon sessions and proposes a state representation that explicitly tracks uncertainty and recency effects.\nIntroduction\n\nExplainable AI (XAI) is increasingly required for medical imaging systems used in screening and triage. Beyond predictive accuracy, clinicians demand transparency about what image features drive automated decisions and whether explanations are stable under shifts.\n\nPost-hoc attribution methods like Grad-CAM and Integrated Gradients highlight salient regions (Selvaraju et al., 2017; Sundararajan et al., 2017). Prototype- and concept-based explanations enhance interpretability (Chen et al., 2019; Kim et al., 2018). Counterfactual generation has been explored for medical images (Chang et al., 2018; Singla et al., 2021).\n\nWe focus on faithfulness under distribution shift and propose an evaluation protocol that aligns explanation stability with clinical acceptance thresholds for screening workflows.\n",
        "completion": "Post-hoc attribution methods like Grad-CAM and Integrated Gradients highlight salient regions (Selvaraju et al., 2017; Sundararajan et al., 2017). Prototype- and concept-based explanations enhance interpretability (Chen et al., 2019; Kim et al., 2018). Counterfactual generation has been explored for medical images (Chang et al., 2018; Singla et al., 2021)."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        occurs when either:\n    a) The author describes or cites papers without connecting them to their own work/argument \n    b) Or only follows up the summary of previous works with their own contribution without explicitly highlighting the gap their work intends to research.\n    c) It does not articulate the author's perspective or motivation.\n    d) A lack of argument/opinion in the first paragraph is permissible as it serves to be the foundation of the author's argument \n    e) Lacks synthesis issues appear either as single sentences or multiple sentences.\n    Examples of lack of synthesis include:\n        i) No elaboration of own contribution/argument:\"Following early neural approaches to question answering, many subsequent studies adopt a pipeline architecture consisting of retrieval and comprehension components. The retrieval component focuses on identifying relevant documents or passages from a large corpus, while the comprehension component extracts an answer span from the retrieved text. Initial models relied on recurrent neural networks with attention mechanisms to encode questions and contexts (Seo et al., 2017; Wang et al., 2017).\"\n        ii)  No explanation of the cited works and relation to their own work: \u201cRecently, several studies have explored the use of prompting techniques with pre-trained language models to influence model outputs or access latent knowledge (Brown et al., 2020; Gao et al., 2021; Liu et al., 2021; Wei et al., 2022).\u201d \n\n        Example text: \n        Related Work\n\nDevelopers rely on code search to find relevant snippets, APIs, or examples. Unlike general document retrieval, code search must bridge natural language intent and program structure.\n\nNeural code search has been addressed with bi-encoders, cross-encoders, and dual learning (Gu et al., 2018; Husain et al., 2019; Feng et al., 2020). Structural representations incorporate ASTs, control flow, and data flow (Alon et al., 2019; Wang et al., 2020; Liu et al., 2021). Pretraining on code and NL improves retrieval metrics across languages (Ahmad et al., 2021; Guo et al., 2021).\n\nIn this paper, we introduce a language-agnostic retriever with compositional queries.\n\nWe evaluate zero-shot transfer across four programming languages.\nIntroduction\n\nGeneralization in text classification can be improved with data augmentation, especially when labeled data are scarce or imbalanced. Approaches range from rule-based edits to model-driven paraphrasing and representation-space mixing.\n\nText augmentation techniques include synonym replacement, random insertion/deletion, back-translation, paraphrase generation, and mixup in embedding or hidden spaces (Wei and Zou, 2019; Sennrich et al., 2016; Kobayashi, 2018; Guo et al., 2020). Recent work explores task-adaptive augmentation policies learned by reinforcement learning (Xie et al., 2020).\n\nEvaluation typically considers robustness to domain shift, label noise, and distributional skew across multiple benchmarks (Pruksachatkun et al., 2020; Hendrycks et al., 2020).\nRelated Work\n\nKnowledge graph completion predicts missing links by learning entity and relation representations. Methods vary in how they encode semantics and handle patterns like symmetry, hierarchy, and composition.\n\nTranslation-based knowledge graph embeddings model relations as translations in vector space (Bordes et al., 2013; Wang et al., 2014), while bilinear and neural models capture more complex interactions (Nickel et al., 2011; Trouillon et al., 2016; Sun et al., 2019). Regularization and rule-guided approaches improve inductive bias and data efficiency (Rockt\u00e4schel et al., 2015; Minervini et al., 2017).\n\nWe introduce a lightweight compositional constraint for hierarchical relations and evaluate on three benchmarks and an industry dataset.\nRelated Work\n\nEnsuring safety during reinforcement learning is critical in real-world control where violations can be costly. Research has proposed both objective-level and mechanism-level solutions.\n\nSafe reinforcement learning approaches include risk-sensitive objectives such as CVaR optimization (Tamar et al., 2015; Chow et al., 2018), constrained policy optimization with safety budgets (Achiam et al., 2017; Yang et al., 2020), and shielding based on model-checking or supervisors (Alshiekh et al., 2018; Dalal et al., 2018). We develop a method that integrates model-predictive constraints with policy gradients.\n\nBenchmarks often evaluate safety in simulated robotics or navigation with cost functions approximating constraint violations (Ray et al., 2019; Bharadhwaj et al., 2021).\nRelated Work\n\nDialog state tracking (DST) has evolved from rule-based slot filling to neural architectures that jointly infer belief states across turns. Early pipeline models used hand-crafted lexicons and semantic frames (Singh and Patel, 2015), but suffered from brittleness to paraphrase and noise. Neural encoders introduced robustness by contextualizing utterances, incorporating attention over dialog history, and modeling slot-value dependencies (Lee et al., 2018; Choe and Kim, 2019).\n\nPretrained language models have further shifted the landscape by enabling few-shot generalization and open-vocabulary slot values. Fine-tuning BERT-like encoders for DST improved cross-domain transfer (Rao et al., 2020), while generative formulations cast state tracking as text-to-text prediction (Mendez et al., 2021).\n\nPrompting-based approaches have also been explored for dialog modeling (Kumar et al., 2021; Ortega and Lin, 2022; Park et al., 2023). These methods condition large language models on task instructions or few-shot exemplars to elicit latent conversational knowledge. Recent variants incorporate calibration or self-consistency to stabilize outputs (Fang et al., 2023; Zhou et al., 2023).\n\nPosition relative to this paper While we also employ pretrained sequence-to-sequence models, our focus is on handling ontology drift in long-running deployments. Specifically, we introduce an adaptive slot schema encoder that aligns evolving taxonomies with dialog evidence, and a contrastive consistency objective to mitigate spurious slot co-activations across domains.\nIntroduction\n\nSelf-supervised learning (SSL) has become the dominant paradigm for learning transferable visual features without labels. By constructing pretext tasks that expose invariances and structure inherent in data, SSL models can match or surpass supervised baselines on many downstream tasks.\n\nContrastive pretraining has been widely adopted for visual representations (Chen et al., 2020; He et al., 2020; Xie and Xu, 2021). Non-contrastive methods remove negative pairs and rely on architectural or objective asymmetries (Grill et al., 2020; Tian et al., 2021). Clustering-based methods jointly learn assignments and embeddings (Caron et al., 2018; Li and Gao, 2022).\n\nDespite these advances, industrial applications often operate under strict memory budgets and latency constraints. In this paper, we investigate compute-aware pretraining objectives that couple multi-crop augmentation with a token-subsampled backbone. We present a latency-regularized alignment loss that preserves downstream accuracy while reducing FLOPs during both pretraining and fine-tuning.\nIntroduction\n\nEfficient exploration remains a central challenge in reinforcement learning (RL), particularly in sparse-reward environments where naive strategies fail to discover rewarding states. Over-exploration, however, can waste samples and destabilize learning.\n\nExploration in reinforcement learning has been advanced by count-based bonuses, intrinsic motivation, curiosity-driven prediction error, and information-theoretic objectives (Bellemare et al., 2016; Pathak et al., 2017; Houthooft et al., 2016; Burda et al., 2019; Ta\u00efga et al., 2020).\n\nYet, when environment dynamics change over time, stale novelty estimates can encourage revisiting obsolete states. We propose a recency-aware intrinsic reward that discounts outdated novelty and couples it with conservative policy updates.\n\nAcross Atari and continuous-control domains with drifting dynamics, our method achieves superior sample efficiency and stability, and ablations confirm the role of recency in balancing exploration and exploitation.\nRelated Work\n\nDetecting anomalies in multivariate time series is vital for monitoring industrial systems and cloud services. The challenge lies in handling seasonality, rare events, and inter-variable dependencies.\n\nClassical anomaly detection leverages ARIMA residual tests, STL decomposition, and control charts, while deep methods introduce autoencoders, VAEs, GANs, LSTMs, and Transformers for reconstruction or prediction errors (Tsay, 2010; Malhotra et al., 2015; An and Cho, 2015; Li et al., 2019; Xu et al., 2021).\n\nWe present Contrastive Forecasting with Graph Priors (CFGP), which learns structure-aware representations via self-supervised objectives and uses calibrated predictive intervals to flag anomalies.\nIntroduction\n\nGeneralizing manipulation skills across objects, tasks, and environments remains a central challenge in robotics. Sparse rewards, safety constraints, and hardware variability complicate learning on physical systems. Recent work studies imitation learning, offline RL, and model-based control for dexterous manipulation (Rajeswaran et al., 2018; Lynch et al., 2020; Nagabandi et al., 2019; Ahn et al., 2022). Despite these advances, scaling data collection and ensuring sim-to-real transfer continue to be bottlenecks.\n\nWe explore a curriculum that interleaves skill discovery from teleoperation logs with conservative online updates, targeting stable improvements under limited interaction budgets.\nRelated Work\n\nConversational recommenders. Systems that interactively elicit user preferences can reduce cold-start and improve satisfaction (Sun and Zhang, 2018). Dialog policy learning for conversational recommendation has explored supervised learning, reinforcement learning, and bandit methods (Christakopoulou et al., 2016; Lei et al., 2020; Chen et al., 2019). User simulators and counterfactual logging have been proposed to address data scarcity and evaluation challenges (Li et al., 2017; Chi et al., 2020).\n\nOur study investigates preference drift over long-horizon sessions and proposes a state representation that explicitly tracks uncertainty and recency effects.\nIntroduction\n\nExplainable AI (XAI) is increasingly required for medical imaging systems used in screening and triage. Beyond predictive accuracy, clinicians demand transparency about what image features drive automated decisions and whether explanations are stable under shifts.\n\nPost-hoc attribution methods like Grad-CAM and Integrated Gradients highlight salient regions (Selvaraju et al., 2017; Sundararajan et al., 2017). Prototype- and concept-based explanations enhance interpretability (Chen et al., 2019; Kim et al., 2018). Counterfactual generation has been explored for medical images (Chang et al., 2018; Singla et al., 2021).\n\nWe focus on faithfulness under distribution shift and propose an evaluation protocol that aligns explanation stability with clinical acceptance thresholds for screening workflows.\nRelated Work\n\nProviding timely, actionable feedback at scale is central to computing education. Traditional approaches combine instructor-designed rubrics with automated tests, but coverage and specificity can be limited for diverse student solutions.\n\nAutomated feedback for programming assignments has been tackled with static analysis, dynamic test generation, and pattern mining (Ke et al., 2016; Gulwani et al., 2018; Singh et al., 2013). Recent NLP-based systems leverage code embeddings, sequence models, and pretrained language models (Allamanis et al., 2018; Feng et al., 2020; Ahmad et al., 2021). Peer learning platforms collect hints and exemplars to guide novice programmers (Piech et al., 2015; Wang et al., 2018).\n\nWhile data-driven approaches show promise, they often struggle with generalizing across tasks and providing pedagogically aligned guidance. Our work investigates structure-aware hint generation that aligns feedback to conceptual steps in problem-solving.\n",
        "completion": "Automated feedback for programming assignments has been tackled with static analysis, dynamic test generation, and pattern mining (Ke et al., 2016; Gulwani et al., 2018; Singh et al., 2013). Recent NLP-based systems leverage code embeddings, sequence models, and pretrained language models (Allamanis et al., 2018; Feng et al., 2020; Ahmad et al., 2021). Peer learning platforms collect hints and exemplars to guide novice programmers (Piech et al., 2015; Wang et al., 2018)."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        occurs when either:\n    a) The author describes or cites papers without connecting them to their own work/argument \n    b) Or only follows up the summary of previous works with their own contribution without explicitly highlighting the gap their work intends to research.\n    c) It does not articulate the author's perspective or motivation.\n    d) A lack of argument/opinion in the first paragraph is permissible as it serves to be the foundation of the author's argument \n    e) Lacks synthesis issues appear either as single sentences or multiple sentences.\n    Examples of lack of synthesis include:\n        i) No elaboration of own contribution/argument:\"Following early neural approaches to question answering, many subsequent studies adopt a pipeline architecture consisting of retrieval and comprehension components. The retrieval component focuses on identifying relevant documents or passages from a large corpus, while the comprehension component extracts an answer span from the retrieved text. Initial models relied on recurrent neural networks with attention mechanisms to encode questions and contexts (Seo et al., 2017; Wang et al., 2017).\"\n        ii)  No explanation of the cited works and relation to their own work: \u201cRecently, several studies have explored the use of prompting techniques with pre-trained language models to influence model outputs or access latent knowledge (Brown et al., 2020; Gao et al., 2021; Liu et al., 2021; Wei et al., 2022).\u201d \n\n        Example text: \n        Related Work\n\nDevelopers rely on code search to find relevant snippets, APIs, or examples. Unlike general document retrieval, code search must bridge natural language intent and program structure.\n\nNeural code search has been addressed with bi-encoders, cross-encoders, and dual learning (Gu et al., 2018; Husain et al., 2019; Feng et al., 2020). Structural representations incorporate ASTs, control flow, and data flow (Alon et al., 2019; Wang et al., 2020; Liu et al., 2021). Pretraining on code and NL improves retrieval metrics across languages (Ahmad et al., 2021; Guo et al., 2021).\n\nIn this paper, we introduce a language-agnostic retriever with compositional queries.\n\nWe evaluate zero-shot transfer across four programming languages.\nIntroduction\n\nGeneralization in text classification can be improved with data augmentation, especially when labeled data are scarce or imbalanced. Approaches range from rule-based edits to model-driven paraphrasing and representation-space mixing.\n\nText augmentation techniques include synonym replacement, random insertion/deletion, back-translation, paraphrase generation, and mixup in embedding or hidden spaces (Wei and Zou, 2019; Sennrich et al., 2016; Kobayashi, 2018; Guo et al., 2020). Recent work explores task-adaptive augmentation policies learned by reinforcement learning (Xie et al., 2020).\n\nEvaluation typically considers robustness to domain shift, label noise, and distributional skew across multiple benchmarks (Pruksachatkun et al., 2020; Hendrycks et al., 2020).\nRelated Work\n\nKnowledge graph completion predicts missing links by learning entity and relation representations. Methods vary in how they encode semantics and handle patterns like symmetry, hierarchy, and composition.\n\nTranslation-based knowledge graph embeddings model relations as translations in vector space (Bordes et al., 2013; Wang et al., 2014), while bilinear and neural models capture more complex interactions (Nickel et al., 2011; Trouillon et al., 2016; Sun et al., 2019). Regularization and rule-guided approaches improve inductive bias and data efficiency (Rockt\u00e4schel et al., 2015; Minervini et al., 2017).\n\nWe introduce a lightweight compositional constraint for hierarchical relations and evaluate on three benchmarks and an industry dataset.\nRelated Work\n\nEnsuring safety during reinforcement learning is critical in real-world control where violations can be costly. Research has proposed both objective-level and mechanism-level solutions.\n\nSafe reinforcement learning approaches include risk-sensitive objectives such as CVaR optimization (Tamar et al., 2015; Chow et al., 2018), constrained policy optimization with safety budgets (Achiam et al., 2017; Yang et al., 2020), and shielding based on model-checking or supervisors (Alshiekh et al., 2018; Dalal et al., 2018). We develop a method that integrates model-predictive constraints with policy gradients.\n\nBenchmarks often evaluate safety in simulated robotics or navigation with cost functions approximating constraint violations (Ray et al., 2019; Bharadhwaj et al., 2021).\nRelated Work\n\nDialog state tracking (DST) has evolved from rule-based slot filling to neural architectures that jointly infer belief states across turns. Early pipeline models used hand-crafted lexicons and semantic frames (Singh and Patel, 2015), but suffered from brittleness to paraphrase and noise. Neural encoders introduced robustness by contextualizing utterances, incorporating attention over dialog history, and modeling slot-value dependencies (Lee et al., 2018; Choe and Kim, 2019).\n\nPretrained language models have further shifted the landscape by enabling few-shot generalization and open-vocabulary slot values. Fine-tuning BERT-like encoders for DST improved cross-domain transfer (Rao et al., 2020), while generative formulations cast state tracking as text-to-text prediction (Mendez et al., 2021).\n\nPrompting-based approaches have also been explored for dialog modeling (Kumar et al., 2021; Ortega and Lin, 2022; Park et al., 2023). These methods condition large language models on task instructions or few-shot exemplars to elicit latent conversational knowledge. Recent variants incorporate calibration or self-consistency to stabilize outputs (Fang et al., 2023; Zhou et al., 2023).\n\nPosition relative to this paper While we also employ pretrained sequence-to-sequence models, our focus is on handling ontology drift in long-running deployments. Specifically, we introduce an adaptive slot schema encoder that aligns evolving taxonomies with dialog evidence, and a contrastive consistency objective to mitigate spurious slot co-activations across domains.\nIntroduction\n\nSelf-supervised learning (SSL) has become the dominant paradigm for learning transferable visual features without labels. By constructing pretext tasks that expose invariances and structure inherent in data, SSL models can match or surpass supervised baselines on many downstream tasks.\n\nContrastive pretraining has been widely adopted for visual representations (Chen et al., 2020; He et al., 2020; Xie and Xu, 2021). Non-contrastive methods remove negative pairs and rely on architectural or objective asymmetries (Grill et al., 2020; Tian et al., 2021). Clustering-based methods jointly learn assignments and embeddings (Caron et al., 2018; Li and Gao, 2022).\n\nDespite these advances, industrial applications often operate under strict memory budgets and latency constraints. In this paper, we investigate compute-aware pretraining objectives that couple multi-crop augmentation with a token-subsampled backbone. We present a latency-regularized alignment loss that preserves downstream accuracy while reducing FLOPs during both pretraining and fine-tuning.\nIntroduction\n\nEfficient exploration remains a central challenge in reinforcement learning (RL), particularly in sparse-reward environments where naive strategies fail to discover rewarding states. Over-exploration, however, can waste samples and destabilize learning.\n\nExploration in reinforcement learning has been advanced by count-based bonuses, intrinsic motivation, curiosity-driven prediction error, and information-theoretic objectives (Bellemare et al., 2016; Pathak et al., 2017; Houthooft et al., 2016; Burda et al., 2019; Ta\u00efga et al., 2020).\n\nYet, when environment dynamics change over time, stale novelty estimates can encourage revisiting obsolete states. We propose a recency-aware intrinsic reward that discounts outdated novelty and couples it with conservative policy updates.\n\nAcross Atari and continuous-control domains with drifting dynamics, our method achieves superior sample efficiency and stability, and ablations confirm the role of recency in balancing exploration and exploitation.\nRelated Work\n\nDetecting anomalies in multivariate time series is vital for monitoring industrial systems and cloud services. The challenge lies in handling seasonality, rare events, and inter-variable dependencies.\n\nClassical anomaly detection leverages ARIMA residual tests, STL decomposition, and control charts, while deep methods introduce autoencoders, VAEs, GANs, LSTMs, and Transformers for reconstruction or prediction errors (Tsay, 2010; Malhotra et al., 2015; An and Cho, 2015; Li et al., 2019; Xu et al., 2021).\n\nWe present Contrastive Forecasting with Graph Priors (CFGP), which learns structure-aware representations via self-supervised objectives and uses calibrated predictive intervals to flag anomalies.\nIntroduction\n\nGeneralizing manipulation skills across objects, tasks, and environments remains a central challenge in robotics. Sparse rewards, safety constraints, and hardware variability complicate learning on physical systems. Recent work studies imitation learning, offline RL, and model-based control for dexterous manipulation (Rajeswaran et al., 2018; Lynch et al., 2020; Nagabandi et al., 2019; Ahn et al., 2022). Despite these advances, scaling data collection and ensuring sim-to-real transfer continue to be bottlenecks.\n\nWe explore a curriculum that interleaves skill discovery from teleoperation logs with conservative online updates, targeting stable improvements under limited interaction budgets.\nRelated Work\n\nConversational recommenders. Systems that interactively elicit user preferences can reduce cold-start and improve satisfaction (Sun and Zhang, 2018). Dialog policy learning for conversational recommendation has explored supervised learning, reinforcement learning, and bandit methods (Christakopoulou et al., 2016; Lei et al., 2020; Chen et al., 2019). User simulators and counterfactual logging have been proposed to address data scarcity and evaluation challenges (Li et al., 2017; Chi et al., 2020).\n\nOur study investigates preference drift over long-horizon sessions and proposes a state representation that explicitly tracks uncertainty and recency effects.\nIntroduction\n\nExplainable AI (XAI) is increasingly required for medical imaging systems used in screening and triage. Beyond predictive accuracy, clinicians demand transparency about what image features drive automated decisions and whether explanations are stable under shifts.\n\nPost-hoc attribution methods like Grad-CAM and Integrated Gradients highlight salient regions (Selvaraju et al., 2017; Sundararajan et al., 2017). Prototype- and concept-based explanations enhance interpretability (Chen et al., 2019; Kim et al., 2018). Counterfactual generation has been explored for medical images (Chang et al., 2018; Singla et al., 2021).\n\nWe focus on faithfulness under distribution shift and propose an evaluation protocol that aligns explanation stability with clinical acceptance thresholds for screening workflows.\nRelated Work\n\nProviding timely, actionable feedback at scale is central to computing education. Traditional approaches combine instructor-designed rubrics with automated tests, but coverage and specificity can be limited for diverse student solutions.\n\nAutomated feedback for programming assignments has been tackled with static analysis, dynamic test generation, and pattern mining (Ke et al., 2016; Gulwani et al., 2018; Singh et al., 2013). Recent NLP-based systems leverage code embeddings, sequence models, and pretrained language models (Allamanis et al., 2018; Feng et al., 2020; Ahmad et al., 2021). Peer learning platforms collect hints and exemplars to guide novice programmers (Piech et al., 2015; Wang et al., 2018).\n\nWhile data-driven approaches show promise, they often struggle with generalizing across tasks and providing pedagogically aligned guidance. Our work investigates structure-aware hint generation that aligns feedback to conceptual steps in problem-solving.\nRelated Work\n\nReinforcement learning (RL) has enabled robots to acquire complex behaviors directly from interaction. However, data hunger, safety, and sim-to-real transfer remain persistent obstacles for deployment in real-world settings.\n\nModel-free methods such as DDPG (Lillicrap et al., 2016), SAC (Haarnoja et al., 2018), and PPO (Schulman et al., 2017) have been widely adopted for continuous control, while model-based approaches leverage learned dynamics for sample efficiency (Deisenroth and Rasmussen, 2011; Chua et al., 2018). Recent lines of work explore offline RL (Levine et al., 2020; Kumar et al., 2020) and representation learning for policy generalization (Laskin et al., 2020; Yarats et al., 2021). Domain randomization and adaptation seek to bridge the sim-to-real gap (Tobin et al., 2017; Peng et al., 2018).\n\nWe propose a training strategy that combines curriculum learning with uncertainty-aware policy updates to improve safety and sample efficiency in robotic manipulation.\n",
        "completion": "Model-free methods such as DDPG (Lillicrap et al., 2016), SAC (Haarnoja et al., 2018), and PPO (Schulman et al., 2017) have been widely adopted for continuous control, while model-based approaches leverage learned dynamics for sample efficiency (Deisenroth and Rasmussen, 2011; Chua et al., 2018)."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        occurs when either:\n    a) The author describes or cites papers without connecting them to their own work/argument \n    b) Or only follows up the summary of previous works with their own contribution without explicitly highlighting the gap their work intends to research.\n    c) It does not articulate the author's perspective or motivation.\n    d) A lack of argument/opinion in the first paragraph is permissible as it serves to be the foundation of the author's argument \n    e) Lacks synthesis issues appear either as single sentences or multiple sentences.\n    Examples of lack of synthesis include:\n        i) No elaboration of own contribution/argument:\"Following early neural approaches to question answering, many subsequent studies adopt a pipeline architecture consisting of retrieval and comprehension components. The retrieval component focuses on identifying relevant documents or passages from a large corpus, while the comprehension component extracts an answer span from the retrieved text. Initial models relied on recurrent neural networks with attention mechanisms to encode questions and contexts (Seo et al., 2017; Wang et al., 2017).\"\n        ii)  No explanation of the cited works and relation to their own work: \u201cRecently, several studies have explored the use of prompting techniques with pre-trained language models to influence model outputs or access latent knowledge (Brown et al., 2020; Gao et al., 2021; Liu et al., 2021; Wei et al., 2022).\u201d \n\n        Example text: \n        Related Work\n\nDevelopers rely on code search to find relevant snippets, APIs, or examples. Unlike general document retrieval, code search must bridge natural language intent and program structure.\n\nNeural code search has been addressed with bi-encoders, cross-encoders, and dual learning (Gu et al., 2018; Husain et al., 2019; Feng et al., 2020). Structural representations incorporate ASTs, control flow, and data flow (Alon et al., 2019; Wang et al., 2020; Liu et al., 2021). Pretraining on code and NL improves retrieval metrics across languages (Ahmad et al., 2021; Guo et al., 2021).\n\nIn this paper, we introduce a language-agnostic retriever with compositional queries.\n\nWe evaluate zero-shot transfer across four programming languages.\nIntroduction\n\nGeneralization in text classification can be improved with data augmentation, especially when labeled data are scarce or imbalanced. Approaches range from rule-based edits to model-driven paraphrasing and representation-space mixing.\n\nText augmentation techniques include synonym replacement, random insertion/deletion, back-translation, paraphrase generation, and mixup in embedding or hidden spaces (Wei and Zou, 2019; Sennrich et al., 2016; Kobayashi, 2018; Guo et al., 2020). Recent work explores task-adaptive augmentation policies learned by reinforcement learning (Xie et al., 2020).\n\nEvaluation typically considers robustness to domain shift, label noise, and distributional skew across multiple benchmarks (Pruksachatkun et al., 2020; Hendrycks et al., 2020).\nRelated Work\n\nKnowledge graph completion predicts missing links by learning entity and relation representations. Methods vary in how they encode semantics and handle patterns like symmetry, hierarchy, and composition.\n\nTranslation-based knowledge graph embeddings model relations as translations in vector space (Bordes et al., 2013; Wang et al., 2014), while bilinear and neural models capture more complex interactions (Nickel et al., 2011; Trouillon et al., 2016; Sun et al., 2019). Regularization and rule-guided approaches improve inductive bias and data efficiency (Rockt\u00e4schel et al., 2015; Minervini et al., 2017).\n\nWe introduce a lightweight compositional constraint for hierarchical relations and evaluate on three benchmarks and an industry dataset.\nRelated Work\n\nEnsuring safety during reinforcement learning is critical in real-world control where violations can be costly. Research has proposed both objective-level and mechanism-level solutions.\n\nSafe reinforcement learning approaches include risk-sensitive objectives such as CVaR optimization (Tamar et al., 2015; Chow et al., 2018), constrained policy optimization with safety budgets (Achiam et al., 2017; Yang et al., 2020), and shielding based on model-checking or supervisors (Alshiekh et al., 2018; Dalal et al., 2018). We develop a method that integrates model-predictive constraints with policy gradients.\n\nBenchmarks often evaluate safety in simulated robotics or navigation with cost functions approximating constraint violations (Ray et al., 2019; Bharadhwaj et al., 2021).\nRelated Work\n\nDialog state tracking (DST) has evolved from rule-based slot filling to neural architectures that jointly infer belief states across turns. Early pipeline models used hand-crafted lexicons and semantic frames (Singh and Patel, 2015), but suffered from brittleness to paraphrase and noise. Neural encoders introduced robustness by contextualizing utterances, incorporating attention over dialog history, and modeling slot-value dependencies (Lee et al., 2018; Choe and Kim, 2019).\n\nPretrained language models have further shifted the landscape by enabling few-shot generalization and open-vocabulary slot values. Fine-tuning BERT-like encoders for DST improved cross-domain transfer (Rao et al., 2020), while generative formulations cast state tracking as text-to-text prediction (Mendez et al., 2021).\n\nPrompting-based approaches have also been explored for dialog modeling (Kumar et al., 2021; Ortega and Lin, 2022; Park et al., 2023). These methods condition large language models on task instructions or few-shot exemplars to elicit latent conversational knowledge. Recent variants incorporate calibration or self-consistency to stabilize outputs (Fang et al., 2023; Zhou et al., 2023).\n\nPosition relative to this paper While we also employ pretrained sequence-to-sequence models, our focus is on handling ontology drift in long-running deployments. Specifically, we introduce an adaptive slot schema encoder that aligns evolving taxonomies with dialog evidence, and a contrastive consistency objective to mitigate spurious slot co-activations across domains.\nIntroduction\n\nSelf-supervised learning (SSL) has become the dominant paradigm for learning transferable visual features without labels. By constructing pretext tasks that expose invariances and structure inherent in data, SSL models can match or surpass supervised baselines on many downstream tasks.\n\nContrastive pretraining has been widely adopted for visual representations (Chen et al., 2020; He et al., 2020; Xie and Xu, 2021). Non-contrastive methods remove negative pairs and rely on architectural or objective asymmetries (Grill et al., 2020; Tian et al., 2021). Clustering-based methods jointly learn assignments and embeddings (Caron et al., 2018; Li and Gao, 2022).\n\nDespite these advances, industrial applications often operate under strict memory budgets and latency constraints. In this paper, we investigate compute-aware pretraining objectives that couple multi-crop augmentation with a token-subsampled backbone. We present a latency-regularized alignment loss that preserves downstream accuracy while reducing FLOPs during both pretraining and fine-tuning.\nIntroduction\n\nEfficient exploration remains a central challenge in reinforcement learning (RL), particularly in sparse-reward environments where naive strategies fail to discover rewarding states. Over-exploration, however, can waste samples and destabilize learning.\n\nExploration in reinforcement learning has been advanced by count-based bonuses, intrinsic motivation, curiosity-driven prediction error, and information-theoretic objectives (Bellemare et al., 2016; Pathak et al., 2017; Houthooft et al., 2016; Burda et al., 2019; Ta\u00efga et al., 2020).\n\nYet, when environment dynamics change over time, stale novelty estimates can encourage revisiting obsolete states. We propose a recency-aware intrinsic reward that discounts outdated novelty and couples it with conservative policy updates.\n\nAcross Atari and continuous-control domains with drifting dynamics, our method achieves superior sample efficiency and stability, and ablations confirm the role of recency in balancing exploration and exploitation.\nRelated Work\n\nDetecting anomalies in multivariate time series is vital for monitoring industrial systems and cloud services. The challenge lies in handling seasonality, rare events, and inter-variable dependencies.\n\nClassical anomaly detection leverages ARIMA residual tests, STL decomposition, and control charts, while deep methods introduce autoencoders, VAEs, GANs, LSTMs, and Transformers for reconstruction or prediction errors (Tsay, 2010; Malhotra et al., 2015; An and Cho, 2015; Li et al., 2019; Xu et al., 2021).\n\nWe present Contrastive Forecasting with Graph Priors (CFGP), which learns structure-aware representations via self-supervised objectives and uses calibrated predictive intervals to flag anomalies.\nIntroduction\n\nGeneralizing manipulation skills across objects, tasks, and environments remains a central challenge in robotics. Sparse rewards, safety constraints, and hardware variability complicate learning on physical systems. Recent work studies imitation learning, offline RL, and model-based control for dexterous manipulation (Rajeswaran et al., 2018; Lynch et al., 2020; Nagabandi et al., 2019; Ahn et al., 2022). Despite these advances, scaling data collection and ensuring sim-to-real transfer continue to be bottlenecks.\n\nWe explore a curriculum that interleaves skill discovery from teleoperation logs with conservative online updates, targeting stable improvements under limited interaction budgets.\nRelated Work\n\nConversational recommenders. Systems that interactively elicit user preferences can reduce cold-start and improve satisfaction (Sun and Zhang, 2018). Dialog policy learning for conversational recommendation has explored supervised learning, reinforcement learning, and bandit methods (Christakopoulou et al., 2016; Lei et al., 2020; Chen et al., 2019). User simulators and counterfactual logging have been proposed to address data scarcity and evaluation challenges (Li et al., 2017; Chi et al., 2020).\n\nOur study investigates preference drift over long-horizon sessions and proposes a state representation that explicitly tracks uncertainty and recency effects.\nIntroduction\n\nExplainable AI (XAI) is increasingly required for medical imaging systems used in screening and triage. Beyond predictive accuracy, clinicians demand transparency about what image features drive automated decisions and whether explanations are stable under shifts.\n\nPost-hoc attribution methods like Grad-CAM and Integrated Gradients highlight salient regions (Selvaraju et al., 2017; Sundararajan et al., 2017). Prototype- and concept-based explanations enhance interpretability (Chen et al., 2019; Kim et al., 2018). Counterfactual generation has been explored for medical images (Chang et al., 2018; Singla et al., 2021).\n\nWe focus on faithfulness under distribution shift and propose an evaluation protocol that aligns explanation stability with clinical acceptance thresholds for screening workflows.\nRelated Work\n\nProviding timely, actionable feedback at scale is central to computing education. Traditional approaches combine instructor-designed rubrics with automated tests, but coverage and specificity can be limited for diverse student solutions.\n\nAutomated feedback for programming assignments has been tackled with static analysis, dynamic test generation, and pattern mining (Ke et al., 2016; Gulwani et al., 2018; Singh et al., 2013). Recent NLP-based systems leverage code embeddings, sequence models, and pretrained language models (Allamanis et al., 2018; Feng et al., 2020; Ahmad et al., 2021). Peer learning platforms collect hints and exemplars to guide novice programmers (Piech et al., 2015; Wang et al., 2018).\n\nWhile data-driven approaches show promise, they often struggle with generalizing across tasks and providing pedagogically aligned guidance. Our work investigates structure-aware hint generation that aligns feedback to conceptual steps in problem-solving.\nRelated Work\n\nReinforcement learning (RL) has enabled robots to acquire complex behaviors directly from interaction. However, data hunger, safety, and sim-to-real transfer remain persistent obstacles for deployment in real-world settings.\n\nModel-free methods such as DDPG (Lillicrap et al., 2016), SAC (Haarnoja et al., 2018), and PPO (Schulman et al., 2017) have been widely adopted for continuous control, while model-based approaches leverage learned dynamics for sample efficiency (Deisenroth and Rasmussen, 2011; Chua et al., 2018). Recent lines of work explore offline RL (Levine et al., 2020; Kumar et al., 2020) and representation learning for policy generalization (Laskin et al., 2020; Yarats et al., 2021). Domain randomization and adaptation seek to bridge the sim-to-real gap (Tobin et al., 2017; Peng et al., 2018).\n\nWe propose a training strategy that combines curriculum learning with uncertainty-aware policy updates to improve safety and sample efficiency in robotic manipulation.\nRelated Work\n\nAutomatic speech recognition (ASR) systems increasingly rely on large encoder\u2013decoder architectures that are costly to deploy on edge devices. Knowledge distillation (KD) is a common strategy to reduce model size while preserving accuracy.\n\nKnowledge distillation for speech recognition has considered frame-level supervision, sequence-level criteria, and wordpiece distributions, transferring knowledge from stronger teachers to smaller students (Hinton et al., 2015; Kim and Rush, 2016; Kurata and Audhkhasi, 2018; Higuchi et al., 2021).\n\nOther compression techniques include quantization and pruning, which can be combined with KD but may degrade robustness to noise and speaker variability. Recent work explores multi-teacher ensembles and intermediate-layer matching to stabilize training.\n\nIn this paper, we study streaming-constrained KD with latency-aware targets, aligning teacher and student under causal masking. Our experiments on LibriSpeech and far-field corpora show improved WER\u2013latency trade-offs compared to strong baselines.\n",
        "completion": "Knowledge distillation for speech recognition has considered frame-level supervision, sequence-level criteria, and wordpiece distributions, transferring knowledge from stronger teachers to smaller students (Hinton et al., 2015; Kim and Rush, 2016; Kurata and Audhkhasi, 2018; Higuchi et al., 2021)."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        occurs when either:\n    a) The author describes or cites papers without connecting them to their own work/argument \n    b) Or only follows up the summary of previous works with their own contribution without explicitly highlighting the gap their work intends to research.\n    c) It does not articulate the author's perspective or motivation.\n    d) A lack of argument/opinion in the first paragraph is permissible as it serves to be the foundation of the author's argument \n    e) Lacks synthesis issues appear either as single sentences or multiple sentences.\n    Examples of lack of synthesis include:\n        i) No elaboration of own contribution/argument:\"Following early neural approaches to question answering, many subsequent studies adopt a pipeline architecture consisting of retrieval and comprehension components. The retrieval component focuses on identifying relevant documents or passages from a large corpus, while the comprehension component extracts an answer span from the retrieved text. Initial models relied on recurrent neural networks with attention mechanisms to encode questions and contexts (Seo et al., 2017; Wang et al., 2017).\"\n        ii)  No explanation of the cited works and relation to their own work: \u201cRecently, several studies have explored the use of prompting techniques with pre-trained language models to influence model outputs or access latent knowledge (Brown et al., 2020; Gao et al., 2021; Liu et al., 2021; Wei et al., 2022).\u201d \n\n        Example text: \n        Related Work\n\nDevelopers rely on code search to find relevant snippets, APIs, or examples. Unlike general document retrieval, code search must bridge natural language intent and program structure.\n\nNeural code search has been addressed with bi-encoders, cross-encoders, and dual learning (Gu et al., 2018; Husain et al., 2019; Feng et al., 2020). Structural representations incorporate ASTs, control flow, and data flow (Alon et al., 2019; Wang et al., 2020; Liu et al., 2021). Pretraining on code and NL improves retrieval metrics across languages (Ahmad et al., 2021; Guo et al., 2021).\n\nIn this paper, we introduce a language-agnostic retriever with compositional queries.\n\nWe evaluate zero-shot transfer across four programming languages.\nIntroduction\n\nGeneralization in text classification can be improved with data augmentation, especially when labeled data are scarce or imbalanced. Approaches range from rule-based edits to model-driven paraphrasing and representation-space mixing.\n\nText augmentation techniques include synonym replacement, random insertion/deletion, back-translation, paraphrase generation, and mixup in embedding or hidden spaces (Wei and Zou, 2019; Sennrich et al., 2016; Kobayashi, 2018; Guo et al., 2020). Recent work explores task-adaptive augmentation policies learned by reinforcement learning (Xie et al., 2020).\n\nEvaluation typically considers robustness to domain shift, label noise, and distributional skew across multiple benchmarks (Pruksachatkun et al., 2020; Hendrycks et al., 2020).\nRelated Work\n\nKnowledge graph completion predicts missing links by learning entity and relation representations. Methods vary in how they encode semantics and handle patterns like symmetry, hierarchy, and composition.\n\nTranslation-based knowledge graph embeddings model relations as translations in vector space (Bordes et al., 2013; Wang et al., 2014), while bilinear and neural models capture more complex interactions (Nickel et al., 2011; Trouillon et al., 2016; Sun et al., 2019). Regularization and rule-guided approaches improve inductive bias and data efficiency (Rockt\u00e4schel et al., 2015; Minervini et al., 2017).\n\nWe introduce a lightweight compositional constraint for hierarchical relations and evaluate on three benchmarks and an industry dataset.\nRelated Work\n\nEnsuring safety during reinforcement learning is critical in real-world control where violations can be costly. Research has proposed both objective-level and mechanism-level solutions.\n\nSafe reinforcement learning approaches include risk-sensitive objectives such as CVaR optimization (Tamar et al., 2015; Chow et al., 2018), constrained policy optimization with safety budgets (Achiam et al., 2017; Yang et al., 2020), and shielding based on model-checking or supervisors (Alshiekh et al., 2018; Dalal et al., 2018). We develop a method that integrates model-predictive constraints with policy gradients.\n\nBenchmarks often evaluate safety in simulated robotics or navigation with cost functions approximating constraint violations (Ray et al., 2019; Bharadhwaj et al., 2021).\nRelated Work\n\nDialog state tracking (DST) has evolved from rule-based slot filling to neural architectures that jointly infer belief states across turns. Early pipeline models used hand-crafted lexicons and semantic frames (Singh and Patel, 2015), but suffered from brittleness to paraphrase and noise. Neural encoders introduced robustness by contextualizing utterances, incorporating attention over dialog history, and modeling slot-value dependencies (Lee et al., 2018; Choe and Kim, 2019).\n\nPretrained language models have further shifted the landscape by enabling few-shot generalization and open-vocabulary slot values. Fine-tuning BERT-like encoders for DST improved cross-domain transfer (Rao et al., 2020), while generative formulations cast state tracking as text-to-text prediction (Mendez et al., 2021).\n\nPrompting-based approaches have also been explored for dialog modeling (Kumar et al., 2021; Ortega and Lin, 2022; Park et al., 2023). These methods condition large language models on task instructions or few-shot exemplars to elicit latent conversational knowledge. Recent variants incorporate calibration or self-consistency to stabilize outputs (Fang et al., 2023; Zhou et al., 2023).\n\nPosition relative to this paper While we also employ pretrained sequence-to-sequence models, our focus is on handling ontology drift in long-running deployments. Specifically, we introduce an adaptive slot schema encoder that aligns evolving taxonomies with dialog evidence, and a contrastive consistency objective to mitigate spurious slot co-activations across domains.\nIntroduction\n\nSelf-supervised learning (SSL) has become the dominant paradigm for learning transferable visual features without labels. By constructing pretext tasks that expose invariances and structure inherent in data, SSL models can match or surpass supervised baselines on many downstream tasks.\n\nContrastive pretraining has been widely adopted for visual representations (Chen et al., 2020; He et al., 2020; Xie and Xu, 2021). Non-contrastive methods remove negative pairs and rely on architectural or objective asymmetries (Grill et al., 2020; Tian et al., 2021). Clustering-based methods jointly learn assignments and embeddings (Caron et al., 2018; Li and Gao, 2022).\n\nDespite these advances, industrial applications often operate under strict memory budgets and latency constraints. In this paper, we investigate compute-aware pretraining objectives that couple multi-crop augmentation with a token-subsampled backbone. We present a latency-regularized alignment loss that preserves downstream accuracy while reducing FLOPs during both pretraining and fine-tuning.\nIntroduction\n\nEfficient exploration remains a central challenge in reinforcement learning (RL), particularly in sparse-reward environments where naive strategies fail to discover rewarding states. Over-exploration, however, can waste samples and destabilize learning.\n\nExploration in reinforcement learning has been advanced by count-based bonuses, intrinsic motivation, curiosity-driven prediction error, and information-theoretic objectives (Bellemare et al., 2016; Pathak et al., 2017; Houthooft et al., 2016; Burda et al., 2019; Ta\u00efga et al., 2020).\n\nYet, when environment dynamics change over time, stale novelty estimates can encourage revisiting obsolete states. We propose a recency-aware intrinsic reward that discounts outdated novelty and couples it with conservative policy updates.\n\nAcross Atari and continuous-control domains with drifting dynamics, our method achieves superior sample efficiency and stability, and ablations confirm the role of recency in balancing exploration and exploitation.\nRelated Work\n\nDetecting anomalies in multivariate time series is vital for monitoring industrial systems and cloud services. The challenge lies in handling seasonality, rare events, and inter-variable dependencies.\n\nClassical anomaly detection leverages ARIMA residual tests, STL decomposition, and control charts, while deep methods introduce autoencoders, VAEs, GANs, LSTMs, and Transformers for reconstruction or prediction errors (Tsay, 2010; Malhotra et al., 2015; An and Cho, 2015; Li et al., 2019; Xu et al., 2021).\n\nWe present Contrastive Forecasting with Graph Priors (CFGP), which learns structure-aware representations via self-supervised objectives and uses calibrated predictive intervals to flag anomalies.\nIntroduction\n\nGeneralizing manipulation skills across objects, tasks, and environments remains a central challenge in robotics. Sparse rewards, safety constraints, and hardware variability complicate learning on physical systems. Recent work studies imitation learning, offline RL, and model-based control for dexterous manipulation (Rajeswaran et al., 2018; Lynch et al., 2020; Nagabandi et al., 2019; Ahn et al., 2022). Despite these advances, scaling data collection and ensuring sim-to-real transfer continue to be bottlenecks.\n\nWe explore a curriculum that interleaves skill discovery from teleoperation logs with conservative online updates, targeting stable improvements under limited interaction budgets.\nRelated Work\n\nConversational recommenders. Systems that interactively elicit user preferences can reduce cold-start and improve satisfaction (Sun and Zhang, 2018). Dialog policy learning for conversational recommendation has explored supervised learning, reinforcement learning, and bandit methods (Christakopoulou et al., 2016; Lei et al., 2020; Chen et al., 2019). User simulators and counterfactual logging have been proposed to address data scarcity and evaluation challenges (Li et al., 2017; Chi et al., 2020).\n\nOur study investigates preference drift over long-horizon sessions and proposes a state representation that explicitly tracks uncertainty and recency effects.\nIntroduction\n\nExplainable AI (XAI) is increasingly required for medical imaging systems used in screening and triage. Beyond predictive accuracy, clinicians demand transparency about what image features drive automated decisions and whether explanations are stable under shifts.\n\nPost-hoc attribution methods like Grad-CAM and Integrated Gradients highlight salient regions (Selvaraju et al., 2017; Sundararajan et al., 2017). Prototype- and concept-based explanations enhance interpretability (Chen et al., 2019; Kim et al., 2018). Counterfactual generation has been explored for medical images (Chang et al., 2018; Singla et al., 2021).\n\nWe focus on faithfulness under distribution shift and propose an evaluation protocol that aligns explanation stability with clinical acceptance thresholds for screening workflows.\nRelated Work\n\nProviding timely, actionable feedback at scale is central to computing education. Traditional approaches combine instructor-designed rubrics with automated tests, but coverage and specificity can be limited for diverse student solutions.\n\nAutomated feedback for programming assignments has been tackled with static analysis, dynamic test generation, and pattern mining (Ke et al., 2016; Gulwani et al., 2018; Singh et al., 2013). Recent NLP-based systems leverage code embeddings, sequence models, and pretrained language models (Allamanis et al., 2018; Feng et al., 2020; Ahmad et al., 2021). Peer learning platforms collect hints and exemplars to guide novice programmers (Piech et al., 2015; Wang et al., 2018).\n\nWhile data-driven approaches show promise, they often struggle with generalizing across tasks and providing pedagogically aligned guidance. Our work investigates structure-aware hint generation that aligns feedback to conceptual steps in problem-solving.\nRelated Work\n\nReinforcement learning (RL) has enabled robots to acquire complex behaviors directly from interaction. However, data hunger, safety, and sim-to-real transfer remain persistent obstacles for deployment in real-world settings.\n\nModel-free methods such as DDPG (Lillicrap et al., 2016), SAC (Haarnoja et al., 2018), and PPO (Schulman et al., 2017) have been widely adopted for continuous control, while model-based approaches leverage learned dynamics for sample efficiency (Deisenroth and Rasmussen, 2011; Chua et al., 2018). Recent lines of work explore offline RL (Levine et al., 2020; Kumar et al., 2020) and representation learning for policy generalization (Laskin et al., 2020; Yarats et al., 2021). Domain randomization and adaptation seek to bridge the sim-to-real gap (Tobin et al., 2017; Peng et al., 2018).\n\nWe propose a training strategy that combines curriculum learning with uncertainty-aware policy updates to improve safety and sample efficiency in robotic manipulation.\nRelated Work\n\nAutomatic speech recognition (ASR) systems increasingly rely on large encoder\u2013decoder architectures that are costly to deploy on edge devices. Knowledge distillation (KD) is a common strategy to reduce model size while preserving accuracy.\n\nKnowledge distillation for speech recognition has considered frame-level supervision, sequence-level criteria, and wordpiece distributions, transferring knowledge from stronger teachers to smaller students (Hinton et al., 2015; Kim and Rush, 2016; Kurata and Audhkhasi, 2018; Higuchi et al., 2021).\n\nOther compression techniques include quantization and pruning, which can be combined with KD but may degrade robustness to noise and speaker variability. Recent work explores multi-teacher ensembles and intermediate-layer matching to stabilize training.\n\nIn this paper, we study streaming-constrained KD with latency-aware targets, aligning teacher and student under causal masking. Our experiments on LibriSpeech and far-field corpora show improved WER\u2013latency trade-offs compared to strong baselines.\nRelated Work\n\nLarge Language Models and Prompting\nLarge language models (LLMs) exhibit emergent program synthesis capabilities when conditioned on natural language instructions and a handful of examples. While these behaviors reduce reliance on supervised datasets, the mechanisms by which prompts control generation remain only partially understood. Prior studies analyze calibration, decoding strategies, and context length effects.\n\nPrompting for Code Generation\nPrompting for code generation has explored zero-shot, few-shot, and chain-of-thought styles using large language models (Chen et al., 2021; Austin et al., 2021; Nijkamp et al., 2022; Li et al., 2023). Work on compiler-aware prompting adds execution feedback to steer generation (Liu et al., 2022; Le et al., 2022; Wang et al., 2023). Program repair and test-driven synthesis have similarly adapted prompting strategies to satisfy unit tests (Jain et al., 2022; Zhang et al., 2023).\n\nExecution-Conditioned Decoding\nBeyond static prompts, execution-conditioned decoding iteratively runs partial programs to reduce search space. Studies report gains on algorithmic problems by interleaving generation and verification under timeouts and sandboxing constraints.\n\nStructured Constraints and Type Guidance\nApproaches that inject grammar constraints or type information restrict invalid outputs and improve pass rates. These methods range from constrained beam search to type-state automata.\n\nPositioning\nWe examine the interaction between prompt structure and execution feedback and study how typed constraints alter search dynamics under limited budgets.\n",
        "completion": "Prompting for code generation has explored zero-shot, few-shot, and chain-of-thought styles using large language models (Chen et al., 2021; Austin et al., 2021; Nijkamp et al., 2022; Li et al., 2023). Work on compiler-aware prompting adds execution feedback to steer generation (Liu et al., 2022; Le et al., 2022; Wang et al., 2023). Program repair and test-driven synthesis have similarly adapted prompting strategies to satisfy unit tests (Jain et al., 2022; Zhang et al., 2023)."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        occurs when either:\n    a) The author describes or cites papers without connecting them to their own work/argument \n    b) Or only follows up the summary of previous works with their own contribution without explicitly highlighting the gap their work intends to research.\n    c) It does not articulate the author's perspective or motivation.\n    d) A lack of argument/opinion in the first paragraph is permissible as it serves to be the foundation of the author's argument \n    e) Lacks synthesis issues appear either as single sentences or multiple sentences.\n    Examples of lack of synthesis include:\n        i) No elaboration of own contribution/argument:\"Following early neural approaches to question answering, many subsequent studies adopt a pipeline architecture consisting of retrieval and comprehension components. The retrieval component focuses on identifying relevant documents or passages from a large corpus, while the comprehension component extracts an answer span from the retrieved text. Initial models relied on recurrent neural networks with attention mechanisms to encode questions and contexts (Seo et al., 2017; Wang et al., 2017).\"\n        ii)  No explanation of the cited works and relation to their own work: \u201cRecently, several studies have explored the use of prompting techniques with pre-trained language models to influence model outputs or access latent knowledge (Brown et al., 2020; Gao et al., 2021; Liu et al., 2021; Wei et al., 2022).\u201d \n\n        Example text: \n        Related Work\n\nDevelopers rely on code search to find relevant snippets, APIs, or examples. Unlike general document retrieval, code search must bridge natural language intent and program structure.\n\nNeural code search has been addressed with bi-encoders, cross-encoders, and dual learning (Gu et al., 2018; Husain et al., 2019; Feng et al., 2020). Structural representations incorporate ASTs, control flow, and data flow (Alon et al., 2019; Wang et al., 2020; Liu et al., 2021). Pretraining on code and NL improves retrieval metrics across languages (Ahmad et al., 2021; Guo et al., 2021).\n\nIn this paper, we introduce a language-agnostic retriever with compositional queries.\n\nWe evaluate zero-shot transfer across four programming languages.\nIntroduction\n\nGeneralization in text classification can be improved with data augmentation, especially when labeled data are scarce or imbalanced. Approaches range from rule-based edits to model-driven paraphrasing and representation-space mixing.\n\nText augmentation techniques include synonym replacement, random insertion/deletion, back-translation, paraphrase generation, and mixup in embedding or hidden spaces (Wei and Zou, 2019; Sennrich et al., 2016; Kobayashi, 2018; Guo et al., 2020). Recent work explores task-adaptive augmentation policies learned by reinforcement learning (Xie et al., 2020).\n\nEvaluation typically considers robustness to domain shift, label noise, and distributional skew across multiple benchmarks (Pruksachatkun et al., 2020; Hendrycks et al., 2020).\nRelated Work\n\nKnowledge graph completion predicts missing links by learning entity and relation representations. Methods vary in how they encode semantics and handle patterns like symmetry, hierarchy, and composition.\n\nTranslation-based knowledge graph embeddings model relations as translations in vector space (Bordes et al., 2013; Wang et al., 2014), while bilinear and neural models capture more complex interactions (Nickel et al., 2011; Trouillon et al., 2016; Sun et al., 2019). Regularization and rule-guided approaches improve inductive bias and data efficiency (Rockt\u00e4schel et al., 2015; Minervini et al., 2017).\n\nWe introduce a lightweight compositional constraint for hierarchical relations and evaluate on three benchmarks and an industry dataset.\nRelated Work\n\nEnsuring safety during reinforcement learning is critical in real-world control where violations can be costly. Research has proposed both objective-level and mechanism-level solutions.\n\nSafe reinforcement learning approaches include risk-sensitive objectives such as CVaR optimization (Tamar et al., 2015; Chow et al., 2018), constrained policy optimization with safety budgets (Achiam et al., 2017; Yang et al., 2020), and shielding based on model-checking or supervisors (Alshiekh et al., 2018; Dalal et al., 2018). We develop a method that integrates model-predictive constraints with policy gradients.\n\nBenchmarks often evaluate safety in simulated robotics or navigation with cost functions approximating constraint violations (Ray et al., 2019; Bharadhwaj et al., 2021).\nRelated Work\n\nDialog state tracking (DST) has evolved from rule-based slot filling to neural architectures that jointly infer belief states across turns. Early pipeline models used hand-crafted lexicons and semantic frames (Singh and Patel, 2015), but suffered from brittleness to paraphrase and noise. Neural encoders introduced robustness by contextualizing utterances, incorporating attention over dialog history, and modeling slot-value dependencies (Lee et al., 2018; Choe and Kim, 2019).\n\nPretrained language models have further shifted the landscape by enabling few-shot generalization and open-vocabulary slot values. Fine-tuning BERT-like encoders for DST improved cross-domain transfer (Rao et al., 2020), while generative formulations cast state tracking as text-to-text prediction (Mendez et al., 2021).\n\nPrompting-based approaches have also been explored for dialog modeling (Kumar et al., 2021; Ortega and Lin, 2022; Park et al., 2023). These methods condition large language models on task instructions or few-shot exemplars to elicit latent conversational knowledge. Recent variants incorporate calibration or self-consistency to stabilize outputs (Fang et al., 2023; Zhou et al., 2023).\n\nPosition relative to this paper While we also employ pretrained sequence-to-sequence models, our focus is on handling ontology drift in long-running deployments. Specifically, we introduce an adaptive slot schema encoder that aligns evolving taxonomies with dialog evidence, and a contrastive consistency objective to mitigate spurious slot co-activations across domains.\nIntroduction\n\nSelf-supervised learning (SSL) has become the dominant paradigm for learning transferable visual features without labels. By constructing pretext tasks that expose invariances and structure inherent in data, SSL models can match or surpass supervised baselines on many downstream tasks.\n\nContrastive pretraining has been widely adopted for visual representations (Chen et al., 2020; He et al., 2020; Xie and Xu, 2021). Non-contrastive methods remove negative pairs and rely on architectural or objective asymmetries (Grill et al., 2020; Tian et al., 2021). Clustering-based methods jointly learn assignments and embeddings (Caron et al., 2018; Li and Gao, 2022).\n\nDespite these advances, industrial applications often operate under strict memory budgets and latency constraints. In this paper, we investigate compute-aware pretraining objectives that couple multi-crop augmentation with a token-subsampled backbone. We present a latency-regularized alignment loss that preserves downstream accuracy while reducing FLOPs during both pretraining and fine-tuning.\nIntroduction\n\nEfficient exploration remains a central challenge in reinforcement learning (RL), particularly in sparse-reward environments where naive strategies fail to discover rewarding states. Over-exploration, however, can waste samples and destabilize learning.\n\nExploration in reinforcement learning has been advanced by count-based bonuses, intrinsic motivation, curiosity-driven prediction error, and information-theoretic objectives (Bellemare et al., 2016; Pathak et al., 2017; Houthooft et al., 2016; Burda et al., 2019; Ta\u00efga et al., 2020).\n\nYet, when environment dynamics change over time, stale novelty estimates can encourage revisiting obsolete states. We propose a recency-aware intrinsic reward that discounts outdated novelty and couples it with conservative policy updates.\n\nAcross Atari and continuous-control domains with drifting dynamics, our method achieves superior sample efficiency and stability, and ablations confirm the role of recency in balancing exploration and exploitation.\nRelated Work\n\nDetecting anomalies in multivariate time series is vital for monitoring industrial systems and cloud services. The challenge lies in handling seasonality, rare events, and inter-variable dependencies.\n\nClassical anomaly detection leverages ARIMA residual tests, STL decomposition, and control charts, while deep methods introduce autoencoders, VAEs, GANs, LSTMs, and Transformers for reconstruction or prediction errors (Tsay, 2010; Malhotra et al., 2015; An and Cho, 2015; Li et al., 2019; Xu et al., 2021).\n\nWe present Contrastive Forecasting with Graph Priors (CFGP), which learns structure-aware representations via self-supervised objectives and uses calibrated predictive intervals to flag anomalies.\nIntroduction\n\nGeneralizing manipulation skills across objects, tasks, and environments remains a central challenge in robotics. Sparse rewards, safety constraints, and hardware variability complicate learning on physical systems. Recent work studies imitation learning, offline RL, and model-based control for dexterous manipulation (Rajeswaran et al., 2018; Lynch et al., 2020; Nagabandi et al., 2019; Ahn et al., 2022). Despite these advances, scaling data collection and ensuring sim-to-real transfer continue to be bottlenecks.\n\nWe explore a curriculum that interleaves skill discovery from teleoperation logs with conservative online updates, targeting stable improvements under limited interaction budgets.\nRelated Work\n\nConversational recommenders. Systems that interactively elicit user preferences can reduce cold-start and improve satisfaction (Sun and Zhang, 2018). Dialog policy learning for conversational recommendation has explored supervised learning, reinforcement learning, and bandit methods (Christakopoulou et al., 2016; Lei et al., 2020; Chen et al., 2019). User simulators and counterfactual logging have been proposed to address data scarcity and evaluation challenges (Li et al., 2017; Chi et al., 2020).\n\nOur study investigates preference drift over long-horizon sessions and proposes a state representation that explicitly tracks uncertainty and recency effects.\nIntroduction\n\nExplainable AI (XAI) is increasingly required for medical imaging systems used in screening and triage. Beyond predictive accuracy, clinicians demand transparency about what image features drive automated decisions and whether explanations are stable under shifts.\n\nPost-hoc attribution methods like Grad-CAM and Integrated Gradients highlight salient regions (Selvaraju et al., 2017; Sundararajan et al., 2017). Prototype- and concept-based explanations enhance interpretability (Chen et al., 2019; Kim et al., 2018). Counterfactual generation has been explored for medical images (Chang et al., 2018; Singla et al., 2021).\n\nWe focus on faithfulness under distribution shift and propose an evaluation protocol that aligns explanation stability with clinical acceptance thresholds for screening workflows.\nRelated Work\n\nProviding timely, actionable feedback at scale is central to computing education. Traditional approaches combine instructor-designed rubrics with automated tests, but coverage and specificity can be limited for diverse student solutions.\n\nAutomated feedback for programming assignments has been tackled with static analysis, dynamic test generation, and pattern mining (Ke et al., 2016; Gulwani et al., 2018; Singh et al., 2013). Recent NLP-based systems leverage code embeddings, sequence models, and pretrained language models (Allamanis et al., 2018; Feng et al., 2020; Ahmad et al., 2021). Peer learning platforms collect hints and exemplars to guide novice programmers (Piech et al., 2015; Wang et al., 2018).\n\nWhile data-driven approaches show promise, they often struggle with generalizing across tasks and providing pedagogically aligned guidance. Our work investigates structure-aware hint generation that aligns feedback to conceptual steps in problem-solving.\nRelated Work\n\nReinforcement learning (RL) has enabled robots to acquire complex behaviors directly from interaction. However, data hunger, safety, and sim-to-real transfer remain persistent obstacles for deployment in real-world settings.\n\nModel-free methods such as DDPG (Lillicrap et al., 2016), SAC (Haarnoja et al., 2018), and PPO (Schulman et al., 2017) have been widely adopted for continuous control, while model-based approaches leverage learned dynamics for sample efficiency (Deisenroth and Rasmussen, 2011; Chua et al., 2018). Recent lines of work explore offline RL (Levine et al., 2020; Kumar et al., 2020) and representation learning for policy generalization (Laskin et al., 2020; Yarats et al., 2021). Domain randomization and adaptation seek to bridge the sim-to-real gap (Tobin et al., 2017; Peng et al., 2018).\n\nWe propose a training strategy that combines curriculum learning with uncertainty-aware policy updates to improve safety and sample efficiency in robotic manipulation.\nRelated Work\n\nAutomatic speech recognition (ASR) systems increasingly rely on large encoder\u2013decoder architectures that are costly to deploy on edge devices. Knowledge distillation (KD) is a common strategy to reduce model size while preserving accuracy.\n\nKnowledge distillation for speech recognition has considered frame-level supervision, sequence-level criteria, and wordpiece distributions, transferring knowledge from stronger teachers to smaller students (Hinton et al., 2015; Kim and Rush, 2016; Kurata and Audhkhasi, 2018; Higuchi et al., 2021).\n\nOther compression techniques include quantization and pruning, which can be combined with KD but may degrade robustness to noise and speaker variability. Recent work explores multi-teacher ensembles and intermediate-layer matching to stabilize training.\n\nIn this paper, we study streaming-constrained KD with latency-aware targets, aligning teacher and student under causal masking. Our experiments on LibriSpeech and far-field corpora show improved WER\u2013latency trade-offs compared to strong baselines.\nRelated Work\n\nLarge Language Models and Prompting\nLarge language models (LLMs) exhibit emergent program synthesis capabilities when conditioned on natural language instructions and a handful of examples. While these behaviors reduce reliance on supervised datasets, the mechanisms by which prompts control generation remain only partially understood. Prior studies analyze calibration, decoding strategies, and context length effects.\n\nPrompting for Code Generation\nPrompting for code generation has explored zero-shot, few-shot, and chain-of-thought styles using large language models (Chen et al., 2021; Austin et al., 2021; Nijkamp et al., 2022; Li et al., 2023). Work on compiler-aware prompting adds execution feedback to steer generation (Liu et al., 2022; Le et al., 2022; Wang et al., 2023). Program repair and test-driven synthesis have similarly adapted prompting strategies to satisfy unit tests (Jain et al., 2022; Zhang et al., 2023).\n\nExecution-Conditioned Decoding\nBeyond static prompts, execution-conditioned decoding iteratively runs partial programs to reduce search space. Studies report gains on algorithmic problems by interleaving generation and verification under timeouts and sandboxing constraints.\n\nStructured Constraints and Type Guidance\nApproaches that inject grammar constraints or type information restrict invalid outputs and improve pass rates. These methods range from constrained beam search to type-state automata.\n\nPositioning\nWe examine the interaction between prompt structure and execution feedback and study how typed constraints alter search dynamics under limited budgets.\nRelated Work\n\nFederated learning (FL) enables on-device training with privacy and communication constraints. Ensuring rigorous privacy guarantees while preserving model utility remains a core challenge.\n\nPrivacy in federated learning has been studied via differential privacy at the client level, secure aggregation, and shuffling (McMahan et al., 2017; Kairouz et al., 2021; Bonawitz et al., 2017; Erlingsson et al., 2019). Gradient perturbation, clipping, and client subsampling are common techniques to control privacy loss (Abadi et al., 2016; Thakkar et al., 2019; Andrew et al., 2021). Auditing methods estimate empirical privacy leakage post hoc (Nasr et al., 2019; Jagielski et al., 2020).\n\nOur approach introduces client-adaptive noise schedules conditioned on participation frequency.\n\nWe empirically evaluate privacy-utility trade-offs across heterogeneous client populations.\n",
        "completion": "Privacy in federated learning has been studied via differential privacy at the client level, secure aggregation, and shuffling (McMahan et al., 2017; Kairouz et al., 2021; Bonawitz et al., 2017; Erlingsson et al., 2019). Gradient perturbation, clipping, and client subsampling are common techniques to control privacy loss (Abadi et al., 2016; Thakkar et al., 2019; Andrew et al., 2021). Auditing methods estimate empirical privacy leakage post hoc (Nasr et al., 2019; Jagielski et al., 2020)."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        occurs when either:\n    a) The author describes or cites papers without connecting them to their own work/argument \n    b) Or only follows up the summary of previous works with their own contribution without explicitly highlighting the gap their work intends to research.\n    c) It does not articulate the author's perspective or motivation.\n    d) A lack of argument/opinion in the first paragraph is permissible as it serves to be the foundation of the author's argument \n    e) Lacks synthesis issues appear either as single sentences or multiple sentences.\n    Examples of lack of synthesis include:\n        i) No elaboration of own contribution/argument:\"Following early neural approaches to question answering, many subsequent studies adopt a pipeline architecture consisting of retrieval and comprehension components. The retrieval component focuses on identifying relevant documents or passages from a large corpus, while the comprehension component extracts an answer span from the retrieved text. Initial models relied on recurrent neural networks with attention mechanisms to encode questions and contexts (Seo et al., 2017; Wang et al., 2017).\"\n        ii)  No explanation of the cited works and relation to their own work: \u201cRecently, several studies have explored the use of prompting techniques with pre-trained language models to influence model outputs or access latent knowledge (Brown et al., 2020; Gao et al., 2021; Liu et al., 2021; Wei et al., 2022).\u201d \n\n        Example text: \n        Related Work\n\nDevelopers rely on code search to find relevant snippets, APIs, or examples. Unlike general document retrieval, code search must bridge natural language intent and program structure.\n\nNeural code search has been addressed with bi-encoders, cross-encoders, and dual learning (Gu et al., 2018; Husain et al., 2019; Feng et al., 2020). Structural representations incorporate ASTs, control flow, and data flow (Alon et al., 2019; Wang et al., 2020; Liu et al., 2021). Pretraining on code and NL improves retrieval metrics across languages (Ahmad et al., 2021; Guo et al., 2021).\n\nIn this paper, we introduce a language-agnostic retriever with compositional queries.\n\nWe evaluate zero-shot transfer across four programming languages.\nIntroduction\n\nGeneralization in text classification can be improved with data augmentation, especially when labeled data are scarce or imbalanced. Approaches range from rule-based edits to model-driven paraphrasing and representation-space mixing.\n\nText augmentation techniques include synonym replacement, random insertion/deletion, back-translation, paraphrase generation, and mixup in embedding or hidden spaces (Wei and Zou, 2019; Sennrich et al., 2016; Kobayashi, 2018; Guo et al., 2020). Recent work explores task-adaptive augmentation policies learned by reinforcement learning (Xie et al., 2020).\n\nEvaluation typically considers robustness to domain shift, label noise, and distributional skew across multiple benchmarks (Pruksachatkun et al., 2020; Hendrycks et al., 2020).\nRelated Work\n\nKnowledge graph completion predicts missing links by learning entity and relation representations. Methods vary in how they encode semantics and handle patterns like symmetry, hierarchy, and composition.\n\nTranslation-based knowledge graph embeddings model relations as translations in vector space (Bordes et al., 2013; Wang et al., 2014), while bilinear and neural models capture more complex interactions (Nickel et al., 2011; Trouillon et al., 2016; Sun et al., 2019). Regularization and rule-guided approaches improve inductive bias and data efficiency (Rockt\u00e4schel et al., 2015; Minervini et al., 2017).\n\nWe introduce a lightweight compositional constraint for hierarchical relations and evaluate on three benchmarks and an industry dataset.\nRelated Work\n\nEnsuring safety during reinforcement learning is critical in real-world control where violations can be costly. Research has proposed both objective-level and mechanism-level solutions.\n\nSafe reinforcement learning approaches include risk-sensitive objectives such as CVaR optimization (Tamar et al., 2015; Chow et al., 2018), constrained policy optimization with safety budgets (Achiam et al., 2017; Yang et al., 2020), and shielding based on model-checking or supervisors (Alshiekh et al., 2018; Dalal et al., 2018). We develop a method that integrates model-predictive constraints with policy gradients.\n\nBenchmarks often evaluate safety in simulated robotics or navigation with cost functions approximating constraint violations (Ray et al., 2019; Bharadhwaj et al., 2021).\nRelated Work\n\nDialog state tracking (DST) has evolved from rule-based slot filling to neural architectures that jointly infer belief states across turns. Early pipeline models used hand-crafted lexicons and semantic frames (Singh and Patel, 2015), but suffered from brittleness to paraphrase and noise. Neural encoders introduced robustness by contextualizing utterances, incorporating attention over dialog history, and modeling slot-value dependencies (Lee et al., 2018; Choe and Kim, 2019).\n\nPretrained language models have further shifted the landscape by enabling few-shot generalization and open-vocabulary slot values. Fine-tuning BERT-like encoders for DST improved cross-domain transfer (Rao et al., 2020), while generative formulations cast state tracking as text-to-text prediction (Mendez et al., 2021).\n\nPrompting-based approaches have also been explored for dialog modeling (Kumar et al., 2021; Ortega and Lin, 2022; Park et al., 2023). These methods condition large language models on task instructions or few-shot exemplars to elicit latent conversational knowledge. Recent variants incorporate calibration or self-consistency to stabilize outputs (Fang et al., 2023; Zhou et al., 2023).\n\nPosition relative to this paper While we also employ pretrained sequence-to-sequence models, our focus is on handling ontology drift in long-running deployments. Specifically, we introduce an adaptive slot schema encoder that aligns evolving taxonomies with dialog evidence, and a contrastive consistency objective to mitigate spurious slot co-activations across domains.\nIntroduction\n\nSelf-supervised learning (SSL) has become the dominant paradigm for learning transferable visual features without labels. By constructing pretext tasks that expose invariances and structure inherent in data, SSL models can match or surpass supervised baselines on many downstream tasks.\n\nContrastive pretraining has been widely adopted for visual representations (Chen et al., 2020; He et al., 2020; Xie and Xu, 2021). Non-contrastive methods remove negative pairs and rely on architectural or objective asymmetries (Grill et al., 2020; Tian et al., 2021). Clustering-based methods jointly learn assignments and embeddings (Caron et al., 2018; Li and Gao, 2022).\n\nDespite these advances, industrial applications often operate under strict memory budgets and latency constraints. In this paper, we investigate compute-aware pretraining objectives that couple multi-crop augmentation with a token-subsampled backbone. We present a latency-regularized alignment loss that preserves downstream accuracy while reducing FLOPs during both pretraining and fine-tuning.\nIntroduction\n\nEfficient exploration remains a central challenge in reinforcement learning (RL), particularly in sparse-reward environments where naive strategies fail to discover rewarding states. Over-exploration, however, can waste samples and destabilize learning.\n\nExploration in reinforcement learning has been advanced by count-based bonuses, intrinsic motivation, curiosity-driven prediction error, and information-theoretic objectives (Bellemare et al., 2016; Pathak et al., 2017; Houthooft et al., 2016; Burda et al., 2019; Ta\u00efga et al., 2020).\n\nYet, when environment dynamics change over time, stale novelty estimates can encourage revisiting obsolete states. We propose a recency-aware intrinsic reward that discounts outdated novelty and couples it with conservative policy updates.\n\nAcross Atari and continuous-control domains with drifting dynamics, our method achieves superior sample efficiency and stability, and ablations confirm the role of recency in balancing exploration and exploitation.\nRelated Work\n\nDetecting anomalies in multivariate time series is vital for monitoring industrial systems and cloud services. The challenge lies in handling seasonality, rare events, and inter-variable dependencies.\n\nClassical anomaly detection leverages ARIMA residual tests, STL decomposition, and control charts, while deep methods introduce autoencoders, VAEs, GANs, LSTMs, and Transformers for reconstruction or prediction errors (Tsay, 2010; Malhotra et al., 2015; An and Cho, 2015; Li et al., 2019; Xu et al., 2021).\n\nWe present Contrastive Forecasting with Graph Priors (CFGP), which learns structure-aware representations via self-supervised objectives and uses calibrated predictive intervals to flag anomalies.\nIntroduction\n\nGeneralizing manipulation skills across objects, tasks, and environments remains a central challenge in robotics. Sparse rewards, safety constraints, and hardware variability complicate learning on physical systems. Recent work studies imitation learning, offline RL, and model-based control for dexterous manipulation (Rajeswaran et al., 2018; Lynch et al., 2020; Nagabandi et al., 2019; Ahn et al., 2022). Despite these advances, scaling data collection and ensuring sim-to-real transfer continue to be bottlenecks.\n\nWe explore a curriculum that interleaves skill discovery from teleoperation logs with conservative online updates, targeting stable improvements under limited interaction budgets.\nRelated Work\n\nConversational recommenders. Systems that interactively elicit user preferences can reduce cold-start and improve satisfaction (Sun and Zhang, 2018). Dialog policy learning for conversational recommendation has explored supervised learning, reinforcement learning, and bandit methods (Christakopoulou et al., 2016; Lei et al., 2020; Chen et al., 2019). User simulators and counterfactual logging have been proposed to address data scarcity and evaluation challenges (Li et al., 2017; Chi et al., 2020).\n\nOur study investigates preference drift over long-horizon sessions and proposes a state representation that explicitly tracks uncertainty and recency effects.\nIntroduction\n\nExplainable AI (XAI) is increasingly required for medical imaging systems used in screening and triage. Beyond predictive accuracy, clinicians demand transparency about what image features drive automated decisions and whether explanations are stable under shifts.\n\nPost-hoc attribution methods like Grad-CAM and Integrated Gradients highlight salient regions (Selvaraju et al., 2017; Sundararajan et al., 2017). Prototype- and concept-based explanations enhance interpretability (Chen et al., 2019; Kim et al., 2018). Counterfactual generation has been explored for medical images (Chang et al., 2018; Singla et al., 2021).\n\nWe focus on faithfulness under distribution shift and propose an evaluation protocol that aligns explanation stability with clinical acceptance thresholds for screening workflows.\nRelated Work\n\nProviding timely, actionable feedback at scale is central to computing education. Traditional approaches combine instructor-designed rubrics with automated tests, but coverage and specificity can be limited for diverse student solutions.\n\nAutomated feedback for programming assignments has been tackled with static analysis, dynamic test generation, and pattern mining (Ke et al., 2016; Gulwani et al., 2018; Singh et al., 2013). Recent NLP-based systems leverage code embeddings, sequence models, and pretrained language models (Allamanis et al., 2018; Feng et al., 2020; Ahmad et al., 2021). Peer learning platforms collect hints and exemplars to guide novice programmers (Piech et al., 2015; Wang et al., 2018).\n\nWhile data-driven approaches show promise, they often struggle with generalizing across tasks and providing pedagogically aligned guidance. Our work investigates structure-aware hint generation that aligns feedback to conceptual steps in problem-solving.\nRelated Work\n\nReinforcement learning (RL) has enabled robots to acquire complex behaviors directly from interaction. However, data hunger, safety, and sim-to-real transfer remain persistent obstacles for deployment in real-world settings.\n\nModel-free methods such as DDPG (Lillicrap et al., 2016), SAC (Haarnoja et al., 2018), and PPO (Schulman et al., 2017) have been widely adopted for continuous control, while model-based approaches leverage learned dynamics for sample efficiency (Deisenroth and Rasmussen, 2011; Chua et al., 2018). Recent lines of work explore offline RL (Levine et al., 2020; Kumar et al., 2020) and representation learning for policy generalization (Laskin et al., 2020; Yarats et al., 2021). Domain randomization and adaptation seek to bridge the sim-to-real gap (Tobin et al., 2017; Peng et al., 2018).\n\nWe propose a training strategy that combines curriculum learning with uncertainty-aware policy updates to improve safety and sample efficiency in robotic manipulation.\nRelated Work\n\nAutomatic speech recognition (ASR) systems increasingly rely on large encoder\u2013decoder architectures that are costly to deploy on edge devices. Knowledge distillation (KD) is a common strategy to reduce model size while preserving accuracy.\n\nKnowledge distillation for speech recognition has considered frame-level supervision, sequence-level criteria, and wordpiece distributions, transferring knowledge from stronger teachers to smaller students (Hinton et al., 2015; Kim and Rush, 2016; Kurata and Audhkhasi, 2018; Higuchi et al., 2021).\n\nOther compression techniques include quantization and pruning, which can be combined with KD but may degrade robustness to noise and speaker variability. Recent work explores multi-teacher ensembles and intermediate-layer matching to stabilize training.\n\nIn this paper, we study streaming-constrained KD with latency-aware targets, aligning teacher and student under causal masking. Our experiments on LibriSpeech and far-field corpora show improved WER\u2013latency trade-offs compared to strong baselines.\nRelated Work\n\nLarge Language Models and Prompting\nLarge language models (LLMs) exhibit emergent program synthesis capabilities when conditioned on natural language instructions and a handful of examples. While these behaviors reduce reliance on supervised datasets, the mechanisms by which prompts control generation remain only partially understood. Prior studies analyze calibration, decoding strategies, and context length effects.\n\nPrompting for Code Generation\nPrompting for code generation has explored zero-shot, few-shot, and chain-of-thought styles using large language models (Chen et al., 2021; Austin et al., 2021; Nijkamp et al., 2022; Li et al., 2023). Work on compiler-aware prompting adds execution feedback to steer generation (Liu et al., 2022; Le et al., 2022; Wang et al., 2023). Program repair and test-driven synthesis have similarly adapted prompting strategies to satisfy unit tests (Jain et al., 2022; Zhang et al., 2023).\n\nExecution-Conditioned Decoding\nBeyond static prompts, execution-conditioned decoding iteratively runs partial programs to reduce search space. Studies report gains on algorithmic problems by interleaving generation and verification under timeouts and sandboxing constraints.\n\nStructured Constraints and Type Guidance\nApproaches that inject grammar constraints or type information restrict invalid outputs and improve pass rates. These methods range from constrained beam search to type-state automata.\n\nPositioning\nWe examine the interaction between prompt structure and execution feedback and study how typed constraints alter search dynamics under limited budgets.\nRelated Work\n\nFederated learning (FL) enables on-device training with privacy and communication constraints. Ensuring rigorous privacy guarantees while preserving model utility remains a core challenge.\n\nPrivacy in federated learning has been studied via differential privacy at the client level, secure aggregation, and shuffling (McMahan et al., 2017; Kairouz et al., 2021; Bonawitz et al., 2017; Erlingsson et al., 2019). Gradient perturbation, clipping, and client subsampling are common techniques to control privacy loss (Abadi et al., 2016; Thakkar et al., 2019; Andrew et al., 2021). Auditing methods estimate empirical privacy leakage post hoc (Nasr et al., 2019; Jagielski et al., 2020).\n\nOur approach introduces client-adaptive noise schedules conditioned on participation frequency.\n\nWe empirically evaluate privacy-utility trade-offs across heterogeneous client populations.\nIntroduction\n\nInformation retrieval has shifted from lexical term matching to semantic representations that capture contextual meaning. This shift enables better recall of paraphrased content but introduces new challenges in index efficiency and training stability.\n\nNeural semantic search methods combine dual-encoders for efficient retrieval (Yao et al., 2019; Xie and Zhao, 2020) with cross-encoders for reranking (Nogueira and Cho, 2019; Li et al., 2021), and leverage hard-negative mining to improve discriminative power (Gao et al., 2021; Huang et al., 2022). Recent work also explores domain adaptation for specialized corpora such as legal and biomedical texts (Park et al., 2022; Sun et al., 2023).\n\nWe study lightweight domain adaptation under tight indexing budgets.\n",
        "completion": "Neural semantic search methods combine dual-encoders for efficient retrieval (Yao et al., 2019; Xie and Zhao, 2020) with cross-encoders for reranking (Nogueira and Cho, 2019; Li et al., 2021), and leverage hard-negative mining to improve discriminative power (Gao et al., 2021; Huang et al., 2022)."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        occurs when either:\n    a) The author describes or cites papers without connecting them to their own work/argument \n    b) Or only follows up the summary of previous works with their own contribution without explicitly highlighting the gap their work intends to research.\n    c) It does not articulate the author's perspective or motivation.\n    d) A lack of argument/opinion in the first paragraph is permissible as it serves to be the foundation of the author's argument \n    e) Lacks synthesis issues appear either as single sentences or multiple sentences.\n    Examples of lack of synthesis include:\n        i) No elaboration of own contribution/argument:\"Following early neural approaches to question answering, many subsequent studies adopt a pipeline architecture consisting of retrieval and comprehension components. The retrieval component focuses on identifying relevant documents or passages from a large corpus, while the comprehension component extracts an answer span from the retrieved text. Initial models relied on recurrent neural networks with attention mechanisms to encode questions and contexts (Seo et al., 2017; Wang et al., 2017).\"\n        ii)  No explanation of the cited works and relation to their own work: \u201cRecently, several studies have explored the use of prompting techniques with pre-trained language models to influence model outputs or access latent knowledge (Brown et al., 2020; Gao et al., 2021; Liu et al., 2021; Wei et al., 2022).\u201d \n\n        Example text: \n        Related Work\n\nDevelopers rely on code search to find relevant snippets, APIs, or examples. Unlike general document retrieval, code search must bridge natural language intent and program structure.\n\nNeural code search has been addressed with bi-encoders, cross-encoders, and dual learning (Gu et al., 2018; Husain et al., 2019; Feng et al., 2020). Structural representations incorporate ASTs, control flow, and data flow (Alon et al., 2019; Wang et al., 2020; Liu et al., 2021). Pretraining on code and NL improves retrieval metrics across languages (Ahmad et al., 2021; Guo et al., 2021).\n\nIn this paper, we introduce a language-agnostic retriever with compositional queries.\n\nWe evaluate zero-shot transfer across four programming languages.\nIntroduction\n\nGeneralization in text classification can be improved with data augmentation, especially when labeled data are scarce or imbalanced. Approaches range from rule-based edits to model-driven paraphrasing and representation-space mixing.\n\nText augmentation techniques include synonym replacement, random insertion/deletion, back-translation, paraphrase generation, and mixup in embedding or hidden spaces (Wei and Zou, 2019; Sennrich et al., 2016; Kobayashi, 2018; Guo et al., 2020). Recent work explores task-adaptive augmentation policies learned by reinforcement learning (Xie et al., 2020).\n\nEvaluation typically considers robustness to domain shift, label noise, and distributional skew across multiple benchmarks (Pruksachatkun et al., 2020; Hendrycks et al., 2020).\nRelated Work\n\nKnowledge graph completion predicts missing links by learning entity and relation representations. Methods vary in how they encode semantics and handle patterns like symmetry, hierarchy, and composition.\n\nTranslation-based knowledge graph embeddings model relations as translations in vector space (Bordes et al., 2013; Wang et al., 2014), while bilinear and neural models capture more complex interactions (Nickel et al., 2011; Trouillon et al., 2016; Sun et al., 2019). Regularization and rule-guided approaches improve inductive bias and data efficiency (Rockt\u00e4schel et al., 2015; Minervini et al., 2017).\n\nWe introduce a lightweight compositional constraint for hierarchical relations and evaluate on three benchmarks and an industry dataset.\nRelated Work\n\nEnsuring safety during reinforcement learning is critical in real-world control where violations can be costly. Research has proposed both objective-level and mechanism-level solutions.\n\nSafe reinforcement learning approaches include risk-sensitive objectives such as CVaR optimization (Tamar et al., 2015; Chow et al., 2018), constrained policy optimization with safety budgets (Achiam et al., 2017; Yang et al., 2020), and shielding based on model-checking or supervisors (Alshiekh et al., 2018; Dalal et al., 2018). We develop a method that integrates model-predictive constraints with policy gradients.\n\nBenchmarks often evaluate safety in simulated robotics or navigation with cost functions approximating constraint violations (Ray et al., 2019; Bharadhwaj et al., 2021).\nRelated Work\n\nDialog state tracking (DST) has evolved from rule-based slot filling to neural architectures that jointly infer belief states across turns. Early pipeline models used hand-crafted lexicons and semantic frames (Singh and Patel, 2015), but suffered from brittleness to paraphrase and noise. Neural encoders introduced robustness by contextualizing utterances, incorporating attention over dialog history, and modeling slot-value dependencies (Lee et al., 2018; Choe and Kim, 2019).\n\nPretrained language models have further shifted the landscape by enabling few-shot generalization and open-vocabulary slot values. Fine-tuning BERT-like encoders for DST improved cross-domain transfer (Rao et al., 2020), while generative formulations cast state tracking as text-to-text prediction (Mendez et al., 2021).\n\nPrompting-based approaches have also been explored for dialog modeling (Kumar et al., 2021; Ortega and Lin, 2022; Park et al., 2023). These methods condition large language models on task instructions or few-shot exemplars to elicit latent conversational knowledge. Recent variants incorporate calibration or self-consistency to stabilize outputs (Fang et al., 2023; Zhou et al., 2023).\n\nPosition relative to this paper While we also employ pretrained sequence-to-sequence models, our focus is on handling ontology drift in long-running deployments. Specifically, we introduce an adaptive slot schema encoder that aligns evolving taxonomies with dialog evidence, and a contrastive consistency objective to mitigate spurious slot co-activations across domains.\nIntroduction\n\nSelf-supervised learning (SSL) has become the dominant paradigm for learning transferable visual features without labels. By constructing pretext tasks that expose invariances and structure inherent in data, SSL models can match or surpass supervised baselines on many downstream tasks.\n\nContrastive pretraining has been widely adopted for visual representations (Chen et al., 2020; He et al., 2020; Xie and Xu, 2021). Non-contrastive methods remove negative pairs and rely on architectural or objective asymmetries (Grill et al., 2020; Tian et al., 2021). Clustering-based methods jointly learn assignments and embeddings (Caron et al., 2018; Li and Gao, 2022).\n\nDespite these advances, industrial applications often operate under strict memory budgets and latency constraints. In this paper, we investigate compute-aware pretraining objectives that couple multi-crop augmentation with a token-subsampled backbone. We present a latency-regularized alignment loss that preserves downstream accuracy while reducing FLOPs during both pretraining and fine-tuning.\nIntroduction\n\nEfficient exploration remains a central challenge in reinforcement learning (RL), particularly in sparse-reward environments where naive strategies fail to discover rewarding states. Over-exploration, however, can waste samples and destabilize learning.\n\nExploration in reinforcement learning has been advanced by count-based bonuses, intrinsic motivation, curiosity-driven prediction error, and information-theoretic objectives (Bellemare et al., 2016; Pathak et al., 2017; Houthooft et al., 2016; Burda et al., 2019; Ta\u00efga et al., 2020).\n\nYet, when environment dynamics change over time, stale novelty estimates can encourage revisiting obsolete states. We propose a recency-aware intrinsic reward that discounts outdated novelty and couples it with conservative policy updates.\n\nAcross Atari and continuous-control domains with drifting dynamics, our method achieves superior sample efficiency and stability, and ablations confirm the role of recency in balancing exploration and exploitation.\nRelated Work\n\nDetecting anomalies in multivariate time series is vital for monitoring industrial systems and cloud services. The challenge lies in handling seasonality, rare events, and inter-variable dependencies.\n\nClassical anomaly detection leverages ARIMA residual tests, STL decomposition, and control charts, while deep methods introduce autoencoders, VAEs, GANs, LSTMs, and Transformers for reconstruction or prediction errors (Tsay, 2010; Malhotra et al., 2015; An and Cho, 2015; Li et al., 2019; Xu et al., 2021).\n\nWe present Contrastive Forecasting with Graph Priors (CFGP), which learns structure-aware representations via self-supervised objectives and uses calibrated predictive intervals to flag anomalies.\nIntroduction\n\nGeneralizing manipulation skills across objects, tasks, and environments remains a central challenge in robotics. Sparse rewards, safety constraints, and hardware variability complicate learning on physical systems. Recent work studies imitation learning, offline RL, and model-based control for dexterous manipulation (Rajeswaran et al., 2018; Lynch et al., 2020; Nagabandi et al., 2019; Ahn et al., 2022). Despite these advances, scaling data collection and ensuring sim-to-real transfer continue to be bottlenecks.\n\nWe explore a curriculum that interleaves skill discovery from teleoperation logs with conservative online updates, targeting stable improvements under limited interaction budgets.\nRelated Work\n\nConversational recommenders. Systems that interactively elicit user preferences can reduce cold-start and improve satisfaction (Sun and Zhang, 2018). Dialog policy learning for conversational recommendation has explored supervised learning, reinforcement learning, and bandit methods (Christakopoulou et al., 2016; Lei et al., 2020; Chen et al., 2019). User simulators and counterfactual logging have been proposed to address data scarcity and evaluation challenges (Li et al., 2017; Chi et al., 2020).\n\nOur study investigates preference drift over long-horizon sessions and proposes a state representation that explicitly tracks uncertainty and recency effects.\nIntroduction\n\nExplainable AI (XAI) is increasingly required for medical imaging systems used in screening and triage. Beyond predictive accuracy, clinicians demand transparency about what image features drive automated decisions and whether explanations are stable under shifts.\n\nPost-hoc attribution methods like Grad-CAM and Integrated Gradients highlight salient regions (Selvaraju et al., 2017; Sundararajan et al., 2017). Prototype- and concept-based explanations enhance interpretability (Chen et al., 2019; Kim et al., 2018). Counterfactual generation has been explored for medical images (Chang et al., 2018; Singla et al., 2021).\n\nWe focus on faithfulness under distribution shift and propose an evaluation protocol that aligns explanation stability with clinical acceptance thresholds for screening workflows.\nRelated Work\n\nProviding timely, actionable feedback at scale is central to computing education. Traditional approaches combine instructor-designed rubrics with automated tests, but coverage and specificity can be limited for diverse student solutions.\n\nAutomated feedback for programming assignments has been tackled with static analysis, dynamic test generation, and pattern mining (Ke et al., 2016; Gulwani et al., 2018; Singh et al., 2013). Recent NLP-based systems leverage code embeddings, sequence models, and pretrained language models (Allamanis et al., 2018; Feng et al., 2020; Ahmad et al., 2021). Peer learning platforms collect hints and exemplars to guide novice programmers (Piech et al., 2015; Wang et al., 2018).\n\nWhile data-driven approaches show promise, they often struggle with generalizing across tasks and providing pedagogically aligned guidance. Our work investigates structure-aware hint generation that aligns feedback to conceptual steps in problem-solving.\nRelated Work\n\nReinforcement learning (RL) has enabled robots to acquire complex behaviors directly from interaction. However, data hunger, safety, and sim-to-real transfer remain persistent obstacles for deployment in real-world settings.\n\nModel-free methods such as DDPG (Lillicrap et al., 2016), SAC (Haarnoja et al., 2018), and PPO (Schulman et al., 2017) have been widely adopted for continuous control, while model-based approaches leverage learned dynamics for sample efficiency (Deisenroth and Rasmussen, 2011; Chua et al., 2018). Recent lines of work explore offline RL (Levine et al., 2020; Kumar et al., 2020) and representation learning for policy generalization (Laskin et al., 2020; Yarats et al., 2021). Domain randomization and adaptation seek to bridge the sim-to-real gap (Tobin et al., 2017; Peng et al., 2018).\n\nWe propose a training strategy that combines curriculum learning with uncertainty-aware policy updates to improve safety and sample efficiency in robotic manipulation.\nRelated Work\n\nAutomatic speech recognition (ASR) systems increasingly rely on large encoder\u2013decoder architectures that are costly to deploy on edge devices. Knowledge distillation (KD) is a common strategy to reduce model size while preserving accuracy.\n\nKnowledge distillation for speech recognition has considered frame-level supervision, sequence-level criteria, and wordpiece distributions, transferring knowledge from stronger teachers to smaller students (Hinton et al., 2015; Kim and Rush, 2016; Kurata and Audhkhasi, 2018; Higuchi et al., 2021).\n\nOther compression techniques include quantization and pruning, which can be combined with KD but may degrade robustness to noise and speaker variability. Recent work explores multi-teacher ensembles and intermediate-layer matching to stabilize training.\n\nIn this paper, we study streaming-constrained KD with latency-aware targets, aligning teacher and student under causal masking. Our experiments on LibriSpeech and far-field corpora show improved WER\u2013latency trade-offs compared to strong baselines.\nRelated Work\n\nLarge Language Models and Prompting\nLarge language models (LLMs) exhibit emergent program synthesis capabilities when conditioned on natural language instructions and a handful of examples. While these behaviors reduce reliance on supervised datasets, the mechanisms by which prompts control generation remain only partially understood. Prior studies analyze calibration, decoding strategies, and context length effects.\n\nPrompting for Code Generation\nPrompting for code generation has explored zero-shot, few-shot, and chain-of-thought styles using large language models (Chen et al., 2021; Austin et al., 2021; Nijkamp et al., 2022; Li et al., 2023). Work on compiler-aware prompting adds execution feedback to steer generation (Liu et al., 2022; Le et al., 2022; Wang et al., 2023). Program repair and test-driven synthesis have similarly adapted prompting strategies to satisfy unit tests (Jain et al., 2022; Zhang et al., 2023).\n\nExecution-Conditioned Decoding\nBeyond static prompts, execution-conditioned decoding iteratively runs partial programs to reduce search space. Studies report gains on algorithmic problems by interleaving generation and verification under timeouts and sandboxing constraints.\n\nStructured Constraints and Type Guidance\nApproaches that inject grammar constraints or type information restrict invalid outputs and improve pass rates. These methods range from constrained beam search to type-state automata.\n\nPositioning\nWe examine the interaction between prompt structure and execution feedback and study how typed constraints alter search dynamics under limited budgets.\nRelated Work\n\nFederated learning (FL) enables on-device training with privacy and communication constraints. Ensuring rigorous privacy guarantees while preserving model utility remains a core challenge.\n\nPrivacy in federated learning has been studied via differential privacy at the client level, secure aggregation, and shuffling (McMahan et al., 2017; Kairouz et al., 2021; Bonawitz et al., 2017; Erlingsson et al., 2019). Gradient perturbation, clipping, and client subsampling are common techniques to control privacy loss (Abadi et al., 2016; Thakkar et al., 2019; Andrew et al., 2021). Auditing methods estimate empirical privacy leakage post hoc (Nasr et al., 2019; Jagielski et al., 2020).\n\nOur approach introduces client-adaptive noise schedules conditioned on participation frequency.\n\nWe empirically evaluate privacy-utility trade-offs across heterogeneous client populations.\nIntroduction\n\nInformation retrieval has shifted from lexical term matching to semantic representations that capture contextual meaning. This shift enables better recall of paraphrased content but introduces new challenges in index efficiency and training stability.\n\nNeural semantic search methods combine dual-encoders for efficient retrieval (Yao et al., 2019; Xie and Zhao, 2020) with cross-encoders for reranking (Nogueira and Cho, 2019; Li et al., 2021), and leverage hard-negative mining to improve discriminative power (Gao et al., 2021; Huang et al., 2022). Recent work also explores domain adaptation for specialized corpora such as legal and biomedical texts (Park et al., 2022; Sun et al., 2023).\n\nWe study lightweight domain adaptation under tight indexing budgets.\nRelated Work\n\nDetecting anomalies in time-series is a long-standing problem with applications in monitoring, finance, and industrial IoT. Methods vary widely in assumptions, supervision requirements, and scalability.\n\nTime-series anomaly detection spans classical statistical tests, isolation-based methods, and deep learning models such as autoencoders, temporal convolutional networks, and Transformers (Gupta et al., 2014; Liu et al., 2008; Malhotra et al., 2016; Xu et al., 2020). Synthetic anomaly injection and semi-supervised training are also common practices (Zhang et al., 2019; Shen et al., 2021).\n\nBenchmarking efforts have sought consistent evaluation protocols across datasets with different anomaly types and frequencies (Hundman et al., 2018; Wu and Keogh, 2021).\n",
        "completion": "Time-series anomaly detection spans classical statistical tests, isolation-based methods, and deep learning models such as autoencoders, temporal convolutional networks, and Transformers (Gupta et al., 2014; Liu et al., 2008; Malhotra et al., 2016; Xu et al., 2020). Synthetic anomaly injection and semi-supervised training are also common practices (Zhang et al., 2019; Shen et al., 2021)."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        occurs when either:\n    a) The author describes or cites papers without connecting them to their own work/argument \n    b) Or only follows up the summary of previous works with their own contribution without explicitly highlighting the gap their work intends to research.\n    c) It does not articulate the author's perspective or motivation.\n    d) A lack of argument/opinion in the first paragraph is permissible as it serves to be the foundation of the author's argument \n    e) Lacks synthesis issues appear either as single sentences or multiple sentences.\n    Examples of lack of synthesis include:\n        i) No elaboration of own contribution/argument:\"Following early neural approaches to question answering, many subsequent studies adopt a pipeline architecture consisting of retrieval and comprehension components. The retrieval component focuses on identifying relevant documents or passages from a large corpus, while the comprehension component extracts an answer span from the retrieved text. Initial models relied on recurrent neural networks with attention mechanisms to encode questions and contexts (Seo et al., 2017; Wang et al., 2017).\"\n        ii)  No explanation of the cited works and relation to their own work: \u201cRecently, several studies have explored the use of prompting techniques with pre-trained language models to influence model outputs or access latent knowledge (Brown et al., 2020; Gao et al., 2021; Liu et al., 2021; Wei et al., 2022).\u201d \n\n        Example text: \n        Related Work\n\nDevelopers rely on code search to find relevant snippets, APIs, or examples. Unlike general document retrieval, code search must bridge natural language intent and program structure.\n\nNeural code search has been addressed with bi-encoders, cross-encoders, and dual learning (Gu et al., 2018; Husain et al., 2019; Feng et al., 2020). Structural representations incorporate ASTs, control flow, and data flow (Alon et al., 2019; Wang et al., 2020; Liu et al., 2021). Pretraining on code and NL improves retrieval metrics across languages (Ahmad et al., 2021; Guo et al., 2021).\n\nIn this paper, we introduce a language-agnostic retriever with compositional queries.\n\nWe evaluate zero-shot transfer across four programming languages.\nIntroduction\n\nGeneralization in text classification can be improved with data augmentation, especially when labeled data are scarce or imbalanced. Approaches range from rule-based edits to model-driven paraphrasing and representation-space mixing.\n\nText augmentation techniques include synonym replacement, random insertion/deletion, back-translation, paraphrase generation, and mixup in embedding or hidden spaces (Wei and Zou, 2019; Sennrich et al., 2016; Kobayashi, 2018; Guo et al., 2020). Recent work explores task-adaptive augmentation policies learned by reinforcement learning (Xie et al., 2020).\n\nEvaluation typically considers robustness to domain shift, label noise, and distributional skew across multiple benchmarks (Pruksachatkun et al., 2020; Hendrycks et al., 2020).\nRelated Work\n\nKnowledge graph completion predicts missing links by learning entity and relation representations. Methods vary in how they encode semantics and handle patterns like symmetry, hierarchy, and composition.\n\nTranslation-based knowledge graph embeddings model relations as translations in vector space (Bordes et al., 2013; Wang et al., 2014), while bilinear and neural models capture more complex interactions (Nickel et al., 2011; Trouillon et al., 2016; Sun et al., 2019). Regularization and rule-guided approaches improve inductive bias and data efficiency (Rockt\u00e4schel et al., 2015; Minervini et al., 2017).\n\nWe introduce a lightweight compositional constraint for hierarchical relations and evaluate on three benchmarks and an industry dataset.\nRelated Work\n\nEnsuring safety during reinforcement learning is critical in real-world control where violations can be costly. Research has proposed both objective-level and mechanism-level solutions.\n\nSafe reinforcement learning approaches include risk-sensitive objectives such as CVaR optimization (Tamar et al., 2015; Chow et al., 2018), constrained policy optimization with safety budgets (Achiam et al., 2017; Yang et al., 2020), and shielding based on model-checking or supervisors (Alshiekh et al., 2018; Dalal et al., 2018). We develop a method that integrates model-predictive constraints with policy gradients.\n\nBenchmarks often evaluate safety in simulated robotics or navigation with cost functions approximating constraint violations (Ray et al., 2019; Bharadhwaj et al., 2021).\nRelated Work\n\nDialog state tracking (DST) has evolved from rule-based slot filling to neural architectures that jointly infer belief states across turns. Early pipeline models used hand-crafted lexicons and semantic frames (Singh and Patel, 2015), but suffered from brittleness to paraphrase and noise. Neural encoders introduced robustness by contextualizing utterances, incorporating attention over dialog history, and modeling slot-value dependencies (Lee et al., 2018; Choe and Kim, 2019).\n\nPretrained language models have further shifted the landscape by enabling few-shot generalization and open-vocabulary slot values. Fine-tuning BERT-like encoders for DST improved cross-domain transfer (Rao et al., 2020), while generative formulations cast state tracking as text-to-text prediction (Mendez et al., 2021).\n\nPrompting-based approaches have also been explored for dialog modeling (Kumar et al., 2021; Ortega and Lin, 2022; Park et al., 2023). These methods condition large language models on task instructions or few-shot exemplars to elicit latent conversational knowledge. Recent variants incorporate calibration or self-consistency to stabilize outputs (Fang et al., 2023; Zhou et al., 2023).\n\nPosition relative to this paper While we also employ pretrained sequence-to-sequence models, our focus is on handling ontology drift in long-running deployments. Specifically, we introduce an adaptive slot schema encoder that aligns evolving taxonomies with dialog evidence, and a contrastive consistency objective to mitigate spurious slot co-activations across domains.\nIntroduction\n\nSelf-supervised learning (SSL) has become the dominant paradigm for learning transferable visual features without labels. By constructing pretext tasks that expose invariances and structure inherent in data, SSL models can match or surpass supervised baselines on many downstream tasks.\n\nContrastive pretraining has been widely adopted for visual representations (Chen et al., 2020; He et al., 2020; Xie and Xu, 2021). Non-contrastive methods remove negative pairs and rely on architectural or objective asymmetries (Grill et al., 2020; Tian et al., 2021). Clustering-based methods jointly learn assignments and embeddings (Caron et al., 2018; Li and Gao, 2022).\n\nDespite these advances, industrial applications often operate under strict memory budgets and latency constraints. In this paper, we investigate compute-aware pretraining objectives that couple multi-crop augmentation with a token-subsampled backbone. We present a latency-regularized alignment loss that preserves downstream accuracy while reducing FLOPs during both pretraining and fine-tuning.\nIntroduction\n\nEfficient exploration remains a central challenge in reinforcement learning (RL), particularly in sparse-reward environments where naive strategies fail to discover rewarding states. Over-exploration, however, can waste samples and destabilize learning.\n\nExploration in reinforcement learning has been advanced by count-based bonuses, intrinsic motivation, curiosity-driven prediction error, and information-theoretic objectives (Bellemare et al., 2016; Pathak et al., 2017; Houthooft et al., 2016; Burda et al., 2019; Ta\u00efga et al., 2020).\n\nYet, when environment dynamics change over time, stale novelty estimates can encourage revisiting obsolete states. We propose a recency-aware intrinsic reward that discounts outdated novelty and couples it with conservative policy updates.\n\nAcross Atari and continuous-control domains with drifting dynamics, our method achieves superior sample efficiency and stability, and ablations confirm the role of recency in balancing exploration and exploitation.\nRelated Work\n\nDetecting anomalies in multivariate time series is vital for monitoring industrial systems and cloud services. The challenge lies in handling seasonality, rare events, and inter-variable dependencies.\n\nClassical anomaly detection leverages ARIMA residual tests, STL decomposition, and control charts, while deep methods introduce autoencoders, VAEs, GANs, LSTMs, and Transformers for reconstruction or prediction errors (Tsay, 2010; Malhotra et al., 2015; An and Cho, 2015; Li et al., 2019; Xu et al., 2021).\n\nWe present Contrastive Forecasting with Graph Priors (CFGP), which learns structure-aware representations via self-supervised objectives and uses calibrated predictive intervals to flag anomalies.\nIntroduction\n\nGeneralizing manipulation skills across objects, tasks, and environments remains a central challenge in robotics. Sparse rewards, safety constraints, and hardware variability complicate learning on physical systems. Recent work studies imitation learning, offline RL, and model-based control for dexterous manipulation (Rajeswaran et al., 2018; Lynch et al., 2020; Nagabandi et al., 2019; Ahn et al., 2022). Despite these advances, scaling data collection and ensuring sim-to-real transfer continue to be bottlenecks.\n\nWe explore a curriculum that interleaves skill discovery from teleoperation logs with conservative online updates, targeting stable improvements under limited interaction budgets.\nRelated Work\n\nConversational recommenders. Systems that interactively elicit user preferences can reduce cold-start and improve satisfaction (Sun and Zhang, 2018). Dialog policy learning for conversational recommendation has explored supervised learning, reinforcement learning, and bandit methods (Christakopoulou et al., 2016; Lei et al., 2020; Chen et al., 2019). User simulators and counterfactual logging have been proposed to address data scarcity and evaluation challenges (Li et al., 2017; Chi et al., 2020).\n\nOur study investigates preference drift over long-horizon sessions and proposes a state representation that explicitly tracks uncertainty and recency effects.\nIntroduction\n\nExplainable AI (XAI) is increasingly required for medical imaging systems used in screening and triage. Beyond predictive accuracy, clinicians demand transparency about what image features drive automated decisions and whether explanations are stable under shifts.\n\nPost-hoc attribution methods like Grad-CAM and Integrated Gradients highlight salient regions (Selvaraju et al., 2017; Sundararajan et al., 2017). Prototype- and concept-based explanations enhance interpretability (Chen et al., 2019; Kim et al., 2018). Counterfactual generation has been explored for medical images (Chang et al., 2018; Singla et al., 2021).\n\nWe focus on faithfulness under distribution shift and propose an evaluation protocol that aligns explanation stability with clinical acceptance thresholds for screening workflows.\nRelated Work\n\nProviding timely, actionable feedback at scale is central to computing education. Traditional approaches combine instructor-designed rubrics with automated tests, but coverage and specificity can be limited for diverse student solutions.\n\nAutomated feedback for programming assignments has been tackled with static analysis, dynamic test generation, and pattern mining (Ke et al., 2016; Gulwani et al., 2018; Singh et al., 2013). Recent NLP-based systems leverage code embeddings, sequence models, and pretrained language models (Allamanis et al., 2018; Feng et al., 2020; Ahmad et al., 2021). Peer learning platforms collect hints and exemplars to guide novice programmers (Piech et al., 2015; Wang et al., 2018).\n\nWhile data-driven approaches show promise, they often struggle with generalizing across tasks and providing pedagogically aligned guidance. Our work investigates structure-aware hint generation that aligns feedback to conceptual steps in problem-solving.\nRelated Work\n\nReinforcement learning (RL) has enabled robots to acquire complex behaviors directly from interaction. However, data hunger, safety, and sim-to-real transfer remain persistent obstacles for deployment in real-world settings.\n\nModel-free methods such as DDPG (Lillicrap et al., 2016), SAC (Haarnoja et al., 2018), and PPO (Schulman et al., 2017) have been widely adopted for continuous control, while model-based approaches leverage learned dynamics for sample efficiency (Deisenroth and Rasmussen, 2011; Chua et al., 2018). Recent lines of work explore offline RL (Levine et al., 2020; Kumar et al., 2020) and representation learning for policy generalization (Laskin et al., 2020; Yarats et al., 2021). Domain randomization and adaptation seek to bridge the sim-to-real gap (Tobin et al., 2017; Peng et al., 2018).\n\nWe propose a training strategy that combines curriculum learning with uncertainty-aware policy updates to improve safety and sample efficiency in robotic manipulation.\nRelated Work\n\nAutomatic speech recognition (ASR) systems increasingly rely on large encoder\u2013decoder architectures that are costly to deploy on edge devices. Knowledge distillation (KD) is a common strategy to reduce model size while preserving accuracy.\n\nKnowledge distillation for speech recognition has considered frame-level supervision, sequence-level criteria, and wordpiece distributions, transferring knowledge from stronger teachers to smaller students (Hinton et al., 2015; Kim and Rush, 2016; Kurata and Audhkhasi, 2018; Higuchi et al., 2021).\n\nOther compression techniques include quantization and pruning, which can be combined with KD but may degrade robustness to noise and speaker variability. Recent work explores multi-teacher ensembles and intermediate-layer matching to stabilize training.\n\nIn this paper, we study streaming-constrained KD with latency-aware targets, aligning teacher and student under causal masking. Our experiments on LibriSpeech and far-field corpora show improved WER\u2013latency trade-offs compared to strong baselines.\nRelated Work\n\nLarge Language Models and Prompting\nLarge language models (LLMs) exhibit emergent program synthesis capabilities when conditioned on natural language instructions and a handful of examples. While these behaviors reduce reliance on supervised datasets, the mechanisms by which prompts control generation remain only partially understood. Prior studies analyze calibration, decoding strategies, and context length effects.\n\nPrompting for Code Generation\nPrompting for code generation has explored zero-shot, few-shot, and chain-of-thought styles using large language models (Chen et al., 2021; Austin et al., 2021; Nijkamp et al., 2022; Li et al., 2023). Work on compiler-aware prompting adds execution feedback to steer generation (Liu et al., 2022; Le et al., 2022; Wang et al., 2023). Program repair and test-driven synthesis have similarly adapted prompting strategies to satisfy unit tests (Jain et al., 2022; Zhang et al., 2023).\n\nExecution-Conditioned Decoding\nBeyond static prompts, execution-conditioned decoding iteratively runs partial programs to reduce search space. Studies report gains on algorithmic problems by interleaving generation and verification under timeouts and sandboxing constraints.\n\nStructured Constraints and Type Guidance\nApproaches that inject grammar constraints or type information restrict invalid outputs and improve pass rates. These methods range from constrained beam search to type-state automata.\n\nPositioning\nWe examine the interaction between prompt structure and execution feedback and study how typed constraints alter search dynamics under limited budgets.\nRelated Work\n\nFederated learning (FL) enables on-device training with privacy and communication constraints. Ensuring rigorous privacy guarantees while preserving model utility remains a core challenge.\n\nPrivacy in federated learning has been studied via differential privacy at the client level, secure aggregation, and shuffling (McMahan et al., 2017; Kairouz et al., 2021; Bonawitz et al., 2017; Erlingsson et al., 2019). Gradient perturbation, clipping, and client subsampling are common techniques to control privacy loss (Abadi et al., 2016; Thakkar et al., 2019; Andrew et al., 2021). Auditing methods estimate empirical privacy leakage post hoc (Nasr et al., 2019; Jagielski et al., 2020).\n\nOur approach introduces client-adaptive noise schedules conditioned on participation frequency.\n\nWe empirically evaluate privacy-utility trade-offs across heterogeneous client populations.\nIntroduction\n\nInformation retrieval has shifted from lexical term matching to semantic representations that capture contextual meaning. This shift enables better recall of paraphrased content but introduces new challenges in index efficiency and training stability.\n\nNeural semantic search methods combine dual-encoders for efficient retrieval (Yao et al., 2019; Xie and Zhao, 2020) with cross-encoders for reranking (Nogueira and Cho, 2019; Li et al., 2021), and leverage hard-negative mining to improve discriminative power (Gao et al., 2021; Huang et al., 2022). Recent work also explores domain adaptation for specialized corpora such as legal and biomedical texts (Park et al., 2022; Sun et al., 2023).\n\nWe study lightweight domain adaptation under tight indexing budgets.\nRelated Work\n\nDetecting anomalies in time-series is a long-standing problem with applications in monitoring, finance, and industrial IoT. Methods vary widely in assumptions, supervision requirements, and scalability.\n\nTime-series anomaly detection spans classical statistical tests, isolation-based methods, and deep learning models such as autoencoders, temporal convolutional networks, and Transformers (Gupta et al., 2014; Liu et al., 2008; Malhotra et al., 2016; Xu et al., 2020). Synthetic anomaly injection and semi-supervised training are also common practices (Zhang et al., 2019; Shen et al., 2021).\n\nBenchmarking efforts have sought consistent evaluation protocols across datasets with different anomaly types and frequencies (Hundman et al., 2018; Wu and Keogh, 2021).\nRelated Work\n\nPredicting molecular properties from structure has catalyzed a broad literature at the intersection of cheminformatics and geometric deep learning. Approaches differ in how they encode graph topology, chemical attributes, and geometric constraints.\n\nGraph representation learning methods such as spectral GCNs, spatial message passing networks, and attention-based GNNs have been widely applied to molecular property prediction (Kipf and Welling, 2017; Gilmer et al., 2017; Veli\u010dkovi\u0107 et al., 2018). Extensions include edge-conditioned convolutions, higher-order structures, and equivariant networks for 3D geometries (Simonovsky and Komodakis, 2017; Batzner et al., 2022).\n\nPretraining strategies on large unlabeled molecule corpora with contrastive or masked node prediction objectives have further improved generalization, especially in low-data regimes (Hu et al., 2020; Rong et al., 2020).\n",
        "completion": "Graph representation learning methods such as spectral GCNs, spatial message passing networks, and attention-based GNNs have been widely applied to molecular property prediction (Kipf and Welling, 2017; Gilmer et al., 2017; Veli\u010dkovi\u0107 et al., 2018). Extensions include edge-conditioned convolutions, higher-order structures, and equivariant networks for 3D geometries (Simonovsky and Komodakis, 2017; Batzner et al., 2022)."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        occurs when either:\n    a) The author describes or cites papers without connecting them to their own work/argument \n    b) Or only follows up the summary of previous works with their own contribution without explicitly highlighting the gap their work intends to research.\n    c) It does not articulate the author's perspective or motivation.\n    d) A lack of argument/opinion in the first paragraph is permissible as it serves to be the foundation of the author's argument \n    e) Lacks synthesis issues appear either as single sentences or multiple sentences.\n    Examples of lack of synthesis include:\n        i) No elaboration of own contribution/argument:\"Following early neural approaches to question answering, many subsequent studies adopt a pipeline architecture consisting of retrieval and comprehension components. The retrieval component focuses on identifying relevant documents or passages from a large corpus, while the comprehension component extracts an answer span from the retrieved text. Initial models relied on recurrent neural networks with attention mechanisms to encode questions and contexts (Seo et al., 2017; Wang et al., 2017).\"\n        ii)  No explanation of the cited works and relation to their own work: \u201cRecently, several studies have explored the use of prompting techniques with pre-trained language models to influence model outputs or access latent knowledge (Brown et al., 2020; Gao et al., 2021; Liu et al., 2021; Wei et al., 2022).\u201d \n\n        Example text: \n        Related Work\n\nDevelopers rely on code search to find relevant snippets, APIs, or examples. Unlike general document retrieval, code search must bridge natural language intent and program structure.\n\nNeural code search has been addressed with bi-encoders, cross-encoders, and dual learning (Gu et al., 2018; Husain et al., 2019; Feng et al., 2020). Structural representations incorporate ASTs, control flow, and data flow (Alon et al., 2019; Wang et al., 2020; Liu et al., 2021). Pretraining on code and NL improves retrieval metrics across languages (Ahmad et al., 2021; Guo et al., 2021).\n\nIn this paper, we introduce a language-agnostic retriever with compositional queries.\n\nWe evaluate zero-shot transfer across four programming languages.\nIntroduction\n\nGeneralization in text classification can be improved with data augmentation, especially when labeled data are scarce or imbalanced. Approaches range from rule-based edits to model-driven paraphrasing and representation-space mixing.\n\nText augmentation techniques include synonym replacement, random insertion/deletion, back-translation, paraphrase generation, and mixup in embedding or hidden spaces (Wei and Zou, 2019; Sennrich et al., 2016; Kobayashi, 2018; Guo et al., 2020). Recent work explores task-adaptive augmentation policies learned by reinforcement learning (Xie et al., 2020).\n\nEvaluation typically considers robustness to domain shift, label noise, and distributional skew across multiple benchmarks (Pruksachatkun et al., 2020; Hendrycks et al., 2020).\nRelated Work\n\nKnowledge graph completion predicts missing links by learning entity and relation representations. Methods vary in how they encode semantics and handle patterns like symmetry, hierarchy, and composition.\n\nTranslation-based knowledge graph embeddings model relations as translations in vector space (Bordes et al., 2013; Wang et al., 2014), while bilinear and neural models capture more complex interactions (Nickel et al., 2011; Trouillon et al., 2016; Sun et al., 2019). Regularization and rule-guided approaches improve inductive bias and data efficiency (Rockt\u00e4schel et al., 2015; Minervini et al., 2017).\n\nWe introduce a lightweight compositional constraint for hierarchical relations and evaluate on three benchmarks and an industry dataset.\nRelated Work\n\nEnsuring safety during reinforcement learning is critical in real-world control where violations can be costly. Research has proposed both objective-level and mechanism-level solutions.\n\nSafe reinforcement learning approaches include risk-sensitive objectives such as CVaR optimization (Tamar et al., 2015; Chow et al., 2018), constrained policy optimization with safety budgets (Achiam et al., 2017; Yang et al., 2020), and shielding based on model-checking or supervisors (Alshiekh et al., 2018; Dalal et al., 2018). We develop a method that integrates model-predictive constraints with policy gradients.\n\nBenchmarks often evaluate safety in simulated robotics or navigation with cost functions approximating constraint violations (Ray et al., 2019; Bharadhwaj et al., 2021).\nRelated Work\n\nDialog state tracking (DST) has evolved from rule-based slot filling to neural architectures that jointly infer belief states across turns. Early pipeline models used hand-crafted lexicons and semantic frames (Singh and Patel, 2015), but suffered from brittleness to paraphrase and noise. Neural encoders introduced robustness by contextualizing utterances, incorporating attention over dialog history, and modeling slot-value dependencies (Lee et al., 2018; Choe and Kim, 2019).\n\nPretrained language models have further shifted the landscape by enabling few-shot generalization and open-vocabulary slot values. Fine-tuning BERT-like encoders for DST improved cross-domain transfer (Rao et al., 2020), while generative formulations cast state tracking as text-to-text prediction (Mendez et al., 2021).\n\nPrompting-based approaches have also been explored for dialog modeling (Kumar et al., 2021; Ortega and Lin, 2022; Park et al., 2023). These methods condition large language models on task instructions or few-shot exemplars to elicit latent conversational knowledge. Recent variants incorporate calibration or self-consistency to stabilize outputs (Fang et al., 2023; Zhou et al., 2023).\n\nPosition relative to this paper While we also employ pretrained sequence-to-sequence models, our focus is on handling ontology drift in long-running deployments. Specifically, we introduce an adaptive slot schema encoder that aligns evolving taxonomies with dialog evidence, and a contrastive consistency objective to mitigate spurious slot co-activations across domains.\nIntroduction\n\nSelf-supervised learning (SSL) has become the dominant paradigm for learning transferable visual features without labels. By constructing pretext tasks that expose invariances and structure inherent in data, SSL models can match or surpass supervised baselines on many downstream tasks.\n\nContrastive pretraining has been widely adopted for visual representations (Chen et al., 2020; He et al., 2020; Xie and Xu, 2021). Non-contrastive methods remove negative pairs and rely on architectural or objective asymmetries (Grill et al., 2020; Tian et al., 2021). Clustering-based methods jointly learn assignments and embeddings (Caron et al., 2018; Li and Gao, 2022).\n\nDespite these advances, industrial applications often operate under strict memory budgets and latency constraints. In this paper, we investigate compute-aware pretraining objectives that couple multi-crop augmentation with a token-subsampled backbone. We present a latency-regularized alignment loss that preserves downstream accuracy while reducing FLOPs during both pretraining and fine-tuning.\nIntroduction\n\nEfficient exploration remains a central challenge in reinforcement learning (RL), particularly in sparse-reward environments where naive strategies fail to discover rewarding states. Over-exploration, however, can waste samples and destabilize learning.\n\nExploration in reinforcement learning has been advanced by count-based bonuses, intrinsic motivation, curiosity-driven prediction error, and information-theoretic objectives (Bellemare et al., 2016; Pathak et al., 2017; Houthooft et al., 2016; Burda et al., 2019; Ta\u00efga et al., 2020).\n\nYet, when environment dynamics change over time, stale novelty estimates can encourage revisiting obsolete states. We propose a recency-aware intrinsic reward that discounts outdated novelty and couples it with conservative policy updates.\n\nAcross Atari and continuous-control domains with drifting dynamics, our method achieves superior sample efficiency and stability, and ablations confirm the role of recency in balancing exploration and exploitation.\nRelated Work\n\nDetecting anomalies in multivariate time series is vital for monitoring industrial systems and cloud services. The challenge lies in handling seasonality, rare events, and inter-variable dependencies.\n\nClassical anomaly detection leverages ARIMA residual tests, STL decomposition, and control charts, while deep methods introduce autoencoders, VAEs, GANs, LSTMs, and Transformers for reconstruction or prediction errors (Tsay, 2010; Malhotra et al., 2015; An and Cho, 2015; Li et al., 2019; Xu et al., 2021).\n\nWe present Contrastive Forecasting with Graph Priors (CFGP), which learns structure-aware representations via self-supervised objectives and uses calibrated predictive intervals to flag anomalies.\nIntroduction\n\nGeneralizing manipulation skills across objects, tasks, and environments remains a central challenge in robotics. Sparse rewards, safety constraints, and hardware variability complicate learning on physical systems. Recent work studies imitation learning, offline RL, and model-based control for dexterous manipulation (Rajeswaran et al., 2018; Lynch et al., 2020; Nagabandi et al., 2019; Ahn et al., 2022). Despite these advances, scaling data collection and ensuring sim-to-real transfer continue to be bottlenecks.\n\nWe explore a curriculum that interleaves skill discovery from teleoperation logs with conservative online updates, targeting stable improvements under limited interaction budgets.\nRelated Work\n\nConversational recommenders. Systems that interactively elicit user preferences can reduce cold-start and improve satisfaction (Sun and Zhang, 2018). Dialog policy learning for conversational recommendation has explored supervised learning, reinforcement learning, and bandit methods (Christakopoulou et al., 2016; Lei et al., 2020; Chen et al., 2019). User simulators and counterfactual logging have been proposed to address data scarcity and evaluation challenges (Li et al., 2017; Chi et al., 2020).\n\nOur study investigates preference drift over long-horizon sessions and proposes a state representation that explicitly tracks uncertainty and recency effects.\nIntroduction\n\nExplainable AI (XAI) is increasingly required for medical imaging systems used in screening and triage. Beyond predictive accuracy, clinicians demand transparency about what image features drive automated decisions and whether explanations are stable under shifts.\n\nPost-hoc attribution methods like Grad-CAM and Integrated Gradients highlight salient regions (Selvaraju et al., 2017; Sundararajan et al., 2017). Prototype- and concept-based explanations enhance interpretability (Chen et al., 2019; Kim et al., 2018). Counterfactual generation has been explored for medical images (Chang et al., 2018; Singla et al., 2021).\n\nWe focus on faithfulness under distribution shift and propose an evaluation protocol that aligns explanation stability with clinical acceptance thresholds for screening workflows.\nRelated Work\n\nProviding timely, actionable feedback at scale is central to computing education. Traditional approaches combine instructor-designed rubrics with automated tests, but coverage and specificity can be limited for diverse student solutions.\n\nAutomated feedback for programming assignments has been tackled with static analysis, dynamic test generation, and pattern mining (Ke et al., 2016; Gulwani et al., 2018; Singh et al., 2013). Recent NLP-based systems leverage code embeddings, sequence models, and pretrained language models (Allamanis et al., 2018; Feng et al., 2020; Ahmad et al., 2021). Peer learning platforms collect hints and exemplars to guide novice programmers (Piech et al., 2015; Wang et al., 2018).\n\nWhile data-driven approaches show promise, they often struggle with generalizing across tasks and providing pedagogically aligned guidance. Our work investigates structure-aware hint generation that aligns feedback to conceptual steps in problem-solving.\nRelated Work\n\nReinforcement learning (RL) has enabled robots to acquire complex behaviors directly from interaction. However, data hunger, safety, and sim-to-real transfer remain persistent obstacles for deployment in real-world settings.\n\nModel-free methods such as DDPG (Lillicrap et al., 2016), SAC (Haarnoja et al., 2018), and PPO (Schulman et al., 2017) have been widely adopted for continuous control, while model-based approaches leverage learned dynamics for sample efficiency (Deisenroth and Rasmussen, 2011; Chua et al., 2018). Recent lines of work explore offline RL (Levine et al., 2020; Kumar et al., 2020) and representation learning for policy generalization (Laskin et al., 2020; Yarats et al., 2021). Domain randomization and adaptation seek to bridge the sim-to-real gap (Tobin et al., 2017; Peng et al., 2018).\n\nWe propose a training strategy that combines curriculum learning with uncertainty-aware policy updates to improve safety and sample efficiency in robotic manipulation.\nRelated Work\n\nAutomatic speech recognition (ASR) systems increasingly rely on large encoder\u2013decoder architectures that are costly to deploy on edge devices. Knowledge distillation (KD) is a common strategy to reduce model size while preserving accuracy.\n\nKnowledge distillation for speech recognition has considered frame-level supervision, sequence-level criteria, and wordpiece distributions, transferring knowledge from stronger teachers to smaller students (Hinton et al., 2015; Kim and Rush, 2016; Kurata and Audhkhasi, 2018; Higuchi et al., 2021).\n\nOther compression techniques include quantization and pruning, which can be combined with KD but may degrade robustness to noise and speaker variability. Recent work explores multi-teacher ensembles and intermediate-layer matching to stabilize training.\n\nIn this paper, we study streaming-constrained KD with latency-aware targets, aligning teacher and student under causal masking. Our experiments on LibriSpeech and far-field corpora show improved WER\u2013latency trade-offs compared to strong baselines.\nRelated Work\n\nLarge Language Models and Prompting\nLarge language models (LLMs) exhibit emergent program synthesis capabilities when conditioned on natural language instructions and a handful of examples. While these behaviors reduce reliance on supervised datasets, the mechanisms by which prompts control generation remain only partially understood. Prior studies analyze calibration, decoding strategies, and context length effects.\n\nPrompting for Code Generation\nPrompting for code generation has explored zero-shot, few-shot, and chain-of-thought styles using large language models (Chen et al., 2021; Austin et al., 2021; Nijkamp et al., 2022; Li et al., 2023). Work on compiler-aware prompting adds execution feedback to steer generation (Liu et al., 2022; Le et al., 2022; Wang et al., 2023). Program repair and test-driven synthesis have similarly adapted prompting strategies to satisfy unit tests (Jain et al., 2022; Zhang et al., 2023).\n\nExecution-Conditioned Decoding\nBeyond static prompts, execution-conditioned decoding iteratively runs partial programs to reduce search space. Studies report gains on algorithmic problems by interleaving generation and verification under timeouts and sandboxing constraints.\n\nStructured Constraints and Type Guidance\nApproaches that inject grammar constraints or type information restrict invalid outputs and improve pass rates. These methods range from constrained beam search to type-state automata.\n\nPositioning\nWe examine the interaction between prompt structure and execution feedback and study how typed constraints alter search dynamics under limited budgets.\nRelated Work\n\nFederated learning (FL) enables on-device training with privacy and communication constraints. Ensuring rigorous privacy guarantees while preserving model utility remains a core challenge.\n\nPrivacy in federated learning has been studied via differential privacy at the client level, secure aggregation, and shuffling (McMahan et al., 2017; Kairouz et al., 2021; Bonawitz et al., 2017; Erlingsson et al., 2019). Gradient perturbation, clipping, and client subsampling are common techniques to control privacy loss (Abadi et al., 2016; Thakkar et al., 2019; Andrew et al., 2021). Auditing methods estimate empirical privacy leakage post hoc (Nasr et al., 2019; Jagielski et al., 2020).\n\nOur approach introduces client-adaptive noise schedules conditioned on participation frequency.\n\nWe empirically evaluate privacy-utility trade-offs across heterogeneous client populations.\nIntroduction\n\nInformation retrieval has shifted from lexical term matching to semantic representations that capture contextual meaning. This shift enables better recall of paraphrased content but introduces new challenges in index efficiency and training stability.\n\nNeural semantic search methods combine dual-encoders for efficient retrieval (Yao et al., 2019; Xie and Zhao, 2020) with cross-encoders for reranking (Nogueira and Cho, 2019; Li et al., 2021), and leverage hard-negative mining to improve discriminative power (Gao et al., 2021; Huang et al., 2022). Recent work also explores domain adaptation for specialized corpora such as legal and biomedical texts (Park et al., 2022; Sun et al., 2023).\n\nWe study lightweight domain adaptation under tight indexing budgets.\nRelated Work\n\nDetecting anomalies in time-series is a long-standing problem with applications in monitoring, finance, and industrial IoT. Methods vary widely in assumptions, supervision requirements, and scalability.\n\nTime-series anomaly detection spans classical statistical tests, isolation-based methods, and deep learning models such as autoencoders, temporal convolutional networks, and Transformers (Gupta et al., 2014; Liu et al., 2008; Malhotra et al., 2016; Xu et al., 2020). Synthetic anomaly injection and semi-supervised training are also common practices (Zhang et al., 2019; Shen et al., 2021).\n\nBenchmarking efforts have sought consistent evaluation protocols across datasets with different anomaly types and frequencies (Hundman et al., 2018; Wu and Keogh, 2021).\nRelated Work\n\nPredicting molecular properties from structure has catalyzed a broad literature at the intersection of cheminformatics and geometric deep learning. Approaches differ in how they encode graph topology, chemical attributes, and geometric constraints.\n\nGraph representation learning methods such as spectral GCNs, spatial message passing networks, and attention-based GNNs have been widely applied to molecular property prediction (Kipf and Welling, 2017; Gilmer et al., 2017; Veli\u010dkovi\u0107 et al., 2018). Extensions include edge-conditioned convolutions, higher-order structures, and equivariant networks for 3D geometries (Simonovsky and Komodakis, 2017; Batzner et al., 2022).\n\nPretraining strategies on large unlabeled molecule corpora with contrastive or masked node prediction objectives have further improved generalization, especially in low-data regimes (Hu et al., 2020; Rong et al., 2020).\nIntroduction\n\nAutomated analysis of pathology whole-slide images (WSIs) faces extreme resolution, sparse lesion patterns, and distribution shifts across scanners and staining protocols. Convolutional networks have advanced the field but can be limited in modeling long-range dependencies over gigapixel slides.\n\nVision Transformers have been applied to medical image classification, segmentation, and detection with pure transformer backbones or hybrid CNN\u2013Transformer designs (Dosovitskiy et al., 2020; Chen et al., 2021; Hatamizadeh et al., 2022; Wang et al., 2021; Xie et al., 2021).\n\nWeakly supervised multiple-instance learning (MIL) further alleviates slide-level labeling costs by aggregating patch evidence, yet attention pooling can overfit to spurious correlations. We investigate whether token-level sparsification combined with instance reweighting can improve robustness in cross-site evaluation.\n\nOur method introduces a curriculum-sparse token selection and slide-consistent calibration loss to stabilize attention under domain shift. On three WSI benchmarks spanning different scanners, we observe gains in AUC and improved calibration, with minimal added compute.\n\nWe conduct ablations on sparsity schedules and release pretrained weights for community use.\n",
        "completion": "Vision Transformers have been applied to medical image classification, segmentation, and detection with pure transformer backbones or hybrid CNN\u2013Transformer designs (Dosovitskiy et al., 2020; Chen et al., 2021; Hatamizadeh et al., 2022; Wang et al., 2021; Xie et al., 2021)."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        occurs when either:\n    a) The author describes or cites papers without connecting them to their own work/argument \n    b) Or only follows up the summary of previous works with their own contribution without explicitly highlighting the gap their work intends to research.\n    c) It does not articulate the author's perspective or motivation.\n    d) A lack of argument/opinion in the first paragraph is permissible as it serves to be the foundation of the author's argument \n    e) Lacks synthesis issues appear either as single sentences or multiple sentences.\n    Examples of lack of synthesis include:\n        i) No elaboration of own contribution/argument:\"Following early neural approaches to question answering, many subsequent studies adopt a pipeline architecture consisting of retrieval and comprehension components. The retrieval component focuses on identifying relevant documents or passages from a large corpus, while the comprehension component extracts an answer span from the retrieved text. Initial models relied on recurrent neural networks with attention mechanisms to encode questions and contexts (Seo et al., 2017; Wang et al., 2017).\"\n        ii)  No explanation of the cited works and relation to their own work: \u201cRecently, several studies have explored the use of prompting techniques with pre-trained language models to influence model outputs or access latent knowledge (Brown et al., 2020; Gao et al., 2021; Liu et al., 2021; Wei et al., 2022).\u201d \n\n        Example text: \n        Related Work\n\nDevelopers rely on code search to find relevant snippets, APIs, or examples. Unlike general document retrieval, code search must bridge natural language intent and program structure.\n\nNeural code search has been addressed with bi-encoders, cross-encoders, and dual learning (Gu et al., 2018; Husain et al., 2019; Feng et al., 2020). Structural representations incorporate ASTs, control flow, and data flow (Alon et al., 2019; Wang et al., 2020; Liu et al., 2021). Pretraining on code and NL improves retrieval metrics across languages (Ahmad et al., 2021; Guo et al., 2021).\n\nIn this paper, we introduce a language-agnostic retriever with compositional queries.\n\nWe evaluate zero-shot transfer across four programming languages.\nIntroduction\n\nGeneralization in text classification can be improved with data augmentation, especially when labeled data are scarce or imbalanced. Approaches range from rule-based edits to model-driven paraphrasing and representation-space mixing.\n\nText augmentation techniques include synonym replacement, random insertion/deletion, back-translation, paraphrase generation, and mixup in embedding or hidden spaces (Wei and Zou, 2019; Sennrich et al., 2016; Kobayashi, 2018; Guo et al., 2020). Recent work explores task-adaptive augmentation policies learned by reinforcement learning (Xie et al., 2020).\n\nEvaluation typically considers robustness to domain shift, label noise, and distributional skew across multiple benchmarks (Pruksachatkun et al., 2020; Hendrycks et al., 2020).\nRelated Work\n\nKnowledge graph completion predicts missing links by learning entity and relation representations. Methods vary in how they encode semantics and handle patterns like symmetry, hierarchy, and composition.\n\nTranslation-based knowledge graph embeddings model relations as translations in vector space (Bordes et al., 2013; Wang et al., 2014), while bilinear and neural models capture more complex interactions (Nickel et al., 2011; Trouillon et al., 2016; Sun et al., 2019). Regularization and rule-guided approaches improve inductive bias and data efficiency (Rockt\u00e4schel et al., 2015; Minervini et al., 2017).\n\nWe introduce a lightweight compositional constraint for hierarchical relations and evaluate on three benchmarks and an industry dataset.\nRelated Work\n\nEnsuring safety during reinforcement learning is critical in real-world control where violations can be costly. Research has proposed both objective-level and mechanism-level solutions.\n\nSafe reinforcement learning approaches include risk-sensitive objectives such as CVaR optimization (Tamar et al., 2015; Chow et al., 2018), constrained policy optimization with safety budgets (Achiam et al., 2017; Yang et al., 2020), and shielding based on model-checking or supervisors (Alshiekh et al., 2018; Dalal et al., 2018). We develop a method that integrates model-predictive constraints with policy gradients.\n\nBenchmarks often evaluate safety in simulated robotics or navigation with cost functions approximating constraint violations (Ray et al., 2019; Bharadhwaj et al., 2021).\nRelated Work\n\nDialog state tracking (DST) has evolved from rule-based slot filling to neural architectures that jointly infer belief states across turns. Early pipeline models used hand-crafted lexicons and semantic frames (Singh and Patel, 2015), but suffered from brittleness to paraphrase and noise. Neural encoders introduced robustness by contextualizing utterances, incorporating attention over dialog history, and modeling slot-value dependencies (Lee et al., 2018; Choe and Kim, 2019).\n\nPretrained language models have further shifted the landscape by enabling few-shot generalization and open-vocabulary slot values. Fine-tuning BERT-like encoders for DST improved cross-domain transfer (Rao et al., 2020), while generative formulations cast state tracking as text-to-text prediction (Mendez et al., 2021).\n\nPrompting-based approaches have also been explored for dialog modeling (Kumar et al., 2021; Ortega and Lin, 2022; Park et al., 2023). These methods condition large language models on task instructions or few-shot exemplars to elicit latent conversational knowledge. Recent variants incorporate calibration or self-consistency to stabilize outputs (Fang et al., 2023; Zhou et al., 2023).\n\nPosition relative to this paper While we also employ pretrained sequence-to-sequence models, our focus is on handling ontology drift in long-running deployments. Specifically, we introduce an adaptive slot schema encoder that aligns evolving taxonomies with dialog evidence, and a contrastive consistency objective to mitigate spurious slot co-activations across domains.\nIntroduction\n\nSelf-supervised learning (SSL) has become the dominant paradigm for learning transferable visual features without labels. By constructing pretext tasks that expose invariances and structure inherent in data, SSL models can match or surpass supervised baselines on many downstream tasks.\n\nContrastive pretraining has been widely adopted for visual representations (Chen et al., 2020; He et al., 2020; Xie and Xu, 2021). Non-contrastive methods remove negative pairs and rely on architectural or objective asymmetries (Grill et al., 2020; Tian et al., 2021). Clustering-based methods jointly learn assignments and embeddings (Caron et al., 2018; Li and Gao, 2022).\n\nDespite these advances, industrial applications often operate under strict memory budgets and latency constraints. In this paper, we investigate compute-aware pretraining objectives that couple multi-crop augmentation with a token-subsampled backbone. We present a latency-regularized alignment loss that preserves downstream accuracy while reducing FLOPs during both pretraining and fine-tuning.\nIntroduction\n\nEfficient exploration remains a central challenge in reinforcement learning (RL), particularly in sparse-reward environments where naive strategies fail to discover rewarding states. Over-exploration, however, can waste samples and destabilize learning.\n\nExploration in reinforcement learning has been advanced by count-based bonuses, intrinsic motivation, curiosity-driven prediction error, and information-theoretic objectives (Bellemare et al., 2016; Pathak et al., 2017; Houthooft et al., 2016; Burda et al., 2019; Ta\u00efga et al., 2020).\n\nYet, when environment dynamics change over time, stale novelty estimates can encourage revisiting obsolete states. We propose a recency-aware intrinsic reward that discounts outdated novelty and couples it with conservative policy updates.\n\nAcross Atari and continuous-control domains with drifting dynamics, our method achieves superior sample efficiency and stability, and ablations confirm the role of recency in balancing exploration and exploitation.\nRelated Work\n\nDetecting anomalies in multivariate time series is vital for monitoring industrial systems and cloud services. The challenge lies in handling seasonality, rare events, and inter-variable dependencies.\n\nClassical anomaly detection leverages ARIMA residual tests, STL decomposition, and control charts, while deep methods introduce autoencoders, VAEs, GANs, LSTMs, and Transformers for reconstruction or prediction errors (Tsay, 2010; Malhotra et al., 2015; An and Cho, 2015; Li et al., 2019; Xu et al., 2021).\n\nWe present Contrastive Forecasting with Graph Priors (CFGP), which learns structure-aware representations via self-supervised objectives and uses calibrated predictive intervals to flag anomalies.\nIntroduction\n\nGeneralizing manipulation skills across objects, tasks, and environments remains a central challenge in robotics. Sparse rewards, safety constraints, and hardware variability complicate learning on physical systems. Recent work studies imitation learning, offline RL, and model-based control for dexterous manipulation (Rajeswaran et al., 2018; Lynch et al., 2020; Nagabandi et al., 2019; Ahn et al., 2022). Despite these advances, scaling data collection and ensuring sim-to-real transfer continue to be bottlenecks.\n\nWe explore a curriculum that interleaves skill discovery from teleoperation logs with conservative online updates, targeting stable improvements under limited interaction budgets.\nRelated Work\n\nConversational recommenders. Systems that interactively elicit user preferences can reduce cold-start and improve satisfaction (Sun and Zhang, 2018). Dialog policy learning for conversational recommendation has explored supervised learning, reinforcement learning, and bandit methods (Christakopoulou et al., 2016; Lei et al., 2020; Chen et al., 2019). User simulators and counterfactual logging have been proposed to address data scarcity and evaluation challenges (Li et al., 2017; Chi et al., 2020).\n\nOur study investigates preference drift over long-horizon sessions and proposes a state representation that explicitly tracks uncertainty and recency effects.\nIntroduction\n\nExplainable AI (XAI) is increasingly required for medical imaging systems used in screening and triage. Beyond predictive accuracy, clinicians demand transparency about what image features drive automated decisions and whether explanations are stable under shifts.\n\nPost-hoc attribution methods like Grad-CAM and Integrated Gradients highlight salient regions (Selvaraju et al., 2017; Sundararajan et al., 2017). Prototype- and concept-based explanations enhance interpretability (Chen et al., 2019; Kim et al., 2018). Counterfactual generation has been explored for medical images (Chang et al., 2018; Singla et al., 2021).\n\nWe focus on faithfulness under distribution shift and propose an evaluation protocol that aligns explanation stability with clinical acceptance thresholds for screening workflows.\nRelated Work\n\nProviding timely, actionable feedback at scale is central to computing education. Traditional approaches combine instructor-designed rubrics with automated tests, but coverage and specificity can be limited for diverse student solutions.\n\nAutomated feedback for programming assignments has been tackled with static analysis, dynamic test generation, and pattern mining (Ke et al., 2016; Gulwani et al., 2018; Singh et al., 2013). Recent NLP-based systems leverage code embeddings, sequence models, and pretrained language models (Allamanis et al., 2018; Feng et al., 2020; Ahmad et al., 2021). Peer learning platforms collect hints and exemplars to guide novice programmers (Piech et al., 2015; Wang et al., 2018).\n\nWhile data-driven approaches show promise, they often struggle with generalizing across tasks and providing pedagogically aligned guidance. Our work investigates structure-aware hint generation that aligns feedback to conceptual steps in problem-solving.\nRelated Work\n\nReinforcement learning (RL) has enabled robots to acquire complex behaviors directly from interaction. However, data hunger, safety, and sim-to-real transfer remain persistent obstacles for deployment in real-world settings.\n\nModel-free methods such as DDPG (Lillicrap et al., 2016), SAC (Haarnoja et al., 2018), and PPO (Schulman et al., 2017) have been widely adopted for continuous control, while model-based approaches leverage learned dynamics for sample efficiency (Deisenroth and Rasmussen, 2011; Chua et al., 2018). Recent lines of work explore offline RL (Levine et al., 2020; Kumar et al., 2020) and representation learning for policy generalization (Laskin et al., 2020; Yarats et al., 2021). Domain randomization and adaptation seek to bridge the sim-to-real gap (Tobin et al., 2017; Peng et al., 2018).\n\nWe propose a training strategy that combines curriculum learning with uncertainty-aware policy updates to improve safety and sample efficiency in robotic manipulation.\nRelated Work\n\nAutomatic speech recognition (ASR) systems increasingly rely on large encoder\u2013decoder architectures that are costly to deploy on edge devices. Knowledge distillation (KD) is a common strategy to reduce model size while preserving accuracy.\n\nKnowledge distillation for speech recognition has considered frame-level supervision, sequence-level criteria, and wordpiece distributions, transferring knowledge from stronger teachers to smaller students (Hinton et al., 2015; Kim and Rush, 2016; Kurata and Audhkhasi, 2018; Higuchi et al., 2021).\n\nOther compression techniques include quantization and pruning, which can be combined with KD but may degrade robustness to noise and speaker variability. Recent work explores multi-teacher ensembles and intermediate-layer matching to stabilize training.\n\nIn this paper, we study streaming-constrained KD with latency-aware targets, aligning teacher and student under causal masking. Our experiments on LibriSpeech and far-field corpora show improved WER\u2013latency trade-offs compared to strong baselines.\nRelated Work\n\nLarge Language Models and Prompting\nLarge language models (LLMs) exhibit emergent program synthesis capabilities when conditioned on natural language instructions and a handful of examples. While these behaviors reduce reliance on supervised datasets, the mechanisms by which prompts control generation remain only partially understood. Prior studies analyze calibration, decoding strategies, and context length effects.\n\nPrompting for Code Generation\nPrompting for code generation has explored zero-shot, few-shot, and chain-of-thought styles using large language models (Chen et al., 2021; Austin et al., 2021; Nijkamp et al., 2022; Li et al., 2023). Work on compiler-aware prompting adds execution feedback to steer generation (Liu et al., 2022; Le et al., 2022; Wang et al., 2023). Program repair and test-driven synthesis have similarly adapted prompting strategies to satisfy unit tests (Jain et al., 2022; Zhang et al., 2023).\n\nExecution-Conditioned Decoding\nBeyond static prompts, execution-conditioned decoding iteratively runs partial programs to reduce search space. Studies report gains on algorithmic problems by interleaving generation and verification under timeouts and sandboxing constraints.\n\nStructured Constraints and Type Guidance\nApproaches that inject grammar constraints or type information restrict invalid outputs and improve pass rates. These methods range from constrained beam search to type-state automata.\n\nPositioning\nWe examine the interaction between prompt structure and execution feedback and study how typed constraints alter search dynamics under limited budgets.\nRelated Work\n\nFederated learning (FL) enables on-device training with privacy and communication constraints. Ensuring rigorous privacy guarantees while preserving model utility remains a core challenge.\n\nPrivacy in federated learning has been studied via differential privacy at the client level, secure aggregation, and shuffling (McMahan et al., 2017; Kairouz et al., 2021; Bonawitz et al., 2017; Erlingsson et al., 2019). Gradient perturbation, clipping, and client subsampling are common techniques to control privacy loss (Abadi et al., 2016; Thakkar et al., 2019; Andrew et al., 2021). Auditing methods estimate empirical privacy leakage post hoc (Nasr et al., 2019; Jagielski et al., 2020).\n\nOur approach introduces client-adaptive noise schedules conditioned on participation frequency.\n\nWe empirically evaluate privacy-utility trade-offs across heterogeneous client populations.\nIntroduction\n\nInformation retrieval has shifted from lexical term matching to semantic representations that capture contextual meaning. This shift enables better recall of paraphrased content but introduces new challenges in index efficiency and training stability.\n\nNeural semantic search methods combine dual-encoders for efficient retrieval (Yao et al., 2019; Xie and Zhao, 2020) with cross-encoders for reranking (Nogueira and Cho, 2019; Li et al., 2021), and leverage hard-negative mining to improve discriminative power (Gao et al., 2021; Huang et al., 2022). Recent work also explores domain adaptation for specialized corpora such as legal and biomedical texts (Park et al., 2022; Sun et al., 2023).\n\nWe study lightweight domain adaptation under tight indexing budgets.\nRelated Work\n\nDetecting anomalies in time-series is a long-standing problem with applications in monitoring, finance, and industrial IoT. Methods vary widely in assumptions, supervision requirements, and scalability.\n\nTime-series anomaly detection spans classical statistical tests, isolation-based methods, and deep learning models such as autoencoders, temporal convolutional networks, and Transformers (Gupta et al., 2014; Liu et al., 2008; Malhotra et al., 2016; Xu et al., 2020). Synthetic anomaly injection and semi-supervised training are also common practices (Zhang et al., 2019; Shen et al., 2021).\n\nBenchmarking efforts have sought consistent evaluation protocols across datasets with different anomaly types and frequencies (Hundman et al., 2018; Wu and Keogh, 2021).\nRelated Work\n\nPredicting molecular properties from structure has catalyzed a broad literature at the intersection of cheminformatics and geometric deep learning. Approaches differ in how they encode graph topology, chemical attributes, and geometric constraints.\n\nGraph representation learning methods such as spectral GCNs, spatial message passing networks, and attention-based GNNs have been widely applied to molecular property prediction (Kipf and Welling, 2017; Gilmer et al., 2017; Veli\u010dkovi\u0107 et al., 2018). Extensions include edge-conditioned convolutions, higher-order structures, and equivariant networks for 3D geometries (Simonovsky and Komodakis, 2017; Batzner et al., 2022).\n\nPretraining strategies on large unlabeled molecule corpora with contrastive or masked node prediction objectives have further improved generalization, especially in low-data regimes (Hu et al., 2020; Rong et al., 2020).\nIntroduction\n\nAutomated analysis of pathology whole-slide images (WSIs) faces extreme resolution, sparse lesion patterns, and distribution shifts across scanners and staining protocols. Convolutional networks have advanced the field but can be limited in modeling long-range dependencies over gigapixel slides.\n\nVision Transformers have been applied to medical image classification, segmentation, and detection with pure transformer backbones or hybrid CNN\u2013Transformer designs (Dosovitskiy et al., 2020; Chen et al., 2021; Hatamizadeh et al., 2022; Wang et al., 2021; Xie et al., 2021).\n\nWeakly supervised multiple-instance learning (MIL) further alleviates slide-level labeling costs by aggregating patch evidence, yet attention pooling can overfit to spurious correlations. We investigate whether token-level sparsification combined with instance reweighting can improve robustness in cross-site evaluation.\n\nOur method introduces a curriculum-sparse token selection and slide-consistent calibration loss to stabilize attention under domain shift. On three WSI benchmarks spanning different scanners, we observe gains in AUC and improved calibration, with minimal added compute.\n\nWe conduct ablations on sparsity schedules and release pretrained weights for community use.\nRelated Work\n\nRemote sensing change detection relies on robust representations that separate illumination and seasonal effects from structural changes. Recent advances in high-resolution satellites have shifted attention to fine-grained, building-level change cues.\n\nClassical two-stream CNNs, Siamese architectures, and attention-based models have been widely adopted for change detection (Daudt et al., 2018; Fang et al., 2020; Chen et al., 2021). Large-scale datasets such as LEVIR-CD, CDD, and WHU-CD have enabled benchmarking across urban scenes (Levir et al., 2020; Wang et al., 2020; Ji et al., 2019). Transformer-based encoders further improve long-range modeling (Ban et al., 2021; Liu et al., 2021).\n\nWhile these efforts improve accuracy, they largely assume perfectly registered image pairs and abundant labels. Our work targets label-scarce scenarios with misalignment by learning registration-aware tokens that disentangle geometry from appearance.\n",
        "completion": "Classical two-stream CNNs, Siamese architectures, and attention-based models have been widely adopted for change detection (Daudt et al., 2018; Fang et al., 2020; Chen et al., 2021). Large-scale datasets such as LEVIR-CD, CDD, and WHU-CD have enabled benchmarking across urban scenes (Levir et al., 2020; Wang et al., 2020; Ji et al., 2019). Transformer-based encoders further improve long-range modeling (Ban et al., 2021; Liu et al., 2021)."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        occurs when either:\n    a) The author describes or cites papers without connecting them to their own work/argument \n    b) Or only follows up the summary of previous works with their own contribution without explicitly highlighting the gap their work intends to research.\n    c) It does not articulate the author's perspective or motivation.\n    d) A lack of argument/opinion in the first paragraph is permissible as it serves to be the foundation of the author's argument \n    e) Lacks synthesis issues appear either as single sentences or multiple sentences.\n    Examples of lack of synthesis include:\n        i) No elaboration of own contribution/argument:\"Following early neural approaches to question answering, many subsequent studies adopt a pipeline architecture consisting of retrieval and comprehension components. The retrieval component focuses on identifying relevant documents or passages from a large corpus, while the comprehension component extracts an answer span from the retrieved text. Initial models relied on recurrent neural networks with attention mechanisms to encode questions and contexts (Seo et al., 2017; Wang et al., 2017).\"\n        ii)  No explanation of the cited works and relation to their own work: \u201cRecently, several studies have explored the use of prompting techniques with pre-trained language models to influence model outputs or access latent knowledge (Brown et al., 2020; Gao et al., 2021; Liu et al., 2021; Wei et al., 2022).\u201d \n\n        Example text: \n        Related Work\n\nDevelopers rely on code search to find relevant snippets, APIs, or examples. Unlike general document retrieval, code search must bridge natural language intent and program structure.\n\nNeural code search has been addressed with bi-encoders, cross-encoders, and dual learning (Gu et al., 2018; Husain et al., 2019; Feng et al., 2020). Structural representations incorporate ASTs, control flow, and data flow (Alon et al., 2019; Wang et al., 2020; Liu et al., 2021). Pretraining on code and NL improves retrieval metrics across languages (Ahmad et al., 2021; Guo et al., 2021).\n\nIn this paper, we introduce a language-agnostic retriever with compositional queries.\n\nWe evaluate zero-shot transfer across four programming languages.\nIntroduction\n\nGeneralization in text classification can be improved with data augmentation, especially when labeled data are scarce or imbalanced. Approaches range from rule-based edits to model-driven paraphrasing and representation-space mixing.\n\nText augmentation techniques include synonym replacement, random insertion/deletion, back-translation, paraphrase generation, and mixup in embedding or hidden spaces (Wei and Zou, 2019; Sennrich et al., 2016; Kobayashi, 2018; Guo et al., 2020). Recent work explores task-adaptive augmentation policies learned by reinforcement learning (Xie et al., 2020).\n\nEvaluation typically considers robustness to domain shift, label noise, and distributional skew across multiple benchmarks (Pruksachatkun et al., 2020; Hendrycks et al., 2020).\nRelated Work\n\nKnowledge graph completion predicts missing links by learning entity and relation representations. Methods vary in how they encode semantics and handle patterns like symmetry, hierarchy, and composition.\n\nTranslation-based knowledge graph embeddings model relations as translations in vector space (Bordes et al., 2013; Wang et al., 2014), while bilinear and neural models capture more complex interactions (Nickel et al., 2011; Trouillon et al., 2016; Sun et al., 2019). Regularization and rule-guided approaches improve inductive bias and data efficiency (Rockt\u00e4schel et al., 2015; Minervini et al., 2017).\n\nWe introduce a lightweight compositional constraint for hierarchical relations and evaluate on three benchmarks and an industry dataset.\nRelated Work\n\nEnsuring safety during reinforcement learning is critical in real-world control where violations can be costly. Research has proposed both objective-level and mechanism-level solutions.\n\nSafe reinforcement learning approaches include risk-sensitive objectives such as CVaR optimization (Tamar et al., 2015; Chow et al., 2018), constrained policy optimization with safety budgets (Achiam et al., 2017; Yang et al., 2020), and shielding based on model-checking or supervisors (Alshiekh et al., 2018; Dalal et al., 2018). We develop a method that integrates model-predictive constraints with policy gradients.\n\nBenchmarks often evaluate safety in simulated robotics or navigation with cost functions approximating constraint violations (Ray et al., 2019; Bharadhwaj et al., 2021).\nRelated Work\n\nDialog state tracking (DST) has evolved from rule-based slot filling to neural architectures that jointly infer belief states across turns. Early pipeline models used hand-crafted lexicons and semantic frames (Singh and Patel, 2015), but suffered from brittleness to paraphrase and noise. Neural encoders introduced robustness by contextualizing utterances, incorporating attention over dialog history, and modeling slot-value dependencies (Lee et al., 2018; Choe and Kim, 2019).\n\nPretrained language models have further shifted the landscape by enabling few-shot generalization and open-vocabulary slot values. Fine-tuning BERT-like encoders for DST improved cross-domain transfer (Rao et al., 2020), while generative formulations cast state tracking as text-to-text prediction (Mendez et al., 2021).\n\nPrompting-based approaches have also been explored for dialog modeling (Kumar et al., 2021; Ortega and Lin, 2022; Park et al., 2023). These methods condition large language models on task instructions or few-shot exemplars to elicit latent conversational knowledge. Recent variants incorporate calibration or self-consistency to stabilize outputs (Fang et al., 2023; Zhou et al., 2023).\n\nPosition relative to this paper While we also employ pretrained sequence-to-sequence models, our focus is on handling ontology drift in long-running deployments. Specifically, we introduce an adaptive slot schema encoder that aligns evolving taxonomies with dialog evidence, and a contrastive consistency objective to mitigate spurious slot co-activations across domains.\nIntroduction\n\nSelf-supervised learning (SSL) has become the dominant paradigm for learning transferable visual features without labels. By constructing pretext tasks that expose invariances and structure inherent in data, SSL models can match or surpass supervised baselines on many downstream tasks.\n\nContrastive pretraining has been widely adopted for visual representations (Chen et al., 2020; He et al., 2020; Xie and Xu, 2021). Non-contrastive methods remove negative pairs and rely on architectural or objective asymmetries (Grill et al., 2020; Tian et al., 2021). Clustering-based methods jointly learn assignments and embeddings (Caron et al., 2018; Li and Gao, 2022).\n\nDespite these advances, industrial applications often operate under strict memory budgets and latency constraints. In this paper, we investigate compute-aware pretraining objectives that couple multi-crop augmentation with a token-subsampled backbone. We present a latency-regularized alignment loss that preserves downstream accuracy while reducing FLOPs during both pretraining and fine-tuning.\nIntroduction\n\nEfficient exploration remains a central challenge in reinforcement learning (RL), particularly in sparse-reward environments where naive strategies fail to discover rewarding states. Over-exploration, however, can waste samples and destabilize learning.\n\nExploration in reinforcement learning has been advanced by count-based bonuses, intrinsic motivation, curiosity-driven prediction error, and information-theoretic objectives (Bellemare et al., 2016; Pathak et al., 2017; Houthooft et al., 2016; Burda et al., 2019; Ta\u00efga et al., 2020).\n\nYet, when environment dynamics change over time, stale novelty estimates can encourage revisiting obsolete states. We propose a recency-aware intrinsic reward that discounts outdated novelty and couples it with conservative policy updates.\n\nAcross Atari and continuous-control domains with drifting dynamics, our method achieves superior sample efficiency and stability, and ablations confirm the role of recency in balancing exploration and exploitation.\nRelated Work\n\nDetecting anomalies in multivariate time series is vital for monitoring industrial systems and cloud services. The challenge lies in handling seasonality, rare events, and inter-variable dependencies.\n\nClassical anomaly detection leverages ARIMA residual tests, STL decomposition, and control charts, while deep methods introduce autoencoders, VAEs, GANs, LSTMs, and Transformers for reconstruction or prediction errors (Tsay, 2010; Malhotra et al., 2015; An and Cho, 2015; Li et al., 2019; Xu et al., 2021).\n\nWe present Contrastive Forecasting with Graph Priors (CFGP), which learns structure-aware representations via self-supervised objectives and uses calibrated predictive intervals to flag anomalies.\nIntroduction\n\nGeneralizing manipulation skills across objects, tasks, and environments remains a central challenge in robotics. Sparse rewards, safety constraints, and hardware variability complicate learning on physical systems. Recent work studies imitation learning, offline RL, and model-based control for dexterous manipulation (Rajeswaran et al., 2018; Lynch et al., 2020; Nagabandi et al., 2019; Ahn et al., 2022). Despite these advances, scaling data collection and ensuring sim-to-real transfer continue to be bottlenecks.\n\nWe explore a curriculum that interleaves skill discovery from teleoperation logs with conservative online updates, targeting stable improvements under limited interaction budgets.\nRelated Work\n\nConversational recommenders. Systems that interactively elicit user preferences can reduce cold-start and improve satisfaction (Sun and Zhang, 2018). Dialog policy learning for conversational recommendation has explored supervised learning, reinforcement learning, and bandit methods (Christakopoulou et al., 2016; Lei et al., 2020; Chen et al., 2019). User simulators and counterfactual logging have been proposed to address data scarcity and evaluation challenges (Li et al., 2017; Chi et al., 2020).\n\nOur study investigates preference drift over long-horizon sessions and proposes a state representation that explicitly tracks uncertainty and recency effects.\nIntroduction\n\nExplainable AI (XAI) is increasingly required for medical imaging systems used in screening and triage. Beyond predictive accuracy, clinicians demand transparency about what image features drive automated decisions and whether explanations are stable under shifts.\n\nPost-hoc attribution methods like Grad-CAM and Integrated Gradients highlight salient regions (Selvaraju et al., 2017; Sundararajan et al., 2017). Prototype- and concept-based explanations enhance interpretability (Chen et al., 2019; Kim et al., 2018). Counterfactual generation has been explored for medical images (Chang et al., 2018; Singla et al., 2021).\n\nWe focus on faithfulness under distribution shift and propose an evaluation protocol that aligns explanation stability with clinical acceptance thresholds for screening workflows.\nRelated Work\n\nProviding timely, actionable feedback at scale is central to computing education. Traditional approaches combine instructor-designed rubrics with automated tests, but coverage and specificity can be limited for diverse student solutions.\n\nAutomated feedback for programming assignments has been tackled with static analysis, dynamic test generation, and pattern mining (Ke et al., 2016; Gulwani et al., 2018; Singh et al., 2013). Recent NLP-based systems leverage code embeddings, sequence models, and pretrained language models (Allamanis et al., 2018; Feng et al., 2020; Ahmad et al., 2021). Peer learning platforms collect hints and exemplars to guide novice programmers (Piech et al., 2015; Wang et al., 2018).\n\nWhile data-driven approaches show promise, they often struggle with generalizing across tasks and providing pedagogically aligned guidance. Our work investigates structure-aware hint generation that aligns feedback to conceptual steps in problem-solving.\nRelated Work\n\nReinforcement learning (RL) has enabled robots to acquire complex behaviors directly from interaction. However, data hunger, safety, and sim-to-real transfer remain persistent obstacles for deployment in real-world settings.\n\nModel-free methods such as DDPG (Lillicrap et al., 2016), SAC (Haarnoja et al., 2018), and PPO (Schulman et al., 2017) have been widely adopted for continuous control, while model-based approaches leverage learned dynamics for sample efficiency (Deisenroth and Rasmussen, 2011; Chua et al., 2018). Recent lines of work explore offline RL (Levine et al., 2020; Kumar et al., 2020) and representation learning for policy generalization (Laskin et al., 2020; Yarats et al., 2021). Domain randomization and adaptation seek to bridge the sim-to-real gap (Tobin et al., 2017; Peng et al., 2018).\n\nWe propose a training strategy that combines curriculum learning with uncertainty-aware policy updates to improve safety and sample efficiency in robotic manipulation.\nRelated Work\n\nAutomatic speech recognition (ASR) systems increasingly rely on large encoder\u2013decoder architectures that are costly to deploy on edge devices. Knowledge distillation (KD) is a common strategy to reduce model size while preserving accuracy.\n\nKnowledge distillation for speech recognition has considered frame-level supervision, sequence-level criteria, and wordpiece distributions, transferring knowledge from stronger teachers to smaller students (Hinton et al., 2015; Kim and Rush, 2016; Kurata and Audhkhasi, 2018; Higuchi et al., 2021).\n\nOther compression techniques include quantization and pruning, which can be combined with KD but may degrade robustness to noise and speaker variability. Recent work explores multi-teacher ensembles and intermediate-layer matching to stabilize training.\n\nIn this paper, we study streaming-constrained KD with latency-aware targets, aligning teacher and student under causal masking. Our experiments on LibriSpeech and far-field corpora show improved WER\u2013latency trade-offs compared to strong baselines.\nRelated Work\n\nLarge Language Models and Prompting\nLarge language models (LLMs) exhibit emergent program synthesis capabilities when conditioned on natural language instructions and a handful of examples. While these behaviors reduce reliance on supervised datasets, the mechanisms by which prompts control generation remain only partially understood. Prior studies analyze calibration, decoding strategies, and context length effects.\n\nPrompting for Code Generation\nPrompting for code generation has explored zero-shot, few-shot, and chain-of-thought styles using large language models (Chen et al., 2021; Austin et al., 2021; Nijkamp et al., 2022; Li et al., 2023). Work on compiler-aware prompting adds execution feedback to steer generation (Liu et al., 2022; Le et al., 2022; Wang et al., 2023). Program repair and test-driven synthesis have similarly adapted prompting strategies to satisfy unit tests (Jain et al., 2022; Zhang et al., 2023).\n\nExecution-Conditioned Decoding\nBeyond static prompts, execution-conditioned decoding iteratively runs partial programs to reduce search space. Studies report gains on algorithmic problems by interleaving generation and verification under timeouts and sandboxing constraints.\n\nStructured Constraints and Type Guidance\nApproaches that inject grammar constraints or type information restrict invalid outputs and improve pass rates. These methods range from constrained beam search to type-state automata.\n\nPositioning\nWe examine the interaction between prompt structure and execution feedback and study how typed constraints alter search dynamics under limited budgets.\nRelated Work\n\nFederated learning (FL) enables on-device training with privacy and communication constraints. Ensuring rigorous privacy guarantees while preserving model utility remains a core challenge.\n\nPrivacy in federated learning has been studied via differential privacy at the client level, secure aggregation, and shuffling (McMahan et al., 2017; Kairouz et al., 2021; Bonawitz et al., 2017; Erlingsson et al., 2019). Gradient perturbation, clipping, and client subsampling are common techniques to control privacy loss (Abadi et al., 2016; Thakkar et al., 2019; Andrew et al., 2021). Auditing methods estimate empirical privacy leakage post hoc (Nasr et al., 2019; Jagielski et al., 2020).\n\nOur approach introduces client-adaptive noise schedules conditioned on participation frequency.\n\nWe empirically evaluate privacy-utility trade-offs across heterogeneous client populations.\nIntroduction\n\nInformation retrieval has shifted from lexical term matching to semantic representations that capture contextual meaning. This shift enables better recall of paraphrased content but introduces new challenges in index efficiency and training stability.\n\nNeural semantic search methods combine dual-encoders for efficient retrieval (Yao et al., 2019; Xie and Zhao, 2020) with cross-encoders for reranking (Nogueira and Cho, 2019; Li et al., 2021), and leverage hard-negative mining to improve discriminative power (Gao et al., 2021; Huang et al., 2022). Recent work also explores domain adaptation for specialized corpora such as legal and biomedical texts (Park et al., 2022; Sun et al., 2023).\n\nWe study lightweight domain adaptation under tight indexing budgets.\nRelated Work\n\nDetecting anomalies in time-series is a long-standing problem with applications in monitoring, finance, and industrial IoT. Methods vary widely in assumptions, supervision requirements, and scalability.\n\nTime-series anomaly detection spans classical statistical tests, isolation-based methods, and deep learning models such as autoencoders, temporal convolutional networks, and Transformers (Gupta et al., 2014; Liu et al., 2008; Malhotra et al., 2016; Xu et al., 2020). Synthetic anomaly injection and semi-supervised training are also common practices (Zhang et al., 2019; Shen et al., 2021).\n\nBenchmarking efforts have sought consistent evaluation protocols across datasets with different anomaly types and frequencies (Hundman et al., 2018; Wu and Keogh, 2021).\nRelated Work\n\nPredicting molecular properties from structure has catalyzed a broad literature at the intersection of cheminformatics and geometric deep learning. Approaches differ in how they encode graph topology, chemical attributes, and geometric constraints.\n\nGraph representation learning methods such as spectral GCNs, spatial message passing networks, and attention-based GNNs have been widely applied to molecular property prediction (Kipf and Welling, 2017; Gilmer et al., 2017; Veli\u010dkovi\u0107 et al., 2018). Extensions include edge-conditioned convolutions, higher-order structures, and equivariant networks for 3D geometries (Simonovsky and Komodakis, 2017; Batzner et al., 2022).\n\nPretraining strategies on large unlabeled molecule corpora with contrastive or masked node prediction objectives have further improved generalization, especially in low-data regimes (Hu et al., 2020; Rong et al., 2020).\nIntroduction\n\nAutomated analysis of pathology whole-slide images (WSIs) faces extreme resolution, sparse lesion patterns, and distribution shifts across scanners and staining protocols. Convolutional networks have advanced the field but can be limited in modeling long-range dependencies over gigapixel slides.\n\nVision Transformers have been applied to medical image classification, segmentation, and detection with pure transformer backbones or hybrid CNN\u2013Transformer designs (Dosovitskiy et al., 2020; Chen et al., 2021; Hatamizadeh et al., 2022; Wang et al., 2021; Xie et al., 2021).\n\nWeakly supervised multiple-instance learning (MIL) further alleviates slide-level labeling costs by aggregating patch evidence, yet attention pooling can overfit to spurious correlations. We investigate whether token-level sparsification combined with instance reweighting can improve robustness in cross-site evaluation.\n\nOur method introduces a curriculum-sparse token selection and slide-consistent calibration loss to stabilize attention under domain shift. On three WSI benchmarks spanning different scanners, we observe gains in AUC and improved calibration, with minimal added compute.\n\nWe conduct ablations on sparsity schedules and release pretrained weights for community use.\nRelated Work\n\nRemote sensing change detection relies on robust representations that separate illumination and seasonal effects from structural changes. Recent advances in high-resolution satellites have shifted attention to fine-grained, building-level change cues.\n\nClassical two-stream CNNs, Siamese architectures, and attention-based models have been widely adopted for change detection (Daudt et al., 2018; Fang et al., 2020; Chen et al., 2021). Large-scale datasets such as LEVIR-CD, CDD, and WHU-CD have enabled benchmarking across urban scenes (Levir et al., 2020; Wang et al., 2020; Ji et al., 2019). Transformer-based encoders further improve long-range modeling (Ban et al., 2021; Liu et al., 2021).\n\nWhile these efforts improve accuracy, they largely assume perfectly registered image pairs and abundant labels. Our work targets label-scarce scenarios with misalignment by learning registration-aware tokens that disentangle geometry from appearance.\nIntroduction\n\nEffective human-robot collaboration requires balancing adaptability to user intent with guarantees on safety and task efficiency. Real-world deployments must operate under partial observability and distribution shifts in user behavior.\n\nShared autonomy techniques span predictive user intent modeling, POMDP-based assistance, arbitration policies that blend human and robot commands, and learning from demonstration for collaborative tasks (Dragan and Srinivasa, 2013; Javdani et al., 2015; Reddy et al., 2018; Losey et al., 2020).\n\nWe propose CertAssist, a certifiably safe shared autonomy framework combining control barrier functions with belief-dependent arbitration, evaluated on manipulation and navigation tasks with human participants.\n",
        "completion": "Shared autonomy techniques span predictive user intent modeling, POMDP-based assistance, arbitration policies that blend human and robot commands, and learning from demonstration for collaborative tasks (Dragan and Srinivasa, 2013; Javdani et al., 2015; Reddy et al., 2018; Losey et al., 2020)."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        occurs when either:\n    a) The author describes or cites papers without connecting them to their own work/argument \n    b) Or only follows up the summary of previous works with their own contribution without explicitly highlighting the gap their work intends to research.\n    c) It does not articulate the author's perspective or motivation.\n    d) A lack of argument/opinion in the first paragraph is permissible as it serves to be the foundation of the author's argument \n    e) Lacks synthesis issues appear either as single sentences or multiple sentences.\n    Examples of lack of synthesis include:\n        i) No elaboration of own contribution/argument:\"Following early neural approaches to question answering, many subsequent studies adopt a pipeline architecture consisting of retrieval and comprehension components. The retrieval component focuses on identifying relevant documents or passages from a large corpus, while the comprehension component extracts an answer span from the retrieved text. Initial models relied on recurrent neural networks with attention mechanisms to encode questions and contexts (Seo et al., 2017; Wang et al., 2017).\"\n        ii)  No explanation of the cited works and relation to their own work: \u201cRecently, several studies have explored the use of prompting techniques with pre-trained language models to influence model outputs or access latent knowledge (Brown et al., 2020; Gao et al., 2021; Liu et al., 2021; Wei et al., 2022).\u201d \n\n        Example text: \n        Related Work\n\nDevelopers rely on code search to find relevant snippets, APIs, or examples. Unlike general document retrieval, code search must bridge natural language intent and program structure.\n\nNeural code search has been addressed with bi-encoders, cross-encoders, and dual learning (Gu et al., 2018; Husain et al., 2019; Feng et al., 2020). Structural representations incorporate ASTs, control flow, and data flow (Alon et al., 2019; Wang et al., 2020; Liu et al., 2021). Pretraining on code and NL improves retrieval metrics across languages (Ahmad et al., 2021; Guo et al., 2021).\n\nIn this paper, we introduce a language-agnostic retriever with compositional queries.\n\nWe evaluate zero-shot transfer across four programming languages.\nIntroduction\n\nGeneralization in text classification can be improved with data augmentation, especially when labeled data are scarce or imbalanced. Approaches range from rule-based edits to model-driven paraphrasing and representation-space mixing.\n\nText augmentation techniques include synonym replacement, random insertion/deletion, back-translation, paraphrase generation, and mixup in embedding or hidden spaces (Wei and Zou, 2019; Sennrich et al., 2016; Kobayashi, 2018; Guo et al., 2020). Recent work explores task-adaptive augmentation policies learned by reinforcement learning (Xie et al., 2020).\n\nEvaluation typically considers robustness to domain shift, label noise, and distributional skew across multiple benchmarks (Pruksachatkun et al., 2020; Hendrycks et al., 2020).\nRelated Work\n\nKnowledge graph completion predicts missing links by learning entity and relation representations. Methods vary in how they encode semantics and handle patterns like symmetry, hierarchy, and composition.\n\nTranslation-based knowledge graph embeddings model relations as translations in vector space (Bordes et al., 2013; Wang et al., 2014), while bilinear and neural models capture more complex interactions (Nickel et al., 2011; Trouillon et al., 2016; Sun et al., 2019). Regularization and rule-guided approaches improve inductive bias and data efficiency (Rockt\u00e4schel et al., 2015; Minervini et al., 2017).\n\nWe introduce a lightweight compositional constraint for hierarchical relations and evaluate on three benchmarks and an industry dataset.\nRelated Work\n\nEnsuring safety during reinforcement learning is critical in real-world control where violations can be costly. Research has proposed both objective-level and mechanism-level solutions.\n\nSafe reinforcement learning approaches include risk-sensitive objectives such as CVaR optimization (Tamar et al., 2015; Chow et al., 2018), constrained policy optimization with safety budgets (Achiam et al., 2017; Yang et al., 2020), and shielding based on model-checking or supervisors (Alshiekh et al., 2018; Dalal et al., 2018). We develop a method that integrates model-predictive constraints with policy gradients.\n\nBenchmarks often evaluate safety in simulated robotics or navigation with cost functions approximating constraint violations (Ray et al., 2019; Bharadhwaj et al., 2021).\nRelated Work\n\nDialog state tracking (DST) has evolved from rule-based slot filling to neural architectures that jointly infer belief states across turns. Early pipeline models used hand-crafted lexicons and semantic frames (Singh and Patel, 2015), but suffered from brittleness to paraphrase and noise. Neural encoders introduced robustness by contextualizing utterances, incorporating attention over dialog history, and modeling slot-value dependencies (Lee et al., 2018; Choe and Kim, 2019).\n\nPretrained language models have further shifted the landscape by enabling few-shot generalization and open-vocabulary slot values. Fine-tuning BERT-like encoders for DST improved cross-domain transfer (Rao et al., 2020), while generative formulations cast state tracking as text-to-text prediction (Mendez et al., 2021).\n\nPrompting-based approaches have also been explored for dialog modeling (Kumar et al., 2021; Ortega and Lin, 2022; Park et al., 2023). These methods condition large language models on task instructions or few-shot exemplars to elicit latent conversational knowledge. Recent variants incorporate calibration or self-consistency to stabilize outputs (Fang et al., 2023; Zhou et al., 2023).\n\nPosition relative to this paper While we also employ pretrained sequence-to-sequence models, our focus is on handling ontology drift in long-running deployments. Specifically, we introduce an adaptive slot schema encoder that aligns evolving taxonomies with dialog evidence, and a contrastive consistency objective to mitigate spurious slot co-activations across domains.\nIntroduction\n\nSelf-supervised learning (SSL) has become the dominant paradigm for learning transferable visual features without labels. By constructing pretext tasks that expose invariances and structure inherent in data, SSL models can match or surpass supervised baselines on many downstream tasks.\n\nContrastive pretraining has been widely adopted for visual representations (Chen et al., 2020; He et al., 2020; Xie and Xu, 2021). Non-contrastive methods remove negative pairs and rely on architectural or objective asymmetries (Grill et al., 2020; Tian et al., 2021). Clustering-based methods jointly learn assignments and embeddings (Caron et al., 2018; Li and Gao, 2022).\n\nDespite these advances, industrial applications often operate under strict memory budgets and latency constraints. In this paper, we investigate compute-aware pretraining objectives that couple multi-crop augmentation with a token-subsampled backbone. We present a latency-regularized alignment loss that preserves downstream accuracy while reducing FLOPs during both pretraining and fine-tuning.\nIntroduction\n\nEfficient exploration remains a central challenge in reinforcement learning (RL), particularly in sparse-reward environments where naive strategies fail to discover rewarding states. Over-exploration, however, can waste samples and destabilize learning.\n\nExploration in reinforcement learning has been advanced by count-based bonuses, intrinsic motivation, curiosity-driven prediction error, and information-theoretic objectives (Bellemare et al., 2016; Pathak et al., 2017; Houthooft et al., 2016; Burda et al., 2019; Ta\u00efga et al., 2020).\n\nYet, when environment dynamics change over time, stale novelty estimates can encourage revisiting obsolete states. We propose a recency-aware intrinsic reward that discounts outdated novelty and couples it with conservative policy updates.\n\nAcross Atari and continuous-control domains with drifting dynamics, our method achieves superior sample efficiency and stability, and ablations confirm the role of recency in balancing exploration and exploitation.\nRelated Work\n\nDetecting anomalies in multivariate time series is vital for monitoring industrial systems and cloud services. The challenge lies in handling seasonality, rare events, and inter-variable dependencies.\n\nClassical anomaly detection leverages ARIMA residual tests, STL decomposition, and control charts, while deep methods introduce autoencoders, VAEs, GANs, LSTMs, and Transformers for reconstruction or prediction errors (Tsay, 2010; Malhotra et al., 2015; An and Cho, 2015; Li et al., 2019; Xu et al., 2021).\n\nWe present Contrastive Forecasting with Graph Priors (CFGP), which learns structure-aware representations via self-supervised objectives and uses calibrated predictive intervals to flag anomalies.\nIntroduction\n\nGeneralizing manipulation skills across objects, tasks, and environments remains a central challenge in robotics. Sparse rewards, safety constraints, and hardware variability complicate learning on physical systems. Recent work studies imitation learning, offline RL, and model-based control for dexterous manipulation (Rajeswaran et al., 2018; Lynch et al., 2020; Nagabandi et al., 2019; Ahn et al., 2022). Despite these advances, scaling data collection and ensuring sim-to-real transfer continue to be bottlenecks.\n\nWe explore a curriculum that interleaves skill discovery from teleoperation logs with conservative online updates, targeting stable improvements under limited interaction budgets.\nRelated Work\n\nConversational recommenders. Systems that interactively elicit user preferences can reduce cold-start and improve satisfaction (Sun and Zhang, 2018). Dialog policy learning for conversational recommendation has explored supervised learning, reinforcement learning, and bandit methods (Christakopoulou et al., 2016; Lei et al., 2020; Chen et al., 2019). User simulators and counterfactual logging have been proposed to address data scarcity and evaluation challenges (Li et al., 2017; Chi et al., 2020).\n\nOur study investigates preference drift over long-horizon sessions and proposes a state representation that explicitly tracks uncertainty and recency effects.\nIntroduction\n\nExplainable AI (XAI) is increasingly required for medical imaging systems used in screening and triage. Beyond predictive accuracy, clinicians demand transparency about what image features drive automated decisions and whether explanations are stable under shifts.\n\nPost-hoc attribution methods like Grad-CAM and Integrated Gradients highlight salient regions (Selvaraju et al., 2017; Sundararajan et al., 2017). Prototype- and concept-based explanations enhance interpretability (Chen et al., 2019; Kim et al., 2018). Counterfactual generation has been explored for medical images (Chang et al., 2018; Singla et al., 2021).\n\nWe focus on faithfulness under distribution shift and propose an evaluation protocol that aligns explanation stability with clinical acceptance thresholds for screening workflows.\nRelated Work\n\nProviding timely, actionable feedback at scale is central to computing education. Traditional approaches combine instructor-designed rubrics with automated tests, but coverage and specificity can be limited for diverse student solutions.\n\nAutomated feedback for programming assignments has been tackled with static analysis, dynamic test generation, and pattern mining (Ke et al., 2016; Gulwani et al., 2018; Singh et al., 2013). Recent NLP-based systems leverage code embeddings, sequence models, and pretrained language models (Allamanis et al., 2018; Feng et al., 2020; Ahmad et al., 2021). Peer learning platforms collect hints and exemplars to guide novice programmers (Piech et al., 2015; Wang et al., 2018).\n\nWhile data-driven approaches show promise, they often struggle with generalizing across tasks and providing pedagogically aligned guidance. Our work investigates structure-aware hint generation that aligns feedback to conceptual steps in problem-solving.\nRelated Work\n\nReinforcement learning (RL) has enabled robots to acquire complex behaviors directly from interaction. However, data hunger, safety, and sim-to-real transfer remain persistent obstacles for deployment in real-world settings.\n\nModel-free methods such as DDPG (Lillicrap et al., 2016), SAC (Haarnoja et al., 2018), and PPO (Schulman et al., 2017) have been widely adopted for continuous control, while model-based approaches leverage learned dynamics for sample efficiency (Deisenroth and Rasmussen, 2011; Chua et al., 2018). Recent lines of work explore offline RL (Levine et al., 2020; Kumar et al., 2020) and representation learning for policy generalization (Laskin et al., 2020; Yarats et al., 2021). Domain randomization and adaptation seek to bridge the sim-to-real gap (Tobin et al., 2017; Peng et al., 2018).\n\nWe propose a training strategy that combines curriculum learning with uncertainty-aware policy updates to improve safety and sample efficiency in robotic manipulation.\nRelated Work\n\nAutomatic speech recognition (ASR) systems increasingly rely on large encoder\u2013decoder architectures that are costly to deploy on edge devices. Knowledge distillation (KD) is a common strategy to reduce model size while preserving accuracy.\n\nKnowledge distillation for speech recognition has considered frame-level supervision, sequence-level criteria, and wordpiece distributions, transferring knowledge from stronger teachers to smaller students (Hinton et al., 2015; Kim and Rush, 2016; Kurata and Audhkhasi, 2018; Higuchi et al., 2021).\n\nOther compression techniques include quantization and pruning, which can be combined with KD but may degrade robustness to noise and speaker variability. Recent work explores multi-teacher ensembles and intermediate-layer matching to stabilize training.\n\nIn this paper, we study streaming-constrained KD with latency-aware targets, aligning teacher and student under causal masking. Our experiments on LibriSpeech and far-field corpora show improved WER\u2013latency trade-offs compared to strong baselines.\nRelated Work\n\nLarge Language Models and Prompting\nLarge language models (LLMs) exhibit emergent program synthesis capabilities when conditioned on natural language instructions and a handful of examples. While these behaviors reduce reliance on supervised datasets, the mechanisms by which prompts control generation remain only partially understood. Prior studies analyze calibration, decoding strategies, and context length effects.\n\nPrompting for Code Generation\nPrompting for code generation has explored zero-shot, few-shot, and chain-of-thought styles using large language models (Chen et al., 2021; Austin et al., 2021; Nijkamp et al., 2022; Li et al., 2023). Work on compiler-aware prompting adds execution feedback to steer generation (Liu et al., 2022; Le et al., 2022; Wang et al., 2023). Program repair and test-driven synthesis have similarly adapted prompting strategies to satisfy unit tests (Jain et al., 2022; Zhang et al., 2023).\n\nExecution-Conditioned Decoding\nBeyond static prompts, execution-conditioned decoding iteratively runs partial programs to reduce search space. Studies report gains on algorithmic problems by interleaving generation and verification under timeouts and sandboxing constraints.\n\nStructured Constraints and Type Guidance\nApproaches that inject grammar constraints or type information restrict invalid outputs and improve pass rates. These methods range from constrained beam search to type-state automata.\n\nPositioning\nWe examine the interaction between prompt structure and execution feedback and study how typed constraints alter search dynamics under limited budgets.\nRelated Work\n\nFederated learning (FL) enables on-device training with privacy and communication constraints. Ensuring rigorous privacy guarantees while preserving model utility remains a core challenge.\n\nPrivacy in federated learning has been studied via differential privacy at the client level, secure aggregation, and shuffling (McMahan et al., 2017; Kairouz et al., 2021; Bonawitz et al., 2017; Erlingsson et al., 2019). Gradient perturbation, clipping, and client subsampling are common techniques to control privacy loss (Abadi et al., 2016; Thakkar et al., 2019; Andrew et al., 2021). Auditing methods estimate empirical privacy leakage post hoc (Nasr et al., 2019; Jagielski et al., 2020).\n\nOur approach introduces client-adaptive noise schedules conditioned on participation frequency.\n\nWe empirically evaluate privacy-utility trade-offs across heterogeneous client populations.\nIntroduction\n\nInformation retrieval has shifted from lexical term matching to semantic representations that capture contextual meaning. This shift enables better recall of paraphrased content but introduces new challenges in index efficiency and training stability.\n\nNeural semantic search methods combine dual-encoders for efficient retrieval (Yao et al., 2019; Xie and Zhao, 2020) with cross-encoders for reranking (Nogueira and Cho, 2019; Li et al., 2021), and leverage hard-negative mining to improve discriminative power (Gao et al., 2021; Huang et al., 2022). Recent work also explores domain adaptation for specialized corpora such as legal and biomedical texts (Park et al., 2022; Sun et al., 2023).\n\nWe study lightweight domain adaptation under tight indexing budgets.\nRelated Work\n\nDetecting anomalies in time-series is a long-standing problem with applications in monitoring, finance, and industrial IoT. Methods vary widely in assumptions, supervision requirements, and scalability.\n\nTime-series anomaly detection spans classical statistical tests, isolation-based methods, and deep learning models such as autoencoders, temporal convolutional networks, and Transformers (Gupta et al., 2014; Liu et al., 2008; Malhotra et al., 2016; Xu et al., 2020). Synthetic anomaly injection and semi-supervised training are also common practices (Zhang et al., 2019; Shen et al., 2021).\n\nBenchmarking efforts have sought consistent evaluation protocols across datasets with different anomaly types and frequencies (Hundman et al., 2018; Wu and Keogh, 2021).\nRelated Work\n\nPredicting molecular properties from structure has catalyzed a broad literature at the intersection of cheminformatics and geometric deep learning. Approaches differ in how they encode graph topology, chemical attributes, and geometric constraints.\n\nGraph representation learning methods such as spectral GCNs, spatial message passing networks, and attention-based GNNs have been widely applied to molecular property prediction (Kipf and Welling, 2017; Gilmer et al., 2017; Veli\u010dkovi\u0107 et al., 2018). Extensions include edge-conditioned convolutions, higher-order structures, and equivariant networks for 3D geometries (Simonovsky and Komodakis, 2017; Batzner et al., 2022).\n\nPretraining strategies on large unlabeled molecule corpora with contrastive or masked node prediction objectives have further improved generalization, especially in low-data regimes (Hu et al., 2020; Rong et al., 2020).\nIntroduction\n\nAutomated analysis of pathology whole-slide images (WSIs) faces extreme resolution, sparse lesion patterns, and distribution shifts across scanners and staining protocols. Convolutional networks have advanced the field but can be limited in modeling long-range dependencies over gigapixel slides.\n\nVision Transformers have been applied to medical image classification, segmentation, and detection with pure transformer backbones or hybrid CNN\u2013Transformer designs (Dosovitskiy et al., 2020; Chen et al., 2021; Hatamizadeh et al., 2022; Wang et al., 2021; Xie et al., 2021).\n\nWeakly supervised multiple-instance learning (MIL) further alleviates slide-level labeling costs by aggregating patch evidence, yet attention pooling can overfit to spurious correlations. We investigate whether token-level sparsification combined with instance reweighting can improve robustness in cross-site evaluation.\n\nOur method introduces a curriculum-sparse token selection and slide-consistent calibration loss to stabilize attention under domain shift. On three WSI benchmarks spanning different scanners, we observe gains in AUC and improved calibration, with minimal added compute.\n\nWe conduct ablations on sparsity schedules and release pretrained weights for community use.\nRelated Work\n\nRemote sensing change detection relies on robust representations that separate illumination and seasonal effects from structural changes. Recent advances in high-resolution satellites have shifted attention to fine-grained, building-level change cues.\n\nClassical two-stream CNNs, Siamese architectures, and attention-based models have been widely adopted for change detection (Daudt et al., 2018; Fang et al., 2020; Chen et al., 2021). Large-scale datasets such as LEVIR-CD, CDD, and WHU-CD have enabled benchmarking across urban scenes (Levir et al., 2020; Wang et al., 2020; Ji et al., 2019). Transformer-based encoders further improve long-range modeling (Ban et al., 2021; Liu et al., 2021).\n\nWhile these efforts improve accuracy, they largely assume perfectly registered image pairs and abundant labels. Our work targets label-scarce scenarios with misalignment by learning registration-aware tokens that disentangle geometry from appearance.\nIntroduction\n\nEffective human-robot collaboration requires balancing adaptability to user intent with guarantees on safety and task efficiency. Real-world deployments must operate under partial observability and distribution shifts in user behavior.\n\nShared autonomy techniques span predictive user intent modeling, POMDP-based assistance, arbitration policies that blend human and robot commands, and learning from demonstration for collaborative tasks (Dragan and Srinivasa, 2013; Javdani et al., 2015; Reddy et al., 2018; Losey et al., 2020).\n\nWe propose CertAssist, a certifiably safe shared autonomy framework combining control barrier functions with belief-dependent arbitration, evaluated on manipulation and navigation tasks with human participants.\nIntroduction\nAccurate forecasting underpins decision-making in supply chains, energy, and finance. Models must balance bias-variance trade-offs, handle sparse covariates, and remain robust to nonstationary shifts and irregular sampling.\n\nClassical time series forecasting relies on ARIMA and exponential smoothing to model linear dependencies (Box and Jenkins, 1970; Hyndman et al., 2008). Neural models introduce nonlinearity via RNNs, LSTMs, and temporal convolutions (Hochreiter and Schmidhuber, 1997; Bai et al., 2018). Transformer-based forecasters use attention to capture long-range dependencies (Li et al., 2019; Zhou et al., 2021). Decomposition and frequency-domain methods further reduce complexity and highlight seasonal structure (Oreshkin et al., 2020; Wu et al., 2021).\n\nWe present an uncertainty-aware spectral transformer that couples learnable seasonal kernels with interval calibration, yielding improved accuracy and coverage under regime shifts in retail and traffic datasets.\n",
        "completion": "Classical time series forecasting relies on ARIMA and exponential smoothing to model linear dependencies (Box and Jenkins, 1970; Hyndman et al., 2008). Neural models introduce nonlinearity via RNNs, LSTMs, and temporal convolutions (Hochreiter and Schmidhuber, 1997; Bai et al., 2018). Transformer-based forecasters use attention to capture long-range dependencies (Li et al., 2019; Zhou et al., 2021). Decomposition and frequency-domain methods further reduce complexity and highlight seasonal structure (Oreshkin et al., 2020; Wu et al., 2021)."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        occurs when either:\n    a) The author describes or cites papers without connecting them to their own work/argument \n    b) Or only follows up the summary of previous works with their own contribution without explicitly highlighting the gap their work intends to research.\n    c) It does not articulate the author's perspective or motivation.\n    d) A lack of argument/opinion in the first paragraph is permissible as it serves to be the foundation of the author's argument \n    e) Lacks synthesis issues appear either as single sentences or multiple sentences.\n    Examples of lack of synthesis include:\n        i) No elaboration of own contribution/argument:\"Following early neural approaches to question answering, many subsequent studies adopt a pipeline architecture consisting of retrieval and comprehension components. The retrieval component focuses on identifying relevant documents or passages from a large corpus, while the comprehension component extracts an answer span from the retrieved text. Initial models relied on recurrent neural networks with attention mechanisms to encode questions and contexts (Seo et al., 2017; Wang et al., 2017).\"\n        ii)  No explanation of the cited works and relation to their own work: \u201cRecently, several studies have explored the use of prompting techniques with pre-trained language models to influence model outputs or access latent knowledge (Brown et al., 2020; Gao et al., 2021; Liu et al., 2021; Wei et al., 2022).\u201d \n\n        Example text: \n        Related Work\n\nDevelopers rely on code search to find relevant snippets, APIs, or examples. Unlike general document retrieval, code search must bridge natural language intent and program structure.\n\nNeural code search has been addressed with bi-encoders, cross-encoders, and dual learning (Gu et al., 2018; Husain et al., 2019; Feng et al., 2020). Structural representations incorporate ASTs, control flow, and data flow (Alon et al., 2019; Wang et al., 2020; Liu et al., 2021). Pretraining on code and NL improves retrieval metrics across languages (Ahmad et al., 2021; Guo et al., 2021).\n\nIn this paper, we introduce a language-agnostic retriever with compositional queries.\n\nWe evaluate zero-shot transfer across four programming languages.\nIntroduction\n\nGeneralization in text classification can be improved with data augmentation, especially when labeled data are scarce or imbalanced. Approaches range from rule-based edits to model-driven paraphrasing and representation-space mixing.\n\nText augmentation techniques include synonym replacement, random insertion/deletion, back-translation, paraphrase generation, and mixup in embedding or hidden spaces (Wei and Zou, 2019; Sennrich et al., 2016; Kobayashi, 2018; Guo et al., 2020). Recent work explores task-adaptive augmentation policies learned by reinforcement learning (Xie et al., 2020).\n\nEvaluation typically considers robustness to domain shift, label noise, and distributional skew across multiple benchmarks (Pruksachatkun et al., 2020; Hendrycks et al., 2020).\nRelated Work\n\nKnowledge graph completion predicts missing links by learning entity and relation representations. Methods vary in how they encode semantics and handle patterns like symmetry, hierarchy, and composition.\n\nTranslation-based knowledge graph embeddings model relations as translations in vector space (Bordes et al., 2013; Wang et al., 2014), while bilinear and neural models capture more complex interactions (Nickel et al., 2011; Trouillon et al., 2016; Sun et al., 2019). Regularization and rule-guided approaches improve inductive bias and data efficiency (Rockt\u00e4schel et al., 2015; Minervini et al., 2017).\n\nWe introduce a lightweight compositional constraint for hierarchical relations and evaluate on three benchmarks and an industry dataset.\nRelated Work\n\nEnsuring safety during reinforcement learning is critical in real-world control where violations can be costly. Research has proposed both objective-level and mechanism-level solutions.\n\nSafe reinforcement learning approaches include risk-sensitive objectives such as CVaR optimization (Tamar et al., 2015; Chow et al., 2018), constrained policy optimization with safety budgets (Achiam et al., 2017; Yang et al., 2020), and shielding based on model-checking or supervisors (Alshiekh et al., 2018; Dalal et al., 2018). We develop a method that integrates model-predictive constraints with policy gradients.\n\nBenchmarks often evaluate safety in simulated robotics or navigation with cost functions approximating constraint violations (Ray et al., 2019; Bharadhwaj et al., 2021).\nRelated Work\n\nDialog state tracking (DST) has evolved from rule-based slot filling to neural architectures that jointly infer belief states across turns. Early pipeline models used hand-crafted lexicons and semantic frames (Singh and Patel, 2015), but suffered from brittleness to paraphrase and noise. Neural encoders introduced robustness by contextualizing utterances, incorporating attention over dialog history, and modeling slot-value dependencies (Lee et al., 2018; Choe and Kim, 2019).\n\nPretrained language models have further shifted the landscape by enabling few-shot generalization and open-vocabulary slot values. Fine-tuning BERT-like encoders for DST improved cross-domain transfer (Rao et al., 2020), while generative formulations cast state tracking as text-to-text prediction (Mendez et al., 2021).\n\nPrompting-based approaches have also been explored for dialog modeling (Kumar et al., 2021; Ortega and Lin, 2022; Park et al., 2023). These methods condition large language models on task instructions or few-shot exemplars to elicit latent conversational knowledge. Recent variants incorporate calibration or self-consistency to stabilize outputs (Fang et al., 2023; Zhou et al., 2023).\n\nPosition relative to this paper While we also employ pretrained sequence-to-sequence models, our focus is on handling ontology drift in long-running deployments. Specifically, we introduce an adaptive slot schema encoder that aligns evolving taxonomies with dialog evidence, and a contrastive consistency objective to mitigate spurious slot co-activations across domains.\nIntroduction\n\nSelf-supervised learning (SSL) has become the dominant paradigm for learning transferable visual features without labels. By constructing pretext tasks that expose invariances and structure inherent in data, SSL models can match or surpass supervised baselines on many downstream tasks.\n\nContrastive pretraining has been widely adopted for visual representations (Chen et al., 2020; He et al., 2020; Xie and Xu, 2021). Non-contrastive methods remove negative pairs and rely on architectural or objective asymmetries (Grill et al., 2020; Tian et al., 2021). Clustering-based methods jointly learn assignments and embeddings (Caron et al., 2018; Li and Gao, 2022).\n\nDespite these advances, industrial applications often operate under strict memory budgets and latency constraints. In this paper, we investigate compute-aware pretraining objectives that couple multi-crop augmentation with a token-subsampled backbone. We present a latency-regularized alignment loss that preserves downstream accuracy while reducing FLOPs during both pretraining and fine-tuning.\nIntroduction\n\nEfficient exploration remains a central challenge in reinforcement learning (RL), particularly in sparse-reward environments where naive strategies fail to discover rewarding states. Over-exploration, however, can waste samples and destabilize learning.\n\nExploration in reinforcement learning has been advanced by count-based bonuses, intrinsic motivation, curiosity-driven prediction error, and information-theoretic objectives (Bellemare et al., 2016; Pathak et al., 2017; Houthooft et al., 2016; Burda et al., 2019; Ta\u00efga et al., 2020).\n\nYet, when environment dynamics change over time, stale novelty estimates can encourage revisiting obsolete states. We propose a recency-aware intrinsic reward that discounts outdated novelty and couples it with conservative policy updates.\n\nAcross Atari and continuous-control domains with drifting dynamics, our method achieves superior sample efficiency and stability, and ablations confirm the role of recency in balancing exploration and exploitation.\nRelated Work\n\nDetecting anomalies in multivariate time series is vital for monitoring industrial systems and cloud services. The challenge lies in handling seasonality, rare events, and inter-variable dependencies.\n\nClassical anomaly detection leverages ARIMA residual tests, STL decomposition, and control charts, while deep methods introduce autoencoders, VAEs, GANs, LSTMs, and Transformers for reconstruction or prediction errors (Tsay, 2010; Malhotra et al., 2015; An and Cho, 2015; Li et al., 2019; Xu et al., 2021).\n\nWe present Contrastive Forecasting with Graph Priors (CFGP), which learns structure-aware representations via self-supervised objectives and uses calibrated predictive intervals to flag anomalies.\nIntroduction\n\nGeneralizing manipulation skills across objects, tasks, and environments remains a central challenge in robotics. Sparse rewards, safety constraints, and hardware variability complicate learning on physical systems. Recent work studies imitation learning, offline RL, and model-based control for dexterous manipulation (Rajeswaran et al., 2018; Lynch et al., 2020; Nagabandi et al., 2019; Ahn et al., 2022). Despite these advances, scaling data collection and ensuring sim-to-real transfer continue to be bottlenecks.\n\nWe explore a curriculum that interleaves skill discovery from teleoperation logs with conservative online updates, targeting stable improvements under limited interaction budgets.\nRelated Work\n\nConversational recommenders. Systems that interactively elicit user preferences can reduce cold-start and improve satisfaction (Sun and Zhang, 2018). Dialog policy learning for conversational recommendation has explored supervised learning, reinforcement learning, and bandit methods (Christakopoulou et al., 2016; Lei et al., 2020; Chen et al., 2019). User simulators and counterfactual logging have been proposed to address data scarcity and evaluation challenges (Li et al., 2017; Chi et al., 2020).\n\nOur study investigates preference drift over long-horizon sessions and proposes a state representation that explicitly tracks uncertainty and recency effects.\nIntroduction\n\nExplainable AI (XAI) is increasingly required for medical imaging systems used in screening and triage. Beyond predictive accuracy, clinicians demand transparency about what image features drive automated decisions and whether explanations are stable under shifts.\n\nPost-hoc attribution methods like Grad-CAM and Integrated Gradients highlight salient regions (Selvaraju et al., 2017; Sundararajan et al., 2017). Prototype- and concept-based explanations enhance interpretability (Chen et al., 2019; Kim et al., 2018). Counterfactual generation has been explored for medical images (Chang et al., 2018; Singla et al., 2021).\n\nWe focus on faithfulness under distribution shift and propose an evaluation protocol that aligns explanation stability with clinical acceptance thresholds for screening workflows.\nRelated Work\n\nProviding timely, actionable feedback at scale is central to computing education. Traditional approaches combine instructor-designed rubrics with automated tests, but coverage and specificity can be limited for diverse student solutions.\n\nAutomated feedback for programming assignments has been tackled with static analysis, dynamic test generation, and pattern mining (Ke et al., 2016; Gulwani et al., 2018; Singh et al., 2013). Recent NLP-based systems leverage code embeddings, sequence models, and pretrained language models (Allamanis et al., 2018; Feng et al., 2020; Ahmad et al., 2021). Peer learning platforms collect hints and exemplars to guide novice programmers (Piech et al., 2015; Wang et al., 2018).\n\nWhile data-driven approaches show promise, they often struggle with generalizing across tasks and providing pedagogically aligned guidance. Our work investigates structure-aware hint generation that aligns feedback to conceptual steps in problem-solving.\nRelated Work\n\nReinforcement learning (RL) has enabled robots to acquire complex behaviors directly from interaction. However, data hunger, safety, and sim-to-real transfer remain persistent obstacles for deployment in real-world settings.\n\nModel-free methods such as DDPG (Lillicrap et al., 2016), SAC (Haarnoja et al., 2018), and PPO (Schulman et al., 2017) have been widely adopted for continuous control, while model-based approaches leverage learned dynamics for sample efficiency (Deisenroth and Rasmussen, 2011; Chua et al., 2018). Recent lines of work explore offline RL (Levine et al., 2020; Kumar et al., 2020) and representation learning for policy generalization (Laskin et al., 2020; Yarats et al., 2021). Domain randomization and adaptation seek to bridge the sim-to-real gap (Tobin et al., 2017; Peng et al., 2018).\n\nWe propose a training strategy that combines curriculum learning with uncertainty-aware policy updates to improve safety and sample efficiency in robotic manipulation.\nRelated Work\n\nAutomatic speech recognition (ASR) systems increasingly rely on large encoder\u2013decoder architectures that are costly to deploy on edge devices. Knowledge distillation (KD) is a common strategy to reduce model size while preserving accuracy.\n\nKnowledge distillation for speech recognition has considered frame-level supervision, sequence-level criteria, and wordpiece distributions, transferring knowledge from stronger teachers to smaller students (Hinton et al., 2015; Kim and Rush, 2016; Kurata and Audhkhasi, 2018; Higuchi et al., 2021).\n\nOther compression techniques include quantization and pruning, which can be combined with KD but may degrade robustness to noise and speaker variability. Recent work explores multi-teacher ensembles and intermediate-layer matching to stabilize training.\n\nIn this paper, we study streaming-constrained KD with latency-aware targets, aligning teacher and student under causal masking. Our experiments on LibriSpeech and far-field corpora show improved WER\u2013latency trade-offs compared to strong baselines.\nRelated Work\n\nLarge Language Models and Prompting\nLarge language models (LLMs) exhibit emergent program synthesis capabilities when conditioned on natural language instructions and a handful of examples. While these behaviors reduce reliance on supervised datasets, the mechanisms by which prompts control generation remain only partially understood. Prior studies analyze calibration, decoding strategies, and context length effects.\n\nPrompting for Code Generation\nPrompting for code generation has explored zero-shot, few-shot, and chain-of-thought styles using large language models (Chen et al., 2021; Austin et al., 2021; Nijkamp et al., 2022; Li et al., 2023). Work on compiler-aware prompting adds execution feedback to steer generation (Liu et al., 2022; Le et al., 2022; Wang et al., 2023). Program repair and test-driven synthesis have similarly adapted prompting strategies to satisfy unit tests (Jain et al., 2022; Zhang et al., 2023).\n\nExecution-Conditioned Decoding\nBeyond static prompts, execution-conditioned decoding iteratively runs partial programs to reduce search space. Studies report gains on algorithmic problems by interleaving generation and verification under timeouts and sandboxing constraints.\n\nStructured Constraints and Type Guidance\nApproaches that inject grammar constraints or type information restrict invalid outputs and improve pass rates. These methods range from constrained beam search to type-state automata.\n\nPositioning\nWe examine the interaction between prompt structure and execution feedback and study how typed constraints alter search dynamics under limited budgets.\nRelated Work\n\nFederated learning (FL) enables on-device training with privacy and communication constraints. Ensuring rigorous privacy guarantees while preserving model utility remains a core challenge.\n\nPrivacy in federated learning has been studied via differential privacy at the client level, secure aggregation, and shuffling (McMahan et al., 2017; Kairouz et al., 2021; Bonawitz et al., 2017; Erlingsson et al., 2019). Gradient perturbation, clipping, and client subsampling are common techniques to control privacy loss (Abadi et al., 2016; Thakkar et al., 2019; Andrew et al., 2021). Auditing methods estimate empirical privacy leakage post hoc (Nasr et al., 2019; Jagielski et al., 2020).\n\nOur approach introduces client-adaptive noise schedules conditioned on participation frequency.\n\nWe empirically evaluate privacy-utility trade-offs across heterogeneous client populations.\nIntroduction\n\nInformation retrieval has shifted from lexical term matching to semantic representations that capture contextual meaning. This shift enables better recall of paraphrased content but introduces new challenges in index efficiency and training stability.\n\nNeural semantic search methods combine dual-encoders for efficient retrieval (Yao et al., 2019; Xie and Zhao, 2020) with cross-encoders for reranking (Nogueira and Cho, 2019; Li et al., 2021), and leverage hard-negative mining to improve discriminative power (Gao et al., 2021; Huang et al., 2022). Recent work also explores domain adaptation for specialized corpora such as legal and biomedical texts (Park et al., 2022; Sun et al., 2023).\n\nWe study lightweight domain adaptation under tight indexing budgets.\nRelated Work\n\nDetecting anomalies in time-series is a long-standing problem with applications in monitoring, finance, and industrial IoT. Methods vary widely in assumptions, supervision requirements, and scalability.\n\nTime-series anomaly detection spans classical statistical tests, isolation-based methods, and deep learning models such as autoencoders, temporal convolutional networks, and Transformers (Gupta et al., 2014; Liu et al., 2008; Malhotra et al., 2016; Xu et al., 2020). Synthetic anomaly injection and semi-supervised training are also common practices (Zhang et al., 2019; Shen et al., 2021).\n\nBenchmarking efforts have sought consistent evaluation protocols across datasets with different anomaly types and frequencies (Hundman et al., 2018; Wu and Keogh, 2021).\nRelated Work\n\nPredicting molecular properties from structure has catalyzed a broad literature at the intersection of cheminformatics and geometric deep learning. Approaches differ in how they encode graph topology, chemical attributes, and geometric constraints.\n\nGraph representation learning methods such as spectral GCNs, spatial message passing networks, and attention-based GNNs have been widely applied to molecular property prediction (Kipf and Welling, 2017; Gilmer et al., 2017; Veli\u010dkovi\u0107 et al., 2018). Extensions include edge-conditioned convolutions, higher-order structures, and equivariant networks for 3D geometries (Simonovsky and Komodakis, 2017; Batzner et al., 2022).\n\nPretraining strategies on large unlabeled molecule corpora with contrastive or masked node prediction objectives have further improved generalization, especially in low-data regimes (Hu et al., 2020; Rong et al., 2020).\nIntroduction\n\nAutomated analysis of pathology whole-slide images (WSIs) faces extreme resolution, sparse lesion patterns, and distribution shifts across scanners and staining protocols. Convolutional networks have advanced the field but can be limited in modeling long-range dependencies over gigapixel slides.\n\nVision Transformers have been applied to medical image classification, segmentation, and detection with pure transformer backbones or hybrid CNN\u2013Transformer designs (Dosovitskiy et al., 2020; Chen et al., 2021; Hatamizadeh et al., 2022; Wang et al., 2021; Xie et al., 2021).\n\nWeakly supervised multiple-instance learning (MIL) further alleviates slide-level labeling costs by aggregating patch evidence, yet attention pooling can overfit to spurious correlations. We investigate whether token-level sparsification combined with instance reweighting can improve robustness in cross-site evaluation.\n\nOur method introduces a curriculum-sparse token selection and slide-consistent calibration loss to stabilize attention under domain shift. On three WSI benchmarks spanning different scanners, we observe gains in AUC and improved calibration, with minimal added compute.\n\nWe conduct ablations on sparsity schedules and release pretrained weights for community use.\nRelated Work\n\nRemote sensing change detection relies on robust representations that separate illumination and seasonal effects from structural changes. Recent advances in high-resolution satellites have shifted attention to fine-grained, building-level change cues.\n\nClassical two-stream CNNs, Siamese architectures, and attention-based models have been widely adopted for change detection (Daudt et al., 2018; Fang et al., 2020; Chen et al., 2021). Large-scale datasets such as LEVIR-CD, CDD, and WHU-CD have enabled benchmarking across urban scenes (Levir et al., 2020; Wang et al., 2020; Ji et al., 2019). Transformer-based encoders further improve long-range modeling (Ban et al., 2021; Liu et al., 2021).\n\nWhile these efforts improve accuracy, they largely assume perfectly registered image pairs and abundant labels. Our work targets label-scarce scenarios with misalignment by learning registration-aware tokens that disentangle geometry from appearance.\nIntroduction\n\nEffective human-robot collaboration requires balancing adaptability to user intent with guarantees on safety and task efficiency. Real-world deployments must operate under partial observability and distribution shifts in user behavior.\n\nShared autonomy techniques span predictive user intent modeling, POMDP-based assistance, arbitration policies that blend human and robot commands, and learning from demonstration for collaborative tasks (Dragan and Srinivasa, 2013; Javdani et al., 2015; Reddy et al., 2018; Losey et al., 2020).\n\nWe propose CertAssist, a certifiably safe shared autonomy framework combining control barrier functions with belief-dependent arbitration, evaluated on manipulation and navigation tasks with human participants.\nIntroduction\nAccurate forecasting underpins decision-making in supply chains, energy, and finance. Models must balance bias-variance trade-offs, handle sparse covariates, and remain robust to nonstationary shifts and irregular sampling.\n\nClassical time series forecasting relies on ARIMA and exponential smoothing to model linear dependencies (Box and Jenkins, 1970; Hyndman et al., 2008). Neural models introduce nonlinearity via RNNs, LSTMs, and temporal convolutions (Hochreiter and Schmidhuber, 1997; Bai et al., 2018). Transformer-based forecasters use attention to capture long-range dependencies (Li et al., 2019; Zhou et al., 2021). Decomposition and frequency-domain methods further reduce complexity and highlight seasonal structure (Oreshkin et al., 2020; Wu et al., 2021).\n\nWe present an uncertainty-aware spectral transformer that couples learnable seasonal kernels with interval calibration, yielding improved accuracy and coverage under regime shifts in retail and traffic datasets.\nRelated Work\n\nControllable text generation seeks to guide large language models (LLMs) toward specified attributes with minimal task-specific supervision. Recent approaches either modify inputs via prompts or adjust model parameters through lightweight adapters.\n\nPrompt-based methods for steering pre-trained language models have been explored in a variety of settings. Discrete prompt mining identifies trigger tokens that elicit desired behavior (Kim and Park, 2020; Zhou et al., 2021). Continuous prompt tuning replaces hard prompts with trainable embeddings (Li and Sung, 2021; Qin et al., 2022). Instruction following with few-shot exemplars has also been shown to improve task transfer (Rao and Lin, 2021; Xu et al., 2022).\n\nAdapter-based control introduces small task-specific modules into frozen backbones, enabling multi-task training while limiting memory costs (Chen et al., 2021; Gupta and Lee, 2022). Other lines include decoding constraints (He and Zhao, 2020) and classifier-guided re-ranking (Sharma et al., 2021).\n\nIn parallel, evaluation protocols for controllability measure attribute accuracy, content preservation, and fluency (Liu et al., 2020; Feng and Ma, 2021).\n",
        "completion": "Prompt-based methods for steering pre-trained language models have been explored in a variety of settings. Discrete prompt mining identifies trigger tokens that elicit desired behavior (Kim and Park, 2020; Zhou et al., 2021). Continuous prompt tuning replaces hard prompts with trainable embeddings (Li and Sung, 2021; Qin et al., 2022). Instruction following with few-shot exemplars has also been shown to improve task transfer (Rao and Lin, 2021; Xu et al., 2022)."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        occurs when either:\n    a) The author describes or cites papers without connecting them to their own work/argument \n    b) Or only follows up the summary of previous works with their own contribution without explicitly highlighting the gap their work intends to research.\n    c) It does not articulate the author's perspective or motivation.\n    d) A lack of argument/opinion in the first paragraph is permissible as it serves to be the foundation of the author's argument \n    e) Lacks synthesis issues appear either as single sentences or multiple sentences.\n    Examples of lack of synthesis include:\n        i) No elaboration of own contribution/argument:\"Following early neural approaches to question answering, many subsequent studies adopt a pipeline architecture consisting of retrieval and comprehension components. The retrieval component focuses on identifying relevant documents or passages from a large corpus, while the comprehension component extracts an answer span from the retrieved text. Initial models relied on recurrent neural networks with attention mechanisms to encode questions and contexts (Seo et al., 2017; Wang et al., 2017).\"\n        ii)  No explanation of the cited works and relation to their own work: \u201cRecently, several studies have explored the use of prompting techniques with pre-trained language models to influence model outputs or access latent knowledge (Brown et al., 2020; Gao et al., 2021; Liu et al., 2021; Wei et al., 2022).\u201d \n\n        Example text: \n        Related Work\n\nDevelopers rely on code search to find relevant snippets, APIs, or examples. Unlike general document retrieval, code search must bridge natural language intent and program structure.\n\nNeural code search has been addressed with bi-encoders, cross-encoders, and dual learning (Gu et al., 2018; Husain et al., 2019; Feng et al., 2020). Structural representations incorporate ASTs, control flow, and data flow (Alon et al., 2019; Wang et al., 2020; Liu et al., 2021). Pretraining on code and NL improves retrieval metrics across languages (Ahmad et al., 2021; Guo et al., 2021).\n\nIn this paper, we introduce a language-agnostic retriever with compositional queries.\n\nWe evaluate zero-shot transfer across four programming languages.\nIntroduction\n\nGeneralization in text classification can be improved with data augmentation, especially when labeled data are scarce or imbalanced. Approaches range from rule-based edits to model-driven paraphrasing and representation-space mixing.\n\nText augmentation techniques include synonym replacement, random insertion/deletion, back-translation, paraphrase generation, and mixup in embedding or hidden spaces (Wei and Zou, 2019; Sennrich et al., 2016; Kobayashi, 2018; Guo et al., 2020). Recent work explores task-adaptive augmentation policies learned by reinforcement learning (Xie et al., 2020).\n\nEvaluation typically considers robustness to domain shift, label noise, and distributional skew across multiple benchmarks (Pruksachatkun et al., 2020; Hendrycks et al., 2020).\nRelated Work\n\nKnowledge graph completion predicts missing links by learning entity and relation representations. Methods vary in how they encode semantics and handle patterns like symmetry, hierarchy, and composition.\n\nTranslation-based knowledge graph embeddings model relations as translations in vector space (Bordes et al., 2013; Wang et al., 2014), while bilinear and neural models capture more complex interactions (Nickel et al., 2011; Trouillon et al., 2016; Sun et al., 2019). Regularization and rule-guided approaches improve inductive bias and data efficiency (Rockt\u00e4schel et al., 2015; Minervini et al., 2017).\n\nWe introduce a lightweight compositional constraint for hierarchical relations and evaluate on three benchmarks and an industry dataset.\nRelated Work\n\nEnsuring safety during reinforcement learning is critical in real-world control where violations can be costly. Research has proposed both objective-level and mechanism-level solutions.\n\nSafe reinforcement learning approaches include risk-sensitive objectives such as CVaR optimization (Tamar et al., 2015; Chow et al., 2018), constrained policy optimization with safety budgets (Achiam et al., 2017; Yang et al., 2020), and shielding based on model-checking or supervisors (Alshiekh et al., 2018; Dalal et al., 2018). We develop a method that integrates model-predictive constraints with policy gradients.\n\nBenchmarks often evaluate safety in simulated robotics or navigation with cost functions approximating constraint violations (Ray et al., 2019; Bharadhwaj et al., 2021).\nRelated Work\n\nDialog state tracking (DST) has evolved from rule-based slot filling to neural architectures that jointly infer belief states across turns. Early pipeline models used hand-crafted lexicons and semantic frames (Singh and Patel, 2015), but suffered from brittleness to paraphrase and noise. Neural encoders introduced robustness by contextualizing utterances, incorporating attention over dialog history, and modeling slot-value dependencies (Lee et al., 2018; Choe and Kim, 2019).\n\nPretrained language models have further shifted the landscape by enabling few-shot generalization and open-vocabulary slot values. Fine-tuning BERT-like encoders for DST improved cross-domain transfer (Rao et al., 2020), while generative formulations cast state tracking as text-to-text prediction (Mendez et al., 2021).\n\nPrompting-based approaches have also been explored for dialog modeling (Kumar et al., 2021; Ortega and Lin, 2022; Park et al., 2023). These methods condition large language models on task instructions or few-shot exemplars to elicit latent conversational knowledge. Recent variants incorporate calibration or self-consistency to stabilize outputs (Fang et al., 2023; Zhou et al., 2023).\n\nPosition relative to this paper While we also employ pretrained sequence-to-sequence models, our focus is on handling ontology drift in long-running deployments. Specifically, we introduce an adaptive slot schema encoder that aligns evolving taxonomies with dialog evidence, and a contrastive consistency objective to mitigate spurious slot co-activations across domains.\nIntroduction\n\nSelf-supervised learning (SSL) has become the dominant paradigm for learning transferable visual features without labels. By constructing pretext tasks that expose invariances and structure inherent in data, SSL models can match or surpass supervised baselines on many downstream tasks.\n\nContrastive pretraining has been widely adopted for visual representations (Chen et al., 2020; He et al., 2020; Xie and Xu, 2021). Non-contrastive methods remove negative pairs and rely on architectural or objective asymmetries (Grill et al., 2020; Tian et al., 2021). Clustering-based methods jointly learn assignments and embeddings (Caron et al., 2018; Li and Gao, 2022).\n\nDespite these advances, industrial applications often operate under strict memory budgets and latency constraints. In this paper, we investigate compute-aware pretraining objectives that couple multi-crop augmentation with a token-subsampled backbone. We present a latency-regularized alignment loss that preserves downstream accuracy while reducing FLOPs during both pretraining and fine-tuning.\nIntroduction\n\nEfficient exploration remains a central challenge in reinforcement learning (RL), particularly in sparse-reward environments where naive strategies fail to discover rewarding states. Over-exploration, however, can waste samples and destabilize learning.\n\nExploration in reinforcement learning has been advanced by count-based bonuses, intrinsic motivation, curiosity-driven prediction error, and information-theoretic objectives (Bellemare et al., 2016; Pathak et al., 2017; Houthooft et al., 2016; Burda et al., 2019; Ta\u00efga et al., 2020).\n\nYet, when environment dynamics change over time, stale novelty estimates can encourage revisiting obsolete states. We propose a recency-aware intrinsic reward that discounts outdated novelty and couples it with conservative policy updates.\n\nAcross Atari and continuous-control domains with drifting dynamics, our method achieves superior sample efficiency and stability, and ablations confirm the role of recency in balancing exploration and exploitation.\nRelated Work\n\nDetecting anomalies in multivariate time series is vital for monitoring industrial systems and cloud services. The challenge lies in handling seasonality, rare events, and inter-variable dependencies.\n\nClassical anomaly detection leverages ARIMA residual tests, STL decomposition, and control charts, while deep methods introduce autoencoders, VAEs, GANs, LSTMs, and Transformers for reconstruction or prediction errors (Tsay, 2010; Malhotra et al., 2015; An and Cho, 2015; Li et al., 2019; Xu et al., 2021).\n\nWe present Contrastive Forecasting with Graph Priors (CFGP), which learns structure-aware representations via self-supervised objectives and uses calibrated predictive intervals to flag anomalies.\nIntroduction\n\nGeneralizing manipulation skills across objects, tasks, and environments remains a central challenge in robotics. Sparse rewards, safety constraints, and hardware variability complicate learning on physical systems. Recent work studies imitation learning, offline RL, and model-based control for dexterous manipulation (Rajeswaran et al., 2018; Lynch et al., 2020; Nagabandi et al., 2019; Ahn et al., 2022). Despite these advances, scaling data collection and ensuring sim-to-real transfer continue to be bottlenecks.\n\nWe explore a curriculum that interleaves skill discovery from teleoperation logs with conservative online updates, targeting stable improvements under limited interaction budgets.\nRelated Work\n\nConversational recommenders. Systems that interactively elicit user preferences can reduce cold-start and improve satisfaction (Sun and Zhang, 2018). Dialog policy learning for conversational recommendation has explored supervised learning, reinforcement learning, and bandit methods (Christakopoulou et al., 2016; Lei et al., 2020; Chen et al., 2019). User simulators and counterfactual logging have been proposed to address data scarcity and evaluation challenges (Li et al., 2017; Chi et al., 2020).\n\nOur study investigates preference drift over long-horizon sessions and proposes a state representation that explicitly tracks uncertainty and recency effects.\nIntroduction\n\nExplainable AI (XAI) is increasingly required for medical imaging systems used in screening and triage. Beyond predictive accuracy, clinicians demand transparency about what image features drive automated decisions and whether explanations are stable under shifts.\n\nPost-hoc attribution methods like Grad-CAM and Integrated Gradients highlight salient regions (Selvaraju et al., 2017; Sundararajan et al., 2017). Prototype- and concept-based explanations enhance interpretability (Chen et al., 2019; Kim et al., 2018). Counterfactual generation has been explored for medical images (Chang et al., 2018; Singla et al., 2021).\n\nWe focus on faithfulness under distribution shift and propose an evaluation protocol that aligns explanation stability with clinical acceptance thresholds for screening workflows.\nRelated Work\n\nProviding timely, actionable feedback at scale is central to computing education. Traditional approaches combine instructor-designed rubrics with automated tests, but coverage and specificity can be limited for diverse student solutions.\n\nAutomated feedback for programming assignments has been tackled with static analysis, dynamic test generation, and pattern mining (Ke et al., 2016; Gulwani et al., 2018; Singh et al., 2013). Recent NLP-based systems leverage code embeddings, sequence models, and pretrained language models (Allamanis et al., 2018; Feng et al., 2020; Ahmad et al., 2021). Peer learning platforms collect hints and exemplars to guide novice programmers (Piech et al., 2015; Wang et al., 2018).\n\nWhile data-driven approaches show promise, they often struggle with generalizing across tasks and providing pedagogically aligned guidance. Our work investigates structure-aware hint generation that aligns feedback to conceptual steps in problem-solving.\nRelated Work\n\nReinforcement learning (RL) has enabled robots to acquire complex behaviors directly from interaction. However, data hunger, safety, and sim-to-real transfer remain persistent obstacles for deployment in real-world settings.\n\nModel-free methods such as DDPG (Lillicrap et al., 2016), SAC (Haarnoja et al., 2018), and PPO (Schulman et al., 2017) have been widely adopted for continuous control, while model-based approaches leverage learned dynamics for sample efficiency (Deisenroth and Rasmussen, 2011; Chua et al., 2018). Recent lines of work explore offline RL (Levine et al., 2020; Kumar et al., 2020) and representation learning for policy generalization (Laskin et al., 2020; Yarats et al., 2021). Domain randomization and adaptation seek to bridge the sim-to-real gap (Tobin et al., 2017; Peng et al., 2018).\n\nWe propose a training strategy that combines curriculum learning with uncertainty-aware policy updates to improve safety and sample efficiency in robotic manipulation.\nRelated Work\n\nAutomatic speech recognition (ASR) systems increasingly rely on large encoder\u2013decoder architectures that are costly to deploy on edge devices. Knowledge distillation (KD) is a common strategy to reduce model size while preserving accuracy.\n\nKnowledge distillation for speech recognition has considered frame-level supervision, sequence-level criteria, and wordpiece distributions, transferring knowledge from stronger teachers to smaller students (Hinton et al., 2015; Kim and Rush, 2016; Kurata and Audhkhasi, 2018; Higuchi et al., 2021).\n\nOther compression techniques include quantization and pruning, which can be combined with KD but may degrade robustness to noise and speaker variability. Recent work explores multi-teacher ensembles and intermediate-layer matching to stabilize training.\n\nIn this paper, we study streaming-constrained KD with latency-aware targets, aligning teacher and student under causal masking. Our experiments on LibriSpeech and far-field corpora show improved WER\u2013latency trade-offs compared to strong baselines.\nRelated Work\n\nLarge Language Models and Prompting\nLarge language models (LLMs) exhibit emergent program synthesis capabilities when conditioned on natural language instructions and a handful of examples. While these behaviors reduce reliance on supervised datasets, the mechanisms by which prompts control generation remain only partially understood. Prior studies analyze calibration, decoding strategies, and context length effects.\n\nPrompting for Code Generation\nPrompting for code generation has explored zero-shot, few-shot, and chain-of-thought styles using large language models (Chen et al., 2021; Austin et al., 2021; Nijkamp et al., 2022; Li et al., 2023). Work on compiler-aware prompting adds execution feedback to steer generation (Liu et al., 2022; Le et al., 2022; Wang et al., 2023). Program repair and test-driven synthesis have similarly adapted prompting strategies to satisfy unit tests (Jain et al., 2022; Zhang et al., 2023).\n\nExecution-Conditioned Decoding\nBeyond static prompts, execution-conditioned decoding iteratively runs partial programs to reduce search space. Studies report gains on algorithmic problems by interleaving generation and verification under timeouts and sandboxing constraints.\n\nStructured Constraints and Type Guidance\nApproaches that inject grammar constraints or type information restrict invalid outputs and improve pass rates. These methods range from constrained beam search to type-state automata.\n\nPositioning\nWe examine the interaction between prompt structure and execution feedback and study how typed constraints alter search dynamics under limited budgets.\nRelated Work\n\nFederated learning (FL) enables on-device training with privacy and communication constraints. Ensuring rigorous privacy guarantees while preserving model utility remains a core challenge.\n\nPrivacy in federated learning has been studied via differential privacy at the client level, secure aggregation, and shuffling (McMahan et al., 2017; Kairouz et al., 2021; Bonawitz et al., 2017; Erlingsson et al., 2019). Gradient perturbation, clipping, and client subsampling are common techniques to control privacy loss (Abadi et al., 2016; Thakkar et al., 2019; Andrew et al., 2021). Auditing methods estimate empirical privacy leakage post hoc (Nasr et al., 2019; Jagielski et al., 2020).\n\nOur approach introduces client-adaptive noise schedules conditioned on participation frequency.\n\nWe empirically evaluate privacy-utility trade-offs across heterogeneous client populations.\nIntroduction\n\nInformation retrieval has shifted from lexical term matching to semantic representations that capture contextual meaning. This shift enables better recall of paraphrased content but introduces new challenges in index efficiency and training stability.\n\nNeural semantic search methods combine dual-encoders for efficient retrieval (Yao et al., 2019; Xie and Zhao, 2020) with cross-encoders for reranking (Nogueira and Cho, 2019; Li et al., 2021), and leverage hard-negative mining to improve discriminative power (Gao et al., 2021; Huang et al., 2022). Recent work also explores domain adaptation for specialized corpora such as legal and biomedical texts (Park et al., 2022; Sun et al., 2023).\n\nWe study lightweight domain adaptation under tight indexing budgets.\nRelated Work\n\nDetecting anomalies in time-series is a long-standing problem with applications in monitoring, finance, and industrial IoT. Methods vary widely in assumptions, supervision requirements, and scalability.\n\nTime-series anomaly detection spans classical statistical tests, isolation-based methods, and deep learning models such as autoencoders, temporal convolutional networks, and Transformers (Gupta et al., 2014; Liu et al., 2008; Malhotra et al., 2016; Xu et al., 2020). Synthetic anomaly injection and semi-supervised training are also common practices (Zhang et al., 2019; Shen et al., 2021).\n\nBenchmarking efforts have sought consistent evaluation protocols across datasets with different anomaly types and frequencies (Hundman et al., 2018; Wu and Keogh, 2021).\nRelated Work\n\nPredicting molecular properties from structure has catalyzed a broad literature at the intersection of cheminformatics and geometric deep learning. Approaches differ in how they encode graph topology, chemical attributes, and geometric constraints.\n\nGraph representation learning methods such as spectral GCNs, spatial message passing networks, and attention-based GNNs have been widely applied to molecular property prediction (Kipf and Welling, 2017; Gilmer et al., 2017; Veli\u010dkovi\u0107 et al., 2018). Extensions include edge-conditioned convolutions, higher-order structures, and equivariant networks for 3D geometries (Simonovsky and Komodakis, 2017; Batzner et al., 2022).\n\nPretraining strategies on large unlabeled molecule corpora with contrastive or masked node prediction objectives have further improved generalization, especially in low-data regimes (Hu et al., 2020; Rong et al., 2020).\nIntroduction\n\nAutomated analysis of pathology whole-slide images (WSIs) faces extreme resolution, sparse lesion patterns, and distribution shifts across scanners and staining protocols. Convolutional networks have advanced the field but can be limited in modeling long-range dependencies over gigapixel slides.\n\nVision Transformers have been applied to medical image classification, segmentation, and detection with pure transformer backbones or hybrid CNN\u2013Transformer designs (Dosovitskiy et al., 2020; Chen et al., 2021; Hatamizadeh et al., 2022; Wang et al., 2021; Xie et al., 2021).\n\nWeakly supervised multiple-instance learning (MIL) further alleviates slide-level labeling costs by aggregating patch evidence, yet attention pooling can overfit to spurious correlations. We investigate whether token-level sparsification combined with instance reweighting can improve robustness in cross-site evaluation.\n\nOur method introduces a curriculum-sparse token selection and slide-consistent calibration loss to stabilize attention under domain shift. On three WSI benchmarks spanning different scanners, we observe gains in AUC and improved calibration, with minimal added compute.\n\nWe conduct ablations on sparsity schedules and release pretrained weights for community use.\nRelated Work\n\nRemote sensing change detection relies on robust representations that separate illumination and seasonal effects from structural changes. Recent advances in high-resolution satellites have shifted attention to fine-grained, building-level change cues.\n\nClassical two-stream CNNs, Siamese architectures, and attention-based models have been widely adopted for change detection (Daudt et al., 2018; Fang et al., 2020; Chen et al., 2021). Large-scale datasets such as LEVIR-CD, CDD, and WHU-CD have enabled benchmarking across urban scenes (Levir et al., 2020; Wang et al., 2020; Ji et al., 2019). Transformer-based encoders further improve long-range modeling (Ban et al., 2021; Liu et al., 2021).\n\nWhile these efforts improve accuracy, they largely assume perfectly registered image pairs and abundant labels. Our work targets label-scarce scenarios with misalignment by learning registration-aware tokens that disentangle geometry from appearance.\nIntroduction\n\nEffective human-robot collaboration requires balancing adaptability to user intent with guarantees on safety and task efficiency. Real-world deployments must operate under partial observability and distribution shifts in user behavior.\n\nShared autonomy techniques span predictive user intent modeling, POMDP-based assistance, arbitration policies that blend human and robot commands, and learning from demonstration for collaborative tasks (Dragan and Srinivasa, 2013; Javdani et al., 2015; Reddy et al., 2018; Losey et al., 2020).\n\nWe propose CertAssist, a certifiably safe shared autonomy framework combining control barrier functions with belief-dependent arbitration, evaluated on manipulation and navigation tasks with human participants.\nIntroduction\nAccurate forecasting underpins decision-making in supply chains, energy, and finance. Models must balance bias-variance trade-offs, handle sparse covariates, and remain robust to nonstationary shifts and irregular sampling.\n\nClassical time series forecasting relies on ARIMA and exponential smoothing to model linear dependencies (Box and Jenkins, 1970; Hyndman et al., 2008). Neural models introduce nonlinearity via RNNs, LSTMs, and temporal convolutions (Hochreiter and Schmidhuber, 1997; Bai et al., 2018). Transformer-based forecasters use attention to capture long-range dependencies (Li et al., 2019; Zhou et al., 2021). Decomposition and frequency-domain methods further reduce complexity and highlight seasonal structure (Oreshkin et al., 2020; Wu et al., 2021).\n\nWe present an uncertainty-aware spectral transformer that couples learnable seasonal kernels with interval calibration, yielding improved accuracy and coverage under regime shifts in retail and traffic datasets.\nRelated Work\n\nControllable text generation seeks to guide large language models (LLMs) toward specified attributes with minimal task-specific supervision. Recent approaches either modify inputs via prompts or adjust model parameters through lightweight adapters.\n\nPrompt-based methods for steering pre-trained language models have been explored in a variety of settings. Discrete prompt mining identifies trigger tokens that elicit desired behavior (Kim and Park, 2020; Zhou et al., 2021). Continuous prompt tuning replaces hard prompts with trainable embeddings (Li and Sung, 2021; Qin et al., 2022). Instruction following with few-shot exemplars has also been shown to improve task transfer (Rao and Lin, 2021; Xu et al., 2022).\n\nAdapter-based control introduces small task-specific modules into frozen backbones, enabling multi-task training while limiting memory costs (Chen et al., 2021; Gupta and Lee, 2022). Other lines include decoding constraints (He and Zhao, 2020) and classifier-guided re-ranking (Sharma et al., 2021).\n\nIn parallel, evaluation protocols for controllability measure attribute accuracy, content preservation, and fluency (Liu et al., 2020; Feng and Ma, 2021).\nRelated Work\n\nFederated learning enables collaborative training across a population of devices while keeping raw data local. The distributed setting raises new challenges in privacy, robustness, and communication efficiency.\n\nPrivacy in federated learning has been studied through differential privacy mechanisms for client updates (Abadi et al., 2016; McMahan et al., 2018), secure aggregation protocols to hide individual contributions (Bonawitz et al., 2017), split learning to keep raw data on-device (Gupta and Raskar, 2018), and cryptographic techniques like homomorphic encryption and MPC (Gentry, 2009; Mohassel and Zhang, 2017). Communication reduction has been addressed via sparsification and quantization (Stich et al., 2018; Kone\u010dn\u00fd et al., 2016).\n\nOur method jointly optimizes privacy noise allocation and gradient compression schedules under a fixed bandwidth budget.\n",
        "completion": "Privacy in federated learning has been studied through differential privacy mechanisms for client updates (Abadi et al., 2016; McMahan et al., 2018), secure aggregation protocols to hide individual contributions (Bonawitz et al., 2017), split learning to keep raw data on-device (Gupta and Raskar, 2018), and cryptographic techniques like homomorphic encryption and MPC (Gentry, 2009; Mohassel and Zhang, 2017). Communication reduction has been addressed via sparsification and quantization (Stich et al., 2018; Kone\u010dn\u00fd et al., 2016)."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        occurs when either:\n    a) The author describes or cites papers without connecting them to their own work/argument \n    b) Or only follows up the summary of previous works with their own contribution without explicitly highlighting the gap their work intends to research.\n    c) It does not articulate the author's perspective or motivation.\n    d) A lack of argument/opinion in the first paragraph is permissible as it serves to be the foundation of the author's argument \n    e) Lacks synthesis issues appear either as single sentences or multiple sentences.\n    Examples of lack of synthesis include:\n        i) No elaboration of own contribution/argument:\"Following early neural approaches to question answering, many subsequent studies adopt a pipeline architecture consisting of retrieval and comprehension components. The retrieval component focuses on identifying relevant documents or passages from a large corpus, while the comprehension component extracts an answer span from the retrieved text. Initial models relied on recurrent neural networks with attention mechanisms to encode questions and contexts (Seo et al., 2017; Wang et al., 2017).\"\n        ii)  No explanation of the cited works and relation to their own work: \u201cRecently, several studies have explored the use of prompting techniques with pre-trained language models to influence model outputs or access latent knowledge (Brown et al., 2020; Gao et al., 2021; Liu et al., 2021; Wei et al., 2022).\u201d \n\n        Example text: \n        Related Work\n\nDevelopers rely on code search to find relevant snippets, APIs, or examples. Unlike general document retrieval, code search must bridge natural language intent and program structure.\n\nNeural code search has been addressed with bi-encoders, cross-encoders, and dual learning (Gu et al., 2018; Husain et al., 2019; Feng et al., 2020). Structural representations incorporate ASTs, control flow, and data flow (Alon et al., 2019; Wang et al., 2020; Liu et al., 2021). Pretraining on code and NL improves retrieval metrics across languages (Ahmad et al., 2021; Guo et al., 2021).\n\nIn this paper, we introduce a language-agnostic retriever with compositional queries.\n\nWe evaluate zero-shot transfer across four programming languages.\nIntroduction\n\nGeneralization in text classification can be improved with data augmentation, especially when labeled data are scarce or imbalanced. Approaches range from rule-based edits to model-driven paraphrasing and representation-space mixing.\n\nText augmentation techniques include synonym replacement, random insertion/deletion, back-translation, paraphrase generation, and mixup in embedding or hidden spaces (Wei and Zou, 2019; Sennrich et al., 2016; Kobayashi, 2018; Guo et al., 2020). Recent work explores task-adaptive augmentation policies learned by reinforcement learning (Xie et al., 2020).\n\nEvaluation typically considers robustness to domain shift, label noise, and distributional skew across multiple benchmarks (Pruksachatkun et al., 2020; Hendrycks et al., 2020).\nRelated Work\n\nKnowledge graph completion predicts missing links by learning entity and relation representations. Methods vary in how they encode semantics and handle patterns like symmetry, hierarchy, and composition.\n\nTranslation-based knowledge graph embeddings model relations as translations in vector space (Bordes et al., 2013; Wang et al., 2014), while bilinear and neural models capture more complex interactions (Nickel et al., 2011; Trouillon et al., 2016; Sun et al., 2019). Regularization and rule-guided approaches improve inductive bias and data efficiency (Rockt\u00e4schel et al., 2015; Minervini et al., 2017).\n\nWe introduce a lightweight compositional constraint for hierarchical relations and evaluate on three benchmarks and an industry dataset.\nRelated Work\n\nEnsuring safety during reinforcement learning is critical in real-world control where violations can be costly. Research has proposed both objective-level and mechanism-level solutions.\n\nSafe reinforcement learning approaches include risk-sensitive objectives such as CVaR optimization (Tamar et al., 2015; Chow et al., 2018), constrained policy optimization with safety budgets (Achiam et al., 2017; Yang et al., 2020), and shielding based on model-checking or supervisors (Alshiekh et al., 2018; Dalal et al., 2018). We develop a method that integrates model-predictive constraints with policy gradients.\n\nBenchmarks often evaluate safety in simulated robotics or navigation with cost functions approximating constraint violations (Ray et al., 2019; Bharadhwaj et al., 2021).\nRelated Work\n\nDialog state tracking (DST) has evolved from rule-based slot filling to neural architectures that jointly infer belief states across turns. Early pipeline models used hand-crafted lexicons and semantic frames (Singh and Patel, 2015), but suffered from brittleness to paraphrase and noise. Neural encoders introduced robustness by contextualizing utterances, incorporating attention over dialog history, and modeling slot-value dependencies (Lee et al., 2018; Choe and Kim, 2019).\n\nPretrained language models have further shifted the landscape by enabling few-shot generalization and open-vocabulary slot values. Fine-tuning BERT-like encoders for DST improved cross-domain transfer (Rao et al., 2020), while generative formulations cast state tracking as text-to-text prediction (Mendez et al., 2021).\n\nPrompting-based approaches have also been explored for dialog modeling (Kumar et al., 2021; Ortega and Lin, 2022; Park et al., 2023). These methods condition large language models on task instructions or few-shot exemplars to elicit latent conversational knowledge. Recent variants incorporate calibration or self-consistency to stabilize outputs (Fang et al., 2023; Zhou et al., 2023).\n\nPosition relative to this paper While we also employ pretrained sequence-to-sequence models, our focus is on handling ontology drift in long-running deployments. Specifically, we introduce an adaptive slot schema encoder that aligns evolving taxonomies with dialog evidence, and a contrastive consistency objective to mitigate spurious slot co-activations across domains.\nIntroduction\n\nSelf-supervised learning (SSL) has become the dominant paradigm for learning transferable visual features without labels. By constructing pretext tasks that expose invariances and structure inherent in data, SSL models can match or surpass supervised baselines on many downstream tasks.\n\nContrastive pretraining has been widely adopted for visual representations (Chen et al., 2020; He et al., 2020; Xie and Xu, 2021). Non-contrastive methods remove negative pairs and rely on architectural or objective asymmetries (Grill et al., 2020; Tian et al., 2021). Clustering-based methods jointly learn assignments and embeddings (Caron et al., 2018; Li and Gao, 2022).\n\nDespite these advances, industrial applications often operate under strict memory budgets and latency constraints. In this paper, we investigate compute-aware pretraining objectives that couple multi-crop augmentation with a token-subsampled backbone. We present a latency-regularized alignment loss that preserves downstream accuracy while reducing FLOPs during both pretraining and fine-tuning.\nIntroduction\n\nEfficient exploration remains a central challenge in reinforcement learning (RL), particularly in sparse-reward environments where naive strategies fail to discover rewarding states. Over-exploration, however, can waste samples and destabilize learning.\n\nExploration in reinforcement learning has been advanced by count-based bonuses, intrinsic motivation, curiosity-driven prediction error, and information-theoretic objectives (Bellemare et al., 2016; Pathak et al., 2017; Houthooft et al., 2016; Burda et al., 2019; Ta\u00efga et al., 2020).\n\nYet, when environment dynamics change over time, stale novelty estimates can encourage revisiting obsolete states. We propose a recency-aware intrinsic reward that discounts outdated novelty and couples it with conservative policy updates.\n\nAcross Atari and continuous-control domains with drifting dynamics, our method achieves superior sample efficiency and stability, and ablations confirm the role of recency in balancing exploration and exploitation.\nRelated Work\n\nDetecting anomalies in multivariate time series is vital for monitoring industrial systems and cloud services. The challenge lies in handling seasonality, rare events, and inter-variable dependencies.\n\nClassical anomaly detection leverages ARIMA residual tests, STL decomposition, and control charts, while deep methods introduce autoencoders, VAEs, GANs, LSTMs, and Transformers for reconstruction or prediction errors (Tsay, 2010; Malhotra et al., 2015; An and Cho, 2015; Li et al., 2019; Xu et al., 2021).\n\nWe present Contrastive Forecasting with Graph Priors (CFGP), which learns structure-aware representations via self-supervised objectives and uses calibrated predictive intervals to flag anomalies.\nIntroduction\n\nGeneralizing manipulation skills across objects, tasks, and environments remains a central challenge in robotics. Sparse rewards, safety constraints, and hardware variability complicate learning on physical systems. Recent work studies imitation learning, offline RL, and model-based control for dexterous manipulation (Rajeswaran et al., 2018; Lynch et al., 2020; Nagabandi et al., 2019; Ahn et al., 2022). Despite these advances, scaling data collection and ensuring sim-to-real transfer continue to be bottlenecks.\n\nWe explore a curriculum that interleaves skill discovery from teleoperation logs with conservative online updates, targeting stable improvements under limited interaction budgets.\nRelated Work\n\nConversational recommenders. Systems that interactively elicit user preferences can reduce cold-start and improve satisfaction (Sun and Zhang, 2018). Dialog policy learning for conversational recommendation has explored supervised learning, reinforcement learning, and bandit methods (Christakopoulou et al., 2016; Lei et al., 2020; Chen et al., 2019). User simulators and counterfactual logging have been proposed to address data scarcity and evaluation challenges (Li et al., 2017; Chi et al., 2020).\n\nOur study investigates preference drift over long-horizon sessions and proposes a state representation that explicitly tracks uncertainty and recency effects.\nIntroduction\n\nExplainable AI (XAI) is increasingly required for medical imaging systems used in screening and triage. Beyond predictive accuracy, clinicians demand transparency about what image features drive automated decisions and whether explanations are stable under shifts.\n\nPost-hoc attribution methods like Grad-CAM and Integrated Gradients highlight salient regions (Selvaraju et al., 2017; Sundararajan et al., 2017). Prototype- and concept-based explanations enhance interpretability (Chen et al., 2019; Kim et al., 2018). Counterfactual generation has been explored for medical images (Chang et al., 2018; Singla et al., 2021).\n\nWe focus on faithfulness under distribution shift and propose an evaluation protocol that aligns explanation stability with clinical acceptance thresholds for screening workflows.\nRelated Work\n\nProviding timely, actionable feedback at scale is central to computing education. Traditional approaches combine instructor-designed rubrics with automated tests, but coverage and specificity can be limited for diverse student solutions.\n\nAutomated feedback for programming assignments has been tackled with static analysis, dynamic test generation, and pattern mining (Ke et al., 2016; Gulwani et al., 2018; Singh et al., 2013). Recent NLP-based systems leverage code embeddings, sequence models, and pretrained language models (Allamanis et al., 2018; Feng et al., 2020; Ahmad et al., 2021). Peer learning platforms collect hints and exemplars to guide novice programmers (Piech et al., 2015; Wang et al., 2018).\n\nWhile data-driven approaches show promise, they often struggle with generalizing across tasks and providing pedagogically aligned guidance. Our work investigates structure-aware hint generation that aligns feedback to conceptual steps in problem-solving.\nRelated Work\n\nReinforcement learning (RL) has enabled robots to acquire complex behaviors directly from interaction. However, data hunger, safety, and sim-to-real transfer remain persistent obstacles for deployment in real-world settings.\n\nModel-free methods such as DDPG (Lillicrap et al., 2016), SAC (Haarnoja et al., 2018), and PPO (Schulman et al., 2017) have been widely adopted for continuous control, while model-based approaches leverage learned dynamics for sample efficiency (Deisenroth and Rasmussen, 2011; Chua et al., 2018). Recent lines of work explore offline RL (Levine et al., 2020; Kumar et al., 2020) and representation learning for policy generalization (Laskin et al., 2020; Yarats et al., 2021). Domain randomization and adaptation seek to bridge the sim-to-real gap (Tobin et al., 2017; Peng et al., 2018).\n\nWe propose a training strategy that combines curriculum learning with uncertainty-aware policy updates to improve safety and sample efficiency in robotic manipulation.\nRelated Work\n\nAutomatic speech recognition (ASR) systems increasingly rely on large encoder\u2013decoder architectures that are costly to deploy on edge devices. Knowledge distillation (KD) is a common strategy to reduce model size while preserving accuracy.\n\nKnowledge distillation for speech recognition has considered frame-level supervision, sequence-level criteria, and wordpiece distributions, transferring knowledge from stronger teachers to smaller students (Hinton et al., 2015; Kim and Rush, 2016; Kurata and Audhkhasi, 2018; Higuchi et al., 2021).\n\nOther compression techniques include quantization and pruning, which can be combined with KD but may degrade robustness to noise and speaker variability. Recent work explores multi-teacher ensembles and intermediate-layer matching to stabilize training.\n\nIn this paper, we study streaming-constrained KD with latency-aware targets, aligning teacher and student under causal masking. Our experiments on LibriSpeech and far-field corpora show improved WER\u2013latency trade-offs compared to strong baselines.\nRelated Work\n\nLarge Language Models and Prompting\nLarge language models (LLMs) exhibit emergent program synthesis capabilities when conditioned on natural language instructions and a handful of examples. While these behaviors reduce reliance on supervised datasets, the mechanisms by which prompts control generation remain only partially understood. Prior studies analyze calibration, decoding strategies, and context length effects.\n\nPrompting for Code Generation\nPrompting for code generation has explored zero-shot, few-shot, and chain-of-thought styles using large language models (Chen et al., 2021; Austin et al., 2021; Nijkamp et al., 2022; Li et al., 2023). Work on compiler-aware prompting adds execution feedback to steer generation (Liu et al., 2022; Le et al., 2022; Wang et al., 2023). Program repair and test-driven synthesis have similarly adapted prompting strategies to satisfy unit tests (Jain et al., 2022; Zhang et al., 2023).\n\nExecution-Conditioned Decoding\nBeyond static prompts, execution-conditioned decoding iteratively runs partial programs to reduce search space. Studies report gains on algorithmic problems by interleaving generation and verification under timeouts and sandboxing constraints.\n\nStructured Constraints and Type Guidance\nApproaches that inject grammar constraints or type information restrict invalid outputs and improve pass rates. These methods range from constrained beam search to type-state automata.\n\nPositioning\nWe examine the interaction between prompt structure and execution feedback and study how typed constraints alter search dynamics under limited budgets.\nRelated Work\n\nFederated learning (FL) enables on-device training with privacy and communication constraints. Ensuring rigorous privacy guarantees while preserving model utility remains a core challenge.\n\nPrivacy in federated learning has been studied via differential privacy at the client level, secure aggregation, and shuffling (McMahan et al., 2017; Kairouz et al., 2021; Bonawitz et al., 2017; Erlingsson et al., 2019). Gradient perturbation, clipping, and client subsampling are common techniques to control privacy loss (Abadi et al., 2016; Thakkar et al., 2019; Andrew et al., 2021). Auditing methods estimate empirical privacy leakage post hoc (Nasr et al., 2019; Jagielski et al., 2020).\n\nOur approach introduces client-adaptive noise schedules conditioned on participation frequency.\n\nWe empirically evaluate privacy-utility trade-offs across heterogeneous client populations.\nIntroduction\n\nInformation retrieval has shifted from lexical term matching to semantic representations that capture contextual meaning. This shift enables better recall of paraphrased content but introduces new challenges in index efficiency and training stability.\n\nNeural semantic search methods combine dual-encoders for efficient retrieval (Yao et al., 2019; Xie and Zhao, 2020) with cross-encoders for reranking (Nogueira and Cho, 2019; Li et al., 2021), and leverage hard-negative mining to improve discriminative power (Gao et al., 2021; Huang et al., 2022). Recent work also explores domain adaptation for specialized corpora such as legal and biomedical texts (Park et al., 2022; Sun et al., 2023).\n\nWe study lightweight domain adaptation under tight indexing budgets.\nRelated Work\n\nDetecting anomalies in time-series is a long-standing problem with applications in monitoring, finance, and industrial IoT. Methods vary widely in assumptions, supervision requirements, and scalability.\n\nTime-series anomaly detection spans classical statistical tests, isolation-based methods, and deep learning models such as autoencoders, temporal convolutional networks, and Transformers (Gupta et al., 2014; Liu et al., 2008; Malhotra et al., 2016; Xu et al., 2020). Synthetic anomaly injection and semi-supervised training are also common practices (Zhang et al., 2019; Shen et al., 2021).\n\nBenchmarking efforts have sought consistent evaluation protocols across datasets with different anomaly types and frequencies (Hundman et al., 2018; Wu and Keogh, 2021).\nRelated Work\n\nPredicting molecular properties from structure has catalyzed a broad literature at the intersection of cheminformatics and geometric deep learning. Approaches differ in how they encode graph topology, chemical attributes, and geometric constraints.\n\nGraph representation learning methods such as spectral GCNs, spatial message passing networks, and attention-based GNNs have been widely applied to molecular property prediction (Kipf and Welling, 2017; Gilmer et al., 2017; Veli\u010dkovi\u0107 et al., 2018). Extensions include edge-conditioned convolutions, higher-order structures, and equivariant networks for 3D geometries (Simonovsky and Komodakis, 2017; Batzner et al., 2022).\n\nPretraining strategies on large unlabeled molecule corpora with contrastive or masked node prediction objectives have further improved generalization, especially in low-data regimes (Hu et al., 2020; Rong et al., 2020).\nIntroduction\n\nAutomated analysis of pathology whole-slide images (WSIs) faces extreme resolution, sparse lesion patterns, and distribution shifts across scanners and staining protocols. Convolutional networks have advanced the field but can be limited in modeling long-range dependencies over gigapixel slides.\n\nVision Transformers have been applied to medical image classification, segmentation, and detection with pure transformer backbones or hybrid CNN\u2013Transformer designs (Dosovitskiy et al., 2020; Chen et al., 2021; Hatamizadeh et al., 2022; Wang et al., 2021; Xie et al., 2021).\n\nWeakly supervised multiple-instance learning (MIL) further alleviates slide-level labeling costs by aggregating patch evidence, yet attention pooling can overfit to spurious correlations. We investigate whether token-level sparsification combined with instance reweighting can improve robustness in cross-site evaluation.\n\nOur method introduces a curriculum-sparse token selection and slide-consistent calibration loss to stabilize attention under domain shift. On three WSI benchmarks spanning different scanners, we observe gains in AUC and improved calibration, with minimal added compute.\n\nWe conduct ablations on sparsity schedules and release pretrained weights for community use.\nRelated Work\n\nRemote sensing change detection relies on robust representations that separate illumination and seasonal effects from structural changes. Recent advances in high-resolution satellites have shifted attention to fine-grained, building-level change cues.\n\nClassical two-stream CNNs, Siamese architectures, and attention-based models have been widely adopted for change detection (Daudt et al., 2018; Fang et al., 2020; Chen et al., 2021). Large-scale datasets such as LEVIR-CD, CDD, and WHU-CD have enabled benchmarking across urban scenes (Levir et al., 2020; Wang et al., 2020; Ji et al., 2019). Transformer-based encoders further improve long-range modeling (Ban et al., 2021; Liu et al., 2021).\n\nWhile these efforts improve accuracy, they largely assume perfectly registered image pairs and abundant labels. Our work targets label-scarce scenarios with misalignment by learning registration-aware tokens that disentangle geometry from appearance.\nIntroduction\n\nEffective human-robot collaboration requires balancing adaptability to user intent with guarantees on safety and task efficiency. Real-world deployments must operate under partial observability and distribution shifts in user behavior.\n\nShared autonomy techniques span predictive user intent modeling, POMDP-based assistance, arbitration policies that blend human and robot commands, and learning from demonstration for collaborative tasks (Dragan and Srinivasa, 2013; Javdani et al., 2015; Reddy et al., 2018; Losey et al., 2020).\n\nWe propose CertAssist, a certifiably safe shared autonomy framework combining control barrier functions with belief-dependent arbitration, evaluated on manipulation and navigation tasks with human participants.\nIntroduction\nAccurate forecasting underpins decision-making in supply chains, energy, and finance. Models must balance bias-variance trade-offs, handle sparse covariates, and remain robust to nonstationary shifts and irregular sampling.\n\nClassical time series forecasting relies on ARIMA and exponential smoothing to model linear dependencies (Box and Jenkins, 1970; Hyndman et al., 2008). Neural models introduce nonlinearity via RNNs, LSTMs, and temporal convolutions (Hochreiter and Schmidhuber, 1997; Bai et al., 2018). Transformer-based forecasters use attention to capture long-range dependencies (Li et al., 2019; Zhou et al., 2021). Decomposition and frequency-domain methods further reduce complexity and highlight seasonal structure (Oreshkin et al., 2020; Wu et al., 2021).\n\nWe present an uncertainty-aware spectral transformer that couples learnable seasonal kernels with interval calibration, yielding improved accuracy and coverage under regime shifts in retail and traffic datasets.\nRelated Work\n\nControllable text generation seeks to guide large language models (LLMs) toward specified attributes with minimal task-specific supervision. Recent approaches either modify inputs via prompts or adjust model parameters through lightweight adapters.\n\nPrompt-based methods for steering pre-trained language models have been explored in a variety of settings. Discrete prompt mining identifies trigger tokens that elicit desired behavior (Kim and Park, 2020; Zhou et al., 2021). Continuous prompt tuning replaces hard prompts with trainable embeddings (Li and Sung, 2021; Qin et al., 2022). Instruction following with few-shot exemplars has also been shown to improve task transfer (Rao and Lin, 2021; Xu et al., 2022).\n\nAdapter-based control introduces small task-specific modules into frozen backbones, enabling multi-task training while limiting memory costs (Chen et al., 2021; Gupta and Lee, 2022). Other lines include decoding constraints (He and Zhao, 2020) and classifier-guided re-ranking (Sharma et al., 2021).\n\nIn parallel, evaluation protocols for controllability measure attribute accuracy, content preservation, and fluency (Liu et al., 2020; Feng and Ma, 2021).\nRelated Work\n\nFederated learning enables collaborative training across a population of devices while keeping raw data local. The distributed setting raises new challenges in privacy, robustness, and communication efficiency.\n\nPrivacy in federated learning has been studied through differential privacy mechanisms for client updates (Abadi et al., 2016; McMahan et al., 2018), secure aggregation protocols to hide individual contributions (Bonawitz et al., 2017), split learning to keep raw data on-device (Gupta and Raskar, 2018), and cryptographic techniques like homomorphic encryption and MPC (Gentry, 2009; Mohassel and Zhang, 2017). Communication reduction has been addressed via sparsification and quantization (Stich et al., 2018; Kone\u010dn\u00fd et al., 2016).\n\nOur method jointly optimizes privacy noise allocation and gradient compression schedules under a fixed bandwidth budget.\nIntroduction\n\nUrban congestion degrades mobility, increases emissions, and undermines economic productivity. Adaptive traffic signal control promises to improve throughput by tailoring signal plans to real-time conditions. Reinforcement learning offers a data-driven framework to learn such policies directly from interaction.\n\nClassical traffic signal control uses handcrafted rules and model-based optimization (Webster, 1958; Gartner, 1983). RL-based approaches apply tabular Q-learning, deep Q-networks, and policy gradients to learn adaptive strategies (Abdoos et al., 2013; Van der Pol and Oliehoek, 2016; Wei et al., 2018). Multi-agent methods coordinate intersections via shared critics or communication (Chu et al., 2019; Zang et al., 2020; Chen et al., 2020). In this work, we propose a hierarchical actor-critic that decomposes phase selection and duration control.\n\nWe validate our approach on synthetic and real-world networks, showing gains in average travel time and queue length.\n",
        "completion": "Classical traffic signal control uses handcrafted rules and model-based optimization (Webster, 1958; Gartner, 1983). RL-based approaches apply tabular Q-learning, deep Q-networks, and policy gradients to learn adaptive strategies (Abdoos et al., 2013; Van der Pol and Oliehoek, 2016; Wei et al., 2018). Multi-agent methods coordinate intersections via shared critics or communication (Chu et al., 2019; Zang et al., 2020; Chen et al., 2020). In this work, we propose a hierarchical actor-critic that decomposes phase selection and duration control."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        occurs when either:\n    a) The author describes or cites papers without connecting them to their own work/argument \n    b) Or only follows up the summary of previous works with their own contribution without explicitly highlighting the gap their work intends to research.\n    c) It does not articulate the author's perspective or motivation.\n    d) A lack of argument/opinion in the first paragraph is permissible as it serves to be the foundation of the author's argument \n    e) Lacks synthesis issues appear either as single sentences or multiple sentences.\n    Examples of lack of synthesis include:\n        i) No elaboration of own contribution/argument:\"Following early neural approaches to question answering, many subsequent studies adopt a pipeline architecture consisting of retrieval and comprehension components. The retrieval component focuses on identifying relevant documents or passages from a large corpus, while the comprehension component extracts an answer span from the retrieved text. Initial models relied on recurrent neural networks with attention mechanisms to encode questions and contexts (Seo et al., 2017; Wang et al., 2017).\"\n        ii)  No explanation of the cited works and relation to their own work: \u201cRecently, several studies have explored the use of prompting techniques with pre-trained language models to influence model outputs or access latent knowledge (Brown et al., 2020; Gao et al., 2021; Liu et al., 2021; Wei et al., 2022).\u201d \n\n        Example text: \n        Related Work\n\nDevelopers rely on code search to find relevant snippets, APIs, or examples. Unlike general document retrieval, code search must bridge natural language intent and program structure.\n\nNeural code search has been addressed with bi-encoders, cross-encoders, and dual learning (Gu et al., 2018; Husain et al., 2019; Feng et al., 2020). Structural representations incorporate ASTs, control flow, and data flow (Alon et al., 2019; Wang et al., 2020; Liu et al., 2021). Pretraining on code and NL improves retrieval metrics across languages (Ahmad et al., 2021; Guo et al., 2021).\n\nIn this paper, we introduce a language-agnostic retriever with compositional queries.\n\nWe evaluate zero-shot transfer across four programming languages.\nIntroduction\n\nGeneralization in text classification can be improved with data augmentation, especially when labeled data are scarce or imbalanced. Approaches range from rule-based edits to model-driven paraphrasing and representation-space mixing.\n\nText augmentation techniques include synonym replacement, random insertion/deletion, back-translation, paraphrase generation, and mixup in embedding or hidden spaces (Wei and Zou, 2019; Sennrich et al., 2016; Kobayashi, 2018; Guo et al., 2020). Recent work explores task-adaptive augmentation policies learned by reinforcement learning (Xie et al., 2020).\n\nEvaluation typically considers robustness to domain shift, label noise, and distributional skew across multiple benchmarks (Pruksachatkun et al., 2020; Hendrycks et al., 2020).\nRelated Work\n\nKnowledge graph completion predicts missing links by learning entity and relation representations. Methods vary in how they encode semantics and handle patterns like symmetry, hierarchy, and composition.\n\nTranslation-based knowledge graph embeddings model relations as translations in vector space (Bordes et al., 2013; Wang et al., 2014), while bilinear and neural models capture more complex interactions (Nickel et al., 2011; Trouillon et al., 2016; Sun et al., 2019). Regularization and rule-guided approaches improve inductive bias and data efficiency (Rockt\u00e4schel et al., 2015; Minervini et al., 2017).\n\nWe introduce a lightweight compositional constraint for hierarchical relations and evaluate on three benchmarks and an industry dataset.\nRelated Work\n\nEnsuring safety during reinforcement learning is critical in real-world control where violations can be costly. Research has proposed both objective-level and mechanism-level solutions.\n\nSafe reinforcement learning approaches include risk-sensitive objectives such as CVaR optimization (Tamar et al., 2015; Chow et al., 2018), constrained policy optimization with safety budgets (Achiam et al., 2017; Yang et al., 2020), and shielding based on model-checking or supervisors (Alshiekh et al., 2018; Dalal et al., 2018). We develop a method that integrates model-predictive constraints with policy gradients.\n\nBenchmarks often evaluate safety in simulated robotics or navigation with cost functions approximating constraint violations (Ray et al., 2019; Bharadhwaj et al., 2021).\nRelated Work\n\nDialog state tracking (DST) has evolved from rule-based slot filling to neural architectures that jointly infer belief states across turns. Early pipeline models used hand-crafted lexicons and semantic frames (Singh and Patel, 2015), but suffered from brittleness to paraphrase and noise. Neural encoders introduced robustness by contextualizing utterances, incorporating attention over dialog history, and modeling slot-value dependencies (Lee et al., 2018; Choe and Kim, 2019).\n\nPretrained language models have further shifted the landscape by enabling few-shot generalization and open-vocabulary slot values. Fine-tuning BERT-like encoders for DST improved cross-domain transfer (Rao et al., 2020), while generative formulations cast state tracking as text-to-text prediction (Mendez et al., 2021).\n\nPrompting-based approaches have also been explored for dialog modeling (Kumar et al., 2021; Ortega and Lin, 2022; Park et al., 2023). These methods condition large language models on task instructions or few-shot exemplars to elicit latent conversational knowledge. Recent variants incorporate calibration or self-consistency to stabilize outputs (Fang et al., 2023; Zhou et al., 2023).\n\nPosition relative to this paper While we also employ pretrained sequence-to-sequence models, our focus is on handling ontology drift in long-running deployments. Specifically, we introduce an adaptive slot schema encoder that aligns evolving taxonomies with dialog evidence, and a contrastive consistency objective to mitigate spurious slot co-activations across domains.\nIntroduction\n\nSelf-supervised learning (SSL) has become the dominant paradigm for learning transferable visual features without labels. By constructing pretext tasks that expose invariances and structure inherent in data, SSL models can match or surpass supervised baselines on many downstream tasks.\n\nContrastive pretraining has been widely adopted for visual representations (Chen et al., 2020; He et al., 2020; Xie and Xu, 2021). Non-contrastive methods remove negative pairs and rely on architectural or objective asymmetries (Grill et al., 2020; Tian et al., 2021). Clustering-based methods jointly learn assignments and embeddings (Caron et al., 2018; Li and Gao, 2022).\n\nDespite these advances, industrial applications often operate under strict memory budgets and latency constraints. In this paper, we investigate compute-aware pretraining objectives that couple multi-crop augmentation with a token-subsampled backbone. We present a latency-regularized alignment loss that preserves downstream accuracy while reducing FLOPs during both pretraining and fine-tuning.\nIntroduction\n\nEfficient exploration remains a central challenge in reinforcement learning (RL), particularly in sparse-reward environments where naive strategies fail to discover rewarding states. Over-exploration, however, can waste samples and destabilize learning.\n\nExploration in reinforcement learning has been advanced by count-based bonuses, intrinsic motivation, curiosity-driven prediction error, and information-theoretic objectives (Bellemare et al., 2016; Pathak et al., 2017; Houthooft et al., 2016; Burda et al., 2019; Ta\u00efga et al., 2020).\n\nYet, when environment dynamics change over time, stale novelty estimates can encourage revisiting obsolete states. We propose a recency-aware intrinsic reward that discounts outdated novelty and couples it with conservative policy updates.\n\nAcross Atari and continuous-control domains with drifting dynamics, our method achieves superior sample efficiency and stability, and ablations confirm the role of recency in balancing exploration and exploitation.\nRelated Work\n\nDetecting anomalies in multivariate time series is vital for monitoring industrial systems and cloud services. The challenge lies in handling seasonality, rare events, and inter-variable dependencies.\n\nClassical anomaly detection leverages ARIMA residual tests, STL decomposition, and control charts, while deep methods introduce autoencoders, VAEs, GANs, LSTMs, and Transformers for reconstruction or prediction errors (Tsay, 2010; Malhotra et al., 2015; An and Cho, 2015; Li et al., 2019; Xu et al., 2021).\n\nWe present Contrastive Forecasting with Graph Priors (CFGP), which learns structure-aware representations via self-supervised objectives and uses calibrated predictive intervals to flag anomalies.\nIntroduction\n\nGeneralizing manipulation skills across objects, tasks, and environments remains a central challenge in robotics. Sparse rewards, safety constraints, and hardware variability complicate learning on physical systems. Recent work studies imitation learning, offline RL, and model-based control for dexterous manipulation (Rajeswaran et al., 2018; Lynch et al., 2020; Nagabandi et al., 2019; Ahn et al., 2022). Despite these advances, scaling data collection and ensuring sim-to-real transfer continue to be bottlenecks.\n\nWe explore a curriculum that interleaves skill discovery from teleoperation logs with conservative online updates, targeting stable improvements under limited interaction budgets.\nRelated Work\n\nConversational recommenders. Systems that interactively elicit user preferences can reduce cold-start and improve satisfaction (Sun and Zhang, 2018). Dialog policy learning for conversational recommendation has explored supervised learning, reinforcement learning, and bandit methods (Christakopoulou et al., 2016; Lei et al., 2020; Chen et al., 2019). User simulators and counterfactual logging have been proposed to address data scarcity and evaluation challenges (Li et al., 2017; Chi et al., 2020).\n\nOur study investigates preference drift over long-horizon sessions and proposes a state representation that explicitly tracks uncertainty and recency effects.\nIntroduction\n\nExplainable AI (XAI) is increasingly required for medical imaging systems used in screening and triage. Beyond predictive accuracy, clinicians demand transparency about what image features drive automated decisions and whether explanations are stable under shifts.\n\nPost-hoc attribution methods like Grad-CAM and Integrated Gradients highlight salient regions (Selvaraju et al., 2017; Sundararajan et al., 2017). Prototype- and concept-based explanations enhance interpretability (Chen et al., 2019; Kim et al., 2018). Counterfactual generation has been explored for medical images (Chang et al., 2018; Singla et al., 2021).\n\nWe focus on faithfulness under distribution shift and propose an evaluation protocol that aligns explanation stability with clinical acceptance thresholds for screening workflows.\nRelated Work\n\nProviding timely, actionable feedback at scale is central to computing education. Traditional approaches combine instructor-designed rubrics with automated tests, but coverage and specificity can be limited for diverse student solutions.\n\nAutomated feedback for programming assignments has been tackled with static analysis, dynamic test generation, and pattern mining (Ke et al., 2016; Gulwani et al., 2018; Singh et al., 2013). Recent NLP-based systems leverage code embeddings, sequence models, and pretrained language models (Allamanis et al., 2018; Feng et al., 2020; Ahmad et al., 2021). Peer learning platforms collect hints and exemplars to guide novice programmers (Piech et al., 2015; Wang et al., 2018).\n\nWhile data-driven approaches show promise, they often struggle with generalizing across tasks and providing pedagogically aligned guidance. Our work investigates structure-aware hint generation that aligns feedback to conceptual steps in problem-solving.\nRelated Work\n\nReinforcement learning (RL) has enabled robots to acquire complex behaviors directly from interaction. However, data hunger, safety, and sim-to-real transfer remain persistent obstacles for deployment in real-world settings.\n\nModel-free methods such as DDPG (Lillicrap et al., 2016), SAC (Haarnoja et al., 2018), and PPO (Schulman et al., 2017) have been widely adopted for continuous control, while model-based approaches leverage learned dynamics for sample efficiency (Deisenroth and Rasmussen, 2011; Chua et al., 2018). Recent lines of work explore offline RL (Levine et al., 2020; Kumar et al., 2020) and representation learning for policy generalization (Laskin et al., 2020; Yarats et al., 2021). Domain randomization and adaptation seek to bridge the sim-to-real gap (Tobin et al., 2017; Peng et al., 2018).\n\nWe propose a training strategy that combines curriculum learning with uncertainty-aware policy updates to improve safety and sample efficiency in robotic manipulation.\nRelated Work\n\nAutomatic speech recognition (ASR) systems increasingly rely on large encoder\u2013decoder architectures that are costly to deploy on edge devices. Knowledge distillation (KD) is a common strategy to reduce model size while preserving accuracy.\n\nKnowledge distillation for speech recognition has considered frame-level supervision, sequence-level criteria, and wordpiece distributions, transferring knowledge from stronger teachers to smaller students (Hinton et al., 2015; Kim and Rush, 2016; Kurata and Audhkhasi, 2018; Higuchi et al., 2021).\n\nOther compression techniques include quantization and pruning, which can be combined with KD but may degrade robustness to noise and speaker variability. Recent work explores multi-teacher ensembles and intermediate-layer matching to stabilize training.\n\nIn this paper, we study streaming-constrained KD with latency-aware targets, aligning teacher and student under causal masking. Our experiments on LibriSpeech and far-field corpora show improved WER\u2013latency trade-offs compared to strong baselines.\nRelated Work\n\nLarge Language Models and Prompting\nLarge language models (LLMs) exhibit emergent program synthesis capabilities when conditioned on natural language instructions and a handful of examples. While these behaviors reduce reliance on supervised datasets, the mechanisms by which prompts control generation remain only partially understood. Prior studies analyze calibration, decoding strategies, and context length effects.\n\nPrompting for Code Generation\nPrompting for code generation has explored zero-shot, few-shot, and chain-of-thought styles using large language models (Chen et al., 2021; Austin et al., 2021; Nijkamp et al., 2022; Li et al., 2023). Work on compiler-aware prompting adds execution feedback to steer generation (Liu et al., 2022; Le et al., 2022; Wang et al., 2023). Program repair and test-driven synthesis have similarly adapted prompting strategies to satisfy unit tests (Jain et al., 2022; Zhang et al., 2023).\n\nExecution-Conditioned Decoding\nBeyond static prompts, execution-conditioned decoding iteratively runs partial programs to reduce search space. Studies report gains on algorithmic problems by interleaving generation and verification under timeouts and sandboxing constraints.\n\nStructured Constraints and Type Guidance\nApproaches that inject grammar constraints or type information restrict invalid outputs and improve pass rates. These methods range from constrained beam search to type-state automata.\n\nPositioning\nWe examine the interaction between prompt structure and execution feedback and study how typed constraints alter search dynamics under limited budgets.\nRelated Work\n\nFederated learning (FL) enables on-device training with privacy and communication constraints. Ensuring rigorous privacy guarantees while preserving model utility remains a core challenge.\n\nPrivacy in federated learning has been studied via differential privacy at the client level, secure aggregation, and shuffling (McMahan et al., 2017; Kairouz et al., 2021; Bonawitz et al., 2017; Erlingsson et al., 2019). Gradient perturbation, clipping, and client subsampling are common techniques to control privacy loss (Abadi et al., 2016; Thakkar et al., 2019; Andrew et al., 2021). Auditing methods estimate empirical privacy leakage post hoc (Nasr et al., 2019; Jagielski et al., 2020).\n\nOur approach introduces client-adaptive noise schedules conditioned on participation frequency.\n\nWe empirically evaluate privacy-utility trade-offs across heterogeneous client populations.\nIntroduction\n\nInformation retrieval has shifted from lexical term matching to semantic representations that capture contextual meaning. This shift enables better recall of paraphrased content but introduces new challenges in index efficiency and training stability.\n\nNeural semantic search methods combine dual-encoders for efficient retrieval (Yao et al., 2019; Xie and Zhao, 2020) with cross-encoders for reranking (Nogueira and Cho, 2019; Li et al., 2021), and leverage hard-negative mining to improve discriminative power (Gao et al., 2021; Huang et al., 2022). Recent work also explores domain adaptation for specialized corpora such as legal and biomedical texts (Park et al., 2022; Sun et al., 2023).\n\nWe study lightweight domain adaptation under tight indexing budgets.\nRelated Work\n\nDetecting anomalies in time-series is a long-standing problem with applications in monitoring, finance, and industrial IoT. Methods vary widely in assumptions, supervision requirements, and scalability.\n\nTime-series anomaly detection spans classical statistical tests, isolation-based methods, and deep learning models such as autoencoders, temporal convolutional networks, and Transformers (Gupta et al., 2014; Liu et al., 2008; Malhotra et al., 2016; Xu et al., 2020). Synthetic anomaly injection and semi-supervised training are also common practices (Zhang et al., 2019; Shen et al., 2021).\n\nBenchmarking efforts have sought consistent evaluation protocols across datasets with different anomaly types and frequencies (Hundman et al., 2018; Wu and Keogh, 2021).\nRelated Work\n\nPredicting molecular properties from structure has catalyzed a broad literature at the intersection of cheminformatics and geometric deep learning. Approaches differ in how they encode graph topology, chemical attributes, and geometric constraints.\n\nGraph representation learning methods such as spectral GCNs, spatial message passing networks, and attention-based GNNs have been widely applied to molecular property prediction (Kipf and Welling, 2017; Gilmer et al., 2017; Veli\u010dkovi\u0107 et al., 2018). Extensions include edge-conditioned convolutions, higher-order structures, and equivariant networks for 3D geometries (Simonovsky and Komodakis, 2017; Batzner et al., 2022).\n\nPretraining strategies on large unlabeled molecule corpora with contrastive or masked node prediction objectives have further improved generalization, especially in low-data regimes (Hu et al., 2020; Rong et al., 2020).\nIntroduction\n\nAutomated analysis of pathology whole-slide images (WSIs) faces extreme resolution, sparse lesion patterns, and distribution shifts across scanners and staining protocols. Convolutional networks have advanced the field but can be limited in modeling long-range dependencies over gigapixel slides.\n\nVision Transformers have been applied to medical image classification, segmentation, and detection with pure transformer backbones or hybrid CNN\u2013Transformer designs (Dosovitskiy et al., 2020; Chen et al., 2021; Hatamizadeh et al., 2022; Wang et al., 2021; Xie et al., 2021).\n\nWeakly supervised multiple-instance learning (MIL) further alleviates slide-level labeling costs by aggregating patch evidence, yet attention pooling can overfit to spurious correlations. We investigate whether token-level sparsification combined with instance reweighting can improve robustness in cross-site evaluation.\n\nOur method introduces a curriculum-sparse token selection and slide-consistent calibration loss to stabilize attention under domain shift. On three WSI benchmarks spanning different scanners, we observe gains in AUC and improved calibration, with minimal added compute.\n\nWe conduct ablations on sparsity schedules and release pretrained weights for community use.\nRelated Work\n\nRemote sensing change detection relies on robust representations that separate illumination and seasonal effects from structural changes. Recent advances in high-resolution satellites have shifted attention to fine-grained, building-level change cues.\n\nClassical two-stream CNNs, Siamese architectures, and attention-based models have been widely adopted for change detection (Daudt et al., 2018; Fang et al., 2020; Chen et al., 2021). Large-scale datasets such as LEVIR-CD, CDD, and WHU-CD have enabled benchmarking across urban scenes (Levir et al., 2020; Wang et al., 2020; Ji et al., 2019). Transformer-based encoders further improve long-range modeling (Ban et al., 2021; Liu et al., 2021).\n\nWhile these efforts improve accuracy, they largely assume perfectly registered image pairs and abundant labels. Our work targets label-scarce scenarios with misalignment by learning registration-aware tokens that disentangle geometry from appearance.\nIntroduction\n\nEffective human-robot collaboration requires balancing adaptability to user intent with guarantees on safety and task efficiency. Real-world deployments must operate under partial observability and distribution shifts in user behavior.\n\nShared autonomy techniques span predictive user intent modeling, POMDP-based assistance, arbitration policies that blend human and robot commands, and learning from demonstration for collaborative tasks (Dragan and Srinivasa, 2013; Javdani et al., 2015; Reddy et al., 2018; Losey et al., 2020).\n\nWe propose CertAssist, a certifiably safe shared autonomy framework combining control barrier functions with belief-dependent arbitration, evaluated on manipulation and navigation tasks with human participants.\nIntroduction\nAccurate forecasting underpins decision-making in supply chains, energy, and finance. Models must balance bias-variance trade-offs, handle sparse covariates, and remain robust to nonstationary shifts and irregular sampling.\n\nClassical time series forecasting relies on ARIMA and exponential smoothing to model linear dependencies (Box and Jenkins, 1970; Hyndman et al., 2008). Neural models introduce nonlinearity via RNNs, LSTMs, and temporal convolutions (Hochreiter and Schmidhuber, 1997; Bai et al., 2018). Transformer-based forecasters use attention to capture long-range dependencies (Li et al., 2019; Zhou et al., 2021). Decomposition and frequency-domain methods further reduce complexity and highlight seasonal structure (Oreshkin et al., 2020; Wu et al., 2021).\n\nWe present an uncertainty-aware spectral transformer that couples learnable seasonal kernels with interval calibration, yielding improved accuracy and coverage under regime shifts in retail and traffic datasets.\nRelated Work\n\nControllable text generation seeks to guide large language models (LLMs) toward specified attributes with minimal task-specific supervision. Recent approaches either modify inputs via prompts or adjust model parameters through lightweight adapters.\n\nPrompt-based methods for steering pre-trained language models have been explored in a variety of settings. Discrete prompt mining identifies trigger tokens that elicit desired behavior (Kim and Park, 2020; Zhou et al., 2021). Continuous prompt tuning replaces hard prompts with trainable embeddings (Li and Sung, 2021; Qin et al., 2022). Instruction following with few-shot exemplars has also been shown to improve task transfer (Rao and Lin, 2021; Xu et al., 2022).\n\nAdapter-based control introduces small task-specific modules into frozen backbones, enabling multi-task training while limiting memory costs (Chen et al., 2021; Gupta and Lee, 2022). Other lines include decoding constraints (He and Zhao, 2020) and classifier-guided re-ranking (Sharma et al., 2021).\n\nIn parallel, evaluation protocols for controllability measure attribute accuracy, content preservation, and fluency (Liu et al., 2020; Feng and Ma, 2021).\nRelated Work\n\nFederated learning enables collaborative training across a population of devices while keeping raw data local. The distributed setting raises new challenges in privacy, robustness, and communication efficiency.\n\nPrivacy in federated learning has been studied through differential privacy mechanisms for client updates (Abadi et al., 2016; McMahan et al., 2018), secure aggregation protocols to hide individual contributions (Bonawitz et al., 2017), split learning to keep raw data on-device (Gupta and Raskar, 2018), and cryptographic techniques like homomorphic encryption and MPC (Gentry, 2009; Mohassel and Zhang, 2017). Communication reduction has been addressed via sparsification and quantization (Stich et al., 2018; Kone\u010dn\u00fd et al., 2016).\n\nOur method jointly optimizes privacy noise allocation and gradient compression schedules under a fixed bandwidth budget.\nIntroduction\n\nUrban congestion degrades mobility, increases emissions, and undermines economic productivity. Adaptive traffic signal control promises to improve throughput by tailoring signal plans to real-time conditions. Reinforcement learning offers a data-driven framework to learn such policies directly from interaction.\n\nClassical traffic signal control uses handcrafted rules and model-based optimization (Webster, 1958; Gartner, 1983). RL-based approaches apply tabular Q-learning, deep Q-networks, and policy gradients to learn adaptive strategies (Abdoos et al., 2013; Van der Pol and Oliehoek, 2016; Wei et al., 2018). Multi-agent methods coordinate intersections via shared critics or communication (Chu et al., 2019; Zang et al., 2020; Chen et al., 2020). In this work, we propose a hierarchical actor-critic that decomposes phase selection and duration control.\n\nWe validate our approach on synthetic and real-world networks, showing gains in average travel time and queue length.\nRelated Work\n\nMultimodal summarization seeks to distill essential content by integrating complementary cues across text, images, and video. Approaches differ in the depth of fusion, supervision requirements, and the granularity of output (sentential vs. extractive vs. abstractive).\n\nEarly multimodal summarization methods fuse visual features with textual encoders (Li et al., 2017; Chen and Bansal, 2018). Video summarization leverages temporal attention and key-shot selection (Zhang et al., 2016; Rochan and Wang, 2019). Recent transformer-based models introduce cross-modal alignment modules (Liu et al., 2021; Zeng et al., 2022).\n\nDespite the progress, practical systems must handle noisy modalities and domain shifts. Our study focuses on robust alignment under weak supervision and evaluates consistency constraints that mitigate cross-modal mismatch.\n",
        "completion": "Early multimodal summarization methods fuse visual features with textual encoders (Li et al., 2017; Chen and Bansal, 2018). Video summarization leverages temporal attention and key-shot selection (Zhang et al., 2016; Rochan and Wang, 2019). Recent transformer-based models introduce cross-modal alignment modules (Liu et al., 2021; Zeng et al., 2022)."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        occurs when either:\n    a) The author describes or cites papers without connecting them to their own work/argument \n    b) Or only follows up the summary of previous works with their own contribution without explicitly highlighting the gap their work intends to research.\n    c) It does not articulate the author's perspective or motivation.\n    d) A lack of argument/opinion in the first paragraph is permissible as it serves to be the foundation of the author's argument \n    e) Lacks synthesis issues appear either as single sentences or multiple sentences.\n    Examples of lack of synthesis include:\n        i) No elaboration of own contribution/argument:\"Following early neural approaches to question answering, many subsequent studies adopt a pipeline architecture consisting of retrieval and comprehension components. The retrieval component focuses on identifying relevant documents or passages from a large corpus, while the comprehension component extracts an answer span from the retrieved text. Initial models relied on recurrent neural networks with attention mechanisms to encode questions and contexts (Seo et al., 2017; Wang et al., 2017).\"\n        ii)  No explanation of the cited works and relation to their own work: \u201cRecently, several studies have explored the use of prompting techniques with pre-trained language models to influence model outputs or access latent knowledge (Brown et al., 2020; Gao et al., 2021; Liu et al., 2021; Wei et al., 2022).\u201d \n\n        Example text: \n        Related Work\n\nDevelopers rely on code search to find relevant snippets, APIs, or examples. Unlike general document retrieval, code search must bridge natural language intent and program structure.\n\nNeural code search has been addressed with bi-encoders, cross-encoders, and dual learning (Gu et al., 2018; Husain et al., 2019; Feng et al., 2020). Structural representations incorporate ASTs, control flow, and data flow (Alon et al., 2019; Wang et al., 2020; Liu et al., 2021). Pretraining on code and NL improves retrieval metrics across languages (Ahmad et al., 2021; Guo et al., 2021).\n\nIn this paper, we introduce a language-agnostic retriever with compositional queries.\n\nWe evaluate zero-shot transfer across four programming languages.\nIntroduction\n\nGeneralization in text classification can be improved with data augmentation, especially when labeled data are scarce or imbalanced. Approaches range from rule-based edits to model-driven paraphrasing and representation-space mixing.\n\nText augmentation techniques include synonym replacement, random insertion/deletion, back-translation, paraphrase generation, and mixup in embedding or hidden spaces (Wei and Zou, 2019; Sennrich et al., 2016; Kobayashi, 2018; Guo et al., 2020). Recent work explores task-adaptive augmentation policies learned by reinforcement learning (Xie et al., 2020).\n\nEvaluation typically considers robustness to domain shift, label noise, and distributional skew across multiple benchmarks (Pruksachatkun et al., 2020; Hendrycks et al., 2020).\nRelated Work\n\nKnowledge graph completion predicts missing links by learning entity and relation representations. Methods vary in how they encode semantics and handle patterns like symmetry, hierarchy, and composition.\n\nTranslation-based knowledge graph embeddings model relations as translations in vector space (Bordes et al., 2013; Wang et al., 2014), while bilinear and neural models capture more complex interactions (Nickel et al., 2011; Trouillon et al., 2016; Sun et al., 2019). Regularization and rule-guided approaches improve inductive bias and data efficiency (Rockt\u00e4schel et al., 2015; Minervini et al., 2017).\n\nWe introduce a lightweight compositional constraint for hierarchical relations and evaluate on three benchmarks and an industry dataset.\nRelated Work\n\nEnsuring safety during reinforcement learning is critical in real-world control where violations can be costly. Research has proposed both objective-level and mechanism-level solutions.\n\nSafe reinforcement learning approaches include risk-sensitive objectives such as CVaR optimization (Tamar et al., 2015; Chow et al., 2018), constrained policy optimization with safety budgets (Achiam et al., 2017; Yang et al., 2020), and shielding based on model-checking or supervisors (Alshiekh et al., 2018; Dalal et al., 2018). We develop a method that integrates model-predictive constraints with policy gradients.\n\nBenchmarks often evaluate safety in simulated robotics or navigation with cost functions approximating constraint violations (Ray et al., 2019; Bharadhwaj et al., 2021).\nRelated Work\n\nDialog state tracking (DST) has evolved from rule-based slot filling to neural architectures that jointly infer belief states across turns. Early pipeline models used hand-crafted lexicons and semantic frames (Singh and Patel, 2015), but suffered from brittleness to paraphrase and noise. Neural encoders introduced robustness by contextualizing utterances, incorporating attention over dialog history, and modeling slot-value dependencies (Lee et al., 2018; Choe and Kim, 2019).\n\nPretrained language models have further shifted the landscape by enabling few-shot generalization and open-vocabulary slot values. Fine-tuning BERT-like encoders for DST improved cross-domain transfer (Rao et al., 2020), while generative formulations cast state tracking as text-to-text prediction (Mendez et al., 2021).\n\nPrompting-based approaches have also been explored for dialog modeling (Kumar et al., 2021; Ortega and Lin, 2022; Park et al., 2023). These methods condition large language models on task instructions or few-shot exemplars to elicit latent conversational knowledge. Recent variants incorporate calibration or self-consistency to stabilize outputs (Fang et al., 2023; Zhou et al., 2023).\n\nPosition relative to this paper While we also employ pretrained sequence-to-sequence models, our focus is on handling ontology drift in long-running deployments. Specifically, we introduce an adaptive slot schema encoder that aligns evolving taxonomies with dialog evidence, and a contrastive consistency objective to mitigate spurious slot co-activations across domains.\nIntroduction\n\nSelf-supervised learning (SSL) has become the dominant paradigm for learning transferable visual features without labels. By constructing pretext tasks that expose invariances and structure inherent in data, SSL models can match or surpass supervised baselines on many downstream tasks.\n\nContrastive pretraining has been widely adopted for visual representations (Chen et al., 2020; He et al., 2020; Xie and Xu, 2021). Non-contrastive methods remove negative pairs and rely on architectural or objective asymmetries (Grill et al., 2020; Tian et al., 2021). Clustering-based methods jointly learn assignments and embeddings (Caron et al., 2018; Li and Gao, 2022).\n\nDespite these advances, industrial applications often operate under strict memory budgets and latency constraints. In this paper, we investigate compute-aware pretraining objectives that couple multi-crop augmentation with a token-subsampled backbone. We present a latency-regularized alignment loss that preserves downstream accuracy while reducing FLOPs during both pretraining and fine-tuning.\nIntroduction\n\nEfficient exploration remains a central challenge in reinforcement learning (RL), particularly in sparse-reward environments where naive strategies fail to discover rewarding states. Over-exploration, however, can waste samples and destabilize learning.\n\nExploration in reinforcement learning has been advanced by count-based bonuses, intrinsic motivation, curiosity-driven prediction error, and information-theoretic objectives (Bellemare et al., 2016; Pathak et al., 2017; Houthooft et al., 2016; Burda et al., 2019; Ta\u00efga et al., 2020).\n\nYet, when environment dynamics change over time, stale novelty estimates can encourage revisiting obsolete states. We propose a recency-aware intrinsic reward that discounts outdated novelty and couples it with conservative policy updates.\n\nAcross Atari and continuous-control domains with drifting dynamics, our method achieves superior sample efficiency and stability, and ablations confirm the role of recency in balancing exploration and exploitation.\nRelated Work\n\nDetecting anomalies in multivariate time series is vital for monitoring industrial systems and cloud services. The challenge lies in handling seasonality, rare events, and inter-variable dependencies.\n\nClassical anomaly detection leverages ARIMA residual tests, STL decomposition, and control charts, while deep methods introduce autoencoders, VAEs, GANs, LSTMs, and Transformers for reconstruction or prediction errors (Tsay, 2010; Malhotra et al., 2015; An and Cho, 2015; Li et al., 2019; Xu et al., 2021).\n\nWe present Contrastive Forecasting with Graph Priors (CFGP), which learns structure-aware representations via self-supervised objectives and uses calibrated predictive intervals to flag anomalies.\nIntroduction\n\nGeneralizing manipulation skills across objects, tasks, and environments remains a central challenge in robotics. Sparse rewards, safety constraints, and hardware variability complicate learning on physical systems. Recent work studies imitation learning, offline RL, and model-based control for dexterous manipulation (Rajeswaran et al., 2018; Lynch et al., 2020; Nagabandi et al., 2019; Ahn et al., 2022). Despite these advances, scaling data collection and ensuring sim-to-real transfer continue to be bottlenecks.\n\nWe explore a curriculum that interleaves skill discovery from teleoperation logs with conservative online updates, targeting stable improvements under limited interaction budgets.\nRelated Work\n\nConversational recommenders. Systems that interactively elicit user preferences can reduce cold-start and improve satisfaction (Sun and Zhang, 2018). Dialog policy learning for conversational recommendation has explored supervised learning, reinforcement learning, and bandit methods (Christakopoulou et al., 2016; Lei et al., 2020; Chen et al., 2019). User simulators and counterfactual logging have been proposed to address data scarcity and evaluation challenges (Li et al., 2017; Chi et al., 2020).\n\nOur study investigates preference drift over long-horizon sessions and proposes a state representation that explicitly tracks uncertainty and recency effects.\nIntroduction\n\nExplainable AI (XAI) is increasingly required for medical imaging systems used in screening and triage. Beyond predictive accuracy, clinicians demand transparency about what image features drive automated decisions and whether explanations are stable under shifts.\n\nPost-hoc attribution methods like Grad-CAM and Integrated Gradients highlight salient regions (Selvaraju et al., 2017; Sundararajan et al., 2017). Prototype- and concept-based explanations enhance interpretability (Chen et al., 2019; Kim et al., 2018). Counterfactual generation has been explored for medical images (Chang et al., 2018; Singla et al., 2021).\n\nWe focus on faithfulness under distribution shift and propose an evaluation protocol that aligns explanation stability with clinical acceptance thresholds for screening workflows.\nRelated Work\n\nProviding timely, actionable feedback at scale is central to computing education. Traditional approaches combine instructor-designed rubrics with automated tests, but coverage and specificity can be limited for diverse student solutions.\n\nAutomated feedback for programming assignments has been tackled with static analysis, dynamic test generation, and pattern mining (Ke et al., 2016; Gulwani et al., 2018; Singh et al., 2013). Recent NLP-based systems leverage code embeddings, sequence models, and pretrained language models (Allamanis et al., 2018; Feng et al., 2020; Ahmad et al., 2021). Peer learning platforms collect hints and exemplars to guide novice programmers (Piech et al., 2015; Wang et al., 2018).\n\nWhile data-driven approaches show promise, they often struggle with generalizing across tasks and providing pedagogically aligned guidance. Our work investigates structure-aware hint generation that aligns feedback to conceptual steps in problem-solving.\nRelated Work\n\nReinforcement learning (RL) has enabled robots to acquire complex behaviors directly from interaction. However, data hunger, safety, and sim-to-real transfer remain persistent obstacles for deployment in real-world settings.\n\nModel-free methods such as DDPG (Lillicrap et al., 2016), SAC (Haarnoja et al., 2018), and PPO (Schulman et al., 2017) have been widely adopted for continuous control, while model-based approaches leverage learned dynamics for sample efficiency (Deisenroth and Rasmussen, 2011; Chua et al., 2018). Recent lines of work explore offline RL (Levine et al., 2020; Kumar et al., 2020) and representation learning for policy generalization (Laskin et al., 2020; Yarats et al., 2021). Domain randomization and adaptation seek to bridge the sim-to-real gap (Tobin et al., 2017; Peng et al., 2018).\n\nWe propose a training strategy that combines curriculum learning with uncertainty-aware policy updates to improve safety and sample efficiency in robotic manipulation.\nRelated Work\n\nAutomatic speech recognition (ASR) systems increasingly rely on large encoder\u2013decoder architectures that are costly to deploy on edge devices. Knowledge distillation (KD) is a common strategy to reduce model size while preserving accuracy.\n\nKnowledge distillation for speech recognition has considered frame-level supervision, sequence-level criteria, and wordpiece distributions, transferring knowledge from stronger teachers to smaller students (Hinton et al., 2015; Kim and Rush, 2016; Kurata and Audhkhasi, 2018; Higuchi et al., 2021).\n\nOther compression techniques include quantization and pruning, which can be combined with KD but may degrade robustness to noise and speaker variability. Recent work explores multi-teacher ensembles and intermediate-layer matching to stabilize training.\n\nIn this paper, we study streaming-constrained KD with latency-aware targets, aligning teacher and student under causal masking. Our experiments on LibriSpeech and far-field corpora show improved WER\u2013latency trade-offs compared to strong baselines.\nRelated Work\n\nLarge Language Models and Prompting\nLarge language models (LLMs) exhibit emergent program synthesis capabilities when conditioned on natural language instructions and a handful of examples. While these behaviors reduce reliance on supervised datasets, the mechanisms by which prompts control generation remain only partially understood. Prior studies analyze calibration, decoding strategies, and context length effects.\n\nPrompting for Code Generation\nPrompting for code generation has explored zero-shot, few-shot, and chain-of-thought styles using large language models (Chen et al., 2021; Austin et al., 2021; Nijkamp et al., 2022; Li et al., 2023). Work on compiler-aware prompting adds execution feedback to steer generation (Liu et al., 2022; Le et al., 2022; Wang et al., 2023). Program repair and test-driven synthesis have similarly adapted prompting strategies to satisfy unit tests (Jain et al., 2022; Zhang et al., 2023).\n\nExecution-Conditioned Decoding\nBeyond static prompts, execution-conditioned decoding iteratively runs partial programs to reduce search space. Studies report gains on algorithmic problems by interleaving generation and verification under timeouts and sandboxing constraints.\n\nStructured Constraints and Type Guidance\nApproaches that inject grammar constraints or type information restrict invalid outputs and improve pass rates. These methods range from constrained beam search to type-state automata.\n\nPositioning\nWe examine the interaction between prompt structure and execution feedback and study how typed constraints alter search dynamics under limited budgets.\nRelated Work\n\nFederated learning (FL) enables on-device training with privacy and communication constraints. Ensuring rigorous privacy guarantees while preserving model utility remains a core challenge.\n\nPrivacy in federated learning has been studied via differential privacy at the client level, secure aggregation, and shuffling (McMahan et al., 2017; Kairouz et al., 2021; Bonawitz et al., 2017; Erlingsson et al., 2019). Gradient perturbation, clipping, and client subsampling are common techniques to control privacy loss (Abadi et al., 2016; Thakkar et al., 2019; Andrew et al., 2021). Auditing methods estimate empirical privacy leakage post hoc (Nasr et al., 2019; Jagielski et al., 2020).\n\nOur approach introduces client-adaptive noise schedules conditioned on participation frequency.\n\nWe empirically evaluate privacy-utility trade-offs across heterogeneous client populations.\nIntroduction\n\nInformation retrieval has shifted from lexical term matching to semantic representations that capture contextual meaning. This shift enables better recall of paraphrased content but introduces new challenges in index efficiency and training stability.\n\nNeural semantic search methods combine dual-encoders for efficient retrieval (Yao et al., 2019; Xie and Zhao, 2020) with cross-encoders for reranking (Nogueira and Cho, 2019; Li et al., 2021), and leverage hard-negative mining to improve discriminative power (Gao et al., 2021; Huang et al., 2022). Recent work also explores domain adaptation for specialized corpora such as legal and biomedical texts (Park et al., 2022; Sun et al., 2023).\n\nWe study lightweight domain adaptation under tight indexing budgets.\nRelated Work\n\nDetecting anomalies in time-series is a long-standing problem with applications in monitoring, finance, and industrial IoT. Methods vary widely in assumptions, supervision requirements, and scalability.\n\nTime-series anomaly detection spans classical statistical tests, isolation-based methods, and deep learning models such as autoencoders, temporal convolutional networks, and Transformers (Gupta et al., 2014; Liu et al., 2008; Malhotra et al., 2016; Xu et al., 2020). Synthetic anomaly injection and semi-supervised training are also common practices (Zhang et al., 2019; Shen et al., 2021).\n\nBenchmarking efforts have sought consistent evaluation protocols across datasets with different anomaly types and frequencies (Hundman et al., 2018; Wu and Keogh, 2021).\nRelated Work\n\nPredicting molecular properties from structure has catalyzed a broad literature at the intersection of cheminformatics and geometric deep learning. Approaches differ in how they encode graph topology, chemical attributes, and geometric constraints.\n\nGraph representation learning methods such as spectral GCNs, spatial message passing networks, and attention-based GNNs have been widely applied to molecular property prediction (Kipf and Welling, 2017; Gilmer et al., 2017; Veli\u010dkovi\u0107 et al., 2018). Extensions include edge-conditioned convolutions, higher-order structures, and equivariant networks for 3D geometries (Simonovsky and Komodakis, 2017; Batzner et al., 2022).\n\nPretraining strategies on large unlabeled molecule corpora with contrastive or masked node prediction objectives have further improved generalization, especially in low-data regimes (Hu et al., 2020; Rong et al., 2020).\nIntroduction\n\nAutomated analysis of pathology whole-slide images (WSIs) faces extreme resolution, sparse lesion patterns, and distribution shifts across scanners and staining protocols. Convolutional networks have advanced the field but can be limited in modeling long-range dependencies over gigapixel slides.\n\nVision Transformers have been applied to medical image classification, segmentation, and detection with pure transformer backbones or hybrid CNN\u2013Transformer designs (Dosovitskiy et al., 2020; Chen et al., 2021; Hatamizadeh et al., 2022; Wang et al., 2021; Xie et al., 2021).\n\nWeakly supervised multiple-instance learning (MIL) further alleviates slide-level labeling costs by aggregating patch evidence, yet attention pooling can overfit to spurious correlations. We investigate whether token-level sparsification combined with instance reweighting can improve robustness in cross-site evaluation.\n\nOur method introduces a curriculum-sparse token selection and slide-consistent calibration loss to stabilize attention under domain shift. On three WSI benchmarks spanning different scanners, we observe gains in AUC and improved calibration, with minimal added compute.\n\nWe conduct ablations on sparsity schedules and release pretrained weights for community use.\nRelated Work\n\nRemote sensing change detection relies on robust representations that separate illumination and seasonal effects from structural changes. Recent advances in high-resolution satellites have shifted attention to fine-grained, building-level change cues.\n\nClassical two-stream CNNs, Siamese architectures, and attention-based models have been widely adopted for change detection (Daudt et al., 2018; Fang et al., 2020; Chen et al., 2021). Large-scale datasets such as LEVIR-CD, CDD, and WHU-CD have enabled benchmarking across urban scenes (Levir et al., 2020; Wang et al., 2020; Ji et al., 2019). Transformer-based encoders further improve long-range modeling (Ban et al., 2021; Liu et al., 2021).\n\nWhile these efforts improve accuracy, they largely assume perfectly registered image pairs and abundant labels. Our work targets label-scarce scenarios with misalignment by learning registration-aware tokens that disentangle geometry from appearance.\nIntroduction\n\nEffective human-robot collaboration requires balancing adaptability to user intent with guarantees on safety and task efficiency. Real-world deployments must operate under partial observability and distribution shifts in user behavior.\n\nShared autonomy techniques span predictive user intent modeling, POMDP-based assistance, arbitration policies that blend human and robot commands, and learning from demonstration for collaborative tasks (Dragan and Srinivasa, 2013; Javdani et al., 2015; Reddy et al., 2018; Losey et al., 2020).\n\nWe propose CertAssist, a certifiably safe shared autonomy framework combining control barrier functions with belief-dependent arbitration, evaluated on manipulation and navigation tasks with human participants.\nIntroduction\nAccurate forecasting underpins decision-making in supply chains, energy, and finance. Models must balance bias-variance trade-offs, handle sparse covariates, and remain robust to nonstationary shifts and irregular sampling.\n\nClassical time series forecasting relies on ARIMA and exponential smoothing to model linear dependencies (Box and Jenkins, 1970; Hyndman et al., 2008). Neural models introduce nonlinearity via RNNs, LSTMs, and temporal convolutions (Hochreiter and Schmidhuber, 1997; Bai et al., 2018). Transformer-based forecasters use attention to capture long-range dependencies (Li et al., 2019; Zhou et al., 2021). Decomposition and frequency-domain methods further reduce complexity and highlight seasonal structure (Oreshkin et al., 2020; Wu et al., 2021).\n\nWe present an uncertainty-aware spectral transformer that couples learnable seasonal kernels with interval calibration, yielding improved accuracy and coverage under regime shifts in retail and traffic datasets.\nRelated Work\n\nControllable text generation seeks to guide large language models (LLMs) toward specified attributes with minimal task-specific supervision. Recent approaches either modify inputs via prompts or adjust model parameters through lightweight adapters.\n\nPrompt-based methods for steering pre-trained language models have been explored in a variety of settings. Discrete prompt mining identifies trigger tokens that elicit desired behavior (Kim and Park, 2020; Zhou et al., 2021). Continuous prompt tuning replaces hard prompts with trainable embeddings (Li and Sung, 2021; Qin et al., 2022). Instruction following with few-shot exemplars has also been shown to improve task transfer (Rao and Lin, 2021; Xu et al., 2022).\n\nAdapter-based control introduces small task-specific modules into frozen backbones, enabling multi-task training while limiting memory costs (Chen et al., 2021; Gupta and Lee, 2022). Other lines include decoding constraints (He and Zhao, 2020) and classifier-guided re-ranking (Sharma et al., 2021).\n\nIn parallel, evaluation protocols for controllability measure attribute accuracy, content preservation, and fluency (Liu et al., 2020; Feng and Ma, 2021).\nRelated Work\n\nFederated learning enables collaborative training across a population of devices while keeping raw data local. The distributed setting raises new challenges in privacy, robustness, and communication efficiency.\n\nPrivacy in federated learning has been studied through differential privacy mechanisms for client updates (Abadi et al., 2016; McMahan et al., 2018), secure aggregation protocols to hide individual contributions (Bonawitz et al., 2017), split learning to keep raw data on-device (Gupta and Raskar, 2018), and cryptographic techniques like homomorphic encryption and MPC (Gentry, 2009; Mohassel and Zhang, 2017). Communication reduction has been addressed via sparsification and quantization (Stich et al., 2018; Kone\u010dn\u00fd et al., 2016).\n\nOur method jointly optimizes privacy noise allocation and gradient compression schedules under a fixed bandwidth budget.\nIntroduction\n\nUrban congestion degrades mobility, increases emissions, and undermines economic productivity. Adaptive traffic signal control promises to improve throughput by tailoring signal plans to real-time conditions. Reinforcement learning offers a data-driven framework to learn such policies directly from interaction.\n\nClassical traffic signal control uses handcrafted rules and model-based optimization (Webster, 1958; Gartner, 1983). RL-based approaches apply tabular Q-learning, deep Q-networks, and policy gradients to learn adaptive strategies (Abdoos et al., 2013; Van der Pol and Oliehoek, 2016; Wei et al., 2018). Multi-agent methods coordinate intersections via shared critics or communication (Chu et al., 2019; Zang et al., 2020; Chen et al., 2020). In this work, we propose a hierarchical actor-critic that decomposes phase selection and duration control.\n\nWe validate our approach on synthetic and real-world networks, showing gains in average travel time and queue length.\nRelated Work\n\nMultimodal summarization seeks to distill essential content by integrating complementary cues across text, images, and video. Approaches differ in the depth of fusion, supervision requirements, and the granularity of output (sentential vs. extractive vs. abstractive).\n\nEarly multimodal summarization methods fuse visual features with textual encoders (Li et al., 2017; Chen and Bansal, 2018). Video summarization leverages temporal attention and key-shot selection (Zhang et al., 2016; Rochan and Wang, 2019). Recent transformer-based models introduce cross-modal alignment modules (Liu et al., 2021; Zeng et al., 2022).\n\nDespite the progress, practical systems must handle noisy modalities and domain shifts. Our study focuses on robust alignment under weak supervision and evaluates consistency constraints that mitigate cross-modal mismatch.\nIntroduction\n\nLearning control policies in simulation and transferring them to real robots reduces data collection cost but introduces the reality gap problem. A wide range of techniques aim to close this gap by randomizing simulators or adapting policies.\n\nFor sim-to-real transfer in robotics, domain randomization perturbs textures and dynamics (Tobin et al., 2017; Peng et al., 2018), while domain adaptation aligns feature distributions (Tzeng et al., 2017; Ganin et al., 2016). Recent work leverages privileged information (Rajeswaran et al., 2017), online adaptation (Chebotar et al., 2019), and residual policy learning (Johannink et al., 2019).\n\nHardware-aware policy learning and safety constraints have been explored to ensure feasible trajectories under actuation limits (Dalal et al., 2018; Berkenkamp et al., 2017).\n\nWe evaluate a modular adaptation pipeline on manipulation and locomotion tasks.\n",
        "completion": "For sim-to-real transfer in robotics, domain randomization perturbs textures and dynamics (Tobin et al., 2017; Peng et al., 2018), while domain adaptation aligns feature distributions (Tzeng et al., 2017; Ganin et al., 2016). Recent work leverages privileged information (Rajeswaran et al., 2017), online adaptation (Chebotar et al., 2019), and residual policy learning (Johannink et al., 2019)."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        occurs when either:\n    a) The author describes or cites papers without connecting them to their own work/argument \n    b) Or only follows up the summary of previous works with their own contribution without explicitly highlighting the gap their work intends to research.\n    c) It does not articulate the author's perspective or motivation.\n    d) A lack of argument/opinion in the first paragraph is permissible as it serves to be the foundation of the author's argument \n    e) Lacks synthesis issues appear either as single sentences or multiple sentences.\n    Examples of lack of synthesis include:\n        i) No elaboration of own contribution/argument:\"Following early neural approaches to question answering, many subsequent studies adopt a pipeline architecture consisting of retrieval and comprehension components. The retrieval component focuses on identifying relevant documents or passages from a large corpus, while the comprehension component extracts an answer span from the retrieved text. Initial models relied on recurrent neural networks with attention mechanisms to encode questions and contexts (Seo et al., 2017; Wang et al., 2017).\"\n        ii)  No explanation of the cited works and relation to their own work: \u201cRecently, several studies have explored the use of prompting techniques with pre-trained language models to influence model outputs or access latent knowledge (Brown et al., 2020; Gao et al., 2021; Liu et al., 2021; Wei et al., 2022).\u201d \n\n        Example text: \n        Related Work\n\nDevelopers rely on code search to find relevant snippets, APIs, or examples. Unlike general document retrieval, code search must bridge natural language intent and program structure.\n\nNeural code search has been addressed with bi-encoders, cross-encoders, and dual learning (Gu et al., 2018; Husain et al., 2019; Feng et al., 2020). Structural representations incorporate ASTs, control flow, and data flow (Alon et al., 2019; Wang et al., 2020; Liu et al., 2021). Pretraining on code and NL improves retrieval metrics across languages (Ahmad et al., 2021; Guo et al., 2021).\n\nIn this paper, we introduce a language-agnostic retriever with compositional queries.\n\nWe evaluate zero-shot transfer across four programming languages.\nIntroduction\n\nGeneralization in text classification can be improved with data augmentation, especially when labeled data are scarce or imbalanced. Approaches range from rule-based edits to model-driven paraphrasing and representation-space mixing.\n\nText augmentation techniques include synonym replacement, random insertion/deletion, back-translation, paraphrase generation, and mixup in embedding or hidden spaces (Wei and Zou, 2019; Sennrich et al., 2016; Kobayashi, 2018; Guo et al., 2020). Recent work explores task-adaptive augmentation policies learned by reinforcement learning (Xie et al., 2020).\n\nEvaluation typically considers robustness to domain shift, label noise, and distributional skew across multiple benchmarks (Pruksachatkun et al., 2020; Hendrycks et al., 2020).\nRelated Work\n\nKnowledge graph completion predicts missing links by learning entity and relation representations. Methods vary in how they encode semantics and handle patterns like symmetry, hierarchy, and composition.\n\nTranslation-based knowledge graph embeddings model relations as translations in vector space (Bordes et al., 2013; Wang et al., 2014), while bilinear and neural models capture more complex interactions (Nickel et al., 2011; Trouillon et al., 2016; Sun et al., 2019). Regularization and rule-guided approaches improve inductive bias and data efficiency (Rockt\u00e4schel et al., 2015; Minervini et al., 2017).\n\nWe introduce a lightweight compositional constraint for hierarchical relations and evaluate on three benchmarks and an industry dataset.\nRelated Work\n\nEnsuring safety during reinforcement learning is critical in real-world control where violations can be costly. Research has proposed both objective-level and mechanism-level solutions.\n\nSafe reinforcement learning approaches include risk-sensitive objectives such as CVaR optimization (Tamar et al., 2015; Chow et al., 2018), constrained policy optimization with safety budgets (Achiam et al., 2017; Yang et al., 2020), and shielding based on model-checking or supervisors (Alshiekh et al., 2018; Dalal et al., 2018). We develop a method that integrates model-predictive constraints with policy gradients.\n\nBenchmarks often evaluate safety in simulated robotics or navigation with cost functions approximating constraint violations (Ray et al., 2019; Bharadhwaj et al., 2021).\nRelated Work\n\nDialog state tracking (DST) has evolved from rule-based slot filling to neural architectures that jointly infer belief states across turns. Early pipeline models used hand-crafted lexicons and semantic frames (Singh and Patel, 2015), but suffered from brittleness to paraphrase and noise. Neural encoders introduced robustness by contextualizing utterances, incorporating attention over dialog history, and modeling slot-value dependencies (Lee et al., 2018; Choe and Kim, 2019).\n\nPretrained language models have further shifted the landscape by enabling few-shot generalization and open-vocabulary slot values. Fine-tuning BERT-like encoders for DST improved cross-domain transfer (Rao et al., 2020), while generative formulations cast state tracking as text-to-text prediction (Mendez et al., 2021).\n\nPrompting-based approaches have also been explored for dialog modeling (Kumar et al., 2021; Ortega and Lin, 2022; Park et al., 2023). These methods condition large language models on task instructions or few-shot exemplars to elicit latent conversational knowledge. Recent variants incorporate calibration or self-consistency to stabilize outputs (Fang et al., 2023; Zhou et al., 2023).\n\nPosition relative to this paper While we also employ pretrained sequence-to-sequence models, our focus is on handling ontology drift in long-running deployments. Specifically, we introduce an adaptive slot schema encoder that aligns evolving taxonomies with dialog evidence, and a contrastive consistency objective to mitigate spurious slot co-activations across domains.\nIntroduction\n\nSelf-supervised learning (SSL) has become the dominant paradigm for learning transferable visual features without labels. By constructing pretext tasks that expose invariances and structure inherent in data, SSL models can match or surpass supervised baselines on many downstream tasks.\n\nContrastive pretraining has been widely adopted for visual representations (Chen et al., 2020; He et al., 2020; Xie and Xu, 2021). Non-contrastive methods remove negative pairs and rely on architectural or objective asymmetries (Grill et al., 2020; Tian et al., 2021). Clustering-based methods jointly learn assignments and embeddings (Caron et al., 2018; Li and Gao, 2022).\n\nDespite these advances, industrial applications often operate under strict memory budgets and latency constraints. In this paper, we investigate compute-aware pretraining objectives that couple multi-crop augmentation with a token-subsampled backbone. We present a latency-regularized alignment loss that preserves downstream accuracy while reducing FLOPs during both pretraining and fine-tuning.\nIntroduction\n\nEfficient exploration remains a central challenge in reinforcement learning (RL), particularly in sparse-reward environments where naive strategies fail to discover rewarding states. Over-exploration, however, can waste samples and destabilize learning.\n\nExploration in reinforcement learning has been advanced by count-based bonuses, intrinsic motivation, curiosity-driven prediction error, and information-theoretic objectives (Bellemare et al., 2016; Pathak et al., 2017; Houthooft et al., 2016; Burda et al., 2019; Ta\u00efga et al., 2020).\n\nYet, when environment dynamics change over time, stale novelty estimates can encourage revisiting obsolete states. We propose a recency-aware intrinsic reward that discounts outdated novelty and couples it with conservative policy updates.\n\nAcross Atari and continuous-control domains with drifting dynamics, our method achieves superior sample efficiency and stability, and ablations confirm the role of recency in balancing exploration and exploitation.\nRelated Work\n\nDetecting anomalies in multivariate time series is vital for monitoring industrial systems and cloud services. The challenge lies in handling seasonality, rare events, and inter-variable dependencies.\n\nClassical anomaly detection leverages ARIMA residual tests, STL decomposition, and control charts, while deep methods introduce autoencoders, VAEs, GANs, LSTMs, and Transformers for reconstruction or prediction errors (Tsay, 2010; Malhotra et al., 2015; An and Cho, 2015; Li et al., 2019; Xu et al., 2021).\n\nWe present Contrastive Forecasting with Graph Priors (CFGP), which learns structure-aware representations via self-supervised objectives and uses calibrated predictive intervals to flag anomalies.\nIntroduction\n\nGeneralizing manipulation skills across objects, tasks, and environments remains a central challenge in robotics. Sparse rewards, safety constraints, and hardware variability complicate learning on physical systems. Recent work studies imitation learning, offline RL, and model-based control for dexterous manipulation (Rajeswaran et al., 2018; Lynch et al., 2020; Nagabandi et al., 2019; Ahn et al., 2022). Despite these advances, scaling data collection and ensuring sim-to-real transfer continue to be bottlenecks.\n\nWe explore a curriculum that interleaves skill discovery from teleoperation logs with conservative online updates, targeting stable improvements under limited interaction budgets.\nRelated Work\n\nConversational recommenders. Systems that interactively elicit user preferences can reduce cold-start and improve satisfaction (Sun and Zhang, 2018). Dialog policy learning for conversational recommendation has explored supervised learning, reinforcement learning, and bandit methods (Christakopoulou et al., 2016; Lei et al., 2020; Chen et al., 2019). User simulators and counterfactual logging have been proposed to address data scarcity and evaluation challenges (Li et al., 2017; Chi et al., 2020).\n\nOur study investigates preference drift over long-horizon sessions and proposes a state representation that explicitly tracks uncertainty and recency effects.\nIntroduction\n\nExplainable AI (XAI) is increasingly required for medical imaging systems used in screening and triage. Beyond predictive accuracy, clinicians demand transparency about what image features drive automated decisions and whether explanations are stable under shifts.\n\nPost-hoc attribution methods like Grad-CAM and Integrated Gradients highlight salient regions (Selvaraju et al., 2017; Sundararajan et al., 2017). Prototype- and concept-based explanations enhance interpretability (Chen et al., 2019; Kim et al., 2018). Counterfactual generation has been explored for medical images (Chang et al., 2018; Singla et al., 2021).\n\nWe focus on faithfulness under distribution shift and propose an evaluation protocol that aligns explanation stability with clinical acceptance thresholds for screening workflows.\nRelated Work\n\nProviding timely, actionable feedback at scale is central to computing education. Traditional approaches combine instructor-designed rubrics with automated tests, but coverage and specificity can be limited for diverse student solutions.\n\nAutomated feedback for programming assignments has been tackled with static analysis, dynamic test generation, and pattern mining (Ke et al., 2016; Gulwani et al., 2018; Singh et al., 2013). Recent NLP-based systems leverage code embeddings, sequence models, and pretrained language models (Allamanis et al., 2018; Feng et al., 2020; Ahmad et al., 2021). Peer learning platforms collect hints and exemplars to guide novice programmers (Piech et al., 2015; Wang et al., 2018).\n\nWhile data-driven approaches show promise, they often struggle with generalizing across tasks and providing pedagogically aligned guidance. Our work investigates structure-aware hint generation that aligns feedback to conceptual steps in problem-solving.\nRelated Work\n\nReinforcement learning (RL) has enabled robots to acquire complex behaviors directly from interaction. However, data hunger, safety, and sim-to-real transfer remain persistent obstacles for deployment in real-world settings.\n\nModel-free methods such as DDPG (Lillicrap et al., 2016), SAC (Haarnoja et al., 2018), and PPO (Schulman et al., 2017) have been widely adopted for continuous control, while model-based approaches leverage learned dynamics for sample efficiency (Deisenroth and Rasmussen, 2011; Chua et al., 2018). Recent lines of work explore offline RL (Levine et al., 2020; Kumar et al., 2020) and representation learning for policy generalization (Laskin et al., 2020; Yarats et al., 2021). Domain randomization and adaptation seek to bridge the sim-to-real gap (Tobin et al., 2017; Peng et al., 2018).\n\nWe propose a training strategy that combines curriculum learning with uncertainty-aware policy updates to improve safety and sample efficiency in robotic manipulation.\nRelated Work\n\nAutomatic speech recognition (ASR) systems increasingly rely on large encoder\u2013decoder architectures that are costly to deploy on edge devices. Knowledge distillation (KD) is a common strategy to reduce model size while preserving accuracy.\n\nKnowledge distillation for speech recognition has considered frame-level supervision, sequence-level criteria, and wordpiece distributions, transferring knowledge from stronger teachers to smaller students (Hinton et al., 2015; Kim and Rush, 2016; Kurata and Audhkhasi, 2018; Higuchi et al., 2021).\n\nOther compression techniques include quantization and pruning, which can be combined with KD but may degrade robustness to noise and speaker variability. Recent work explores multi-teacher ensembles and intermediate-layer matching to stabilize training.\n\nIn this paper, we study streaming-constrained KD with latency-aware targets, aligning teacher and student under causal masking. Our experiments on LibriSpeech and far-field corpora show improved WER\u2013latency trade-offs compared to strong baselines.\nRelated Work\n\nLarge Language Models and Prompting\nLarge language models (LLMs) exhibit emergent program synthesis capabilities when conditioned on natural language instructions and a handful of examples. While these behaviors reduce reliance on supervised datasets, the mechanisms by which prompts control generation remain only partially understood. Prior studies analyze calibration, decoding strategies, and context length effects.\n\nPrompting for Code Generation\nPrompting for code generation has explored zero-shot, few-shot, and chain-of-thought styles using large language models (Chen et al., 2021; Austin et al., 2021; Nijkamp et al., 2022; Li et al., 2023). Work on compiler-aware prompting adds execution feedback to steer generation (Liu et al., 2022; Le et al., 2022; Wang et al., 2023). Program repair and test-driven synthesis have similarly adapted prompting strategies to satisfy unit tests (Jain et al., 2022; Zhang et al., 2023).\n\nExecution-Conditioned Decoding\nBeyond static prompts, execution-conditioned decoding iteratively runs partial programs to reduce search space. Studies report gains on algorithmic problems by interleaving generation and verification under timeouts and sandboxing constraints.\n\nStructured Constraints and Type Guidance\nApproaches that inject grammar constraints or type information restrict invalid outputs and improve pass rates. These methods range from constrained beam search to type-state automata.\n\nPositioning\nWe examine the interaction between prompt structure and execution feedback and study how typed constraints alter search dynamics under limited budgets.\nRelated Work\n\nFederated learning (FL) enables on-device training with privacy and communication constraints. Ensuring rigorous privacy guarantees while preserving model utility remains a core challenge.\n\nPrivacy in federated learning has been studied via differential privacy at the client level, secure aggregation, and shuffling (McMahan et al., 2017; Kairouz et al., 2021; Bonawitz et al., 2017; Erlingsson et al., 2019). Gradient perturbation, clipping, and client subsampling are common techniques to control privacy loss (Abadi et al., 2016; Thakkar et al., 2019; Andrew et al., 2021). Auditing methods estimate empirical privacy leakage post hoc (Nasr et al., 2019; Jagielski et al., 2020).\n\nOur approach introduces client-adaptive noise schedules conditioned on participation frequency.\n\nWe empirically evaluate privacy-utility trade-offs across heterogeneous client populations.\nIntroduction\n\nInformation retrieval has shifted from lexical term matching to semantic representations that capture contextual meaning. This shift enables better recall of paraphrased content but introduces new challenges in index efficiency and training stability.\n\nNeural semantic search methods combine dual-encoders for efficient retrieval (Yao et al., 2019; Xie and Zhao, 2020) with cross-encoders for reranking (Nogueira and Cho, 2019; Li et al., 2021), and leverage hard-negative mining to improve discriminative power (Gao et al., 2021; Huang et al., 2022). Recent work also explores domain adaptation for specialized corpora such as legal and biomedical texts (Park et al., 2022; Sun et al., 2023).\n\nWe study lightweight domain adaptation under tight indexing budgets.\nRelated Work\n\nDetecting anomalies in time-series is a long-standing problem with applications in monitoring, finance, and industrial IoT. Methods vary widely in assumptions, supervision requirements, and scalability.\n\nTime-series anomaly detection spans classical statistical tests, isolation-based methods, and deep learning models such as autoencoders, temporal convolutional networks, and Transformers (Gupta et al., 2014; Liu et al., 2008; Malhotra et al., 2016; Xu et al., 2020). Synthetic anomaly injection and semi-supervised training are also common practices (Zhang et al., 2019; Shen et al., 2021).\n\nBenchmarking efforts have sought consistent evaluation protocols across datasets with different anomaly types and frequencies (Hundman et al., 2018; Wu and Keogh, 2021).\nRelated Work\n\nPredicting molecular properties from structure has catalyzed a broad literature at the intersection of cheminformatics and geometric deep learning. Approaches differ in how they encode graph topology, chemical attributes, and geometric constraints.\n\nGraph representation learning methods such as spectral GCNs, spatial message passing networks, and attention-based GNNs have been widely applied to molecular property prediction (Kipf and Welling, 2017; Gilmer et al., 2017; Veli\u010dkovi\u0107 et al., 2018). Extensions include edge-conditioned convolutions, higher-order structures, and equivariant networks for 3D geometries (Simonovsky and Komodakis, 2017; Batzner et al., 2022).\n\nPretraining strategies on large unlabeled molecule corpora with contrastive or masked node prediction objectives have further improved generalization, especially in low-data regimes (Hu et al., 2020; Rong et al., 2020).\nIntroduction\n\nAutomated analysis of pathology whole-slide images (WSIs) faces extreme resolution, sparse lesion patterns, and distribution shifts across scanners and staining protocols. Convolutional networks have advanced the field but can be limited in modeling long-range dependencies over gigapixel slides.\n\nVision Transformers have been applied to medical image classification, segmentation, and detection with pure transformer backbones or hybrid CNN\u2013Transformer designs (Dosovitskiy et al., 2020; Chen et al., 2021; Hatamizadeh et al., 2022; Wang et al., 2021; Xie et al., 2021).\n\nWeakly supervised multiple-instance learning (MIL) further alleviates slide-level labeling costs by aggregating patch evidence, yet attention pooling can overfit to spurious correlations. We investigate whether token-level sparsification combined with instance reweighting can improve robustness in cross-site evaluation.\n\nOur method introduces a curriculum-sparse token selection and slide-consistent calibration loss to stabilize attention under domain shift. On three WSI benchmarks spanning different scanners, we observe gains in AUC and improved calibration, with minimal added compute.\n\nWe conduct ablations on sparsity schedules and release pretrained weights for community use.\nRelated Work\n\nRemote sensing change detection relies on robust representations that separate illumination and seasonal effects from structural changes. Recent advances in high-resolution satellites have shifted attention to fine-grained, building-level change cues.\n\nClassical two-stream CNNs, Siamese architectures, and attention-based models have been widely adopted for change detection (Daudt et al., 2018; Fang et al., 2020; Chen et al., 2021). Large-scale datasets such as LEVIR-CD, CDD, and WHU-CD have enabled benchmarking across urban scenes (Levir et al., 2020; Wang et al., 2020; Ji et al., 2019). Transformer-based encoders further improve long-range modeling (Ban et al., 2021; Liu et al., 2021).\n\nWhile these efforts improve accuracy, they largely assume perfectly registered image pairs and abundant labels. Our work targets label-scarce scenarios with misalignment by learning registration-aware tokens that disentangle geometry from appearance.\nIntroduction\n\nEffective human-robot collaboration requires balancing adaptability to user intent with guarantees on safety and task efficiency. Real-world deployments must operate under partial observability and distribution shifts in user behavior.\n\nShared autonomy techniques span predictive user intent modeling, POMDP-based assistance, arbitration policies that blend human and robot commands, and learning from demonstration for collaborative tasks (Dragan and Srinivasa, 2013; Javdani et al., 2015; Reddy et al., 2018; Losey et al., 2020).\n\nWe propose CertAssist, a certifiably safe shared autonomy framework combining control barrier functions with belief-dependent arbitration, evaluated on manipulation and navigation tasks with human participants.\nIntroduction\nAccurate forecasting underpins decision-making in supply chains, energy, and finance. Models must balance bias-variance trade-offs, handle sparse covariates, and remain robust to nonstationary shifts and irregular sampling.\n\nClassical time series forecasting relies on ARIMA and exponential smoothing to model linear dependencies (Box and Jenkins, 1970; Hyndman et al., 2008). Neural models introduce nonlinearity via RNNs, LSTMs, and temporal convolutions (Hochreiter and Schmidhuber, 1997; Bai et al., 2018). Transformer-based forecasters use attention to capture long-range dependencies (Li et al., 2019; Zhou et al., 2021). Decomposition and frequency-domain methods further reduce complexity and highlight seasonal structure (Oreshkin et al., 2020; Wu et al., 2021).\n\nWe present an uncertainty-aware spectral transformer that couples learnable seasonal kernels with interval calibration, yielding improved accuracy and coverage under regime shifts in retail and traffic datasets.\nRelated Work\n\nControllable text generation seeks to guide large language models (LLMs) toward specified attributes with minimal task-specific supervision. Recent approaches either modify inputs via prompts or adjust model parameters through lightweight adapters.\n\nPrompt-based methods for steering pre-trained language models have been explored in a variety of settings. Discrete prompt mining identifies trigger tokens that elicit desired behavior (Kim and Park, 2020; Zhou et al., 2021). Continuous prompt tuning replaces hard prompts with trainable embeddings (Li and Sung, 2021; Qin et al., 2022). Instruction following with few-shot exemplars has also been shown to improve task transfer (Rao and Lin, 2021; Xu et al., 2022).\n\nAdapter-based control introduces small task-specific modules into frozen backbones, enabling multi-task training while limiting memory costs (Chen et al., 2021; Gupta and Lee, 2022). Other lines include decoding constraints (He and Zhao, 2020) and classifier-guided re-ranking (Sharma et al., 2021).\n\nIn parallel, evaluation protocols for controllability measure attribute accuracy, content preservation, and fluency (Liu et al., 2020; Feng and Ma, 2021).\nRelated Work\n\nFederated learning enables collaborative training across a population of devices while keeping raw data local. The distributed setting raises new challenges in privacy, robustness, and communication efficiency.\n\nPrivacy in federated learning has been studied through differential privacy mechanisms for client updates (Abadi et al., 2016; McMahan et al., 2018), secure aggregation protocols to hide individual contributions (Bonawitz et al., 2017), split learning to keep raw data on-device (Gupta and Raskar, 2018), and cryptographic techniques like homomorphic encryption and MPC (Gentry, 2009; Mohassel and Zhang, 2017). Communication reduction has been addressed via sparsification and quantization (Stich et al., 2018; Kone\u010dn\u00fd et al., 2016).\n\nOur method jointly optimizes privacy noise allocation and gradient compression schedules under a fixed bandwidth budget.\nIntroduction\n\nUrban congestion degrades mobility, increases emissions, and undermines economic productivity. Adaptive traffic signal control promises to improve throughput by tailoring signal plans to real-time conditions. Reinforcement learning offers a data-driven framework to learn such policies directly from interaction.\n\nClassical traffic signal control uses handcrafted rules and model-based optimization (Webster, 1958; Gartner, 1983). RL-based approaches apply tabular Q-learning, deep Q-networks, and policy gradients to learn adaptive strategies (Abdoos et al., 2013; Van der Pol and Oliehoek, 2016; Wei et al., 2018). Multi-agent methods coordinate intersections via shared critics or communication (Chu et al., 2019; Zang et al., 2020; Chen et al., 2020). In this work, we propose a hierarchical actor-critic that decomposes phase selection and duration control.\n\nWe validate our approach on synthetic and real-world networks, showing gains in average travel time and queue length.\nRelated Work\n\nMultimodal summarization seeks to distill essential content by integrating complementary cues across text, images, and video. Approaches differ in the depth of fusion, supervision requirements, and the granularity of output (sentential vs. extractive vs. abstractive).\n\nEarly multimodal summarization methods fuse visual features with textual encoders (Li et al., 2017; Chen and Bansal, 2018). Video summarization leverages temporal attention and key-shot selection (Zhang et al., 2016; Rochan and Wang, 2019). Recent transformer-based models introduce cross-modal alignment modules (Liu et al., 2021; Zeng et al., 2022).\n\nDespite the progress, practical systems must handle noisy modalities and domain shifts. Our study focuses on robust alignment under weak supervision and evaluates consistency constraints that mitigate cross-modal mismatch.\nIntroduction\n\nLearning control policies in simulation and transferring them to real robots reduces data collection cost but introduces the reality gap problem. A wide range of techniques aim to close this gap by randomizing simulators or adapting policies.\n\nFor sim-to-real transfer in robotics, domain randomization perturbs textures and dynamics (Tobin et al., 2017; Peng et al., 2018), while domain adaptation aligns feature distributions (Tzeng et al., 2017; Ganin et al., 2016). Recent work leverages privileged information (Rajeswaran et al., 2017), online adaptation (Chebotar et al., 2019), and residual policy learning (Johannink et al., 2019).\n\nHardware-aware policy learning and safety constraints have been explored to ensure feasible trajectories under actuation limits (Dalal et al., 2018; Berkenkamp et al., 2017).\n\nWe evaluate a modular adaptation pipeline on manipulation and locomotion tasks.\nRelated Work\n\nMedical image segmentation has long relied on convolutional architectures such as U-Net and its variants due to their inductive biases and efficiency (Ronneberger et al., 2015; Milletari et al., 2016). Recent progress in self-attention and transformers has motivated their application to dense prediction.\n\nTransformer-based segmentation has been explored through pure-ViT decoders, hybrid CNN\u2013ViT backbones, and pyramid tokens (Chen et al., 2021; Strudel et al., 2021; Xie et al., 2021). Medical adaptations include axial attention, windowed self-attention, and lightweight transformers (Wang et al., 2021; Hatamizadeh et al., 2022; Chen et al., 2022). Further studies consider multi-scale fusion and boundary-aware losses (Oktay et al., 2018; Kirillov et al., 2020; Zhao et al., 2017).\n\nRecent benchmarks reveal the sensitivity of ViT-based models to training data size and augmentation strategies (Dosovitskiy et al., 2021; Touvron et al., 2021). However, clinical datasets remain small and heterogeneous, posing challenges for generalization.\n\nWe present a compact hybrid that targets data efficiency by constraining attention spans and sharing parameters across scales, evaluating on multi-institutional MRI and CT cohorts.\n",
        "completion": "Transformer-based segmentation has been explored through pure-ViT decoders, hybrid CNN\u2013ViT backbones, and pyramid tokens (Chen et al., 2021; Strudel et al., 2021; Xie et al., 2021). Medical adaptations include axial attention, windowed self-attention, and lightweight transformers (Wang et al., 2021; Hatamizadeh et al., 2022; Chen et al., 2022). Further studies consider multi-scale fusion and boundary-aware losses (Oktay et al., 2018; Kirillov et al., 2020; Zhao et al., 2017)."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        occurs when either:\n    a) The author describes or cites papers without connecting them to their own work/argument \n    b) Or only follows up the summary of previous works with their own contribution without explicitly highlighting the gap their work intends to research.\n    c) It does not articulate the author's perspective or motivation.\n    d) A lack of argument/opinion in the first paragraph is permissible as it serves to be the foundation of the author's argument \n    e) Lacks synthesis issues appear either as single sentences or multiple sentences.\n    Examples of lack of synthesis include:\n        i) No elaboration of own contribution/argument:\"Following early neural approaches to question answering, many subsequent studies adopt a pipeline architecture consisting of retrieval and comprehension components. The retrieval component focuses on identifying relevant documents or passages from a large corpus, while the comprehension component extracts an answer span from the retrieved text. Initial models relied on recurrent neural networks with attention mechanisms to encode questions and contexts (Seo et al., 2017; Wang et al., 2017).\"\n        ii)  No explanation of the cited works and relation to their own work: \u201cRecently, several studies have explored the use of prompting techniques with pre-trained language models to influence model outputs or access latent knowledge (Brown et al., 2020; Gao et al., 2021; Liu et al., 2021; Wei et al., 2022).\u201d \n\n        Example text: \n        Related Work\n\nDevelopers rely on code search to find relevant snippets, APIs, or examples. Unlike general document retrieval, code search must bridge natural language intent and program structure.\n\nNeural code search has been addressed with bi-encoders, cross-encoders, and dual learning (Gu et al., 2018; Husain et al., 2019; Feng et al., 2020). Structural representations incorporate ASTs, control flow, and data flow (Alon et al., 2019; Wang et al., 2020; Liu et al., 2021). Pretraining on code and NL improves retrieval metrics across languages (Ahmad et al., 2021; Guo et al., 2021).\n\nIn this paper, we introduce a language-agnostic retriever with compositional queries.\n\nWe evaluate zero-shot transfer across four programming languages.\nIntroduction\n\nGeneralization in text classification can be improved with data augmentation, especially when labeled data are scarce or imbalanced. Approaches range from rule-based edits to model-driven paraphrasing and representation-space mixing.\n\nText augmentation techniques include synonym replacement, random insertion/deletion, back-translation, paraphrase generation, and mixup in embedding or hidden spaces (Wei and Zou, 2019; Sennrich et al., 2016; Kobayashi, 2018; Guo et al., 2020). Recent work explores task-adaptive augmentation policies learned by reinforcement learning (Xie et al., 2020).\n\nEvaluation typically considers robustness to domain shift, label noise, and distributional skew across multiple benchmarks (Pruksachatkun et al., 2020; Hendrycks et al., 2020).\nRelated Work\n\nKnowledge graph completion predicts missing links by learning entity and relation representations. Methods vary in how they encode semantics and handle patterns like symmetry, hierarchy, and composition.\n\nTranslation-based knowledge graph embeddings model relations as translations in vector space (Bordes et al., 2013; Wang et al., 2014), while bilinear and neural models capture more complex interactions (Nickel et al., 2011; Trouillon et al., 2016; Sun et al., 2019). Regularization and rule-guided approaches improve inductive bias and data efficiency (Rockt\u00e4schel et al., 2015; Minervini et al., 2017).\n\nWe introduce a lightweight compositional constraint for hierarchical relations and evaluate on three benchmarks and an industry dataset.\nRelated Work\n\nEnsuring safety during reinforcement learning is critical in real-world control where violations can be costly. Research has proposed both objective-level and mechanism-level solutions.\n\nSafe reinforcement learning approaches include risk-sensitive objectives such as CVaR optimization (Tamar et al., 2015; Chow et al., 2018), constrained policy optimization with safety budgets (Achiam et al., 2017; Yang et al., 2020), and shielding based on model-checking or supervisors (Alshiekh et al., 2018; Dalal et al., 2018). We develop a method that integrates model-predictive constraints with policy gradients.\n\nBenchmarks often evaluate safety in simulated robotics or navigation with cost functions approximating constraint violations (Ray et al., 2019; Bharadhwaj et al., 2021).\nRelated Work\n\nDialog state tracking (DST) has evolved from rule-based slot filling to neural architectures that jointly infer belief states across turns. Early pipeline models used hand-crafted lexicons and semantic frames (Singh and Patel, 2015), but suffered from brittleness to paraphrase and noise. Neural encoders introduced robustness by contextualizing utterances, incorporating attention over dialog history, and modeling slot-value dependencies (Lee et al., 2018; Choe and Kim, 2019).\n\nPretrained language models have further shifted the landscape by enabling few-shot generalization and open-vocabulary slot values. Fine-tuning BERT-like encoders for DST improved cross-domain transfer (Rao et al., 2020), while generative formulations cast state tracking as text-to-text prediction (Mendez et al., 2021).\n\nPrompting-based approaches have also been explored for dialog modeling (Kumar et al., 2021; Ortega and Lin, 2022; Park et al., 2023). These methods condition large language models on task instructions or few-shot exemplars to elicit latent conversational knowledge. Recent variants incorporate calibration or self-consistency to stabilize outputs (Fang et al., 2023; Zhou et al., 2023).\n\nPosition relative to this paper While we also employ pretrained sequence-to-sequence models, our focus is on handling ontology drift in long-running deployments. Specifically, we introduce an adaptive slot schema encoder that aligns evolving taxonomies with dialog evidence, and a contrastive consistency objective to mitigate spurious slot co-activations across domains.\nIntroduction\n\nSelf-supervised learning (SSL) has become the dominant paradigm for learning transferable visual features without labels. By constructing pretext tasks that expose invariances and structure inherent in data, SSL models can match or surpass supervised baselines on many downstream tasks.\n\nContrastive pretraining has been widely adopted for visual representations (Chen et al., 2020; He et al., 2020; Xie and Xu, 2021). Non-contrastive methods remove negative pairs and rely on architectural or objective asymmetries (Grill et al., 2020; Tian et al., 2021). Clustering-based methods jointly learn assignments and embeddings (Caron et al., 2018; Li and Gao, 2022).\n\nDespite these advances, industrial applications often operate under strict memory budgets and latency constraints. In this paper, we investigate compute-aware pretraining objectives that couple multi-crop augmentation with a token-subsampled backbone. We present a latency-regularized alignment loss that preserves downstream accuracy while reducing FLOPs during both pretraining and fine-tuning.\nIntroduction\n\nEfficient exploration remains a central challenge in reinforcement learning (RL), particularly in sparse-reward environments where naive strategies fail to discover rewarding states. Over-exploration, however, can waste samples and destabilize learning.\n\nExploration in reinforcement learning has been advanced by count-based bonuses, intrinsic motivation, curiosity-driven prediction error, and information-theoretic objectives (Bellemare et al., 2016; Pathak et al., 2017; Houthooft et al., 2016; Burda et al., 2019; Ta\u00efga et al., 2020).\n\nYet, when environment dynamics change over time, stale novelty estimates can encourage revisiting obsolete states. We propose a recency-aware intrinsic reward that discounts outdated novelty and couples it with conservative policy updates.\n\nAcross Atari and continuous-control domains with drifting dynamics, our method achieves superior sample efficiency and stability, and ablations confirm the role of recency in balancing exploration and exploitation.\nRelated Work\n\nDetecting anomalies in multivariate time series is vital for monitoring industrial systems and cloud services. The challenge lies in handling seasonality, rare events, and inter-variable dependencies.\n\nClassical anomaly detection leverages ARIMA residual tests, STL decomposition, and control charts, while deep methods introduce autoencoders, VAEs, GANs, LSTMs, and Transformers for reconstruction or prediction errors (Tsay, 2010; Malhotra et al., 2015; An and Cho, 2015; Li et al., 2019; Xu et al., 2021).\n\nWe present Contrastive Forecasting with Graph Priors (CFGP), which learns structure-aware representations via self-supervised objectives and uses calibrated predictive intervals to flag anomalies.\nIntroduction\n\nGeneralizing manipulation skills across objects, tasks, and environments remains a central challenge in robotics. Sparse rewards, safety constraints, and hardware variability complicate learning on physical systems. Recent work studies imitation learning, offline RL, and model-based control for dexterous manipulation (Rajeswaran et al., 2018; Lynch et al., 2020; Nagabandi et al., 2019; Ahn et al., 2022). Despite these advances, scaling data collection and ensuring sim-to-real transfer continue to be bottlenecks.\n\nWe explore a curriculum that interleaves skill discovery from teleoperation logs with conservative online updates, targeting stable improvements under limited interaction budgets.\nRelated Work\n\nConversational recommenders. Systems that interactively elicit user preferences can reduce cold-start and improve satisfaction (Sun and Zhang, 2018). Dialog policy learning for conversational recommendation has explored supervised learning, reinforcement learning, and bandit methods (Christakopoulou et al., 2016; Lei et al., 2020; Chen et al., 2019). User simulators and counterfactual logging have been proposed to address data scarcity and evaluation challenges (Li et al., 2017; Chi et al., 2020).\n\nOur study investigates preference drift over long-horizon sessions and proposes a state representation that explicitly tracks uncertainty and recency effects.\nIntroduction\n\nExplainable AI (XAI) is increasingly required for medical imaging systems used in screening and triage. Beyond predictive accuracy, clinicians demand transparency about what image features drive automated decisions and whether explanations are stable under shifts.\n\nPost-hoc attribution methods like Grad-CAM and Integrated Gradients highlight salient regions (Selvaraju et al., 2017; Sundararajan et al., 2017). Prototype- and concept-based explanations enhance interpretability (Chen et al., 2019; Kim et al., 2018). Counterfactual generation has been explored for medical images (Chang et al., 2018; Singla et al., 2021).\n\nWe focus on faithfulness under distribution shift and propose an evaluation protocol that aligns explanation stability with clinical acceptance thresholds for screening workflows.\nRelated Work\n\nProviding timely, actionable feedback at scale is central to computing education. Traditional approaches combine instructor-designed rubrics with automated tests, but coverage and specificity can be limited for diverse student solutions.\n\nAutomated feedback for programming assignments has been tackled with static analysis, dynamic test generation, and pattern mining (Ke et al., 2016; Gulwani et al., 2018; Singh et al., 2013). Recent NLP-based systems leverage code embeddings, sequence models, and pretrained language models (Allamanis et al., 2018; Feng et al., 2020; Ahmad et al., 2021). Peer learning platforms collect hints and exemplars to guide novice programmers (Piech et al., 2015; Wang et al., 2018).\n\nWhile data-driven approaches show promise, they often struggle with generalizing across tasks and providing pedagogically aligned guidance. Our work investigates structure-aware hint generation that aligns feedback to conceptual steps in problem-solving.\nRelated Work\n\nReinforcement learning (RL) has enabled robots to acquire complex behaviors directly from interaction. However, data hunger, safety, and sim-to-real transfer remain persistent obstacles for deployment in real-world settings.\n\nModel-free methods such as DDPG (Lillicrap et al., 2016), SAC (Haarnoja et al., 2018), and PPO (Schulman et al., 2017) have been widely adopted for continuous control, while model-based approaches leverage learned dynamics for sample efficiency (Deisenroth and Rasmussen, 2011; Chua et al., 2018). Recent lines of work explore offline RL (Levine et al., 2020; Kumar et al., 2020) and representation learning for policy generalization (Laskin et al., 2020; Yarats et al., 2021). Domain randomization and adaptation seek to bridge the sim-to-real gap (Tobin et al., 2017; Peng et al., 2018).\n\nWe propose a training strategy that combines curriculum learning with uncertainty-aware policy updates to improve safety and sample efficiency in robotic manipulation.\nRelated Work\n\nAutomatic speech recognition (ASR) systems increasingly rely on large encoder\u2013decoder architectures that are costly to deploy on edge devices. Knowledge distillation (KD) is a common strategy to reduce model size while preserving accuracy.\n\nKnowledge distillation for speech recognition has considered frame-level supervision, sequence-level criteria, and wordpiece distributions, transferring knowledge from stronger teachers to smaller students (Hinton et al., 2015; Kim and Rush, 2016; Kurata and Audhkhasi, 2018; Higuchi et al., 2021).\n\nOther compression techniques include quantization and pruning, which can be combined with KD but may degrade robustness to noise and speaker variability. Recent work explores multi-teacher ensembles and intermediate-layer matching to stabilize training.\n\nIn this paper, we study streaming-constrained KD with latency-aware targets, aligning teacher and student under causal masking. Our experiments on LibriSpeech and far-field corpora show improved WER\u2013latency trade-offs compared to strong baselines.\nRelated Work\n\nLarge Language Models and Prompting\nLarge language models (LLMs) exhibit emergent program synthesis capabilities when conditioned on natural language instructions and a handful of examples. While these behaviors reduce reliance on supervised datasets, the mechanisms by which prompts control generation remain only partially understood. Prior studies analyze calibration, decoding strategies, and context length effects.\n\nPrompting for Code Generation\nPrompting for code generation has explored zero-shot, few-shot, and chain-of-thought styles using large language models (Chen et al., 2021; Austin et al., 2021; Nijkamp et al., 2022; Li et al., 2023). Work on compiler-aware prompting adds execution feedback to steer generation (Liu et al., 2022; Le et al., 2022; Wang et al., 2023). Program repair and test-driven synthesis have similarly adapted prompting strategies to satisfy unit tests (Jain et al., 2022; Zhang et al., 2023).\n\nExecution-Conditioned Decoding\nBeyond static prompts, execution-conditioned decoding iteratively runs partial programs to reduce search space. Studies report gains on algorithmic problems by interleaving generation and verification under timeouts and sandboxing constraints.\n\nStructured Constraints and Type Guidance\nApproaches that inject grammar constraints or type information restrict invalid outputs and improve pass rates. These methods range from constrained beam search to type-state automata.\n\nPositioning\nWe examine the interaction between prompt structure and execution feedback and study how typed constraints alter search dynamics under limited budgets.\nRelated Work\n\nFederated learning (FL) enables on-device training with privacy and communication constraints. Ensuring rigorous privacy guarantees while preserving model utility remains a core challenge.\n\nPrivacy in federated learning has been studied via differential privacy at the client level, secure aggregation, and shuffling (McMahan et al., 2017; Kairouz et al., 2021; Bonawitz et al., 2017; Erlingsson et al., 2019). Gradient perturbation, clipping, and client subsampling are common techniques to control privacy loss (Abadi et al., 2016; Thakkar et al., 2019; Andrew et al., 2021). Auditing methods estimate empirical privacy leakage post hoc (Nasr et al., 2019; Jagielski et al., 2020).\n\nOur approach introduces client-adaptive noise schedules conditioned on participation frequency.\n\nWe empirically evaluate privacy-utility trade-offs across heterogeneous client populations.\nIntroduction\n\nInformation retrieval has shifted from lexical term matching to semantic representations that capture contextual meaning. This shift enables better recall of paraphrased content but introduces new challenges in index efficiency and training stability.\n\nNeural semantic search methods combine dual-encoders for efficient retrieval (Yao et al., 2019; Xie and Zhao, 2020) with cross-encoders for reranking (Nogueira and Cho, 2019; Li et al., 2021), and leverage hard-negative mining to improve discriminative power (Gao et al., 2021; Huang et al., 2022). Recent work also explores domain adaptation for specialized corpora such as legal and biomedical texts (Park et al., 2022; Sun et al., 2023).\n\nWe study lightweight domain adaptation under tight indexing budgets.\nRelated Work\n\nDetecting anomalies in time-series is a long-standing problem with applications in monitoring, finance, and industrial IoT. Methods vary widely in assumptions, supervision requirements, and scalability.\n\nTime-series anomaly detection spans classical statistical tests, isolation-based methods, and deep learning models such as autoencoders, temporal convolutional networks, and Transformers (Gupta et al., 2014; Liu et al., 2008; Malhotra et al., 2016; Xu et al., 2020). Synthetic anomaly injection and semi-supervised training are also common practices (Zhang et al., 2019; Shen et al., 2021).\n\nBenchmarking efforts have sought consistent evaluation protocols across datasets with different anomaly types and frequencies (Hundman et al., 2018; Wu and Keogh, 2021).\nRelated Work\n\nPredicting molecular properties from structure has catalyzed a broad literature at the intersection of cheminformatics and geometric deep learning. Approaches differ in how they encode graph topology, chemical attributes, and geometric constraints.\n\nGraph representation learning methods such as spectral GCNs, spatial message passing networks, and attention-based GNNs have been widely applied to molecular property prediction (Kipf and Welling, 2017; Gilmer et al., 2017; Veli\u010dkovi\u0107 et al., 2018). Extensions include edge-conditioned convolutions, higher-order structures, and equivariant networks for 3D geometries (Simonovsky and Komodakis, 2017; Batzner et al., 2022).\n\nPretraining strategies on large unlabeled molecule corpora with contrastive or masked node prediction objectives have further improved generalization, especially in low-data regimes (Hu et al., 2020; Rong et al., 2020).\nIntroduction\n\nAutomated analysis of pathology whole-slide images (WSIs) faces extreme resolution, sparse lesion patterns, and distribution shifts across scanners and staining protocols. Convolutional networks have advanced the field but can be limited in modeling long-range dependencies over gigapixel slides.\n\nVision Transformers have been applied to medical image classification, segmentation, and detection with pure transformer backbones or hybrid CNN\u2013Transformer designs (Dosovitskiy et al., 2020; Chen et al., 2021; Hatamizadeh et al., 2022; Wang et al., 2021; Xie et al., 2021).\n\nWeakly supervised multiple-instance learning (MIL) further alleviates slide-level labeling costs by aggregating patch evidence, yet attention pooling can overfit to spurious correlations. We investigate whether token-level sparsification combined with instance reweighting can improve robustness in cross-site evaluation.\n\nOur method introduces a curriculum-sparse token selection and slide-consistent calibration loss to stabilize attention under domain shift. On three WSI benchmarks spanning different scanners, we observe gains in AUC and improved calibration, with minimal added compute.\n\nWe conduct ablations on sparsity schedules and release pretrained weights for community use.\nRelated Work\n\nRemote sensing change detection relies on robust representations that separate illumination and seasonal effects from structural changes. Recent advances in high-resolution satellites have shifted attention to fine-grained, building-level change cues.\n\nClassical two-stream CNNs, Siamese architectures, and attention-based models have been widely adopted for change detection (Daudt et al., 2018; Fang et al., 2020; Chen et al., 2021). Large-scale datasets such as LEVIR-CD, CDD, and WHU-CD have enabled benchmarking across urban scenes (Levir et al., 2020; Wang et al., 2020; Ji et al., 2019). Transformer-based encoders further improve long-range modeling (Ban et al., 2021; Liu et al., 2021).\n\nWhile these efforts improve accuracy, they largely assume perfectly registered image pairs and abundant labels. Our work targets label-scarce scenarios with misalignment by learning registration-aware tokens that disentangle geometry from appearance.\nIntroduction\n\nEffective human-robot collaboration requires balancing adaptability to user intent with guarantees on safety and task efficiency. Real-world deployments must operate under partial observability and distribution shifts in user behavior.\n\nShared autonomy techniques span predictive user intent modeling, POMDP-based assistance, arbitration policies that blend human and robot commands, and learning from demonstration for collaborative tasks (Dragan and Srinivasa, 2013; Javdani et al., 2015; Reddy et al., 2018; Losey et al., 2020).\n\nWe propose CertAssist, a certifiably safe shared autonomy framework combining control barrier functions with belief-dependent arbitration, evaluated on manipulation and navigation tasks with human participants.\nIntroduction\nAccurate forecasting underpins decision-making in supply chains, energy, and finance. Models must balance bias-variance trade-offs, handle sparse covariates, and remain robust to nonstationary shifts and irregular sampling.\n\nClassical time series forecasting relies on ARIMA and exponential smoothing to model linear dependencies (Box and Jenkins, 1970; Hyndman et al., 2008). Neural models introduce nonlinearity via RNNs, LSTMs, and temporal convolutions (Hochreiter and Schmidhuber, 1997; Bai et al., 2018). Transformer-based forecasters use attention to capture long-range dependencies (Li et al., 2019; Zhou et al., 2021). Decomposition and frequency-domain methods further reduce complexity and highlight seasonal structure (Oreshkin et al., 2020; Wu et al., 2021).\n\nWe present an uncertainty-aware spectral transformer that couples learnable seasonal kernels with interval calibration, yielding improved accuracy and coverage under regime shifts in retail and traffic datasets.\nRelated Work\n\nControllable text generation seeks to guide large language models (LLMs) toward specified attributes with minimal task-specific supervision. Recent approaches either modify inputs via prompts or adjust model parameters through lightweight adapters.\n\nPrompt-based methods for steering pre-trained language models have been explored in a variety of settings. Discrete prompt mining identifies trigger tokens that elicit desired behavior (Kim and Park, 2020; Zhou et al., 2021). Continuous prompt tuning replaces hard prompts with trainable embeddings (Li and Sung, 2021; Qin et al., 2022). Instruction following with few-shot exemplars has also been shown to improve task transfer (Rao and Lin, 2021; Xu et al., 2022).\n\nAdapter-based control introduces small task-specific modules into frozen backbones, enabling multi-task training while limiting memory costs (Chen et al., 2021; Gupta and Lee, 2022). Other lines include decoding constraints (He and Zhao, 2020) and classifier-guided re-ranking (Sharma et al., 2021).\n\nIn parallel, evaluation protocols for controllability measure attribute accuracy, content preservation, and fluency (Liu et al., 2020; Feng and Ma, 2021).\nRelated Work\n\nFederated learning enables collaborative training across a population of devices while keeping raw data local. The distributed setting raises new challenges in privacy, robustness, and communication efficiency.\n\nPrivacy in federated learning has been studied through differential privacy mechanisms for client updates (Abadi et al., 2016; McMahan et al., 2018), secure aggregation protocols to hide individual contributions (Bonawitz et al., 2017), split learning to keep raw data on-device (Gupta and Raskar, 2018), and cryptographic techniques like homomorphic encryption and MPC (Gentry, 2009; Mohassel and Zhang, 2017). Communication reduction has been addressed via sparsification and quantization (Stich et al., 2018; Kone\u010dn\u00fd et al., 2016).\n\nOur method jointly optimizes privacy noise allocation and gradient compression schedules under a fixed bandwidth budget.\nIntroduction\n\nUrban congestion degrades mobility, increases emissions, and undermines economic productivity. Adaptive traffic signal control promises to improve throughput by tailoring signal plans to real-time conditions. Reinforcement learning offers a data-driven framework to learn such policies directly from interaction.\n\nClassical traffic signal control uses handcrafted rules and model-based optimization (Webster, 1958; Gartner, 1983). RL-based approaches apply tabular Q-learning, deep Q-networks, and policy gradients to learn adaptive strategies (Abdoos et al., 2013; Van der Pol and Oliehoek, 2016; Wei et al., 2018). Multi-agent methods coordinate intersections via shared critics or communication (Chu et al., 2019; Zang et al., 2020; Chen et al., 2020). In this work, we propose a hierarchical actor-critic that decomposes phase selection and duration control.\n\nWe validate our approach on synthetic and real-world networks, showing gains in average travel time and queue length.\nRelated Work\n\nMultimodal summarization seeks to distill essential content by integrating complementary cues across text, images, and video. Approaches differ in the depth of fusion, supervision requirements, and the granularity of output (sentential vs. extractive vs. abstractive).\n\nEarly multimodal summarization methods fuse visual features with textual encoders (Li et al., 2017; Chen and Bansal, 2018). Video summarization leverages temporal attention and key-shot selection (Zhang et al., 2016; Rochan and Wang, 2019). Recent transformer-based models introduce cross-modal alignment modules (Liu et al., 2021; Zeng et al., 2022).\n\nDespite the progress, practical systems must handle noisy modalities and domain shifts. Our study focuses on robust alignment under weak supervision and evaluates consistency constraints that mitigate cross-modal mismatch.\nIntroduction\n\nLearning control policies in simulation and transferring them to real robots reduces data collection cost but introduces the reality gap problem. A wide range of techniques aim to close this gap by randomizing simulators or adapting policies.\n\nFor sim-to-real transfer in robotics, domain randomization perturbs textures and dynamics (Tobin et al., 2017; Peng et al., 2018), while domain adaptation aligns feature distributions (Tzeng et al., 2017; Ganin et al., 2016). Recent work leverages privileged information (Rajeswaran et al., 2017), online adaptation (Chebotar et al., 2019), and residual policy learning (Johannink et al., 2019).\n\nHardware-aware policy learning and safety constraints have been explored to ensure feasible trajectories under actuation limits (Dalal et al., 2018; Berkenkamp et al., 2017).\n\nWe evaluate a modular adaptation pipeline on manipulation and locomotion tasks.\nRelated Work\n\nMedical image segmentation has long relied on convolutional architectures such as U-Net and its variants due to their inductive biases and efficiency (Ronneberger et al., 2015; Milletari et al., 2016). Recent progress in self-attention and transformers has motivated their application to dense prediction.\n\nTransformer-based segmentation has been explored through pure-ViT decoders, hybrid CNN\u2013ViT backbones, and pyramid tokens (Chen et al., 2021; Strudel et al., 2021; Xie et al., 2021). Medical adaptations include axial attention, windowed self-attention, and lightweight transformers (Wang et al., 2021; Hatamizadeh et al., 2022; Chen et al., 2022). Further studies consider multi-scale fusion and boundary-aware losses (Oktay et al., 2018; Kirillov et al., 2020; Zhao et al., 2017).\n\nRecent benchmarks reveal the sensitivity of ViT-based models to training data size and augmentation strategies (Dosovitskiy et al., 2021; Touvron et al., 2021). However, clinical datasets remain small and heterogeneous, posing challenges for generalization.\n\nWe present a compact hybrid that targets data efficiency by constraining attention spans and sharing parameters across scales, evaluating on multi-institutional MRI and CT cohorts.\nRelated Work\n\nClassic Indexing\nB-trees and hash tables offer predictable performance envelopes and decades of engineering maturity. Their behavior under skew and dynamic workloads has inspired numerous variants.\n\nLearned Indexes\nLearned index structures replace trees or hash tables with models that map keys to positions, using linear models, neural networks, or mixture-of-experts (Kraska et al., 2018; Ding et al., 2020; Marcus et al., 2021). Alternatives use recursive models or spline approximations to bound errors (Kipf et al., 2019; Ferragina and Vinciguerra, 2020).\n\nSystems Concerns\nUpdate handling, concurrency control, and memory locality remain central challenges for adopting learned indexes in production.\n\nOur Scope\nWe study latency tails under shifting key distributions and propose a controller that adapts model partitions online.\n",
        "completion": "Learned index structures replace trees or hash tables with models that map keys to positions, using linear models, neural networks, or mixture-of-experts (Kraska et al., 2018; Ding et al., 2020; Marcus et al., 2021). Alternatives use recursive models or spline approximations to bound errors (Kipf et al., 2019; Ferragina and Vinciguerra, 2020)."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        occurs when either:\n    a) The author describes or cites papers without connecting them to their own work/argument \n    b) Or only follows up the summary of previous works with their own contribution without explicitly highlighting the gap their work intends to research.\n    c) It does not articulate the author's perspective or motivation.\n    d) A lack of argument/opinion in the first paragraph is permissible as it serves to be the foundation of the author's argument \n    e) Lacks synthesis issues appear either as single sentences or multiple sentences.\n    Examples of lack of synthesis include:\n        i) No elaboration of own contribution/argument:\"Following early neural approaches to question answering, many subsequent studies adopt a pipeline architecture consisting of retrieval and comprehension components. The retrieval component focuses on identifying relevant documents or passages from a large corpus, while the comprehension component extracts an answer span from the retrieved text. Initial models relied on recurrent neural networks with attention mechanisms to encode questions and contexts (Seo et al., 2017; Wang et al., 2017).\"\n        ii)  No explanation of the cited works and relation to their own work: \u201cRecently, several studies have explored the use of prompting techniques with pre-trained language models to influence model outputs or access latent knowledge (Brown et al., 2020; Gao et al., 2021; Liu et al., 2021; Wei et al., 2022).\u201d \n\n        Example text: \n        Related Work\n\nDevelopers rely on code search to find relevant snippets, APIs, or examples. Unlike general document retrieval, code search must bridge natural language intent and program structure.\n\nNeural code search has been addressed with bi-encoders, cross-encoders, and dual learning (Gu et al., 2018; Husain et al., 2019; Feng et al., 2020). Structural representations incorporate ASTs, control flow, and data flow (Alon et al., 2019; Wang et al., 2020; Liu et al., 2021). Pretraining on code and NL improves retrieval metrics across languages (Ahmad et al., 2021; Guo et al., 2021).\n\nIn this paper, we introduce a language-agnostic retriever with compositional queries.\n\nWe evaluate zero-shot transfer across four programming languages.\nIntroduction\n\nGeneralization in text classification can be improved with data augmentation, especially when labeled data are scarce or imbalanced. Approaches range from rule-based edits to model-driven paraphrasing and representation-space mixing.\n\nText augmentation techniques include synonym replacement, random insertion/deletion, back-translation, paraphrase generation, and mixup in embedding or hidden spaces (Wei and Zou, 2019; Sennrich et al., 2016; Kobayashi, 2018; Guo et al., 2020). Recent work explores task-adaptive augmentation policies learned by reinforcement learning (Xie et al., 2020).\n\nEvaluation typically considers robustness to domain shift, label noise, and distributional skew across multiple benchmarks (Pruksachatkun et al., 2020; Hendrycks et al., 2020).\nRelated Work\n\nKnowledge graph completion predicts missing links by learning entity and relation representations. Methods vary in how they encode semantics and handle patterns like symmetry, hierarchy, and composition.\n\nTranslation-based knowledge graph embeddings model relations as translations in vector space (Bordes et al., 2013; Wang et al., 2014), while bilinear and neural models capture more complex interactions (Nickel et al., 2011; Trouillon et al., 2016; Sun et al., 2019). Regularization and rule-guided approaches improve inductive bias and data efficiency (Rockt\u00e4schel et al., 2015; Minervini et al., 2017).\n\nWe introduce a lightweight compositional constraint for hierarchical relations and evaluate on three benchmarks and an industry dataset.\nRelated Work\n\nEnsuring safety during reinforcement learning is critical in real-world control where violations can be costly. Research has proposed both objective-level and mechanism-level solutions.\n\nSafe reinforcement learning approaches include risk-sensitive objectives such as CVaR optimization (Tamar et al., 2015; Chow et al., 2018), constrained policy optimization with safety budgets (Achiam et al., 2017; Yang et al., 2020), and shielding based on model-checking or supervisors (Alshiekh et al., 2018; Dalal et al., 2018). We develop a method that integrates model-predictive constraints with policy gradients.\n\nBenchmarks often evaluate safety in simulated robotics or navigation with cost functions approximating constraint violations (Ray et al., 2019; Bharadhwaj et al., 2021).\nRelated Work\n\nDialog state tracking (DST) has evolved from rule-based slot filling to neural architectures that jointly infer belief states across turns. Early pipeline models used hand-crafted lexicons and semantic frames (Singh and Patel, 2015), but suffered from brittleness to paraphrase and noise. Neural encoders introduced robustness by contextualizing utterances, incorporating attention over dialog history, and modeling slot-value dependencies (Lee et al., 2018; Choe and Kim, 2019).\n\nPretrained language models have further shifted the landscape by enabling few-shot generalization and open-vocabulary slot values. Fine-tuning BERT-like encoders for DST improved cross-domain transfer (Rao et al., 2020), while generative formulations cast state tracking as text-to-text prediction (Mendez et al., 2021).\n\nPrompting-based approaches have also been explored for dialog modeling (Kumar et al., 2021; Ortega and Lin, 2022; Park et al., 2023). These methods condition large language models on task instructions or few-shot exemplars to elicit latent conversational knowledge. Recent variants incorporate calibration or self-consistency to stabilize outputs (Fang et al., 2023; Zhou et al., 2023).\n\nPosition relative to this paper While we also employ pretrained sequence-to-sequence models, our focus is on handling ontology drift in long-running deployments. Specifically, we introduce an adaptive slot schema encoder that aligns evolving taxonomies with dialog evidence, and a contrastive consistency objective to mitigate spurious slot co-activations across domains.\nIntroduction\n\nSelf-supervised learning (SSL) has become the dominant paradigm for learning transferable visual features without labels. By constructing pretext tasks that expose invariances and structure inherent in data, SSL models can match or surpass supervised baselines on many downstream tasks.\n\nContrastive pretraining has been widely adopted for visual representations (Chen et al., 2020; He et al., 2020; Xie and Xu, 2021). Non-contrastive methods remove negative pairs and rely on architectural or objective asymmetries (Grill et al., 2020; Tian et al., 2021). Clustering-based methods jointly learn assignments and embeddings (Caron et al., 2018; Li and Gao, 2022).\n\nDespite these advances, industrial applications often operate under strict memory budgets and latency constraints. In this paper, we investigate compute-aware pretraining objectives that couple multi-crop augmentation with a token-subsampled backbone. We present a latency-regularized alignment loss that preserves downstream accuracy while reducing FLOPs during both pretraining and fine-tuning.\nIntroduction\n\nEfficient exploration remains a central challenge in reinforcement learning (RL), particularly in sparse-reward environments where naive strategies fail to discover rewarding states. Over-exploration, however, can waste samples and destabilize learning.\n\nExploration in reinforcement learning has been advanced by count-based bonuses, intrinsic motivation, curiosity-driven prediction error, and information-theoretic objectives (Bellemare et al., 2016; Pathak et al., 2017; Houthooft et al., 2016; Burda et al., 2019; Ta\u00efga et al., 2020).\n\nYet, when environment dynamics change over time, stale novelty estimates can encourage revisiting obsolete states. We propose a recency-aware intrinsic reward that discounts outdated novelty and couples it with conservative policy updates.\n\nAcross Atari and continuous-control domains with drifting dynamics, our method achieves superior sample efficiency and stability, and ablations confirm the role of recency in balancing exploration and exploitation.\nRelated Work\n\nDetecting anomalies in multivariate time series is vital for monitoring industrial systems and cloud services. The challenge lies in handling seasonality, rare events, and inter-variable dependencies.\n\nClassical anomaly detection leverages ARIMA residual tests, STL decomposition, and control charts, while deep methods introduce autoencoders, VAEs, GANs, LSTMs, and Transformers for reconstruction or prediction errors (Tsay, 2010; Malhotra et al., 2015; An and Cho, 2015; Li et al., 2019; Xu et al., 2021).\n\nWe present Contrastive Forecasting with Graph Priors (CFGP), which learns structure-aware representations via self-supervised objectives and uses calibrated predictive intervals to flag anomalies.\nIntroduction\n\nGeneralizing manipulation skills across objects, tasks, and environments remains a central challenge in robotics. Sparse rewards, safety constraints, and hardware variability complicate learning on physical systems. Recent work studies imitation learning, offline RL, and model-based control for dexterous manipulation (Rajeswaran et al., 2018; Lynch et al., 2020; Nagabandi et al., 2019; Ahn et al., 2022). Despite these advances, scaling data collection and ensuring sim-to-real transfer continue to be bottlenecks.\n\nWe explore a curriculum that interleaves skill discovery from teleoperation logs with conservative online updates, targeting stable improvements under limited interaction budgets.\nRelated Work\n\nConversational recommenders. Systems that interactively elicit user preferences can reduce cold-start and improve satisfaction (Sun and Zhang, 2018). Dialog policy learning for conversational recommendation has explored supervised learning, reinforcement learning, and bandit methods (Christakopoulou et al., 2016; Lei et al., 2020; Chen et al., 2019). User simulators and counterfactual logging have been proposed to address data scarcity and evaluation challenges (Li et al., 2017; Chi et al., 2020).\n\nOur study investigates preference drift over long-horizon sessions and proposes a state representation that explicitly tracks uncertainty and recency effects.\nIntroduction\n\nExplainable AI (XAI) is increasingly required for medical imaging systems used in screening and triage. Beyond predictive accuracy, clinicians demand transparency about what image features drive automated decisions and whether explanations are stable under shifts.\n\nPost-hoc attribution methods like Grad-CAM and Integrated Gradients highlight salient regions (Selvaraju et al., 2017; Sundararajan et al., 2017). Prototype- and concept-based explanations enhance interpretability (Chen et al., 2019; Kim et al., 2018). Counterfactual generation has been explored for medical images (Chang et al., 2018; Singla et al., 2021).\n\nWe focus on faithfulness under distribution shift and propose an evaluation protocol that aligns explanation stability with clinical acceptance thresholds for screening workflows.\nRelated Work\n\nProviding timely, actionable feedback at scale is central to computing education. Traditional approaches combine instructor-designed rubrics with automated tests, but coverage and specificity can be limited for diverse student solutions.\n\nAutomated feedback for programming assignments has been tackled with static analysis, dynamic test generation, and pattern mining (Ke et al., 2016; Gulwani et al., 2018; Singh et al., 2013). Recent NLP-based systems leverage code embeddings, sequence models, and pretrained language models (Allamanis et al., 2018; Feng et al., 2020; Ahmad et al., 2021). Peer learning platforms collect hints and exemplars to guide novice programmers (Piech et al., 2015; Wang et al., 2018).\n\nWhile data-driven approaches show promise, they often struggle with generalizing across tasks and providing pedagogically aligned guidance. Our work investigates structure-aware hint generation that aligns feedback to conceptual steps in problem-solving.\nRelated Work\n\nReinforcement learning (RL) has enabled robots to acquire complex behaviors directly from interaction. However, data hunger, safety, and sim-to-real transfer remain persistent obstacles for deployment in real-world settings.\n\nModel-free methods such as DDPG (Lillicrap et al., 2016), SAC (Haarnoja et al., 2018), and PPO (Schulman et al., 2017) have been widely adopted for continuous control, while model-based approaches leverage learned dynamics for sample efficiency (Deisenroth and Rasmussen, 2011; Chua et al., 2018). Recent lines of work explore offline RL (Levine et al., 2020; Kumar et al., 2020) and representation learning for policy generalization (Laskin et al., 2020; Yarats et al., 2021). Domain randomization and adaptation seek to bridge the sim-to-real gap (Tobin et al., 2017; Peng et al., 2018).\n\nWe propose a training strategy that combines curriculum learning with uncertainty-aware policy updates to improve safety and sample efficiency in robotic manipulation.\nRelated Work\n\nAutomatic speech recognition (ASR) systems increasingly rely on large encoder\u2013decoder architectures that are costly to deploy on edge devices. Knowledge distillation (KD) is a common strategy to reduce model size while preserving accuracy.\n\nKnowledge distillation for speech recognition has considered frame-level supervision, sequence-level criteria, and wordpiece distributions, transferring knowledge from stronger teachers to smaller students (Hinton et al., 2015; Kim and Rush, 2016; Kurata and Audhkhasi, 2018; Higuchi et al., 2021).\n\nOther compression techniques include quantization and pruning, which can be combined with KD but may degrade robustness to noise and speaker variability. Recent work explores multi-teacher ensembles and intermediate-layer matching to stabilize training.\n\nIn this paper, we study streaming-constrained KD with latency-aware targets, aligning teacher and student under causal masking. Our experiments on LibriSpeech and far-field corpora show improved WER\u2013latency trade-offs compared to strong baselines.\nRelated Work\n\nLarge Language Models and Prompting\nLarge language models (LLMs) exhibit emergent program synthesis capabilities when conditioned on natural language instructions and a handful of examples. While these behaviors reduce reliance on supervised datasets, the mechanisms by which prompts control generation remain only partially understood. Prior studies analyze calibration, decoding strategies, and context length effects.\n\nPrompting for Code Generation\nPrompting for code generation has explored zero-shot, few-shot, and chain-of-thought styles using large language models (Chen et al., 2021; Austin et al., 2021; Nijkamp et al., 2022; Li et al., 2023). Work on compiler-aware prompting adds execution feedback to steer generation (Liu et al., 2022; Le et al., 2022; Wang et al., 2023). Program repair and test-driven synthesis have similarly adapted prompting strategies to satisfy unit tests (Jain et al., 2022; Zhang et al., 2023).\n\nExecution-Conditioned Decoding\nBeyond static prompts, execution-conditioned decoding iteratively runs partial programs to reduce search space. Studies report gains on algorithmic problems by interleaving generation and verification under timeouts and sandboxing constraints.\n\nStructured Constraints and Type Guidance\nApproaches that inject grammar constraints or type information restrict invalid outputs and improve pass rates. These methods range from constrained beam search to type-state automata.\n\nPositioning\nWe examine the interaction between prompt structure and execution feedback and study how typed constraints alter search dynamics under limited budgets.\nRelated Work\n\nFederated learning (FL) enables on-device training with privacy and communication constraints. Ensuring rigorous privacy guarantees while preserving model utility remains a core challenge.\n\nPrivacy in federated learning has been studied via differential privacy at the client level, secure aggregation, and shuffling (McMahan et al., 2017; Kairouz et al., 2021; Bonawitz et al., 2017; Erlingsson et al., 2019). Gradient perturbation, clipping, and client subsampling are common techniques to control privacy loss (Abadi et al., 2016; Thakkar et al., 2019; Andrew et al., 2021). Auditing methods estimate empirical privacy leakage post hoc (Nasr et al., 2019; Jagielski et al., 2020).\n\nOur approach introduces client-adaptive noise schedules conditioned on participation frequency.\n\nWe empirically evaluate privacy-utility trade-offs across heterogeneous client populations.\nIntroduction\n\nInformation retrieval has shifted from lexical term matching to semantic representations that capture contextual meaning. This shift enables better recall of paraphrased content but introduces new challenges in index efficiency and training stability.\n\nNeural semantic search methods combine dual-encoders for efficient retrieval (Yao et al., 2019; Xie and Zhao, 2020) with cross-encoders for reranking (Nogueira and Cho, 2019; Li et al., 2021), and leverage hard-negative mining to improve discriminative power (Gao et al., 2021; Huang et al., 2022). Recent work also explores domain adaptation for specialized corpora such as legal and biomedical texts (Park et al., 2022; Sun et al., 2023).\n\nWe study lightweight domain adaptation under tight indexing budgets.\nRelated Work\n\nDetecting anomalies in time-series is a long-standing problem with applications in monitoring, finance, and industrial IoT. Methods vary widely in assumptions, supervision requirements, and scalability.\n\nTime-series anomaly detection spans classical statistical tests, isolation-based methods, and deep learning models such as autoencoders, temporal convolutional networks, and Transformers (Gupta et al., 2014; Liu et al., 2008; Malhotra et al., 2016; Xu et al., 2020). Synthetic anomaly injection and semi-supervised training are also common practices (Zhang et al., 2019; Shen et al., 2021).\n\nBenchmarking efforts have sought consistent evaluation protocols across datasets with different anomaly types and frequencies (Hundman et al., 2018; Wu and Keogh, 2021).\nRelated Work\n\nPredicting molecular properties from structure has catalyzed a broad literature at the intersection of cheminformatics and geometric deep learning. Approaches differ in how they encode graph topology, chemical attributes, and geometric constraints.\n\nGraph representation learning methods such as spectral GCNs, spatial message passing networks, and attention-based GNNs have been widely applied to molecular property prediction (Kipf and Welling, 2017; Gilmer et al., 2017; Veli\u010dkovi\u0107 et al., 2018). Extensions include edge-conditioned convolutions, higher-order structures, and equivariant networks for 3D geometries (Simonovsky and Komodakis, 2017; Batzner et al., 2022).\n\nPretraining strategies on large unlabeled molecule corpora with contrastive or masked node prediction objectives have further improved generalization, especially in low-data regimes (Hu et al., 2020; Rong et al., 2020).\nIntroduction\n\nAutomated analysis of pathology whole-slide images (WSIs) faces extreme resolution, sparse lesion patterns, and distribution shifts across scanners and staining protocols. Convolutional networks have advanced the field but can be limited in modeling long-range dependencies over gigapixel slides.\n\nVision Transformers have been applied to medical image classification, segmentation, and detection with pure transformer backbones or hybrid CNN\u2013Transformer designs (Dosovitskiy et al., 2020; Chen et al., 2021; Hatamizadeh et al., 2022; Wang et al., 2021; Xie et al., 2021).\n\nWeakly supervised multiple-instance learning (MIL) further alleviates slide-level labeling costs by aggregating patch evidence, yet attention pooling can overfit to spurious correlations. We investigate whether token-level sparsification combined with instance reweighting can improve robustness in cross-site evaluation.\n\nOur method introduces a curriculum-sparse token selection and slide-consistent calibration loss to stabilize attention under domain shift. On three WSI benchmarks spanning different scanners, we observe gains in AUC and improved calibration, with minimal added compute.\n\nWe conduct ablations on sparsity schedules and release pretrained weights for community use.\nRelated Work\n\nRemote sensing change detection relies on robust representations that separate illumination and seasonal effects from structural changes. Recent advances in high-resolution satellites have shifted attention to fine-grained, building-level change cues.\n\nClassical two-stream CNNs, Siamese architectures, and attention-based models have been widely adopted for change detection (Daudt et al., 2018; Fang et al., 2020; Chen et al., 2021). Large-scale datasets such as LEVIR-CD, CDD, and WHU-CD have enabled benchmarking across urban scenes (Levir et al., 2020; Wang et al., 2020; Ji et al., 2019). Transformer-based encoders further improve long-range modeling (Ban et al., 2021; Liu et al., 2021).\n\nWhile these efforts improve accuracy, they largely assume perfectly registered image pairs and abundant labels. Our work targets label-scarce scenarios with misalignment by learning registration-aware tokens that disentangle geometry from appearance.\nIntroduction\n\nEffective human-robot collaboration requires balancing adaptability to user intent with guarantees on safety and task efficiency. Real-world deployments must operate under partial observability and distribution shifts in user behavior.\n\nShared autonomy techniques span predictive user intent modeling, POMDP-based assistance, arbitration policies that blend human and robot commands, and learning from demonstration for collaborative tasks (Dragan and Srinivasa, 2013; Javdani et al., 2015; Reddy et al., 2018; Losey et al., 2020).\n\nWe propose CertAssist, a certifiably safe shared autonomy framework combining control barrier functions with belief-dependent arbitration, evaluated on manipulation and navigation tasks with human participants.\nIntroduction\nAccurate forecasting underpins decision-making in supply chains, energy, and finance. Models must balance bias-variance trade-offs, handle sparse covariates, and remain robust to nonstationary shifts and irregular sampling.\n\nClassical time series forecasting relies on ARIMA and exponential smoothing to model linear dependencies (Box and Jenkins, 1970; Hyndman et al., 2008). Neural models introduce nonlinearity via RNNs, LSTMs, and temporal convolutions (Hochreiter and Schmidhuber, 1997; Bai et al., 2018). Transformer-based forecasters use attention to capture long-range dependencies (Li et al., 2019; Zhou et al., 2021). Decomposition and frequency-domain methods further reduce complexity and highlight seasonal structure (Oreshkin et al., 2020; Wu et al., 2021).\n\nWe present an uncertainty-aware spectral transformer that couples learnable seasonal kernels with interval calibration, yielding improved accuracy and coverage under regime shifts in retail and traffic datasets.\nRelated Work\n\nControllable text generation seeks to guide large language models (LLMs) toward specified attributes with minimal task-specific supervision. Recent approaches either modify inputs via prompts or adjust model parameters through lightweight adapters.\n\nPrompt-based methods for steering pre-trained language models have been explored in a variety of settings. Discrete prompt mining identifies trigger tokens that elicit desired behavior (Kim and Park, 2020; Zhou et al., 2021). Continuous prompt tuning replaces hard prompts with trainable embeddings (Li and Sung, 2021; Qin et al., 2022). Instruction following with few-shot exemplars has also been shown to improve task transfer (Rao and Lin, 2021; Xu et al., 2022).\n\nAdapter-based control introduces small task-specific modules into frozen backbones, enabling multi-task training while limiting memory costs (Chen et al., 2021; Gupta and Lee, 2022). Other lines include decoding constraints (He and Zhao, 2020) and classifier-guided re-ranking (Sharma et al., 2021).\n\nIn parallel, evaluation protocols for controllability measure attribute accuracy, content preservation, and fluency (Liu et al., 2020; Feng and Ma, 2021).\nRelated Work\n\nFederated learning enables collaborative training across a population of devices while keeping raw data local. The distributed setting raises new challenges in privacy, robustness, and communication efficiency.\n\nPrivacy in federated learning has been studied through differential privacy mechanisms for client updates (Abadi et al., 2016; McMahan et al., 2018), secure aggregation protocols to hide individual contributions (Bonawitz et al., 2017), split learning to keep raw data on-device (Gupta and Raskar, 2018), and cryptographic techniques like homomorphic encryption and MPC (Gentry, 2009; Mohassel and Zhang, 2017). Communication reduction has been addressed via sparsification and quantization (Stich et al., 2018; Kone\u010dn\u00fd et al., 2016).\n\nOur method jointly optimizes privacy noise allocation and gradient compression schedules under a fixed bandwidth budget.\nIntroduction\n\nUrban congestion degrades mobility, increases emissions, and undermines economic productivity. Adaptive traffic signal control promises to improve throughput by tailoring signal plans to real-time conditions. Reinforcement learning offers a data-driven framework to learn such policies directly from interaction.\n\nClassical traffic signal control uses handcrafted rules and model-based optimization (Webster, 1958; Gartner, 1983). RL-based approaches apply tabular Q-learning, deep Q-networks, and policy gradients to learn adaptive strategies (Abdoos et al., 2013; Van der Pol and Oliehoek, 2016; Wei et al., 2018). Multi-agent methods coordinate intersections via shared critics or communication (Chu et al., 2019; Zang et al., 2020; Chen et al., 2020). In this work, we propose a hierarchical actor-critic that decomposes phase selection and duration control.\n\nWe validate our approach on synthetic and real-world networks, showing gains in average travel time and queue length.\nRelated Work\n\nMultimodal summarization seeks to distill essential content by integrating complementary cues across text, images, and video. Approaches differ in the depth of fusion, supervision requirements, and the granularity of output (sentential vs. extractive vs. abstractive).\n\nEarly multimodal summarization methods fuse visual features with textual encoders (Li et al., 2017; Chen and Bansal, 2018). Video summarization leverages temporal attention and key-shot selection (Zhang et al., 2016; Rochan and Wang, 2019). Recent transformer-based models introduce cross-modal alignment modules (Liu et al., 2021; Zeng et al., 2022).\n\nDespite the progress, practical systems must handle noisy modalities and domain shifts. Our study focuses on robust alignment under weak supervision and evaluates consistency constraints that mitigate cross-modal mismatch.\nIntroduction\n\nLearning control policies in simulation and transferring them to real robots reduces data collection cost but introduces the reality gap problem. A wide range of techniques aim to close this gap by randomizing simulators or adapting policies.\n\nFor sim-to-real transfer in robotics, domain randomization perturbs textures and dynamics (Tobin et al., 2017; Peng et al., 2018), while domain adaptation aligns feature distributions (Tzeng et al., 2017; Ganin et al., 2016). Recent work leverages privileged information (Rajeswaran et al., 2017), online adaptation (Chebotar et al., 2019), and residual policy learning (Johannink et al., 2019).\n\nHardware-aware policy learning and safety constraints have been explored to ensure feasible trajectories under actuation limits (Dalal et al., 2018; Berkenkamp et al., 2017).\n\nWe evaluate a modular adaptation pipeline on manipulation and locomotion tasks.\nRelated Work\n\nMedical image segmentation has long relied on convolutional architectures such as U-Net and its variants due to their inductive biases and efficiency (Ronneberger et al., 2015; Milletari et al., 2016). Recent progress in self-attention and transformers has motivated their application to dense prediction.\n\nTransformer-based segmentation has been explored through pure-ViT decoders, hybrid CNN\u2013ViT backbones, and pyramid tokens (Chen et al., 2021; Strudel et al., 2021; Xie et al., 2021). Medical adaptations include axial attention, windowed self-attention, and lightweight transformers (Wang et al., 2021; Hatamizadeh et al., 2022; Chen et al., 2022). Further studies consider multi-scale fusion and boundary-aware losses (Oktay et al., 2018; Kirillov et al., 2020; Zhao et al., 2017).\n\nRecent benchmarks reveal the sensitivity of ViT-based models to training data size and augmentation strategies (Dosovitskiy et al., 2021; Touvron et al., 2021). However, clinical datasets remain small and heterogeneous, posing challenges for generalization.\n\nWe present a compact hybrid that targets data efficiency by constraining attention spans and sharing parameters across scales, evaluating on multi-institutional MRI and CT cohorts.\nRelated Work\n\nClassic Indexing\nB-trees and hash tables offer predictable performance envelopes and decades of engineering maturity. Their behavior under skew and dynamic workloads has inspired numerous variants.\n\nLearned Indexes\nLearned index structures replace trees or hash tables with models that map keys to positions, using linear models, neural networks, or mixture-of-experts (Kraska et al., 2018; Ding et al., 2020; Marcus et al., 2021). Alternatives use recursive models or spline approximations to bound errors (Kipf et al., 2019; Ferragina and Vinciguerra, 2020).\n\nSystems Concerns\nUpdate handling, concurrency control, and memory locality remain central challenges for adopting learned indexes in production.\n\nOur Scope\nWe study latency tails under shifting key distributions and propose a controller that adapts model partitions online.\nIntroduction\n\nHigh-resolution climate information is crucial for local risk assessment, yet global climate models operate at coarse spatial scales. Statistical downscaling offers a data-driven pathway to bridge this scale gap using historical observations.\n\nDeep learning for statistical downscaling includes convolutional super-resolution architectures such as SRCNN and EDSR adapted to climate grids (Dong et al., 2014; Lim et al., 2017), U-Net variants tailored for precipitation fields (Ronneberger et al., 2015; Pan et al., 2019), and GAN-based methods like SRGAN and ESRGAN for sharper extremes (Ledig et al., 2017; Wang et al., 2018). Diffusion-based super-resolution has also been explored for geospatial data (Saharia et al., 2022; Rombach et al., 2022). Bias correction has been combined with deep downscalers via adversarial or quantile mapping losses (Zhang et al., 2020; Vaittinada Ayar et al., 2021).\n\nWe propose a physically guided diffusion downscaler that conditions on coarse-scale dynamics and enforces conservation via soft constraints.\n",
        "completion": "Deep learning for statistical downscaling includes convolutional super-resolution architectures such as SRCNN and EDSR adapted to climate grids (Dong et al., 2014; Lim et al., 2017), U-Net variants tailored for precipitation fields (Ronneberger et al., 2015; Pan et al., 2019), and GAN-based methods like SRGAN and ESRGAN for sharper extremes (Ledig et al., 2017; Wang et al., 2018). Diffusion-based super-resolution has also been explored for geospatial data (Saharia et al., 2022; Rombach et al., 2022). Bias correction has been combined with deep downscalers via adversarial or quantile mapping losses (Zhang et al., 2020; Vaittinada Ayar et al., 2021)."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        occurs when either:\n    a) The author describes or cites papers without connecting them to their own work/argument \n    b) Or only follows up the summary of previous works with their own contribution without explicitly highlighting the gap their work intends to research.\n    c) It does not articulate the author's perspective or motivation.\n    d) A lack of argument/opinion in the first paragraph is permissible as it serves to be the foundation of the author's argument \n    e) Lacks synthesis issues appear either as single sentences or multiple sentences.\n    Examples of lack of synthesis include:\n        i) No elaboration of own contribution/argument:\"Following early neural approaches to question answering, many subsequent studies adopt a pipeline architecture consisting of retrieval and comprehension components. The retrieval component focuses on identifying relevant documents or passages from a large corpus, while the comprehension component extracts an answer span from the retrieved text. Initial models relied on recurrent neural networks with attention mechanisms to encode questions and contexts (Seo et al., 2017; Wang et al., 2017).\"\n        ii)  No explanation of the cited works and relation to their own work: \u201cRecently, several studies have explored the use of prompting techniques with pre-trained language models to influence model outputs or access latent knowledge (Brown et al., 2020; Gao et al., 2021; Liu et al., 2021; Wei et al., 2022).\u201d \n\n        Example text: \n        Related Work\n\nDevelopers rely on code search to find relevant snippets, APIs, or examples. Unlike general document retrieval, code search must bridge natural language intent and program structure.\n\nNeural code search has been addressed with bi-encoders, cross-encoders, and dual learning (Gu et al., 2018; Husain et al., 2019; Feng et al., 2020). Structural representations incorporate ASTs, control flow, and data flow (Alon et al., 2019; Wang et al., 2020; Liu et al., 2021). Pretraining on code and NL improves retrieval metrics across languages (Ahmad et al., 2021; Guo et al., 2021).\n\nIn this paper, we introduce a language-agnostic retriever with compositional queries.\n\nWe evaluate zero-shot transfer across four programming languages.\nIntroduction\n\nGeneralization in text classification can be improved with data augmentation, especially when labeled data are scarce or imbalanced. Approaches range from rule-based edits to model-driven paraphrasing and representation-space mixing.\n\nText augmentation techniques include synonym replacement, random insertion/deletion, back-translation, paraphrase generation, and mixup in embedding or hidden spaces (Wei and Zou, 2019; Sennrich et al., 2016; Kobayashi, 2018; Guo et al., 2020). Recent work explores task-adaptive augmentation policies learned by reinforcement learning (Xie et al., 2020).\n\nEvaluation typically considers robustness to domain shift, label noise, and distributional skew across multiple benchmarks (Pruksachatkun et al., 2020; Hendrycks et al., 2020).\nRelated Work\n\nKnowledge graph completion predicts missing links by learning entity and relation representations. Methods vary in how they encode semantics and handle patterns like symmetry, hierarchy, and composition.\n\nTranslation-based knowledge graph embeddings model relations as translations in vector space (Bordes et al., 2013; Wang et al., 2014), while bilinear and neural models capture more complex interactions (Nickel et al., 2011; Trouillon et al., 2016; Sun et al., 2019). Regularization and rule-guided approaches improve inductive bias and data efficiency (Rockt\u00e4schel et al., 2015; Minervini et al., 2017).\n\nWe introduce a lightweight compositional constraint for hierarchical relations and evaluate on three benchmarks and an industry dataset.\nRelated Work\n\nEnsuring safety during reinforcement learning is critical in real-world control where violations can be costly. Research has proposed both objective-level and mechanism-level solutions.\n\nSafe reinforcement learning approaches include risk-sensitive objectives such as CVaR optimization (Tamar et al., 2015; Chow et al., 2018), constrained policy optimization with safety budgets (Achiam et al., 2017; Yang et al., 2020), and shielding based on model-checking or supervisors (Alshiekh et al., 2018; Dalal et al., 2018). We develop a method that integrates model-predictive constraints with policy gradients.\n\nBenchmarks often evaluate safety in simulated robotics or navigation with cost functions approximating constraint violations (Ray et al., 2019; Bharadhwaj et al., 2021).\nRelated Work\n\nDialog state tracking (DST) has evolved from rule-based slot filling to neural architectures that jointly infer belief states across turns. Early pipeline models used hand-crafted lexicons and semantic frames (Singh and Patel, 2015), but suffered from brittleness to paraphrase and noise. Neural encoders introduced robustness by contextualizing utterances, incorporating attention over dialog history, and modeling slot-value dependencies (Lee et al., 2018; Choe and Kim, 2019).\n\nPretrained language models have further shifted the landscape by enabling few-shot generalization and open-vocabulary slot values. Fine-tuning BERT-like encoders for DST improved cross-domain transfer (Rao et al., 2020), while generative formulations cast state tracking as text-to-text prediction (Mendez et al., 2021).\n\nPrompting-based approaches have also been explored for dialog modeling (Kumar et al., 2021; Ortega and Lin, 2022; Park et al., 2023). These methods condition large language models on task instructions or few-shot exemplars to elicit latent conversational knowledge. Recent variants incorporate calibration or self-consistency to stabilize outputs (Fang et al., 2023; Zhou et al., 2023).\n\nPosition relative to this paper While we also employ pretrained sequence-to-sequence models, our focus is on handling ontology drift in long-running deployments. Specifically, we introduce an adaptive slot schema encoder that aligns evolving taxonomies with dialog evidence, and a contrastive consistency objective to mitigate spurious slot co-activations across domains.\nIntroduction\n\nSelf-supervised learning (SSL) has become the dominant paradigm for learning transferable visual features without labels. By constructing pretext tasks that expose invariances and structure inherent in data, SSL models can match or surpass supervised baselines on many downstream tasks.\n\nContrastive pretraining has been widely adopted for visual representations (Chen et al., 2020; He et al., 2020; Xie and Xu, 2021). Non-contrastive methods remove negative pairs and rely on architectural or objective asymmetries (Grill et al., 2020; Tian et al., 2021). Clustering-based methods jointly learn assignments and embeddings (Caron et al., 2018; Li and Gao, 2022).\n\nDespite these advances, industrial applications often operate under strict memory budgets and latency constraints. In this paper, we investigate compute-aware pretraining objectives that couple multi-crop augmentation with a token-subsampled backbone. We present a latency-regularized alignment loss that preserves downstream accuracy while reducing FLOPs during both pretraining and fine-tuning.\nIntroduction\n\nEfficient exploration remains a central challenge in reinforcement learning (RL), particularly in sparse-reward environments where naive strategies fail to discover rewarding states. Over-exploration, however, can waste samples and destabilize learning.\n\nExploration in reinforcement learning has been advanced by count-based bonuses, intrinsic motivation, curiosity-driven prediction error, and information-theoretic objectives (Bellemare et al., 2016; Pathak et al., 2017; Houthooft et al., 2016; Burda et al., 2019; Ta\u00efga et al., 2020).\n\nYet, when environment dynamics change over time, stale novelty estimates can encourage revisiting obsolete states. We propose a recency-aware intrinsic reward that discounts outdated novelty and couples it with conservative policy updates.\n\nAcross Atari and continuous-control domains with drifting dynamics, our method achieves superior sample efficiency and stability, and ablations confirm the role of recency in balancing exploration and exploitation.\nRelated Work\n\nDetecting anomalies in multivariate time series is vital for monitoring industrial systems and cloud services. The challenge lies in handling seasonality, rare events, and inter-variable dependencies.\n\nClassical anomaly detection leverages ARIMA residual tests, STL decomposition, and control charts, while deep methods introduce autoencoders, VAEs, GANs, LSTMs, and Transformers for reconstruction or prediction errors (Tsay, 2010; Malhotra et al., 2015; An and Cho, 2015; Li et al., 2019; Xu et al., 2021).\n\nWe present Contrastive Forecasting with Graph Priors (CFGP), which learns structure-aware representations via self-supervised objectives and uses calibrated predictive intervals to flag anomalies.\nIntroduction\n\nGeneralizing manipulation skills across objects, tasks, and environments remains a central challenge in robotics. Sparse rewards, safety constraints, and hardware variability complicate learning on physical systems. Recent work studies imitation learning, offline RL, and model-based control for dexterous manipulation (Rajeswaran et al., 2018; Lynch et al., 2020; Nagabandi et al., 2019; Ahn et al., 2022). Despite these advances, scaling data collection and ensuring sim-to-real transfer continue to be bottlenecks.\n\nWe explore a curriculum that interleaves skill discovery from teleoperation logs with conservative online updates, targeting stable improvements under limited interaction budgets.\nRelated Work\n\nConversational recommenders. Systems that interactively elicit user preferences can reduce cold-start and improve satisfaction (Sun and Zhang, 2018). Dialog policy learning for conversational recommendation has explored supervised learning, reinforcement learning, and bandit methods (Christakopoulou et al., 2016; Lei et al., 2020; Chen et al., 2019). User simulators and counterfactual logging have been proposed to address data scarcity and evaluation challenges (Li et al., 2017; Chi et al., 2020).\n\nOur study investigates preference drift over long-horizon sessions and proposes a state representation that explicitly tracks uncertainty and recency effects.\nIntroduction\n\nExplainable AI (XAI) is increasingly required for medical imaging systems used in screening and triage. Beyond predictive accuracy, clinicians demand transparency about what image features drive automated decisions and whether explanations are stable under shifts.\n\nPost-hoc attribution methods like Grad-CAM and Integrated Gradients highlight salient regions (Selvaraju et al., 2017; Sundararajan et al., 2017). Prototype- and concept-based explanations enhance interpretability (Chen et al., 2019; Kim et al., 2018). Counterfactual generation has been explored for medical images (Chang et al., 2018; Singla et al., 2021).\n\nWe focus on faithfulness under distribution shift and propose an evaluation protocol that aligns explanation stability with clinical acceptance thresholds for screening workflows.\nRelated Work\n\nProviding timely, actionable feedback at scale is central to computing education. Traditional approaches combine instructor-designed rubrics with automated tests, but coverage and specificity can be limited for diverse student solutions.\n\nAutomated feedback for programming assignments has been tackled with static analysis, dynamic test generation, and pattern mining (Ke et al., 2016; Gulwani et al., 2018; Singh et al., 2013). Recent NLP-based systems leverage code embeddings, sequence models, and pretrained language models (Allamanis et al., 2018; Feng et al., 2020; Ahmad et al., 2021). Peer learning platforms collect hints and exemplars to guide novice programmers (Piech et al., 2015; Wang et al., 2018).\n\nWhile data-driven approaches show promise, they often struggle with generalizing across tasks and providing pedagogically aligned guidance. Our work investigates structure-aware hint generation that aligns feedback to conceptual steps in problem-solving.\nRelated Work\n\nReinforcement learning (RL) has enabled robots to acquire complex behaviors directly from interaction. However, data hunger, safety, and sim-to-real transfer remain persistent obstacles for deployment in real-world settings.\n\nModel-free methods such as DDPG (Lillicrap et al., 2016), SAC (Haarnoja et al., 2018), and PPO (Schulman et al., 2017) have been widely adopted for continuous control, while model-based approaches leverage learned dynamics for sample efficiency (Deisenroth and Rasmussen, 2011; Chua et al., 2018). Recent lines of work explore offline RL (Levine et al., 2020; Kumar et al., 2020) and representation learning for policy generalization (Laskin et al., 2020; Yarats et al., 2021). Domain randomization and adaptation seek to bridge the sim-to-real gap (Tobin et al., 2017; Peng et al., 2018).\n\nWe propose a training strategy that combines curriculum learning with uncertainty-aware policy updates to improve safety and sample efficiency in robotic manipulation.\nRelated Work\n\nAutomatic speech recognition (ASR) systems increasingly rely on large encoder\u2013decoder architectures that are costly to deploy on edge devices. Knowledge distillation (KD) is a common strategy to reduce model size while preserving accuracy.\n\nKnowledge distillation for speech recognition has considered frame-level supervision, sequence-level criteria, and wordpiece distributions, transferring knowledge from stronger teachers to smaller students (Hinton et al., 2015; Kim and Rush, 2016; Kurata and Audhkhasi, 2018; Higuchi et al., 2021).\n\nOther compression techniques include quantization and pruning, which can be combined with KD but may degrade robustness to noise and speaker variability. Recent work explores multi-teacher ensembles and intermediate-layer matching to stabilize training.\n\nIn this paper, we study streaming-constrained KD with latency-aware targets, aligning teacher and student under causal masking. Our experiments on LibriSpeech and far-field corpora show improved WER\u2013latency trade-offs compared to strong baselines.\nRelated Work\n\nLarge Language Models and Prompting\nLarge language models (LLMs) exhibit emergent program synthesis capabilities when conditioned on natural language instructions and a handful of examples. While these behaviors reduce reliance on supervised datasets, the mechanisms by which prompts control generation remain only partially understood. Prior studies analyze calibration, decoding strategies, and context length effects.\n\nPrompting for Code Generation\nPrompting for code generation has explored zero-shot, few-shot, and chain-of-thought styles using large language models (Chen et al., 2021; Austin et al., 2021; Nijkamp et al., 2022; Li et al., 2023). Work on compiler-aware prompting adds execution feedback to steer generation (Liu et al., 2022; Le et al., 2022; Wang et al., 2023). Program repair and test-driven synthesis have similarly adapted prompting strategies to satisfy unit tests (Jain et al., 2022; Zhang et al., 2023).\n\nExecution-Conditioned Decoding\nBeyond static prompts, execution-conditioned decoding iteratively runs partial programs to reduce search space. Studies report gains on algorithmic problems by interleaving generation and verification under timeouts and sandboxing constraints.\n\nStructured Constraints and Type Guidance\nApproaches that inject grammar constraints or type information restrict invalid outputs and improve pass rates. These methods range from constrained beam search to type-state automata.\n\nPositioning\nWe examine the interaction between prompt structure and execution feedback and study how typed constraints alter search dynamics under limited budgets.\nRelated Work\n\nFederated learning (FL) enables on-device training with privacy and communication constraints. Ensuring rigorous privacy guarantees while preserving model utility remains a core challenge.\n\nPrivacy in federated learning has been studied via differential privacy at the client level, secure aggregation, and shuffling (McMahan et al., 2017; Kairouz et al., 2021; Bonawitz et al., 2017; Erlingsson et al., 2019). Gradient perturbation, clipping, and client subsampling are common techniques to control privacy loss (Abadi et al., 2016; Thakkar et al., 2019; Andrew et al., 2021). Auditing methods estimate empirical privacy leakage post hoc (Nasr et al., 2019; Jagielski et al., 2020).\n\nOur approach introduces client-adaptive noise schedules conditioned on participation frequency.\n\nWe empirically evaluate privacy-utility trade-offs across heterogeneous client populations.\nIntroduction\n\nInformation retrieval has shifted from lexical term matching to semantic representations that capture contextual meaning. This shift enables better recall of paraphrased content but introduces new challenges in index efficiency and training stability.\n\nNeural semantic search methods combine dual-encoders for efficient retrieval (Yao et al., 2019; Xie and Zhao, 2020) with cross-encoders for reranking (Nogueira and Cho, 2019; Li et al., 2021), and leverage hard-negative mining to improve discriminative power (Gao et al., 2021; Huang et al., 2022). Recent work also explores domain adaptation for specialized corpora such as legal and biomedical texts (Park et al., 2022; Sun et al., 2023).\n\nWe study lightweight domain adaptation under tight indexing budgets.\nRelated Work\n\nDetecting anomalies in time-series is a long-standing problem with applications in monitoring, finance, and industrial IoT. Methods vary widely in assumptions, supervision requirements, and scalability.\n\nTime-series anomaly detection spans classical statistical tests, isolation-based methods, and deep learning models such as autoencoders, temporal convolutional networks, and Transformers (Gupta et al., 2014; Liu et al., 2008; Malhotra et al., 2016; Xu et al., 2020). Synthetic anomaly injection and semi-supervised training are also common practices (Zhang et al., 2019; Shen et al., 2021).\n\nBenchmarking efforts have sought consistent evaluation protocols across datasets with different anomaly types and frequencies (Hundman et al., 2018; Wu and Keogh, 2021).\nRelated Work\n\nPredicting molecular properties from structure has catalyzed a broad literature at the intersection of cheminformatics and geometric deep learning. Approaches differ in how they encode graph topology, chemical attributes, and geometric constraints.\n\nGraph representation learning methods such as spectral GCNs, spatial message passing networks, and attention-based GNNs have been widely applied to molecular property prediction (Kipf and Welling, 2017; Gilmer et al., 2017; Veli\u010dkovi\u0107 et al., 2018). Extensions include edge-conditioned convolutions, higher-order structures, and equivariant networks for 3D geometries (Simonovsky and Komodakis, 2017; Batzner et al., 2022).\n\nPretraining strategies on large unlabeled molecule corpora with contrastive or masked node prediction objectives have further improved generalization, especially in low-data regimes (Hu et al., 2020; Rong et al., 2020).\nIntroduction\n\nAutomated analysis of pathology whole-slide images (WSIs) faces extreme resolution, sparse lesion patterns, and distribution shifts across scanners and staining protocols. Convolutional networks have advanced the field but can be limited in modeling long-range dependencies over gigapixel slides.\n\nVision Transformers have been applied to medical image classification, segmentation, and detection with pure transformer backbones or hybrid CNN\u2013Transformer designs (Dosovitskiy et al., 2020; Chen et al., 2021; Hatamizadeh et al., 2022; Wang et al., 2021; Xie et al., 2021).\n\nWeakly supervised multiple-instance learning (MIL) further alleviates slide-level labeling costs by aggregating patch evidence, yet attention pooling can overfit to spurious correlations. We investigate whether token-level sparsification combined with instance reweighting can improve robustness in cross-site evaluation.\n\nOur method introduces a curriculum-sparse token selection and slide-consistent calibration loss to stabilize attention under domain shift. On three WSI benchmarks spanning different scanners, we observe gains in AUC and improved calibration, with minimal added compute.\n\nWe conduct ablations on sparsity schedules and release pretrained weights for community use.\nRelated Work\n\nRemote sensing change detection relies on robust representations that separate illumination and seasonal effects from structural changes. Recent advances in high-resolution satellites have shifted attention to fine-grained, building-level change cues.\n\nClassical two-stream CNNs, Siamese architectures, and attention-based models have been widely adopted for change detection (Daudt et al., 2018; Fang et al., 2020; Chen et al., 2021). Large-scale datasets such as LEVIR-CD, CDD, and WHU-CD have enabled benchmarking across urban scenes (Levir et al., 2020; Wang et al., 2020; Ji et al., 2019). Transformer-based encoders further improve long-range modeling (Ban et al., 2021; Liu et al., 2021).\n\nWhile these efforts improve accuracy, they largely assume perfectly registered image pairs and abundant labels. Our work targets label-scarce scenarios with misalignment by learning registration-aware tokens that disentangle geometry from appearance.\nIntroduction\n\nEffective human-robot collaboration requires balancing adaptability to user intent with guarantees on safety and task efficiency. Real-world deployments must operate under partial observability and distribution shifts in user behavior.\n\nShared autonomy techniques span predictive user intent modeling, POMDP-based assistance, arbitration policies that blend human and robot commands, and learning from demonstration for collaborative tasks (Dragan and Srinivasa, 2013; Javdani et al., 2015; Reddy et al., 2018; Losey et al., 2020).\n\nWe propose CertAssist, a certifiably safe shared autonomy framework combining control barrier functions with belief-dependent arbitration, evaluated on manipulation and navigation tasks with human participants.\nIntroduction\nAccurate forecasting underpins decision-making in supply chains, energy, and finance. Models must balance bias-variance trade-offs, handle sparse covariates, and remain robust to nonstationary shifts and irregular sampling.\n\nClassical time series forecasting relies on ARIMA and exponential smoothing to model linear dependencies (Box and Jenkins, 1970; Hyndman et al., 2008). Neural models introduce nonlinearity via RNNs, LSTMs, and temporal convolutions (Hochreiter and Schmidhuber, 1997; Bai et al., 2018). Transformer-based forecasters use attention to capture long-range dependencies (Li et al., 2019; Zhou et al., 2021). Decomposition and frequency-domain methods further reduce complexity and highlight seasonal structure (Oreshkin et al., 2020; Wu et al., 2021).\n\nWe present an uncertainty-aware spectral transformer that couples learnable seasonal kernels with interval calibration, yielding improved accuracy and coverage under regime shifts in retail and traffic datasets.\nRelated Work\n\nControllable text generation seeks to guide large language models (LLMs) toward specified attributes with minimal task-specific supervision. Recent approaches either modify inputs via prompts or adjust model parameters through lightweight adapters.\n\nPrompt-based methods for steering pre-trained language models have been explored in a variety of settings. Discrete prompt mining identifies trigger tokens that elicit desired behavior (Kim and Park, 2020; Zhou et al., 2021). Continuous prompt tuning replaces hard prompts with trainable embeddings (Li and Sung, 2021; Qin et al., 2022). Instruction following with few-shot exemplars has also been shown to improve task transfer (Rao and Lin, 2021; Xu et al., 2022).\n\nAdapter-based control introduces small task-specific modules into frozen backbones, enabling multi-task training while limiting memory costs (Chen et al., 2021; Gupta and Lee, 2022). Other lines include decoding constraints (He and Zhao, 2020) and classifier-guided re-ranking (Sharma et al., 2021).\n\nIn parallel, evaluation protocols for controllability measure attribute accuracy, content preservation, and fluency (Liu et al., 2020; Feng and Ma, 2021).\nRelated Work\n\nFederated learning enables collaborative training across a population of devices while keeping raw data local. The distributed setting raises new challenges in privacy, robustness, and communication efficiency.\n\nPrivacy in federated learning has been studied through differential privacy mechanisms for client updates (Abadi et al., 2016; McMahan et al., 2018), secure aggregation protocols to hide individual contributions (Bonawitz et al., 2017), split learning to keep raw data on-device (Gupta and Raskar, 2018), and cryptographic techniques like homomorphic encryption and MPC (Gentry, 2009; Mohassel and Zhang, 2017). Communication reduction has been addressed via sparsification and quantization (Stich et al., 2018; Kone\u010dn\u00fd et al., 2016).\n\nOur method jointly optimizes privacy noise allocation and gradient compression schedules under a fixed bandwidth budget.\nIntroduction\n\nUrban congestion degrades mobility, increases emissions, and undermines economic productivity. Adaptive traffic signal control promises to improve throughput by tailoring signal plans to real-time conditions. Reinforcement learning offers a data-driven framework to learn such policies directly from interaction.\n\nClassical traffic signal control uses handcrafted rules and model-based optimization (Webster, 1958; Gartner, 1983). RL-based approaches apply tabular Q-learning, deep Q-networks, and policy gradients to learn adaptive strategies (Abdoos et al., 2013; Van der Pol and Oliehoek, 2016; Wei et al., 2018). Multi-agent methods coordinate intersections via shared critics or communication (Chu et al., 2019; Zang et al., 2020; Chen et al., 2020). In this work, we propose a hierarchical actor-critic that decomposes phase selection and duration control.\n\nWe validate our approach on synthetic and real-world networks, showing gains in average travel time and queue length.\nRelated Work\n\nMultimodal summarization seeks to distill essential content by integrating complementary cues across text, images, and video. Approaches differ in the depth of fusion, supervision requirements, and the granularity of output (sentential vs. extractive vs. abstractive).\n\nEarly multimodal summarization methods fuse visual features with textual encoders (Li et al., 2017; Chen and Bansal, 2018). Video summarization leverages temporal attention and key-shot selection (Zhang et al., 2016; Rochan and Wang, 2019). Recent transformer-based models introduce cross-modal alignment modules (Liu et al., 2021; Zeng et al., 2022).\n\nDespite the progress, practical systems must handle noisy modalities and domain shifts. Our study focuses on robust alignment under weak supervision and evaluates consistency constraints that mitigate cross-modal mismatch.\nIntroduction\n\nLearning control policies in simulation and transferring them to real robots reduces data collection cost but introduces the reality gap problem. A wide range of techniques aim to close this gap by randomizing simulators or adapting policies.\n\nFor sim-to-real transfer in robotics, domain randomization perturbs textures and dynamics (Tobin et al., 2017; Peng et al., 2018), while domain adaptation aligns feature distributions (Tzeng et al., 2017; Ganin et al., 2016). Recent work leverages privileged information (Rajeswaran et al., 2017), online adaptation (Chebotar et al., 2019), and residual policy learning (Johannink et al., 2019).\n\nHardware-aware policy learning and safety constraints have been explored to ensure feasible trajectories under actuation limits (Dalal et al., 2018; Berkenkamp et al., 2017).\n\nWe evaluate a modular adaptation pipeline on manipulation and locomotion tasks.\nRelated Work\n\nMedical image segmentation has long relied on convolutional architectures such as U-Net and its variants due to their inductive biases and efficiency (Ronneberger et al., 2015; Milletari et al., 2016). Recent progress in self-attention and transformers has motivated their application to dense prediction.\n\nTransformer-based segmentation has been explored through pure-ViT decoders, hybrid CNN\u2013ViT backbones, and pyramid tokens (Chen et al., 2021; Strudel et al., 2021; Xie et al., 2021). Medical adaptations include axial attention, windowed self-attention, and lightweight transformers (Wang et al., 2021; Hatamizadeh et al., 2022; Chen et al., 2022). Further studies consider multi-scale fusion and boundary-aware losses (Oktay et al., 2018; Kirillov et al., 2020; Zhao et al., 2017).\n\nRecent benchmarks reveal the sensitivity of ViT-based models to training data size and augmentation strategies (Dosovitskiy et al., 2021; Touvron et al., 2021). However, clinical datasets remain small and heterogeneous, posing challenges for generalization.\n\nWe present a compact hybrid that targets data efficiency by constraining attention spans and sharing parameters across scales, evaluating on multi-institutional MRI and CT cohorts.\nRelated Work\n\nClassic Indexing\nB-trees and hash tables offer predictable performance envelopes and decades of engineering maturity. Their behavior under skew and dynamic workloads has inspired numerous variants.\n\nLearned Indexes\nLearned index structures replace trees or hash tables with models that map keys to positions, using linear models, neural networks, or mixture-of-experts (Kraska et al., 2018; Ding et al., 2020; Marcus et al., 2021). Alternatives use recursive models or spline approximations to bound errors (Kipf et al., 2019; Ferragina and Vinciguerra, 2020).\n\nSystems Concerns\nUpdate handling, concurrency control, and memory locality remain central challenges for adopting learned indexes in production.\n\nOur Scope\nWe study latency tails under shifting key distributions and propose a controller that adapts model partitions online.\nIntroduction\n\nHigh-resolution climate information is crucial for local risk assessment, yet global climate models operate at coarse spatial scales. Statistical downscaling offers a data-driven pathway to bridge this scale gap using historical observations.\n\nDeep learning for statistical downscaling includes convolutional super-resolution architectures such as SRCNN and EDSR adapted to climate grids (Dong et al., 2014; Lim et al., 2017), U-Net variants tailored for precipitation fields (Ronneberger et al., 2015; Pan et al., 2019), and GAN-based methods like SRGAN and ESRGAN for sharper extremes (Ledig et al., 2017; Wang et al., 2018). Diffusion-based super-resolution has also been explored for geospatial data (Saharia et al., 2022; Rombach et al., 2022). Bias correction has been combined with deep downscalers via adversarial or quantile mapping losses (Zhang et al., 2020; Vaittinada Ayar et al., 2021).\n\nWe propose a physically guided diffusion downscaler that conditions on coarse-scale dynamics and enforces conservation via soft constraints.\nIntroduction\n\nUnderstanding human affect from speech enables richer human-computer interaction and mental health monitoring. However, variability in speakers, environments, and label granularity complicates modeling.\n\nSpeech emotion recognition has adopted CNNs for spectrogram features (Satt et al., 2017), recurrent models for temporal dynamics (Zhang et al., 2018), attention mechanisms (Mirsamadi et al., 2017), and multimodal fusion with text and video (Poria et al., 2017). Self-supervised pretraining with wav2vec-style encoders has also improved performance (Baevski et al., 2020; Pepino et al., 2021).\n\nDataset imbalance and domain shift across corpora are ongoing challenges, with cross-corpus evaluation highlighting generalization issues.\n\nWe present EmoAdapter, a lightweight adapter-based architecture for efficient fine-tuning on small emotion datasets.\n",
        "completion": "Speech emotion recognition has adopted CNNs for spectrogram features (Satt et al., 2017), recurrent models for temporal dynamics (Zhang et al., 2018), attention mechanisms (Mirsamadi et al., 2017), and multimodal fusion with text and video (Poria et al., 2017). Self-supervised pretraining with wav2vec-style encoders has also improved performance (Baevski et al., 2020; Pepino et al., 2021)."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        occurs when either:\n    a) The author describes or cites papers without connecting them to their own work/argument \n    b) Or only follows up the summary of previous works with their own contribution without explicitly highlighting the gap their work intends to research.\n    c) It does not articulate the author's perspective or motivation.\n    d) A lack of argument/opinion in the first paragraph is permissible as it serves to be the foundation of the author's argument \n    e) Lacks synthesis issues appear either as single sentences or multiple sentences.\n    Examples of lack of synthesis include:\n        i) No elaboration of own contribution/argument:\"Following early neural approaches to question answering, many subsequent studies adopt a pipeline architecture consisting of retrieval and comprehension components. The retrieval component focuses on identifying relevant documents or passages from a large corpus, while the comprehension component extracts an answer span from the retrieved text. Initial models relied on recurrent neural networks with attention mechanisms to encode questions and contexts (Seo et al., 2017; Wang et al., 2017).\"\n        ii)  No explanation of the cited works and relation to their own work: \u201cRecently, several studies have explored the use of prompting techniques with pre-trained language models to influence model outputs or access latent knowledge (Brown et al., 2020; Gao et al., 2021; Liu et al., 2021; Wei et al., 2022).\u201d \n\n        Example text: \n        Related Work\n\nDevelopers rely on code search to find relevant snippets, APIs, or examples. Unlike general document retrieval, code search must bridge natural language intent and program structure.\n\nNeural code search has been addressed with bi-encoders, cross-encoders, and dual learning (Gu et al., 2018; Husain et al., 2019; Feng et al., 2020). Structural representations incorporate ASTs, control flow, and data flow (Alon et al., 2019; Wang et al., 2020; Liu et al., 2021). Pretraining on code and NL improves retrieval metrics across languages (Ahmad et al., 2021; Guo et al., 2021).\n\nIn this paper, we introduce a language-agnostic retriever with compositional queries.\n\nWe evaluate zero-shot transfer across four programming languages.\nIntroduction\n\nGeneralization in text classification can be improved with data augmentation, especially when labeled data are scarce or imbalanced. Approaches range from rule-based edits to model-driven paraphrasing and representation-space mixing.\n\nText augmentation techniques include synonym replacement, random insertion/deletion, back-translation, paraphrase generation, and mixup in embedding or hidden spaces (Wei and Zou, 2019; Sennrich et al., 2016; Kobayashi, 2018; Guo et al., 2020). Recent work explores task-adaptive augmentation policies learned by reinforcement learning (Xie et al., 2020).\n\nEvaluation typically considers robustness to domain shift, label noise, and distributional skew across multiple benchmarks (Pruksachatkun et al., 2020; Hendrycks et al., 2020).\nRelated Work\n\nKnowledge graph completion predicts missing links by learning entity and relation representations. Methods vary in how they encode semantics and handle patterns like symmetry, hierarchy, and composition.\n\nTranslation-based knowledge graph embeddings model relations as translations in vector space (Bordes et al., 2013; Wang et al., 2014), while bilinear and neural models capture more complex interactions (Nickel et al., 2011; Trouillon et al., 2016; Sun et al., 2019). Regularization and rule-guided approaches improve inductive bias and data efficiency (Rockt\u00e4schel et al., 2015; Minervini et al., 2017).\n\nWe introduce a lightweight compositional constraint for hierarchical relations and evaluate on three benchmarks and an industry dataset.\nRelated Work\n\nEnsuring safety during reinforcement learning is critical in real-world control where violations can be costly. Research has proposed both objective-level and mechanism-level solutions.\n\nSafe reinforcement learning approaches include risk-sensitive objectives such as CVaR optimization (Tamar et al., 2015; Chow et al., 2018), constrained policy optimization with safety budgets (Achiam et al., 2017; Yang et al., 2020), and shielding based on model-checking or supervisors (Alshiekh et al., 2018; Dalal et al., 2018). We develop a method that integrates model-predictive constraints with policy gradients.\n\nBenchmarks often evaluate safety in simulated robotics or navigation with cost functions approximating constraint violations (Ray et al., 2019; Bharadhwaj et al., 2021).\nRelated Work\n\nDialog state tracking (DST) has evolved from rule-based slot filling to neural architectures that jointly infer belief states across turns. Early pipeline models used hand-crafted lexicons and semantic frames (Singh and Patel, 2015), but suffered from brittleness to paraphrase and noise. Neural encoders introduced robustness by contextualizing utterances, incorporating attention over dialog history, and modeling slot-value dependencies (Lee et al., 2018; Choe and Kim, 2019).\n\nPretrained language models have further shifted the landscape by enabling few-shot generalization and open-vocabulary slot values. Fine-tuning BERT-like encoders for DST improved cross-domain transfer (Rao et al., 2020), while generative formulations cast state tracking as text-to-text prediction (Mendez et al., 2021).\n\nPrompting-based approaches have also been explored for dialog modeling (Kumar et al., 2021; Ortega and Lin, 2022; Park et al., 2023). These methods condition large language models on task instructions or few-shot exemplars to elicit latent conversational knowledge. Recent variants incorporate calibration or self-consistency to stabilize outputs (Fang et al., 2023; Zhou et al., 2023).\n\nPosition relative to this paper While we also employ pretrained sequence-to-sequence models, our focus is on handling ontology drift in long-running deployments. Specifically, we introduce an adaptive slot schema encoder that aligns evolving taxonomies with dialog evidence, and a contrastive consistency objective to mitigate spurious slot co-activations across domains.\nIntroduction\n\nSelf-supervised learning (SSL) has become the dominant paradigm for learning transferable visual features without labels. By constructing pretext tasks that expose invariances and structure inherent in data, SSL models can match or surpass supervised baselines on many downstream tasks.\n\nContrastive pretraining has been widely adopted for visual representations (Chen et al., 2020; He et al., 2020; Xie and Xu, 2021). Non-contrastive methods remove negative pairs and rely on architectural or objective asymmetries (Grill et al., 2020; Tian et al., 2021). Clustering-based methods jointly learn assignments and embeddings (Caron et al., 2018; Li and Gao, 2022).\n\nDespite these advances, industrial applications often operate under strict memory budgets and latency constraints. In this paper, we investigate compute-aware pretraining objectives that couple multi-crop augmentation with a token-subsampled backbone. We present a latency-regularized alignment loss that preserves downstream accuracy while reducing FLOPs during both pretraining and fine-tuning.\nIntroduction\n\nEfficient exploration remains a central challenge in reinforcement learning (RL), particularly in sparse-reward environments where naive strategies fail to discover rewarding states. Over-exploration, however, can waste samples and destabilize learning.\n\nExploration in reinforcement learning has been advanced by count-based bonuses, intrinsic motivation, curiosity-driven prediction error, and information-theoretic objectives (Bellemare et al., 2016; Pathak et al., 2017; Houthooft et al., 2016; Burda et al., 2019; Ta\u00efga et al., 2020).\n\nYet, when environment dynamics change over time, stale novelty estimates can encourage revisiting obsolete states. We propose a recency-aware intrinsic reward that discounts outdated novelty and couples it with conservative policy updates.\n\nAcross Atari and continuous-control domains with drifting dynamics, our method achieves superior sample efficiency and stability, and ablations confirm the role of recency in balancing exploration and exploitation.\nRelated Work\n\nDetecting anomalies in multivariate time series is vital for monitoring industrial systems and cloud services. The challenge lies in handling seasonality, rare events, and inter-variable dependencies.\n\nClassical anomaly detection leverages ARIMA residual tests, STL decomposition, and control charts, while deep methods introduce autoencoders, VAEs, GANs, LSTMs, and Transformers for reconstruction or prediction errors (Tsay, 2010; Malhotra et al., 2015; An and Cho, 2015; Li et al., 2019; Xu et al., 2021).\n\nWe present Contrastive Forecasting with Graph Priors (CFGP), which learns structure-aware representations via self-supervised objectives and uses calibrated predictive intervals to flag anomalies.\nIntroduction\n\nGeneralizing manipulation skills across objects, tasks, and environments remains a central challenge in robotics. Sparse rewards, safety constraints, and hardware variability complicate learning on physical systems. Recent work studies imitation learning, offline RL, and model-based control for dexterous manipulation (Rajeswaran et al., 2018; Lynch et al., 2020; Nagabandi et al., 2019; Ahn et al., 2022). Despite these advances, scaling data collection and ensuring sim-to-real transfer continue to be bottlenecks.\n\nWe explore a curriculum that interleaves skill discovery from teleoperation logs with conservative online updates, targeting stable improvements under limited interaction budgets.\nRelated Work\n\nConversational recommenders. Systems that interactively elicit user preferences can reduce cold-start and improve satisfaction (Sun and Zhang, 2018). Dialog policy learning for conversational recommendation has explored supervised learning, reinforcement learning, and bandit methods (Christakopoulou et al., 2016; Lei et al., 2020; Chen et al., 2019). User simulators and counterfactual logging have been proposed to address data scarcity and evaluation challenges (Li et al., 2017; Chi et al., 2020).\n\nOur study investigates preference drift over long-horizon sessions and proposes a state representation that explicitly tracks uncertainty and recency effects.\nIntroduction\n\nExplainable AI (XAI) is increasingly required for medical imaging systems used in screening and triage. Beyond predictive accuracy, clinicians demand transparency about what image features drive automated decisions and whether explanations are stable under shifts.\n\nPost-hoc attribution methods like Grad-CAM and Integrated Gradients highlight salient regions (Selvaraju et al., 2017; Sundararajan et al., 2017). Prototype- and concept-based explanations enhance interpretability (Chen et al., 2019; Kim et al., 2018). Counterfactual generation has been explored for medical images (Chang et al., 2018; Singla et al., 2021).\n\nWe focus on faithfulness under distribution shift and propose an evaluation protocol that aligns explanation stability with clinical acceptance thresholds for screening workflows.\nRelated Work\n\nProviding timely, actionable feedback at scale is central to computing education. Traditional approaches combine instructor-designed rubrics with automated tests, but coverage and specificity can be limited for diverse student solutions.\n\nAutomated feedback for programming assignments has been tackled with static analysis, dynamic test generation, and pattern mining (Ke et al., 2016; Gulwani et al., 2018; Singh et al., 2013). Recent NLP-based systems leverage code embeddings, sequence models, and pretrained language models (Allamanis et al., 2018; Feng et al., 2020; Ahmad et al., 2021). Peer learning platforms collect hints and exemplars to guide novice programmers (Piech et al., 2015; Wang et al., 2018).\n\nWhile data-driven approaches show promise, they often struggle with generalizing across tasks and providing pedagogically aligned guidance. Our work investigates structure-aware hint generation that aligns feedback to conceptual steps in problem-solving.\nRelated Work\n\nReinforcement learning (RL) has enabled robots to acquire complex behaviors directly from interaction. However, data hunger, safety, and sim-to-real transfer remain persistent obstacles for deployment in real-world settings.\n\nModel-free methods such as DDPG (Lillicrap et al., 2016), SAC (Haarnoja et al., 2018), and PPO (Schulman et al., 2017) have been widely adopted for continuous control, while model-based approaches leverage learned dynamics for sample efficiency (Deisenroth and Rasmussen, 2011; Chua et al., 2018). Recent lines of work explore offline RL (Levine et al., 2020; Kumar et al., 2020) and representation learning for policy generalization (Laskin et al., 2020; Yarats et al., 2021). Domain randomization and adaptation seek to bridge the sim-to-real gap (Tobin et al., 2017; Peng et al., 2018).\n\nWe propose a training strategy that combines curriculum learning with uncertainty-aware policy updates to improve safety and sample efficiency in robotic manipulation.\nRelated Work\n\nAutomatic speech recognition (ASR) systems increasingly rely on large encoder\u2013decoder architectures that are costly to deploy on edge devices. Knowledge distillation (KD) is a common strategy to reduce model size while preserving accuracy.\n\nKnowledge distillation for speech recognition has considered frame-level supervision, sequence-level criteria, and wordpiece distributions, transferring knowledge from stronger teachers to smaller students (Hinton et al., 2015; Kim and Rush, 2016; Kurata and Audhkhasi, 2018; Higuchi et al., 2021).\n\nOther compression techniques include quantization and pruning, which can be combined with KD but may degrade robustness to noise and speaker variability. Recent work explores multi-teacher ensembles and intermediate-layer matching to stabilize training.\n\nIn this paper, we study streaming-constrained KD with latency-aware targets, aligning teacher and student under causal masking. Our experiments on LibriSpeech and far-field corpora show improved WER\u2013latency trade-offs compared to strong baselines.\nRelated Work\n\nLarge Language Models and Prompting\nLarge language models (LLMs) exhibit emergent program synthesis capabilities when conditioned on natural language instructions and a handful of examples. While these behaviors reduce reliance on supervised datasets, the mechanisms by which prompts control generation remain only partially understood. Prior studies analyze calibration, decoding strategies, and context length effects.\n\nPrompting for Code Generation\nPrompting for code generation has explored zero-shot, few-shot, and chain-of-thought styles using large language models (Chen et al., 2021; Austin et al., 2021; Nijkamp et al., 2022; Li et al., 2023). Work on compiler-aware prompting adds execution feedback to steer generation (Liu et al., 2022; Le et al., 2022; Wang et al., 2023). Program repair and test-driven synthesis have similarly adapted prompting strategies to satisfy unit tests (Jain et al., 2022; Zhang et al., 2023).\n\nExecution-Conditioned Decoding\nBeyond static prompts, execution-conditioned decoding iteratively runs partial programs to reduce search space. Studies report gains on algorithmic problems by interleaving generation and verification under timeouts and sandboxing constraints.\n\nStructured Constraints and Type Guidance\nApproaches that inject grammar constraints or type information restrict invalid outputs and improve pass rates. These methods range from constrained beam search to type-state automata.\n\nPositioning\nWe examine the interaction between prompt structure and execution feedback and study how typed constraints alter search dynamics under limited budgets.\nRelated Work\n\nFederated learning (FL) enables on-device training with privacy and communication constraints. Ensuring rigorous privacy guarantees while preserving model utility remains a core challenge.\n\nPrivacy in federated learning has been studied via differential privacy at the client level, secure aggregation, and shuffling (McMahan et al., 2017; Kairouz et al., 2021; Bonawitz et al., 2017; Erlingsson et al., 2019). Gradient perturbation, clipping, and client subsampling are common techniques to control privacy loss (Abadi et al., 2016; Thakkar et al., 2019; Andrew et al., 2021). Auditing methods estimate empirical privacy leakage post hoc (Nasr et al., 2019; Jagielski et al., 2020).\n\nOur approach introduces client-adaptive noise schedules conditioned on participation frequency.\n\nWe empirically evaluate privacy-utility trade-offs across heterogeneous client populations.\nIntroduction\n\nInformation retrieval has shifted from lexical term matching to semantic representations that capture contextual meaning. This shift enables better recall of paraphrased content but introduces new challenges in index efficiency and training stability.\n\nNeural semantic search methods combine dual-encoders for efficient retrieval (Yao et al., 2019; Xie and Zhao, 2020) with cross-encoders for reranking (Nogueira and Cho, 2019; Li et al., 2021), and leverage hard-negative mining to improve discriminative power (Gao et al., 2021; Huang et al., 2022). Recent work also explores domain adaptation for specialized corpora such as legal and biomedical texts (Park et al., 2022; Sun et al., 2023).\n\nWe study lightweight domain adaptation under tight indexing budgets.\nRelated Work\n\nDetecting anomalies in time-series is a long-standing problem with applications in monitoring, finance, and industrial IoT. Methods vary widely in assumptions, supervision requirements, and scalability.\n\nTime-series anomaly detection spans classical statistical tests, isolation-based methods, and deep learning models such as autoencoders, temporal convolutional networks, and Transformers (Gupta et al., 2014; Liu et al., 2008; Malhotra et al., 2016; Xu et al., 2020). Synthetic anomaly injection and semi-supervised training are also common practices (Zhang et al., 2019; Shen et al., 2021).\n\nBenchmarking efforts have sought consistent evaluation protocols across datasets with different anomaly types and frequencies (Hundman et al., 2018; Wu and Keogh, 2021).\nRelated Work\n\nPredicting molecular properties from structure has catalyzed a broad literature at the intersection of cheminformatics and geometric deep learning. Approaches differ in how they encode graph topology, chemical attributes, and geometric constraints.\n\nGraph representation learning methods such as spectral GCNs, spatial message passing networks, and attention-based GNNs have been widely applied to molecular property prediction (Kipf and Welling, 2017; Gilmer et al., 2017; Veli\u010dkovi\u0107 et al., 2018). Extensions include edge-conditioned convolutions, higher-order structures, and equivariant networks for 3D geometries (Simonovsky and Komodakis, 2017; Batzner et al., 2022).\n\nPretraining strategies on large unlabeled molecule corpora with contrastive or masked node prediction objectives have further improved generalization, especially in low-data regimes (Hu et al., 2020; Rong et al., 2020).\nIntroduction\n\nAutomated analysis of pathology whole-slide images (WSIs) faces extreme resolution, sparse lesion patterns, and distribution shifts across scanners and staining protocols. Convolutional networks have advanced the field but can be limited in modeling long-range dependencies over gigapixel slides.\n\nVision Transformers have been applied to medical image classification, segmentation, and detection with pure transformer backbones or hybrid CNN\u2013Transformer designs (Dosovitskiy et al., 2020; Chen et al., 2021; Hatamizadeh et al., 2022; Wang et al., 2021; Xie et al., 2021).\n\nWeakly supervised multiple-instance learning (MIL) further alleviates slide-level labeling costs by aggregating patch evidence, yet attention pooling can overfit to spurious correlations. We investigate whether token-level sparsification combined with instance reweighting can improve robustness in cross-site evaluation.\n\nOur method introduces a curriculum-sparse token selection and slide-consistent calibration loss to stabilize attention under domain shift. On three WSI benchmarks spanning different scanners, we observe gains in AUC and improved calibration, with minimal added compute.\n\nWe conduct ablations on sparsity schedules and release pretrained weights for community use.\nRelated Work\n\nRemote sensing change detection relies on robust representations that separate illumination and seasonal effects from structural changes. Recent advances in high-resolution satellites have shifted attention to fine-grained, building-level change cues.\n\nClassical two-stream CNNs, Siamese architectures, and attention-based models have been widely adopted for change detection (Daudt et al., 2018; Fang et al., 2020; Chen et al., 2021). Large-scale datasets such as LEVIR-CD, CDD, and WHU-CD have enabled benchmarking across urban scenes (Levir et al., 2020; Wang et al., 2020; Ji et al., 2019). Transformer-based encoders further improve long-range modeling (Ban et al., 2021; Liu et al., 2021).\n\nWhile these efforts improve accuracy, they largely assume perfectly registered image pairs and abundant labels. Our work targets label-scarce scenarios with misalignment by learning registration-aware tokens that disentangle geometry from appearance.\nIntroduction\n\nEffective human-robot collaboration requires balancing adaptability to user intent with guarantees on safety and task efficiency. Real-world deployments must operate under partial observability and distribution shifts in user behavior.\n\nShared autonomy techniques span predictive user intent modeling, POMDP-based assistance, arbitration policies that blend human and robot commands, and learning from demonstration for collaborative tasks (Dragan and Srinivasa, 2013; Javdani et al., 2015; Reddy et al., 2018; Losey et al., 2020).\n\nWe propose CertAssist, a certifiably safe shared autonomy framework combining control barrier functions with belief-dependent arbitration, evaluated on manipulation and navigation tasks with human participants.\nIntroduction\nAccurate forecasting underpins decision-making in supply chains, energy, and finance. Models must balance bias-variance trade-offs, handle sparse covariates, and remain robust to nonstationary shifts and irregular sampling.\n\nClassical time series forecasting relies on ARIMA and exponential smoothing to model linear dependencies (Box and Jenkins, 1970; Hyndman et al., 2008). Neural models introduce nonlinearity via RNNs, LSTMs, and temporal convolutions (Hochreiter and Schmidhuber, 1997; Bai et al., 2018). Transformer-based forecasters use attention to capture long-range dependencies (Li et al., 2019; Zhou et al., 2021). Decomposition and frequency-domain methods further reduce complexity and highlight seasonal structure (Oreshkin et al., 2020; Wu et al., 2021).\n\nWe present an uncertainty-aware spectral transformer that couples learnable seasonal kernels with interval calibration, yielding improved accuracy and coverage under regime shifts in retail and traffic datasets.\nRelated Work\n\nControllable text generation seeks to guide large language models (LLMs) toward specified attributes with minimal task-specific supervision. Recent approaches either modify inputs via prompts or adjust model parameters through lightweight adapters.\n\nPrompt-based methods for steering pre-trained language models have been explored in a variety of settings. Discrete prompt mining identifies trigger tokens that elicit desired behavior (Kim and Park, 2020; Zhou et al., 2021). Continuous prompt tuning replaces hard prompts with trainable embeddings (Li and Sung, 2021; Qin et al., 2022). Instruction following with few-shot exemplars has also been shown to improve task transfer (Rao and Lin, 2021; Xu et al., 2022).\n\nAdapter-based control introduces small task-specific modules into frozen backbones, enabling multi-task training while limiting memory costs (Chen et al., 2021; Gupta and Lee, 2022). Other lines include decoding constraints (He and Zhao, 2020) and classifier-guided re-ranking (Sharma et al., 2021).\n\nIn parallel, evaluation protocols for controllability measure attribute accuracy, content preservation, and fluency (Liu et al., 2020; Feng and Ma, 2021).\nRelated Work\n\nFederated learning enables collaborative training across a population of devices while keeping raw data local. The distributed setting raises new challenges in privacy, robustness, and communication efficiency.\n\nPrivacy in federated learning has been studied through differential privacy mechanisms for client updates (Abadi et al., 2016; McMahan et al., 2018), secure aggregation protocols to hide individual contributions (Bonawitz et al., 2017), split learning to keep raw data on-device (Gupta and Raskar, 2018), and cryptographic techniques like homomorphic encryption and MPC (Gentry, 2009; Mohassel and Zhang, 2017). Communication reduction has been addressed via sparsification and quantization (Stich et al., 2018; Kone\u010dn\u00fd et al., 2016).\n\nOur method jointly optimizes privacy noise allocation and gradient compression schedules under a fixed bandwidth budget.\nIntroduction\n\nUrban congestion degrades mobility, increases emissions, and undermines economic productivity. Adaptive traffic signal control promises to improve throughput by tailoring signal plans to real-time conditions. Reinforcement learning offers a data-driven framework to learn such policies directly from interaction.\n\nClassical traffic signal control uses handcrafted rules and model-based optimization (Webster, 1958; Gartner, 1983). RL-based approaches apply tabular Q-learning, deep Q-networks, and policy gradients to learn adaptive strategies (Abdoos et al., 2013; Van der Pol and Oliehoek, 2016; Wei et al., 2018). Multi-agent methods coordinate intersections via shared critics or communication (Chu et al., 2019; Zang et al., 2020; Chen et al., 2020). In this work, we propose a hierarchical actor-critic that decomposes phase selection and duration control.\n\nWe validate our approach on synthetic and real-world networks, showing gains in average travel time and queue length.\nRelated Work\n\nMultimodal summarization seeks to distill essential content by integrating complementary cues across text, images, and video. Approaches differ in the depth of fusion, supervision requirements, and the granularity of output (sentential vs. extractive vs. abstractive).\n\nEarly multimodal summarization methods fuse visual features with textual encoders (Li et al., 2017; Chen and Bansal, 2018). Video summarization leverages temporal attention and key-shot selection (Zhang et al., 2016; Rochan and Wang, 2019). Recent transformer-based models introduce cross-modal alignment modules (Liu et al., 2021; Zeng et al., 2022).\n\nDespite the progress, practical systems must handle noisy modalities and domain shifts. Our study focuses on robust alignment under weak supervision and evaluates consistency constraints that mitigate cross-modal mismatch.\nIntroduction\n\nLearning control policies in simulation and transferring them to real robots reduces data collection cost but introduces the reality gap problem. A wide range of techniques aim to close this gap by randomizing simulators or adapting policies.\n\nFor sim-to-real transfer in robotics, domain randomization perturbs textures and dynamics (Tobin et al., 2017; Peng et al., 2018), while domain adaptation aligns feature distributions (Tzeng et al., 2017; Ganin et al., 2016). Recent work leverages privileged information (Rajeswaran et al., 2017), online adaptation (Chebotar et al., 2019), and residual policy learning (Johannink et al., 2019).\n\nHardware-aware policy learning and safety constraints have been explored to ensure feasible trajectories under actuation limits (Dalal et al., 2018; Berkenkamp et al., 2017).\n\nWe evaluate a modular adaptation pipeline on manipulation and locomotion tasks.\nRelated Work\n\nMedical image segmentation has long relied on convolutional architectures such as U-Net and its variants due to their inductive biases and efficiency (Ronneberger et al., 2015; Milletari et al., 2016). Recent progress in self-attention and transformers has motivated their application to dense prediction.\n\nTransformer-based segmentation has been explored through pure-ViT decoders, hybrid CNN\u2013ViT backbones, and pyramid tokens (Chen et al., 2021; Strudel et al., 2021; Xie et al., 2021). Medical adaptations include axial attention, windowed self-attention, and lightweight transformers (Wang et al., 2021; Hatamizadeh et al., 2022; Chen et al., 2022). Further studies consider multi-scale fusion and boundary-aware losses (Oktay et al., 2018; Kirillov et al., 2020; Zhao et al., 2017).\n\nRecent benchmarks reveal the sensitivity of ViT-based models to training data size and augmentation strategies (Dosovitskiy et al., 2021; Touvron et al., 2021). However, clinical datasets remain small and heterogeneous, posing challenges for generalization.\n\nWe present a compact hybrid that targets data efficiency by constraining attention spans and sharing parameters across scales, evaluating on multi-institutional MRI and CT cohorts.\nRelated Work\n\nClassic Indexing\nB-trees and hash tables offer predictable performance envelopes and decades of engineering maturity. Their behavior under skew and dynamic workloads has inspired numerous variants.\n\nLearned Indexes\nLearned index structures replace trees or hash tables with models that map keys to positions, using linear models, neural networks, or mixture-of-experts (Kraska et al., 2018; Ding et al., 2020; Marcus et al., 2021). Alternatives use recursive models or spline approximations to bound errors (Kipf et al., 2019; Ferragina and Vinciguerra, 2020).\n\nSystems Concerns\nUpdate handling, concurrency control, and memory locality remain central challenges for adopting learned indexes in production.\n\nOur Scope\nWe study latency tails under shifting key distributions and propose a controller that adapts model partitions online.\nIntroduction\n\nHigh-resolution climate information is crucial for local risk assessment, yet global climate models operate at coarse spatial scales. Statistical downscaling offers a data-driven pathway to bridge this scale gap using historical observations.\n\nDeep learning for statistical downscaling includes convolutional super-resolution architectures such as SRCNN and EDSR adapted to climate grids (Dong et al., 2014; Lim et al., 2017), U-Net variants tailored for precipitation fields (Ronneberger et al., 2015; Pan et al., 2019), and GAN-based methods like SRGAN and ESRGAN for sharper extremes (Ledig et al., 2017; Wang et al., 2018). Diffusion-based super-resolution has also been explored for geospatial data (Saharia et al., 2022; Rombach et al., 2022). Bias correction has been combined with deep downscalers via adversarial or quantile mapping losses (Zhang et al., 2020; Vaittinada Ayar et al., 2021).\n\nWe propose a physically guided diffusion downscaler that conditions on coarse-scale dynamics and enforces conservation via soft constraints.\nIntroduction\n\nUnderstanding human affect from speech enables richer human-computer interaction and mental health monitoring. However, variability in speakers, environments, and label granularity complicates modeling.\n\nSpeech emotion recognition has adopted CNNs for spectrogram features (Satt et al., 2017), recurrent models for temporal dynamics (Zhang et al., 2018), attention mechanisms (Mirsamadi et al., 2017), and multimodal fusion with text and video (Poria et al., 2017). Self-supervised pretraining with wav2vec-style encoders has also improved performance (Baevski et al., 2020; Pepino et al., 2021).\n\nDataset imbalance and domain shift across corpora are ongoing challenges, with cross-corpus evaluation highlighting generalization issues.\n\nWe present EmoAdapter, a lightweight adapter-based architecture for efficient fine-tuning on small emotion datasets.\nIntroduction\n\nProviding timely, high-quality formative feedback at scale is a central challenge in writing pedagogy. Automated writing evaluation (AWE) tools offer partially automated support for feedback generation and revision guidance.\n\nAutomated writing evaluation systems leverage rule-based NLP, neural classifiers, and large language models to provide feedback (Attali and Burstein, 2006; Mathias et al., 2020; Rei et al., 2021; Zhuang et al., 2023; OpenAI, 2023). Complementary research examines rubric alignment, fairness, and reliability of automated scoring (Williamson et al., 2012; Beigman Klebanov and Madnani, 2020).\n\nThis paper reports a classroom deployment study of a feedback assistant but does not contrast its mechanisms with those of prior AWE systems.\n",
        "completion": "Automated writing evaluation systems leverage rule-based NLP, neural classifiers, and large language models to provide feedback (Attali and Burstein, 2006; Mathias et al., 2020; Rei et al., 2021; Zhuang et al., 2023; OpenAI, 2023)."
    },
    {
        "prompt": "Extract the words or sub-sentences that have an issue in citation or argumentation around prior work in the provided example, according to this definition: \n        occurs when either:\n    a) The author describes or cites papers without connecting them to their own work/argument \n    b) Or only follows up the summary of previous works with their own contribution without explicitly highlighting the gap their work intends to research.\n    c) It does not articulate the author's perspective or motivation.\n    d) A lack of argument/opinion in the first paragraph is permissible as it serves to be the foundation of the author's argument \n    e) Lacks synthesis issues appear either as single sentences or multiple sentences.\n    Examples of lack of synthesis include:\n        i) No elaboration of own contribution/argument:\"Following early neural approaches to question answering, many subsequent studies adopt a pipeline architecture consisting of retrieval and comprehension components. The retrieval component focuses on identifying relevant documents or passages from a large corpus, while the comprehension component extracts an answer span from the retrieved text. Initial models relied on recurrent neural networks with attention mechanisms to encode questions and contexts (Seo et al., 2017; Wang et al., 2017).\"\n        ii)  No explanation of the cited works and relation to their own work: \u201cRecently, several studies have explored the use of prompting techniques with pre-trained language models to influence model outputs or access latent knowledge (Brown et al., 2020; Gao et al., 2021; Liu et al., 2021; Wei et al., 2022).\u201d \n\n        Example text: \n        Related Work\n\nDevelopers rely on code search to find relevant snippets, APIs, or examples. Unlike general document retrieval, code search must bridge natural language intent and program structure.\n\nNeural code search has been addressed with bi-encoders, cross-encoders, and dual learning (Gu et al., 2018; Husain et al., 2019; Feng et al., 2020). Structural representations incorporate ASTs, control flow, and data flow (Alon et al., 2019; Wang et al., 2020; Liu et al., 2021). Pretraining on code and NL improves retrieval metrics across languages (Ahmad et al., 2021; Guo et al., 2021).\n\nIn this paper, we introduce a language-agnostic retriever with compositional queries.\n\nWe evaluate zero-shot transfer across four programming languages.\nIntroduction\n\nGeneralization in text classification can be improved with data augmentation, especially when labeled data are scarce or imbalanced. Approaches range from rule-based edits to model-driven paraphrasing and representation-space mixing.\n\nText augmentation techniques include synonym replacement, random insertion/deletion, back-translation, paraphrase generation, and mixup in embedding or hidden spaces (Wei and Zou, 2019; Sennrich et al., 2016; Kobayashi, 2018; Guo et al., 2020). Recent work explores task-adaptive augmentation policies learned by reinforcement learning (Xie et al., 2020).\n\nEvaluation typically considers robustness to domain shift, label noise, and distributional skew across multiple benchmarks (Pruksachatkun et al., 2020; Hendrycks et al., 2020).\nRelated Work\n\nKnowledge graph completion predicts missing links by learning entity and relation representations. Methods vary in how they encode semantics and handle patterns like symmetry, hierarchy, and composition.\n\nTranslation-based knowledge graph embeddings model relations as translations in vector space (Bordes et al., 2013; Wang et al., 2014), while bilinear and neural models capture more complex interactions (Nickel et al., 2011; Trouillon et al., 2016; Sun et al., 2019). Regularization and rule-guided approaches improve inductive bias and data efficiency (Rockt\u00e4schel et al., 2015; Minervini et al., 2017).\n\nWe introduce a lightweight compositional constraint for hierarchical relations and evaluate on three benchmarks and an industry dataset.\nRelated Work\n\nEnsuring safety during reinforcement learning is critical in real-world control where violations can be costly. Research has proposed both objective-level and mechanism-level solutions.\n\nSafe reinforcement learning approaches include risk-sensitive objectives such as CVaR optimization (Tamar et al., 2015; Chow et al., 2018), constrained policy optimization with safety budgets (Achiam et al., 2017; Yang et al., 2020), and shielding based on model-checking or supervisors (Alshiekh et al., 2018; Dalal et al., 2018). We develop a method that integrates model-predictive constraints with policy gradients.\n\nBenchmarks often evaluate safety in simulated robotics or navigation with cost functions approximating constraint violations (Ray et al., 2019; Bharadhwaj et al., 2021).\nRelated Work\n\nDialog state tracking (DST) has evolved from rule-based slot filling to neural architectures that jointly infer belief states across turns. Early pipeline models used hand-crafted lexicons and semantic frames (Singh and Patel, 2015), but suffered from brittleness to paraphrase and noise. Neural encoders introduced robustness by contextualizing utterances, incorporating attention over dialog history, and modeling slot-value dependencies (Lee et al., 2018; Choe and Kim, 2019).\n\nPretrained language models have further shifted the landscape by enabling few-shot generalization and open-vocabulary slot values. Fine-tuning BERT-like encoders for DST improved cross-domain transfer (Rao et al., 2020), while generative formulations cast state tracking as text-to-text prediction (Mendez et al., 2021).\n\nPrompting-based approaches have also been explored for dialog modeling (Kumar et al., 2021; Ortega and Lin, 2022; Park et al., 2023). These methods condition large language models on task instructions or few-shot exemplars to elicit latent conversational knowledge. Recent variants incorporate calibration or self-consistency to stabilize outputs (Fang et al., 2023; Zhou et al., 2023).\n\nPosition relative to this paper While we also employ pretrained sequence-to-sequence models, our focus is on handling ontology drift in long-running deployments. Specifically, we introduce an adaptive slot schema encoder that aligns evolving taxonomies with dialog evidence, and a contrastive consistency objective to mitigate spurious slot co-activations across domains.\nIntroduction\n\nSelf-supervised learning (SSL) has become the dominant paradigm for learning transferable visual features without labels. By constructing pretext tasks that expose invariances and structure inherent in data, SSL models can match or surpass supervised baselines on many downstream tasks.\n\nContrastive pretraining has been widely adopted for visual representations (Chen et al., 2020; He et al., 2020; Xie and Xu, 2021). Non-contrastive methods remove negative pairs and rely on architectural or objective asymmetries (Grill et al., 2020; Tian et al., 2021). Clustering-based methods jointly learn assignments and embeddings (Caron et al., 2018; Li and Gao, 2022).\n\nDespite these advances, industrial applications often operate under strict memory budgets and latency constraints. In this paper, we investigate compute-aware pretraining objectives that couple multi-crop augmentation with a token-subsampled backbone. We present a latency-regularized alignment loss that preserves downstream accuracy while reducing FLOPs during both pretraining and fine-tuning.\nIntroduction\n\nEfficient exploration remains a central challenge in reinforcement learning (RL), particularly in sparse-reward environments where naive strategies fail to discover rewarding states. Over-exploration, however, can waste samples and destabilize learning.\n\nExploration in reinforcement learning has been advanced by count-based bonuses, intrinsic motivation, curiosity-driven prediction error, and information-theoretic objectives (Bellemare et al., 2016; Pathak et al., 2017; Houthooft et al., 2016; Burda et al., 2019; Ta\u00efga et al., 2020).\n\nYet, when environment dynamics change over time, stale novelty estimates can encourage revisiting obsolete states. We propose a recency-aware intrinsic reward that discounts outdated novelty and couples it with conservative policy updates.\n\nAcross Atari and continuous-control domains with drifting dynamics, our method achieves superior sample efficiency and stability, and ablations confirm the role of recency in balancing exploration and exploitation.\nRelated Work\n\nDetecting anomalies in multivariate time series is vital for monitoring industrial systems and cloud services. The challenge lies in handling seasonality, rare events, and inter-variable dependencies.\n\nClassical anomaly detection leverages ARIMA residual tests, STL decomposition, and control charts, while deep methods introduce autoencoders, VAEs, GANs, LSTMs, and Transformers for reconstruction or prediction errors (Tsay, 2010; Malhotra et al., 2015; An and Cho, 2015; Li et al., 2019; Xu et al., 2021).\n\nWe present Contrastive Forecasting with Graph Priors (CFGP), which learns structure-aware representations via self-supervised objectives and uses calibrated predictive intervals to flag anomalies.\nIntroduction\n\nGeneralizing manipulation skills across objects, tasks, and environments remains a central challenge in robotics. Sparse rewards, safety constraints, and hardware variability complicate learning on physical systems. Recent work studies imitation learning, offline RL, and model-based control for dexterous manipulation (Rajeswaran et al., 2018; Lynch et al., 2020; Nagabandi et al., 2019; Ahn et al., 2022). Despite these advances, scaling data collection and ensuring sim-to-real transfer continue to be bottlenecks.\n\nWe explore a curriculum that interleaves skill discovery from teleoperation logs with conservative online updates, targeting stable improvements under limited interaction budgets.\nRelated Work\n\nConversational recommenders. Systems that interactively elicit user preferences can reduce cold-start and improve satisfaction (Sun and Zhang, 2018). Dialog policy learning for conversational recommendation has explored supervised learning, reinforcement learning, and bandit methods (Christakopoulou et al., 2016; Lei et al., 2020; Chen et al., 2019). User simulators and counterfactual logging have been proposed to address data scarcity and evaluation challenges (Li et al., 2017; Chi et al., 2020).\n\nOur study investigates preference drift over long-horizon sessions and proposes a state representation that explicitly tracks uncertainty and recency effects.\nIntroduction\n\nExplainable AI (XAI) is increasingly required for medical imaging systems used in screening and triage. Beyond predictive accuracy, clinicians demand transparency about what image features drive automated decisions and whether explanations are stable under shifts.\n\nPost-hoc attribution methods like Grad-CAM and Integrated Gradients highlight salient regions (Selvaraju et al., 2017; Sundararajan et al., 2017). Prototype- and concept-based explanations enhance interpretability (Chen et al., 2019; Kim et al., 2018). Counterfactual generation has been explored for medical images (Chang et al., 2018; Singla et al., 2021).\n\nWe focus on faithfulness under distribution shift and propose an evaluation protocol that aligns explanation stability with clinical acceptance thresholds for screening workflows.\nRelated Work\n\nProviding timely, actionable feedback at scale is central to computing education. Traditional approaches combine instructor-designed rubrics with automated tests, but coverage and specificity can be limited for diverse student solutions.\n\nAutomated feedback for programming assignments has been tackled with static analysis, dynamic test generation, and pattern mining (Ke et al., 2016; Gulwani et al., 2018; Singh et al., 2013). Recent NLP-based systems leverage code embeddings, sequence models, and pretrained language models (Allamanis et al., 2018; Feng et al., 2020; Ahmad et al., 2021). Peer learning platforms collect hints and exemplars to guide novice programmers (Piech et al., 2015; Wang et al., 2018).\n\nWhile data-driven approaches show promise, they often struggle with generalizing across tasks and providing pedagogically aligned guidance. Our work investigates structure-aware hint generation that aligns feedback to conceptual steps in problem-solving.\nRelated Work\n\nReinforcement learning (RL) has enabled robots to acquire complex behaviors directly from interaction. However, data hunger, safety, and sim-to-real transfer remain persistent obstacles for deployment in real-world settings.\n\nModel-free methods such as DDPG (Lillicrap et al., 2016), SAC (Haarnoja et al., 2018), and PPO (Schulman et al., 2017) have been widely adopted for continuous control, while model-based approaches leverage learned dynamics for sample efficiency (Deisenroth and Rasmussen, 2011; Chua et al., 2018). Recent lines of work explore offline RL (Levine et al., 2020; Kumar et al., 2020) and representation learning for policy generalization (Laskin et al., 2020; Yarats et al., 2021). Domain randomization and adaptation seek to bridge the sim-to-real gap (Tobin et al., 2017; Peng et al., 2018).\n\nWe propose a training strategy that combines curriculum learning with uncertainty-aware policy updates to improve safety and sample efficiency in robotic manipulation.\nRelated Work\n\nAutomatic speech recognition (ASR) systems increasingly rely on large encoder\u2013decoder architectures that are costly to deploy on edge devices. Knowledge distillation (KD) is a common strategy to reduce model size while preserving accuracy.\n\nKnowledge distillation for speech recognition has considered frame-level supervision, sequence-level criteria, and wordpiece distributions, transferring knowledge from stronger teachers to smaller students (Hinton et al., 2015; Kim and Rush, 2016; Kurata and Audhkhasi, 2018; Higuchi et al., 2021).\n\nOther compression techniques include quantization and pruning, which can be combined with KD but may degrade robustness to noise and speaker variability. Recent work explores multi-teacher ensembles and intermediate-layer matching to stabilize training.\n\nIn this paper, we study streaming-constrained KD with latency-aware targets, aligning teacher and student under causal masking. Our experiments on LibriSpeech and far-field corpora show improved WER\u2013latency trade-offs compared to strong baselines.\nRelated Work\n\nLarge Language Models and Prompting\nLarge language models (LLMs) exhibit emergent program synthesis capabilities when conditioned on natural language instructions and a handful of examples. While these behaviors reduce reliance on supervised datasets, the mechanisms by which prompts control generation remain only partially understood. Prior studies analyze calibration, decoding strategies, and context length effects.\n\nPrompting for Code Generation\nPrompting for code generation has explored zero-shot, few-shot, and chain-of-thought styles using large language models (Chen et al., 2021; Austin et al., 2021; Nijkamp et al., 2022; Li et al., 2023). Work on compiler-aware prompting adds execution feedback to steer generation (Liu et al., 2022; Le et al., 2022; Wang et al., 2023). Program repair and test-driven synthesis have similarly adapted prompting strategies to satisfy unit tests (Jain et al., 2022; Zhang et al., 2023).\n\nExecution-Conditioned Decoding\nBeyond static prompts, execution-conditioned decoding iteratively runs partial programs to reduce search space. Studies report gains on algorithmic problems by interleaving generation and verification under timeouts and sandboxing constraints.\n\nStructured Constraints and Type Guidance\nApproaches that inject grammar constraints or type information restrict invalid outputs and improve pass rates. These methods range from constrained beam search to type-state automata.\n\nPositioning\nWe examine the interaction between prompt structure and execution feedback and study how typed constraints alter search dynamics under limited budgets.\nRelated Work\n\nFederated learning (FL) enables on-device training with privacy and communication constraints. Ensuring rigorous privacy guarantees while preserving model utility remains a core challenge.\n\nPrivacy in federated learning has been studied via differential privacy at the client level, secure aggregation, and shuffling (McMahan et al., 2017; Kairouz et al., 2021; Bonawitz et al., 2017; Erlingsson et al., 2019). Gradient perturbation, clipping, and client subsampling are common techniques to control privacy loss (Abadi et al., 2016; Thakkar et al., 2019; Andrew et al., 2021). Auditing methods estimate empirical privacy leakage post hoc (Nasr et al., 2019; Jagielski et al., 2020).\n\nOur approach introduces client-adaptive noise schedules conditioned on participation frequency.\n\nWe empirically evaluate privacy-utility trade-offs across heterogeneous client populations.\nIntroduction\n\nInformation retrieval has shifted from lexical term matching to semantic representations that capture contextual meaning. This shift enables better recall of paraphrased content but introduces new challenges in index efficiency and training stability.\n\nNeural semantic search methods combine dual-encoders for efficient retrieval (Yao et al., 2019; Xie and Zhao, 2020) with cross-encoders for reranking (Nogueira and Cho, 2019; Li et al., 2021), and leverage hard-negative mining to improve discriminative power (Gao et al., 2021; Huang et al., 2022). Recent work also explores domain adaptation for specialized corpora such as legal and biomedical texts (Park et al., 2022; Sun et al., 2023).\n\nWe study lightweight domain adaptation under tight indexing budgets.\nRelated Work\n\nDetecting anomalies in time-series is a long-standing problem with applications in monitoring, finance, and industrial IoT. Methods vary widely in assumptions, supervision requirements, and scalability.\n\nTime-series anomaly detection spans classical statistical tests, isolation-based methods, and deep learning models such as autoencoders, temporal convolutional networks, and Transformers (Gupta et al., 2014; Liu et al., 2008; Malhotra et al., 2016; Xu et al., 2020). Synthetic anomaly injection and semi-supervised training are also common practices (Zhang et al., 2019; Shen et al., 2021).\n\nBenchmarking efforts have sought consistent evaluation protocols across datasets with different anomaly types and frequencies (Hundman et al., 2018; Wu and Keogh, 2021).\nRelated Work\n\nPredicting molecular properties from structure has catalyzed a broad literature at the intersection of cheminformatics and geometric deep learning. Approaches differ in how they encode graph topology, chemical attributes, and geometric constraints.\n\nGraph representation learning methods such as spectral GCNs, spatial message passing networks, and attention-based GNNs have been widely applied to molecular property prediction (Kipf and Welling, 2017; Gilmer et al., 2017; Veli\u010dkovi\u0107 et al., 2018). Extensions include edge-conditioned convolutions, higher-order structures, and equivariant networks for 3D geometries (Simonovsky and Komodakis, 2017; Batzner et al., 2022).\n\nPretraining strategies on large unlabeled molecule corpora with contrastive or masked node prediction objectives have further improved generalization, especially in low-data regimes (Hu et al., 2020; Rong et al., 2020).\nIntroduction\n\nAutomated analysis of pathology whole-slide images (WSIs) faces extreme resolution, sparse lesion patterns, and distribution shifts across scanners and staining protocols. Convolutional networks have advanced the field but can be limited in modeling long-range dependencies over gigapixel slides.\n\nVision Transformers have been applied to medical image classification, segmentation, and detection with pure transformer backbones or hybrid CNN\u2013Transformer designs (Dosovitskiy et al., 2020; Chen et al., 2021; Hatamizadeh et al., 2022; Wang et al., 2021; Xie et al., 2021).\n\nWeakly supervised multiple-instance learning (MIL) further alleviates slide-level labeling costs by aggregating patch evidence, yet attention pooling can overfit to spurious correlations. We investigate whether token-level sparsification combined with instance reweighting can improve robustness in cross-site evaluation.\n\nOur method introduces a curriculum-sparse token selection and slide-consistent calibration loss to stabilize attention under domain shift. On three WSI benchmarks spanning different scanners, we observe gains in AUC and improved calibration, with minimal added compute.\n\nWe conduct ablations on sparsity schedules and release pretrained weights for community use.\nRelated Work\n\nRemote sensing change detection relies on robust representations that separate illumination and seasonal effects from structural changes. Recent advances in high-resolution satellites have shifted attention to fine-grained, building-level change cues.\n\nClassical two-stream CNNs, Siamese architectures, and attention-based models have been widely adopted for change detection (Daudt et al., 2018; Fang et al., 2020; Chen et al., 2021). Large-scale datasets such as LEVIR-CD, CDD, and WHU-CD have enabled benchmarking across urban scenes (Levir et al., 2020; Wang et al., 2020; Ji et al., 2019). Transformer-based encoders further improve long-range modeling (Ban et al., 2021; Liu et al., 2021).\n\nWhile these efforts improve accuracy, they largely assume perfectly registered image pairs and abundant labels. Our work targets label-scarce scenarios with misalignment by learning registration-aware tokens that disentangle geometry from appearance.\nIntroduction\n\nEffective human-robot collaboration requires balancing adaptability to user intent with guarantees on safety and task efficiency. Real-world deployments must operate under partial observability and distribution shifts in user behavior.\n\nShared autonomy techniques span predictive user intent modeling, POMDP-based assistance, arbitration policies that blend human and robot commands, and learning from demonstration for collaborative tasks (Dragan and Srinivasa, 2013; Javdani et al., 2015; Reddy et al., 2018; Losey et al., 2020).\n\nWe propose CertAssist, a certifiably safe shared autonomy framework combining control barrier functions with belief-dependent arbitration, evaluated on manipulation and navigation tasks with human participants.\nIntroduction\nAccurate forecasting underpins decision-making in supply chains, energy, and finance. Models must balance bias-variance trade-offs, handle sparse covariates, and remain robust to nonstationary shifts and irregular sampling.\n\nClassical time series forecasting relies on ARIMA and exponential smoothing to model linear dependencies (Box and Jenkins, 1970; Hyndman et al., 2008). Neural models introduce nonlinearity via RNNs, LSTMs, and temporal convolutions (Hochreiter and Schmidhuber, 1997; Bai et al., 2018). Transformer-based forecasters use attention to capture long-range dependencies (Li et al., 2019; Zhou et al., 2021). Decomposition and frequency-domain methods further reduce complexity and highlight seasonal structure (Oreshkin et al., 2020; Wu et al., 2021).\n\nWe present an uncertainty-aware spectral transformer that couples learnable seasonal kernels with interval calibration, yielding improved accuracy and coverage under regime shifts in retail and traffic datasets.\nRelated Work\n\nControllable text generation seeks to guide large language models (LLMs) toward specified attributes with minimal task-specific supervision. Recent approaches either modify inputs via prompts or adjust model parameters through lightweight adapters.\n\nPrompt-based methods for steering pre-trained language models have been explored in a variety of settings. Discrete prompt mining identifies trigger tokens that elicit desired behavior (Kim and Park, 2020; Zhou et al., 2021). Continuous prompt tuning replaces hard prompts with trainable embeddings (Li and Sung, 2021; Qin et al., 2022). Instruction following with few-shot exemplars has also been shown to improve task transfer (Rao and Lin, 2021; Xu et al., 2022).\n\nAdapter-based control introduces small task-specific modules into frozen backbones, enabling multi-task training while limiting memory costs (Chen et al., 2021; Gupta and Lee, 2022). Other lines include decoding constraints (He and Zhao, 2020) and classifier-guided re-ranking (Sharma et al., 2021).\n\nIn parallel, evaluation protocols for controllability measure attribute accuracy, content preservation, and fluency (Liu et al., 2020; Feng and Ma, 2021).\nRelated Work\n\nFederated learning enables collaborative training across a population of devices while keeping raw data local. The distributed setting raises new challenges in privacy, robustness, and communication efficiency.\n\nPrivacy in federated learning has been studied through differential privacy mechanisms for client updates (Abadi et al., 2016; McMahan et al., 2018), secure aggregation protocols to hide individual contributions (Bonawitz et al., 2017), split learning to keep raw data on-device (Gupta and Raskar, 2018), and cryptographic techniques like homomorphic encryption and MPC (Gentry, 2009; Mohassel and Zhang, 2017). Communication reduction has been addressed via sparsification and quantization (Stich et al., 2018; Kone\u010dn\u00fd et al., 2016).\n\nOur method jointly optimizes privacy noise allocation and gradient compression schedules under a fixed bandwidth budget.\nIntroduction\n\nUrban congestion degrades mobility, increases emissions, and undermines economic productivity. Adaptive traffic signal control promises to improve throughput by tailoring signal plans to real-time conditions. Reinforcement learning offers a data-driven framework to learn such policies directly from interaction.\n\nClassical traffic signal control uses handcrafted rules and model-based optimization (Webster, 1958; Gartner, 1983). RL-based approaches apply tabular Q-learning, deep Q-networks, and policy gradients to learn adaptive strategies (Abdoos et al., 2013; Van der Pol and Oliehoek, 2016; Wei et al., 2018). Multi-agent methods coordinate intersections via shared critics or communication (Chu et al., 2019; Zang et al., 2020; Chen et al., 2020). In this work, we propose a hierarchical actor-critic that decomposes phase selection and duration control.\n\nWe validate our approach on synthetic and real-world networks, showing gains in average travel time and queue length.\nRelated Work\n\nMultimodal summarization seeks to distill essential content by integrating complementary cues across text, images, and video. Approaches differ in the depth of fusion, supervision requirements, and the granularity of output (sentential vs. extractive vs. abstractive).\n\nEarly multimodal summarization methods fuse visual features with textual encoders (Li et al., 2017; Chen and Bansal, 2018). Video summarization leverages temporal attention and key-shot selection (Zhang et al., 2016; Rochan and Wang, 2019). Recent transformer-based models introduce cross-modal alignment modules (Liu et al., 2021; Zeng et al., 2022).\n\nDespite the progress, practical systems must handle noisy modalities and domain shifts. Our study focuses on robust alignment under weak supervision and evaluates consistency constraints that mitigate cross-modal mismatch.\nIntroduction\n\nLearning control policies in simulation and transferring them to real robots reduces data collection cost but introduces the reality gap problem. A wide range of techniques aim to close this gap by randomizing simulators or adapting policies.\n\nFor sim-to-real transfer in robotics, domain randomization perturbs textures and dynamics (Tobin et al., 2017; Peng et al., 2018), while domain adaptation aligns feature distributions (Tzeng et al., 2017; Ganin et al., 2016). Recent work leverages privileged information (Rajeswaran et al., 2017), online adaptation (Chebotar et al., 2019), and residual policy learning (Johannink et al., 2019).\n\nHardware-aware policy learning and safety constraints have been explored to ensure feasible trajectories under actuation limits (Dalal et al., 2018; Berkenkamp et al., 2017).\n\nWe evaluate a modular adaptation pipeline on manipulation and locomotion tasks.\nRelated Work\n\nMedical image segmentation has long relied on convolutional architectures such as U-Net and its variants due to their inductive biases and efficiency (Ronneberger et al., 2015; Milletari et al., 2016). Recent progress in self-attention and transformers has motivated their application to dense prediction.\n\nTransformer-based segmentation has been explored through pure-ViT decoders, hybrid CNN\u2013ViT backbones, and pyramid tokens (Chen et al., 2021; Strudel et al., 2021; Xie et al., 2021). Medical adaptations include axial attention, windowed self-attention, and lightweight transformers (Wang et al., 2021; Hatamizadeh et al., 2022; Chen et al., 2022). Further studies consider multi-scale fusion and boundary-aware losses (Oktay et al., 2018; Kirillov et al., 2020; Zhao et al., 2017).\n\nRecent benchmarks reveal the sensitivity of ViT-based models to training data size and augmentation strategies (Dosovitskiy et al., 2021; Touvron et al., 2021). However, clinical datasets remain small and heterogeneous, posing challenges for generalization.\n\nWe present a compact hybrid that targets data efficiency by constraining attention spans and sharing parameters across scales, evaluating on multi-institutional MRI and CT cohorts.\nRelated Work\n\nClassic Indexing\nB-trees and hash tables offer predictable performance envelopes and decades of engineering maturity. Their behavior under skew and dynamic workloads has inspired numerous variants.\n\nLearned Indexes\nLearned index structures replace trees or hash tables with models that map keys to positions, using linear models, neural networks, or mixture-of-experts (Kraska et al., 2018; Ding et al., 2020; Marcus et al., 2021). Alternatives use recursive models or spline approximations to bound errors (Kipf et al., 2019; Ferragina and Vinciguerra, 2020).\n\nSystems Concerns\nUpdate handling, concurrency control, and memory locality remain central challenges for adopting learned indexes in production.\n\nOur Scope\nWe study latency tails under shifting key distributions and propose a controller that adapts model partitions online.\nIntroduction\n\nHigh-resolution climate information is crucial for local risk assessment, yet global climate models operate at coarse spatial scales. Statistical downscaling offers a data-driven pathway to bridge this scale gap using historical observations.\n\nDeep learning for statistical downscaling includes convolutional super-resolution architectures such as SRCNN and EDSR adapted to climate grids (Dong et al., 2014; Lim et al., 2017), U-Net variants tailored for precipitation fields (Ronneberger et al., 2015; Pan et al., 2019), and GAN-based methods like SRGAN and ESRGAN for sharper extremes (Ledig et al., 2017; Wang et al., 2018). Diffusion-based super-resolution has also been explored for geospatial data (Saharia et al., 2022; Rombach et al., 2022). Bias correction has been combined with deep downscalers via adversarial or quantile mapping losses (Zhang et al., 2020; Vaittinada Ayar et al., 2021).\n\nWe propose a physically guided diffusion downscaler that conditions on coarse-scale dynamics and enforces conservation via soft constraints.\nIntroduction\n\nUnderstanding human affect from speech enables richer human-computer interaction and mental health monitoring. However, variability in speakers, environments, and label granularity complicates modeling.\n\nSpeech emotion recognition has adopted CNNs for spectrogram features (Satt et al., 2017), recurrent models for temporal dynamics (Zhang et al., 2018), attention mechanisms (Mirsamadi et al., 2017), and multimodal fusion with text and video (Poria et al., 2017). Self-supervised pretraining with wav2vec-style encoders has also improved performance (Baevski et al., 2020; Pepino et al., 2021).\n\nDataset imbalance and domain shift across corpora are ongoing challenges, with cross-corpus evaluation highlighting generalization issues.\n\nWe present EmoAdapter, a lightweight adapter-based architecture for efficient fine-tuning on small emotion datasets.\nIntroduction\n\nProviding timely, high-quality formative feedback at scale is a central challenge in writing pedagogy. Automated writing evaluation (AWE) tools offer partially automated support for feedback generation and revision guidance.\n\nAutomated writing evaluation systems leverage rule-based NLP, neural classifiers, and large language models to provide feedback (Attali and Burstein, 2006; Mathias et al., 2020; Rei et al., 2021; Zhuang et al., 2023; OpenAI, 2023). Complementary research examines rubric alignment, fairness, and reliability of automated scoring (Williamson et al., 2012; Beigman Klebanov and Madnani, 2020).\n\nThis paper reports a classroom deployment study of a feedback assistant but does not contrast its mechanisms with those of prior AWE systems.\nRelated Work\n\nKnowledge Distillation and Calibration\nKnowledge distillation techniques transfer supervision from larger teachers to compact students using soft labels, feature mimicking, or intermediate hints (Hinton et al., 2015; Romero et al., 2015; Zagoruyko and Komodakis, 2016; Tian et al., 2020). Temperature scaling and label smoothing are widely used to improve student calibration (M\u00fcller et al., 2019; Guo et al., 2017).\n\nSelf-Distillation and Data-Free KD\nSelf-distillation and data-free distillation extend KD to settings without external teachers or original data, relying on self-training or synthetic samples (Furlanello et al., 2018; Micaelli and Storkey, 2019).\n",
        "completion": "Knowledge distillation techniques transfer supervision from larger teachers to compact students using soft labels, feature mimicking, or intermediate hints (Hinton et al., 2015; Romero et al., 2015; Zagoruyko and Komodakis, 2016; Tian et al., 2020). Temperature scaling and label smoothing are widely used to improve student calibration (M\u00fcller et al., 2019; Guo et al., 2017)."
    }
]