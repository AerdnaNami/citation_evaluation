Introduction

Morality helps humans discern right from wrong. Pluralist moral philosophers argue that human morality can be represented, understood, and explained by a finite number of irreducible basic elements, referred to as moral values (Graham et al., 2013). The difference in our preferences over moral values explains how and why we think differently. For instance, both conservatives and liberals may agree that individual welfare is important. However, a conservative, who cherishes the values of freedom and independence, may believe that taxes should be decreased to attain more individual welfare. In contrast, a liberal, who cherishes the values of community and care, may believe that taxes should be increased to obtain welfare (Graham et al., 2009).

It is crucial to understand human morality to develop beneficial AI (Soares and Fallenstein, 2017;Russell, 2019). As artificial agents live and operate among humans (Akata et al., 2020), they must be able to comprehend and recognize the moral values that drive the differences in human behavior (Gabriel, 2020). The ability to understand moral rhetoric can be instrumental for, e.g., facilitating human-agent trust (Chhogyal et al., 2019;Mehrotra et al., 2021) and engineering value-aligned sociotechnical systems (Murukannaiah et al., 2020;Serramia et al., 2020;Montes and Sierra, 2021).

There are survey instruments to estimate individual value profiles (Schwartz, 2012;Graham et al., 2013). However, reasoning about moral values is challenging for humans (Le Dantec et al., 2009;Pommeranz et al., 2012). Further, in practical applications, e.g., to conduct meaningful conversations (Tigunova et al., 2019) or to identify online trends (Mooijman et al., 2018), artificial agents should be able to understand moral rhetoric on the fly.

The growing capabilities of natural language processing (NLP) enable the estimation of moral rhetoric from discourse Mooijman et al., 2018;Rezapour et al., 2019;Hoover et al., 2020;Araque et al., 2020). Value classifiers can be used to identify the moral values underlying a piece of text on the fly. For instance, Mooijman et al. (2018) show that detecting moral values from tweets can predict violent protests.

Existing value classifiers are evaluated on a specific dataset, without re-training or testing the classifier on a different dataset. This shows the ability of the classifier to predict values from text, but not the ability to transfer the learned knowledge across datasets. A critical aspect of moral values is that they are intrinsically linked to the domain under discussion (Pommeranz et al., 2012;Liscio et al., 2021). Moral value expressions may take different forms in different domains. For example, in the driving domain, the value of safety concerns speed limits and seat belts, but in the COVID-19 domain, safety concerns social distancing and face masks. Thus, a word (broadly, language) may trigger different moral rhetoric in different domains. For example, in a libertarian blog, the word 'taxes' may be linked to the authority values, but in a socialist blog it may be linked to the community values. Then, it is crucial for a value classifier to recognize domain-specific connotations of moral rhetoric.

Collecting and annotating a sufficient amount of training examples in each domain is expensive and time consuming. To reduce the need for new annotated examples, we can pretrain classifiers with similar available annotated data and transfer the acquired knowledge to a novel task-a practice known as transfer learning (Ruder, 2019). Despite the benefits, transfer learning poses wellknown challenges, including: (1) generalizability: how well does a classifier perform on novel data? (2) transferability: how well is knowledge transferred from one domain to another? and (3) catastrophic forgetting: to what extent is knowledge of a previous domain lost after training in a new domain? These challenges are crucial for value classification because of its domain-specific nature.

We perform the first comprehensive crossdomain evaluation of a value classifier. We employ the Moral Foundation Twitter Corpus (Hoover et al., 2020), consisting of seven datasets spanning different socio-political areas, annotated with the value taxonomy of the Moral Foundation Theory (Graham et al., 2013). Treating each dataset as a domain, we train a deep learning model (BERT Devlin et al. (2019)) in four training settings to evaluate the value classifier's generalizability, transferability, and catastrophic forgetting.

Our experiments show that (1) a value classifier can generalize to novel domains, especially when trained on a varied array of domains, (2) initializing a classifier with examples from different domains improves performance in novel domains even when little training data is available in the novel domains, (3) catastrophic forgetting occurs even when training on a small portion of data from the novel domain, and its impact must be considered when training on a novel domain, and (4) in the large majority of cases, in all considered training settings, there is at least one annotator that agrees with the model predictions. These results provide insights to researchers and practitioners on estimating moral values in different domains.

 References: 
Fikri Aji, A., Bogoychev, N., Heafield, K., and Sennrich, R. 2020. What Does Transfer Learning Transfer?. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. pp. 7701--7710 10.18653/v1/2020.acl-main.688
Akata, Z., Balliet, D., Maarten De Rijke, F., Dignum, V., Dignum, G., Eiben, A., Fokkens, D., Grossi, K., Hindriks, H., Hoos, H., Hung, Catholijn, J. M., Jonker, C., Monz, M., Neerincx, F., Oliehoek, H., Prakken, S., and Schlobach Linda van der Gaag, Frank van Harmelen, Herke van Hoof, Birna van Riemsdijk, Aimee van Wynsberghe, Rineke Verbrugge. In Piek Vossen, and Max Welling. 2020. A Research Agenda for Hybrid Intelligence: Augmenting Human Intellect With Collaborative, Adaptive, Responsible, and Explainable Artificial Intelligence. pp. 18--28 10.1109/MC.2020.2996587
Al-Khatib, K., Wachsmuth, H., Hagen, M., Köhler, J., and Stein, B. 2016. Crossdomain mining of argumentative text through distant supervision. In Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL HLT 2016 -Proceedings of the Conference. pp. 1395--1404 10.18653/v1/n16-1165
Al-Moslmi, T., Omar, N., and Abdullah, S. 2017. Approaches to Cross-Domain Sentiment Analysis: A Systematic Literature Review. In IEEE Access. pp. 16173--16192 10.1109/ACCESS.2017.2690342
Araque, O., Gatti, L., and Kalimeri, K. 2020. MoralStrength: Exploiting a moral lexicon and embedding similarity for moral foundations prediction. Knowledge-Based Systems. In MoralStrength: Exploiting a moral lexicon and embedding similarity for moral foundations prediction. Knowledge-Based Systems. pp. 1--29 10.1016/j.knosys.2019.105184
Araque, O., Gatti, L., and Kalimeri, K. 2021. The Language of Liberty: A preliminary study. In Companion Proceedings of the Web Conference 2021 (WWW '21 Companion). pp. 1--4 10.1145/3442442.3452351
Bahgat, M., Wilson, S. R., and Magdy, W. 2020. Towards Using Word Embedding Vector Space for Better Cohort Analysis. In Proceedings of the Fourteenth International AAAI Conference on Web and Social Media (ICWSM 2020). pp. 919--923
Basile, V., Fell, M., Fornaciari, T., Hovy, D., and Paun, S. 2021. We Need to Consider Disagreement in Evaluation. In Proceedings of the 1st Workshop on Benchmarking: Past, Present and Future. pp. 15--21 10.18653/v1/2021.bppf-1.3
Bornea, M., Pan, L., Rosenthal, S., Florian, R., and Sil, A. 2021. Multilingual Transfer Learning for QA Using Translation as Data Augmentation. In The Thirty-Fifth AAAI Conference on Artificial Intelligence (AAAI-21) Multilingual. pp. 12583--12591
Charte, F., Rivera, A. J., María, J., Del, J., and Herrera, F. 2015. Addressing imbalance in multilabel classification: Measures and random resampling algorithms. In Neurocomputing. pp. 3--16 10.1016/j.neucom.2014.08.091
Chhogyal, K., Nayak, A., Ghose, A., and Dam, H. K. 2019. A value-based trust assessment model for multi-agent systems. In IJCAI International Joint Conference on Artificial Intelligence. pp. 194--200 10.24963/ijcai.2019/28
Davidson, T., Warmsley, D., Macy, M., and Weber, I. 2017. Automated hate speech detection and the problem of offensive language. In Proceedings of the 11th International Conference on Web and Social Media, ICWSM 2017. pp. 512--515
Daxenberger, J., Eger, S., Habernal, I., Stab, C., and Gurevych, I. 2017. What is the essence of a claim? Cross-domain claim identification. In EMNLP 2017 -Conference on Empirical Methods in Natural Language Processing, Proceedings. pp. 2055--2066 10.18653/v1/d17-1218
Devlin, J., Chang, M., Lee, K., and Toutanova, K. 2019. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. In Proceedings of NAACL. pp. 4171--4186
Dinan, E., Fan, A., Wu, L., Weston, J., Kiela, D., and Williams, A. 2020. Multi-Dimensional Gender Bias Classification. In EMNLP 2020 -2020 Conference on Empirical Methods in Natural Language Processing, Proceedings of the Conference. pp. 314--331 10.18653/v1/2020.emnlp-main.23
Du, C., Sun, H., Wang, J., Qi, Q., and Liao, J. 2020. Adversarial and Domain-Aware BERT for Cross-Domain Sentiment Analysis. In Proceedings ofthe 58th Annual Meeting of the Association for Computational Linguistics. pp. 4019--4028 10.18653/v1/2020.acl-main.370
Friedman, B., Kahn, P. H., and Borning, A. 2008. Value Sensitive Design and Information Systems. In The Handbook of Information and Computer Ethics. pp. 69--101 10.1002/9780470281819.ch4
Fung, Y., Thomas, C., Gangi Reddy, R., Polisetty, S., Ji, H., Chang, S., Mckeown, K., Bansal, M., and Sil, A. 2021. InfoSurgeon: Cross-media fine-grained information consistency checking for fake news detection. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing. pp. 1683--1698 10.18653/v1/2021.acl-long.133
Gabriel, I. 2020. Artificial Intelligence, Values, and Alignment. Minds and Machines. In Artificial Intelligence, Values, and Alignment. Minds and Machines. pp. 411--437 10.1007/s11023-020-09539-2
Garten, J., Hoover, J., Johnson, K. M., and Boghrati, R. 2018. Dictionaries and distributions: Combining expert knowledge and large scale textual data content analysis: Distributed dictionary representation. In Behavior Research Methods. pp. 344--361 10.3758/s13428-017-0875-9
Graham, J., Haidt, J., Koleva, S., Motyl, M., Iyer, R., Wojcik, S. P., and Ditto, P. H. 2013. Moral Foundations Theory: The Pragmatic Validity of Moral Pluralism. In Advances in Experimental Social Psychology. pp. 55--130 10.1016/B978-0-12-407236-7.00002-4
Graham, J., Haidt, J., and Nosek, B. A. 2009. Liberals and Conservatives Rely on Different Sets of Moral Foundations. In Journal of Personality and Social Psychology. pp. 1029--1046 10.1037/a0015141
Hollander, M. and Wolfe, D. A. 1999. Nonparametric Statistical Methods. In Nonparametric Statistical Methods.
Hoover, J., Portillo-Wightman, G., Yeh, L., Havaldar, S., Davani, A. M., Lin, Y., Kennedy, B., Atari, M., Kamel, Z., Mendlen, M., Moreno, G., Park, C., Chang, T. E., and Chin, J. Christian Leong, Jun Yen Leung, Arineh Mirinjian, and Morteza Dehghani. 2020. Moral Foundations Twitter Corpus: A Collection of 35k Tweets Annotated for Moral Sentiment. Social Psychological and Personality Science. In Christian Leong, Jun Yen Leung, Arineh Mirinjian, and Morteza Dehghani. 2020. Moral Foundations Twitter Corpus: A Collection of 35k Tweets Annotated for Moral Sentiment. Social Psychological and Personality Science. pp. 1057--1071 10.1177/1948550619876629
Hopp, F. R., Fisher, J. T., Cornell, D., Huskey, R., and Weber, R. 2020. The extended Moral Foundations Dictionary (eMFD): Development and applications of a crowd-sourced approach to extracting moral intuitions from text. In Behavior Research Methods. pp. 1--23 10.3758/s13428-020-01433-0
Howard, J. and Ruder, S. 2018. Universal language model fine-tuning for text classification. In ACL 2018 -56th Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference (Long Papers). pp. 328--339 10.18653/v1/p18-1031
Jiang, H., He, P., Chen, W., Liu, X., Gao, J., and Zhao, T. 2020. SMART: Robust and Efficient Fine-Tuning for Pretrained Natural Language Models through Principled Regularized Optimization. In Proceedings ofthe 58th Annual Meeting of the Association for Computational Linguistics. pp. 2177--2190 10.18653/v1/2020.acl-main.197
Kirkpatrick, J., Pascanu, R., Rabinowitz, N., Veness, J., Desjardins, G., Rusu, A. A., Milan, K., Quan, J., and Ramalho, T. 2017. Agnieszka Grabska-Barwinska, Demis Hassabis, Claudia Clopath, Dharshan Kumaran, and Raia Hadsell. In Agnieszka Grabska-Barwinska, Demis Hassabis, Claudia Clopath, Dharshan Kumaran, and Raia Hadsell. pp. 3521--3526 10.1073/pnas.1611835114
Kleinberg, J., Ludwig, J., Mullainathan, S., and Rambachan, A. 2018. Algorithmic Fairness. In AEA Papers and Proceedings. pp. 22--27 10.1257/pandp.20181018
Christopher, A. L., Dantec, E. S., Poole, S. P., and Wyche 2009. Values as lived experience. In Proceedings of the 27th international conference on Human factors in computing systems -CHI 09. pp. 1141 10.1145/1518701.1518875
Li, Z. and Hoiem, D. 2018. Learning without Forgetting. In IEEE Transactions on Pattern Analysis and Machine Intelligence. pp. 2935--2947 10.1109/TPAMI.2017.2773081
Lin, Y., Hoover, J., Portillo-Wightman, G., Park, C., Dehghani, M., and Ji, H. 2018. Acquiring Background Knowledge to Improve Moral Value Prediction. In 2018 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM). pp. 552--559 10.1109/ASONAM.2018.8508244
Liscio, E., Van Der Meer, C. M., Jonker, P. K., and Murukannaiah 2021. A Collaborative Platform for Identifying Context-Specific Values. In Proc. of the 20th International Conference on Autonomous Agents and Multiagent Systems (AA-MAS 2021). pp. 1773--1775
Maheshwari, T., Reganti, A. N., Gupta, S., Jamatia, A., Kumar, U., Gambäck, B., and Das, A. 2017. A societal sentiment analysis: Predicting the values and ethics of for Computational Linguistics. In A societal sentiment analysis: Predicting the values and ethics of for Computational Linguistics. pp. 731--741
Markov, I. and Daelemans, W. 2021. Improving cross-domain hate speech detection by reducing the false positive rate. In Proceedings of the Fourth Workshop on NLP for Internet Freedom: Censorship, Disinformation, and Propaganda. pp. 17--22 10.18653/v1/2021.nlp4if-1.3
Mehrabi, N., Morstatter, F., Saxena, N., Lerman, K., and Galstyan, A. 2021. A Survey on Bias and Fairness in Machine Learning. In ACM Computing Surveys. pp. 54 10.1145/3457607
Mehrotra, S., Catholijn, M., Jonker, M. L., and Tielman 2021. More Similar Values, More Trust? -the Effect of Value Similarity on Trust in Human-Agent Interaction. In Proceedings of the 2021. 10.1145/3461702.3462576
AAAI/ACM Conference on AI, Ethics, and Society (AIES '21). In AAAI/ACM Conference on AI, Ethics, and Society (AIES '21). pp. 1--7
Montes, N. and Sierra, C. 2021. Value-Guided Synthesis of Parametric Normative Systems. In Proc. of the 20th International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2021). pp. 907--915
Mooijman, M., Hoover, J., Lin, Y., Heng, J., and Dehghani, M. 2018. Moralization in social networks and the emergence of violence during protests. In Nature Human Behaviour. pp. 389--396 10.1038/s41562-018-0353-0
Mouter, N., Koster, P., and Dekker, T. 2021. Contrasting the recommendations of Participatory Value Evaluation and Cost-Benefit Analysis in the context of urban mobility investments. In Transportation Research Part A. pp. 54--73 10.1016/j.tra.2020.12.008
Pradeep, K., Murukannaiah, N., Ajmeri, Catholijn, J. M., Jonker, M. P., and Singh 2020. International Foundation for Autonomous Agents and Multiagent Systems. In Proceedings of the 19th International Conference on Autonomous Agents and MultiAgent Systems. pp. 1706--1710
Van Nguyen, M., Ngo Nguyen, T., Min, B., and Nguyen, T.H. 2021. Crosslingual transfer learning for relation and event extraction via word category and class alignments. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing. pp. 5414--5426
Pennebaker, J. W., Francis, M. E., and Booth, R. J. 2001. Linguistic Inquiry and Word Count (LIWC). Mahway. In Linguistic Inquiry and Word Count (LIWC). Mahway. pp. 71 10.4018/978-1-60960-741-8.ch012
Pommeranz, A., Detweiler, C., Wiggers, P., and Jonker, C. M. 2012. Elicitation of situated values: Need for tools to help stakeholders and designers to reflect and communicate. In Ethics and Information Technology. pp. 285--303 10.1007/s10676-011-9282-6
Ponizovskiy, V., Ardag, M., Grigoryan, L., Boyd, R., Dobewall, H., and Holtz, P. 2020. Development and Validation of the Personal Values Dictionary: A Theory-Driven Tool for Investigating References to Basic Human Values in Text. In European Journal of Personality. pp. 885--902 10.1002/per.2294
Qu, X., Zou, Z., Cheng, Y., Yang, Y., and Zhou, P. 2019. Adversarial category alignment network for cross-domain sentiment classification. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. pp. 2496--2508 10.18653/v1/N19-1258
Rezapour, R., Saumil, H., Shah, J., and Diesner 2019. Enhancing the Measurement of Social Effects by Capturing Morality. In Proceedings ofthe 10th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis. pp. 35--45 10.18653/v1/w19-1305
Rongali, S., Liu, B., Cai, L., Arkoudas, K., Su, C., and Hamza, W. 2021. Exploring Transfer Learning For End-to-End Spoken Language Understanding. In The Thirty-Fifth AAAI Conference on Artificial Intelligence (AAAI-21). pp. 13754--13761
Ruder, S. 2019. Neural Transfer Learning for Natural Language Processing. In Neural Transfer Learning for Natural Language Processing.
Russell, S. 2019. Human compatible: Artificial intelligence and the problem of control. In Human compatible: Artificial intelligence and the problem of control.
Schwartz, S. H. 2012. An Overview of the Schwartz Theory of Basic Values. In Online readings in Psychology and Culture. pp. 1--20
Serramia, M., Lopez-Sanchez, M., and Rodríguez-Aguilar, J. A. 2020. A Qualitative Approach to Composing Value-Aligned Norm Systems. In Proc. ofthe 19th International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2020). pp. 1233--1241
Shen, Y., Wilson, S. R., and Mihalcea, R. 2019. Measuring Personal Values in Cross-Cultural User-Generated Content. In Proceedings of the 10th International Conference on Social Informatics (SocInfo '19). pp. 143--156 10.1007/978-3-030-34971-4{_}10
Silva, A., Luo, L., Karunasekera, S., and Leckie, C. 2021. Embracing Domain Differences in Fake News: Cross-domain Fake News Detection using Multi-modal Data. In Proceedings of the AAAI Conference on Artificial Intelligence. pp. 557--565
Soares, N. and Fallenstein, B. 2017. Agent Foundations for Aligning Machine Intelligence with Human Interests: A Technical Research Agenda. In The Technological Singularity: Managing the Journey. pp. 103--125 10.1007/978-3-662-54033-6{_}5
Sun, C., Qiu, X., Xu, Y., and Huang, X. 2019. How to Fine-Tune BERT for Text Classification?. In How to Fine-Tune BERT for Text Classification?. 10.1007/978-3-030-32381-3{_}16
Thompson, B., Gwinnup, J., Khayrallah, H., Duh, K., and Koehn, P. 2019. Overcoming catastrophic forgetting during domain adaptation of neural machine translation. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. pp. 2062--2068 10.18653/v1/N19-1209
Sasha Thorn Jakobsen, T., Barrett, M., and Søgaard, A. 2021. Spurious correlations in crosstopic argument mining. In Proceedings of *SEM 2021: The Tenth Joint Conference on Lexical and Computational Semantics. pp. 263--277 10.18653/v1/2021.starsem-1.25
Tigunova, A., Mirza, P., Yates, A., and Weikum, G. 2019. Listening between the lines: Learning personal attributes from conversations. In Proceedings of the World Wide Web Conference, WWW 2019. pp. 1818--1828 10.1145/3308558.3313498
Vargas, F. and Cotterell, R. 2020. Exploring the Linear Subspace Hypothesis in Gender Bias Mitigation. In EMNLP 2020 -2020 Conference on Empirical Methods in Natural Language Processing, Proceedings of the Conference. pp. 2902--2913 10.18653/v1/2020.emnlp-main.232
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, L., and Polosukhin, I. 2017. Attention Is All You Need. In 31st Conference on Neural Information Processing Systems. pp. 5998--6008
Steven, R., Wilson, Y., Shen, R., and Mihalcea 2018. Building and validating hierarchical lexicons with a case study on personal values. In Proceedings of the 10th International Conference on Social Informatics (SocInfo '18). pp. 455--470 10.1007/978-3-030-01129-1{_}28
Yuan, H., Zheng, J., Ye, Q., Qian, Y., and Zhang, Y. 2021. Improving fake news detection with domain-adversarial and graph-attention neural network. In Decision Support Systems. pp. 113633 10.1016/j.dss.2021.113633
C(source source) 64.1 45.7 64.0 52.1 61.1 39.6 59.2 48.0 63.5 46.5 66.4 47.1 65.6 46.8 63.4 46.5
C(target, source). In C(target, source).
(f Inetune, C. pp. 61
fastText C(source, source) 66. In fastText C(source, source) 66. source) 64.5 46.7 63.2 49.2 62.3 41.4 59.3 47.7 64.2 48.6 66.4 48.7 65.8 48.1 63.7 47.2
C(target, source). In C(target, source).
(f Inetune, C. pp. 62
Bert C(source source) 73.9 65.6 73.9 68.3 71.2 61.8 71.1 66.4 73.3 66.4 75.7 68.0 74.5 66.5 73.4 66.1
C(target, source). In C(target, source).
(f Inetune, C. pp. 70
C(source pp. 19 target) 52.5 40.2
(f Inetune, C. pp. 43 target) 61.4 51.2 69.0 23.2 78.2 77.2 92.2 9
Target, C. target) 62.4 50.4 69.2 18.3 77.6 74.2 92.1 9.0 63.8 39.5 49.4 40.8 57.4 34.0 67.4 38.0
(f Inetune, C. pp. 59 target) 62.5 57.5 68.6 30.1 77.8 78.6 88.6 9
Target, C. target) 68.0 56.8 71.4 23.5 84.4 84.6 92.2 9.0 70.9 52.6 59.4 55.9 65.3 44.6 73.1 46.7
(f Inetune, C. pp. 59 target) 69.4 67.0 72.1 37.4 84.6 85.5 92.2 9
Majority
C(target, source). In C(target, source).
(f Inetune, C. pp. 64
six C(source, source) 73. In six C(source, source) 73. source) 70.9 69.1 66.3 62.6 67.1 63.4 75.9 69.8 70.9 68.9 74.6 71.5 72.5 69.7 71.2 67.9
C(target, source). In C(target, source).
(f Inetune, C. pp. 70