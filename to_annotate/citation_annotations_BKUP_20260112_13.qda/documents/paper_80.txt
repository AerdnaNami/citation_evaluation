Introduction

Coherence describes the semantic relation between elements of a text. It recognizes how well a text is organized to convey the information to the reader effectively. Modeling coherence can be beneficial to any system which needs to process a text.

Recent neural coherence models (Mesgar and Strube, 2018;Moon et al., 2019) encode the input document using large-scale pretrained language models (Peters et al., 2018). These neural models compute local coherence, semantic relations between items in adjacent sentences, on the basis of words and even sub-words.

However, it has been unclear on which basis these models compute local coherence. Jeon and Strube (2020) present a neural coherence model, which allows to interpret focus information for the first time. Their investigation reveals that neural models, adopting large-scale pretrained language models, frequently compute coherence on the basis of connections between any (sub-)words or function words. In these cases, the model might capture the focus based on spurious information. While such a model might reach or set the state of the art in some end applications, it will do so for the wrong reasons from a linguistic perspective.

This problem did not appear with pre-neural models of coherence, since they compute coherence on the basis of entities. Early work about pronoun and anaphora resolution by Sidner (1981Sidner ( , 1983 assumes that there is one single salient entity in a sentence, its focus, which serves as a preferred antecedent for anaphoric expressions. Centering theory (Joshi and Weinstein, 1981;Grosz et al., 1995) builds on these insights and introduces an algorithm for tracking changes in focus. Centering theory serves as basis for many researchers to develop systems computing local coherence based on the approximations of entities (Barzilay and Lapata 2008;Feng and Hirst 2012;Guinaudeau and Strube 2013, inter alia).

In this paper, we propose a neural coherence model which is linguistically more sound than previously proposed neural coherence models. We compute coherence on the basis of entities by constraining our model to capture focus on noun phrases and proper names. This provides us with an explicit representation of the most important items in sentences, leading to the notion of focus. This brings our model linguistically in line with pre-neural models of coherence.

Our approach is not only linguistically more sound but also is in accord with the recent empirical study by O'Connor and Andreas (2021) who investigate what contextual information contributes to accurate predictions in transformer-based language models. Their experiments show that most usable information is captured by nouns and verbs. Their findings suggest that we can design better neural models by focusing on specific context words. Our work follows their findings by modeling entitybased coherence in an end-to-end framework to improve a neural coherence model.

Our model integrates a local coherence module with a component which takes context into account. Our model first encodes a document using a pretrained language model and identifies entities using an linguistic parser. The local coherence module captures the most related representations of entities between adjacent sentences, the local focus. Then it tracks the changes of local foci. The second component captures the context of a text by averaging sentence representations.

We evaluate our model on three downstream tasks: automated essay scoring (AES), assessing writing quality (AWQ), and assessing discourse coherence (ADC). AES and AWQ determine text quality for a given text, aiming to replicate human scoring results. Since coherence is an essential factor in assessing text quality, many previous coherence models are evaluated on AES and AWQ. ADC evaluates coherence models on informal texts such as emails and online reviews. In our evaluation, our model achieves state-of-the-art performance.

We also perform a series of analyses to investigate how our model works. Our analyses show that capturing focus on entities gives us better insight into the behaviour of the model, leading to better explainability. Using this information, we examine the statistical differences of texts assigned to different qualities. From the perspective of local coherence, we find that texts of higher quality are neither semantically too consistent nor too variant. Finally, we inspect error cases to investigate how the models achieve their performance differently.

 References: 
Bahdanau, D., Cho, K., and Bengio, Y. 2015. Neural machine translation by jointly learning to align and translate. In Proceedings of the ICLR Conference.
Barzilay, R. and Lapata, M. 2008. Modeling local coherence: An entity-based approach. In Computational Linguistics. pp. 1--34 10.1162/coli.2008.34.1.1
Blanchard, D. and Tetreault, J. 2013. Derrick Higgins, Aoife Cahill, and Martin Chodorow. In ETS Research Report Series. pp. 15
Chollet, F. 2017. Xception: Deep learning with depthwise separable convolutions. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 1251--1258
Dong, F., Zhang, Y., and Yang, J. 2017. Attentionbased recurrent convolutional neural network for automatic essay scoring. In Proceedings of the 21st Conference on Computational Natural Language Learning. pp. 153--162 10.18653/v1/K17-1017
Wei Feng, V. and Hirst, G. 2012. Extending the entity-based coherence model with multiple ranks. In Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics. pp. 315--324
Ferracane, E., Durrett, G., Li, J. J., and Erk, K. 2019. Evaluating discourse in structured text representations. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics. pp. 646--653 10.18653/v1/P19-1062
Grosz, B. J., Joshi, A. K., and Weinstein, S. 1995. Centering: A framework for modeling the local coherence of discourse. In Computational Linguistics. pp. 203--225
Guinaudeau, C. and Strube, M. 2013. Graphbased local coherence modeling. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics. pp. 93--103
Hardt, D. and Romero, M. 2004. Ellipsis and the structure of discourse. In Journal of Semantics. pp. 375--414
Jeon, S. and Strube, M. 2020. Centeringbased neural coherence modeling with hierarchical discourse segments. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP). pp. 7458--7472 10.18653/v1/2020.emnlp-main.604
Aravind, K., Joshi, S., and Weinstein 1981. Control of inference: Role of some aspects of discourse structure-centering. In IJCAI. pp. 385--387
Kitaev, N. and Klein, D. 2018. Constituency parsing with a self-attentive encoder. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics. pp. 2676--2686 10.18653/v1/P18-1249
Laban, P., Dai, L., Bandarkar, L., and Hearst, M. A. 2021. Can transformer models measure coherence in text? Re-thinking the shuffle test. In Can transformer models measure coherence in text? Re-thinking the shuffle test. arXiv:2107.03448
Lai, A. and Tetreault, J. 2018. Discourse coherence in the wild: A dataset, evaluation and methods. In Proceedings of the 19th Annual SIGdial Meeting on Discourse and Dialogue. pp. 214--223 10.18653/v1/W18-5023
Li, J. and Jurafsky, D. 2017. Neural net models of open-domain discourse coherence. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing. pp. 198--209 10.18653/v1/D17-1019
Liu, Y. and Lapata, M. 2018. Learning structured text representations. In Transactions of the Association for Computational Linguistics. pp. 63--75 10.1162/tacl_a_00005
Louis, A. and Nenkova, A. 2013. What makes writing great? first experiments on article quality prediction in the science journalism domain. In Transactions of the Association for Computational Linguistics. pp. 341--352 10.1162/tacl_a_00232
Mesgar, M. and Strube, M. 2018. A neural local coherence model for text quality assessment. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing. pp. 4328--4339 10.18653/v1/D18-1464
Mohiuddin, T., Jwalapuram, P., Lin, X., and Joty, S. 2021. Rethinking coherence modeling: Synthetic vs. downstream tasks. In Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume. pp. 3528--3539
Han Cheol Moon, T., Mohiuddin, S., Joty, C., and Xu 2019. A unified neural coherence model. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP). pp. 2262--2272 10.18653/v1/D19-1231