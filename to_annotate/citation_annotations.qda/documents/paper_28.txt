Related Work

Learning from Imbalanced Data

Class imbalance is a long-standing problem in machine learning tasks, posing challenges to researchers and practitioners in many domains (King and Zeng, 2001;Lu and Jain, 2003;He and Garcia, 2009;Moreo et al., 2016). Classes in real-world data often have highly skewed distribution, leading to substantial gaps between majority and minority classes. While the positive (minority) class is often of interest, the lack of positive examples makes classifiers conservative, i.e., they incline to predict all example as the negative (majority) class. This often results in a low recall of the positive class. Because only a small number of examples are predicted as positive, precision of the positive class tends to be high or unstable. Such a low-recall, high-precision pattern often hurts the F1-score, the standard metric that emphasizes a balanced precision and recall (Juba and Le, 2019). This performance pattern is observed not only in classification tasks, but also in NER tasks where named entity tokens are the minority compared to non-entity tokens (Mao et al., 2007;Kuperus et al., 2013).

Researchers have proposed various techniques for imbalanced learning, including resampling and cost-sensitive learning (He and Ma, 2013). Both aim to re-balance the representation of different classes in the loss function, such that the classifier is less conservative in making positive predictions. In principle, by equating per-instance resampling frequency with per-instance cost, resampling can be implemented as cost-sensitive learning. However, resampling can be applied to models that do not support cost-sensitive learning, making it conveniently applicable to all models.

Resampling in Sequence Tagging Tasks

Resampling (and cost-sensitive learning) can be conveniently used in classification and regression tasks where a model makes pointwise predictions (a single categorical or scalar value). Each example has a clearly defined sampling rate (or cost) according to its class label. However, in sequence tagging tasks like NER (more broadly, structured prediction tasks (BakIr et al., 2007;Smith, 2011)), a model predicts multiple values for a sequence (or structured output). For sequence learning algorithms such as linear-chain conditional random fields, while the learning objective is formulated at the sequence level, the evaluation metrics are defined at the entity span level. This makes it nontrivial to determine the sampling rate (or cost) for a sequence that contains tokens from both majority and minority entity types. Simply resampling entities by stripping surrounding context is problematic as sequence tagging algorithms depend on context to make predictions. Recent works proposed to randomly or heuristically drop tokens from sentences to re-balance NER data, which had success using conditional random fields and shallow n-gram features (Akkasi, 2018;Akkasi and Varoglu, 2019;Grancharova et al., 2020). However, these methods distort the syntactic and semantic structure of complete sentences, which may generate low-quality data for models that are capable of capturing longdistance linguistic dependencies (e.g. BERT) and hurt performance of those models. In this work, we focus on resampling strategies that leaves sentences intact.

Loss Functions for Imbalanced Data

Recent literature proposed special loss functions for tackling data imbalance, including focal loss (Lin et al., 2017) and Dice loss (Li et al., 2019). They increase the cost of 'hard positives' where the correct label has low predicted probability and decrease the cost of 'easy negatives' where the correct label has high predicted probability. However, these loss functions do not fully address data imbalance in NER. First, the formulation does not always emphasize the loss of minority-class tokens -majority-class tokens can also be hard to classify, and minority-class tokens can also be easy to classify. Second, these loss functions only work on token-wise prediction outputs. They cannot work on sequence-level outputs generated by conditional random fields, which is commonly used in NER. Our resampling methods can be seen as estimating sentence-level losses with explicit emphasis on sentences containing minority-class tokens.

 References: 
Akkasi, A. and Varoglu 2019. Improvement of chemical named entity recognition through sentence-based random under-sampling and classifier combination. In Journal of AI and Data Mining. pp. 311--319
Akkasi, A. 2018. Sentence-based undersampling for named entity recognition using genetic algorithm. In Iran Journal of Computer Science. pp. 165--174
Akkasi, A., Varoglu, E., and Dimililer, N. 2018. Balanced undersampling: a novel sentencebased undersampling method to improve recognition of named entities in chemical and biomedical text. In Applied Intelligence. pp. 1965--1978
Bakir, G., Hofmann, T., Schölkopf, B., Smola, A. J., and Taskar, B. 2007. Predicting structured data. In Predicting structured data.
Bos, J., Basile, V., Evang, K., Venhuizen, N., and Bjerva, J. 2017. The groningen meaning bank. In Handbook of Linguistic Annotation. pp. 463--496
Dai, X. and Adel, H. 2020. An analysis of simple data augmentation for named entity recognition. In An analysis of simple data augmentation for named entity recognition. arXiv:2010.11683
Derczynski, L., Nichols, E., Van Erp, M., and Limsopatham, N. 2017. Results of the wnut2017 shared task on novel and emerging entity recognition. In Proceedings of the 3rd Workshop on Noisy Usergenerated Text. pp. 140--147
Devlin, J., Chang, M., Lee, K., and Toutanova, K. 2018. Bert: Pre-training of deep bidirectional transformers for language understanding. In Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv:1810.04805
Fang, H., Tao, T., and Zhai, C. 2004. A formal study of information retrieval heuristics. In Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrieval. pp. 49--56
Grancharova, M., Hanna, and Dalianis, H. 2020. Improving named entity recognition and classification in class imbalanced swedish electronic patient records through resampling. In Eighth Swedish Language Technology Conference (SLTC). Förlag Göteborgs Universitet.
He, H., Edwardo, A., and Garcia 2009. Learning from imbalanced data. In IEEE Transactions on knowledge and data engineering. pp. 1263--1284
He, H. and Ma, Y. 2013. Imbalanced learning: foundations, algorithms. In Imbalanced learning: foundations, algorithms.
Henry, S., Buchan, K., Filannino, M., Stubbs, A., and Uzuner, O. 2020. 2018 n2c2 shared task on adverse drug events and medication extraction in electronic health records. In Journal of the American Medical Informatics Association. pp. 3--12
Huang, J., Xu, K., and Vydiswaran 2016. Analyzing multiple medical corpora using word embedding. In 2016 IEEE International Conference on Healthcare Informatics (ICHI). pp. 527--533
Juba, B., Hai, S., and Le 2019. Precision-recall versus accuracy and the role of large data sets. In Proceedings of the AAAI Conference on Artificial Intelligence. pp. 4039--4048
Kaggle, D. 2018. Annotated GMB corpus. In Annotated GMB corpus. pp. 2021--2025
Karimi, S., Metke-Jimenez, A., Kemp, M., and Wang, C. 2015. Cadec: A corpus of adverse drug event annotations. In Journal of biomedical informatics. pp. 73--81
King, G. and Zeng, L. 2001. Logistic regression in rare events data. In Political analysis. pp. 137--163
Diederik, P., Kingma, J., and Ba 2014. Adam: A method for stochastic optimization. In Adam: A method for stochastic optimization. arXiv:1412.6980
Kuperus, J., Cor, J., Veenman, M., and Van Keulen 2013. Increasing ner recall with minimal precision loss. In 2013 European Intelligence and Security Informatics Conference. pp. 106--111
Li, X., Sun, X., Meng, Y., Liang, J., Wu, F., and Li, J. 2019. Dice loss for data-imbalanced nlp tasks. In Dice loss for data-imbalanced nlp tasks. arXiv:1911.02855
Lin, T., Goyal, P., and Girshick, R. 2017. Focal loss for dense object detection. In Proceedings of the IEEE international conference on computer vision. pp. 2980--2988
Dong, C., Liu, J., and Nocedal 1989. On the limited memory bfgs method for large scale optimization. In Mathematical programming. pp. 503--528
Lu, X. and Jain 2003. Resampling for face recognition. In International Conference on Audio-and Video-based Biometric Person Authentication. pp. 869--877
Mao, X., Xu, W., Dong, Y., He, S., and Wang, H. 2007. Using non-local features to improve named entity recognition recall. In Proceedings of the 21st Pacific Asia Conference on Language, Information and Computation. pp. 303--310
Moreo, A., Esuli, A., and Sebastiani, F. 2016. Distributional random oversampling for imbalanced text classification. In Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval. pp. 805--808
Ohta, T., Pyysalo, S., Jun'ichi Tsujii, S., and Ananiadou 2012. Open-domain anatomical entity mention detection. In Proceedings of the workshop on detecting structure in scholarly discourse. pp. 27--36
Ralph, W., Martha, P., Mitchell, M., Eduard, H., Sameer, P., Lance, R., Nianwen, X., Ann, T., Jeff, K., and Michelle, F. 2013. 10.35111/xmhb-2b84
Salton, G. and Buckley, C. 1988. Termweighting approaches in automatic text retrieval. Information processing & management. In Termweighting approaches in automatic text retrieval. Information processing & management. pp. 513--523
Tjong, E. F., Sang, K., and De Meulder, F. 2003. Introduction to CoNLL-2003 shared task: Language-independent named entity recognition. In Proceedings of the Seventh Conference on Natural Language Learning at HLT-NAACL 2003. pp. 142--147
Singhal, A., Salton, G., Mitra, M., and Buckley, C. 1996. Document length normalization. In formation Processing & Management. pp. 619--633
Noah, A. and Smith 2011. Linguistic structure prediction. In Linguistic structure prediction. pp. 1--274
Tomanek, K. and Hahn, U. 2009. Reducing class imbalance during active learning for named entity annotation. In Proceedings of the fifth international conference on Knowledge capture. pp. 105--112