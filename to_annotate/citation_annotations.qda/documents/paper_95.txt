Related work

The application of NLP methods to automatic LSC detection is already a rather well-developed subfield of NLP research (Tahmasebi et al., 2018;Kutuzov et al., 2018). In particular, the emergence of word embeddings as a viable way to model the distributional hypothesis in semantics (Firth, 1957) has paved the way for an application of word embeddings to LSC modeling (Kim et al., 2014;Hamilton et al., 2016b;Eger and Mehler, 2016;Yao et al., 2018). Synchronically, the meaning of a word is characterized by word embeddings in terms of the contexts it appears in. LSC is captured by training word embeddings at different time points and comparing these distributions typically using cosine distance.

The main issues in this comparison is the alignment of temporal embeddings spaces, especially for neural embeddings as these are initialized and trained stochastically, which means that separate runs -on even the same data -will yield different embeddings spaces. Thus, work has focused on the development of methods to perform alignments to make embedding spaces comparable across time (see Kutuzov et al. (2018) for an overview). As an alternative to neural embeddings, scholars have also used purely count-based measures, which are naturally aligned across dimensions. Normalisation techniques are also applied, e.g. based on positive pointwise mutual information (PPMI) (Hamilton et al., 2016b;Yao et al., 2018).

Most studies of LSC do not rely on a control dataset against which to validate their conclusions. In Dubossarsky et al. (2017), on the contrary, it is argued that any claims about putative laws of semantic change in diachronic corpora must be evaluated against a relevant control condition. The authors propose a methodology in which a control condition is created artificially from the original diachronic text collection by reshuffling the data.

No systematic LSC is expected in the artificially developed control dataset.

The distributional hypothesis has also been proposed as an explanatory model within the domain of phonology suggesting that phonological classes are acquired through distributional information (Chomsky and Halle, 1968;Mielke, 2008). Driven by this hypothesis, recent work has focused on testing how distributional properties can be learned by phoneme embeddings (see Mayer 2020 for an overview). Silfverberg et al. (2018) investigated to what extent learned vector representations of phonemes align with their respective representations in a feature space in which dimensions are articulatory descriptors (e.g., ±plosive). Recently, Mayer (2020) has shown that phonological classes, such as long and short vowels, can be deduced from phoneme embeddings normalised using PPMI by iteratively performing PCA on candidate classes.

Thus, while the distributional hypothesis for phonology is well-established, one notable issue is the fact that the empirical evidence to study sound change is relatively inaccessible since it requires recorded speech or phonologically transcribed data. Simulation is therefore used as a tool for studying the underlying mechanisms of sound change by creating computational models based on linguistic theory (Wedel, 2015). Through simulation, questions pertaining to e.g., what factors influence the (in)stability of vowel systems across generations (de Boer, 2003) can be modeled by controlling the assumptions made by the model. Work on simulation ranges from implementing theoretical approaches using mathematical models (Pierrehumbert, 2001;Blythe and Croft, 2012) to iterated learning and neural networks (Hare and Elman, 1995;Beguš, 2021).

While the output of such models can be tested empirically on what we observe at a synchronic level, they are primarily theoretically driven. In this paper, we wish to take a data-driven approach and utilize some of the methods reviewed above to track historical sound change in writing. Rather than using word embeddings as done to model lexical change, we will use character embeddings, that are better suited to the task of sound change modeling.

 References: 
Beguš, G. 2021. Deep sound change: Deep and iterative learning, convolutional neural networks, and language change. In Deep sound change: Deep and iterative learning, convolutional neural networks, and language change.
Richard, A., Blythe, W., and Croft 2012. S-curves and the mechanisms of propagation in language change. In Language. pp. 269--304
Chomsky, N. and Halle, M. 1968. The sound pattern of English. In The sound pattern of English.
Stednavne, D. 1922. Danmarks Stednavne. C. A. Reitzel. In Danmarks Stednavne. C. A. Reitzel.
Bart De, B. 2003. Conditions for stable vowel systems in a population. In Advances in Artificial Life. pp. 415--424
Denison, D. 2003. Log(ist)ic and simplistic scurves. In Motives for Language Change. pp. 54--70 10.1017/CBO9780511486937.005
Dubossarsky, H., Weinshall, D., and Grossman, E. 2017. Outta control: Laws of semantic change and inherent biases in word representation models. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing. pp. 1136--1145 10.18653/v1/D17-1118
Eger, S. and Mehler, A. 2016. On the linearity of semantic change: Investigating meaning variation via dynamic graph models. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics. pp. 52--58 10.18653/v1/P16-2009
John R Firth 1957. A synopsis of linguistic theory, 1930-1955. Studies in linguistic analysis. In A synopsis of linguistic theory, 1930-1955. Studies in linguistic analysis.
Fox, J. and Weisberg, S. 2019. An R Companion to Applied Regression. In An R Companion to Applied Regression.
Olrik Frederiksen, B. 2018. Gammeldansk. In Ebba Hjorth, Henrik Galberg Jakobsen, Bent Jørgensen, Brigitte Jacobsen, Merete Korvenius Jørgensen, and Laurids Kristian Fahl. pp. 151--179
Hamilton, W. L., Leskovec, J., and Jurafsky, D. 2016. Cultural shift or linguistic drift? comparing two computational measures of semantic change. In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing. pp. 2116--2121 10.18653/v1/D16-1229
Hamilton, W. L., Leskovec, J., and Jurafsky, D. 2016. Diachronic word embeddings reveal statistical laws of semantic change. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics. pp. 1489--1501 10.18653/v1/P16-1141
Hare, M. and Jeffrey L Elman 1995. Learning and morphological change. In Cognition. pp. 61--98
Johannsen, A., Héctor Martínez Alonso, B., and Plank 2015. Universal dependencies for danish. In International Workshop on Treebanks and Linguistic Theories (TLT14). pp. 157
Kim, Y., Chiu, Y., Hanaki, K., Hegde, D., and Petrov, S. 2014. Temporal analysis of language through neural language models. In Proceedings of the ACL 2014 Workshop on Language Technologies and Computational Social Science. pp. 61--65 10.3115/v1/W14-2517
Kroonen, G. 2013. Etymological Dictionary of Proto-Germanic. In Etymological Dictionary of Proto-Germanic.
Kutuzov, A., Øvrelid, L., Szymanski, T., and Velldal, E. 2018. Diachronic word embeddings and semantic shifts: a survey. In Proceedings of the 27th International Conference on Computational Linguistics. pp. 1384--1397
Mayer, C. 2020. An algorithm for learning phonological classes from distributional similarity. In Phonology. pp. 91--131 10.1017/S0952675720000056
Mielke, J. 2008. The emergence of distinctive features. In The emergence of distinctive features.
Robert, W. and Murray 2015. The Oxford Handbook of Historical Phonology, Oxford Handbooks in Linguistics. In The Oxford Handbook of Historical Phonology, Oxford Handbooks in Linguistics.
Pierrehumbert, J. B. 2001. Exemplar dynamics: Word frequency, lenition and contrast. In Typological studies in language. pp. 137--157 10.1075/tsl.45.08pie
R Core Team 2021. R: A Language and Environment for Statistical Computing. R Foundation for Statistical Computing. In R: A Language and Environment for Statistical Computing. R Foundation for Statistical Computing.
Shoemark, P., Farhana, F., Liza, D., Nguyen, S., Hale, B., and Mcgillivray 2019. Room to Glo: A systematic comparison of semantic change detection approaches with word embeddings. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP). pp. 66--76 10.18653/v1/D19-1007
Miikka, P., Silfverberg, L., Mao, M., and Hulden 2018. Sound analogies with phoneme embeddings. In Proceedings of the Society for Computation in Linguistics (SCiL. pp. 136--144 10.7275/R5NZ85VD
Tahmasebi, N., Borin, L., and Jatowt, A. 2018. Survey of computational approaches to lexical semantic change. In Preprint at ArXiv.
Wedel, A. 2015. The Oxford Handbook of Historical Phonology, Oxford Handbooks in Linguistics. In The Oxford Handbook of Historical Phonology, Oxford Handbooks in Linguistics.
Yao, Z., Sun, Y., Ding, W., Rao, N., and Xiong, H. 2018. Dynamic word embeddings for evolving semantic discovery. In Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining. 10.1145/3159652.3159703