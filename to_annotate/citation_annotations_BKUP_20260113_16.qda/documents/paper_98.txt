Introduction

Retrieval systems aim at retrieving the documents most relevant to the input queries, and have received substantial spotlight since they work as core elements in diverse applications, especially for open-domain question answering (QA) (Voorhees, 1999). Open-domain QA is a task of answering the question from a massive amount of documents, often requiring two components, a retriever and a reader (Chen et al., 2017;Karpukhin et al., 2020). Specifically, a retriever ranks the most questionrelated documents, and a reader answers the question using the retrieved documents.

Traditional sparse retrieval approaches such as BM25 (Robertson et al., 1994) and TF-IDF rely on term-based matching, hence suffering from the vocabulary mismatch problem: the failure of retrieving relevant documents due to the lexical difference from queries. To tackle such a problem, recent research focuses on dense retrieval models to generate learnable dense representations for queries and documents with a dual encoder structure (Karpukhin et al., 2020;. Despite their recent successes, some challenges still remain in the dense retrieval scheme for a couple of reasons. First, dense retrieval models need a large amount of labeled training data for a decent performance. However, as Figure 1 shows, the proportion of labeled query-document pairs is extremely small since it is almost impossible to rely on humans for the annotations of a large document corpus. Second, in order to adapt a retrieval model to the real world, where documents constantly emerge, handling unlabeled documents that are not seen during training should obviously be considered, but remains challenging.

To automatically expand the query-document pairs, recent work generates queries from generative models (Liang et al., 2020;Ma et al., 2021) or incorporates queries from other datasets , and then generates extra pairs of augmented queries and documents. However, these query augmentation schemes have serious obvious drawbacks. First, it is infeasible to augment queries for every document in the dataset (see the number of unlabeled documents in Figure 1), since generating and pairing queries are quite costly. Second, even after obtaining new pairs, we need extra training steps to reflect the generated pairs on the retrieval model. Third, this query augmentation method does not add variations to the documents but only to the queries, thus it may be suboptimal to handle enormous unlabeled documents. Since augmenting additional queries is costly, the question is then if it is feasible to only manipulate the given query-document pairing to handle numerous unlabeled documents. To answer this question, we first visualize the embeddings of labeled and unlabeled documents. Figure 1 shows that there is no distinct distributional shift between labeled and unlabeled documents. Thus it could be effective to manipulate only the labeled documents to handle the nearby unlabeled documents as well as the labeled documents. Using this observation, we propose a novel document augmentation method for a dense retriever, which not only interpolates two different document representations associated with the labeled query (Figure 2, center), but also stochastically perturbs the representations of labeled documents with a dropout mask (Figure 2,right). One notable advantage of our scheme is that, since it manipulates only the representations of documents, our model does not require explicit annotation steps of query-document pairs, which is efficient. We refer to our overall method as Document Augmentation for dense Retrieval (DAR).

We experimentally validate our method on standard open-domain QA datasets, namely Natural Question (NQ) (Kwiatkowski et al., 2019) and Triv-iaQA (Joshi et al., 2017) (TQA), against various evaluation metrics for retrieval models. The experimental results show that our method significantly improves the retrieval performances on both the unlabeled and labeled documents. Furthermore, a detailed analysis of the proposed model shows that interpolation and stochastic perturbation positively contribute to the overall performance.

Our contributions in this work are threefold: • We propose to augment documents for dense retrieval models to tackle the problem of insufficient labels of query-document pairs. • We present two novel document augmentation schemes for dense retrievers: interpolation and perturbation of document representations. • We show that our method achieves outstanding retrieval performances on both labeled and unlabeled documents on open-domain QA tasks.

 References: 
Chen, D., Fisch, A., Weston, J., and Bordes, A. 2017. Reading wikipedia to answer opendomain questions. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics. pp. 1870--1879 10.18653/v1/P17-1171
Chen, J., Yang, Z., and Yang, D. 2020. Mix-Text: Linguistically-informed interpolation of hidden space for semi-supervised text classification. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. pp. 2147--2157 10.18653/v1/2020.acl-main.194
Chen, T., Kornblith, S., Norouzi, M., and Hinton, G. E. 2020. A simple framework for contrastive learning of visual representations. In Proceedings of the 37th International Conference on Machine Learning. pp. 1597--1607
Devlin, J., Chang, M., Lee, K., and Toutanova, K. 2019. BERT: Pre-training of deep bidirectional transformers for language understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. pp. 4171--4186 10.18653/v1/N19-1423
Hedderich, M. A., Lange, L., and Adel, H. 2021. A survey on recent approaches for natural language processing in low-resource scenarios. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. pp. 2545--2568 10.18653/v1/2021.naacl-main.201
Jeong, S., Baek, J., Park, C., and Park, J. 2021. Unsupervised document expansion for information retrieval with stochastic text generation. In Proceedings of the Second Workshop on Scholarly Document Processing. pp. 7--17 10.18653/v1/2021.sdp-1.2
Joshi, M., Choi, E., Weld, D. S., and Zettlemoyer, L. 2017. Triviaqa: A large scale distantly supervised challenge dataset for reading comprehension. In ACL.
Karpukhin, V., Oguz, B., Min, S., Lewis, P., Wu, L., Edunov, S., Chen, D., and Yih, W. 2020. Dense passage retrieval for open-domain question answering. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP). pp. 6769--6781 10.18653/v1/2020.emnlp-main.550
Diederik, P., Kingma, J., and Ba 2015. Adam: A method for stochastic optimization. In 3rd International Conference on Learning Representations.
Kwiatkowski, T., Palomaki, J., Redfield, O., Collins, M., Parikh, A., Alberti, C., Epstein, D., Polosukhin, I., Kelcey, M., Devlin, J., Lee, K., Toutanova, K. N., Jones, L., Chang, M., Dai, A., Uszkoreit, J., Le, Q., and Petrov, S. 2019. Natural questions: a benchmark for question answering research. Transactions of the Association of Computational Linguistics. In Natural questions: a benchmark for question answering research. Transactions of the Association of Computational Linguistics.
Lee, K., Chang, M., and Toutanova, K. 2019. Latent retrieval for weakly supervised open domain question answering. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics. pp. 6086--6096 10.18653/v1/P19-1612
Lee, S., Kang, M., Lee, J., and Hwang, S. J. 2021. Learning to perturb word embeddings for out-of-distribution qa. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics.
Liang, D., Xu, P., Shakeri, S., Nogueira, C., Santos, R., Nallapati, Z., Huang, B., and Xiang 2020. Embedding-based zero-shot retrieval through query generation. In Embedding-based zero-shot retrieval through query generation. arXiv:2009.10270
Ma, E. 2019. Nlp augmentation. In Nlp augmentation.
Ma, J., Korotkov, I., Yang, Y., Hall, K., and Mcdonald, R. 2021. Zero-shot neural passage retrieval via domain-targeted synthetic question generation. In Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume. pp. 1075--1088
Van Der Maaten, L. and Hinton, G. 2008. Visualizing data using t-sne. In Journal of machine learning research.
Mao, Y., He, P., Liu, X., Shen, Y., Gao, J., Han, J., and Chen, W. 2021. Generation-augmented retrieval for opendomain question answering. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing. pp. 4089--4100 10.18653/v1/2021.acl-long.316
Mao, Y., He, P., Liu, X., Shen, Y., Gao, J., Han, J., and Chen, W. 2021. Reader-guided passage reranking for opendomain question answering. In Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021. pp. 344--350 10.18653/v1/2021.findings-acl.29
Qu, Y., Ding, Y., Liu, J., Liu, K., Ren, R., Zhao, W. X., Dong, D., Wu, H., and Wang, H. 2021. Rocketqa: An optimized training approach to dense passage retrieval for opendomain question answering. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. pp. 5835--5847
Robertson, S. E., Walker, S., Jones, S., Hancock-Beaulieu, M., and Gatford, M. 1994. Okapi at TREC-3. In Proceedings of The Third Text REtrieval Conference. pp. 109--126
Stephen, E., Robertson, H., and Zaragoza 2009. The probabilistic relevance framework: BM25 and be-Found. In Trends Inf. Retr. pp. 333--389
Rosset, C., Mitra, B., Xiong, C., Craswell, N., Song, X., and Tiwary, S. 2019. An axiomatic approach to regularizing neural ranking models. In Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR 2019. pp. 981--984
Shorten, C., Taghi, M., and Khoshgoftaar 2019. A survey on image data augmentation for deep learning. In J. Big Data. pp. 60 10.1186/s40537-019-0197-0
Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., and Salakhutdinov, R. 2014. Dropout: A simple way to prevent neural networks from overfitting. In Journal of Machine Learning Research. pp. 1929--1958
Verma, V., Lamb, A., Beckham, C., Najafi, A., Mitliagkas, I., Lopez-Paz, D., and Bengio, Y. 2019. Manifold mixup: Better representations by interpolating hidden states. In Proceedings of the 36th International Conference on Machine Learning, ICML 2019. pp. 6438--6447
Voorhees, E. M. 1999. The TREC-8 question answering track report. In Proceedings of The Eighth Text REtrieval Conference. TREC 1999
Wei, J. and Zou, K. 2019. EDA: Easy data augmentation techniques for boosting performance on text classification tasks. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP). pp. 6383--6389
Xiong, L., Xiong, C., Li, Y., Tang, K., Liu, J., Bennett, P. N., Ahmed, J., and Overwijk, A. 2021. Approximate nearest neighbor negative contrastive learning for dense text retrieval. In International Conference on Learning Representations.
Yin, W., Wang, H., Qu, J., and Xiong, C. 2021. BatchMixup: Improving training by interpolating hidden states of the entire mini-batch. In Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021. pp. 4908--4912 10.18653/v1/2021.findings-acl.434
You, Y., Li, J., Sashank, J., Reddi, J., Hseu, S., Kumar, S., Bhojanapalli, X., Song, J., Demmel, K., Keutzer, C., and Hsieh 2020. Large batch optimization for deep learning: Training BERT in 76 minutes. In 8th International Conference on Learning Representations.
Zhang, H., Cisse, M., Dauphin, Y. N., and Lopez-Paz, D. 2018. mixup: Beyond empirical risk minimization. International Conference on Learning Representations. In mixup: Beyond empirical risk minimization. International Conference on Learning Representations.