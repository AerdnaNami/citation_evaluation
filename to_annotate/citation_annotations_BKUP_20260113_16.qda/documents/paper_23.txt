Related Work

The goal of constrained textual generation is to find the sequence of tokens x1:T which maximises p(x1:T | c), given a constraint c. Few methods address the constrained textual generation. 

Class-conditional language models. Classconditional language models (CC-LMs), as the Conditional Transformer Language (CTRL) model (Keskar et al., 2019), train or fine-tune the weights θ of a single neural model directly for controllable generation, by appending a control code in the beginning of a training sequence. The control code indicates the constraint to verify and is related to a class containing texts that satisfy the constraint. For the sake of simplicity, we will denote without distinction the class, the constraint verified by its texts and the associated control code by c. Trained with different control codes, the model learns pθ(x1:T | c) = ∏T t=1 pθ(xt | x1:t−1, c). The constraint can then be applied during generation by appending the corresponding control code to the prompt. While this method gives some kind of control over the generation, the control codes need to be defined upfront and the LM still needs to be trained specifically for each set of control codes. This is an important limitation since the current trend in text generation is the use of large pre-trained model which can hardly be fine-tuned (for instance, the last version of GPT, GPT-3, cannot be fine-tuned without access to very large hardware resources). Discriminator-based methods The general idea of discriminator-guided generation is to combine a disciminator D with a generative LM. The discriminator explicitly models the constraint by calculating the probability pD(c | x1:T ) of the sequence x1:T to satisfy the constraint c.  This probability is directly related to p(x1:T | c) through Bayes’ rule : p(x1:T | c) ∝ pD(c | x1:T )pθ(x1:T ). 

Discriminator-based methods alleviate the training cost problem, as discriminators are easier to train than a LM. Moreover, any additional constraint can be defined a posteriori without tuning the LM, only by training another discriminator. The discriminators have been used in different ways to explore the search space. In the work of (Holtzman et al., 2018; Scialom et al., 2020), the space is first searched using beam search to generate a pool of proposals with a high likelihood pθ(x1:T ), and then the discriminator is used to re-rank them. However, in addition that beam search can miss sequences with high likelihood, it is biased towards the likelihood, while the best sequence might only have an average likelihood, but satisfies the constraint perfectly. 

Hence, it might be more suitable to take the discriminator probability into account during decoding rather than after generating a whole sequence. In this case, the discriminator is used at each generation step to get the probability pD(c | x1:t) for each token of the vocabulary V, and merge it to the likelihood pθ(x1:t) to choose which token to emit. In order to reduce the cost of using a discriminator on every possible continuation, GeDi (Krause et al., 2020) proposes to use CC-LMs as generative discriminators. The method relies on the fact that the CC-LM computes pθ (xt | x1:t−1, c) for all tokens of the vocabulary which can be used to get pθ(c | x1:t) for all tokens using Bayes’ equation. This approach is thus at the intersection of tuning the LM and using a discriminator: it tunes a small LM (the CC-LM) to guide a bigger one. 

In Plug And Play Language Model (PPLM) (Dathathri et al., 2020), the discriminator is used to shift the hidden states of the pre-trained transformer-based LM towards the desired class at every generation step. PPLM can be used on any LM and with any discriminator. However, PPLM needs to access the LM to modify its hidden states, while our approach only requires the output logits. As some LM can only be used through access to logits (e.g. GPT-3 API), this makes our approach more plug and play than PPLM. A common drawback of all these approaches is their lack of a long-term vision of the  generation. Indeed, the discriminator probabilities become necessarily more meaningful as the sequence grows and might only be trustable to guide the search when the sequence is (nearly) finished.  When used in a myopic decoding strategy, classification errors will cause the generation process to deviate further and further. Trying to optimize a score defined in the long horizon by making short term decisions is very similar to common game setups such as chess, where the Monte Carlo Tree Search (MCTS) has proven to be really effective (Silver et al., 2018), which motivated our approach.
 

 References: 
Bender, E. M., Gebru, T., Mcmillan-Major, A., and Shmitchell, S. 2021. On the dangers of stochastic parrots: Can language models be too big?. In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency, FAccT '21. pp. 610--623 10.1145/3442188.3445922
Brown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., Agarwal, S., Herbert-Voss, A., Krueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler, D. M., Wu, J., Winter, C., Hesse, C., Chen, M., Sigler, E., and Litwin, M. Mc-Candlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language models are few-shot learners. In Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020.
Caccia, M., Caccia, L., Fedus, W., Larochelle, H., Pineau, J., and Charlin, L. 2020. Language gans falling short. In 8th International Conference on Learning Representations.
Cotarelo, A., Díaz, V. G., Valdez, E. N., González García, C., Gómez, A., and Lin, J. 2021. Improving monte carlo tree search with artificial neural networks without heuristics. In Applied Sciences. pp. 2056 10.3390/app11052056
2006. Efficient selectivity and backup operators in monte-carlo tree search. In Computers and Games, 5th International Conference. pp. 72--83 10.1007/978-3-540-75538-8_7
Dathathri, S., Madotto, A., Lan, J., Hung, J., Frank, E., Molino, P., Yosinski, J., and Liu, R. 2020. Plug and play language models: A simple approach to controlled text generation. In 8th International Conference on Learning Representations.
2018. Speech understanding systems: summary of results of the five-year research effort at carnegiemellon university. In Speech understanding systems: summary of results of the five-year research effort at carnegiemellon university. 10.1184/R1/6609821.v1
Devlin, J., Chang, M., Lee, K., and Toutanova, K. 2019. BERT: pre-training of deep bidirectional transformers for language understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019. pp. 4171--4186 10.18653/v1/n19-1423
Samuel Gehman, S., Gururangan, M., Sap, Y., Choi, N. A., and Smith 2020. RealToxi-cityPrompts: Evaluating neural toxic degeneration in language models. In Findings of the Association for Computational Linguistics: EMNLP 2020. pp. 3356--3369 10.18653/v1/2020.findings-emnlp.301
Holtzman, A., Buys, J., Du, L., Forbes, M., and Choi, Y. 2020. The curious case of neural text degeneration. In 8th International Conference on Learning Representations.
Holtzman, A., Buys, J., Forbes, M., Bosselut, A., Golub, D., and Choi, Y. 2018. Learning to write with cooperative discriminators. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics. pp. 1638--1649 10.18653/v1/P18-1152
Nitish Shirish Keskar, B., Mccann, R., Varshney, C., Xiong, R., and Socher 2019. CTRL: A conditional transformer language model for controllable generation. In CTRL: A conditional transformer language model for controllable generation. abs/1909.05858
Krause, B., Deepak Gotmare, A., Mc-Cann, B., Shirish Keskar, N., Shafiq, R., Joty, R., Socher, N.F., and Rajani 2009. Gedi: Generative discriminator guided sequence generation. In Gedi: Generative discriminator guided sequence generation.
Kumar, V., Choudhary, A., and Cho, E. 2003. Data augmentation using pre-trained transformer models. CoRR, abs. In Data augmentation using pre-trained transformer models. CoRR, abs.
Le, H., Vial, L., Frej, J., Segonne, V., Coavoux, M., Lecouteux, B., Allauzen, A., Crabbé, B., Besacier, L., and Schwab, D. 2020. Flaubert: Unsupervised language model pre-training for french. In Proceedings of The 12th Language Resources and Evaluation Conference. pp. 2479--2490
Leblond, R., Alayrac, J., Sifre, L., Pislar, M., and Lespiau, J. 2021. Karen Simonyan, and Oriol Vinyals. 2021. Machine translation decoding beyond beam search. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing. pp. 8410--8434
Novikova, J., Dusek, O., Curry, A. C., and Rieser, V. 2017. Why we need new evaluation metrics for NLG. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing. pp. 2241--2252 10.18653/v1/d17-1238
Papanikolaou, Y. and Pierleoni, A. 2004. DARE: data augmented relation extraction with GPT-2. CoRR, abs. In DARE: data augmented relation extraction with GPT-2. CoRR, abs.
Papineni, K., Roukos, S., Ward, T., and Zhu, W. 2002. Bleu: a method for automatic evaluation of machine translation. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics. pp. 311--318 10.3115/1073083.1073135
Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., and Sutskever, I. 2019. Language models are unsupervised multitask learners. In Language models are unsupervised multitask learners.
Rosin, C. D. 2011. Multi-armed bandits with episode context. In Ann. Math. Artif. Intell. pp. 203--230 10.1007/s10472-011-9258-6
Saravia, E., Liu, H.T., Huang, Y., Wu, J., and Chen, Y. 2018. CARER: contextualized affect representations for emotion recognition. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing. pp. 3687--3697 10.18653/v1/d18-1404
Scialom, T., Dray, P., Lamprier, S., Piwowarski, B., and Staiano, J. 2020. Discriminative adversarial search for abstractive summarization. In Proceedings of the 37th International Conference on Machine Learning. pp. 8555--8564
Scialom, T., Dray, P., Lamprier, S., Piwowarski, B., and Staiano, J. 2021. To beam or not to beam: That is a question of cooperation for language gans. In Advances in neural information processing systems.
Silver, D., Hubert, T., Schrittwieser, J., Antonoglou, I., Lai, M., Guez, A., Lanctot, M., Sifre, L., Kumaran, D., Graepel, T., Lillicrap, T., Simonyan, K., and Hassabis, D. 2018. A general reinforcement learning algorithm that masters chess, shogi, and go through self-play. In Science. pp. 1140--1144 10.1126/science.aar6404
Silver, D., Schrittwieser, J., Simonyan, K., Antonoglou, I., Huang, A., Guez, A., Hubert, T., Baker, L., Lai, M., Bolton, A., Chen, Y., Lillicrap, T. P., Hui, F., and Sifre, L. 2017. George van den Driessche, Thore Graepel, and Demis Hassabis. In Nat. pp. 354--359 10.1038/nature24270
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, L., and Polosukhin, I. 2017. Attention is all you need. In Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems. pp. 5998--6008