Introduction

Named entity recognition (NER) aims at identifying text spans pertaining to specific entity types. It plays an important role in many downstream tasks such as relation extraction (Ji et al., 2017), entity linking (Sevgili et al., 2020), co-reference resolution (Clark and Manning, 2016), and knowledge graph (Ji et al., 2020). Due to the complex composition (Gui et al., 2019), character-level Chinese NER is more challenging compared to English NER. As shown in Figure 1 (a), the middle charac-  ter "流" can constitute words with the characters to both their left and their right, such as "河流 (River)" and "流经 (flows)", leading to ambiguous character boundaries.

There are two typical frameworks for NER. The first one conceptualizes NER as a sequence labeling task (Huang et al., 2015;Lample et al., 2016;Ma and Hovy, 2016), where each character is assigned to a special label (e.g., B-LOC, I-LOC). The second one is span-based method (Li et al., 2020a;, which classifies candidate spans based on their span-level representations. However, despite the success of these two types of methods, they do not explicitly take the complex composition of Chinese NER into consideration. Recently, several works (Zhang and Yang, 2018;Gui et al., 2019;Li et al., 2020b) utilize external lexicon knowledge to help connect related characters and promote capturing the local composition. Nevertheless, building the lexicon is time-consuming and the quality of the lexicon may not be satisfied.

In contrast to previous works, we observe that the regularity exists in the common NER types (e.g., ORG and LOC). As shown in Figure 1 (a), "尼日尔河 (Niger River)" follows the specific composition pattern "XX+河 (XX + River)" which ends with indicator character "河" and mostly belongs to location type, and the ambiguous character "流" can properly constitute "流经" with the right character "经". Thus, the regularity information serves as important clues for entity type recognition and identifying the character composition. Formally, we refer to regularity as specific internal patterns contained in a type of entity (Lin et al., 2020). However, too immersed regularity leads to unfavorable boundary detection of entities and disturbing character composition. As shown in Figure 1 (b), "中国队 (Chinese team)" conforms to the pattern "XX+队 (XX + Team)", but the correct entity boundary should be "中国 (Chinese)" and "队员 (players)" according to the context. Therefore, the context also plays a key role in determining the character boundary.

In this paper, we introduce a simple but effective method to explore the regularity information of entity spans for Chinese NER, dubbed as Regularity-Inspired reCOgnition Network (RICON). The proposed model consists of two branches named regularity-aware module and regularity-agnostic module, where each module has task-specific encoder and optimization object. Concretely, the regularity-aware module aims at analyzing the internal regularity of each span and integrates the significant regularity information into the corresponding span-level representation, leading to precise entity type prediction. Meanwhile, the regularityagnostic module is devised to capture context information and avoid excessive focus on intra-span regularity. Furthermore, we adopt an orthogonality space restriction to encourage two branches to extract different features with regard to the regularity. To verify the effectiveness of our method, we conduct extensive experiments on three large-scale benchmark datasets (OntoNotes V4.0, OntoNotes V5.0, and MSRA). The results show that RICON achieves considerable improvements compared to the state-of-the-art models, even outperforming existing lexicon-based models. Moreover, we experiment on a practical medical dataset (CBLUE) to further demonstrate the ability of RICON.

Our contributions can be summarized as follows:

• This is the first work that explicitly explores the internal regularity of entity mentions for Chinese NER.

• We propose a simple but effective method for Chinese NER, which effectively utilizes regularity information while avoiding excessive focus on intra-span regularity.

• Extensive experiments on three large-scale benchmark datasets and a practical medical dataset demonstrate the effectiveness of our proposed method.

 References: 
Chen, C. and Kong, F. 2021. Enhancing entity boundary detection for better Chinese named entity recognition. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing. pp. 20--25 10.18653/v1/2021.acl-short.4
Clark, K. and Manning, C. D. 2016. Improving coreference resolution by learning entitylevel distributed representations. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics. pp. 643--653 10.18653/v1/P16-1061
Devlin, J., Chang, M., Lee, K., and Toutanova, K. 2019. BERT: Pre-training of deep bidirectional transformers for language understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. pp. 4171--4186 10.18653/v1/N19-1423
Gui, T., Zou, Y., Zhang, Q., Peng, M., Fu, J., Wei, Z., and Huang, X. 2019. A lexicon-based graph neural network for Chinese NER. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP). pp. 1040--1050 10.18653/v1/D19-1096
Hongying, Z., Wenxin, L., Kunli, Z., Yajuan, Y., Baobao, C., and Zhifang, S. 2020. Building a pediatric medical corpus: Word segmentation and named entity annotation. In Workshop on Chinese Lexical Semantics. pp. 652--664
Huang, Z., Wei, X., and Kai, Y. 2015. Bidirectional lstmcrf models for sequence tagging. In Bidirectional lstmcrf models for sequence tagging. arXiv:1508.01991
Ji, G. and Liu, K. 2017. Distant supervision for relation extraction with sentence-level attention and entity descriptions. In Proceedings of the AAAI Conference on Artificial Intelligence.
Ji, S., Pan, S., Cambria, E., Marttinen, P., and Yu, P. S. 2020. A survey on knowledge graphs: Representation, acquisition and applications. In Computer Science arXiv preprint. arXiv:2002.00388
Jie, Z. and Lu, W. 2019. Dependency-guided lstmcrf for named entity recognition. In Dependency-guided lstmcrf for named entity recognition. arXiv:1909.10148
Lample, G., Ballesteros, M., Subramanian, S., Kawakami, K., and Dyer, C. 2016. Neural architectures for named entity recognition. In Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. pp. 260--270 10.18653/v1/N16-1030
Levow, G. 2006. The third international Chinese language processing bakeoff: Word segmentation and named entity recognition. In Proceedings of the Fifth SIGHAN Workshop on Chinese Language Processing. pp. 108--117
Li, J., Sun, A., and Ma, Y. 2020. Neural named entity boundary detection. In IEEE Transactions on Knowledge and Data Engineering. pp. 1--1
Li, X., Yan, H., Qiu, X., and Huang, X. 2020. FLAT: Chinese NER using flat-lattice transformer. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. pp. 6836--6842 10.18653/v1/2020.acl-main.611
Lin, H., Lu, Y., Tang, J., Han, X., Sun, L., Wei, Z., and Yuan, N.J. 2020. A rigorous study on named entity recognition: Can fine-tuning pretrained model lead to the promised land. In A rigorous study on named entity recognition: Can fine-tuning pretrained model lead to the promised land. arXiv:2004.12126
Liu, W., Fu, X., Zhang, Y., and Xiao, W. 2021. Lexicon enhanced chinese sequence labelling using bert adapter. In Lexicon enhanced chinese sequence labelling using bert adapter. arXiv:2105.07148
Ma, R., Peng, M., Zhang, Q., Wei, Z., and Huang, X. 2020. Simplify the usage of lexicon in Chinese NER. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. pp. 5951--5960 10.18653/v1/2020.acl-main.528
Ma, X. and Hovy, E. 2016. End-to-end sequence labeling via bi-directional LSTM-CNNs-CRF. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics. pp. 1064--1074 10.18653/v1/P16-1101
Mengge, X., Yu, B., Liu, T., Zhang, Y., Meng, E., and Wang, B. 2020. Porous lattice transformer encoder for Chinese NER. In Proceedings of the 28th International Conference on Computational Linguistics. pp. 3831--3841 10.18653/v1/2020.coling-main.340
Peters, M. E., Neumann, M., Iyyer, M., Gardner, M., Clark, C., Lee, K., and Zettlemoyer, L. 2018. Deep contextualized word representations. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. pp. 2227--2237 10.18653/v1/N18-1202
Sameer Pradhan, A., Moschitti, N., Xue, H.T., Ng, A., Björkelund, O., Uryupina, Y., Zhang, Z., and Zhong 2013. Towards robust linguistic analysis using OntoNotes. In Proceedings of the Seventeenth Conference on Computational Natural Language Learning. pp. 143--152
Sevgili, O., Shelmanov, A., Arkhipov, M., Panchenko, A., and Biemann, C. 2020. Neural entity linking: A survey of models based on deep learning. In Computer Science arXiv preprint. arXiv:2006.00575
Shen, Y., Ma, X., Tan, Z., Zhang, S., Wang, W., and Lu, W. 2021. Locate and label: A two-stage identifier for nested named entity recognition. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics.
Mohammad, G., Sohrab, M., and Miwa 2018. Deep exhaustive model for nested named entity recognition. In Proceedings of the. 10.18653/v1/D18-1309
Conference on Empirical Methods in Natural Language Processing. In Conference on Empirical Methods in Natural Language Processing. pp. 2843--2849
Sui, D., Chen, Y., and Liu, K. 2019. Leverage lexical knowledge for Chinese named entity recognition via collaborative graph network. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP). pp. 3830--3840 10.18653/v1/D19-1396
Tang, Z., Wan, B., and Yang, L. 2020. Word-character graph convolution network for chinese named entity recognition. In Speech, and Language Processing. pp. 1--1
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, Ł., and Polosukhin, I. 2017. Attention is all you need. In Advances in neural information processing systems. pp. 5998--6008
Weischedel, R., Palmer, M., Marcus, M., Hovy, E., Pradhan, S., Ramshaw, L., Xue, N., Taylor, A., Kaufman, J., and Franchini, M. 2011. Ontonotes release 4.0. LDC2011T03. In Ontonotes release 4.0. LDC2011T03.
Xia, C., Zhang, C., Yang, T., Li, Y., Du, N., Wu, X., Fan, W., Ma, F., and Yu, P. 2019. Multi-grained named entity recognition. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics. pp. 1430--1440 10.18653/v1/P19-1138
Yu, J., Bohnet, B., and Poesio, M. 2020. Named entity recognition as dependency parsing. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. pp. 6470--6476 10.18653/v1/2020.acl-main.577