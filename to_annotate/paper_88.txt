Introduction

Distributed representations of events, are a common way to represent events in a machine-readable form and have shown to provide meaningful features for various tasks (Lee and Goldwasser, 2018;Rezaee and Ferraro, 2021;Deng et al., 2021;Martin et al., 2018;. Obtaining effective event representations is challenging, as it requires representations to capture various relations between events. Figure 1 presents four pairs of events with different relations. Two events may share the same event attributes (e.g. event types and sentiments), and there may also be a causal or temporal relation between two events.

Early works (Weber et al., 2018) exploit easily accessible co-occurrence relation of events to learn event representations. Although the use of cooccurrence relation works well, it is too coarse for deep understanding of events, which requires finegrained knowledge (Lee and Goldwasser, 2019). Recent works focus on fine-grained knowledge, such as discourse relations (Prasad et al., 2006;Lee and Goldwasser, 2019;Zheng et al., 2020) and commonsense knowledge (e.g. sentiments and intents) (Sap et al., 2019;Ding et al., 2019). Concretely, Lee and Goldwasser (2019) and Zheng et al. (2020) leverage 11 discourse relation types to model event script knowledge. Ding et al. (2019) incorporate manually labeled commonsense knowledge (intents and sentiments) into event representation learning. However, the types of fine-grained event knowledge are so diverse that we cannot enumerate all of them and currently adopted finegrained knowledge fall under a small set of event knowledge. In addition, some manually labeled knowledge (Sap et al., 2019;Hwang et al., 2021) is costly and difficult to apply on large datasets.

In our work, we observe that there is a rich amount of information in co-occurring events, but previous works did not make good use of such information. Based on existing works on event relation extraction (Xue et al., 2016;Lee and Goldwasser, 2019;, we find that the co-occurrence relation, which refers to two events appearing in the same document, can be seen as a superset of current defined explicit discourse relations, as most existing automatic methods extract event relations from documents or sentences. More than that, it also includes other implicit event knowledge, that is, events that occur in the same document may share the same topic and event type. Previous works (Granroth-Wilding and Clark, 2016;Weber et al., 2018) based on cooccurrence information usually exploit instancewise contrastive learning approaches related to the margin loss, which consists of an anchor, positive, and negative sample, where the anchor is more similar to the positive than the negative. However, they share two common limitations: (1) such marginbased approaches struggle to capture the essential differences between events with different semantics, as they only consider one positive and one negative per anchor. (2) Randomly sampled negative samples may contain samples semantically related to the anchor but are undesirably pushed apart in embedding space. This problem arises because these instance-wise contrastive learning approaches treat randomly selected events as negative samples, regardless of their semantic relevance.

We are motivated to address the above issues with the goal of making better use of cooccurrence information of events. To this end, we present SWCC: a Simultaneous Weakly supervised Contrastive learning and Clustering framework for event representation learning, where we exploit document-level co-occurrence information of events as weak supervision and learn event representations by simultaneously performing weakly supervised contrastive learning and prototype-based clustering. To address the first issue, we build our approach on the contrastive framework with the InfoNCE objective (van den Oord et al., 2019), which is a self-supervised contrastive learning method that uses one positive and multiple negatives. Further, we extend the InfoNCE to a weakly supervised contrastive learning setting, allowing us to consider multiple positives and multiple negatives per anchor (as opposed to the margin loss which uses only one positive and one negative). Co-occurring events are then incorporated as additional positives, weighted by a normalized co-occurrence frequency. To address the second issue, we introduce a prototype-based clustering method to avoid semantically related events being pulled apart. Specifically, we impose a prototype for each cluster, which is a representative embed-ding for a group of semantically related events. Then we cluster the data while enforce consistency between cluster assignments produced for different augmented representations of an event. Unlike the instance-wise contrastive learning, our clustering method focuses on the cluster-level semantic concepts by contrasting between representations of events and clusters. Overall, we make the following contributions:

• We propose a simple and effective framework (SWCC) that learns event representations by making better use of co-occurrence information of events. Experimental results show that our approach outperforms previous approaches on several event related tasks. • We introduce a weakly supervised contrastive learning method that allows us to consider multiple positives and multiple negatives, and a prototype-based clustering method that avoids semantically related events being pulled apart. • We provide a thorough analysis of the prototypebased clustering method to demonstrate that the learned prototype vectors are able to implicitly capture various relations between events. The source code 1 of our SWCC has been uploaded to Anonymous Github for reproducing our results.

 References: 
Asano, Y. M., Rupprecht, C., and Vedaldi, A. 2020. Self-labelling via simultaneous clustering and representation learning. In 8th International Conference on Learning Representations.
Bai, L., Guan, S., Guo, J., Li, Z., Jin, X., and Cheng, X. 2021. Integrating deep event-level and script-level information for script event prediction. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing. pp. 9869--9878
Caron, M., Bojanowski, P., Joulin, A., and Douze, M. 2018. Deep clustering for unsupervised learning of visual features. In Proceedings of the European Conference on Computer Vision (ECCV). pp. 132--149
Caron, M., Misra, I., Mairal, J., Goyal, P., Bojanowski, P., and Joulin, A. 2020. Unsupervised learning of visual features by contrasting cluster assignments. In Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020.
Chambers, N. and Jurafsky, D. 2008. Unsupervised learning of narrative event chains. In Proceedings of ACL-08: HLT. pp. 789--797
Chen, H., Shu, R., Takamura, H., and Nakayama, H. 2021. Graphplan: Story generation by planning with event graph. In Graphplan: Story generation by planning with event graph. abs/2102.02977
Chen, T., Kornblith, S., Norouzi, M., and Hinton, G. E. 2020. A simple framework for contrastive learning of visual representations. In Proceedings of the 37th International Conference on Machine Learning. pp. 1597--1607
Chen, X., Fan, H., Girshick, R., and He, K. 2003. Improved baselines with momentum contrastive learning. ArXiv preprint, abs. In Improved baselines with momentum contrastive learning. ArXiv preprint, abs.
Chen, X. and He, K. 2021. Exploring simple siamese representation learning. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 15750--15758
Cuturi, M. 2013. Sinkhorn distances: Lightspeed computation of optimal transport. In Advances in Neural Information Processing Systems 26: 27th Annual Conference on Neural Information Processing Systems. pp. 2292--2300
Deng, S., Zhang, N., Li, L., Hui, C., Huaixiao, T., Chen, M., Huang, F., and Chen, H. 2021. OntoED: Low-resource event detection with ontology embedding. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing. pp. 2828--2839 10.18653/v1/2021.acl-long.220
Devlin, J., Chang, M., Lee, K., and Toutanova, K. 2019. BERT: Pre-training of deep bidirectional transformers for language understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. pp. 4171--4186 10.18653/v1/N19-1423
Ding, X., Liao, K., Liu, T., Li, Z., and Duan, J. 2019. Event representation learning enhanced with external commonsense knowledge. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP). pp. 4894--4903 10.18653/v1/D19-1495
Ding, X., Zhang, Y., Liu, T., and Duan, J. 2016. Knowledge-driven event embedding for stock prediction. In Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers. pp. 2133--2142
Gao, T., Yao, X., and Chen, D. 2021. Simcse: Simple contrastive learning of sentence embeddings. In Simcse: Simple contrastive learning of sentence embeddings. abs/2104.08821
Granroth, M., Wilding, -., and Clark, S. 2016. What happens next? event prediction using a compositional neural network model. In Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence. pp. 2727--2733
Grill, J., Strub, F., Altché, F., Tallec, C., Richemond, P. H., Buchatskaya, E., Doersch, C., Bernardo Ávila Pires, Z., Guo, M. G., Azar, B., Piot, K., Kavukcuoglu, R., Munos, M., and Valko 2020. Bootstrap your own latent -A new approach to self-supervised learning. In Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020.
He, K., Fan, H., Wu, Y., Xie, S., and Girshick, R. B. 2020. Momentum contrast for unsupervised visual representation learning. In 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 9726--9735 10.1109/CVPR42600.2020.00975
Hu, Q., Wang, X., Hu, W., and Guo 2021. Adco: Adversarial contrast for efficient learning of unsupervised representations from selftrained negative adversaries. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 1074--1083
Hu, Z., Shi, H., Tan, B., Wang, W., Yang, Z., Zhao, T., He, J., Qin, L., Wang, D., Ma, X., Liu, Z., Liang, X., Zhu, W., Sachan, D., and Xing, E. 2019. Texar: A modularized, versatile, and extensible toolkit for text generation. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations. pp. 159--164 10.18653/v1/P19-3027
Jena, D., Hwang, C., Bhagavatula, Ronan Le Bras, J., Da, K., Sakaguchi, A., Bosselut, Y., and Choi 2021. On symbolic and neural commonsense knowledge graphs. In On symbolic and neural commonsense knowledge graphs.
Jans, B., Bethard, S., Vulić, I., and Moens, M. F. 2012. Skip n-grams and ranking functions for predicting script events. In Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics. pp. 336--344
Kartsaklis, D. and Sadrzadeh, M. 2014. A study of entanglement in a categorical framework of natural language. In A study of entanglement in a categorical framework of natural language. abs/1405.2874
Khosla, P., Teterwak, P., Wang, C., Sarna, A., Tian, Y., Isola, P., Maschinot, A., Liu, C., and Krishnan, D. 2020. Supervised contrastive learning. In Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020.
Lee, I. and Goldwasser, D. 2018. FEEL: featured event embedding learning. In Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence, (AAAI-18), the 30th innovative Applications of Artificial Intelligence (IAAI-18), and the 8th AAAI Symposium on Educational Advances in Artificial Intelligence (EAAI-18). pp. 4840--4847
Lee, I. and Goldwasser, D. 2019. Multi-relational script learning for discourse relations. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics. pp. 4214--4226 10.18653/v1/P19-1413
Li, J., Zhou, P., Xiong, C., and Hoi, S. C.H. 2021. Prototypical contrastive learning of unsupervised representations. In 9th International Conference on Learning Representations, ICLR 2021, Virtual Event.
Li, M., Zeng, Q., Lin, Y., Cho, K., Ji, H., May, J., Chambers, N., and Voss, C. 2020. Connecting the dots: Event graph schema induction with path language modeling. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP). pp. 684--695 10.18653/v1/2020.emnlp-main.50
Li, Z., Ding, X., and Liu, T. 2018. Constructing narrative event evolutionary graph for script event prediction. In Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence. pp. 4201--4207 10.24963/ijcai.2018/584
Liang, X., Wu, L., Li, J., Wang, Y., Meng, Q., Qin, T., Chen, W., Zhang, M., and Liu, T. Regularized dropout for neural networks. In Regularized dropout for neural networks.
Lv, S., Qian, W., Huang, L., Han, J., and Hu, S. 2019. Sam-net: Integrating event-level and chain-level attentions to predict what happens next. In The Thirty-Third AAAI Conference on Artificial Intelligence, AAAI 2019, The Thirty-First Innovative Applications of Artificial Intelligence Conference, IAAI 2019. pp. 6802--6809 10.1609/aaai.v33i01.33016802
Lv, S., Zhu, F., and Hu, S. 2020. Integrating external event knowledge for script learning. In Proceedings of the 28th International Conference on Computational Linguistics. pp. 306--315 10.18653/v1/2020.coling-main.27
Martin, L. J., Ammanabrolu, P., Wang, X., Hancock, W., Singh, S., Harrison, B., and Riedl, M. O. 2018. Event representations for automated story generation with deep neural nets. In Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence, (AAAI-18), the 30th innovative Applications of Artificial Intelligence (IAAI-18), and the 8th AAAI Symposium on Educational Advances in Artificial Intelligence (EAAI-18). pp. 868--875
Mausam, M., Schmitz, S., Soderland, R., Bart, O., and Etzioni 2012. Open language learning for information extraction. In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning. pp. 523--534
Mikolov, T., Chen, K., Corrado, G., and Dean, J. 2013. Efficient estimation of word representations in vector space. In ArXiv preprint. abs/1301.3781
Ning, Q., Wu, H., and Roth, D. 2018. A multiaxis annotation scheme for event temporal relations. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics. pp. 1318--1328 10.18653/v1/P18-1122
Prasad, R., Miltsakaki, E., Dinesh, N., Lee, A., Joshi, A. K., Robaldo, L., and Webber, B. L. 2006. The penn discourse treebank 2.0 annotation manual. In The penn discourse treebank 2.0 annotation manual.
Rezaee, M. and Ferraro, F. 2021. Event representation with sequential, semi-supervised discrete variables. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. pp. 4701--4716 10.18653/v1/2021.naacl-main.374
Sap, M., Ronan Le Bras, E., Allaway, C., Bhagavatula, N., Lourie, H., Rashkin, B., Roof, N. A., Smith, Y., and Choi 2019. ATOMIC: an atlas of machine commonsense for if-then reasoning. In The Thirty-Third AAAI Conference on Artificial Intelligence, AAAI 2019, The Thirty-First Innovative Applications of Artificial Intelligence Conference, IAAI 2019, The Ninth AAAI Symposium on Educational Advances in Artificial Intelligence. pp. 3027--3035 10.1609/aaai.v33i01.33013027
Schroff, F., Kalenichenko, D., and Philbin, J. 2015. Facenet: A unified embedding for face recognition and clustering. In IEEE Conference on Computer Vision and Pattern Recognition. pp. 815--823 10.1109/CVPR.2015.7298682
Socher, R., Chen, D., Manning, C. D., and Ng, A. Y. 2013. Reasoning with neural tensor networks for knowledge base completion. In Advances in Neural Information Processing Systems 26: 27th Annual Conference on Neural Information Processing Systems 2013. Proceedings of a meeting held. pp. 926--934
Socher, R., Perelygin, A., Wu, J., Chuang, J., Manning, C. D., Ng, A., and Potts, C. 2013. Recursive deep models for semantic compositionality over a sentiment treebank. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing. pp. 1631--1642
Van Den Oord, A., Li, Y., and Vinyals, O. 2019.
Vijayaraghavan, P. and Roy, D. 2021. Lifelong knowledge-enriched social event representation learning. In Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume. pp. 3624--3635
Wang, H., Chen, M., Zhang, H., and Roth, D. 2020. Joint constrained learning for event-event relation extraction. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP). pp. 696--706 10.18653/v1/2020.emnlp-main.51
Weber, N., Balasubramanian, N., and Chambers, N. 2018. Event representations with tensor-based compositions. In Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence, (AAAI-18), the 30th innovative Applications of Artificial Intelligence (IAAI-18), and the 8th AAAI Symposium on Educational Advances in Artificial Intelligence (EAAI-18). pp. 4946--4953
Xue, N., Hwee Tou Ng, S., Pradhan, A., Rutherford, B., Webber, C., Wang, H., and Wang 2016. CoNLL 2016 shared task on multilingual shallow discourse parsing. In Proceedings of the CoNLL-16 shared task. pp. 1--19 10.18653/v1/K16-2001
Yu, C., Zhang, H., Song, Y., Ng, W., and Shang, L. 2020. Enriching largescale eventuality knowledge graph with entailment relations. In Automated Knowledge Base Construction.
Zbontar, J., Jing, L., Misra, I., Lecun, Y., and Deny, S. 2021. Barlow twins: Selfsupervised learning via redundancy reduction. In Proceedings of the 38th International Conference on Machine Learning, ICML 2021. pp. 12310--12320
Zhan, X., Xie, J., and Liu, Z. 2020. Online deep clustering for unsupervised representation learning. In 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 6687--6696 10.1109/CVPR42600.2020.00672
Zhang, D., Nan, F., Wei, X., Li, S., Zhu, H., Mckeown, K., Nallapati, R., Arnold, A. O., and Xiang, B. 2021. Supporting clustering with contrastive learning. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. pp. 5419--5430 10.18653/v1/2021.naacl-main.427
Zhang, H., Liu, X., Pan, H., Song, Y., Wing, C., and Leung, -. 2020. ASER: A largescale eventuality knowledge graph. In WWW '20: The Web Conference 2020. pp. 201--211 10.1145/3366423.3380107
Zheng, J., Cai, F., and Chen, H. 2020. Incorporating scenario knowledge into A unified finetuning architecture for event representation. In Proceedings of the 43rd International ACM SIGIR conference on research and development in Information Retrieval, SIGIR 2020, Virtual Event. pp. 249--258 10.1145/3397271.3401173
Zhou, Y., Geng, X., Shen, T., Pei, J., Zhang, W., and Jiang, D. 2021. Modeling event-pair relations in external knowledge graphs for script reasoning. In Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021. pp. 4586--4596 10.18653/v1/2021.findings-acl.403