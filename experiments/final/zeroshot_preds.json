{
  "paper_100.txt": {
    "filename": "paper_100.txt",
    "full_text": "Related work\n\nWe describe related works on pinyin input method and pinyin-enhanced pretrained models here.\n\nPinyin Input Method \n\nWe describe existing works based on whether the input pinyin is perfect or abbreviated. A majority of existing works focus on perfect pinyin. Traditional models are typically based on statistical language models (Chen and Lee, 2000) and statistical machine translation (Yang et al., 2012). Recent works are usually built with neural network. For example, Moon IME (Huang et al., 2018) integrates attention-based neural network and an information retrieval module. Zhang et al. (2019) improves an LSTM-\nbased encoder-decoder model with online vocabulary adaptation. For abbreviated pinyin, CoCAT (Huang et al., 2015) uses machine translation technology to reduce the number of the typing letters. Huang and Zhao (2018) propose an LSTM-based encoder-decoder approach with the concatenation of context words and abbreviated pinyin as input. Our work differs from existing works in that we are the first one to exploit GPT and verify the pros and cons of GPT in different situations. In addition, there are some works handling\npinyin with typing errors. Chen and Lee (2000) investigate a typing model which handles spelling correction in sentence-based pinyin input method. CHIME (Zheng et al., 2011) is a error-tolerant Chinese pinyin input method. It finds similar pinyin which will be further ranked with Chinese specific features. Jia and Zhao (2014) propose a joint graph model to globally optimize the tasks of pinyin input method and typo correction. We leave error-tolerant pinyin input method as a future work. \n\nPinyin-enhanced Pretrained Models \n\nOur methodology also relates to pretrained models that use pinyin information. Sun et al. (2021) propose a general-purpose Chinese BERT with\nnew embedding layers to inject pinyin and glyph information of characters. There are also task-specific BERT models, especially for the task of grammatical error correction since an important type of error is caused by characters pronounced with the same pinyin. Zhang et al. (2021a) add a pinyin embedding layer and learns to predict characters from similarly pronounced candidates. PLOME (Liu et al., 2021) add two embedding layers implemented with two GRU networks to inject both pinyin and shape of characters, respectively. Xu et al. (2021) add a hierarchical encoder to inject the pinyin letters at character and sentence levels, and add a ResNet encoder to use graphic features of character image.\n\n ",
    "all_spans": [
      {
        "span_text": "A majority of existing works focus on perfect pinyin.",
        "gpt_label": "Unsupported Claim",
        "reason": "Makes a quantitative/coverage claim about the literature without citing evidence or surveys to support it.",
        "start": 216,
        "end": 268
      },
      {
        "span_text": "Recent works are usually built with neural network.",
        "gpt_label": "Unsupported Claim",
        "reason": "References 'recent works' and makes a generalization without providing citations to back the claim.",
        "start": 415,
        "end": 465
      },
      {
        "span_text": "Our work differs from existing works in that we are the first one to exploit GPT and verify the pros and cons of GPT in different situations.",
        "gpt_label": "Unsupported Claim",
        "reason": "Claims novelty ('first') without evidence or citations demonstrating no prior work has done this.",
        "start": 955,
        "end": 1095
      },
      {
        "span_text": "since an important type of error is caused by characters pronounced with the same pinyin.",
        "gpt_label": "Unsupported Claim",
        "reason": "Asserts a domain-specific fact about error distributions in Chinese GEC without citation.",
        "start": 1974,
        "end": 2062
      },
      {
        "span_text": "Zhang et al. (2021a)",
        "gpt_label": "Format",
        "reason": "Year suffix 'a' is used without any other 2021 work by the same authors cited in the passage, making the disambiguation suffix unnecessary and inconsistent with citation style.",
        "start": 2063,
        "end": 2082
      },
      {
        "span_text": "Our work differs from existing works in that we are the first one to exploit GPT and verify the pros and cons of GPT in different situations. In addition, there are some works handling\npinyin with typing errors.",
        "gpt_label": "Coherence",
        "reason": "Abrupt transition from a claim about the authors’ own contribution (GPT) to a new category of related work (error-tolerant input) without explaining the connection; the relationship between these sentences is implied but not explicitly stated.",
        "start": 955,
        "end": 1164
      },
      {
        "span_text": "Our methodology also relates to pretrained models that use pinyin information. Sun et al. (2021) propose a general-purpose Chinese BERT with\nnew embedding layers to inject pinyin and glyph information of characters. There are also task-specific BERT models, especially for the task of grammatical error correction since an important type of error is caused by characters pronounced with the same pinyin. Zhang et al. (2021a) add a pinyin embedding layer and learns to predict characters from similarly pronounced candidates. PLOME (Liu et al., 2021) add two embedding layers implemented with two GRU networks to inject both pinyin and shape of characters, respectively. Xu et al. (2021) add a hierarchical encoder to inject the pinyin letters at character and sentence levels, and add a ResNet encoder to use graphic features of character image.",
        "gpt_label": "Lacks synthesis",
        "reason": "Primarily lists prior works without connecting them to the authors’ approach, articulating a specific gap, or providing the authors’ perspective; the paragraph offers no synthesis beyond stating that their methodology 'relates' to these models.",
        "start": 1663,
        "end": 2498
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "A majority of existing works focus on perfect pinyin.",
          "gpt_label": "Unsupported Claim",
          "reason": "Makes a quantitative/coverage claim about the literature without citing evidence or surveys to support it.",
          "start": 216,
          "end": 268
        },
        {
          "span_text": "Recent works are usually built with neural network.",
          "gpt_label": "Unsupported Claim",
          "reason": "References 'recent works' and makes a generalization without providing citations to back the claim.",
          "start": 415,
          "end": 465
        },
        {
          "span_text": "Our work differs from existing works in that we are the first one to exploit GPT and verify the pros and cons of GPT in different situations.",
          "gpt_label": "Unsupported Claim",
          "reason": "Claims novelty ('first') without evidence or citations demonstrating no prior work has done this.",
          "start": 955,
          "end": 1095
        },
        {
          "span_text": "since an important type of error is caused by characters pronounced with the same pinyin.",
          "gpt_label": "Unsupported Claim",
          "reason": "Asserts a domain-specific fact about error distributions in Chinese GEC without citation.",
          "start": 1974,
          "end": 2062
        }
      ],
      "Format": [
        {
          "span_text": "Zhang et al. (2021a)",
          "gpt_label": "Format",
          "reason": "Year suffix 'a' is used without any other 2021 work by the same authors cited in the passage, making the disambiguation suffix unnecessary and inconsistent with citation style.",
          "start": 2063,
          "end": 2082
        }
      ],
      "Coherence": [
        {
          "span_text": "Our work differs from existing works in that we are the first one to exploit GPT and verify the pros and cons of GPT in different situations. In addition, there are some works handling\npinyin with typing errors.",
          "gpt_label": "Coherence",
          "reason": "Abrupt transition from a claim about the authors’ own contribution (GPT) to a new category of related work (error-tolerant input) without explaining the connection; the relationship between these sentences is implied but not explicitly stated.",
          "start": 955,
          "end": 1164
        }
      ],
      "Lacks synthesis": [
        {
          "span_text": "Our methodology also relates to pretrained models that use pinyin information. Sun et al. (2021) propose a general-purpose Chinese BERT with\nnew embedding layers to inject pinyin and glyph information of characters. There are also task-specific BERT models, especially for the task of grammatical error correction since an important type of error is caused by characters pronounced with the same pinyin. Zhang et al. (2021a) add a pinyin embedding layer and learns to predict characters from similarly pronounced candidates. PLOME (Liu et al., 2021) add two embedding layers implemented with two GRU networks to inject both pinyin and shape of characters, respectively. Xu et al. (2021) add a hierarchical encoder to inject the pinyin letters at character and sentence levels, and add a ResNet encoder to use graphic features of character image.",
          "gpt_label": "Lacks synthesis",
          "reason": "Primarily lists prior works without connecting them to the authors’ approach, articulating a specific gap, or providing the authors’ perspective; the paragraph offers no synthesis beyond stating that their methodology 'relates' to these models.",
          "start": 1663,
          "end": 2498
        }
      ]
    }
  },
  "paper_1.txt": {
    "filename": "paper_1.txt",
    "full_text": "Related Work\n\nLarge-scale pretrained language models have been shown to encode some knowledge implicitly through their pretraining objectives (Petroni et al., 2019a), including both commonsense (Shwartz et al., 2020) and factual knowledge (Petroni et al., 2019b). However, pretrained language models still struggle with some downstream applications, especially when the model needs to make inference based on context (Do and Pavlick, 2021;Kassner and Schütze, 2020). Thus, recent works have also explored enhancing pretrained models with external knowledge.\n\nIntroducing knowledge into language models has been shown to be successful on various downstream tasks and model architecture (Ren et al., 2020;Zhao et al., 2020;Song et al., 2019). For instance, Mao et al. (2019) generates story with multitasking learning on commonsense QA datasets. Zhao et al. (2020) used BERT as a knowledge selection module for dialogue generation. Chakrabarty et al. (2020) ranked knowledge generated from the COMET for sarcasm generation. Ji et al. (2020) do multi-hop with a graph convolutional network on ConceptNet. Similarly, our work uses external knowledge sources, but with several different settings to enhance text generation for counseling conversations.\n\nThere are various types of knowledge resources that can be used to enhance language models, focusing on different aspects. For example, large-scale commonsense knowledge graphs (CSKG) store structured commonsense knowledge in the form of knowledge triplets. The most widely used CSKG resources include Concept-Net (Speer et al., 2017), ATOMIC TransOMCS (Zhang et al., 2020). There are also medical related knowledge base such UMLS (Bodenreider, 2004) and OHAMA 1 . We use ConceptNet for commonsense and decide to collect a counseling knowledge base as the medical knowledge bases have a limited amount of knowledge align with our need.\n\n ",
    "all_spans": [
      {
        "span_text": "Thus, recent works have also explored enhancing pretrained models with external knowledge.",
        "gpt_label": "Unsupported Claim",
        "reason": "Mentions 'recent works' without providing citations in the sentence; such claims should be accompanied by references.",
        "start": 462,
        "end": 551
      },
      {
        "span_text": "The most widely used CSKG resources include Concept-Net (Speer et al., 2017), ATOMIC TransOMCS (Zhang et al., 2020).",
        "gpt_label": "Unsupported Claim",
        "reason": "Asserts 'most widely used' without evidence; citing the resources themselves does not substantiate their prevalence.",
        "start": 1486,
        "end": 1599
      },
      {
        "span_text": "BERT",
        "gpt_label": "Unsupported Claim",
        "reason": "First mention of a specific model should be cited (e.g., Devlin et al., 2019), but no citation is provided here.",
        "start": 855,
        "end": 859
      },
      {
        "span_text": "the COMET",
        "gpt_label": "Unsupported Claim",
        "reason": "First mention of a specific system/resource should include a citation to its original paper, which is missing.",
        "start": 973,
        "end": 982
      },
      {
        "span_text": "OHAMA 1",
        "gpt_label": "Unsupported Claim",
        "reason": "Mentions a specific knowledge base without an academic citation; first mentions of datasets/resources should be cited.",
        "start": 1680,
        "end": 1687
      },
      {
        "span_text": "as the medical knowledge bases have a limited amount of knowledge align with our need.",
        "gpt_label": "Unsupported Claim",
        "reason": "Claims a specific limitation of medical knowledge bases without evidence or citation.",
        "start": 1773,
        "end": 1858
      },
      {
        "span_text": "For instance, Mao et al. (2019) generates story with multitasking learning on commonsense QA datasets. Zhao et al. (2020) used BERT as a knowledge selection module for dialogue generation. Chakrabarty et al. (2020) ranked knowledge generated from the COMET for sarcasm generation. Ji et al. (2020) do multi-hop with a graph convolutional network on ConceptNet.",
        "gpt_label": "Coherence",
        "reason": "These sentences list disparate works across different tasks without explicit connections or transitions explaining how each relates to the others beyond being examples of using external knowledge; the relationships are implied rather than stated.",
        "start": 731,
        "end": 1083
      },
      {
        "span_text": "For instance, Mao et al. (2019) generates story with multitasking learning on commonsense QA datasets. Zhao et al. (2020) used BERT as a knowledge selection module for dialogue generation. Chakrabarty et al. (2020) ranked knowledge generated from the COMET for sarcasm generation. Ji et al. (2020) do multi-hop with a graph convolutional network on ConceptNet.",
        "gpt_label": "Lacks synthesis",
        "reason": "This sequence lists prior works as isolated examples without integrating them into a coherent narrative, explaining their relationships, or articulating a specific gap. It summarizes others’ contributions but does not connect them to the authors’ argument or clearly motivate how these works inform or fall short relative to the present study.",
        "start": 731,
        "end": 1083
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "Thus, recent works have also explored enhancing pretrained models with external knowledge.",
          "gpt_label": "Unsupported Claim",
          "reason": "Mentions 'recent works' without providing citations in the sentence; such claims should be accompanied by references.",
          "start": 462,
          "end": 551
        },
        {
          "span_text": "The most widely used CSKG resources include Concept-Net (Speer et al., 2017), ATOMIC TransOMCS (Zhang et al., 2020).",
          "gpt_label": "Unsupported Claim",
          "reason": "Asserts 'most widely used' without evidence; citing the resources themselves does not substantiate their prevalence.",
          "start": 1486,
          "end": 1599
        },
        {
          "span_text": "BERT",
          "gpt_label": "Unsupported Claim",
          "reason": "First mention of a specific model should be cited (e.g., Devlin et al., 2019), but no citation is provided here.",
          "start": 855,
          "end": 859
        },
        {
          "span_text": "the COMET",
          "gpt_label": "Unsupported Claim",
          "reason": "First mention of a specific system/resource should include a citation to its original paper, which is missing.",
          "start": 973,
          "end": 982
        },
        {
          "span_text": "OHAMA 1",
          "gpt_label": "Unsupported Claim",
          "reason": "Mentions a specific knowledge base without an academic citation; first mentions of datasets/resources should be cited.",
          "start": 1680,
          "end": 1687
        },
        {
          "span_text": "as the medical knowledge bases have a limited amount of knowledge align with our need.",
          "gpt_label": "Unsupported Claim",
          "reason": "Claims a specific limitation of medical knowledge bases without evidence or citation.",
          "start": 1773,
          "end": 1858
        }
      ],
      "Format": [],
      "Coherence": [
        {
          "span_text": "For instance, Mao et al. (2019) generates story with multitasking learning on commonsense QA datasets. Zhao et al. (2020) used BERT as a knowledge selection module for dialogue generation. Chakrabarty et al. (2020) ranked knowledge generated from the COMET for sarcasm generation. Ji et al. (2020) do multi-hop with a graph convolutional network on ConceptNet.",
          "gpt_label": "Coherence",
          "reason": "These sentences list disparate works across different tasks without explicit connections or transitions explaining how each relates to the others beyond being examples of using external knowledge; the relationships are implied rather than stated.",
          "start": 731,
          "end": 1083
        }
      ],
      "Lacks synthesis": [
        {
          "span_text": "For instance, Mao et al. (2019) generates story with multitasking learning on commonsense QA datasets. Zhao et al. (2020) used BERT as a knowledge selection module for dialogue generation. Chakrabarty et al. (2020) ranked knowledge generated from the COMET for sarcasm generation. Ji et al. (2020) do multi-hop with a graph convolutional network on ConceptNet.",
          "gpt_label": "Lacks synthesis",
          "reason": "This sequence lists prior works as isolated examples without integrating them into a coherent narrative, explaining their relationships, or articulating a specific gap. It summarizes others’ contributions but does not connect them to the authors’ argument or clearly motivate how these works inform or fall short relative to the present study.",
          "start": 731,
          "end": 1083
        }
      ]
    }
  },
  "paper_2.txt": {
    "filename": "paper_2.txt",
    "full_text": "Background\n\nHuman values are of concern to most if not to all social sciences (Rokeach, 1973) and have also been integrated into computational frameworks of argumentation (Bench-Capon, 2003). In NLP, values have been analyzed for personality profiling (Maheshwari et al., 2017), but not yet for argument mining, as considered here.\n\nValues in Social Science\n\nRokeach (1973) already described the two concepts of (1) a value as a belief pertaining to desirable end states or modes of conduct and (2) a value system as prioritization of values based on cultural, social, and personal factors. These definitions attribute values to persons rather than to objects, facilitating a systematic analysis (Rokeach, 1973). The paper at hand targets the personal values behind arguments, meaning the values in the former sense that the arguments, mostly implicitly, resort to.\n\nSeveral of the value schemes proposed in the literature pertain to specific purposes. England (1967) suggested 66 values related to management decisions, such as high productivity and prestige, and categorized them by relevant entity, for example business organizations and individuals. Brown and Crace (2002) looked at 14 values for counseling and therapy, such as responsibility and spirituality, and Kahle et al. (1988) at nine for consumer research, such as warm relationships and excitement.\n\nOther proposed value schemes are more generic. Combining research from anthropology, sociology, philosophy, and psychology, Rokeach (1973) estimates the total number of human values to be fewer than hundreds, and develops a practical survey of 36 values that distinguishes between values pertaining to desirable end states and desirable behavior. Specifically for cross-cultural analyses, Schwartz et al. ( 2012) derived 48 value questions from the universal needs of individuals and societies, including obeying all the laws and to be humble. Moreover, Schwartz (1994) proposes a relatedness of values by their tendency to be compatible in their pursuit (see Figure 1). This relatedness reflects two \"higher order\" conflicts: (1) openness to change/own thoughts vs. conservation/submission, and (2) self-transcension (directed towards others/the environment) vs. self-enhancing (directed towards one's self), allowing to analyse values at several levels. Cheng and Fleischmann (2010) consolidates 12 schemes into a \"meta-inventory\" with 16 values, such as honesty and justice, revealing a large overlap in schemes across fields of research. However, as the meta-inventory is strictly more coarse-grained than Schwartz et al.'s theory we do not investigate it further for this paper.\n\nValues in Argumentation Research\n\nFormal argumentation employs value systems to model audience-specific preferences, that is, an argument's strength depends on the degree to which the audience reveres the values the argument resorts to. Examples include value-based argumentation schemes (van der Weide et al., 2009), defeasible logic programming (Teze et al., 2019), and the value-based argumentation framework of Bench-Capon (2003). The latter is an extension of the abstract argumentation framework of Dung (1995) that has already been applied manually to analyze interactions with reasoning and persuasion subject to a specific value system (Atkinson and Bench-Capon, 2021). This paper present a first step towards the large-scale automatic application of these works as it takes values to argument mining. Feldman (2021) recently showed the strong connection between values and the moral foundation theory (Haidt, 2012). Like personal values, this theory analyzes ethical reasoning behind human choices, but considers five rather abstract \"foundations:\" care, fairness, loyalty, authority, and purity. Alshomary and Wachsmuth (2021) hypothesized that the foundations could be used for audiencespecific argument generation. Kobbe et al. (2020) tried to classify arguments by foundations, but noted a low human agreement due to the vagueness of the foundations. We assume values can here contribute to the classification by foundations.\n\nPartly, values overlap with ideas of framing in communication, that is, the selection and emphasis of specific aspects of (perceived) reality to promote a particular problem definition, causal interpretation, ethical evaluation, and/or recommendation (Entman, 1993). In frames, values can define the costs and benefits of options (Entman, 1993) whereas common value systems are used for evaluation. Frames have been studied computationally for news (Naderi and Hirst, 2015), political speech (De Vreese, 2005), and argumentation (Ajjour et al., 2019). In argumentation, some values are so prevalent that they constitute frames of their own, indicating a potential use of values in frame identification. For example, 14 of the 54 values we use in this work are also frames in the dataset of Ajjour et al. 1 Values may be considered as aspects under which to group arguments. Some researchers have mined aspects from text (Trautmann, 2020) or used them to control argument generation (Schiller et al., 2021). Others have studied the task of opinion summarization in arguments (Egan et al., 2016;Misra et al., 2016;Chen et al., 2019), aiming at the most important aspects discussed in a debate. Related, the task of key point analysis (Bar-Haim et al., 2020;Friedman et al., 2021) is to generate a small set of concise statements that each represent a different aspect. We argue that analyzing the values found in a collection of arguments provides a new perspective to aspects in argumentation, focusing on the \"why\" behind an argument's reasoning.\n\n ",
    "all_spans": [
      {
        "span_text": "but not yet for argument mining, as considered here.",
        "gpt_label": "Unsupported Claim",
        "reason": "Asserts absence of prior work on values in argument mining without citing surveys or studies to substantiate the novelty claim.",
        "start": 277,
        "end": 328
      },
      {
        "span_text": "This paper present a first step towards the large-scale automatic application of these works as it takes values to argument mining.",
        "gpt_label": "Unsupported Claim",
        "reason": "Claims precedence/novelty ('first step') regarding large-scale automatic application without evidence or citations comparing to prior work.",
        "start": 3303,
        "end": 3433
      },
      {
        "span_text": "In argumentation, some values are so prevalent that they constitute frames of their own, indicating a potential use of values in frame identification.",
        "gpt_label": "Unsupported Claim",
        "reason": "Asserts prevalence of certain values as frames without external evidence or citations; the subsequent example shows category overlap, not prevalence.",
        "start": 4606,
        "end": 4755
      },
      {
        "span_text": "whereas common value systems are used for evaluation.",
        "gpt_label": "Unsupported Claim",
        "reason": "Makes a general claim about evaluative use of value systems in framing without a supporting citation.",
        "start": 4402,
        "end": 4454
      },
      {
        "span_text": "Schwartz et al. ( 2012)",
        "gpt_label": "Format",
        "reason": "Extra space inside the parentheses; should be (2012).",
        "start": 1742,
        "end": 1764
      },
      {
        "span_text": "Ajjour et al. 1",
        "gpt_label": "Format",
        "reason": "Improper citation/footnote marker; missing standard author–year format or proper bracket/superscript.",
        "start": 4843,
        "end": 4857
      },
      {
        "span_text": "Frames have been studied computationally for news (Naderi and Hirst, 2015), political speech (De Vreese, 2005), and argumentation (Ajjour et al., 2019). In argumentation, some values are so prevalent that they constitute frames of their own, indicating a potential use of values in frame identification. For example, 14 of the 54 values we use in this work are also frames in the dataset of Ajjour et al. 1 Values may be considered as aspects under which to group arguments. Some researchers have mined aspects from text (Trautmann, 2020) or used them to control argument generation (Schiller et al., 2021).",
        "gpt_label": "Coherence",
        "reason": "The text shifts abruptly from framing literature to aspects without an explicit linkage explaining how frames relate to aspects. The relationship between the cited works on frames and those on aspect mining/generation is implied rather than stated, and the transition between these topics lacks connective explanation across multiple sentences.",
        "start": 4455,
        "end": 5055
      },
      {
        "span_text": "Several of the value schemes proposed in the literature pertain to specific purposes. England (1967) suggested 66 values related to management decisions, such as high productivity and prestige, and categorized them by relevant entity, for example business organizations and individuals. Brown and Crace (2002) looked at 14 values for counseling and therapy, such as responsibility and spirituality, and Kahle et al. (1988) at nine for consumer research, such as warm relationships and excitement.",
        "gpt_label": "Lacks synthesis",
        "reason": "This paragraph lists prior schemes and citations without connecting them to the paper’s argument or method, and it does not articulate why these schemes matter for the authors’ approach or what gap remains.",
        "start": 861,
        "end": 1353
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "but not yet for argument mining, as considered here.",
          "gpt_label": "Unsupported Claim",
          "reason": "Asserts absence of prior work on values in argument mining without citing surveys or studies to substantiate the novelty claim.",
          "start": 277,
          "end": 328
        },
        {
          "span_text": "This paper present a first step towards the large-scale automatic application of these works as it takes values to argument mining.",
          "gpt_label": "Unsupported Claim",
          "reason": "Claims precedence/novelty ('first step') regarding large-scale automatic application without evidence or citations comparing to prior work.",
          "start": 3303,
          "end": 3433
        },
        {
          "span_text": "In argumentation, some values are so prevalent that they constitute frames of their own, indicating a potential use of values in frame identification.",
          "gpt_label": "Unsupported Claim",
          "reason": "Asserts prevalence of certain values as frames without external evidence or citations; the subsequent example shows category overlap, not prevalence.",
          "start": 4606,
          "end": 4755
        },
        {
          "span_text": "whereas common value systems are used for evaluation.",
          "gpt_label": "Unsupported Claim",
          "reason": "Makes a general claim about evaluative use of value systems in framing without a supporting citation.",
          "start": 4402,
          "end": 4454
        }
      ],
      "Format": [
        {
          "span_text": "Schwartz et al. ( 2012)",
          "gpt_label": "Format",
          "reason": "Extra space inside the parentheses; should be (2012).",
          "start": 1742,
          "end": 1764
        },
        {
          "span_text": "Ajjour et al. 1",
          "gpt_label": "Format",
          "reason": "Improper citation/footnote marker; missing standard author–year format or proper bracket/superscript.",
          "start": 4843,
          "end": 4857
        }
      ],
      "Coherence": [
        {
          "span_text": "Frames have been studied computationally for news (Naderi and Hirst, 2015), political speech (De Vreese, 2005), and argumentation (Ajjour et al., 2019). In argumentation, some values are so prevalent that they constitute frames of their own, indicating a potential use of values in frame identification. For example, 14 of the 54 values we use in this work are also frames in the dataset of Ajjour et al. 1 Values may be considered as aspects under which to group arguments. Some researchers have mined aspects from text (Trautmann, 2020) or used them to control argument generation (Schiller et al., 2021).",
          "gpt_label": "Coherence",
          "reason": "The text shifts abruptly from framing literature to aspects without an explicit linkage explaining how frames relate to aspects. The relationship between the cited works on frames and those on aspect mining/generation is implied rather than stated, and the transition between these topics lacks connective explanation across multiple sentences.",
          "start": 4455,
          "end": 5055
        }
      ],
      "Lacks synthesis": [
        {
          "span_text": "Several of the value schemes proposed in the literature pertain to specific purposes. England (1967) suggested 66 values related to management decisions, such as high productivity and prestige, and categorized them by relevant entity, for example business organizations and individuals. Brown and Crace (2002) looked at 14 values for counseling and therapy, such as responsibility and spirituality, and Kahle et al. (1988) at nine for consumer research, such as warm relationships and excitement.",
          "gpt_label": "Lacks synthesis",
          "reason": "This paragraph lists prior schemes and citations without connecting them to the paper’s argument or method, and it does not articulate why these schemes matter for the authors’ approach or what gap remains.",
          "start": 861,
          "end": 1353
        }
      ]
    }
  },
  "paper_3.txt": {
    "filename": "paper_3.txt",
    "full_text": "Introduction\n\nStarting with ELMo (Peters et al., 2018) and BERT (Devlin et al., 2019), substantial work has shown that pre-trained models can significantly improve in various natural language processing (NLP) tasks (Radford et al., 2019; Lample and Conneau, 2019; Yang et al., 2019; Dong et al., 2019; Lewis et al., 2020). Following the pre-training techniques in NLP, self-supervised speech representation learning has also been investigated and shown promising results, benefiting from richly learned representations (Chung and Glass, 2018;Chuang et al., 2019;Song et al., 2019;Baevski et al., 2020;Hsu et al., 2021;Chung et al., 2021a), such as wav2vec 2.0 (Baevski et al., 2020) and HuBERT (Hsu et al., 2021).\n\nHowever, previous speech pre-training work suffers from two problems: (1) most of them learn the speech representation with only unlabeled speech data but ignore the importance of textual data to spoken language tasks (e.g., automatic speech recognition) which require the modality transformation; (2) most of these models solely rely on a pre-trained speech encoder for various downstream tasks, leaving the decoder not pre-trained for the sequence-to-sequence generation tasks. How to design a unified encoder-decoder model that can take advantage of both unlabeled speech and text data to improve various spoken language processing tasks is not well explored.\n\nInspired by the T5 method (Raffel et al., 2019), we attempt to formulate each spoken language processing task as a speech/text to speech/text problem via an encoder-decoder framework, which enables us to use the same pre-trained model with bimodal data across diverse tasks, as shown in Figure 1. To achieve this, we propose a unified-modal pre-training framework, SpeechT5, containing an encoder-decoder backbone network and modal-specific pre/post-nets. With the pre-nets, the input speech/text is embedded in a shared space, and the encoder-decoder backbone network models the sequence-to-sequence conversion, from which the model-specific post-nets generate the speech/text output. Particularly, SpeechT5 is mainly pre-trained with a denoising sequence-tosequence method by leveraging large-scale unlabeled text and speech corpus. To align the textual and acoustic information into a unified semantic space, the proposed SpeechT5 model ( 1) maps text and speech representations into a shared vector quantization space, and (2) randomly mixes up the quantized latent representations and the contextual states, which can better guide the quantizer to learn the cross-modal features.\n\nWe fine-tune SpeechT5 on a wide variety of downstream spoken language processing tasks, including automatic speech recognition (ASR), textto-speech (TTS), speech translation (ST), voice conversion (VC), speech enhancement (SE), and speaker identification (SID). Massive experiments show that the proposed SpeechT5 model achieves a significant improvement on these spoken language processing tasks compared with the state-of-theart baselines. Specifically, the proposed SpeechT5 outperforms wav2vec 2.0 (Baevski et al., 2020) and HuBERT (Hsu et al., 2021) with the BASE model on the ASR task and also performs better than the state-of-the-art voice Transformer network  on the VC task. Besides, SpeechT5 is significantly superior to SpeechNet (Chen et al., 2021b) and pre-trained models from SUPERB (Yang et al., 2021) and achieves the stateof-the-art performance (i.e., 96.49%) on the SID task. We further provide an empirical comparison of the pre-training tasks and modules, and the ablation study demonstrates the effectiveness of the proposed joint speech-text pre-training method.\n\nThe contributions of this paper are summarized as follows.\n\n• To the best of our knowledge, this is the first work to investigate a unified encoder-decoder framework for various spoken language processing tasks.\n\n• We propose a cross-modal vector quantization approach, which learns the implicit alignment between acoustic and textual represen-tation with large-scale unlabeled speech and text data.\n\n• Extensive experiments on spoken language processing tasks demonstrate the effectiveness and superiority of the proposed SpeechT5 model.\n\n ",
    "all_spans": [
      {
        "span_text": "(1) most of them learn the speech representation with only unlabeled speech data but ignore the importance of textual data to spoken language tasks (e.g., automatic speech recognition) which require the modality transformation;",
        "gpt_label": "Unsupported Claim",
        "reason": "Broad claim about prior work’s limitations (“most of them”) requires citations to representative studies.",
        "start": 769,
        "end": 994
      },
      {
        "span_text": "(2) most of these models solely rely on a pre-trained speech encoder for various downstream tasks, leaving the decoder not pre-trained for the sequence-to-sequence generation tasks.",
        "gpt_label": "Unsupported Claim",
        "reason": "General assertion about the common practice in prior work lacks supporting citations.",
        "start": 995,
        "end": 1175
      },
      {
        "span_text": "How to design a unified encoder-decoder model that can take advantage of both unlabeled speech and text data to improve various spoken language processing tasks is not well explored.",
        "gpt_label": "Unsupported Claim",
        "reason": "Claim about the state of the literature (“not well explored”) needs evidence or references.",
        "start": 1176,
        "end": 1357
      },
      {
        "span_text": "and also performs better than the state-of-the-art voice Transformer network  on the VC task.",
        "gpt_label": "Unsupported Claim",
        "reason": "First mention of a specific prior model (“state-of-the-art voice Transformer network”) lacks a citation.",
        "start": 3125,
        "end": 3217
      },
      {
        "span_text": "To the best of our knowledge, this is the first work to investigate a unified encoder-decoder framework for various spoken language processing tasks.",
        "gpt_label": "Unsupported Claim",
        "reason": "Novelty claim about prior work should be substantiated or supported by references/survey evidence.",
        "start": 3674,
        "end": 3822
      },
      {
        "span_text": "Specifically, the proposed SpeechT5 outperforms wav2vec 2.0 (Baevski et al., 2020) and HuBERT (Hsu et al., 2021) with the BASE model on the ASR task and also performs better than the state-of-the-art voice Transformer network  on the VC task. Besides, SpeechT5 is significantly superior to SpeechNet (Chen et al., 2021b) and pre-trained models from SUPERB (Yang et al., 2021) and achieves the stateof-the-art performance (i.e., 96.49%) on the SID task.",
        "gpt_label": "Coherence",
        "reason": "These consecutive sentences abruptly switch across tasks and baselines (ASR, VC, SID) and list disparate cited works without explicitly explaining how they relate to each other or why they are grouped, relying on implied connections and minimal transition ('Besides').",
        "start": 2979,
        "end": 3421
      },
      {
        "span_text": "Starting with ELMo (Peters et al., 2018) and BERT (Devlin et al., 2019), substantial work has shown that pre-trained models can significantly improve in various natural language processing (NLP) tasks (Radford et al., 2019; Lample and Conneau, 2019; Yang et al., 2019; Dong et al., 2019; Lewis et al., 2020). Following the pre-training techniques in NLP, self-supervised speech representation learning has also been investigated and shown promising results, benefiting from richly learned representations (Chung and Glass, 2018;Chuang et al., 2019;Song et al., 2019;Baevski et al., 2020;Hsu et al., 2021;Chung et al., 2021a), such as wav2vec 2.0 (Baevski et al., 2020) and HuBERT (Hsu et al., 2021).",
        "gpt_label": "Lacks synthesis",
        "reason": "This paragraph enumerates prior NLP and speech pre-training works and their successes without explicitly connecting them to the paper’s own research question or articulating the specific gap or motivation, which only appears in the following paragraph.",
        "start": 14,
        "end": 697
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "(1) most of them learn the speech representation with only unlabeled speech data but ignore the importance of textual data to spoken language tasks (e.g., automatic speech recognition) which require the modality transformation;",
          "gpt_label": "Unsupported Claim",
          "reason": "Broad claim about prior work’s limitations (“most of them”) requires citations to representative studies.",
          "start": 769,
          "end": 994
        },
        {
          "span_text": "(2) most of these models solely rely on a pre-trained speech encoder for various downstream tasks, leaving the decoder not pre-trained for the sequence-to-sequence generation tasks.",
          "gpt_label": "Unsupported Claim",
          "reason": "General assertion about the common practice in prior work lacks supporting citations.",
          "start": 995,
          "end": 1175
        },
        {
          "span_text": "How to design a unified encoder-decoder model that can take advantage of both unlabeled speech and text data to improve various spoken language processing tasks is not well explored.",
          "gpt_label": "Unsupported Claim",
          "reason": "Claim about the state of the literature (“not well explored”) needs evidence or references.",
          "start": 1176,
          "end": 1357
        },
        {
          "span_text": "and also performs better than the state-of-the-art voice Transformer network  on the VC task.",
          "gpt_label": "Unsupported Claim",
          "reason": "First mention of a specific prior model (“state-of-the-art voice Transformer network”) lacks a citation.",
          "start": 3125,
          "end": 3217
        },
        {
          "span_text": "To the best of our knowledge, this is the first work to investigate a unified encoder-decoder framework for various spoken language processing tasks.",
          "gpt_label": "Unsupported Claim",
          "reason": "Novelty claim about prior work should be substantiated or supported by references/survey evidence.",
          "start": 3674,
          "end": 3822
        }
      ],
      "Format": [],
      "Coherence": [
        {
          "span_text": "Specifically, the proposed SpeechT5 outperforms wav2vec 2.0 (Baevski et al., 2020) and HuBERT (Hsu et al., 2021) with the BASE model on the ASR task and also performs better than the state-of-the-art voice Transformer network  on the VC task. Besides, SpeechT5 is significantly superior to SpeechNet (Chen et al., 2021b) and pre-trained models from SUPERB (Yang et al., 2021) and achieves the stateof-the-art performance (i.e., 96.49%) on the SID task.",
          "gpt_label": "Coherence",
          "reason": "These consecutive sentences abruptly switch across tasks and baselines (ASR, VC, SID) and list disparate cited works without explicitly explaining how they relate to each other or why they are grouped, relying on implied connections and minimal transition ('Besides').",
          "start": 2979,
          "end": 3421
        }
      ],
      "Lacks synthesis": [
        {
          "span_text": "Starting with ELMo (Peters et al., 2018) and BERT (Devlin et al., 2019), substantial work has shown that pre-trained models can significantly improve in various natural language processing (NLP) tasks (Radford et al., 2019; Lample and Conneau, 2019; Yang et al., 2019; Dong et al., 2019; Lewis et al., 2020). Following the pre-training techniques in NLP, self-supervised speech representation learning has also been investigated and shown promising results, benefiting from richly learned representations (Chung and Glass, 2018;Chuang et al., 2019;Song et al., 2019;Baevski et al., 2020;Hsu et al., 2021;Chung et al., 2021a), such as wav2vec 2.0 (Baevski et al., 2020) and HuBERT (Hsu et al., 2021).",
          "gpt_label": "Lacks synthesis",
          "reason": "This paragraph enumerates prior NLP and speech pre-training works and their successes without explicitly connecting them to the paper’s own research question or articulating the specific gap or motivation, which only appears in the following paragraph.",
          "start": 14,
          "end": 697
        }
      ]
    }
  },
  "paper_4.txt": {
    "filename": "paper_4.txt",
    "full_text": "Problems in Past Evaluations\n\nA common issue occurs that can potentially impact the validity of results is filtering the set of systems to be evaluated via automatic metric scores. Since metric scores are known to be a poor substitute for human assessment, this only results in the pos-sibility that the best system according to human judges is inadvertently filtered out at this stage. For example, ConvAI2 (Dinan et al., 2019) ranked models firstly using automatic metrics before top models according to metric scores were assessed by crowd-sourced workers on Mechanical Turk, while similarly in the sixth Dialog System Technology Challenge (DSTC6) systems were filtered according to metric scores prior to human evaluation.\n\nIn terms of the live evaluation, competitions such as Convai2 report such evaluations as highly challenging, with many of the resulting dialogues reported to be senseless, offensive, or simply not in line with instructions and ultimately live evaluation results have been discarded.\n\nDespite challenges, competitions that operate in the public domain, making data and evaluation techniques available to researchers (such as ourselves) should be applauded for such efforts.\n\nOn the other hand, competitions that (for one reason or another) do not release data and evaluation techniques into the public domain have reported relative success in terms of human evaluation. However until such methods can be accessed and independently verified through replication studies, they will unfortunately have little impact . The first Amazon Alexa Socialbot Grand Challenge required human assessors to score how coherent and engaging conversations were on a 1-5 rating scale by two distinct groups: volunteer Amazon employees (experts), and general Alexa users (crowds) (Ram et al., 2018), are reported to achieve a correlation of overall scores for the two types of human assessors at 0.93. The absolute average rating across all chatbots was reported to be 20% lower for experts compared to general users. In an additional effort to evaluate models, conversational user experience, coherence, engagement, domain coverage, topical diversity, and conversational depth were assessed (1-5 scale), with combined scores reported to correlate with those of general users at r = 0.66. In addition to methods and data not being publicly available, correlations are difficult to interpret since no detail is provided about the number of judgments on which the correlation is calculated for example.\n\nIn addition to competitions that generally aim to include human evaluation of systems, automatic metrics are often proposed for dialogue evaluation, themselves requiring a human evaluation data set on which to evaluate the proposed metric. How-ever, inappropriate statistics are often applied. For example, Pang et al. (2020) propose a holistic metric to automatically evaluate four distinct aspects of dialogue, and a human evaluation experiment is deployed on Mechanical Turk using a 1-5 rating scale. The mean correlation between human assessors is reported as r = 0.61. However, mean correlations are unfortunately difficult to interpret, since correlation coefficients are not additive , averages calculated in the usual way cannot be assumed to reflect central tendency, and unfortunately, the distribution of correlations is not reported (Alexander, 1990). Mehri and Eskenazi (2020b) propose USR (Un-Supervised and Reference-free), an unsupervised model that predicts the quality of dialog for a range of criteria using various rating scales: understandable (0-1 rating scale), natural (1-3), maintains context (1-3), interesting (1-3), uses knowledge (0-1); overall quality (1-5). Despite human evaluation being carried out by experts inter-annotator agreement levels varied depending on criteria being measured, ranging from as low as 0.298. Additionally, although correlations between human assessments are reported as significant at p < 0.01, despite such statistics often being reported for correlations, they are unfortunately not very meaningful in terms of their impact on correlation interpretation and can be somewhat misleading. Contrary to common expectations, even small effect sizes (low r) can produce very low p-values (strong significance) in such tests. Aiming to achieve a significant correlation is an extremely low bar to reach in terms of consistency, since a low p-value in this case simply rejects the null hypothesis that the correlation is zero.\n\nIn addition to the above issues, human evaluation of dialogue systems rarely take into account the fact that differences in performance can occur simply by chance. The method of human evaluation we propose provides a means of applying standard tests for statistical significance to avoid concluding differences that are highly likely to have occurred simply by chance.\n\n ",
    "all_spans": [
      {
        "span_text": "Since metric scores are known to be a poor substitute for human assessment,",
        "gpt_label": "Unsupported Claim",
        "reason": "Field-specific assertion about the reliability of automatic metrics versus human assessment lacks citations to supporting studies.",
        "start": 180,
        "end": 255
      },
      {
        "span_text": "while similarly in the sixth Dialog System Technology Challenge (DSTC6) systems were filtered according to metric scores prior to human evaluation.",
        "gpt_label": "Unsupported Claim",
        "reason": "First mention of DSTC6 should include a citation to the relevant shared task/overview paper.",
        "start": 576,
        "end": 722
      },
      {
        "span_text": "with many of the resulting dialogues reported to be senseless, offensive, or simply not in line with instructions and ultimately live evaluation results have been discarded.",
        "gpt_label": "Unsupported Claim",
        "reason": "Specific claims about evaluation outcomes for a competition require a citation to the source reporting these findings.",
        "start": 833,
        "end": 1005
      },
      {
        "span_text": "competitions that (for one reason or another) do not release data and evaluation techniques into the public domain have reported relative success in terms of human evaluation.",
        "gpt_label": "Unsupported Claim",
        "reason": "General claim about outcomes of non-public competitions needs citations to concrete examples or studies.",
        "start": 1215,
        "end": 1389
      },
      {
        "span_text": "How-ever, inappropriate statistics are often applied.",
        "gpt_label": "Unsupported Claim",
        "reason": "Frequency-based generalization about the literature requires supporting references beyond subsequent examples.",
        "start": 2732,
        "end": 2784
      },
      {
        "span_text": "Contrary to common expectations, even small effect sizes (low r) can produce very low p-values (strong significance) in such tests.",
        "gpt_label": "Unsupported Claim",
        "reason": "General statistical claim should be supported with a citation to statistical methodology literature.",
        "start": 4128,
        "end": 4258
      },
      {
        "span_text": "In addition to the above issues, human evaluation of dialogue systems rarely take into account the fact that differences in performance can occur simply by chance.",
        "gpt_label": "Unsupported Claim",
        "reason": "Frequency claim about common practice in the field requires evidence or citations to surveys or audits.",
        "start": 4459,
        "end": 4621
      },
      {
        "span_text": "Mehri and Eskenazi (2020b)",
        "gpt_label": "Format",
        "reason": "Uses a year suffix ('b') without any corresponding '2020a' citation in the passage, which is inconsistent with disambiguation conventions and thus a citation formatting issue.",
        "start": 3350,
        "end": 3376
      },
      {
        "span_text": "However until such methods can be accessed and independently verified through replication studies, they will unfortunately have little impact . The first Amazon Alexa Socialbot Grand Challenge required human assessors to score how coherent and engaging conversations were on a 1-5 rating scale by two distinct groups: volunteer Amazon employees (experts), and general Alexa users (crowds) (Ram et al., 2018), are reported to achieve a correlation of overall scores for the two types of human assessors at 0.93. The absolute average rating across all chatbots was reported to be 20% lower for experts compared to general users. In an additional effort to evaluate models, conversational user experience, coherence, engagement, domain coverage, topical diversity, and conversational depth were assessed (1-5 scale), with combined scores reported to correlate with those of general users at r = 0.66. In addition to methods and data not being publicly available, correlations are difficult to interpret since no detail is provided about the number of judgments on which the correlation is calculated for example.",
        "gpt_label": "Coherence",
        "reason": "The transition from a general point about non-public competitions to the specific Alexa challenge is implied but not made explicit, creating an abrupt shift. Later, the critique that “correlations are difficult to interpret” does not clearly specify whether it refers to the 0.93 or 0.66 correlation mentioned in the preceding sentences, leaving the relationship between these sentences unclear.",
        "start": 1390,
        "end": 2491
      },
      {
        "span_text": "The first Amazon Alexa Socialbot Grand Challenge required human assessors to score how coherent and engaging conversations were on a 1-5 rating scale by two distinct groups: volunteer Amazon employees (experts), and general Alexa users (crowds) (Ram et al., 2018), are reported to achieve a correlation of overall scores for the two types of human assessors at 0.93. The absolute average rating across all chatbots was reported to be 20% lower for experts compared to general users. In an additional effort to evaluate models, conversational user experience, coherence, engagement, domain coverage, topical diversity, and conversational depth were assessed (1-5 scale), with combined scores reported to correlate with those of general users at r = 0.66.",
        "gpt_label": "Lacks synthesis",
        "reason": "This segment recounts evaluation procedures and results from a prior competition without explicitly linking these details to the authors’ argument or contribution; the critique and gap (replicability, interpretability) only follow afterward, leaving this block as descriptive rather than synthesized.",
        "start": 1533,
        "end": 2280
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "Since metric scores are known to be a poor substitute for human assessment,",
          "gpt_label": "Unsupported Claim",
          "reason": "Field-specific assertion about the reliability of automatic metrics versus human assessment lacks citations to supporting studies.",
          "start": 180,
          "end": 255
        },
        {
          "span_text": "while similarly in the sixth Dialog System Technology Challenge (DSTC6) systems were filtered according to metric scores prior to human evaluation.",
          "gpt_label": "Unsupported Claim",
          "reason": "First mention of DSTC6 should include a citation to the relevant shared task/overview paper.",
          "start": 576,
          "end": 722
        },
        {
          "span_text": "with many of the resulting dialogues reported to be senseless, offensive, or simply not in line with instructions and ultimately live evaluation results have been discarded.",
          "gpt_label": "Unsupported Claim",
          "reason": "Specific claims about evaluation outcomes for a competition require a citation to the source reporting these findings.",
          "start": 833,
          "end": 1005
        },
        {
          "span_text": "competitions that (for one reason or another) do not release data and evaluation techniques into the public domain have reported relative success in terms of human evaluation.",
          "gpt_label": "Unsupported Claim",
          "reason": "General claim about outcomes of non-public competitions needs citations to concrete examples or studies.",
          "start": 1215,
          "end": 1389
        },
        {
          "span_text": "How-ever, inappropriate statistics are often applied.",
          "gpt_label": "Unsupported Claim",
          "reason": "Frequency-based generalization about the literature requires supporting references beyond subsequent examples.",
          "start": 2732,
          "end": 2784
        },
        {
          "span_text": "Contrary to common expectations, even small effect sizes (low r) can produce very low p-values (strong significance) in such tests.",
          "gpt_label": "Unsupported Claim",
          "reason": "General statistical claim should be supported with a citation to statistical methodology literature.",
          "start": 4128,
          "end": 4258
        },
        {
          "span_text": "In addition to the above issues, human evaluation of dialogue systems rarely take into account the fact that differences in performance can occur simply by chance.",
          "gpt_label": "Unsupported Claim",
          "reason": "Frequency claim about common practice in the field requires evidence or citations to surveys or audits.",
          "start": 4459,
          "end": 4621
        }
      ],
      "Format": [
        {
          "span_text": "Mehri and Eskenazi (2020b)",
          "gpt_label": "Format",
          "reason": "Uses a year suffix ('b') without any corresponding '2020a' citation in the passage, which is inconsistent with disambiguation conventions and thus a citation formatting issue.",
          "start": 3350,
          "end": 3376
        }
      ],
      "Coherence": [
        {
          "span_text": "However until such methods can be accessed and independently verified through replication studies, they will unfortunately have little impact . The first Amazon Alexa Socialbot Grand Challenge required human assessors to score how coherent and engaging conversations were on a 1-5 rating scale by two distinct groups: volunteer Amazon employees (experts), and general Alexa users (crowds) (Ram et al., 2018), are reported to achieve a correlation of overall scores for the two types of human assessors at 0.93. The absolute average rating across all chatbots was reported to be 20% lower for experts compared to general users. In an additional effort to evaluate models, conversational user experience, coherence, engagement, domain coverage, topical diversity, and conversational depth were assessed (1-5 scale), with combined scores reported to correlate with those of general users at r = 0.66. In addition to methods and data not being publicly available, correlations are difficult to interpret since no detail is provided about the number of judgments on which the correlation is calculated for example.",
          "gpt_label": "Coherence",
          "reason": "The transition from a general point about non-public competitions to the specific Alexa challenge is implied but not made explicit, creating an abrupt shift. Later, the critique that “correlations are difficult to interpret” does not clearly specify whether it refers to the 0.93 or 0.66 correlation mentioned in the preceding sentences, leaving the relationship between these sentences unclear.",
          "start": 1390,
          "end": 2491
        }
      ],
      "Lacks synthesis": [
        {
          "span_text": "The first Amazon Alexa Socialbot Grand Challenge required human assessors to score how coherent and engaging conversations were on a 1-5 rating scale by two distinct groups: volunteer Amazon employees (experts), and general Alexa users (crowds) (Ram et al., 2018), are reported to achieve a correlation of overall scores for the two types of human assessors at 0.93. The absolute average rating across all chatbots was reported to be 20% lower for experts compared to general users. In an additional effort to evaluate models, conversational user experience, coherence, engagement, domain coverage, topical diversity, and conversational depth were assessed (1-5 scale), with combined scores reported to correlate with those of general users at r = 0.66.",
          "gpt_label": "Lacks synthesis",
          "reason": "This segment recounts evaluation procedures and results from a prior competition without explicitly linking these details to the authors’ argument or contribution; the critique and gap (replicability, interpretability) only follow afterward, leaving this block as descriptive rather than synthesized.",
          "start": 1533,
          "end": 2280
        }
      ]
    }
  },
  "paper_5.txt": {
    "filename": "paper_5.txt",
    "full_text": "Introduction\n\nThe usefulness of learned self-attention functions often correlates with how well it aligns with human attention (Das et al., 2016;Klerke et al., 2016;Barrett et al., 2018;Klerke and Plank, 2019). In this paper, we evaluate how well attention flow (Abnar and Zuidema, 2020) in large language models, namely BERT (Devlin et al., 2019), RoBERTa (Liu et al., 2019) and T5 (Raffel et al., 2020), aligns with human eye fixations during task-specific reading, compared to other shallow sequence labeling models (Lecun and Bengio, 1995;Vaswani et al., 2017) and a classic, heuristic model of human reading (Reichle et al., 2003). We compare the learned attention functions and the heuristic model across two task-specific English reading tasks, namely sentiment analysis (SST movie reviews) and relation extraction (Wikipedia), as well as natural reading, using a publicly available data set with eye-tracking recordings of native speakers of English (Hollenstein et al., 2018).\n\nContributions We compare human and model attention patterns on both sentiment reading and relation extraction tasks. In our analysis, we compare human attention to pre-trained Transformers (BERT, RoBERTa and T5), from-scratch training of two shallow sequence labeling architectures (Lecun and Bengio, 1995; Vaswani et al., 2017), as well as to a frequency baseline and a heuristic, cognitively inspired model of human reading called the E-Z Reader (Reichle et al., 2003). We find that the heuristic model correlates well with human reading, as has been reported in Sood et al. (2020b). However when we apply attention flow (Abnar and Zuidema, 2020), the pre-trained Transformer models also reach comparable levels of correlation strength. Further fine-tuning experiments on BERT did not result in increased correlation to human fixations. To understand what drives the differences between models, we perform an in-depth analysis of the effect of word predictability and POS tags on correlation strength. It reveals that Transformer models do not accurately capture tail phenomena for hard-to-predict words (in contrast to the E-Z Reader) and that Transformer attention flow shows comparably weak correlation on (proper) nouns while the E-Z Reader predicts importance of these more accurately, especially on the sentiment reading task. In addition we investigate a subset of the ZuCo corpus for which aligned task-specific and natural reading data is available and find that Transformers correlate stronger to natural reading patterns. But how faithful are these different attention patterns at producing correct task-classification on a state-of-the-art NLP model? We test this via an input reduction experiment on task-tuned BERT models which highlights the trade-off between a model’s faithfulness and sparsity when comparing importance scores to human attention, i.e., less sparse (higher entropy) attention vectors seem to be less faithful with respect to model predictions. Our code is available at github.com/anon.\n\n ",
    "all_spans": [
      {
        "span_text": "sentiment analysis (SST movie reviews)",
        "gpt_label": "Unsupported Claim",
        "reason": "First mention of a specific dataset (SST) should be accompanied by a citation to its original source.",
        "start": 749,
        "end": 787
      },
      {
        "span_text": "relation extraction (Wikipedia)",
        "gpt_label": "Unsupported Claim",
        "reason": "A dataset/source used for the relation extraction task is referenced without a specific dataset name or citation.",
        "start": 792,
        "end": 823
      },
      {
        "span_text": "a subset of the ZuCo corpus",
        "gpt_label": "Unsupported Claim",
        "reason": "First mention of the ZuCo dataset by name lacks a citation, even though it is a specific corpus that should be referenced.",
        "start": 2327,
        "end": 2354
      },
      {
        "span_text": "In addition we investigate a subset of the ZuCo corpus for which aligned task-specific and natural reading data is available and find that Transformers correlate stronger to natural reading patterns. But how faithful are these different attention patterns at producing correct task-classification on a state-of-the-art NLP model? We test this via an input reduction experiment on task-tuned BERT models which highlights the trade-off between a model’s faithfulness and sparsity when comparing importance scores to human attention, i.e., less sparse (higher entropy) attention vectors seem to be less faithful with respect to model predictions.",
        "gpt_label": "Coherence",
        "reason": "The transition from reporting correlation results on a ZuCo subset to questioning and testing faithfulness via input reduction is abrupt. The relationship between the dataset-specific finding and the subsequent faithfulness experiment is only implied, without an explicit linkage or rationale connecting these steps.",
        "start": 2300,
        "end": 2939
      },
      {
        "span_text": "The usefulness of learned self-attention functions often correlates with how well it aligns with human attention (Das et al., 2016;Klerke et al., 2016;Barrett et al., 2018;Klerke and Plank, 2019).",
        "gpt_label": "Lacks synthesis",
        "reason": "This sentence cites prior work but does not explicitly articulate the authors’ perspective or the specific gap their study addresses, presenting literature without synthesizing it into a clear motivation or argument.",
        "start": 14,
        "end": 206
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "sentiment analysis (SST movie reviews)",
          "gpt_label": "Unsupported Claim",
          "reason": "First mention of a specific dataset (SST) should be accompanied by a citation to its original source.",
          "start": 749,
          "end": 787
        },
        {
          "span_text": "relation extraction (Wikipedia)",
          "gpt_label": "Unsupported Claim",
          "reason": "A dataset/source used for the relation extraction task is referenced without a specific dataset name or citation.",
          "start": 792,
          "end": 823
        },
        {
          "span_text": "a subset of the ZuCo corpus",
          "gpt_label": "Unsupported Claim",
          "reason": "First mention of the ZuCo dataset by name lacks a citation, even though it is a specific corpus that should be referenced.",
          "start": 2327,
          "end": 2354
        }
      ],
      "Format": [],
      "Coherence": [
        {
          "span_text": "In addition we investigate a subset of the ZuCo corpus for which aligned task-specific and natural reading data is available and find that Transformers correlate stronger to natural reading patterns. But how faithful are these different attention patterns at producing correct task-classification on a state-of-the-art NLP model? We test this via an input reduction experiment on task-tuned BERT models which highlights the trade-off between a model’s faithfulness and sparsity when comparing importance scores to human attention, i.e., less sparse (higher entropy) attention vectors seem to be less faithful with respect to model predictions.",
          "gpt_label": "Coherence",
          "reason": "The transition from reporting correlation results on a ZuCo subset to questioning and testing faithfulness via input reduction is abrupt. The relationship between the dataset-specific finding and the subsequent faithfulness experiment is only implied, without an explicit linkage or rationale connecting these steps.",
          "start": 2300,
          "end": 2939
        }
      ],
      "Lacks synthesis": [
        {
          "span_text": "The usefulness of learned self-attention functions often correlates with how well it aligns with human attention (Das et al., 2016;Klerke et al., 2016;Barrett et al., 2018;Klerke and Plank, 2019).",
          "gpt_label": "Lacks synthesis",
          "reason": "This sentence cites prior work but does not explicitly articulate the authors’ perspective or the specific gap their study addresses, presenting literature without synthesizing it into a clear motivation or argument.",
          "start": 14,
          "end": 206
        }
      ]
    }
  },
  "paper_6.txt": {
    "filename": "paper_6.txt",
    "full_text": "Related Work\n\nZero-shot cross-lingual structured prediction. Zero-shot cross-lingual learning becomes an emerging research topic as it eliminates the requirement of labeled data for training models in low-resource languages. Various structured prediction tasks have be studied, including named entity recognition (Pan et al., 2017;Hu et al., 2020), dependency parsing (Ahmad et al., 2019, relation extraction (Zou et al., 2018;Ni and Florian, 2019), and event argument extraction (Subburathinam et al., 2019;Ahmad et al., 2021;Nguyen and Nguyen, 2021). Most of them are classification-based models that build classifiers on top of a multilingual pre-trained masked language models. To further deal with the discrepancy between languages, some of them require additional information, such as bilingual dictionaries (Liu et al., 2019; Ni and Florian, 2019), translation pairs (Zou et al., 2018), and dependency parse trees (Subburathinam et al., 2019;Ahmad et al., 2021;Nguyen and Nguyen, 2021). However, as pointed out by previous literature (Li et al., 2021;Hsu et al., 2021), classification-based models are less powerful to model dependencies between entities compared to generation-based models.\n\nGeneration-based structured prediction. Several works have demonstrated the great success of generation-based models on monolingual structured prediction tasks, including named entity recognition (Yan et al., 2021), relation extraction (Huang et al., 2021;Paolini et al., 2021), and event extraction (Du et al., 2021;Hsu et al., 2021;Lu et al., 2021). Yet, as mentioned in Section 1, their designed generating targets are language-dependent. Accordingly, directly applying their methods to the zero-shot cross-lingual setting would result in less-preferred performance.\n\nPrompting methods. There are growing interests recently to incorporate prompts on pre-trained language models in order to guide the models' behavior or elicit knowledge (Shin et al., 2020;Schick and Schütze, 2021;Qin and Eisner, 2021;Scao and Rush, 2021). Following the taxonomy in (Liu et al., 2021), these methods can be classified depending on whether the language models' parameters are tuned and on whether trainable prompts are introduced. Our method belongs to the category that fixes the prompts and tune the language models' parameters. Despite the flourish of the research in prompting methods, there is only limited attention being put on multilingual tasks (Winata et al., 2021).\n\n ",
    "all_spans": [
      {
        "span_text": "Zero-shot cross-lingual learning becomes an emerging research topic as it eliminates the requirement of labeled data for training models in low-resource languages.",
        "gpt_label": "Unsupported Claim",
        "reason": "Makes a trend and causal claim about the field without citing surveys or evidence to substantiate that it is an emerging topic or that it eliminates the need for labeled data.",
        "start": 60,
        "end": 222
      },
      {
        "span_text": "Most of them are classification-based models that build classifiers on top of a multilingual pre-trained masked language models.",
        "gpt_label": "Unsupported Claim",
        "reason": "Characterizes the majority of prior work without providing citations to support the generalization.",
        "start": 544,
        "end": 671
      },
      {
        "span_text": "Accordingly, directly applying their methods to the zero-shot cross-lingual setting would result in less-preferred performance.",
        "gpt_label": "Unsupported Claim",
        "reason": "Predicts comparative performance outcomes without empirical evidence or citations to support the assertion.",
        "start": 1615,
        "end": 1741
      },
      {
        "span_text": "(Ahmad et al., 2019",
        "gpt_label": "Format",
        "reason": "Missing closing parenthesis in citation.",
        "start": 364,
        "end": 382
      },
      {
        "span_text": "(Liu et al., 2021)",
        "gpt_label": "Format",
        "reason": "Nonstandard in-text citation style following a preposition; typically use narrative style (e.g., Liu et al. (2021)) or rephrase.",
        "start": 2022,
        "end": 2039
      },
      {
        "span_text": "Following the taxonomy in (Liu et al., 2021), these methods can be classified depending on whether the language models' parameters are tuned and on whether trainable prompts are introduced. Our method belongs to the category that fixes the prompts and tune the language models' parameters. Despite the flourish of the research in prompting methods, there is only limited attention being put on multilingual tasks (Winata et al., 2021).",
        "gpt_label": "Coherence",
        "reason": "The sequence jumps from a taxonomy of prompting methods to stating the authors’ chosen category, then abruptly to a citation about multilingual prompting without explicitly linking how the multilingual work relates to the taxonomy or to the authors’ approach. The relationship between these sentences and cited works is implied rather than stated, weakening coherence across the multiple sentences.",
        "start": 1996,
        "end": 2426
      },
      {
        "span_text": "Various structured prediction tasks have be studied, including named entity recognition (Pan et al., 2017;Hu et al., 2020), dependency parsing (Ahmad et al., 2019, relation extraction (Zou et al., 2018;Ni and Florian, 2019), and event argument extraction (Subburathinam et al., 2019;Ahmad et al., 2021;Nguyen and Nguyen, 2021).",
        "gpt_label": "Lacks synthesis",
        "reason": "This sentence lists prior works and tasks without connecting them to the authors’ approach, perspective, or a specific gap their work addresses.",
        "start": 223,
        "end": 543
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "Zero-shot cross-lingual learning becomes an emerging research topic as it eliminates the requirement of labeled data for training models in low-resource languages.",
          "gpt_label": "Unsupported Claim",
          "reason": "Makes a trend and causal claim about the field without citing surveys or evidence to substantiate that it is an emerging topic or that it eliminates the need for labeled data.",
          "start": 60,
          "end": 222
        },
        {
          "span_text": "Most of them are classification-based models that build classifiers on top of a multilingual pre-trained masked language models.",
          "gpt_label": "Unsupported Claim",
          "reason": "Characterizes the majority of prior work without providing citations to support the generalization.",
          "start": 544,
          "end": 671
        },
        {
          "span_text": "Accordingly, directly applying their methods to the zero-shot cross-lingual setting would result in less-preferred performance.",
          "gpt_label": "Unsupported Claim",
          "reason": "Predicts comparative performance outcomes without empirical evidence or citations to support the assertion.",
          "start": 1615,
          "end": 1741
        }
      ],
      "Format": [
        {
          "span_text": "(Ahmad et al., 2019",
          "gpt_label": "Format",
          "reason": "Missing closing parenthesis in citation.",
          "start": 364,
          "end": 382
        },
        {
          "span_text": "(Liu et al., 2021)",
          "gpt_label": "Format",
          "reason": "Nonstandard in-text citation style following a preposition; typically use narrative style (e.g., Liu et al. (2021)) or rephrase.",
          "start": 2022,
          "end": 2039
        }
      ],
      "Coherence": [
        {
          "span_text": "Following the taxonomy in (Liu et al., 2021), these methods can be classified depending on whether the language models' parameters are tuned and on whether trainable prompts are introduced. Our method belongs to the category that fixes the prompts and tune the language models' parameters. Despite the flourish of the research in prompting methods, there is only limited attention being put on multilingual tasks (Winata et al., 2021).",
          "gpt_label": "Coherence",
          "reason": "The sequence jumps from a taxonomy of prompting methods to stating the authors’ chosen category, then abruptly to a citation about multilingual prompting without explicitly linking how the multilingual work relates to the taxonomy or to the authors’ approach. The relationship between these sentences and cited works is implied rather than stated, weakening coherence across the multiple sentences.",
          "start": 1996,
          "end": 2426
        }
      ],
      "Lacks synthesis": [
        {
          "span_text": "Various structured prediction tasks have be studied, including named entity recognition (Pan et al., 2017;Hu et al., 2020), dependency parsing (Ahmad et al., 2019, relation extraction (Zou et al., 2018;Ni and Florian, 2019), and event argument extraction (Subburathinam et al., 2019;Ahmad et al., 2021;Nguyen and Nguyen, 2021).",
          "gpt_label": "Lacks synthesis",
          "reason": "This sentence lists prior works and tasks without connecting them to the authors’ approach, perspective, or a specific gap their work addresses.",
          "start": 223,
          "end": 543
        }
      ]
    }
  },
  "paper_7.txt": {
    "filename": "paper_7.txt",
    "full_text": "Related Work\n\nOpen-Domain Question Answering\n\nIn this era of data explosion, ODQA offers a way to rapidly and accurately fulfill user's information needs, and hence has recently received significant attention from both industry and academia (Min et al., 2021a). Following the work of DrQA (Chen et al., 2017), most recent works build a two-stage retriever-reader system to tackle the problem. The retriever aims at retrieving supportive passages to the given question from a large document corpus. The reader intends to find answer of the question from the first stage retrieved passages. Early work of Chen et al. (2017) adapts a BiLSTM architecture with various lexical and semantic features from the question and passages as inputs. Later, with the emergence of large-scale pre-trained language models, readers based on pre-trained models such as BERT and T5 Raffel et al., 2019) have become a common approach (Yang et al., 2019;Karpukhin et al., 2020;Izacard and Grave, 2020b).\n\nGenerative Readers\n\nCompared to extractive models which extract existing words from the retrieved passages, generative models are able to produce new words out of the retrieved passages, and thus provide a more flexible modeling framework.  and Lewis et al. (2020a) concatenate the given question with top retrieved passages and feed the concatenation to the BART model (Lewis et al., 2019). Izacard and Grave (2020b) separately encodes the question with each top retrieved passage, then takes the concatenation of the encoder outputs as input to the decoder. Their method provide a way to better aggregate evidence from multiple passages and improve the performance significantly. FiD-KD (Izacard and Grave, 2020a) is an extension of FiD model that increases the accuracy of passage retrieval by training the dense retriever with the guidance of the FiD reader iteratively.\n\nPointer-Generator Network\n\nPointer-Generator Network (See et al., 2017) is an extension of the sequence-to-sequence model by integrating a copy mechanism (Vinyals et al., 2017) into the generator. At each decoding stage, the model is able to either directly copy a word from the input or generate one with certain probability, and thus can be viewed as a combination of extractive and generative approaches. It has been frequently used in natural language tasks like summarization (Gu et al., 2016;See et al.,  Gehrmann et al., 2018) and neural machine translation (Luong et al., 2014;Gu et al., 2017), but its application to ODQA has been less explored.\n\n ",
    "all_spans": [
      {
        "span_text": "most recent works build a two-stage retriever-reader system to tackle the problem.",
        "gpt_label": "Unsupported Claim",
        "reason": "Claims a field-wide trend without providing supporting citations to representative recent works.",
        "start": 307,
        "end": 388
      },
      {
        "span_text": "BERT",
        "gpt_label": "Unsupported Claim",
        "reason": "First mention of a specific model lacks a citation to the original paper, which should be provided.",
        "start": 842,
        "end": 846
      },
      {
        "span_text": "its application to ODQA has been less explored.",
        "gpt_label": "Unsupported Claim",
        "reason": "Asserts limited prior work without evidence or citations (e.g., surveys or studies) to substantiate the claim.",
        "start": 2438,
        "end": 2484
      },
      {
        "span_text": "Raffel et al., 2019)",
        "gpt_label": "Format",
        "reason": "Missing opening parenthesis before the citation; it should be formatted as (Raffel et al., 2019) following 'T5'.",
        "start": 854,
        "end": 873
      },
      {
        "span_text": "Compared to extractive models which extract existing words from the retrieved passages, generative models are able to produce new words out of the retrieved passages, and thus provide a more flexible modeling framework.  and Lewis et al. (2020a) concatenate the given question with top retrieved passages and feed the concatenation to the BART model (Lewis et al., 2019).",
        "gpt_label": "Coherence",
        "reason": "The second sentence begins abruptly with 'and' and lacks an explicit transition or explanation connecting the general claim about generative models to the specific method by Lewis et al. The relationship between the two sentences is implied rather than stated, creating a coherence break across sentences.",
        "start": 991,
        "end": 1358
      },
      {
        "span_text": "and Lewis et al. (2020a) concatenate the given question with top retrieved passages and feed the concatenation to the BART model (Lewis et al., 2019). Izacard and Grave (2020b) separately encodes the question with each top retrieved passage, then takes the concatenation of the encoder outputs as input to the decoder. Their method provide a way to better aggregate evidence from multiple passages and improve the performance significantly. FiD-KD (Izacard and Grave, 2020a) is an extension of FiD model that increases the accuracy of passage retrieval by training the dense retriever with the guidance of the FiD reader iteratively.",
        "gpt_label": "Lacks synthesis",
        "reason": "This segment lists prior generative-reader approaches and their improvements but does not connect them to the authors’ own objectives, identify a specific gap these works leave unaddressed, or articulate the authors’ perspective on how their work relates to or differs from them.",
        "start": 1211,
        "end": 1838
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "most recent works build a two-stage retriever-reader system to tackle the problem.",
          "gpt_label": "Unsupported Claim",
          "reason": "Claims a field-wide trend without providing supporting citations to representative recent works.",
          "start": 307,
          "end": 388
        },
        {
          "span_text": "BERT",
          "gpt_label": "Unsupported Claim",
          "reason": "First mention of a specific model lacks a citation to the original paper, which should be provided.",
          "start": 842,
          "end": 846
        },
        {
          "span_text": "its application to ODQA has been less explored.",
          "gpt_label": "Unsupported Claim",
          "reason": "Asserts limited prior work without evidence or citations (e.g., surveys or studies) to substantiate the claim.",
          "start": 2438,
          "end": 2484
        }
      ],
      "Format": [
        {
          "span_text": "Raffel et al., 2019)",
          "gpt_label": "Format",
          "reason": "Missing opening parenthesis before the citation; it should be formatted as (Raffel et al., 2019) following 'T5'.",
          "start": 854,
          "end": 873
        }
      ],
      "Coherence": [
        {
          "span_text": "Compared to extractive models which extract existing words from the retrieved passages, generative models are able to produce new words out of the retrieved passages, and thus provide a more flexible modeling framework.  and Lewis et al. (2020a) concatenate the given question with top retrieved passages and feed the concatenation to the BART model (Lewis et al., 2019).",
          "gpt_label": "Coherence",
          "reason": "The second sentence begins abruptly with 'and' and lacks an explicit transition or explanation connecting the general claim about generative models to the specific method by Lewis et al. The relationship between the two sentences is implied rather than stated, creating a coherence break across sentences.",
          "start": 991,
          "end": 1358
        }
      ],
      "Lacks synthesis": [
        {
          "span_text": "and Lewis et al. (2020a) concatenate the given question with top retrieved passages and feed the concatenation to the BART model (Lewis et al., 2019). Izacard and Grave (2020b) separately encodes the question with each top retrieved passage, then takes the concatenation of the encoder outputs as input to the decoder. Their method provide a way to better aggregate evidence from multiple passages and improve the performance significantly. FiD-KD (Izacard and Grave, 2020a) is an extension of FiD model that increases the accuracy of passage retrieval by training the dense retriever with the guidance of the FiD reader iteratively.",
          "gpt_label": "Lacks synthesis",
          "reason": "This segment lists prior generative-reader approaches and their improvements but does not connect them to the authors’ own objectives, identify a specific gap these works leave unaddressed, or articulate the authors’ perspective on how their work relates to or differs from them.",
          "start": 1211,
          "end": 1838
        }
      ]
    }
  },
  "paper_8.txt": {
    "filename": "paper_8.txt",
    "full_text": "Introduction\n\nEarly exiting is a widely used technique to accelerate inference of deep neural networks. With the rising of pre-trained language models (PLMs) (Devlin et al., 2019;Yang et al., 2019;Raffel et al., 2020;Qiu et al., 2020), early exiting is drawing increasing attention in the NLP community. At its core, early exiting allows simple instances to exit early while allowing hard instances to exit late. Thus, how to measure instance difficulty is a crucial problem.\n\nMost existing early exiting methods attach multiple internal classifiers to the PLM and adopt some heuristic metrics, such as entropy  (Xin et al., 2020;Liu et al., 2020a) or maximum softmax score (Schwartz et al., 2020) of internal outputs, to measure instance difficulty. However, these methods can not easily generalize to new tasks. On the one hand, these metrics are not accessible on some tasks such as regression. On the other hand, In order for these methods to perform well, one usually needs to fine-tune the threshold, which varies widely across different tasks and datasets.\n\nAnother way to measure instance difficulty is to directly learn it. Recent studies (Elbayad et al., 2020;Xin et al., 2021) that use the idea of \"learn-toexit\" have achieved promising results. They jointly train a neural model to predict for each instance the exiting layer. At their core, the learn-to-exit module is to estimate the difficulty for each instance. Compared with previous heuristically designed metrics for difficulty, learn-to-exit is task-agnostic and does not require threshold-tuning, therefore is a more promising way.\n\nDespite their success, it is still unknown whether or how well the instance difficulty can be learned. As a response, in this work, we construct datasets for two kinds of instance difficulty: (a) Humandefined difficulty, and (b) Model-defined difficulty. The dataset for human-defined difficulty has two labels, 0 for instances that can be annotated by human and 1 for instances that cannot. For modeldefined difficulty, we train a multi-exit BERT (Devlin et al., 2019), which is attached with an internal classifier at each layer, on a sentence-level classification task, SNLI (Bowman et al., 2015), and a token-level classification task, OntoNotes NER (Hovy et al., 2006). The trained multi-exit BERTs are then used to annotate for each development instance whether it can be correctly predicted by each internal classifier. Thus, our constructed sentence-level and token-level model-defined difficulty datasets are multi-label classification datasets. Experimental results demonstrate that, modern neu-ral networks perform poorly on predicting instance difficulty. This observation is consistent with previous work (Laverghetta et al., 2020) on estimating instance difficulty for curriculum learning.\n\nGiven that instance difficulty is hard to be predicted, then what works in the learn-to-exit modules? We hypothesis that the consistency between training and inference may play an important role. That is, for a training instance x i that is predicted to exit at layer l, an inference instance x j that is similar with x i should be predicted to exit at layer l, too. Since neural networks are usually smooth functions (Ziegel, 2003), this consistency can be easily satisfied by neural learn-to-exit modules. If this hypothesis holds, we can replace the learn-to-exit module with a simple hash function. In particular, we use hash functions to assign each token to a fixed exiting layer. This hash-based early exiting method is named HASHEE.\n\nCompared with previous methods that use heuristic metrics for difficulty or jointly learn to exit, HASHEE offers several advantages: (a) HASHEE requires no internal classifiers nor extra parameters, which are necessary in previous work. (b) HASHEE can perform token-level early exiting without supervision, therefore can be widely used on various tasks including language understanding and generation. (c) The speed-up ratio can be easily tuned by modifying the hash function. (d) HASHEE can significantly accelerate model inference on a per-batch basis instead of per-instance basis as in previous work Liu et al., 2020a;.\n\nWe conduct experiments on classification, regression, and generation tasks. Experimental results on ELUE (Liu et al., 2021a) demonstrate that HASHEE, despite its simplicity, can achieve higher performance with fewer FLOPs and inference time than previous state-of-the-art methods on various tasks. Besides, our experiments on several text summarization datasets show that HASHEE can reduce ∼50% FLOPs of BART (Lewis et al., 2020) and CPT  while maintaining 97% ROUGE-1 score.\n\n ",
    "all_spans": [
      {
        "span_text": "Early exiting is a widely used technique to accelerate inference of deep neural networks.",
        "gpt_label": "Unsupported Claim",
        "reason": "Claims broad prevalence of a technique without citing supporting studies or surveys.",
        "start": 14,
        "end": 102
      },
      {
        "span_text": "With the rising of pre-trained language models (PLMs) (Devlin et al., 2019;Yang et al., 2019;Raffel et al., 2020;Qiu et al., 2020), early exiting is drawing increasing attention in the NLP community.",
        "gpt_label": "Unsupported Claim",
        "reason": "Asserts a trend about community attention without citing works that specifically demonstrate this increase.",
        "start": 103,
        "end": 297
      },
      {
        "span_text": "However, these methods can not easily generalize to new tasks.",
        "gpt_label": "Unsupported Claim",
        "reason": "Claims a limitation of prior methods without providing evidence or references.",
        "start": 739,
        "end": 800
      },
      {
        "span_text": "On the other hand, In order for these methods to perform well, one usually needs to fine-tune the threshold, which varies widely across different tasks and datasets.",
        "gpt_label": "Unsupported Claim",
        "reason": "States common practice and strong variability across tasks/datasets without citations to support the claim.",
        "start": 884,
        "end": 1048
      },
      {
        "span_text": "Despite their success, it is still unknown whether or how well the instance difficulty can be learned.",
        "gpt_label": "Unsupported Claim",
        "reason": "Asserts an open question about the state of knowledge without citing surveys or prior analyses to justify the claim.",
        "start": 1582,
        "end": 1683
      },
      {
        "span_text": "CPT",
        "gpt_label": "Unsupported Claim",
        "reason": "First mention of a model/dataset without a citation, violating the requirement to cite at first mention.",
        "start": 4561,
        "end": 4564
      },
      {
        "span_text": "Experimental results demonstrate that, modern neu-ral networks perform poorly on predicting instance difficulty. This observation is consistent with previous work (Laverghetta et al., 2020) on estimating instance difficulty for curriculum learning.",
        "gpt_label": "Coherence",
        "reason": "The transition from reporting the authors’ result to citing Laverghetta et al. is abrupt; it does not explicitly explain how difficulty in curriculum learning relates to early-exit instance difficulty. The relationship is implied rather than stated, causing a coherence gap across the two sentences.",
        "start": 2528,
        "end": 2773
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "Early exiting is a widely used technique to accelerate inference of deep neural networks.",
          "gpt_label": "Unsupported Claim",
          "reason": "Claims broad prevalence of a technique without citing supporting studies or surveys.",
          "start": 14,
          "end": 102
        },
        {
          "span_text": "With the rising of pre-trained language models (PLMs) (Devlin et al., 2019;Yang et al., 2019;Raffel et al., 2020;Qiu et al., 2020), early exiting is drawing increasing attention in the NLP community.",
          "gpt_label": "Unsupported Claim",
          "reason": "Asserts a trend about community attention without citing works that specifically demonstrate this increase.",
          "start": 103,
          "end": 297
        },
        {
          "span_text": "However, these methods can not easily generalize to new tasks.",
          "gpt_label": "Unsupported Claim",
          "reason": "Claims a limitation of prior methods without providing evidence or references.",
          "start": 739,
          "end": 800
        },
        {
          "span_text": "On the other hand, In order for these methods to perform well, one usually needs to fine-tune the threshold, which varies widely across different tasks and datasets.",
          "gpt_label": "Unsupported Claim",
          "reason": "States common practice and strong variability across tasks/datasets without citations to support the claim.",
          "start": 884,
          "end": 1048
        },
        {
          "span_text": "Despite their success, it is still unknown whether or how well the instance difficulty can be learned.",
          "gpt_label": "Unsupported Claim",
          "reason": "Asserts an open question about the state of knowledge without citing surveys or prior analyses to justify the claim.",
          "start": 1582,
          "end": 1683
        },
        {
          "span_text": "CPT",
          "gpt_label": "Unsupported Claim",
          "reason": "First mention of a model/dataset without a citation, violating the requirement to cite at first mention.",
          "start": 4561,
          "end": 4564
        }
      ],
      "Format": [],
      "Coherence": [
        {
          "span_text": "Experimental results demonstrate that, modern neu-ral networks perform poorly on predicting instance difficulty. This observation is consistent with previous work (Laverghetta et al., 2020) on estimating instance difficulty for curriculum learning.",
          "gpt_label": "Coherence",
          "reason": "The transition from reporting the authors’ result to citing Laverghetta et al. is abrupt; it does not explicitly explain how difficulty in curriculum learning relates to early-exit instance difficulty. The relationship is implied rather than stated, causing a coherence gap across the two sentences.",
          "start": 2528,
          "end": 2773
        }
      ]
    }
  },
  "paper_9.txt": {
    "filename": "paper_9.txt",
    "full_text": "Related Work\n\nSeveral approaches to zero-shot cross-lingual transfer exist and can broadly be divided into: a) Databased Transfer, which focuses on training data transformation and b) Model-based Transfer that centres around modifying models' training routine.\n\nData-based Transfer Translating utterances for the intent classification task is relatively straightforward so previous works focused on projecting and/or aligning the entity labels between translated utterances (Dou and Neubig, 2021). This technique is followed by standard supervised training with those pseudo-labels and is commonly known as a translate-train method. One of the earliest works still being used for this purpose is fastalign (Dyer et al., 2013). It's an unsupervised word aligner trained on a parallel corpus to map each word (thus its entity label) in the source utterance to the word(s) in the target user utterance. Projecting the entity labels can also be done with word-by-word translation and source label copying (Yi and Cheng, 2021). A teacher model then weakly labels the target data, which is used to train the final student model. Sometimes, this type of label projection is complemented with an additional entity alignment step (Li et al., 2021a). Better performance can be achieved by using machine translation with entity matching and distributional statistics (Jain et al., 2019) though this can be a costly process for each language. A category of 'word substitution' methods such as code-switching (Qin et al., 2020;Kuwanto et al., 2021) or dictionary-enhanced pretraining  have also been shown to improve cross-lingual transfer.\n\nModel-based Transfer Prior to the adoption of multilingual transformers (Lample and Conneau, 2019), task-oriented XNLU methods employed a BiLSTM encoder combined with different multilingual embeddings (Schuster et al., 2019). Newer approaches usually involve a pretrained XLM and the addition of some new training component with the inference routine remaining mostly unchanged. Xu et al. (2020) learn to jointly align and predict entity labels by fusing the source and target language embeddings with attention and using the resulting cross-lingual representation for entity prediction. Qi and Du (2020) include an adversarial language detector in training whose loss encourages the model to generate language-agnostic sentence representations for improved zero-shot trans-fer. Pan et al. (2020) and Chi et al. (2020) added a contrastive loss to pretraining that treats translated sentences as positive examples and unrelated sentences as negative samples. This training step helps the XLM produce similar embeddings in different languages. However, these methods require large annotated datasets and expensive model pretraining (Chi et al., 2020). Our proposed methods only use the English task data (which is relatively limited) and its translations for each language.\n\nThe most related prior works are Arivazhagan et al. (2019) for machine translation and  for task-oriented XNLU. Both of these are cross-lingual alignment methods that use translated training data to zero-shot transfer the source language model to the target language. We focus on the latter work, called XeroAlign, which reported the most recent SOTA scores on our evaluation datasets. XeroAlign works by generating a sentence embedding of the user utterance for each language, e.g. English (source) and Thai (target) using the CLS token of the XLM. A Mean Squared Error loss function minimises the difference between the multilingual sentence embeddings and is backpropagated along with the main task loss. XeroAlign aims to bring sentence embeddings in different languages closer together with a bias towards intent classification due to the CLS embedding, which is the standard input to the intent classifier. We reproduce this method for analysis and comparisons but add a small post-processing step that distinctly improves the reported scores.\n\n ",
    "all_spans": [
      {
        "span_text": "is commonly known as a translate-train method.",
        "gpt_label": "Unsupported Claim",
        "reason": "Asserts a commonly accepted term/practice without citing representative works that use or define the translate-train method.",
        "start": 584,
        "end": 629
      },
      {
        "span_text": "A teacher model then weakly labels the target data, which is used to train the final student model.",
        "gpt_label": "Unsupported Claim",
        "reason": "Introduces a specific teacher–student labeling approach without citing any prior work that uses this method in this context.",
        "start": 1016,
        "end": 1114
      },
      {
        "span_text": "or dictionary-enhanced pretraining  have also been shown to improve cross-lingual transfer.",
        "gpt_label": "Unsupported Claim",
        "reason": "Claims performance improvements for dictionary-enhanced pretraining without providing a supporting citation.",
        "start": 1522,
        "end": 1612
      },
      {
        "span_text": "Newer approaches usually involve a pretrained XLM and the addition of some new training component with the inference routine remaining mostly unchanged.",
        "gpt_label": "Unsupported Claim",
        "reason": "General claim about trends in the literature lacks citations to representative works.",
        "start": 1838,
        "end": 1989
      },
      {
        "span_text": "and  for task-oriented XNLU.",
        "gpt_label": "Unsupported Claim",
        "reason": "Mentions a prior work for task-oriented XNLU without providing a citation at first mention.",
        "start": 2956,
        "end": 2983
      },
      {
        "span_text": "called XeroAlign,",
        "gpt_label": "Unsupported Claim",
        "reason": "Introduces a specific prior method without citing the corresponding paper at first mention.",
        "start": 3168,
        "end": 3185
      },
      {
        "span_text": "which reported the most recent SOTA scores on our evaluation datasets.",
        "gpt_label": "Unsupported Claim",
        "reason": "Claims most recent state-of-the-art results without citing evidence or a source.",
        "start": 3186,
        "end": 3255
      },
      {
        "span_text": "XeroAlign works by generating a sentence embedding of the user utterance for each language, e.g. English (source) and Thai (target) using the CLS token of the XLM.",
        "gpt_label": "Unsupported Claim",
        "reason": "Describes the method of a prior work without citing the original source.",
        "start": 3256,
        "end": 3416
      },
      {
        "span_text": "A Mean Squared Error loss function minimises the difference between the multilingual sentence embeddings and is backpropagated along with the main task loss.",
        "gpt_label": "Unsupported Claim",
        "reason": "Continues detailed description of prior work without citation.",
        "start": 3417,
        "end": 3573
      },
      {
        "span_text": "XeroAlign aims to bring sentence embeddings in different languages closer together with a bias towards intent classification due to the CLS embedding, which is the standard input to the intent classifier.",
        "gpt_label": "Unsupported Claim",
        "reason": "Makes claims about the goals and mechanics of a prior method without citing the original paper; also asserts a standard practice without support.",
        "start": 3574,
        "end": 3777
      },
      {
        "span_text": "The most related prior works are Arivazhagan et al. (2019) for machine translation and  for task-oriented XNLU. Both of these are cross-lingual alignment methods that use translated training data to zero-shot transfer the source language model to the target language. We focus on the latter work, called XeroAlign, which reported the most recent SOTA scores on our evaluation datasets.",
        "gpt_label": "Coherence",
        "reason": "The second cited work is omitted, making 'both of these' ambiguous. The reference to 'the latter work' and only then naming XeroAlign forces the reader to infer the connection. The linkage between the sentences is abrupt and the relationship among the mentioned works is not explicitly established across these sentences.",
        "start": 2874,
        "end": 3255
      },
      {
        "span_text": "Data-based Transfer Translating utterances for the intent classification task is relatively straightforward so previous works focused on projecting and/or aligning the entity labels between translated utterances (Dou and Neubig, 2021). This technique is followed by standard supervised training with those pseudo-labels and is commonly known as a translate-train method. One of the earliest works still being used for this purpose is fastalign (Dyer et al., 2013). It's an unsupervised word aligner trained on a parallel corpus to map each word (thus its entity label) in the source utterance to the word(s) in the target user utterance. Projecting the entity labels can also be done with word-by-word translation and source label copying (Yi and Cheng, 2021). A teacher model then weakly labels the target data, which is used to train the final student model. Sometimes, this type of label projection is complemented with an additional entity alignment step (Li et al., 2021a). Better performance can be achieved by using machine translation with entity matching and distributional statistics (Jain et al., 2019) though this can be a costly process for each language. A category of 'word substitution' methods such as code-switching (Qin et al., 2020;Kuwanto et al., 2021) or dictionary-enhanced pretraining  have also been shown to improve cross-lingual transfer.",
        "gpt_label": "Lacks synthesis",
        "reason": "This paragraph lists prior methods and citations in a purely descriptive, enumerative way without synthesizing them, articulating limitations, or connecting them to the authors’ perspective or proposed approach, thus failing to highlight a clear gap or motivation.",
        "start": 261,
        "end": 1612
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "is commonly known as a translate-train method.",
          "gpt_label": "Unsupported Claim",
          "reason": "Asserts a commonly accepted term/practice without citing representative works that use or define the translate-train method.",
          "start": 584,
          "end": 629
        },
        {
          "span_text": "A teacher model then weakly labels the target data, which is used to train the final student model.",
          "gpt_label": "Unsupported Claim",
          "reason": "Introduces a specific teacher–student labeling approach without citing any prior work that uses this method in this context.",
          "start": 1016,
          "end": 1114
        },
        {
          "span_text": "or dictionary-enhanced pretraining  have also been shown to improve cross-lingual transfer.",
          "gpt_label": "Unsupported Claim",
          "reason": "Claims performance improvements for dictionary-enhanced pretraining without providing a supporting citation.",
          "start": 1522,
          "end": 1612
        },
        {
          "span_text": "Newer approaches usually involve a pretrained XLM and the addition of some new training component with the inference routine remaining mostly unchanged.",
          "gpt_label": "Unsupported Claim",
          "reason": "General claim about trends in the literature lacks citations to representative works.",
          "start": 1838,
          "end": 1989
        },
        {
          "span_text": "and  for task-oriented XNLU.",
          "gpt_label": "Unsupported Claim",
          "reason": "Mentions a prior work for task-oriented XNLU without providing a citation at first mention.",
          "start": 2956,
          "end": 2983
        },
        {
          "span_text": "called XeroAlign,",
          "gpt_label": "Unsupported Claim",
          "reason": "Introduces a specific prior method without citing the corresponding paper at first mention.",
          "start": 3168,
          "end": 3185
        },
        {
          "span_text": "which reported the most recent SOTA scores on our evaluation datasets.",
          "gpt_label": "Unsupported Claim",
          "reason": "Claims most recent state-of-the-art results without citing evidence or a source.",
          "start": 3186,
          "end": 3255
        },
        {
          "span_text": "XeroAlign works by generating a sentence embedding of the user utterance for each language, e.g. English (source) and Thai (target) using the CLS token of the XLM.",
          "gpt_label": "Unsupported Claim",
          "reason": "Describes the method of a prior work without citing the original source.",
          "start": 3256,
          "end": 3416
        },
        {
          "span_text": "A Mean Squared Error loss function minimises the difference between the multilingual sentence embeddings and is backpropagated along with the main task loss.",
          "gpt_label": "Unsupported Claim",
          "reason": "Continues detailed description of prior work without citation.",
          "start": 3417,
          "end": 3573
        },
        {
          "span_text": "XeroAlign aims to bring sentence embeddings in different languages closer together with a bias towards intent classification due to the CLS embedding, which is the standard input to the intent classifier.",
          "gpt_label": "Unsupported Claim",
          "reason": "Makes claims about the goals and mechanics of a prior method without citing the original paper; also asserts a standard practice without support.",
          "start": 3574,
          "end": 3777
        }
      ],
      "Format": [],
      "Coherence": [
        {
          "span_text": "The most related prior works are Arivazhagan et al. (2019) for machine translation and  for task-oriented XNLU. Both of these are cross-lingual alignment methods that use translated training data to zero-shot transfer the source language model to the target language. We focus on the latter work, called XeroAlign, which reported the most recent SOTA scores on our evaluation datasets.",
          "gpt_label": "Coherence",
          "reason": "The second cited work is omitted, making 'both of these' ambiguous. The reference to 'the latter work' and only then naming XeroAlign forces the reader to infer the connection. The linkage between the sentences is abrupt and the relationship among the mentioned works is not explicitly established across these sentences.",
          "start": 2874,
          "end": 3255
        }
      ],
      "Lacks synthesis": [
        {
          "span_text": "Data-based Transfer Translating utterances for the intent classification task is relatively straightforward so previous works focused on projecting and/or aligning the entity labels between translated utterances (Dou and Neubig, 2021). This technique is followed by standard supervised training with those pseudo-labels and is commonly known as a translate-train method. One of the earliest works still being used for this purpose is fastalign (Dyer et al., 2013). It's an unsupervised word aligner trained on a parallel corpus to map each word (thus its entity label) in the source utterance to the word(s) in the target user utterance. Projecting the entity labels can also be done with word-by-word translation and source label copying (Yi and Cheng, 2021). A teacher model then weakly labels the target data, which is used to train the final student model. Sometimes, this type of label projection is complemented with an additional entity alignment step (Li et al., 2021a). Better performance can be achieved by using machine translation with entity matching and distributional statistics (Jain et al., 2019) though this can be a costly process for each language. A category of 'word substitution' methods such as code-switching (Qin et al., 2020;Kuwanto et al., 2021) or dictionary-enhanced pretraining  have also been shown to improve cross-lingual transfer.",
          "gpt_label": "Lacks synthesis",
          "reason": "This paragraph lists prior methods and citations in a purely descriptive, enumerative way without synthesizing them, articulating limitations, or connecting them to the authors’ perspective or proposed approach, thus failing to highlight a clear gap or motivation.",
          "start": 261,
          "end": 1612
        }
      ]
    }
  },
  "paper_10.txt": {
    "filename": "paper_10.txt",
    "full_text": "Introduction\n\nReading comprehension is a complex, multidimensional cognitive process (Kim, 2017). Question answering (QA) are fundamental for supporting humans’ development of reading comprehension skills, as questions serve as both instruments for evaluation and tools to facilitate learning. To achieve this goal, comprehension questions should be valid and reliable, meaning that all items are designed to cohesively assess comprehension rather than some other skills (e.g., text matching, paraphrasing, or memorization) (Roberts and Priest, 2006). Moreover, from the educational perspective, given that reading comprehension is a multicomponent skill, it is ideal for comprehension questions to be able to identify students’ performance in specific sub-skills, thus allowing teachers to provide tailored guidance (Francis et al., 2005). This kind of high-quality questions is also valuable for improving machine reading comprehension.\n\nHowever, creating a large and suitable set of questions for supporting narrative comprehension is both time-consuming and cognitively demanding. Some researchers have proposed to develop models to automatically generate questions to satisfy the need for a continuous supply of new questions (Kurdi et al., 2020). However, existing datasets are not particularly suitable for training question generation (QG) models for educational purposes (Das et al., 2021). This is primarily because the datasets are not typically structured around the specific dimensions of reading comprehension sub-skills, nor do they provide sufficient information on what sub-skills are tested. As a consequence, QG  models built on these datasets only yield one single \"comprehension\" score without a more detailed breakdown of performance on comprehension sub-skills. This issue is compounded by the fact that many benchmarks rely on crowd-sourced workers who may not have sufficient training or education domain knowledge needed to create valid questions in a onsistent way. To bridge the gap, we constructed FairytaleQA, an open-source dataset focusing on comprehension of narratives, targeting students from kindergarten to eighth grade (Table 1). We focus on narrative comprehension for two reasons. First, narrative comprehension is a high-level comprehension skill strongly predictive of reading achievement (Lynch et al., 2008) and plays a central role in daily life as people frequently encounter narratives in different forms (Goldie, 2003). Second, narrative stories have a clear structure of specific elements and relations among these elements, and there are existing validated narrative comprehension frameworks around this structure, which provides a basis for developing the annotation schema for our dataset. We employed education experts who generated 10,580 question-answer pairs based on a collection of 278 fairytale stories for young readers, following evidence-based narrative comprehension frameworks (Paris and Paris, 2003; Alonzo et al., 2009). Thereby, FairytaleQA contains questions that focus on seven narrative elements and relations, namely character, setting, feeling, action, causal relationship, outcome resolution, and prediction (Paris and Paris, 2003), thus increasing the validity and reliability of the assessment. In addition, FairytaleQA also contains both explicit questions that involve answers found directly in the text and implicit questions that require inference making and high-level summarization, thus representing a relatively balanced assessment with questions of varying difficulty levels. Most importantly, our selection of annotators with education domain knoweldge as well as the training and quality control process ensured that the aforementioned annotation protocol was consistently implemented. A subset of questions in our dataset has been validated with 120 kindergarten students, proving the questions’ reliability and validity.\nWe show the utility of FairytaleQA through two benchmarking experiments. First, we used our data to train and evaluate state-of-the-art QA models and demonstrated that (1) FairytaleQA contains challenging phenonmena for existing models, and (2) it can support finer-grained analysis on the aforementioned seven types of comprehension sub-skills,\neven for models trained on standard QA datasets (NarrativeQA (Koˇcisk `y et al., 2018)). We further calibrated model performances with human baseline, highlighting the most visible gap on models’ reasoning capabilities on recognizing casual relationships and predicting event outcomes. Second, we used FairytaleQA to power question generation and showed that the QG model trained on ours was more capable of asking diverse questions and generating questions with higher quality.\n\n ",
    "all_spans": [
      {
        "span_text": "Question answering (QA) are fundamental for supporting humans’ development of reading comprehension skills, as questions serve as both instruments for evaluation and tools to facilitate learning.",
        "gpt_label": "Unsupported Claim",
        "reason": "Broad, field-specific assertion about the educational role of QA lacks supporting citations to prior educational research.",
        "start": 97,
        "end": 291
      },
      {
        "span_text": "This kind of high-quality questions is also valuable for improving machine reading comprehension.",
        "gpt_label": "Unsupported Claim",
        "reason": "Claim about benefits to machine reading comprehension references prior work implicitly but provides no citations.",
        "start": 834,
        "end": 930
      },
      {
        "span_text": "This is primarily because the datasets are not typically structured around the specific dimensions of reading comprehension sub-skills, nor do they provide sufficient information on what sub-skills are tested.",
        "gpt_label": "Unsupported Claim",
        "reason": "Specific characterization of existing datasets requires references to support the claim.",
        "start": 1387,
        "end": 1595
      },
      {
        "span_text": "As a consequence, QG  models built on these datasets only yield one single \"comprehension\" score without a more detailed breakdown of performance on comprehension sub-skills.",
        "gpt_label": "Unsupported Claim",
        "reason": "Generalization about typical outputs of QG models should be backed by citations to exemplifying studies or benchmarks.",
        "start": 1596,
        "end": 1769
      },
      {
        "span_text": "This issue is compounded by the fact that many benchmarks rely on crowd-sourced workers who may not have sufficient training or education domain knowledge needed to create valid questions in a onsistent way.",
        "gpt_label": "Unsupported Claim",
        "reason": "Claim about widespread reliance on crowd workers and their qualifications should be supported with citations to the benchmarks or studies demonstrating this.",
        "start": 1770,
        "end": 1976
      },
      {
        "span_text": "(NarrativeQA (Koˇcisk `y et al., 2018))",
        "gpt_label": "Format",
        "reason": "Nested parentheses and mixed citation style; the dataset name and the citation are combined causing double brackets, which is improper citation formatting.",
        "start": 4275,
        "end": 4313
      },
      {
        "span_text": "However, existing datasets are not particularly suitable for training question generation (QG) models for educational purposes (Das et al., 2021). This is primarily because the datasets are not typically structured around the specific dimensions of reading comprehension sub-skills, nor do they provide sufficient information on what sub-skills are tested. As a consequence, QG  models built on these datasets only yield one single \"comprehension\" score without a more detailed breakdown of performance on comprehension sub-skills.",
        "gpt_label": "Coherence",
        "reason": "The passage shifts from dataset suitability for question generation to a claim about models yielding a single comprehension score without explicitly explaining how QG datasets or models lead to that outcome. The relationship between the cited work (Das et al., 2021) and the subsequent claim about scoring is implied rather than stated, making the multi-sentence connection abrupt and unclear.",
        "start": 1242,
        "end": 1769
      },
      {
        "span_text": "Some researchers have proposed to develop models to automatically generate questions to satisfy the need for a continuous supply of new questions (Kurdi et al., 2020).",
        "gpt_label": "Lacks synthesis",
        "reason": "This sentence cites prior work but does not connect it to the authors’ argument or approach in the moment—there is no explicit contrast, integration, or stated implication for their dataset until subsequent sentences, resulting in a lack of synthesis.",
        "start": 1076,
        "end": 1241
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "Question answering (QA) are fundamental for supporting humans’ development of reading comprehension skills, as questions serve as both instruments for evaluation and tools to facilitate learning.",
          "gpt_label": "Unsupported Claim",
          "reason": "Broad, field-specific assertion about the educational role of QA lacks supporting citations to prior educational research.",
          "start": 97,
          "end": 291
        },
        {
          "span_text": "This kind of high-quality questions is also valuable for improving machine reading comprehension.",
          "gpt_label": "Unsupported Claim",
          "reason": "Claim about benefits to machine reading comprehension references prior work implicitly but provides no citations.",
          "start": 834,
          "end": 930
        },
        {
          "span_text": "This is primarily because the datasets are not typically structured around the specific dimensions of reading comprehension sub-skills, nor do they provide sufficient information on what sub-skills are tested.",
          "gpt_label": "Unsupported Claim",
          "reason": "Specific characterization of existing datasets requires references to support the claim.",
          "start": 1387,
          "end": 1595
        },
        {
          "span_text": "As a consequence, QG  models built on these datasets only yield one single \"comprehension\" score without a more detailed breakdown of performance on comprehension sub-skills.",
          "gpt_label": "Unsupported Claim",
          "reason": "Generalization about typical outputs of QG models should be backed by citations to exemplifying studies or benchmarks.",
          "start": 1596,
          "end": 1769
        },
        {
          "span_text": "This issue is compounded by the fact that many benchmarks rely on crowd-sourced workers who may not have sufficient training or education domain knowledge needed to create valid questions in a onsistent way.",
          "gpt_label": "Unsupported Claim",
          "reason": "Claim about widespread reliance on crowd workers and their qualifications should be supported with citations to the benchmarks or studies demonstrating this.",
          "start": 1770,
          "end": 1976
        }
      ],
      "Format": [
        {
          "span_text": "(NarrativeQA (Koˇcisk `y et al., 2018))",
          "gpt_label": "Format",
          "reason": "Nested parentheses and mixed citation style; the dataset name and the citation are combined causing double brackets, which is improper citation formatting.",
          "start": 4275,
          "end": 4313
        }
      ],
      "Coherence": [
        {
          "span_text": "However, existing datasets are not particularly suitable for training question generation (QG) models for educational purposes (Das et al., 2021). This is primarily because the datasets are not typically structured around the specific dimensions of reading comprehension sub-skills, nor do they provide sufficient information on what sub-skills are tested. As a consequence, QG  models built on these datasets only yield one single \"comprehension\" score without a more detailed breakdown of performance on comprehension sub-skills.",
          "gpt_label": "Coherence",
          "reason": "The passage shifts from dataset suitability for question generation to a claim about models yielding a single comprehension score without explicitly explaining how QG datasets or models lead to that outcome. The relationship between the cited work (Das et al., 2021) and the subsequent claim about scoring is implied rather than stated, making the multi-sentence connection abrupt and unclear.",
          "start": 1242,
          "end": 1769
        }
      ],
      "Lacks synthesis": [
        {
          "span_text": "Some researchers have proposed to develop models to automatically generate questions to satisfy the need for a continuous supply of new questions (Kurdi et al., 2020).",
          "gpt_label": "Lacks synthesis",
          "reason": "This sentence cites prior work but does not connect it to the authors’ argument or approach in the moment—there is no explicit contrast, integration, or stated implication for their dataset until subsequent sentences, resulting in a lack of synthesis.",
          "start": 1076,
          "end": 1241
        }
      ]
    }
  },
  "paper_20.txt": {
    "filename": "paper_20.txt",
    "full_text": "Related Work\n\nD2T Generation with PLMs Large neural language models pretrained on self-supervised tasks (Lewis et al., 2020;Liu et al., 2019;Devlin et al., 2019) have recently gained a lot of traction in D2T generation research (Ferreira et al., 2020). Following Chen et al. (2020c), other works adopt PLMs for few-shot D2T generation (Chang et al., 2021b;Su et al., 2021a). Kale and Rastogi (2020b) and Ribeiro et al. (2020) showed that PLMs using linearized representations of data can outperform graph neural networks on graph-to-text datasets, recently surpassed again by graph-based models (Ke et al., 2021;Chen et al., 2020a). Although the models make use of general-domain pretraining tasks, all of them are eventually finetuned on domain-specific data.\n\nTemplates in Data-Driven D2T Generation Using simple handcrafted templates for individual keys or predicates is an efficient way of introducing domain knowledge while preventing text-to-text models from overfitting to a specific data format (Heidari et al., 2021;Kale and Rastogi, 2020a;. Transforming individual triples to text is also used in Laha et al. (2020) whose work is the most similar to ours. They also build a three-step pipeline for zero-shot D2T generation, but they use handcrafted rules for producing the output text and do not address content planning.\n\nContent Planning in D2T Generation Content planning, i.e. ordering input facts and aggregating them into individual sentences, is a traditional part of the D2T generation pipeline (Ferreira et al., 2019;Gatt and Krahmer, 2018;Reiter and Dale, 1997). As previously demonstrated, using a content plan in neural D2T generation has important impact on the overall text quality (Moryossef et al., 2019a,b;Puduppully et al., 2019;Trisedya et al., 2020). Recently,  have shown that using a content plan leads to improved quality of PLM outputs. All the aforementioned models plan directly using predicates or keys in the D2T datasets representing the corresponding data item. Unlike these works, our planner is trained on ordering sentences in natural language.\n\nSentence Ordering Sentence ordering is the task of organizing a set of natural language sentences to increase the coherence of a text (Barzilay et al., 2001;Lapata, 2003). Several neural methods for this task were proposed, using either interactions between pairs of sentences Li and Jurafsky, 2017), global interactions (Gong et al., 2016;Wang and Wan, 2019), or combination of both (Cui et al., 2020). We base our ordering module ( §5.1) on the recent work of Calizzano et al. (2021), who use a pointer network (Wang and Wan, 2019;Vinyals et al., 2015) on top of a PLM.\n\nFact Aggregation The compact nature of the target text description results in aggregating multiple facts in a single sentence. Previous works (Wiseman et al., 2018;Shao et al., 2019;Shen et al., 2020;Xu et al., 2021) capture the segments which correspond to individual parts of the input as latent variables. Unlike these works, we adopt a simpler scenario using an already ordered sequence of facts, in which we selectively insert delimiters marking sentence boundaries.  Paragraph Compression We introduce paragraph compression as a new task in our D2T generation pipeline. As the last step in the pipeline, it is closely related to linguistic realisation, howeversince we already work with natural language in this step-the focus of our task is on sentence fusion, rephrasing, and coreference resolution. Unlike text summarization or simplification Jiang et al., 2020), we aim to convey the complete semantics of the text without omitting any facts. In contrast to sentence fusion (Geva et al., 2019;Barzilay and McKeown, 2005) or sentence compression (Filippova and Altun, 2013), we operate in the context of multiple sentences in a paragraph. The task is the central focus of our WIKIFLUENT corpus ( §4), which we synthesize using a model for the reverse task, split-andrephrase, i.e. splitting a complex sentence into simpler ones while preserving semantics (Botha et al., 2018;.\n\n ",
    "all_spans": [
      {
        "span_text": "Recently,  have shown that using a content plan leads to improved quality of PLM outputs.",
        "gpt_label": "Unsupported Claim",
        "reason": "This claim references unspecified prior work and uses the phrase 'have shown' without providing any citation or attribution to specific studies.",
        "start": 1754,
        "end": 1842
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "Recently,  have shown that using a content plan leads to improved quality of PLM outputs.",
          "gpt_label": "Unsupported Claim",
          "reason": "This claim references unspecified prior work and uses the phrase 'have shown' without providing any citation or attribution to specific studies.",
          "start": 1754,
          "end": 1842
        }
      ]
    }
  },
  "paper_21.txt": {
    "filename": "paper_21.txt",
    "full_text": "Introduction\n\nNatural language processing (NLP) datasets are plagued with artifacts and biases, which allow models to perform tasks without learning the desired underlying language capabilities. For instance, in natural language inference (NLI) datasets, models can predict an entailment relationship y from the hypothesis text H alone, without considering the premise P at all (Gururangan et al., 2018;Poliak et al., 2018). Another identified source of bias is lexical overlap between P and H, which is associ-ated with an entailment prediction (McCoy et al., 2019). We refer to such biases as structural biases, cases where an undesired subset of the input alone incorrectly identifies the label. Relying on such biases results in poor out-of-distribution (o.o.d) generalization when models are applied to data without bias. Furthermore, models that contain such biases may make surprising predictions when the bias is present, causing problems in critical systems.\n\nA line of work has attempted to improve the performance on o.o.d datasets by proposing different objective functions (e.g., Utama et al., 2020a;Karimi Mahabadi et al., 2020). However, these methods typically still result in a significant gap between the performance in and out of distribution, which indicates that the models are still biased. Table 1 shows this gap, which we term the o.o.d generalization gap (∆).\n\nIn this work, we reformulate classification as a generative task, where the model's task is to generate the remainder features R conditioned on the biased features B and the label y. Using Bayes' Rule, we decompose the posterior p(y | B, R) into the likelihood p(R | y, B) and the prior p(y | B). This reformulation lets us control the amount of bias present in the final model. By setting a uniform prior we can obtain a provably unbiased model. We denote this generative model as GEN..\n\nTo assess the extent to which a given model is biased w.r.t a specific structural bias, we consider two metrics: the o.o.d generalization gap and the correlation between a model and a biased model p(y | B), such as a hypothesis-only or overlap-only model. We first experiment with injecting synthetic bias into a fraction of the training set and evaluating on test sets with and without that bias. We find that the discriminative model's performance decreases as the amount of bias increases, while GEN maintains similar performance at all bias levels. Moreover, the biased-ness of the discriminative model increases, while GEN  Next, we experiment with two kinds of natural bias: hypothesis-only and overlap. We demonstrate that GEN is unbiased compared to the discriminative baseline as measured by its low ∆ and low absolute correlation with a biased model (ρ).\n\nHowever, while our approach leads to unbiased models, it performs worse than the discriminative baseline even on o.o.d data. We then identify and quantify several causes for the poor performance of GEN. We show that generative modeling is a more challenging task than discriminative modeling, and that it requires learning a large amount of spurious signal compared to the discriminative model.\n\nFinally, to mitigate the difficulty of the generative modeling task, we fine-tune GEN with a discriminative objective (Lewis and Fan, 2019). While this leaks some bias into the model, the final model (denoted as GEN-FT) matches or surpasses the discriminative baseline while maintaining a relatively small o.o.d generalization gap.\n\nTo conclude, our contributions are as follows:\n\n• We develop a generative modeling approach, which provably eliminates structural biases in natural language understanding tasks.\n\n• We demonstrate experimentally on two bias types and different NLI datasets that this approach leads to unbiased models.\n\n• We analyze the strengths and weaknesses of the generative model.\n\n• We show how discriminative fine-tuning improves the generative model, while allowing some bias to leak into the model.\n\n ",
    "all_spans": [
      {
        "span_text": "Natural language processing (NLP) datasets are plagued with artifacts and biases, which allow models to perform tasks without learning the desired underlying language capabilities.",
        "gpt_label": "Unsupported Claim",
        "reason": "Broad field-wide claim about dataset biases and their effects without citations; should reference representative studies across NLP.",
        "start": 14,
        "end": 193
      },
      {
        "span_text": "However, these methods typically still result in a significant gap between the performance in and out of distribution, which indicates that the models are still biased.",
        "gpt_label": "Unsupported Claim",
        "reason": "Generalization about prior methods' outcomes across the literature without supporting citations; 'typically' implies a survey-level claim that needs evidence beyond the authors' own table.",
        "start": 1126,
        "end": 1293
      },
      {
        "span_text": "Furthermore, models that contain such biases may make surprising predictions when the bias is present, causing problems in critical systems.",
        "gpt_label": "Unsupported Claim",
        "reason": "Impact claim about critical systems without evidence or citations to documented failures or risk analyses.",
        "start": 817,
        "end": 956
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "Natural language processing (NLP) datasets are plagued with artifacts and biases, which allow models to perform tasks without learning the desired underlying language capabilities.",
          "gpt_label": "Unsupported Claim",
          "reason": "Broad field-wide claim about dataset biases and their effects without citations; should reference representative studies across NLP.",
          "start": 14,
          "end": 193
        },
        {
          "span_text": "However, these methods typically still result in a significant gap between the performance in and out of distribution, which indicates that the models are still biased.",
          "gpt_label": "Unsupported Claim",
          "reason": "Generalization about prior methods' outcomes across the literature without supporting citations; 'typically' implies a survey-level claim that needs evidence beyond the authors' own table.",
          "start": 1126,
          "end": 1293
        },
        {
          "span_text": "Furthermore, models that contain such biases may make surprising predictions when the bias is present, causing problems in critical systems.",
          "gpt_label": "Unsupported Claim",
          "reason": "Impact claim about critical systems without evidence or citations to documented failures or risk analyses.",
          "start": 817,
          "end": 956
        }
      ]
    }
  },
  "paper_22.txt": {
    "filename": "paper_22.txt",
    "full_text": "Related work\n\nSemantic textual similarity\n\nMost recent studies tried to leverage a pretrained language model with various model architectures and training objectives for STS tasks, achieving the state-of-the-art performance. In terms of model architecture, Devlin et al. (2019) focus on exhaustive cross-correlation between sentences by taking a concatenated text of two sentences as an input, while Reimers and Gurevych (2019) improve scalability based on a Siamese network and Humeau et al. (2020) adopt a hybrid approach. Along with the progress of model architectures, many advanced objectives for STS tasks were proposed as well. Specifically, Reimers and Gurevych (2019) mainly use the classification objective for an NLI dataset, and Wu et al. (2020) adopt contrastive learning to utilize self-supervision from a large corpus. Yan et al. (2021); Gao et al. (2021) incorporate a parallel corpus such as NLI datasets into their contrastive learning framework.\n\nDespite their effectiveness, the interpretability of the above models for STS tasks was not fully explored (Belinkov and Glass, 2019). One related task is interpretable STS, which aims to predict chunk alignment between two sentences . For this task, a variety of supervised approaches were proposed based on neural networks (Konopík et al., 2016;, linear programming (Tekumalla and Jat, 2016), and pretrained models (Maji et al., 2020). However, these methods cannot predict the similarity between sentences because they focus on finding chunk alignment only. To the best of our knowledge, no previous approaches based on a pretrained model have taken into account both sentence similarity and interpretation.\n\nOptimal transport\n\nOptimal transport (Monge, 1781) has been successfully adopted in natural language processing due to its ability to find a plausible correspondence between two objects (Li et al., 2020;. For example, Kusner et al. (2015) adopt optimal transport to measure the distance between two documents with pretrained word vectors. In addition, Swanson et al. (2020) discover the rationale in textmatching via optimal transport, thereby improving model interpretability.\n\nOne well-known limitation of optimal transport is that finding the optimal solution is computationally intensive, and thus approximation schemes for this problem have been extensively researched (Grauman and Darrell, 2004;Shirdhonkar and Jacobs, 2008). To get the solution efficiently, Cuturi (2013) provides a regularizer inspired by a probabilistic theory and then uses Sinkhorn's algorithm. Kusner et al. (2015) relax the problem to get the quadratic-time solution by removing one of the constraints, and Wu et al. (2018) introduce a kernel method to approximate the optimal transport.\n\n ",
    "all_spans": [
      {
        "span_text": "Most recent studies tried to leverage a pretrained language model with various model architectures and training objectives for STS tasks, achieving the state-of-the-art performance.",
        "gpt_label": "Unsupported Claim",
        "reason": "Broad claim about 'most recent studies' and achieving SOTA lacks citations to specific works, violating the requirement to cite recent works.",
        "start": 43,
        "end": 223
      },
      {
        "span_text": "One related task is interpretable STS, which aims to predict chunk alignment between two sentences .",
        "gpt_label": "Unsupported Claim",
        "reason": "Definition of a niche task ('interpretable STS') should be supported with a citation to the task/dataset or foundational work.",
        "start": 1090,
        "end": 1189
      },
      {
        "span_text": "However, these methods cannot predict the similarity between sentences because they focus on finding chunk alignment only.",
        "gpt_label": "Unsupported Claim",
        "reason": "Claim about the limitations of prior methods requires evidence or citations showing they do not output sentence similarity.",
        "start": 1389,
        "end": 1510
      },
      {
        "span_text": "To the best of our knowledge, no previous approaches based on a pretrained model have taken into account both sentence similarity and interpretation.",
        "gpt_label": "Unsupported Claim",
        "reason": "Novelty claim about absence of prior work should be substantiated or contrasted with cited related work.",
        "start": 1511,
        "end": 1659
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "Most recent studies tried to leverage a pretrained language model with various model architectures and training objectives for STS tasks, achieving the state-of-the-art performance.",
          "gpt_label": "Unsupported Claim",
          "reason": "Broad claim about 'most recent studies' and achieving SOTA lacks citations to specific works, violating the requirement to cite recent works.",
          "start": 43,
          "end": 223
        },
        {
          "span_text": "One related task is interpretable STS, which aims to predict chunk alignment between two sentences .",
          "gpt_label": "Unsupported Claim",
          "reason": "Definition of a niche task ('interpretable STS') should be supported with a citation to the task/dataset or foundational work.",
          "start": 1090,
          "end": 1189
        },
        {
          "span_text": "However, these methods cannot predict the similarity between sentences because they focus on finding chunk alignment only.",
          "gpt_label": "Unsupported Claim",
          "reason": "Claim about the limitations of prior methods requires evidence or citations showing they do not output sentence similarity.",
          "start": 1389,
          "end": 1510
        },
        {
          "span_text": "To the best of our knowledge, no previous approaches based on a pretrained model have taken into account both sentence similarity and interpretation.",
          "gpt_label": "Unsupported Claim",
          "reason": "Novelty claim about absence of prior work should be substantiated or contrasted with cited related work.",
          "start": 1511,
          "end": 1659
        }
      ]
    }
  },
  "paper_23.txt": {
    "filename": "paper_23.txt",
    "full_text": "Related Work\n\nThe goal of constrained textual generation is to find the sequence of tokens x1:T which maximises p(x1:T | c), given a constraint c. Few methods address the constrained textual generation. \n\nClass-conditional language models. Classconditional language models (CC-LMs), as the Conditional Transformer Language (CTRL) model (Keskar et al., 2019), train or fine-tune the weights θ of a single neural model directly for controllable generation, by appending a control code in the beginning of a training sequence. The control code indicates the constraint to verify and is related to a class containing texts that satisfy the constraint. For the sake of simplicity, we will denote without distinction the class, the constraint verified by its texts and the associated control code by c. Trained with different control codes, the model learns pθ(x1:T | c) = ∏T t=1 pθ(xt | x1:t−1, c). The constraint can then be applied during generation by appending the corresponding control code to the prompt. While this method gives some kind of control over the generation, the control codes need to be defined upfront and the LM still needs to be trained specifically for each set of control codes. This is an important limitation since the current trend in text generation is the use of large pre-trained model which can hardly be fine-tuned (for instance, the last version of GPT, GPT-3, cannot be fine-tuned without access to very large hardware resources). Discriminator-based methods The general idea of discriminator-guided generation is to combine a disciminator D with a generative LM. The discriminator explicitly models the constraint by calculating the probability pD(c | x1:T ) of the sequence x1:T to satisfy the constraint c.  This probability is directly related to p(x1:T | c) through Bayes’ rule : p(x1:T | c) ∝ pD(c | x1:T )pθ(x1:T ). \n\nDiscriminator-based methods alleviate the training cost problem, as discriminators are easier to train than a LM. Moreover, any additional constraint can be defined a posteriori without tuning the LM, only by training another discriminator. The discriminators have been used in different ways to explore the search space. In the work of (Holtzman et al., 2018; Scialom et al., 2020), the space is first searched using beam search to generate a pool of proposals with a high likelihood pθ(x1:T ), and then the discriminator is used to re-rank them. However, in addition that beam search can miss sequences with high likelihood, it is biased towards the likelihood, while the best sequence might only have an average likelihood, but satisfies the constraint perfectly. \n\nHence, it might be more suitable to take the discriminator probability into account during decoding rather than after generating a whole sequence. In this case, the discriminator is used at each generation step to get the probability pD(c | x1:t) for each token of the vocabulary V, and merge it to the likelihood pθ(x1:t) to choose which token to emit. In order to reduce the cost of using a discriminator on every possible continuation, GeDi (Krause et al., 2020) proposes to use CC-LMs as generative discriminators. The method relies on the fact that the CC-LM computes pθ (xt | x1:t−1, c) for all tokens of the vocabulary which can be used to get pθ(c | x1:t) for all tokens using Bayes’ equation. This approach is thus at the intersection of tuning the LM and using a discriminator: it tunes a small LM (the CC-LM) to guide a bigger one. \n\nIn Plug And Play Language Model (PPLM) (Dathathri et al., 2020), the discriminator is used to shift the hidden states of the pre-trained transformer-based LM towards the desired class at every generation step. PPLM can be used on any LM and with any discriminator. However, PPLM needs to access the LM to modify its hidden states, while our approach only requires the output logits. As some LM can only be used through access to logits (e.g. GPT-3 API), this makes our approach more plug and play than PPLM. A common drawback of all these approaches is their lack of a long-term vision of the  generation. Indeed, the discriminator probabilities become necessarily more meaningful as the sequence grows and might only be trustable to guide the search when the sequence is (nearly) finished.  When used in a myopic decoding strategy, classification errors will cause the generation process to deviate further and further. Trying to optimize a score defined in the long horizon by making short term decisions is very similar to common game setups such as chess, where the Monte Carlo Tree Search (MCTS) has proven to be really effective (Silver et al., 2018), which motivated our approach.\n \n\n ",
    "all_spans": [
      {
        "span_text": "Few methods address the constrained textual generation.",
        "gpt_label": "Unsupported Claim",
        "reason": "Field-level claim about the scarcity of methods is presented without citations or evidence.",
        "start": 146,
        "end": 200
      },
      {
        "span_text": "This is an important limitation since the current trend in text generation is the use of large pre-trained model which can hardly be fine-tuned (for instance, the last version of GPT, GPT-3, cannot be fine-tuned without access to very large hardware resources).",
        "gpt_label": "Unsupported Claim",
        "reason": "Claims about the prevailing trend in the field and specific statements about GPT-3 fine-tuning requirements are made without citations.",
        "start": 1188,
        "end": 1448
      },
      {
        "span_text": "Discriminator-based methods alleviate the training cost problem, as discriminators are easier to train than a LM.",
        "gpt_label": "Unsupported Claim",
        "reason": "Comparative claim about training difficulty/cost lacks supporting references.",
        "start": 1840,
        "end": 1952
      },
      {
        "span_text": "However, in addition that beam search can miss sequences with high likelihood, it is biased towards the likelihood, while the best sequence might only have an average likelihood, but satisfies the constraint perfectly.",
        "gpt_label": "Unsupported Claim",
        "reason": "Assertions about beam search behavior and its bias require citations or empirical evidence.",
        "start": 2382,
        "end": 2599
      },
      {
        "span_text": "As some LM can only be used through access to logits (e.g. GPT-3 API)",
        "gpt_label": "Unsupported Claim",
        "reason": "Specific claim about API/model access constraints is made without a reference.",
        "start": 3820,
        "end": 3887
      },
      {
        "span_text": "A common drawback of all these approaches is their lack of a long-term vision of the  generation.",
        "gpt_label": "Unsupported Claim",
        "reason": "Generalized critique of prior methods is presented without citing supporting analyses or studies.",
        "start": 3942,
        "end": 4038
      },
      {
        "span_text": "Indeed, the discriminator probabilities become necessarily more meaningful as the sequence grows and might only be trustable to guide the search when the sequence is (nearly) finished.",
        "gpt_label": "Unsupported Claim",
        "reason": "Claim about the behavior of discriminator probabilities over sequence length lacks evidence or citation.",
        "start": 4039,
        "end": 4222
      },
      {
        "span_text": "When used in a myopic decoding strategy, classification errors will cause the generation process to deviate further and further.",
        "gpt_label": "Unsupported Claim",
        "reason": "Causal claim about error compounding in decoding requires supporting citation.",
        "start": 4224,
        "end": 4351
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "Few methods address the constrained textual generation.",
          "gpt_label": "Unsupported Claim",
          "reason": "Field-level claim about the scarcity of methods is presented without citations or evidence.",
          "start": 146,
          "end": 200
        },
        {
          "span_text": "This is an important limitation since the current trend in text generation is the use of large pre-trained model which can hardly be fine-tuned (for instance, the last version of GPT, GPT-3, cannot be fine-tuned without access to very large hardware resources).",
          "gpt_label": "Unsupported Claim",
          "reason": "Claims about the prevailing trend in the field and specific statements about GPT-3 fine-tuning requirements are made without citations.",
          "start": 1188,
          "end": 1448
        },
        {
          "span_text": "Discriminator-based methods alleviate the training cost problem, as discriminators are easier to train than a LM.",
          "gpt_label": "Unsupported Claim",
          "reason": "Comparative claim about training difficulty/cost lacks supporting references.",
          "start": 1840,
          "end": 1952
        },
        {
          "span_text": "However, in addition that beam search can miss sequences with high likelihood, it is biased towards the likelihood, while the best sequence might only have an average likelihood, but satisfies the constraint perfectly.",
          "gpt_label": "Unsupported Claim",
          "reason": "Assertions about beam search behavior and its bias require citations or empirical evidence.",
          "start": 2382,
          "end": 2599
        },
        {
          "span_text": "As some LM can only be used through access to logits (e.g. GPT-3 API)",
          "gpt_label": "Unsupported Claim",
          "reason": "Specific claim about API/model access constraints is made without a reference.",
          "start": 3820,
          "end": 3887
        },
        {
          "span_text": "A common drawback of all these approaches is their lack of a long-term vision of the  generation.",
          "gpt_label": "Unsupported Claim",
          "reason": "Generalized critique of prior methods is presented without citing supporting analyses or studies.",
          "start": 3942,
          "end": 4038
        },
        {
          "span_text": "Indeed, the discriminator probabilities become necessarily more meaningful as the sequence grows and might only be trustable to guide the search when the sequence is (nearly) finished.",
          "gpt_label": "Unsupported Claim",
          "reason": "Claim about the behavior of discriminator probabilities over sequence length lacks evidence or citation.",
          "start": 4039,
          "end": 4222
        },
        {
          "span_text": "When used in a myopic decoding strategy, classification errors will cause the generation process to deviate further and further.",
          "gpt_label": "Unsupported Claim",
          "reason": "Causal claim about error compounding in decoding requires supporting citation.",
          "start": 4224,
          "end": 4351
        }
      ]
    }
  },
  "paper_24.txt": {
    "filename": "paper_24.txt",
    "full_text": "Introduction\n\nMorality helps humans discern right from wrong. Pluralist moral philosophers argue that human morality can be represented, understood, and explained by a finite number of irreducible basic elements, referred to as moral values (Graham et al., 2013). The difference in our preferences over moral values explains how and why we think differently. For instance, both conservatives and liberals may agree that individual welfare is important. However, a conservative, who cherishes the values of freedom and independence, may believe that taxes should be decreased to attain more individual welfare. In contrast, a liberal, who cherishes the values of community and care, may believe that taxes should be increased to obtain welfare (Graham et al., 2009).\n\nIt is crucial to understand human morality to develop beneficial AI (Soares and Fallenstein, 2017;Russell, 2019). As artificial agents live and operate among humans (Akata et al., 2020), they must be able to comprehend and recognize the moral values that drive the differences in human behavior (Gabriel, 2020). The ability to understand moral rhetoric can be instrumental for, e.g., facilitating human-agent trust (Chhogyal et al., 2019;Mehrotra et al., 2021) and engineering value-aligned sociotechnical systems (Murukannaiah et al., 2020;Serramia et al., 2020;Montes and Sierra, 2021).\n\nThere are survey instruments to estimate individual value profiles (Schwartz, 2012;Graham et al., 2013). However, reasoning about moral values is challenging for humans (Le Dantec et al., 2009;Pommeranz et al., 2012). Further, in practical applications, e.g., to conduct meaningful conversations (Tigunova et al., 2019) or to identify online trends (Mooijman et al., 2018), artificial agents should be able to understand moral rhetoric on the fly.\n\nThe growing capabilities of natural language processing (NLP) enable the estimation of moral rhetoric from discourse Mooijman et al., 2018;Rezapour et al., 2019;Hoover et al., 2020;Araque et al., 2020). Value classifiers can be used to identify the moral values underlying a piece of text on the fly. For instance, Mooijman et al. (2018) show that detecting moral values from tweets can predict violent protests.\n\nExisting value classifiers are evaluated on a specific dataset, without re-training or testing the classifier on a different dataset. This shows the ability of the classifier to predict values from text, but not the ability to transfer the learned knowledge across datasets. A critical aspect of moral values is that they are intrinsically linked to the domain under discussion (Pommeranz et al., 2012;Liscio et al., 2021). Moral value expressions may take different forms in different domains. For example, in the driving domain, the value of safety concerns speed limits and seat belts, but in the COVID-19 domain, safety concerns social distancing and face masks. Thus, a word (broadly, language) may trigger different moral rhetoric in different domains. For example, in a libertarian blog, the word 'taxes' may be linked to the authority values, but in a socialist blog it may be linked to the community values. Then, it is crucial for a value classifier to recognize domain-specific connotations of moral rhetoric.\n\nCollecting and annotating a sufficient amount of training examples in each domain is expensive and time consuming. To reduce the need for new annotated examples, we can pretrain classifiers with similar available annotated data and transfer the acquired knowledge to a novel task-a practice known as transfer learning (Ruder, 2019). Despite the benefits, transfer learning poses wellknown challenges, including: (1) generalizability: how well does a classifier perform on novel data? (2) transferability: how well is knowledge transferred from one domain to another? and (3) catastrophic forgetting: to what extent is knowledge of a previous domain lost after training in a new domain? These challenges are crucial for value classification because of its domain-specific nature.\n\nWe perform the first comprehensive crossdomain evaluation of a value classifier. We employ the Moral Foundation Twitter Corpus (Hoover et al., 2020), consisting of seven datasets spanning different socio-political areas, annotated with the value taxonomy of the Moral Foundation Theory (Graham et al., 2013). Treating each dataset as a domain, we train a deep learning model (BERT Devlin et al. (2019)) in four training settings to evaluate the value classifier's generalizability, transferability, and catastrophic forgetting.\n\nOur experiments show that (1) a value classifier can generalize to novel domains, especially when trained on a varied array of domains, (2) initializing a classifier with examples from different domains improves performance in novel domains even when little training data is available in the novel domains, (3) catastrophic forgetting occurs even when training on a small portion of data from the novel domain, and its impact must be considered when training on a novel domain, and (4) in the large majority of cases, in all considered training settings, there is at least one annotator that agrees with the model predictions. These results provide insights to researchers and practitioners on estimating moral values in different domains.\n\n ",
    "all_spans": [
      {
        "span_text": "Existing value classifiers are evaluated on a specific dataset, without re-training or testing the classifier on a different dataset.",
        "gpt_label": "Unsupported Claim",
        "reason": "Asserts a characterization of prior work's evaluation practices without citing studies or surveys to support it.",
        "start": 2184,
        "end": 2316
      },
      {
        "span_text": "Despite the benefits, transfer learning poses wellknown challenges, including: (1) generalizability: how well does a classifier perform on novel data? (2) transferability: how well is knowledge transferred from one domain to another? and (3) catastrophic forgetting: to what extent is knowledge of a previous domain lost after training in a new domain?",
        "gpt_label": "Unsupported Claim",
        "reason": "Claims these challenges are well-known in the literature but provides no citations to transfer/continual learning works establishing them.",
        "start": 3527,
        "end": 3879
      },
      {
        "span_text": "We perform the first comprehensive crossdomain evaluation of a value classifier.",
        "gpt_label": "Unsupported Claim",
        "reason": "Novelty claim relative to prior work (being the first) lacks citations or evidence comparing to existing studies.",
        "start": 3973,
        "end": 4052
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "Existing value classifiers are evaluated on a specific dataset, without re-training or testing the classifier on a different dataset.",
          "gpt_label": "Unsupported Claim",
          "reason": "Asserts a characterization of prior work's evaluation practices without citing studies or surveys to support it.",
          "start": 2184,
          "end": 2316
        },
        {
          "span_text": "Despite the benefits, transfer learning poses wellknown challenges, including: (1) generalizability: how well does a classifier perform on novel data? (2) transferability: how well is knowledge transferred from one domain to another? and (3) catastrophic forgetting: to what extent is knowledge of a previous domain lost after training in a new domain?",
          "gpt_label": "Unsupported Claim",
          "reason": "Claims these challenges are well-known in the literature but provides no citations to transfer/continual learning works establishing them.",
          "start": 3527,
          "end": 3879
        },
        {
          "span_text": "We perform the first comprehensive crossdomain evaluation of a value classifier.",
          "gpt_label": "Unsupported Claim",
          "reason": "Novelty claim relative to prior work (being the first) lacks citations or evidence comparing to existing studies.",
          "start": 3973,
          "end": 4052
        }
      ]
    }
  },
  "paper_25.txt": {
    "filename": "paper_25.txt",
    "full_text": "Background\n\nContext freeness of natural languages\n\nThere has been a long debate, since the introduction of the Chomsky hierarchy (Chomsky, 1956), on whether all string patterns in natural language can be encompassed by the class of context-free grammars. The dispute often makes a distinction between weak and strong context-freeness, whereby the question shifts between generating all strings or all constituent expressions of a language. In Dutch specifically, patterns involving cross-serial dependencies have been commonly brought up by linguists in arguing that at least fragments of Dutch are context-sensitive, in turn designating the language not strongly context-free (Huybregts, 1984;Pullum and Gazdar, 1982;Bresnan et al., 1982;Shieber, 1985).\n\nTo capture such patterns without employing unnecessary computational expressiveness (and corresponding complexity), one can resort to the more pragmatic alternative of mildly context-sensitive grammars (Joshi, 1985): systems that can capture certain types of crossing dependencies, while remaining computationally tractable.\n\nMultiple Context-Free Grammars\n\nOne of the more general classes of mildly context-sensitive systems are multiple context-free grammars (MCFGs), which essentially generalizes the notion of a context-free grammars to operations on tuples of strings. We defer the reader to Seki et al. (1991) for a full definition and discussion of the properties of MCFGs. Instead we provide a simplified, computationally-oriented description that is more in line with our purposes and implementation. An m-multiple MCFG can be thought of as a tuple ⟨A, N , d, C, R, S 0 ⟩, where:\n\n• A is the terminal alphabet • N is a set of non-terminals and d : N → N a function from non-terminals to natural numbers; each non-terminal N is encoding a tuple of strings of fixed arity d(N) and the maximal arity of N decides the grammar's multiplicity • C is a mapping that associates each nonterminal N to a (possibly empty) set of elements from the d(N)-ary cartesian product N) ; put simply, the set of constants C N prescribes all the possible ways of initializing the non-terminal N • R a set of rewriting rules; rules are functions N × • • • × N → N that provide recipes on how to combine a number of non-terminals into a single non-terminal by rearranging and concetenating their contents; we will write:\n\nto denote a rule that combines non-terminals A and B of arities m and n into a non-terminal C of arity k, where each of the left-hand side coordinates x 1 , . . . y n is used exactly once in the right-hand side coordinates z 1 , . . . z k • S 0 the start symbol, a distinguished element of N satisfying d(S 0 ) = 1\n\nThe choice of MCFGs as our formal backbone comes due to their many advantages. Being a subtle but powerful generalization of CFGs, MCFGs have a familiar presentation that makes them easy to reason about, while remaining computationally tractable (Ljunglöf, 2012;Kallmeyer, 2010). At the same time, they offer an appealing dissociation between abstract and surface syntax and lexical choice. A derivation inspected purely on the level of rule type signatures takes the form of an abstract syntax tree that is reminiscent of a traditional CFG parse. Normalizing an MCFG so as to disallow rules from freely inserting constant strings (i.e. wrapping all constants under a non-terminal) allows us to (i) trace back all substrings of the final yield to a single non-terminal and (ii) provide a clear computational interpretation that casts an MCFG as a linear type system, and its derivation as a functional program (De Groote and Pogodalla, 2003).\n\n ",
    "all_spans": [
      {
        "span_text": "At the same time, they offer an appealing dissociation between abstract and surface syntax and lexical choice.",
        "gpt_label": "Unsupported Claim",
        "reason": "This makes a specific, evaluative claim about a technical property of MCFGs without providing a citation to support it.",
        "start": 2942,
        "end": 3051
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "At the same time, they offer an appealing dissociation between abstract and surface syntax and lexical choice.",
          "gpt_label": "Unsupported Claim",
          "reason": "This makes a specific, evaluative claim about a technical property of MCFGs without providing a citation to support it.",
          "start": 2942,
          "end": 3051
        }
      ]
    }
  },
  "paper_26.txt": {
    "filename": "paper_26.txt",
    "full_text": "Introduction\n\nFigure 1 shows the increase in travel to the ACL annual meeting over the past 40 years. Whereas conferences used to be the privilege of a few academics, they are now attended by participants from companies, research institutes and universities across the world. This comes with an increase in the total volume of work published, and with it an increase in the carbon emissions attributed to travelling to in-person events.\n\nIn this study we seek to quantify the impact of conferences that are increasingly diverse in terms of participation and location (undoubtedly beneficial) on the increased carbon emissions (undoubtedly detrimental). We base our analysis on publications spanning 55 years , taken from the ACL Anthology. We use NLP tools to parse each document and identify the locations of the conference venues and lead researcher's institution. We answer the following questions:\n\n1. Where is NLP research performed and presented?\n\n2. What are the environmental costs?\n\n3. Do conferences increase local participation?\n\n4. Which events attract a diverse audience and how do they compare to non-physical venues?\n\nTo the best of our knowledge, our work is the first to quantitatively explore the relationship between the location of conferences in a research field and diversity of participation. We make our dataset and code available to enable further discussion on the costs and benefits of in-person meetings.\n\n ",
    "all_spans": [
      {
        "span_text": "To the best of our knowledge, our work is the first to quantitatively explore the relationship between the location of conferences in a research field and diversity of participation.",
        "gpt_label": "Unsupported Claim",
        "reason": "This is a novelty claim about prior work; it asserts being the first without providing citations or evidence surveying existing literature.",
        "start": 1123,
        "end": 1304
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "To the best of our knowledge, our work is the first to quantitatively explore the relationship between the location of conferences in a research field and diversity of participation.",
          "gpt_label": "Unsupported Claim",
          "reason": "This is a novelty claim about prior work; it asserts being the first without providing citations or evidence surveying existing literature.",
          "start": 1123,
          "end": 1304
        }
      ]
    }
  },
  "paper_27.txt": {
    "filename": "paper_27.txt",
    "full_text": "Introduction\n\nGiven some text (typically, a sentence) t mentioning an entity pair (e 1 , e 2 ), the goal of relation extraction (RE) is to predict the relationships between e 1 and e 2 that can be inferred from t. Let B(e 1 , e 2 ) denote the set of all sentences (bag) in the corpus mentioning e 1 and e 2 and let R(e 1 , e 2 ) denote all relations from e 1 to e 2 in a KB. Distant supervision (DS) trains RE models given B(e 1 , e 2 ) and R(e 1 , e 2 ), without sentence level annotation (Mintz et al., 2009). Most DS-RE models use the \"at-least one\" assumption: ∀r ∈ R(e 1 , e 2 ), ∃t r ∈ B(e 1 , e 2 ) such that t r expresses (e 1 , r, e 2 ).\n\nRecent neural approaches to DS-RE encode each sentence t ∈ B(e 1 , e 2 ) and then aggregate sentence embeddings using an aggregation operator -the common operator being intra-bag attention (Lin et al., 2016). Various models differ in their approach to encoding (e.g., PCNNs, GCNs, BERT) and their loss functions (e.g., contrastive learning, MLM), but agree on the design choice of encoding each sentence independently of the others (Vashishth et al., 2018;Alt et al., 2019;Christou and Tsoumakas, 2021;Chen et al., 2021). We posit that this choice leads to a suboptimal usage of the available data -information from other sentences might help in better encoding a given sentence.\n\nWe explore this hypothesis by developing a simple baseline solution. We first construct a passage P (e 1 , e 2 ) by concatenating all sentences in B(e 1 , e 2 ). We then encode the whole passage through BERT (Devlin et al., 2019) (or mBERT for multilingual setting). This produces a contextualized embedding of every token in the bag. To make these embeddings aware of the candidate relation, we take a (trained) relation query vector, r, to generate a relation-aware summary of the whole passage using attention. This is then used to predict whether (e 1 , r, e 2 ) is a valid prediction.\n\nDespite its simplicity, our baseline has some conceptual advantages. First, each token is able to exchange information with other tokens from other sentences in the bag -so the embeddings are likely more informed. Second, in principle, the model may be able to relax a part of the at-least-one assumption. For example, if no sentence individually expresses a relation, but if multiple facts in different sentences collectively predict the relation, our model may be able to learn to extract that.\n\nWe name our baseline model Passage-Attended Relation Extraction, PARE (mPARE for multilingual DS-RE). We experiment on four DS-RE datasets -three in English, NYT-10d (Riedel et al., 2010), NYT-10m, and Wiki-20m (Gao et al., 2021), and one multilingual, DiS-ReX (Bhartiya et al., 2021). We find that in all four datasets, our proposed baseline significantly outperforms existing state of the art, yielding up to 5 point AUC gain. Further attention analysis and ablations provide additional insight into model performance. We release our code for reproducibility. We believe that our work represents a simple but strong baseline that can form the basis for further DS-RE research.\n\n ",
    "all_spans": [
      {
        "span_text": "Most DS-RE models use the \"at-least one\" assumption: ∀r ∈ R(e 1 , e 2 ), ∃t r ∈ B(e 1 , e 2 ) such that t r expresses (e 1 , r, e 2 ).",
        "gpt_label": "Unsupported Claim",
        "reason": "Asserts a widespread practice in prior work without citing supporting studies that adopt the at-least-one assumption.",
        "start": 508,
        "end": 641
      },
      {
        "span_text": "Recent neural approaches to DS-RE",
        "gpt_label": "Unsupported Claim",
        "reason": "Mentions “recent” works but does not cite specific approaches at this first mention, as required.",
        "start": 643,
        "end": 676
      },
      {
        "span_text": "the common operator being intra-bag attention",
        "gpt_label": "Unsupported Claim",
        "reason": "Claims prevalence across prior work; a single citation (Lin et al., 2016) does not substantiate that it is the common operator across recent models.",
        "start": 786,
        "end": 831
      },
      {
        "span_text": "PCNNs, GCNs",
        "gpt_label": "Unsupported Claim",
        "reason": "Named prior model families are mentioned without citations to representative papers introducing or using them in DS-RE.",
        "start": 907,
        "end": 918
      },
      {
        "span_text": "contrastive learning, MLM",
        "gpt_label": "Unsupported Claim",
        "reason": "Specific loss functions said to be used in prior work are listed without citing works that employ them for DS-RE.",
        "start": 956,
        "end": 981
      },
      {
        "span_text": "NYT-10m",
        "gpt_label": "Unsupported Claim",
        "reason": "Dataset is mentioned without a citation at its first mention.",
        "start": 2578,
        "end": 2585
      },
      {
        "span_text": "We find that in all four datasets, our proposed baseline significantly outperforms existing state of the art, yielding up to 5 point AUC gain.",
        "gpt_label": "Unsupported Claim",
        "reason": "Quantitative performance claim against state-of-the-art lacks citations identifying the SOTA methods and provides no immediate evidence.",
        "start": 2672,
        "end": 2813
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "Most DS-RE models use the \"at-least one\" assumption: ∀r ∈ R(e 1 , e 2 ), ∃t r ∈ B(e 1 , e 2 ) such that t r expresses (e 1 , r, e 2 ).",
          "gpt_label": "Unsupported Claim",
          "reason": "Asserts a widespread practice in prior work without citing supporting studies that adopt the at-least-one assumption.",
          "start": 508,
          "end": 641
        },
        {
          "span_text": "Recent neural approaches to DS-RE",
          "gpt_label": "Unsupported Claim",
          "reason": "Mentions “recent” works but does not cite specific approaches at this first mention, as required.",
          "start": 643,
          "end": 676
        },
        {
          "span_text": "the common operator being intra-bag attention",
          "gpt_label": "Unsupported Claim",
          "reason": "Claims prevalence across prior work; a single citation (Lin et al., 2016) does not substantiate that it is the common operator across recent models.",
          "start": 786,
          "end": 831
        },
        {
          "span_text": "PCNNs, GCNs",
          "gpt_label": "Unsupported Claim",
          "reason": "Named prior model families are mentioned without citations to representative papers introducing or using them in DS-RE.",
          "start": 907,
          "end": 918
        },
        {
          "span_text": "contrastive learning, MLM",
          "gpt_label": "Unsupported Claim",
          "reason": "Specific loss functions said to be used in prior work are listed without citing works that employ them for DS-RE.",
          "start": 956,
          "end": 981
        },
        {
          "span_text": "NYT-10m",
          "gpt_label": "Unsupported Claim",
          "reason": "Dataset is mentioned without a citation at its first mention.",
          "start": 2578,
          "end": 2585
        },
        {
          "span_text": "We find that in all four datasets, our proposed baseline significantly outperforms existing state of the art, yielding up to 5 point AUC gain.",
          "gpt_label": "Unsupported Claim",
          "reason": "Quantitative performance claim against state-of-the-art lacks citations identifying the SOTA methods and provides no immediate evidence.",
          "start": 2672,
          "end": 2813
        }
      ]
    }
  },
  "paper_28.txt": {
    "filename": "paper_28.txt",
    "full_text": "Related Work\n\nLearning from Imbalanced Data\n\nClass imbalance is a long-standing problem in machine learning tasks, posing challenges to researchers and practitioners in many domains (King and Zeng, 2001;Lu and Jain, 2003;He and Garcia, 2009;Moreo et al., 2016). Classes in real-world data often have highly skewed distribution, leading to substantial gaps between majority and minority classes. While the positive (minority) class is often of interest, the lack of positive examples makes classifiers conservative, i.e., they incline to predict all example as the negative (majority) class. This often results in a low recall of the positive class. Because only a small number of examples are predicted as positive, precision of the positive class tends to be high or unstable. Such a low-recall, high-precision pattern often hurts the F1-score, the standard metric that emphasizes a balanced precision and recall (Juba and Le, 2019). This performance pattern is observed not only in classification tasks, but also in NER tasks where named entity tokens are the minority compared to non-entity tokens (Mao et al., 2007;Kuperus et al., 2013).\n\nResearchers have proposed various techniques for imbalanced learning, including resampling and cost-sensitive learning (He and Ma, 2013). Both aim to re-balance the representation of different classes in the loss function, such that the classifier is less conservative in making positive predictions. In principle, by equating per-instance resampling frequency with per-instance cost, resampling can be implemented as cost-sensitive learning. However, resampling can be applied to models that do not support cost-sensitive learning, making it conveniently applicable to all models.\n\nResampling in Sequence Tagging Tasks\n\nResampling (and cost-sensitive learning) can be conveniently used in classification and regression tasks where a model makes pointwise predictions (a single categorical or scalar value). Each example has a clearly defined sampling rate (or cost) according to its class label. However, in sequence tagging tasks like NER (more broadly, structured prediction tasks (BakIr et al., 2007;Smith, 2011)), a model predicts multiple values for a sequence (or structured output). For sequence learning algorithms such as linear-chain conditional random fields, while the learning objective is formulated at the sequence level, the evaluation metrics are defined at the entity span level. This makes it nontrivial to determine the sampling rate (or cost) for a sequence that contains tokens from both majority and minority entity types. Simply resampling entities by stripping surrounding context is problematic as sequence tagging algorithms depend on context to make predictions. Recent works proposed to randomly or heuristically drop tokens from sentences to re-balance NER data, which had success using conditional random fields and shallow n-gram features (Akkasi, 2018;Akkasi and Varoglu, 2019;Grancharova et al., 2020). However, these methods distort the syntactic and semantic structure of complete sentences, which may generate low-quality data for models that are capable of capturing longdistance linguistic dependencies (e.g. BERT) and hurt performance of those models. In this work, we focus on resampling strategies that leaves sentences intact.\n\nLoss Functions for Imbalanced Data\n\nRecent literature proposed special loss functions for tackling data imbalance, including focal loss (Lin et al., 2017) and Dice loss (Li et al., 2019). They increase the cost of 'hard positives' where the correct label has low predicted probability and decrease the cost of 'easy negatives' where the correct label has high predicted probability. However, these loss functions do not fully address data imbalance in NER. First, the formulation does not always emphasize the loss of minority-class tokens -majority-class tokens can also be hard to classify, and minority-class tokens can also be easy to classify. Second, these loss functions only work on token-wise prediction outputs. They cannot work on sequence-level outputs generated by conditional random fields, which is commonly used in NER. Our resampling methods can be seen as estimating sentence-level losses with explicit emphasis on sentences containing minority-class tokens.\n\n ",
    "all_spans": [
      {
        "span_text": "Because only a small number of examples are predicted as positive, precision of the positive class tends to be high or unstable.",
        "gpt_label": "Unsupported Claim",
        "reason": "Makes a specific claim about precision behavior under class imbalance without citing empirical evidence or prior studies.",
        "start": 642,
        "end": 769
      },
      {
        "span_text": "However, resampling can be applied to models that do not support cost-sensitive learning, making it conveniently applicable to all models.",
        "gpt_label": "Unsupported Claim",
        "reason": "Asserts universal applicability (“to all models”) without supporting citations or evidence.",
        "start": 1571,
        "end": 1708
      },
      {
        "span_text": "However, these methods distort the syntactic and semantic structure of complete sentences, which may generate low-quality data for models that are capable of capturing longdistance linguistic dependencies (e.g. BERT) and hurt performance of those models.",
        "gpt_label": "Unsupported Claim",
        "reason": "Claims negative impact on sentence structure and performance of BERT-like models without citing studies demonstrating this effect.",
        "start": 2956,
        "end": 3207
      },
      {
        "span_text": "However, these loss functions do not fully address data imbalance in NER.",
        "gpt_label": "Unsupported Claim",
        "reason": "Evaluative claim about the inadequacy of prior methods lacks citations or empirical backing.",
        "start": 3665,
        "end": 3737
      },
      {
        "span_text": "Second, these loss functions only work on token-wise prediction outputs.",
        "gpt_label": "Unsupported Claim",
        "reason": "Categorical statement about the scope of focal/Dice loss applicability requires citation or justification.",
        "start": 3929,
        "end": 4000
      },
      {
        "span_text": "They cannot work on sequence-level outputs generated by conditional random fields, which is commonly used in NER.",
        "gpt_label": "Unsupported Claim",
        "reason": "Claims incompatibility with CRF outputs and that CRF is commonly used in NER without providing citations.",
        "start": 4001,
        "end": 4113
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "Because only a small number of examples are predicted as positive, precision of the positive class tends to be high or unstable.",
          "gpt_label": "Unsupported Claim",
          "reason": "Makes a specific claim about precision behavior under class imbalance without citing empirical evidence or prior studies.",
          "start": 642,
          "end": 769
        },
        {
          "span_text": "However, resampling can be applied to models that do not support cost-sensitive learning, making it conveniently applicable to all models.",
          "gpt_label": "Unsupported Claim",
          "reason": "Asserts universal applicability (“to all models”) without supporting citations or evidence.",
          "start": 1571,
          "end": 1708
        },
        {
          "span_text": "However, these methods distort the syntactic and semantic structure of complete sentences, which may generate low-quality data for models that are capable of capturing longdistance linguistic dependencies (e.g. BERT) and hurt performance of those models.",
          "gpt_label": "Unsupported Claim",
          "reason": "Claims negative impact on sentence structure and performance of BERT-like models without citing studies demonstrating this effect.",
          "start": 2956,
          "end": 3207
        },
        {
          "span_text": "However, these loss functions do not fully address data imbalance in NER.",
          "gpt_label": "Unsupported Claim",
          "reason": "Evaluative claim about the inadequacy of prior methods lacks citations or empirical backing.",
          "start": 3665,
          "end": 3737
        },
        {
          "span_text": "Second, these loss functions only work on token-wise prediction outputs.",
          "gpt_label": "Unsupported Claim",
          "reason": "Categorical statement about the scope of focal/Dice loss applicability requires citation or justification.",
          "start": 3929,
          "end": 4000
        },
        {
          "span_text": "They cannot work on sequence-level outputs generated by conditional random fields, which is commonly used in NER.",
          "gpt_label": "Unsupported Claim",
          "reason": "Claims incompatibility with CRF outputs and that CRF is commonly used in NER without providing citations.",
          "start": 4001,
          "end": 4113
        }
      ]
    }
  },
  "paper_11.txt": {
    "filename": "paper_11.txt",
    "full_text": "Introduction\n\nMultilingual models are critical for the democratization of AI. Cross-lingual information retrieval (CLIR) (Braschler et al., 1999;Shakery and Zhai, 2013;Jiang et al., 2020;Asai et al., 2021a), for example, can find relevant text in a high-resource language such as English even when the query is posed in a different, possibly low-resource, language. In this work, we develop useful CLIR models for this constrained, yet important, setting where a retrieval corpus is available only in a single high-resource language (English in our experiments).\n\nA straightforward solution to this problem can be based on machine translation (MT) of the query into English, followed by English IR (Asai et al., 2021a). While this two-stage process is capable of providing accurate predictions, an alternative end-to-end approach that can tackle the problem purely cross-lingually, i.e., without involving MT, would clearly be more efficient and cost-effective. Pre-trained multilingual masked language models (PLMs) such as multilingual BERT  or XLM-RoBERTa (XLM-R) (Conneau et al., 2020) can provide the foundation for such an approach, as one can simply fine-tune a PLM with labeled CLIR data (Asai et al., 2021b).\n\nHere we first run an empirical evaluation of these two approaches on a public CLIR benchmark (Asai et al., 2021a), which includes both in-domain and zero-shot out-of-domain tests. We use ColBERT (Khattab and Zaharia, 2020;Khattab et al., 2021) as our IR architecture 1 and XLM-R as the underlying PLM for both methods ( §2). Results indicate that the MT-based solution can be vastly more effective than CLIR fine-tuning, with observed differences in Recall@5kt of 22.2-28.6 points ( §3). Crucially, the modular design of the former allows it to leverage additional English-only training data for its IR component, providing significant boosts to its results.\n\nThe above findings lead naturally to the central research question of this paper: Can a highperformance CLIR model be trained that can operate without having to rely on MT? To answer the question, instead of viewing the MT-based approach as a competing one, we propose to leverage its strength via knowledge distillation (KD) into an end-to-end CLIR model. KD (Hinton et al., 2014) is a powerful supervision technique typically used to distill the knowledge of a large teacher model about some task into a smaller student model (Mukherjee and Awadallah, 2020;Turc et al., 2020). Here we propose to use it in a slightly different context, where the teacher and the student retriever are identical in size, but the former has superior performance simply due to utilizing MT output and consequently operating in a high-resource and lowdifficulty monolingual environment.\n\nWe run two independent KD operations ( §2.2). One directly optimizes an IR objective by utiliz- ing labeled CLIR data: parallel questions (English and non-English) and corresponding relevant and non-relevant English passages. The teacher and the student are shown the English and non-English versions of the questions, respectively; the training objective is for the student to match the soft query-passage relevance predictions of the teacher.\n\nThe second KD task is representation learning from parallel text, where the student learns to encode a non-English text in a way that matches the teacher's encoding of the aligned English text, at the token level. The cross-lingual token alignment needed to create the training data for this task is generated using a greedy alignment process that exploits the PLM's multilingual representations.\n\nIn our experiments on the XOR-TyDi dataset (Asai et al., 2021a), the KD student outperforms the fine-tuned ColBERT baseline by 25.4 (in-domain) and 14.9 (zero-shot) Recall@5kt, recovering much of the performance loss from the MT-based solution. It is also the best single-model system on the XOR-TyDi leaderboard 2 at the time of this writing. Ablation studies show that each of our two KD processes contribute significantly towards the final performance of the student model.\n\nOur contributions can be summarized as follows:\n\n(1) We present an empirical study of the effectiveness of a SOTA IR method (ColBERT) on crosslingual IR with and without MT.\n(2) We propose a novel end-to-end cross-lingual solution that uses knowledge distillation to learn both improved text representation and retrieval. \n(3) We demonstrate with a new cross-lingual alignment algorithm that distillation using parallel text can strongly augment cross-lingual IR training. \n(4) We achieve new single-model SOTA results on XOR-TyDi.\n\n ",
    "all_spans": [
      {
        "span_text": "Multilingual models are critical for the democratization of AI.",
        "gpt_label": "Unsupported Claim",
        "reason": "Broad field-level importance claim without any citation or evidence.",
        "start": 14,
        "end": 76
      },
      {
        "span_text": "would clearly be more efficient and cost-effective.",
        "gpt_label": "Unsupported Claim",
        "reason": "Efficiency and cost-effectiveness assertion about an alternative approach is made without citation or supporting evidence.",
        "start": 900,
        "end": 950
      },
      {
        "span_text": "multilingual BERT",
        "gpt_label": "Unsupported Claim",
        "reason": "First mention of a specific model lacks a citation to the original work introducing multilingual BERT.",
        "start": 1014,
        "end": 1031
      },
      {
        "span_text": "(4) We achieve new single-model SOTA results on XOR-TyDi.",
        "gpt_label": "Unsupported Claim",
        "reason": "State-of-the-art claim about results on a dataset is made without citing competing methods or providing comparative evidence here.",
        "start": 4502,
        "end": 4558
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "Multilingual models are critical for the democratization of AI.",
          "gpt_label": "Unsupported Claim",
          "reason": "Broad field-level importance claim without any citation or evidence.",
          "start": 14,
          "end": 76
        },
        {
          "span_text": "would clearly be more efficient and cost-effective.",
          "gpt_label": "Unsupported Claim",
          "reason": "Efficiency and cost-effectiveness assertion about an alternative approach is made without citation or supporting evidence.",
          "start": 900,
          "end": 950
        },
        {
          "span_text": "multilingual BERT",
          "gpt_label": "Unsupported Claim",
          "reason": "First mention of a specific model lacks a citation to the original work introducing multilingual BERT.",
          "start": 1014,
          "end": 1031
        },
        {
          "span_text": "(4) We achieve new single-model SOTA results on XOR-TyDi.",
          "gpt_label": "Unsupported Claim",
          "reason": "State-of-the-art claim about results on a dataset is made without citing competing methods or providing comparative evidence here.",
          "start": 4502,
          "end": 4558
        }
      ]
    }
  },
  "paper_13.txt": {
    "filename": "paper_13.txt",
    "full_text": "Introduction\n\nFew-shot learning is the problem of learning classifiers with only a few training examples. Zero-shot learning (Larochelle et al., 2008), also known as dataless classification (Chang et al., 2008), is the extreme case, in which no labeled data is used. For text data, this is usually accomplished by representing the labels of the task in a textual form, which can either be the name of the label or a concise textual description.\n\nIn recent years, there has been a surge in zeroshot and few-shot approaches to text classification. One approach (Yin et al., 2019, 2020; Halder et al., 2020;Wang et al., 2021) makes use of entailment models. Textual entailment (Dagan et al., 2006), also known as natural language inference (NLI) (Bowman et al., 2015), is the problem of predicting whether a textual premise implies a textual hypothesis in a logical sense. For example, Emma loves apples implies that Emma likes apples.\n\nThe entailment approach for text classification sets the input text as the premise and the text repre-senting the label as the hypothesis. A NLI model is applied to each input pair and the entailment probability is used to identify the best matching label.\n\nIn this paper, we investigate an alternative based on Siamese Networks (SN) (Bromley et al., 1993), also known as dual encoders. These models embed both input and label texts into a common vector space. The similarity of the two items can then be computed using a similarity function such as the dot product. The advantage is that input and label text are encoded independently, which means that the label embeddings can be pre-computed. Therefore, at inference time, only a single call to the model per input is needed. In contrast, the models typically applied in the entailment approach are Cross Attention (CA) models which need to be executed for every combination of text and label. On the other hand, they allow for interaction between the tokens of label and input, so that in theory they should be superior in classification accuracy. However, in this work we show that in practice, the difference in quality is small.\n\nBoth CA and SNs also support the few-shot learning setup by fine-tuning the models on a small number of labeled examples. This is usually done by updating all parameters of the model, which in turn makes it impossible to share the models between different tasks. In this work, we show that when using a SN, one can decide to only fine-tune the label embeddings. We call this Label Tuning (LT). With LT the encoder can be shared between different tasks, which greatly eases the deployment of this approach in a production setup. LT comes with a certain drop in quality, but this drop can be compensated by using a variant of knowledge distillation (Hinton et al., 2014).\n\nOur contributions are as follows: We perform a large study on a diverse set of tasks showing that CA models and SN yield similar performance for both zero-shot and few-shot text classification.  (LT). At training time, input and label texts (hypotheses) are processed by the encoder. LT then tunes the labels using a cross entropy (CE) loss. At inference time, the input text is passed through the same encoder. The tuned label embeddings and a similarity function are then used to score each label. The encoder remains unchanged and can be shared between multiple tasks.\n\nIn contrast to most prior work, we also show that these results can also be achieved for languages other than English. We compare the hypothesis patterns commonly used in the literature and using the plain label name (null hypothesis) and find that on average there is no significant difference in performance. Finally, we present LT as an alternative to full fine-tuning that allows using the same model for many tasks and thus greatly increases the scalability of the method. We will release the code and trained models used in our experiments.\n\n ",
    "all_spans": [
      {
        "span_text": "For text data, this is usually accomplished by representing the labels of the task in a textual form, which can either be the name of the label or a concise textual description.",
        "gpt_label": "Unsupported Claim",
        "reason": "Makes a field-wide generalization about the standard approach to zero-shot text classification without citing supporting prior work.",
        "start": 263,
        "end": 439
      },
      {
        "span_text": "In recent years, there has been a surge in zeroshot and few-shot approaches to text classification.",
        "gpt_label": "Unsupported Claim",
        "reason": "Claims a trend in the literature without providing citations to representative works.",
        "start": 441,
        "end": 539
      },
      {
        "span_text": "In contrast, the models typically applied in the entailment approach are Cross Attention (CA) models which need to be executed for every combination of text and label.",
        "gpt_label": "Unsupported Claim",
        "reason": "Asserts what is typically used in prior work without citing specific studies to support the claim.",
        "start": 1691,
        "end": 1857
      },
      {
        "span_text": "In contrast to most prior work, we also show that these results can also be achieved for languages other than English.",
        "gpt_label": "Unsupported Claim",
        "reason": "Makes a comparative claim about the scope of prior work (mostly English) without citing evidence.",
        "start": 3326,
        "end": 3443
      },
      {
        "span_text": "We compare the hypothesis patterns commonly used in the literature",
        "gpt_label": "Unsupported Claim",
        "reason": "References common practices in prior literature without citing exemplar papers that use these patterns.",
        "start": 3444,
        "end": 3510
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "For text data, this is usually accomplished by representing the labels of the task in a textual form, which can either be the name of the label or a concise textual description.",
          "gpt_label": "Unsupported Claim",
          "reason": "Makes a field-wide generalization about the standard approach to zero-shot text classification without citing supporting prior work.",
          "start": 263,
          "end": 439
        },
        {
          "span_text": "In recent years, there has been a surge in zeroshot and few-shot approaches to text classification.",
          "gpt_label": "Unsupported Claim",
          "reason": "Claims a trend in the literature without providing citations to representative works.",
          "start": 441,
          "end": 539
        },
        {
          "span_text": "In contrast, the models typically applied in the entailment approach are Cross Attention (CA) models which need to be executed for every combination of text and label.",
          "gpt_label": "Unsupported Claim",
          "reason": "Asserts what is typically used in prior work without citing specific studies to support the claim.",
          "start": 1691,
          "end": 1857
        },
        {
          "span_text": "In contrast to most prior work, we also show that these results can also be achieved for languages other than English.",
          "gpt_label": "Unsupported Claim",
          "reason": "Makes a comparative claim about the scope of prior work (mostly English) without citing evidence.",
          "start": 3326,
          "end": 3443
        },
        {
          "span_text": "We compare the hypothesis patterns commonly used in the literature",
          "gpt_label": "Unsupported Claim",
          "reason": "References common practices in prior literature without citing exemplar papers that use these patterns.",
          "start": 3444,
          "end": 3510
        }
      ]
    }
  },
  "paper_14.txt": {
    "filename": "paper_14.txt",
    "full_text": "Introduction\n\nAt present, for a large majority of natural language processing tasks, the most successful approach is fine-tuning pre-trained models with task-specific labelled data. Unfortunately, for many languages, and especially low-resource languages, such taskspecific labelled data is often not available. A potential solution is cross-lingual fine-tuning of multilingual pre-trained language models (Conneau et al., 2020;Devlin et al., 2018), using available data from some source language to model the phenomenon in a different target language for which labelled data does not exist.\n\nCross-lingual generalisability of large pretrained language models is often evaluated by finetuning multilingual models on English data and testing them on unseen languages (Conneau et al., 2018;Artetxe et al., 2020;Lewis et al., 2020;Hu et al., 2020). Of course, this approach is influenced by the availability of English training data for given tasks, but also then comes with the implicit assumption that English is a representative source language. This, however, may not be true in practice. Specifically, depending on the task, aspects of similarity between source and target language may be relevant for cross-lingual transfer performance (de Vries et al., 2021). If similarity between source and target language impacts performance, crosslingual transfer should not be assessed using only a single predetermined source language, especially if training sets in multiple languages are available.\n\nFurthermore, target test languages are generally selected based on data availability for the evaluated tasks, but availability may not result in a representative subset of the world's languages. The XTreme benchmark collection (Hu et al., 2020), for example, attempts to alleviate this problem by including a varied selection of languages from different language families. This collection contains token classification, text classification, question answering and retrieval tasks in 40 languages. The language selection does, however, obfuscate the fact that for most non-Indo-European and low-resource languages no data is available for semantically rich tasks such as question answering. This imbalance regarding tasks in this type of collections may consequently inflate the perceived performance for these languages.\n\nIn this work, we aim to shed light on what factors make a language a good source and/or target language for cross-lingual transfer when fine-tuning a large multilingual model. We evaluate this via partof-speech (POS) tagging data, as this is the only task for which high-quality data is available in a large number of languages, including low-resource languages from different language families. Also, high cross-lingual POS tagging performance may be seen as a precondition for more semantically complex tasks, as a base understanding of syntactic structure in both the source and target language is necessary for any meaningful natural language processing task.\n\nContributions This paper is a case-study of cross-lingual transfer learning with part-of-speech tagging. We explore the limits and contributing factors to successful cross-lingual transfer and partof-speech tagging in particular. Among others, we evaluate the effects of (matching) language families, (matching) writing systems, and pre-training on cross-lingual training. Moreover, we provide insights that can help to estimate performance when one tries to transfer to a low-resource language with little or no annotated data. Source code will be released on Github, and 65 fine-tuned models will be shared via the Hugging Face Model Hub.\n\n ",
    "all_spans": [
      {
        "span_text": "At present, for a large majority of natural language processing tasks, the most successful approach is fine-tuning pre-trained models with task-specific labelled data.",
        "gpt_label": "Unsupported Claim",
        "reason": "Makes a broad claim about the state of the field without citing surveys or empirical evidence.",
        "start": 14,
        "end": 180
      },
      {
        "span_text": "Unfortunately, for many languages, and especially low-resource languages, such taskspecific labelled data is often not available.",
        "gpt_label": "Unsupported Claim",
        "reason": "Asserts scarcity of labeled data across languages without supporting references or statistics.",
        "start": 181,
        "end": 309
      },
      {
        "span_text": "Furthermore, target test languages are generally selected based on data availability for the evaluated tasks, but availability may not result in a representative subset of the world's languages.",
        "gpt_label": "Unsupported Claim",
        "reason": "Claims a common practice in evaluation and its representativeness without evidence or citations to benchmark design studies.",
        "start": 1481,
        "end": 1674
      },
      {
        "span_text": "The language selection does, however, obfuscate the fact that for most non-Indo-European and low-resource languages no data is available for semantically rich tasks such as question answering.",
        "gpt_label": "Unsupported Claim",
        "reason": "States a strong quantitative claim (“for most”) about data availability without providing citations or empirical support.",
        "start": 1974,
        "end": 2165
      },
      {
        "span_text": "We evaluate this via partof-speech (POS) tagging data, as this is the only task for which high-quality data is available in a large number of languages, including low-resource languages from different language families.",
        "gpt_label": "Unsupported Claim",
        "reason": "Asserts exclusivity (“the only task”) and widespread availability of high-quality POS data without citing datasets or surveys.",
        "start": 2472,
        "end": 2690
      },
      {
        "span_text": "Also, high cross-lingual POS tagging performance may be seen as a precondition for more semantically complex tasks, as a base understanding of syntactic structure in both the source and target language is necessary for any meaningful natural language processing task.",
        "gpt_label": "Unsupported Claim",
        "reason": "Makes a normative, field-wide necessity claim without references supporting the dependency of semantic tasks on POS performance.",
        "start": 2691,
        "end": 2957
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "At present, for a large majority of natural language processing tasks, the most successful approach is fine-tuning pre-trained models with task-specific labelled data.",
          "gpt_label": "Unsupported Claim",
          "reason": "Makes a broad claim about the state of the field without citing surveys or empirical evidence.",
          "start": 14,
          "end": 180
        },
        {
          "span_text": "Unfortunately, for many languages, and especially low-resource languages, such taskspecific labelled data is often not available.",
          "gpt_label": "Unsupported Claim",
          "reason": "Asserts scarcity of labeled data across languages without supporting references or statistics.",
          "start": 181,
          "end": 309
        },
        {
          "span_text": "Furthermore, target test languages are generally selected based on data availability for the evaluated tasks, but availability may not result in a representative subset of the world's languages.",
          "gpt_label": "Unsupported Claim",
          "reason": "Claims a common practice in evaluation and its representativeness without evidence or citations to benchmark design studies.",
          "start": 1481,
          "end": 1674
        },
        {
          "span_text": "The language selection does, however, obfuscate the fact that for most non-Indo-European and low-resource languages no data is available for semantically rich tasks such as question answering.",
          "gpt_label": "Unsupported Claim",
          "reason": "States a strong quantitative claim (“for most”) about data availability without providing citations or empirical support.",
          "start": 1974,
          "end": 2165
        },
        {
          "span_text": "We evaluate this via partof-speech (POS) tagging data, as this is the only task for which high-quality data is available in a large number of languages, including low-resource languages from different language families.",
          "gpt_label": "Unsupported Claim",
          "reason": "Asserts exclusivity (“the only task”) and widespread availability of high-quality POS data without citing datasets or surveys.",
          "start": 2472,
          "end": 2690
        },
        {
          "span_text": "Also, high cross-lingual POS tagging performance may be seen as a precondition for more semantically complex tasks, as a base understanding of syntactic structure in both the source and target language is necessary for any meaningful natural language processing task.",
          "gpt_label": "Unsupported Claim",
          "reason": "Makes a normative, field-wide necessity claim without references supporting the dependency of semantic tasks on POS performance.",
          "start": 2691,
          "end": 2957
        }
      ]
    }
  },
  "paper_15.txt": {
    "filename": "paper_15.txt",
    "full_text": "Related Work\n\nMultimodal machine translation is a cross-domain task in the filed of machine translation. Early attempts mainly focused on enhancing the MMT model by better incorporation of the vision features (Calixto and Liu, 2017;Elliott and Kádár, 2017;Delbrouck and Dupont, 2017). However, directly encoding the whole image feature brings additional noise to the text (Yao and Wan, 2020;Liu et al., 2021a). To address the above issue, Yao and Wan (2020) proposed a multimodal self-attention to consider the relative difference of information between two modalities. Similarly, Liu et al. (2021a) used a Gumbel Softmax to achieve the same goal.\n\nResearchers also realize that the vision modality maybe redundant. Irrelevant images have little impact on the translation quality, and no significant BLEU drop is observed even the image is absent (Elliott, 2018). Encouraging results appeared in  2021) proposed a cross-lingual visual pretraining approach. In this work, we make a systematic study on whether stronger vision features are helpful. We also extend the research to enhanced features, such as object-detection and image captioning, which is complementary to previous work.\n\n ",
    "all_spans": [
      {
        "span_text": "Researchers also realize that the vision modality maybe redundant.",
        "gpt_label": "Unsupported Claim",
        "reason": "General claim about consensus in prior work lacks a supporting citation at first mention.",
        "start": 642,
        "end": 707
      },
      {
        "span_text": "Encouraging results appeared in  2021) proposed a cross-lingual visual pretraining approach.",
        "gpt_label": "Unsupported Claim",
        "reason": "Mentions a study and its results without a proper citation (authors/details missing) and provides no evidence.",
        "start": 855,
        "end": 946
      },
      {
        "span_text": "which is complementary to previous work.",
        "gpt_label": "Unsupported Claim",
        "reason": "Asserts a relationship to prior work without citing which works or providing evidence.",
        "start": 1133,
        "end": 1172
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "Researchers also realize that the vision modality maybe redundant.",
          "gpt_label": "Unsupported Claim",
          "reason": "General claim about consensus in prior work lacks a supporting citation at first mention.",
          "start": 642,
          "end": 707
        },
        {
          "span_text": "Encouraging results appeared in  2021) proposed a cross-lingual visual pretraining approach.",
          "gpt_label": "Unsupported Claim",
          "reason": "Mentions a study and its results without a proper citation (authors/details missing) and provides no evidence.",
          "start": 855,
          "end": 946
        },
        {
          "span_text": "which is complementary to previous work.",
          "gpt_label": "Unsupported Claim",
          "reason": "Asserts a relationship to prior work without citing which works or providing evidence.",
          "start": 1133,
          "end": 1172
        }
      ]
    }
  },
  "paper_16.txt": {
    "filename": "paper_16.txt",
    "full_text": "Related Work\n\nTo facilitate the study of text summarization, earlier datasets are mostly in the news domain with relatively short input passages, such as NYT (Sandhaus, 2008), Gigaword (Napoles et al., 2012), CNN/Daily Mail (Hermann et al., 2015), NEWSROOM (Grusky et al., 2018) and XSUM (Narayan et al., 2018). Datasets for long docu-ments include Sharma et al. (2019), Cohan et al. (2018), andFisas et al. (2016). In this paper, we explore text summarization in a new domain (i.e., the peer review domain) and provide a new dataset, i.e., MReD. Moreover, MReD's reference summaries (i.e., meta-reviews) are fully annotated and thus allow us to propose a new task, namely structurecontrollable text generation.\n\nResearchers recently explore the peer review domain data for a few tasks, such as PeerRead (Kang et al., 2018) for paper decision predictions, AM-PERE  for proposition classification in reviews, and RR (Cheng et al., 2020) for paired-argument extraction from review-rebuttal pairs. Additionally, a meta-review dataset is introduced by Bhatia et al. (2020) without any annotation. There are also some explorations on research articles (Teufel et al., 1999;Liakata et al., 2010;Lauscher et al., 2018), which differ in nature from the peer review domain.\n\nA wide range of control perspectives has been explored in controllable generation, including style control (e.g., sentiments (Duan et al., 2020), politeness (Madaan et al., 2020), formality , domains (Takeno et al., 2017) and persona ) and content control (e.g., length (Duan et al., 2020), entities (Fan et al., 2018a), and keywords (Tang et al., 2019)). Our structure-controlled generation differs from these works as we control the high-level output structure, rather than the specific styles or the surface details of which keywords to include in the generated output. Our task also differs from content planning (Reiter and Dale, 1997;Shao et al., 2019;, which involves explicitly selecting and arranging the input content. Instead, we provide the model with the high-level control labels, and let the model decide on its own the relevant styles and contents.\n\n ",
    "all_spans": [
      {
        "span_text": "AM-PERE  for proposition classification in reviews",
        "gpt_label": "Unsupported Claim",
        "reason": "Mentions a specific dataset/task (AM-PERE) without providing a citation at its first mention.",
        "start": 838,
        "end": 888
      },
      {
        "span_text": "formality",
        "gpt_label": "Unsupported Claim",
        "reason": "Claims prior work on formality control but provides no citation for this control dimension.",
        "start": 1416,
        "end": 1425
      },
      {
        "span_text": "persona",
        "gpt_label": "Unsupported Claim",
        "reason": "Claims prior work on persona control but provides no citation for this control dimension.",
        "start": 1461,
        "end": 1468
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "AM-PERE  for proposition classification in reviews",
          "gpt_label": "Unsupported Claim",
          "reason": "Mentions a specific dataset/task (AM-PERE) without providing a citation at its first mention.",
          "start": 838,
          "end": 888
        },
        {
          "span_text": "formality",
          "gpt_label": "Unsupported Claim",
          "reason": "Claims prior work on formality control but provides no citation for this control dimension.",
          "start": 1416,
          "end": 1425
        },
        {
          "span_text": "persona",
          "gpt_label": "Unsupported Claim",
          "reason": "Claims prior work on persona control but provides no citation for this control dimension.",
          "start": 1461,
          "end": 1468
        }
      ]
    }
  },
  "paper_17.txt": {
    "filename": "paper_17.txt",
    "full_text": "Related Work\n\nFully supervised event extraction. Event extraction has been studied for over a decade (Ahn, 2006;Ji and Grishman, 2008) and most traditional event extraction works follow the fully supervised setting (Nguyen et al., 2016;Sha et al., 2018;Nguyen and Nguyen, 2019;Yang et al., 2019;Lin et al., 2020;Li et al., 2020). Many of them use classification-based models and use pipeline-style frameworks to extract events (Nguyen et al., 2016;Yang et al., 2019;Wadden et al., 2019). To better leverage shared knowledge in event triggers and arguments, some works propose to incorporate global features to jointly decide triggers and arguments (Lin et al., 2020;Li et al., 2013;Yang and Mitchell, 2016). Recently, few generation-based event extraction models have been proposed. TANL (Paolini et al., 2021) treats event extraction as translation tasks between augmented natural languages. Their predicted targetaugmented language embed labels into the input passage via using brackets and vertical bar symbols, hindering the model from fully leveraging label semantics. BART-Gen  is also a generation-based model focusing on documentlevel event argument extraction. Yet, similar to TANL, they solve event extraction with a pipeline, which prevents knowledge sharing across subtasks. All these fully supervised methods can achieve substantial performance with a large amount of annotated data. However, their designs are not specific for low-resource scenarios, hence, these models can not enjoy all the benefits that DEGREE obtains for low-resource event extraction at the same time, as we mentioned in Section 1.\n\nLow-resource event extraction. It has been a rising interest in event extraction under less data scenario. Liu et al. (2020) uses a machine reading comprehension formulation to conduct event extraction in a low-resource regime. Text2Event (Lu et al., 2021), a sequence-to-structure generation paradigm, first presents events in a linearized format, and then trains a generative model to generate the linearized event sequence. Text2Event's unnatural output format hinders the model from fully leveraging pre-trained knowledge. Hence, their model falls short on the cases with only extremely low data being available (as shown in Section 3).\n\nAnother thread of works are using meta-learning to deal with the less label challenge (Deng et al., 2020;Shen et al., 2021;Cong et al., 2021). However, their methods can only be applied to event detection, which differs from our main focus on studying end-to-end event extraction.\n\n ",
    "all_spans": [
      {
        "span_text": "Recently, few generation-based event extraction models have been proposed.",
        "gpt_label": "Unsupported Claim",
        "reason": "Claims the existence of recent works without providing citations; mentions of 'recently/few models' should be backed by references.",
        "start": 694,
        "end": 767
      },
      {
        "span_text": "BART-Gen  is also a generation-based model focusing on documentlevel event argument extraction.",
        "gpt_label": "Unsupported Claim",
        "reason": "First mention of a specific prior work lacks a citation, which is required when introducing a study or model.",
        "start": 1056,
        "end": 1150
      },
      {
        "span_text": "Yet, similar to TANL, they solve event extraction with a pipeline, which prevents knowledge sharing across subtasks.",
        "gpt_label": "Unsupported Claim",
        "reason": "Attributes specific methodology and limitations to a prior work (implicitly BART-Gen) without citing the source to support the claim.",
        "start": 1151,
        "end": 1266
      },
      {
        "span_text": "It has been a rising interest in event extraction under less data scenario.",
        "gpt_label": "Unsupported Claim",
        "reason": "Trend/interest claim about the field is not supported with citations to representative works or surveys.",
        "start": 1627,
        "end": 1701
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "Recently, few generation-based event extraction models have been proposed.",
          "gpt_label": "Unsupported Claim",
          "reason": "Claims the existence of recent works without providing citations; mentions of 'recently/few models' should be backed by references.",
          "start": 694,
          "end": 767
        },
        {
          "span_text": "BART-Gen  is also a generation-based model focusing on documentlevel event argument extraction.",
          "gpt_label": "Unsupported Claim",
          "reason": "First mention of a specific prior work lacks a citation, which is required when introducing a study or model.",
          "start": 1056,
          "end": 1150
        },
        {
          "span_text": "Yet, similar to TANL, they solve event extraction with a pipeline, which prevents knowledge sharing across subtasks.",
          "gpt_label": "Unsupported Claim",
          "reason": "Attributes specific methodology and limitations to a prior work (implicitly BART-Gen) without citing the source to support the claim.",
          "start": 1151,
          "end": 1266
        },
        {
          "span_text": "It has been a rising interest in event extraction under less data scenario.",
          "gpt_label": "Unsupported Claim",
          "reason": "Trend/interest claim about the field is not supported with citations to representative works or surveys.",
          "start": 1627,
          "end": 1701
        }
      ]
    }
  },
  "paper_18.txt": {
    "filename": "paper_18.txt",
    "full_text": "Introduction\n\nNamed entity recognition (NER) aims at identifying text spans pertaining to specific entity types. It plays an important role in many downstream tasks such as relation extraction (Ji et al., 2017), entity linking (Sevgili et al., 2020), co-reference resolution (Clark and Manning, 2016), and knowledge graph (Ji et al., 2020). Due to the complex composition (Gui et al., 2019), character-level Chinese NER is more challenging compared to English NER. As shown in Figure 1 (a), the middle charac-  ter \"流\" can constitute words with the characters to both their left and their right, such as \"河流 (River)\" and \"流经 (flows)\", leading to ambiguous character boundaries.\n\nThere are two typical frameworks for NER. The first one conceptualizes NER as a sequence labeling task (Huang et al., 2015;Lample et al., 2016;Ma and Hovy, 2016), where each character is assigned to a special label (e.g., B-LOC, I-LOC). The second one is span-based method (Li et al., 2020a;, which classifies candidate spans based on their span-level representations. However, despite the success of these two types of methods, they do not explicitly take the complex composition of Chinese NER into consideration. Recently, several works (Zhang and Yang, 2018;Gui et al., 2019;Li et al., 2020b) utilize external lexicon knowledge to help connect related characters and promote capturing the local composition. Nevertheless, building the lexicon is time-consuming and the quality of the lexicon may not be satisfied.\n\nIn contrast to previous works, we observe that the regularity exists in the common NER types (e.g., ORG and LOC). As shown in Figure 1 (a), \"尼日尔河 (Niger River)\" follows the specific composition pattern \"XX+河 (XX + River)\" which ends with indicator character \"河\" and mostly belongs to location type, and the ambiguous character \"流\" can properly constitute \"流经\" with the right character \"经\". Thus, the regularity information serves as important clues for entity type recognition and identifying the character composition. Formally, we refer to regularity as specific internal patterns contained in a type of entity (Lin et al., 2020). However, too immersed regularity leads to unfavorable boundary detection of entities and disturbing character composition. As shown in Figure 1 (b), \"中国队 (Chinese team)\" conforms to the pattern \"XX+队 (XX + Team)\", but the correct entity boundary should be \"中国 (Chinese)\" and \"队员 (players)\" according to the context. Therefore, the context also plays a key role in determining the character boundary.\n\nIn this paper, we introduce a simple but effective method to explore the regularity information of entity spans for Chinese NER, dubbed as Regularity-Inspired reCOgnition Network (RICON). The proposed model consists of two branches named regularity-aware module and regularity-agnostic module, where each module has task-specific encoder and optimization object. Concretely, the regularity-aware module aims at analyzing the internal regularity of each span and integrates the significant regularity information into the corresponding span-level representation, leading to precise entity type prediction. Meanwhile, the regularityagnostic module is devised to capture context information and avoid excessive focus on intra-span regularity. Furthermore, we adopt an orthogonality space restriction to encourage two branches to extract different features with regard to the regularity. To verify the effectiveness of our method, we conduct extensive experiments on three large-scale benchmark datasets (OntoNotes V4.0, OntoNotes V5.0, and MSRA). The results show that RICON achieves considerable improvements compared to the state-of-the-art models, even outperforming existing lexicon-based models. Moreover, we experiment on a practical medical dataset (CBLUE) to further demonstrate the ability of RICON.\n\nOur contributions can be summarized as follows:\n\n• This is the first work that explicitly explores the internal regularity of entity mentions for Chinese NER.\n\n• We propose a simple but effective method for Chinese NER, which effectively utilizes regularity information while avoiding excessive focus on intra-span regularity.\n\n• Extensive experiments on three large-scale benchmark datasets and a practical medical dataset demonstrate the effectiveness of our proposed method.\n\n ",
    "all_spans": [
      {
        "span_text": "the quality of the lexicon may not be satisfied.",
        "gpt_label": "Unsupported Claim",
        "reason": "Asserts a limitation of lexicon resources without citing evidence or prior studies documenting quality issues.",
        "start": 1428,
        "end": 1475
      },
      {
        "span_text": "three large-scale benchmark datasets (OntoNotes V4.0, OntoNotes V5.0, and MSRA)",
        "gpt_label": "Unsupported Claim",
        "reason": "First mention of specific datasets should be accompanied by citations to their original sources.",
        "start": 3459,
        "end": 3536
      },
      {
        "span_text": "a practical medical dataset (CBLUE)",
        "gpt_label": "Unsupported Claim",
        "reason": "First mention of a specific dataset requires a citation to its original description.",
        "start": 3717,
        "end": 3752
      },
      {
        "span_text": "This is the first work that explicitly explores the internal regularity of entity mentions for Chinese NER.",
        "gpt_label": "Unsupported Claim",
        "reason": "Novelty claim about being the first in the literature is not supported with citations or comparative references.",
        "start": 3849,
        "end": 3955
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "the quality of the lexicon may not be satisfied.",
          "gpt_label": "Unsupported Claim",
          "reason": "Asserts a limitation of lexicon resources without citing evidence or prior studies documenting quality issues.",
          "start": 1428,
          "end": 1475
        },
        {
          "span_text": "three large-scale benchmark datasets (OntoNotes V4.0, OntoNotes V5.0, and MSRA)",
          "gpt_label": "Unsupported Claim",
          "reason": "First mention of specific datasets should be accompanied by citations to their original sources.",
          "start": 3459,
          "end": 3536
        },
        {
          "span_text": "a practical medical dataset (CBLUE)",
          "gpt_label": "Unsupported Claim",
          "reason": "First mention of a specific dataset requires a citation to its original description.",
          "start": 3717,
          "end": 3752
        },
        {
          "span_text": "This is the first work that explicitly explores the internal regularity of entity mentions for Chinese NER.",
          "gpt_label": "Unsupported Claim",
          "reason": "Novelty claim about being the first in the literature is not supported with citations or comparative references.",
          "start": 3849,
          "end": 3955
        }
      ]
    }
  },
  "paper_19.txt": {
    "filename": "paper_19.txt",
    "full_text": "Related Work\n\nDeep learning, to a large extent, has freed data scientists from doing feature engineering, which has been one of the essential obstacles to annotation with AL. This advantage has sparked a series of works on deep active learning (DAL) in natural language processing (NLP). Shen et al. (2017) conduct one of the first investigations on DAL in sequence tagging tasks. They propose an efficient way of quantifying the uncertainty of sentences, namely maximal normalized log probability (MNLP), by averaging log probabilities of their tokens. They also address the problem of excessive duration of a neural network training step during an AL iteration by interleaving online learning with training from scratch. In our work, we take MNLP as a query strategy for experiments on sequence tagging tasks since it has demonstrated a good trade-off between quality and computational performance. We consider that online learning can potentially be used as a complement to our algorithms. Since the most time-consuming part of an AL iteration can be model inference instead of training, in this work, we also pay attention to the acceleration of the inference step.\n\nSeveral recent publications investigate deep pretrained models based on the Transformer architecture (Vaswani et al., 2017), ELMo (Peters et al., 2018), and ULMFiT (Howard and Ruder, 2018) in AL on NLP tasks (Prabhu et al., 2019;Ein-Dor et al., 2020;Yuan et al., 2020;Shelmanov et al., 2021). We continue this line of works by relying on pre-trained Transformers since this architecture has been shown promising for AL in NLP due to its good qualitative and computational performance.\n\nA few works have experimented with Bayesian query strategies for AL. Shen et al. (2017), Sid-dhant and Lipton (2018), Ein-Dor et al. (2020), and Shelmanov et al. (2021 leverage Monte Carlo dropout (Gal and Ghahramani, 2016) for quantifying uncertainty of models. Siddhant and Lipton (2018) also apply the Bayes by backprop algorithm (Blundell et al., 2015) for performing variational inference of a Bayesian neural network. This approach demonstrates the best improvements upon the baseline but introduces large computational overhead both for training and uncertainty estimation of a model, as well as the memory overhead for storing parameters of a Bayesian neural network. The query strategies based on Monte Carlo dropout do not affect the model training procedure and do not change the memory footprint. However, they also suffer from slow uncertainty estimation due to the necessity of making multiple stochastic predictions, while their empirical evaluations with Transformers in recent works (Ein-Dor et al., 2020;Shelmanov et al., 2021) do not demonstrate big advantages. Therefore, we do not use Bayesian query strategies in our experiments and adhere to the classical uncertainty-based query strategies.\n\nRecently proposed alternatives to uncertaintybased query strategies leverage reinforcement learning and imitation learning (Fang et al., 2017;Liu et al., 2018;Vu et al., 2019;Brantley et al., 2020). This series of works aims at constructing trainable policy-based query strategies. However, this requires an excessive amount of computation while the transferability of learned policies across domains and tasks is underresearched.\n\nFinally, Lowell et al. ( 2019) question the usefulness of AL techniques in general. They demonstrate that due to the ASM problem, AL can be even detrimental to the performance of the successor. This finding is also revealed for classical machine learning models by Baldridge and Osborne (2004), Tomanek andMorik (2011), Hu et al. (2016) and supported by experiments with Transformers in (Shelmanov et al., 2021). Our work directly addresses the question raised by Lowell et al. (2019) and suggests a simple solution to the ASM problem. Moreover, we combine it with the method proposed by Shelmanov et al. (2021), who suggest using distilled models for instance acquisition and their teacher models as successors.\n\n ",
    "all_spans": [
      {
        "span_text": "Deep learning, to a large extent, has freed data scientists from doing feature engineering, which has been one of the essential obstacles to annotation with AL.",
        "gpt_label": "Unsupported Claim",
        "reason": "Makes broad claims about the impact of deep learning and the role of feature engineering in AL without providing citations.",
        "start": 14,
        "end": 173
      },
      {
        "span_text": "This advantage has sparked a series of works on deep active learning (DAL) in natural language processing (NLP).",
        "gpt_label": "Unsupported Claim",
        "reason": "Asserts a causal link and references a body of prior work without citing specific studies at first mention.",
        "start": 174,
        "end": 285
      },
      {
        "span_text": "Since the most time-consuming part of an AL iteration can be model inference instead of training, in this work, we also pay attention to the acceleration of the inference step.",
        "gpt_label": "Unsupported Claim",
        "reason": "Claims a non-obvious, empirical property of AL workflows (inference being most time-consuming) without evidence or citation.",
        "start": 985,
        "end": 1160
      },
      {
        "span_text": "We continue this line of works by relying on pre-trained Transformers since this architecture has been shown promising for AL in NLP due to its good qualitative and computational performance.",
        "gpt_label": "Unsupported Claim",
        "reason": "Claims demonstrated promise and specific performance characteristics without directly citing supporting studies at this point.",
        "start": 1448,
        "end": 1638
      },
      {
        "span_text": "This approach demonstrates the best improvements upon the baseline but introduces large computational overhead both for training and uncertainty estimation of a model, as well as the memory overhead for storing parameters of a Bayesian neural network.",
        "gpt_label": "Unsupported Claim",
        "reason": "Asserts comparative superiority and significant overheads without providing citations or evidence for these evaluations.",
        "start": 2057,
        "end": 2307
      },
      {
        "span_text": "However, this requires an excessive amount of computation while the transferability of learned policies across domains and tasks is underresearched.",
        "gpt_label": "Unsupported Claim",
        "reason": "Claims excessive computational cost and lack of research on transferability without citing supporting work.",
        "start": 3119,
        "end": 3266
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "Deep learning, to a large extent, has freed data scientists from doing feature engineering, which has been one of the essential obstacles to annotation with AL.",
          "gpt_label": "Unsupported Claim",
          "reason": "Makes broad claims about the impact of deep learning and the role of feature engineering in AL without providing citations.",
          "start": 14,
          "end": 173
        },
        {
          "span_text": "This advantage has sparked a series of works on deep active learning (DAL) in natural language processing (NLP).",
          "gpt_label": "Unsupported Claim",
          "reason": "Asserts a causal link and references a body of prior work without citing specific studies at first mention.",
          "start": 174,
          "end": 285
        },
        {
          "span_text": "Since the most time-consuming part of an AL iteration can be model inference instead of training, in this work, we also pay attention to the acceleration of the inference step.",
          "gpt_label": "Unsupported Claim",
          "reason": "Claims a non-obvious, empirical property of AL workflows (inference being most time-consuming) without evidence or citation.",
          "start": 985,
          "end": 1160
        },
        {
          "span_text": "We continue this line of works by relying on pre-trained Transformers since this architecture has been shown promising for AL in NLP due to its good qualitative and computational performance.",
          "gpt_label": "Unsupported Claim",
          "reason": "Claims demonstrated promise and specific performance characteristics without directly citing supporting studies at this point.",
          "start": 1448,
          "end": 1638
        },
        {
          "span_text": "This approach demonstrates the best improvements upon the baseline but introduces large computational overhead both for training and uncertainty estimation of a model, as well as the memory overhead for storing parameters of a Bayesian neural network.",
          "gpt_label": "Unsupported Claim",
          "reason": "Asserts comparative superiority and significant overheads without providing citations or evidence for these evaluations.",
          "start": 2057,
          "end": 2307
        },
        {
          "span_text": "However, this requires an excessive amount of computation while the transferability of learned policies across domains and tasks is underresearched.",
          "gpt_label": "Unsupported Claim",
          "reason": "Claims excessive computational cost and lack of research on transferability without citing supporting work.",
          "start": 3119,
          "end": 3266
        }
      ]
    }
  },
  "paper_30.txt": {
    "filename": "paper_30.txt",
    "full_text": "Introduction\n\nPre-trained language models (PLMs) have been widely explored both in natural language understanding (NLU) and generation (NLG) in recent years, this pre-training and fine-tuning paradigm sheds light on various downstream tasks in natural language processing (NLP). Compared with general pre-trained models, task-oriented pre-trained models (such as Summarization, Dialog and etc.), which is designed in line with task characteristics, may achieve better performance and be more robust. In this paper, we proposes a novel pre-trained dialog response generation model based on previous research.\n\nDialogue Response Generation (DSG) in open domain is a challenging task with a wide range of application scenarios. Recent advances in DSG utilize pre-trained language models (PLMs) such as BERT (Devlin et al., 2019) and GPT2 (Radford et al., 2019) in two major categories. The first one focuses on how to fine-tune PLMs in downstream tasks and address the various application-specific needs and challenges (Lin et al., 2020). The second one augments dialog specific tasks into the PLM training Bao et al., 2020) and then fine-tunes the new pre-trained model in downstream tasks. We study the latter in this paper.\n\nThere is a proverbial one-to-many problem in DSG, i.e., a single dialog context could be followed by multiple reasonable responses. Existing works introduce latent variables to model this problem. For example, VHRED (Serban et al., 2017) incorporates latent continuous variable into the sequenceto-sequence (Seq2Seq) RNN model to improve the diversity of generated responses. VAE-Seq2Seq (Bahuleyan et al., 2017) proposes variational attention to replace the vanilla encoder-decoder attention (Luong et al., 2015), to avoid attention to bypass the latent space and invalidate the latent variable. For controllability and interpretability, some discrete VAEs have also been proposed, such as (Oord et al., 2017;Vahdat et al., 2018).\n\nRecently, PLATO (Bao et al., 2020) firstly introduces latent variables into their pre-training dialog model, where the authors introduce a K-way (K = 20) categorical latent variable, and the pretrained model shows significant gains in multiple downstream response generation tasks. Continuous latent variables besides discrete latent variables is popularly used for modeling one-to-many mapping in dialog system, but the potential of incorporating continuous latent variables with large-scale language pretraining is less explored.\n\nIn this paper, we propose a pre-trained latent Variable Encoder-Decoder model for Dialog generation, which is called DialogVED. In this model, we introduce a continuous latent variable into the enhanced encoder-decoder pre-training framework and we adopt the optimization techniques based on the VAEs literature to learn the model with continuous latent variables. More specifically, we conduct the pre-training by optimizing the following 4 pre-training objectives simultaneously: 1) masked language spans loss to enhance the encoder's understanding of context, 2) response generation with n-gram loss to improve the decoder's planning ability, 3) Kullback-Leibler divergence loss to minimize the difference between the posterior and prior distribution of the latent variables, and 4) bag-ofwords loss to reduce posterior distribution collapse. In addition, we also explore the effect of absolute and relative position embeddings specific for conversational data on the model performance.\n\nWe conduct experiments on three different kinds of conversation tasks: chit-chat, knowledge grounded conversation, and conversational question answering. Experimental results verify the effectiveness and superiority of our model compared with the previous state-of-the-art method. We further carry out ablation study to better understand the impact of different components in the DialogVED on model performance including latent space sizes, different decoding strategies, and position embeddings for turns and roles.\n\nOur pre-trained models and source code will be released, hoping to facilitate further research progress in dialogue generation. The main contributions of this paper can be summarized as follows: 1) We propose a pretrained dialog model, which incorporates continuous latent variables into the enhanced encoder-decoder pre-training framework; We explore the impact of latent variable sizes, different decoding strategies, and position embeddings for turns and roles in our model; Extensive experiments show that the proposed model achieves the new state-of-the-art (SOTA) in multiple downstream tasks, and our model has better performance both on relevance and diversity than previous SOTA in response generation.\n\n ",
    "all_spans": [
      {
        "span_text": "Continuous latent variables besides discrete latent variables is popularly used for modeling one-to-many mapping in dialog system, but the potential of incorporating continuous latent variables with large-scale language pretraining is less explored.",
        "gpt_label": "Unsupported Claim",
        "reason": "Claims about the prevalence of continuous latent variables and the relative lack of exploration combining them with large-scale pretraining assert field-wide trends without citing supporting studies or surveys.",
        "start": 2213,
        "end": 2461
      },
      {
        "span_text": "Bao et al., 2020)",
        "gpt_label": "Format",
        "reason": "Missing opening parenthesis; the citation is not properly enclosed as (Bao et al., 2020).",
        "start": 1094,
        "end": 1110
      },
      {
        "span_text": "The second one augments dialog specific tasks into the PLM training Bao et al., 2020) and then fine-tunes the new pre-trained model in downstream tasks. We study the latter in this paper.\n\nThere is a proverbial one-to-many problem in DSG, i.e., a single dialog context could be followed by multiple reasonable responses. Existing works introduce latent variables to model this problem.",
        "gpt_label": "Coherence",
        "reason": "The transition from categorizing PLM-based methods (with a specific citation to Bao et al., 2020) to introducing the one-to-many problem and latent-variable literature is abrupt. The relationship between studying the second PLM category and the subsequent motivation for latent variables is implied but not explicitly stated, creating a gap in coherence across these sentences.",
        "start": 1026,
        "end": 1404
      },
      {
        "span_text": "Existing works introduce latent variables to model this problem. For example, VHRED (Serban et al., 2017) incorporates latent continuous variable into the sequenceto-sequence (Seq2Seq) RNN model to improve the diversity of generated responses. VAE-Seq2Seq (Bahuleyan et al., 2017) proposes variational attention to replace the vanilla encoder-decoder attention (Luong et al., 2015), to avoid attention to bypass the latent space and invalidate the latent variable. For controllability and interpretability, some discrete VAEs have also been proposed, such as (Oord et al., 2017;Vahdat et al., 2018).",
        "gpt_label": "Lacks synthesis",
        "reason": "This passage lists prior approaches and citations without explicitly connecting them to the authors’ own approach or articulating what gap remains; it summarizes related work but does not synthesize it into an argument or motivation for the present study.",
        "start": 1341,
        "end": 1931
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "Continuous latent variables besides discrete latent variables is popularly used for modeling one-to-many mapping in dialog system, but the potential of incorporating continuous latent variables with large-scale language pretraining is less explored.",
          "gpt_label": "Unsupported Claim",
          "reason": "Claims about the prevalence of continuous latent variables and the relative lack of exploration combining them with large-scale pretraining assert field-wide trends without citing supporting studies or surveys.",
          "start": 2213,
          "end": 2461
        }
      ],
      "Format": [
        {
          "span_text": "Bao et al., 2020)",
          "gpt_label": "Format",
          "reason": "Missing opening parenthesis; the citation is not properly enclosed as (Bao et al., 2020).",
          "start": 1094,
          "end": 1110
        }
      ],
      "Coherence": [
        {
          "span_text": "The second one augments dialog specific tasks into the PLM training Bao et al., 2020) and then fine-tunes the new pre-trained model in downstream tasks. We study the latter in this paper.\n\nThere is a proverbial one-to-many problem in DSG, i.e., a single dialog context could be followed by multiple reasonable responses. Existing works introduce latent variables to model this problem.",
          "gpt_label": "Coherence",
          "reason": "The transition from categorizing PLM-based methods (with a specific citation to Bao et al., 2020) to introducing the one-to-many problem and latent-variable literature is abrupt. The relationship between studying the second PLM category and the subsequent motivation for latent variables is implied but not explicitly stated, creating a gap in coherence across these sentences.",
          "start": 1026,
          "end": 1404
        }
      ],
      "Lacks synthesis": [
        {
          "span_text": "Existing works introduce latent variables to model this problem. For example, VHRED (Serban et al., 2017) incorporates latent continuous variable into the sequenceto-sequence (Seq2Seq) RNN model to improve the diversity of generated responses. VAE-Seq2Seq (Bahuleyan et al., 2017) proposes variational attention to replace the vanilla encoder-decoder attention (Luong et al., 2015), to avoid attention to bypass the latent space and invalidate the latent variable. For controllability and interpretability, some discrete VAEs have also been proposed, such as (Oord et al., 2017;Vahdat et al., 2018).",
          "gpt_label": "Lacks synthesis",
          "reason": "This passage lists prior approaches and citations without explicitly connecting them to the authors’ own approach or articulating what gap remains; it summarizes related work but does not synthesize it into an argument or motivation for the present study.",
          "start": 1341,
          "end": 1931
        }
      ]
    }
  },
  "paper_31.txt": {
    "filename": "paper_31.txt",
    "full_text": "Introduction\n\nEntities are integral to applications that require understanding natural language text such as semantic search (Inan et al., 2021;Lashkari et al., 2019), question answering (Chandrasekaran et al., 2020;Cheng and Erk, 2020) and knowledge base construction (Goel et al., 2021;Al-Moslmi et al., 2020). To this end, entity set expansion (ESE) is a crucial task that uses a textual corpus to enhance a set of seed entities (e.g., 'mini bar', 'tv unit') with new entities (e.g., 'coffee', 'clock') that belong to the same semantic concept (e.g., room features).\n\nSince training data in new domains is scarce, many existing ESE methods expand a small seed  set by learning to rank new entity candidates with limited supervision. Broadly speaking, there are two types of such low-resource ESE methods: (a) corpus-based methods (Shen et al., 2018;Huang et al., 2020a;Yu et al., 2019a) that bootstrap the seed set using contextual features and patterns, and (b) language model-based methods  that probe a pre-trained language model with prompts to rank the entity candidates.\n\nDespite the recent progress, reported success of ESE methods is largely limited to benchmarks focusing on named entities (e.g., countries, diseases) and well-written text such as Wikipedia. Furthermore, the evaluation is limited to top 10-50 predictions regardless of the actual size of the entity set. As a result, it is unclear whether the reported effectiveness of ESE methods is conditional to datasets, domains, and/or evaluation methods.\n\nIn this paper, we conduct a comprehensive study to investigate the generalizability of ESE methods in low-resource settings. Specifically, we focus on user-generated text such as customer reviews, which is widely used in many NLP applications (Li et al., 2019;Bhutani et al., 2020;Dai and Song, 2019). Due to lack of benchmarks on user-generated text, we create new benchmarks from three domains -hotels, restaurants and jobs.\n\nWe found that these benchmarks exhibit characteristics (illustrated in Figure 1) distinctive from existing benchmarks: (a) multifaceted entities (entities that belong to multiple concepts -e.g., 'venice beach' can belong to concepts location and nearby attractions); (b) non-named entities (entities that are typically noun phrases but not proper names (Paris and Suchanek, 2021) -e.g., 'coffee'); and (c) vague entities (human annotators have subjective disagreement on their concept labels -e.g., 'casino' for nearby attraction).\n\nWe found that user-generated text can have up to 10X more multifaceted entities and 2X more nonnamed entities compared to well-curated benchmarks. Furthermore, concepts that do not have well-defined semantics result in vague entities. We hypothesize that these characteristics may affect the performance of ESE methods and thus use these to profile ESE methods. 1 kg denotes the number of all correct entities of a concept.\n\n ",
    "all_spans": [
      {
        "span_text": "Since training data in new domains is scarce, many existing ESE methods expand a small seed  set by learning to rank new entity candidates with limited supervision.",
        "gpt_label": "Unsupported Claim",
        "reason": "Makes general claims about data scarcity and the behavior of many existing methods without citing supporting prior work or evidence.",
        "start": 558,
        "end": 721
      },
      {
        "span_text": "and (b) language model-based methods  that probe a pre-trained language model with prompts to rank the entity candidates.",
        "gpt_label": "Unsupported Claim",
        "reason": "Introduces a class of methods without providing citations to representative works.",
        "start": 941,
        "end": 1061
      },
      {
        "span_text": "Despite the recent progress, reported success of ESE methods is largely limited to benchmarks focusing on named entities (e.g., countries, diseases) and well-written text such as Wikipedia.",
        "gpt_label": "Unsupported Claim",
        "reason": "Claims limitations of prior work and references 'recent progress' without citing studies or benchmarks to support the assertion.",
        "start": 1063,
        "end": 1249
      },
      {
        "span_text": "Furthermore, the evaluation is limited to top 10-50 predictions regardless of the actual size of the entity set.",
        "gpt_label": "Unsupported Claim",
        "reason": "Asserts a common evaluation practice in prior work without citing evidence or examples.",
        "start": 1250,
        "end": 1361
      },
      {
        "span_text": "Due to lack of benchmarks on user-generated text, we create new benchmarks from three domains -hotels, restaurants and jobs.",
        "gpt_label": "Unsupported Claim",
        "reason": "States there is a lack of benchmarks on user-generated text without citing surveys or prior work to support the claim.",
        "start": 1801,
        "end": 1924
      },
      {
        "span_text": "We found that user-generated text can have up to 10X more multifaceted entities and 2X more nonnamed entities compared to well-curated benchmarks.",
        "gpt_label": "Unsupported Claim",
        "reason": "Presents specific quantitative findings without pointing to a figure, table, or citation that substantiates the statistics.",
        "start": 2452,
        "end": 2597
      },
      {
        "span_text": "We hypothesize that these characteristics may affect the performance of ESE methods and thus use these to profile ESE methods. 1 kg denotes the number of all correct entities of a concept.",
        "gpt_label": "Coherence",
        "reason": "The second sentence appears abruptly and seems unrelated to the preceding sentence, with no transition or explanation linking the hypothesis about profiling ESE methods to the definition of '1 kg'. The relationship between these sentences is unclear, causing a coherence break across multiple sentences.",
        "start": 2685,
        "end": 2871
      },
      {
        "span_text": "Broadly speaking, there are two types of such low-resource ESE methods: (a) corpus-based methods (Shen et al., 2018;Huang et al., 2020a;Yu et al., 2019a) that bootstrap the seed set using contextual features and patterns, and (b) language model-based methods that probe a pre-trained language model with prompts to rank the entity candidates.",
        "gpt_label": "Lacks synthesis",
        "reason": "This sentence catalogs prior approaches with citations but does not connect them to the authors’ research agenda, implications, or the specific gap being addressed, nor articulate the authors’ perspective or motivation.",
        "start": -1,
        "end": -1
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "Since training data in new domains is scarce, many existing ESE methods expand a small seed  set by learning to rank new entity candidates with limited supervision.",
          "gpt_label": "Unsupported Claim",
          "reason": "Makes general claims about data scarcity and the behavior of many existing methods without citing supporting prior work or evidence.",
          "start": 558,
          "end": 721
        },
        {
          "span_text": "and (b) language model-based methods  that probe a pre-trained language model with prompts to rank the entity candidates.",
          "gpt_label": "Unsupported Claim",
          "reason": "Introduces a class of methods without providing citations to representative works.",
          "start": 941,
          "end": 1061
        },
        {
          "span_text": "Despite the recent progress, reported success of ESE methods is largely limited to benchmarks focusing on named entities (e.g., countries, diseases) and well-written text such as Wikipedia.",
          "gpt_label": "Unsupported Claim",
          "reason": "Claims limitations of prior work and references 'recent progress' without citing studies or benchmarks to support the assertion.",
          "start": 1063,
          "end": 1249
        },
        {
          "span_text": "Furthermore, the evaluation is limited to top 10-50 predictions regardless of the actual size of the entity set.",
          "gpt_label": "Unsupported Claim",
          "reason": "Asserts a common evaluation practice in prior work without citing evidence or examples.",
          "start": 1250,
          "end": 1361
        },
        {
          "span_text": "Due to lack of benchmarks on user-generated text, we create new benchmarks from three domains -hotels, restaurants and jobs.",
          "gpt_label": "Unsupported Claim",
          "reason": "States there is a lack of benchmarks on user-generated text without citing surveys or prior work to support the claim.",
          "start": 1801,
          "end": 1924
        },
        {
          "span_text": "We found that user-generated text can have up to 10X more multifaceted entities and 2X more nonnamed entities compared to well-curated benchmarks.",
          "gpt_label": "Unsupported Claim",
          "reason": "Presents specific quantitative findings without pointing to a figure, table, or citation that substantiates the statistics.",
          "start": 2452,
          "end": 2597
        }
      ],
      "Format": [],
      "Coherence": [
        {
          "span_text": "We hypothesize that these characteristics may affect the performance of ESE methods and thus use these to profile ESE methods. 1 kg denotes the number of all correct entities of a concept.",
          "gpt_label": "Coherence",
          "reason": "The second sentence appears abruptly and seems unrelated to the preceding sentence, with no transition or explanation linking the hypothesis about profiling ESE methods to the definition of '1 kg'. The relationship between these sentences is unclear, causing a coherence break across multiple sentences.",
          "start": 2685,
          "end": 2871
        }
      ],
      "Lacks synthesis": [
        {
          "span_text": "Broadly speaking, there are two types of such low-resource ESE methods: (a) corpus-based methods (Shen et al., 2018;Huang et al., 2020a;Yu et al., 2019a) that bootstrap the seed set using contextual features and patterns, and (b) language model-based methods that probe a pre-trained language model with prompts to rank the entity candidates.",
          "gpt_label": "Lacks synthesis",
          "reason": "This sentence catalogs prior approaches with citations but does not connect them to the authors’ research agenda, implications, or the specific gap being addressed, nor articulate the authors’ perspective or motivation.",
          "start": -1,
          "end": -1
        }
      ]
    }
  },
  "paper_32.txt": {
    "filename": "paper_32.txt",
    "full_text": "Related Work\n\nEffective utilization of annotation budgets has been the area of focus for numerous active learning works, showing improvements for different tasks like POS tagging (Ringger et al., 2007), sentiment analysis (Karlos et al., 2012;Li et al., 2013;Brew et al., 2010;Ju and Li, 2012), syntactic parsing (Duong et al., 2018), and named entity recognition (Settles and Craven, 2008;Shen et al., 2018). The focus of most of these works, however, has been on learning for a single language (often English). Prior work on AL that uses a multilingual setup or cross-lingual information sharing and that goes beyond training a separate model for each language has thus been limited. The closest work where multiple languages influence each other's acquisition is that of Qian et al. (2014); however, they still train a separate model for each language.\n\nFor transfer to multiple languages, recent advances in building MPLMs (Devlin et al., 2019;Conneau et al., 2020;Liu et al., 2020;Xue et al., 2020) have been extremely effective, especially in zero-shot transfer (Pires et al., 2019;Liu et al., 2020). Ein-Dor et al. (2020) studied the dataeffectiveness of these models when used in conjunction with AL, but, as with other AL work, with a single language focus. Finally, Lauscher et al. (2020) studied the effectiveness of the zero-shot setup, showing that adding a few examples to a model trained on English improves performance over zero-shot transfer. However, this assumes the availability of a full English task-specific corpus.\n\n ",
    "all_spans": [
      {
        "span_text": "The focus of most of these works, however, has been on learning for a single language (often English).",
        "gpt_label": "Unsupported Claim",
        "reason": "Makes a broad claim about the typical focus of prior active learning work without providing a supporting citation.",
        "start": 403,
        "end": 504
      },
      {
        "span_text": "Prior work on AL that uses a multilingual setup or cross-lingual information sharing and that goes beyond training a separate model for each language has thus been limited.",
        "gpt_label": "Unsupported Claim",
        "reason": "Asserts scarcity of multilingual or cross-lingual AL approaches without citing evidence or surveys.",
        "start": 505,
        "end": 676
      },
      {
        "span_text": "but, as with other AL work, with a single language focus.",
        "gpt_label": "Unsupported Claim",
        "reason": "Generalizes that other AL work focuses on a single language without citations to support the claim.",
        "start": 1190,
        "end": 1246
      },
      {
        "span_text": "However, this assumes the availability of a full English task-specific corpus.",
        "gpt_label": "Unsupported Claim",
        "reason": "Claims a specific assumption about prior work (Lauscher et al.) without citing evidence that such a full corpus is required.",
        "start": 1438,
        "end": 1515
      },
      {
        "span_text": "The closest work where multiple languages influence each other's acquisition is that of Qian et al. (2014); however, they still train a separate model for each language.\n\nFor transfer to multiple languages, recent advances in building MPLMs (Devlin et al., 2019;Conneau et al., 2020;Liu et al., 2020;Xue et al., 2020) have been extremely effective, especially in zero-shot transfer (Pires et al., 2019;Liu et al., 2020).",
        "gpt_label": "Coherence",
        "reason": "The transition is abrupt: it jumps from cross-lingual active learning work (Qian et al., 2014) to general multilingual pretrained models and zero-shot transfer without explicitly explaining how the latter addresses the limitations of the former or how it connects to active learning. The relationship between these sentences is only implied, not stated.",
        "start": 677,
        "end": 1088
      },
      {
        "span_text": "For transfer to multiple languages, recent advances in building MPLMs (Devlin et al., 2019;Conneau et al., 2020;Liu et al., 2020;Xue et al., 2020) have been extremely effective, especially in zero-shot transfer (Pires et al., 2019;Liu et al., 2020).",
        "gpt_label": "Lacks synthesis",
        "reason": "This sentence lists prior advances and results without explicitly connecting them to the paper’s own aims or argument, and it does not articulate the authors’ perspective or how these works motivate or relate to their approach.",
        "start": 846,
        "end": 1088
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "The focus of most of these works, however, has been on learning for a single language (often English).",
          "gpt_label": "Unsupported Claim",
          "reason": "Makes a broad claim about the typical focus of prior active learning work without providing a supporting citation.",
          "start": 403,
          "end": 504
        },
        {
          "span_text": "Prior work on AL that uses a multilingual setup or cross-lingual information sharing and that goes beyond training a separate model for each language has thus been limited.",
          "gpt_label": "Unsupported Claim",
          "reason": "Asserts scarcity of multilingual or cross-lingual AL approaches without citing evidence or surveys.",
          "start": 505,
          "end": 676
        },
        {
          "span_text": "but, as with other AL work, with a single language focus.",
          "gpt_label": "Unsupported Claim",
          "reason": "Generalizes that other AL work focuses on a single language without citations to support the claim.",
          "start": 1190,
          "end": 1246
        },
        {
          "span_text": "However, this assumes the availability of a full English task-specific corpus.",
          "gpt_label": "Unsupported Claim",
          "reason": "Claims a specific assumption about prior work (Lauscher et al.) without citing evidence that such a full corpus is required.",
          "start": 1438,
          "end": 1515
        }
      ],
      "Format": [],
      "Coherence": [
        {
          "span_text": "The closest work where multiple languages influence each other's acquisition is that of Qian et al. (2014); however, they still train a separate model for each language.\n\nFor transfer to multiple languages, recent advances in building MPLMs (Devlin et al., 2019;Conneau et al., 2020;Liu et al., 2020;Xue et al., 2020) have been extremely effective, especially in zero-shot transfer (Pires et al., 2019;Liu et al., 2020).",
          "gpt_label": "Coherence",
          "reason": "The transition is abrupt: it jumps from cross-lingual active learning work (Qian et al., 2014) to general multilingual pretrained models and zero-shot transfer without explicitly explaining how the latter addresses the limitations of the former or how it connects to active learning. The relationship between these sentences is only implied, not stated.",
          "start": 677,
          "end": 1088
        }
      ],
      "Lacks synthesis": [
        {
          "span_text": "For transfer to multiple languages, recent advances in building MPLMs (Devlin et al., 2019;Conneau et al., 2020;Liu et al., 2020;Xue et al., 2020) have been extremely effective, especially in zero-shot transfer (Pires et al., 2019;Liu et al., 2020).",
          "gpt_label": "Lacks synthesis",
          "reason": "This sentence lists prior advances and results without explicitly connecting them to the paper’s own aims or argument, and it does not articulate the authors’ perspective or how these works motivate or relate to their approach.",
          "start": 846,
          "end": 1088
        }
      ]
    }
  },
  "paper_33.txt": {
    "filename": "paper_33.txt",
    "full_text": "Related Work\n\nMath Problem Understanding Math problem understanding task focuses on understanding the text, formulas and symbols in math domain. A surge of works aim to understand the math formulas for problem solving or mathematical information retrieval. In this way, the formula is usually transformed as a tree or graph (e.g., Operator Tree (Zanibbi and Blostein, 2012)), then network embedding methods Mansouri et al. (2019) and graph neural networkSong and Chen (2021) are utilized to encode it. Besides, a number of works focus on understanding math problem based on the textual information. Among them, Math Word Problem (MWP) Solving is a popular task that generates answers of math word problems. Numerous deep learning based methods have been proposed to tackle MWP, ranging from Seq2Seq (Chiang and Chen, 2019;Li et al., 2019), Seq2Tree Qin et al., 2020), to Pre-trained Language Models Liang et al., 2021). More recently, several works attempt to modeling more complex math problems (Huang et al., 2020;Hendrycks et al., 2021) that require to understand both textual and formula information.\n\n ",
    "all_spans": [
      {
        "span_text": "A surge of works aim to understand the math formulas for problem solving or mathematical information retrieval.",
        "gpt_label": "Unsupported Claim",
        "reason": "Asserts a trend/volume of prior work without citing specific supporting studies at this first mention.",
        "start": 144,
        "end": 254
      },
      {
        "span_text": "Besides, a number of works focus on understanding math problem based on the textual information.",
        "gpt_label": "Unsupported Claim",
        "reason": "Claims existence of a body of work without providing citations to support it.",
        "start": 496,
        "end": 591
      },
      {
        "span_text": "Math Word Problem (MWP) Solving is a popular task that generates answers of math word problems.",
        "gpt_label": "Unsupported Claim",
        "reason": "Introduces a task and asserts its popularity without citing foundational papers, datasets, or surveys at first mention.",
        "start": 604,
        "end": 698
      },
      {
        "span_text": "Qin et al., 2020)",
        "gpt_label": "Format",
        "reason": "Missing opening parenthesis for the citation; should be '(Qin et al., 2020)'.",
        "start": 840,
        "end": 856
      },
      {
        "span_text": "Liang et al., 2021)",
        "gpt_label": "Format",
        "reason": "Missing opening parenthesis for the citation; should be '(Liang et al., 2021)'.",
        "start": 889,
        "end": 907
      },
      {
        "span_text": "Besides, a number of works focus on understanding math problem based on the textual information. Among them, Math Word Problem (MWP) Solving is a popular task that generates answers of math word problems. Numerous deep learning based methods have been proposed to tackle MWP, ranging from Seq2Seq (Chiang and Chen, 2019;Li et al., 2019), Seq2Tree Qin et al., 2020), to Pre-trained Language Models Liang et al., 2021). More recently, several works attempt to modeling more complex math problems (Huang et al., 2020;Hendrycks et al., 2021) that require to understand both textual and formula information.",
        "gpt_label": "Coherence",
        "reason": "The transition from text-only MWP work to complex problems requiring both text and formulas is abrupt and the relationships are implied rather than stated. It is unclear how the listed MWP methods relate to the subsequent multimodal works or to the earlier formula-understanding literature, and no explicit linkage is provided between these sentences.",
        "start": 496,
        "end": 1089
      },
      {
        "span_text": "A surge of works aim to understand the math formulas for problem solving or mathematical information retrieval. In this way, the formula is usually transformed as a tree or graph (e.g., Operator Tree (Zanibbi and Blostein, 2012)), then network embedding methods Mansouri et al. (2019) and graph neural networkSong and Chen (2021) are utilized to encode it. Besides, a number of works focus on understanding math problem based on the textual information. Among them, Math Word Problem (MWP) Solving is a popular task that generates answers of math word problems. Numerous deep learning based methods have been proposed to tackle MWP, ranging from Seq2Seq (Chiang and Chen, 2019;Li et al., 2019), Seq2Tree Qin et al., 2020), to Pre-trained Language Models Liang et al., 2021). More recently, several works attempt to modeling more complex math problems (Huang et al., 2020;Hendrycks et al., 2021) that require to understand both textual and formula information.",
        "gpt_label": "Lacks synthesis",
        "reason": "This passage enumerates prior work and approaches without connecting them to the authors’ own goals, highlighting a specific gap, or articulating the authors’ perspective or motivation.",
        "start": 144,
        "end": 1089
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "A surge of works aim to understand the math formulas for problem solving or mathematical information retrieval.",
          "gpt_label": "Unsupported Claim",
          "reason": "Asserts a trend/volume of prior work without citing specific supporting studies at this first mention.",
          "start": 144,
          "end": 254
        },
        {
          "span_text": "Besides, a number of works focus on understanding math problem based on the textual information.",
          "gpt_label": "Unsupported Claim",
          "reason": "Claims existence of a body of work without providing citations to support it.",
          "start": 496,
          "end": 591
        },
        {
          "span_text": "Math Word Problem (MWP) Solving is a popular task that generates answers of math word problems.",
          "gpt_label": "Unsupported Claim",
          "reason": "Introduces a task and asserts its popularity without citing foundational papers, datasets, or surveys at first mention.",
          "start": 604,
          "end": 698
        }
      ],
      "Format": [
        {
          "span_text": "Qin et al., 2020)",
          "gpt_label": "Format",
          "reason": "Missing opening parenthesis for the citation; should be '(Qin et al., 2020)'.",
          "start": 840,
          "end": 856
        },
        {
          "span_text": "Liang et al., 2021)",
          "gpt_label": "Format",
          "reason": "Missing opening parenthesis for the citation; should be '(Liang et al., 2021)'.",
          "start": 889,
          "end": 907
        }
      ],
      "Coherence": [
        {
          "span_text": "Besides, a number of works focus on understanding math problem based on the textual information. Among them, Math Word Problem (MWP) Solving is a popular task that generates answers of math word problems. Numerous deep learning based methods have been proposed to tackle MWP, ranging from Seq2Seq (Chiang and Chen, 2019;Li et al., 2019), Seq2Tree Qin et al., 2020), to Pre-trained Language Models Liang et al., 2021). More recently, several works attempt to modeling more complex math problems (Huang et al., 2020;Hendrycks et al., 2021) that require to understand both textual and formula information.",
          "gpt_label": "Coherence",
          "reason": "The transition from text-only MWP work to complex problems requiring both text and formulas is abrupt and the relationships are implied rather than stated. It is unclear how the listed MWP methods relate to the subsequent multimodal works or to the earlier formula-understanding literature, and no explicit linkage is provided between these sentences.",
          "start": 496,
          "end": 1089
        }
      ],
      "Lacks synthesis": [
        {
          "span_text": "A surge of works aim to understand the math formulas for problem solving or mathematical information retrieval. In this way, the formula is usually transformed as a tree or graph (e.g., Operator Tree (Zanibbi and Blostein, 2012)), then network embedding methods Mansouri et al. (2019) and graph neural networkSong and Chen (2021) are utilized to encode it. Besides, a number of works focus on understanding math problem based on the textual information. Among them, Math Word Problem (MWP) Solving is a popular task that generates answers of math word problems. Numerous deep learning based methods have been proposed to tackle MWP, ranging from Seq2Seq (Chiang and Chen, 2019;Li et al., 2019), Seq2Tree Qin et al., 2020), to Pre-trained Language Models Liang et al., 2021). More recently, several works attempt to modeling more complex math problems (Huang et al., 2020;Hendrycks et al., 2021) that require to understand both textual and formula information.",
          "gpt_label": "Lacks synthesis",
          "reason": "This passage enumerates prior work and approaches without connecting them to the authors’ own goals, highlighting a specific gap, or articulating the authors’ perspective or motivation.",
          "start": 144,
          "end": 1089
        }
      ]
    }
  },
  "paper_34.txt": {
    "filename": "paper_34.txt",
    "full_text": "Related Work\n\nMany recent works on paraphrase generation have been focused on attempting to achieve high-quality paraphrases. These works can be divided into supervised and unsupervised approaches.\n\nSupervised Approaches To achieve diversity, some works focused on diverse decoding using heuristics such as Hamming distance or distinct n-grams to preserve diverse options during beam search (Vijayakumar et al., 2018). Other works MSCOCO WikiAns ParaBank2 q sem ↑ q syn ↑ q lex ↑ i-BLEU↓ q sem ↑ q syn ↑ q lex ↑ i-BLEU↓ q sem ↑ q syn ↑ q lex ↑ i-BLEU↓ Gold 29.9 34. generate multiple outputs by perturbing latent representations (Gupta et al., 2018;Park et al., 2019). or by using distinct generators (Qian et al., 2019). These methods achieve some diversity, but do not control generation in an interpretable manner.\n\nThe works that are most similar to ours strive to gain diversity using controlled-paraphrase generation, by exposing control mechanisms that are manipulated to produce either lexically (Zeng et al., 2019;Thompson and Post, 2020) or syntactically (Chen et al., 2019; Goyal and Durrett, 2020) diverse paraphrases. One approach is to use an exemplar sentence for guiding the syntax of the generated paraphrase Bao et al., 2019). An alternative is to directly employ constituency tree as the syntax guidance (Iyyer et al., 2018;Li and Choi, 2020). Goyal and Durrett (2020) promote syntactic diversity by conditioning over possible syntactic rearrangements of the input. Zeng et al. (2019) use keywords as lexical guidance for the generation process. Here we introduce a simple model for jointly controlling the lexical, syntactic and semantic aspects of the generated paraphrases.\n\nUnsupervised Approaches Niu et al. (2020) rely on neural models to generate high quality paraphrases, using a decoding method that enforces diversity by preventing repetitive copying of the input tokens. Liu et al. (2020) optimize a quality oriented objective by casting paraphrase generation as an optimization problem, and searching the sentence space to find the optimal point. Garg et al. (2021) and Siddique et al. (2020) use reinforcement learning with quality-oriented reward combining textual entailment, semantic similarity, expression diversity and fluency. In this work, we employ similar metrics for guiding the generation of paraphrases within the supervised framework.\n\n ",
    "all_spans": [
      {
        "span_text": "Many recent works on paraphrase generation have been focused on attempting to achieve high-quality paraphrases.",
        "gpt_label": "Unsupported Claim",
        "reason": "Claims the existence and focus of many recent works without providing citations to support the assertion.",
        "start": 14,
        "end": 124
      },
      {
        "span_text": "These works can be divided into supervised and unsupervised approaches.",
        "gpt_label": "Unsupported Claim",
        "reason": "Presents a taxonomy of prior work without citing sources that establish or exemplify this division.",
        "start": 125,
        "end": 195
      },
      {
        "span_text": "MSCOCO WikiAns ParaBank2",
        "gpt_label": "Unsupported Claim",
        "reason": "Mentions datasets without providing citations at their first mention.",
        "start": 427,
        "end": 451
      },
      {
        "span_text": "These methods achieve some diversity, but do not control generation in an interpretable manner.",
        "gpt_label": "Unsupported Claim",
        "reason": "Evaluative claim about limitations of prior methods lacks citations or evidence.",
        "start": 711,
        "end": 805
      },
      {
        "span_text": "Bao et al., 2019)",
        "gpt_label": "Format",
        "reason": "Missing opening parenthesis for a parenthetical citation.",
        "start": 1211,
        "end": 1227
      },
      {
        "span_text": "Other works MSCOCO WikiAns ParaBank2 q sem ↑ q syn ↑ q lex ↑ i-BLEU↓ q sem ↑ q syn ↑ q lex ↑ i-BLEU↓ q sem ↑ q syn ↑ q lex ↑ i-BLEU↓ Gold 29.9 34. generate multiple outputs by perturbing latent representations (Gupta et al., 2018;Park et al., 2019). or by using distinct generators (Qian et al., 2019).",
        "gpt_label": "Coherence",
        "reason": "The insertion of unrelated table-like content breaks the flow and makes the connection between the described methods abrupt. Additionally, the follow-up sentence fragment starting with 'or' lacks a proper transition, making the relationship between the two sentences implied rather than explicitly articulated.",
        "start": 415,
        "end": 710
      },
      {
        "span_text": "MSCOCO WikiAns ParaBank2 q sem ↑ q syn ↑ q lex ↑ i-BLEU↓ q sem ↑ q syn ↑ q lex ↑ i-BLEU↓ q sem ↑ q syn ↑ q lex ↑ i-BLEU↓ Gold 29.9 34.",
        "gpt_label": "Lacks synthesis",
        "reason": "This stray table/metric fragment interrupts the narrative and is not connected to the surrounding discussion or the authors’ argument, offering no interpretation or integration with the related work.",
        "start": 427,
        "end": 559
      },
      {
        "span_text": "Niu et al. (2020) rely on neural models to generate high quality paraphrases, using a decoding method that enforces diversity by preventing repetitive copying of the input tokens. Liu et al. (2020) optimize a quality oriented objective by casting paraphrase generation as an optimization problem, and searching the sentence space to find the optimal point. Garg et al. (2021) and Siddique et al. (2020) use reinforcement learning with quality-oriented reward combining textual entailment, semantic similarity, expression diversity and fluency.",
        "gpt_label": "Lacks synthesis",
        "reason": "These sentences only enumerate prior unsupervised methods without articulating a gap, comparison, or how they relate to the authors’ goals; they lack the authors’ perspective or motivation and do not synthesize the literature into an argument.",
        "start": 1698,
        "end": 2234
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "Many recent works on paraphrase generation have been focused on attempting to achieve high-quality paraphrases.",
          "gpt_label": "Unsupported Claim",
          "reason": "Claims the existence and focus of many recent works without providing citations to support the assertion.",
          "start": 14,
          "end": 124
        },
        {
          "span_text": "These works can be divided into supervised and unsupervised approaches.",
          "gpt_label": "Unsupported Claim",
          "reason": "Presents a taxonomy of prior work without citing sources that establish or exemplify this division.",
          "start": 125,
          "end": 195
        },
        {
          "span_text": "MSCOCO WikiAns ParaBank2",
          "gpt_label": "Unsupported Claim",
          "reason": "Mentions datasets without providing citations at their first mention.",
          "start": 427,
          "end": 451
        },
        {
          "span_text": "These methods achieve some diversity, but do not control generation in an interpretable manner.",
          "gpt_label": "Unsupported Claim",
          "reason": "Evaluative claim about limitations of prior methods lacks citations or evidence.",
          "start": 711,
          "end": 805
        }
      ],
      "Format": [
        {
          "span_text": "Bao et al., 2019)",
          "gpt_label": "Format",
          "reason": "Missing opening parenthesis for a parenthetical citation.",
          "start": 1211,
          "end": 1227
        }
      ],
      "Coherence": [
        {
          "span_text": "Other works MSCOCO WikiAns ParaBank2 q sem ↑ q syn ↑ q lex ↑ i-BLEU↓ q sem ↑ q syn ↑ q lex ↑ i-BLEU↓ q sem ↑ q syn ↑ q lex ↑ i-BLEU↓ Gold 29.9 34. generate multiple outputs by perturbing latent representations (Gupta et al., 2018;Park et al., 2019). or by using distinct generators (Qian et al., 2019).",
          "gpt_label": "Coherence",
          "reason": "The insertion of unrelated table-like content breaks the flow and makes the connection between the described methods abrupt. Additionally, the follow-up sentence fragment starting with 'or' lacks a proper transition, making the relationship between the two sentences implied rather than explicitly articulated.",
          "start": 415,
          "end": 710
        }
      ],
      "Lacks synthesis": [
        {
          "span_text": "MSCOCO WikiAns ParaBank2 q sem ↑ q syn ↑ q lex ↑ i-BLEU↓ q sem ↑ q syn ↑ q lex ↑ i-BLEU↓ q sem ↑ q syn ↑ q lex ↑ i-BLEU↓ Gold 29.9 34.",
          "gpt_label": "Lacks synthesis",
          "reason": "This stray table/metric fragment interrupts the narrative and is not connected to the surrounding discussion or the authors’ argument, offering no interpretation or integration with the related work.",
          "start": 427,
          "end": 559
        },
        {
          "span_text": "Niu et al. (2020) rely on neural models to generate high quality paraphrases, using a decoding method that enforces diversity by preventing repetitive copying of the input tokens. Liu et al. (2020) optimize a quality oriented objective by casting paraphrase generation as an optimization problem, and searching the sentence space to find the optimal point. Garg et al. (2021) and Siddique et al. (2020) use reinforcement learning with quality-oriented reward combining textual entailment, semantic similarity, expression diversity and fluency.",
          "gpt_label": "Lacks synthesis",
          "reason": "These sentences only enumerate prior unsupervised methods without articulating a gap, comparison, or how they relate to the authors’ goals; they lack the authors’ perspective or motivation and do not synthesize the literature into an argument.",
          "start": 1698,
          "end": 2234
        }
      ]
    }
  },
  "paper_35.txt": {
    "filename": "paper_35.txt",
    "full_text": "Introduction\n\nResearch on long-range language models (LRLMs) aims to process extremely long input sequences by making the base Transformer architecture more efficient (e.g., through sparse attention, recurrence, or cached memory). These modifications are commonly validated by training LRLMs on PG-19 (Rae et al., 2020), a long-document language modeling dataset, and demonstrating small perplexity decreases over shorter context models (Roy et al., 2021). However, recent analysis experiments (Sun et al., 2021;Press et al., 2021) show that modern LRLMs rely mostly on local context (i.e., the immediately preceding 1-2K tokens) and are insensitive to tokens earlier in the input sequence.\n\nIn this paper, we move beyond token-level perplexity by evaluating LRLMs on a task that requires a rich understanding of long-range dependencies. Our task is an instance of suffix identification, in which a language model is given a long input sequence (or prefix) and asked to disambiguate the next n-token segment from a set of hard negatives that are randomly sampled from the same narrative. To succeed at this task, an LRLM should assign high probability to the ground-truth next segment and low probability to the negatives. To specifically test long-range dependencies, we restrict our prefixes to end at chapter breaks of a longer cohesive narrative (e.g., a novel).\n\nWe construct a challenge dataset, CHAPTER-BREAK, by automatically detecting chapter boundaries within both held-out PG-19 documents (indomain for pretrained LRLMs) and works of fan fiction published on the Archive of Our Own (out of domain). We perform a detailed analysis of the types of chapter transitions in our dataset and discover a high frequency of narrative shifts in point-of-view, location, and time, all of which require global narrative understanding. For example, Figure 1 contains a complex prefix in which the time-traveling Billy Pilgrim moves between World War II, 1960s suburban life, and an alien planet. Understanding the cliffhanger ending, in which the narrative abruptly switches from a wartime scene to a 1967 alien abduction, requires an LRLM to make connective inferences using details buried far back in the context (e.g., Billy's age in 1967).\n\nWe evaluate three LRLMs on CHAPTERBREAK, including BigBird (Zaheer et al., 2020), the Routing Transformer (Roy et al., 2021), and its local attention variant, all pretrained or fine-tuned on PG-19. Our experiments show that these LRLMs perform poorly at selecting the ground-truth suffix, regardless of the length of the input sequence. As an upper bound, we train a small RoBERTa-based suffix-level language model on PG-19 and discover that it substantially outperforms all LRLMs on the task. Finally, we perform an analysis on the instances in which all models struggle to choose the correct suffix, which reveals that chapters containing shifts in location and events in focus are particularly challenging to disambiguate. Taken together, these results suggest that CHAPTERBREAK is a useful benchmark for future research into LRLMs.\n\n ",
    "all_spans": [
      {
        "span_text": "suffix identification",
        "gpt_label": "Unsupported Claim",
        "reason": "Introduces a specific task that appears to have prior art but provides no citation at first mention.",
        "start": 853,
        "end": 874
      },
      {
        "span_text": "Archive of Our Own",
        "gpt_label": "Unsupported Claim",
        "reason": "First mention of a data source/corpus should be cited.",
        "start": 1557,
        "end": 1575
      },
      {
        "span_text": "RoBERTa-based suffix-level language model",
        "gpt_label": "Unsupported Claim",
        "reason": "First mention of a prior model (RoBERTa) should include a citation to the original paper.",
        "start": 2588,
        "end": 2629
      },
      {
        "span_text": "We perform a detailed analysis of the types of chapter transitions in our dataset and discover a high frequency of narrative shifts in point-of-view, location, and time, all of which require global narrative understanding. For example, Figure 1 contains a complex prefix in which the time-traveling Billy Pilgrim moves between World War II, 1960s suburban life, and an alien planet.",
        "gpt_label": "Coherence",
        "reason": "The transition to the Figure 1 example is abrupt and does not explicitly state how it relates to the analyzed dataset, leaving it unclear whether the example is drawn from CHAPTER-BREAK or is merely illustrative.",
        "start": 1592,
        "end": 1972
      },
      {
        "span_text": "These modifications are commonly validated by training LRLMs on PG-19 (Rae et al., 2020), a long-document language modeling dataset, and demonstrating small perplexity decreases over shorter context models (Roy et al., 2021).",
        "gpt_label": "Lacks synthesis",
        "reason": "This sentence summarizes prior validation practices and cites related work without explicitly connecting why this practice is insufficient or how the authors’ approach addresses the gap; the link to the paper’s contribution is not articulated within the passage here.",
        "start": 228,
        "end": 450
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "suffix identification",
          "gpt_label": "Unsupported Claim",
          "reason": "Introduces a specific task that appears to have prior art but provides no citation at first mention.",
          "start": 853,
          "end": 874
        },
        {
          "span_text": "Archive of Our Own",
          "gpt_label": "Unsupported Claim",
          "reason": "First mention of a data source/corpus should be cited.",
          "start": 1557,
          "end": 1575
        },
        {
          "span_text": "RoBERTa-based suffix-level language model",
          "gpt_label": "Unsupported Claim",
          "reason": "First mention of a prior model (RoBERTa) should include a citation to the original paper.",
          "start": 2588,
          "end": 2629
        }
      ],
      "Format": [],
      "Coherence": [
        {
          "span_text": "We perform a detailed analysis of the types of chapter transitions in our dataset and discover a high frequency of narrative shifts in point-of-view, location, and time, all of which require global narrative understanding. For example, Figure 1 contains a complex prefix in which the time-traveling Billy Pilgrim moves between World War II, 1960s suburban life, and an alien planet.",
          "gpt_label": "Coherence",
          "reason": "The transition to the Figure 1 example is abrupt and does not explicitly state how it relates to the analyzed dataset, leaving it unclear whether the example is drawn from CHAPTER-BREAK or is merely illustrative.",
          "start": 1592,
          "end": 1972
        }
      ],
      "Lacks synthesis": [
        {
          "span_text": "These modifications are commonly validated by training LRLMs on PG-19 (Rae et al., 2020), a long-document language modeling dataset, and demonstrating small perplexity decreases over shorter context models (Roy et al., 2021).",
          "gpt_label": "Lacks synthesis",
          "reason": "This sentence summarizes prior validation practices and cites related work without explicitly connecting why this practice is insufficient or how the authors’ approach addresses the gap; the link to the paper’s contribution is not articulated within the passage here.",
          "start": 228,
          "end": 450
        }
      ]
    }
  },
  "paper_36.txt": {
    "filename": "paper_36.txt",
    "full_text": "Related Work\n\nBandit learning has been applied to a variety of NLP problems including neural machine translation (NMT; Sokolov et al., 2017;Kreutzer et al., 2018a,b;Mendoncca et al., 2021), structured prediction (Sokolov et al., 2016), semantic parsing (Lawrence and Riezler, 2018), intent recognition (Falke and Lehnen, 2021), and summarization (Gunasekara et al., 2021). Human feedback has been studied as a direct learning signal for NMT (Kreutzer et al., 2018b;Mendoncca et al., 2021), semantic parsing (Lawrence and Riezler, 2018), summarization (Stiennon et al., 2020), and dialogue (Jaques et al., 2020). Nguyen et al. (2017) simulates bandit feedback to improve an MT system fully trained on a large annotated dataset, including analyzing robustness to feedback perturbations. Our work shows that simulated bandit feedback is an effective learning signal for extractive question answering tasks. Our work differs in focus on reducing annotation costs by relying on few annotated examples only to train the initial model, or by eliminating the need for in-domain annotation completely by relying on data in other domains to train initial models. Alternative forms of supervision for QA have been explored in prior work, such as explicitly providing fine-grained information (Dua et al., 2020;Khashabi et al., 2020a). Kratzwald et al. (2020) resembles our setting in that it seeks binary feed-back to replace span annotation, but their goal is to create supervised data more economically. Domain adaptation for QA has been studied in prior work (Fisch et al., 2019;Khashabi et al., 2020b), including using data augmentation (Yue et al., 2021), adversarial training , contrastive method (Yue et al., 2021), back-training (Kulshreshtha et al., 2021, and exploiting small lottery subnetworks (Zhu et al., 2021).\n\n ",
    "all_spans": [
      {
        "span_text": "adversarial training",
        "gpt_label": "Unsupported Claim",
        "reason": "Claims prior work on adversarial training for QA domain adaptation without providing a citation, unlike the other listed methods which are cited.",
        "start": 1627,
        "end": 1647
      },
      {
        "span_text": "(Kulshreshtha et al., 2021,",
        "gpt_label": "Format",
        "reason": "Unbalanced/incorrect parenthetical citation: missing closing parenthesis and incorrect comma placement inside the citation.",
        "start": 1702,
        "end": 1728
      },
      {
        "span_text": "Alternative forms of supervision for QA have been explored in prior work, such as explicitly providing fine-grained information (Dua et al., 2020;Khashabi et al., 2020a). Kratzwald et al. (2020) resembles our setting in that it seeks binary feed-back to replace span annotation, but their goal is to create supervised data more economically. Domain adaptation for QA has been studied in prior work (Fisch et al., 2019;Khashabi et al., 2020b), including using data augmentation (Yue et al., 2021), adversarial training , contrastive method (Yue et al., 2021), back-training (Kulshreshtha et al., 2021, and exploiting small lottery subnetworks (Zhu et al., 2021).",
        "gpt_label": "Coherence",
        "reason": "These consecutive sentences shift from alternative supervision to a specific binary-feedback study and then abruptly to domain adaptation without explicit transitions or explanation of how these threads relate, leaving the connections implied rather than stated.",
        "start": 1138,
        "end": 1787
      },
      {
        "span_text": "Domain adaptation for QA has been studied in prior work (Fisch et al., 2019;Khashabi et al., 2020b), including using data augmentation (Yue et al., 2021), adversarial training , contrastive method (Yue et al., 2021), back-training (Kulshreshtha et al., 2021, and exploiting small lottery subnetworks (Zhu et al., 2021).",
        "gpt_label": "Lacks synthesis",
        "reason": "This sentence lists prior domain adaptation approaches without explaining how they relate to, differ from, or motivate the authors’ method, nor does it articulate the specific gap their work addresses relative to these methods.",
        "start": 1475,
        "end": 1787
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "adversarial training",
          "gpt_label": "Unsupported Claim",
          "reason": "Claims prior work on adversarial training for QA domain adaptation without providing a citation, unlike the other listed methods which are cited.",
          "start": 1627,
          "end": 1647
        }
      ],
      "Format": [
        {
          "span_text": "(Kulshreshtha et al., 2021,",
          "gpt_label": "Format",
          "reason": "Unbalanced/incorrect parenthetical citation: missing closing parenthesis and incorrect comma placement inside the citation.",
          "start": 1702,
          "end": 1728
        }
      ],
      "Coherence": [
        {
          "span_text": "Alternative forms of supervision for QA have been explored in prior work, such as explicitly providing fine-grained information (Dua et al., 2020;Khashabi et al., 2020a). Kratzwald et al. (2020) resembles our setting in that it seeks binary feed-back to replace span annotation, but their goal is to create supervised data more economically. Domain adaptation for QA has been studied in prior work (Fisch et al., 2019;Khashabi et al., 2020b), including using data augmentation (Yue et al., 2021), adversarial training , contrastive method (Yue et al., 2021), back-training (Kulshreshtha et al., 2021, and exploiting small lottery subnetworks (Zhu et al., 2021).",
          "gpt_label": "Coherence",
          "reason": "These consecutive sentences shift from alternative supervision to a specific binary-feedback study and then abruptly to domain adaptation without explicit transitions or explanation of how these threads relate, leaving the connections implied rather than stated.",
          "start": 1138,
          "end": 1787
        }
      ],
      "Lacks synthesis": [
        {
          "span_text": "Domain adaptation for QA has been studied in prior work (Fisch et al., 2019;Khashabi et al., 2020b), including using data augmentation (Yue et al., 2021), adversarial training , contrastive method (Yue et al., 2021), back-training (Kulshreshtha et al., 2021, and exploiting small lottery subnetworks (Zhu et al., 2021).",
          "gpt_label": "Lacks synthesis",
          "reason": "This sentence lists prior domain adaptation approaches without explaining how they relate to, differ from, or motivate the authors’ method, nor does it articulate the specific gap their work addresses relative to these methods.",
          "start": 1475,
          "end": 1787
        }
      ]
    }
  },
  "paper_37.txt": {
    "filename": "paper_37.txt",
    "full_text": "Related Work\n\nVision-language few-shot learning. Recently, several few-shot learners on vision-language tasks were proposed including GPT (Radford et al., 2019;Brown et al., 2020), Frozen (Tsimpoukelli et al., 2021), PICa , and SimVLM . Frozen (Tsimpoukelli et al., 2021) is a large language model based on GPT-2 (Radford et al., 2019), and is transformed into a multimodal few-shot learner by extending the soft prompting to incorporate a set of images and text. Their approach shows the fewshot capability on visual question answering and image classification tasks. Similarly, PICa  uses GPT-3 (Brown et al., 2020) to solve VQA tasks in a few-shot manner by providing a few in-context VQA examples. It converts images into textual descriptions so that GPT-3 can understand the images. SimVLM  is trained with prefix language modeling on weakly-supervised datasets. It demonstrates its effectiveness on a zero-shot captioning task. While these models achieve improvement on few-shot tasks, they are impractical to use in real-world applications due to their model sizes.\n\nLanguage model prompting. Providing prompts or task descriptions play an vital role in improving pre-trained language models in many tasks Radford et al., 2021;Schick and Schütze, 2020a,b;Brown et al., 2020). Among them, GPT models (Radford et al., 2019;Brown et al., 2020) achieved great success in prompting or task demonstrations in NLP tasks. In light of this direction, prompt-based approaches improve small pre-trained models in few-shot text classification tasks Schick and Schütze, 2020a,b). CLIP (Radford et al., 2021) also explores prompt templates for image classification which affect zero-shot performance. We follow these core ideas so we aim to improve zero-shot and few-shot performance using prompts in visionlanguage tasks. We pretrain FEWVLM with masked language modeling (MaskedLM) and prefix language modeling (Pre-fixLM).\n\n ",
    "all_spans": [
      {
        "span_text": "PICa , and SimVLM .",
        "gpt_label": "Unsupported Claim",
        "reason": "First mentions of PICa and SimVLM lack citations to the original works, which are required when introducing specific prior systems.",
        "start": 213,
        "end": 231
      },
      {
        "span_text": "Similarly, PICa  uses GPT-3 (Brown et al., 2020) to solve VQA tasks in a few-shot manner by providing a few in-context VQA examples.",
        "gpt_label": "Unsupported Claim",
        "reason": "This sentence describes the PICa method and results but does not cite the PICa paper at its first mention.",
        "start": 560,
        "end": 690
      },
      {
        "span_text": "It converts images into textual descriptions so that GPT-3 can understand the images.",
        "gpt_label": "Unsupported Claim",
        "reason": "Methodological detail attributed to PICa is presented without a supporting citation to the PICa work.",
        "start": 691,
        "end": 775
      },
      {
        "span_text": "SimVLM  is trained with prefix language modeling on weakly-supervised datasets.",
        "gpt_label": "Unsupported Claim",
        "reason": "First mention of SimVLM and its training procedure is given without a citation to the SimVLM paper.",
        "start": 776,
        "end": 854
      },
      {
        "span_text": "It demonstrates its effectiveness on a zero-shot captioning task.",
        "gpt_label": "Unsupported Claim",
        "reason": "A performance claim about SimVLM is made without citing evidence or the original work.",
        "start": 855,
        "end": 919
      },
      {
        "span_text": "While these models achieve improvement on few-shot tasks, they are impractical to use in real-world applications due to their model sizes.",
        "gpt_label": "Unsupported Claim",
        "reason": "The assertion about impracticality due to model size is a general claim that should be supported with citations or evidence.",
        "start": 920,
        "end": 1057
      },
      {
        "span_text": "Schick and Schütze, 2020a,b)",
        "gpt_label": "Format",
        "reason": "Missing opening parenthesis before the citation.",
        "start": 1522,
        "end": 1550
      },
      {
        "span_text": "SimVLM  is trained with prefix language modeling on weakly-supervised datasets. It demonstrates its effectiveness on a zero-shot captioning task. While these models achieve improvement on few-shot tasks, they are impractical to use in real-world applications due to their model sizes.",
        "gpt_label": "Coherence",
        "reason": "The transition from discussing SimVLM’s zero-shot captioning to a general statement about few-shot performance is abrupt and unclear. It’s not explicit how SimVLM relates to few-shot tasks, and the referent of “these models” is ambiguous, leaving the relationship between the sentences implied rather than stated.",
        "start": 776,
        "end": 1057
      },
      {
        "span_text": "We follow these core ideas so we aim to improve zero-shot and few-shot performance using prompts in visionlanguage tasks. We pretrain FEWVLM with masked language modeling (MaskedLM) and prefix language modeling (Pre-fixLM).",
        "gpt_label": "Lacks synthesis",
        "reason": "After listing prior prompting works, the authors immediately state their approach without explicitly articulating the specific gap in the literature or how their method addresses the identified limitations, thereby failing to synthesize prior work with their motivation and contribution.",
        "start": 1669,
        "end": 1890
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "PICa , and SimVLM .",
          "gpt_label": "Unsupported Claim",
          "reason": "First mentions of PICa and SimVLM lack citations to the original works, which are required when introducing specific prior systems.",
          "start": 213,
          "end": 231
        },
        {
          "span_text": "Similarly, PICa  uses GPT-3 (Brown et al., 2020) to solve VQA tasks in a few-shot manner by providing a few in-context VQA examples.",
          "gpt_label": "Unsupported Claim",
          "reason": "This sentence describes the PICa method and results but does not cite the PICa paper at its first mention.",
          "start": 560,
          "end": 690
        },
        {
          "span_text": "It converts images into textual descriptions so that GPT-3 can understand the images.",
          "gpt_label": "Unsupported Claim",
          "reason": "Methodological detail attributed to PICa is presented without a supporting citation to the PICa work.",
          "start": 691,
          "end": 775
        },
        {
          "span_text": "SimVLM  is trained with prefix language modeling on weakly-supervised datasets.",
          "gpt_label": "Unsupported Claim",
          "reason": "First mention of SimVLM and its training procedure is given without a citation to the SimVLM paper.",
          "start": 776,
          "end": 854
        },
        {
          "span_text": "It demonstrates its effectiveness on a zero-shot captioning task.",
          "gpt_label": "Unsupported Claim",
          "reason": "A performance claim about SimVLM is made without citing evidence or the original work.",
          "start": 855,
          "end": 919
        },
        {
          "span_text": "While these models achieve improvement on few-shot tasks, they are impractical to use in real-world applications due to their model sizes.",
          "gpt_label": "Unsupported Claim",
          "reason": "The assertion about impracticality due to model size is a general claim that should be supported with citations or evidence.",
          "start": 920,
          "end": 1057
        }
      ],
      "Format": [
        {
          "span_text": "Schick and Schütze, 2020a,b)",
          "gpt_label": "Format",
          "reason": "Missing opening parenthesis before the citation.",
          "start": 1522,
          "end": 1550
        }
      ],
      "Coherence": [
        {
          "span_text": "SimVLM  is trained with prefix language modeling on weakly-supervised datasets. It demonstrates its effectiveness on a zero-shot captioning task. While these models achieve improvement on few-shot tasks, they are impractical to use in real-world applications due to their model sizes.",
          "gpt_label": "Coherence",
          "reason": "The transition from discussing SimVLM’s zero-shot captioning to a general statement about few-shot performance is abrupt and unclear. It’s not explicit how SimVLM relates to few-shot tasks, and the referent of “these models” is ambiguous, leaving the relationship between the sentences implied rather than stated.",
          "start": 776,
          "end": 1057
        }
      ],
      "Lacks synthesis": [
        {
          "span_text": "We follow these core ideas so we aim to improve zero-shot and few-shot performance using prompts in visionlanguage tasks. We pretrain FEWVLM with masked language modeling (MaskedLM) and prefix language modeling (Pre-fixLM).",
          "gpt_label": "Lacks synthesis",
          "reason": "After listing prior prompting works, the authors immediately state their approach without explicitly articulating the specific gap in the literature or how their method addresses the identified limitations, thereby failing to synthesize prior work with their motivation and contribution.",
          "start": 1669,
          "end": 1890
        }
      ]
    }
  },
  "paper_38.txt": {
    "filename": "paper_38.txt",
    "full_text": "Introduction\n\nRecently, pre-training a transformer model on a large corpus with language modeling tasks and finetuning it on different downstream tasks has become the main transfer learning paradigm in natural language processing (Devlin et al., 2019). Notably, this paradigm requires updating and storing all the model parameters for every downstream task. As the model size proliferates (e.g., 330M parameters for BERT (Devlin et al., 2019) and 175B for GPT-3 (Brown et al., 2020)), it becomes computationally expensive and challenging to fine-tune the entire pre-trained language model (LM). Thus, it is natural to ask the question of whether we can transfer the knowledge of a pre-trained LM into downstream tasks by tuning only a small portion of its parameters with most of them freezing.\n\nStudies have attempted to address this question from different perspectives. One line of research (Li and Liang, 2021) suggests to augment the model with a few small trainable mod-ules and freeze the original transformer weight. Take Adapter (Houlsby et al., 2019;Pfeiffer et al., 2020a,b) and Compacter (Mahabadi et al., 2021) for example, both of them insert a small set of additional modules between each transformer layer. During fine-tuning, only these additional and taskspecific modules are trained, reducing the trainable parameters to ∼ 1-3% of the original transformer model per task.\n\nAnother line of works focus on prompting. The GPT-3 models (Brown et al., 2020;Schick and Schütze, 2020) find that with proper manual prompts, a pre-trained LM can successfully match the fine-tuning performance of BERT models. LM-BFF (Gao et al., 2020), EFL (Wang et al., 2021), and AutoPrompt (Shin et al., 2020) further this direction by insert prompts in the input embedding layer. However, these methods rely on grid-search for a natural language-based prompt from a large search space, resulting in difficulties to optimize.\n\nTo tackle this issue, prompt tuning (Lester et al., 2021), prefix tuning (Li and Liang, 2021), and Ptuning (Liu et al., 2021a,b) are proposed to prepend trainable prefix tokens to the input layer and train these soft prompts only during the fine-tuning stage. In doing so, the problem of searching discrete prompts are converted into an continuous optimization task, which can be solved by a variety of optimization techniques such as SGD and thus significantly reduced the number of trainable parameters to only a few thousand. However, all existing prompt-tuning methods have thus far focused on task-specific prompts, making them incompatible with the traditional LM objective. For example, it is unlikely to see many different sentences with the same prefix in the pre-training corpus. Thus, a unified prompt may disturb the prediction and lead to a performance drop. In light of these limitations, we instead ask the following question: Can we generate input-dependent prompts to smooth the domain difference?\n\nIn this paper, we present the instance-dependent prompt generation (IDPG) strategy for efficiently tuning large-scale LMs. Different from the traditional prompt-tuning methods that rely on a fixed prompt for each task, IDPG instead develops a conditional prompt generation model to generate prompts for each instance. Formally, the IDPG generator can be denoted as f (x; W), where x is the instance representation and W represents the trainable parameters. Note that by setting W to a zero matrix and only training the bias, IDPG would degenerate into the traditional prompt tuning process (Lester et al., 2021). To further reduce the number of parameters in the generator f (x; W), we propose to apply a lightweight bottleneck architecture (i.e., a two-layer perceptron) and then decompose it by a parameterized hypercomplex multiplication (PHM) layer (Zhang et al., 2021). To summarize, this works makes the following contributions:\n\n• We introduce an input-dependent prompt generation method-IDPG-that only requires training 134K parameters per task, corresponding to ∼0.04% of a pre-trained LM such as RoBERTa-Large (Liu et al., 2019).\n\n• Extensive evaluations on ten natural language understanding (NLU) tasks show that IDPG consistently outperforms task-specific prompt tuning methods by 1.6-3.1 points (Cf. Table 1). Additionally, it also offers comparable performance to Adapter-based methods while using much fewer parameters (134K vs. 1.55M).\n\n• We conduct substantial intrinsic studies, revealing how and why each component of the proposed model and the generated prompts could help the downstream tasks.\n\n ",
    "all_spans": [
      {
        "span_text": "However, all existing prompt-tuning methods have thus far focused on task-specific prompts, making them incompatible with the traditional LM objective.",
        "gpt_label": "Unsupported Claim",
        "reason": "This sweeping characterization of all prior prompt-tuning methods and their incompatibility with the LM objective is a claim about the literature that lacks supporting citations.",
        "start": 2424,
        "end": 2574
      },
      {
        "span_text": "Another line of works focus on prompting. The GPT-3 models (Brown et al., 2020;Schick and Schütze, 2020) find that with proper manual prompts, a pre-trained LM can successfully match the fine-tuning performance of BERT models. LM-BFF (Gao et al., 2020), EFL (Wang et al., 2021), and AutoPrompt (Shin et al., 2020) further this direction by insert prompts in the input embedding layer.",
        "gpt_label": "Coherence",
        "reason": "The connection among the cited works is implied rather than explained: GPT-3 manual prompting is grouped with Schick and Schütze without clarifying their differences, and the link between GPT-3-style prompting and LM-BFF/EFL/AutoPrompt is not explicitly articulated, making the transition between sentences abrupt and the relationship unclear.",
        "start": 1376,
        "end": 1753
      },
      {
        "span_text": "Studies have attempted to address this question from different perspectives. One line of research (Li and Liang, 2021) suggests to augment the model with a few small trainable mod-ules and freeze the original transformer weight. Take Adapter (Houlsby et al., 2019;Pfeiffer et al., 2020a,b) and Compacter (Mahabadi et al., 2021) for example, both of them insert a small set of additional modules between each transformer layer. During fine-tuning, only these additional and taskspecific modules are trained, reducing the trainable parameters to ∼ 1-3% of the original transformer model per task.",
        "gpt_label": "Lacks synthesis",
        "reason": "This passage lists and describes adapter-based methods without articulating how they relate to the authors’ perspective or identifying a specific gap that motivates their approach, resulting in summary without synthesis.",
        "start": 787,
        "end": 1374
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "However, all existing prompt-tuning methods have thus far focused on task-specific prompts, making them incompatible with the traditional LM objective.",
          "gpt_label": "Unsupported Claim",
          "reason": "This sweeping characterization of all prior prompt-tuning methods and their incompatibility with the LM objective is a claim about the literature that lacks supporting citations.",
          "start": 2424,
          "end": 2574
        }
      ],
      "Format": [],
      "Coherence": [
        {
          "span_text": "Another line of works focus on prompting. The GPT-3 models (Brown et al., 2020;Schick and Schütze, 2020) find that with proper manual prompts, a pre-trained LM can successfully match the fine-tuning performance of BERT models. LM-BFF (Gao et al., 2020), EFL (Wang et al., 2021), and AutoPrompt (Shin et al., 2020) further this direction by insert prompts in the input embedding layer.",
          "gpt_label": "Coherence",
          "reason": "The connection among the cited works is implied rather than explained: GPT-3 manual prompting is grouped with Schick and Schütze without clarifying their differences, and the link between GPT-3-style prompting and LM-BFF/EFL/AutoPrompt is not explicitly articulated, making the transition between sentences abrupt and the relationship unclear.",
          "start": 1376,
          "end": 1753
        }
      ],
      "Lacks synthesis": [
        {
          "span_text": "Studies have attempted to address this question from different perspectives. One line of research (Li and Liang, 2021) suggests to augment the model with a few small trainable mod-ules and freeze the original transformer weight. Take Adapter (Houlsby et al., 2019;Pfeiffer et al., 2020a,b) and Compacter (Mahabadi et al., 2021) for example, both of them insert a small set of additional modules between each transformer layer. During fine-tuning, only these additional and taskspecific modules are trained, reducing the trainable parameters to ∼ 1-3% of the original transformer model per task.",
          "gpt_label": "Lacks synthesis",
          "reason": "This passage lists and describes adapter-based methods without articulating how they relate to the authors’ perspective or identifying a specific gap that motivates their approach, resulting in summary without synthesis.",
          "start": 787,
          "end": 1374
        }
      ]
    }
  },
  "paper_39.txt": {
    "filename": "paper_39.txt",
    "full_text": "Related Work\n\nOver the last few years, the success of ToD systems is largely driven by the joint advent of neural network models (Eric et al., 2017;Wu et al., 2019; and collections of largescale annotation corpora. These corpora cover a wide range of topics from a single domain (e.g., ATIS (Hemphill et al., 1990), DSTC 2 (Henderson et al., 2014), Frames (El Asri et al., 2017, KVRET (Eric et al., 2017), WoZ 2.0 (Wen et al., 2017), M2M (Schatzmann et al., 2007)) to multiple domains (e.g., MultiWoZ (Budzianowski et al., 2018), SGD ). Most notably among these collections, MultiWoZ is a large-scale multidomain dataset that focuses on transitions between different domains or scenarios in real conversations (Budzianowski et al., 2018). Due to the high cost of collecting task-oriented dialogues, only a few monolingual or bilingual non-English ToD datasets are available Quan et al., 2020;Lin et al., 2021). While there is an increasing interest in data curation for multilingual ToD systems, a vast majority of existing multilingual ToD datasets do not consider the real use cases when using a ToD system to search for local entities in a country. We fill this gap in this paper to provide the first analysis on three previously unexplored use cases.\n\n ",
    "all_spans": [
      {
        "span_text": "SGD",
        "gpt_label": "Unsupported Claim",
        "reason": "First mention of a dataset lacks a citation; datasets should be cited at first mention.",
        "start": 515,
        "end": 518
      },
      {
        "span_text": "While there is an increasing interest in data curation for multilingual ToD systems,",
        "gpt_label": "Unsupported Claim",
        "reason": "Trend/\"recent works\" claim about the field is made without citations to support it.",
        "start": 890,
        "end": 974
      },
      {
        "span_text": "a vast majority of existing multilingual ToD datasets do not consider the real use cases when using a ToD system to search for local entities in a country.",
        "gpt_label": "Unsupported Claim",
        "reason": "Broad claim about the characteristics of prior datasets is made without supporting citations or evidence.",
        "start": 975,
        "end": 1129
      },
      {
        "span_text": "We fill this gap in this paper to provide the first analysis on three previously unexplored use cases.",
        "gpt_label": "Unsupported Claim",
        "reason": "Novelty/\"first\" claim about prior work requires evidence or citations and is unsupported.",
        "start": 1130,
        "end": 1231
      },
      {
        "span_text": "(El Asri et al., 2017,",
        "gpt_label": "Format",
        "reason": "Missing closing parenthesis; comma used where the citation should be closed before listing the next item.",
        "start": 349,
        "end": 370
      },
      {
        "span_text": "SGD )",
        "gpt_label": "Format",
        "reason": "Dataset mentioned without its citation; malformed within the parenthetical list and contains an extra space before the closing parenthesis.",
        "start": 515,
        "end": 520
      },
      {
        "span_text": "Most notably among these collections, MultiWoZ is a large-scale multidomain dataset that focuses on transitions between different domains or scenarios in real conversations (Budzianowski et al., 2018). Due to the high cost of collecting task-oriented dialogues, only a few monolingual or bilingual non-English ToD datasets are available Quan et al., 2020;Lin et al., 2021).",
        "gpt_label": "Coherence",
        "reason": "The text abruptly shifts from describing the English MultiWoZ dataset to the scarcity of non-English datasets without an explicit transition or explanation of how the latter point relates to the former. The relationship between these sentences and the cited works is implied rather than stated, creating a coherence gap across the two sentences.",
        "start": 521,
        "end": 889
      },
      {
        "span_text": "Over the last few years, the success of ToD systems is largely driven by the joint advent of neural network models (Eric et al., 2017;Wu et al., 2019; and collections of largescale annotation corpora. These corpora cover a wide range of topics from a single domain (e.g., ATIS (Hemphill et al., 1990), DSTC 2 (Henderson et al., 2014), Frames (El Asri et al., 2017, KVRET (Eric et al., 2017), WoZ 2.0 (Wen et al., 2017), M2M (Schatzmann et al., 2007)) to multiple domains (e.g., MultiWoZ (Budzianowski et al., 2018), SGD ). Most notably among these collections, MultiWoZ is a large-scale multidomain dataset that focuses on transitions between different domains or scenarios in real conversations (Budzianowski et al., 2018).",
        "gpt_label": "Lacks synthesis",
        "reason": "This sequence lists prior datasets and describes them without integrating their implications or explicitly connecting them to the paper’s focus; it summarizes literature rather than synthesizing it into a clear argument or motivation for the present work.",
        "start": 14,
        "end": 720
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "SGD",
          "gpt_label": "Unsupported Claim",
          "reason": "First mention of a dataset lacks a citation; datasets should be cited at first mention.",
          "start": 515,
          "end": 518
        },
        {
          "span_text": "While there is an increasing interest in data curation for multilingual ToD systems,",
          "gpt_label": "Unsupported Claim",
          "reason": "Trend/\"recent works\" claim about the field is made without citations to support it.",
          "start": 890,
          "end": 974
        },
        {
          "span_text": "a vast majority of existing multilingual ToD datasets do not consider the real use cases when using a ToD system to search for local entities in a country.",
          "gpt_label": "Unsupported Claim",
          "reason": "Broad claim about the characteristics of prior datasets is made without supporting citations or evidence.",
          "start": 975,
          "end": 1129
        },
        {
          "span_text": "We fill this gap in this paper to provide the first analysis on three previously unexplored use cases.",
          "gpt_label": "Unsupported Claim",
          "reason": "Novelty/\"first\" claim about prior work requires evidence or citations and is unsupported.",
          "start": 1130,
          "end": 1231
        }
      ],
      "Format": [
        {
          "span_text": "(El Asri et al., 2017,",
          "gpt_label": "Format",
          "reason": "Missing closing parenthesis; comma used where the citation should be closed before listing the next item.",
          "start": 349,
          "end": 370
        },
        {
          "span_text": "SGD )",
          "gpt_label": "Format",
          "reason": "Dataset mentioned without its citation; malformed within the parenthetical list and contains an extra space before the closing parenthesis.",
          "start": 515,
          "end": 520
        }
      ],
      "Coherence": [
        {
          "span_text": "Most notably among these collections, MultiWoZ is a large-scale multidomain dataset that focuses on transitions between different domains or scenarios in real conversations (Budzianowski et al., 2018). Due to the high cost of collecting task-oriented dialogues, only a few monolingual or bilingual non-English ToD datasets are available Quan et al., 2020;Lin et al., 2021).",
          "gpt_label": "Coherence",
          "reason": "The text abruptly shifts from describing the English MultiWoZ dataset to the scarcity of non-English datasets without an explicit transition or explanation of how the latter point relates to the former. The relationship between these sentences and the cited works is implied rather than stated, creating a coherence gap across the two sentences.",
          "start": 521,
          "end": 889
        }
      ],
      "Lacks synthesis": [
        {
          "span_text": "Over the last few years, the success of ToD systems is largely driven by the joint advent of neural network models (Eric et al., 2017;Wu et al., 2019; and collections of largescale annotation corpora. These corpora cover a wide range of topics from a single domain (e.g., ATIS (Hemphill et al., 1990), DSTC 2 (Henderson et al., 2014), Frames (El Asri et al., 2017, KVRET (Eric et al., 2017), WoZ 2.0 (Wen et al., 2017), M2M (Schatzmann et al., 2007)) to multiple domains (e.g., MultiWoZ (Budzianowski et al., 2018), SGD ). Most notably among these collections, MultiWoZ is a large-scale multidomain dataset that focuses on transitions between different domains or scenarios in real conversations (Budzianowski et al., 2018).",
          "gpt_label": "Lacks synthesis",
          "reason": "This sequence lists prior datasets and describes them without integrating their implications or explicitly connecting them to the paper’s focus; it summarizes literature rather than synthesizing it into a clear argument or motivation for the present work.",
          "start": 14,
          "end": 720
        }
      ]
    }
  },
  "paper_40.txt": {
    "filename": "paper_40.txt",
    "full_text": "Related Work\n\nThe KILT benchmark and public leaderboard combines eleven datasets across five tasks. The main advantage of the KILT distribution of these datasets is that the provenance information from each dataset is realigned to reference the same snapshot of Wikipedia. A unified evaluation script and set of metrics is also provided. In this work, we focus on four tasks, such as Slot Filling [Levy et al., 2017, Elsahar et al., 2018, Question Answering [Kwiatkowski et al., 2019, Joshi et al., 2017, Fact Checking [Thorne et al., 2018a,c], and Dialog [Dinan et al., 2019] (see Figure 1). A set of baseline methods have been proposed for KILT. GENRE [Cao et al., 2021] is trained on BLINK  and all KILT tasks jointly using a sequence-to-sequence language model to generate the title of the Wikipedia page where the answer can be found. This method is a strong baseline to evaluate the retrieval performance, but it does not address the downstream tasks. On the other hand, generative models, such as BART [Lewis et al., 2020a] and T5 [Raffel et al., 2020], show interesting performance when finetuned on the downstream tasks relying only on the implicit knowledge stored in the weights of the neural networks, without the use of any explicit retrieval component.\n\nRAG [Lewis et al., 2020b], an end-to-end retrieval-based generative model, is the best performing baseline in KILT and it incorporates DPR [Karpukhin et al., 2020] to first retrieve relevant passages for the query, then it uses a model initialized from BART [Lewis et al., 2020a] to perform a sequence-to-sequence generation from each evidence passage concatenated with the query in order to generate the answer. Figure 2 shows the architecture of RAG.\n\nMulti-task DPR  exploits multi-task learning by training both DPR passage and query encoder on all KILT tasks. DensePhrases [Lee et al., 2021] addresses the knowledge intensive tasks with a short answer, such as slot filling. It indexes the phrases in the corpus that can be potential answers. The extracted phrases are represented by their start and end token vectors from the final layer of a transformer initialized from SpanBERT [Joshi et al., 2020].\n\nKnowledge Graph Induction (KGI) [Glass et al., 2021] combines DPR and RAG models, both trained with task and dataset specific training. KGI employs a two phase training procedure: first training the DPR model, i.e. both the query and context encoder, using the KILT provenance ground truth. Then, KGI trains the sequence-to-sequence generation and further trains the query encoder using only the target output as the objective. This results in large improvements in retrieval performance and, as a consequence, in the downstream tasks.\n\nMulti-stage or cascade approaches to retrieval have received ample attention in Information Retrieval (IR) research. The multi-stage approach begins with the initial retrieval phase, where an initial set of documents or passages form the pool of candidates to be considered for ranking. Then one or more phases of increasingly computationally demanding rerankers are applied. Early approaches in learning to rank [Liu, 2009] used features and linear classifiers. Pre-trained language models, especially BERT , have shown state-ofthe-art performance when applied to the task of relevance ranking. Transformers may be applied as classifiers to each query and passage pair independently [Nogueira and Cho, 2019] or as generators to produce labels for passages in a sequence-tosequence model [Nogueira et al., 2020].\n\n ",
    "all_spans": [
      {
        "span_text": "The KILT benchmark and public leaderboard combines eleven datasets across five tasks.",
        "gpt_label": "Unsupported Claim",
        "reason": "First mention of the KILT benchmark/dataset without a citation to the original source.",
        "start": 14,
        "end": 98
      },
      {
        "span_text": "The main advantage of the KILT distribution of these datasets is that the provenance information from each dataset is realigned to reference the same snapshot of Wikipedia.",
        "gpt_label": "Unsupported Claim",
        "reason": "Claims specific features/advantages of KILT without citing the KILT paper.",
        "start": 99,
        "end": 270
      },
      {
        "span_text": "A unified evaluation script and set of metrics is also provided.",
        "gpt_label": "Unsupported Claim",
        "reason": "Asserts provided tooling/metrics of KILT without a supporting citation.",
        "start": 271,
        "end": 334
      },
      {
        "span_text": "A set of baseline methods have been proposed for KILT.",
        "gpt_label": "Unsupported Claim",
        "reason": "Claims prior work (proposed baselines) for KILT without citing the source(s).",
        "start": 583,
        "end": 636
      },
      {
        "span_text": "BLINK",
        "gpt_label": "Unsupported Claim",
        "reason": "First mention of the BLINK dataset/method lacks a citation.",
        "start": 675,
        "end": 680
      },
      {
        "span_text": "This method is a strong baseline to evaluate the retrieval performance, but it does not address the downstream tasks.",
        "gpt_label": "Unsupported Claim",
        "reason": "Evaluative claim about baseline strength and scope without evidence or citation.",
        "start": 827,
        "end": 943
      },
      {
        "span_text": "On the other hand, generative models, such as BART [Lewis et al., 2020a] and T5 [Raffel et al., 2020], show interesting performance when finetuned on the downstream tasks relying only on the implicit knowledge stored in the weights of the neural networks, without the use of any explicit retrieval component.",
        "gpt_label": "Unsupported Claim",
        "reason": "Asserts performance characteristics of generative models for these tasks without citing empirical studies supporting the claim.",
        "start": 944,
        "end": 1249
      },
      {
        "span_text": "is the best performing baseline in KILT",
        "gpt_label": "Unsupported Claim",
        "reason": "Superlative claim about performance on KILT without citing leaderboard or comparative results.",
        "start": 1325,
        "end": 1364
      },
      {
        "span_text": "Multi-task DPR  exploits multi-task learning by training both DPR passage and query encoder on all KILT tasks.",
        "gpt_label": "Unsupported Claim",
        "reason": "Introduces a specific method (Multi-task DPR) without a citation to its source.",
        "start": 1700,
        "end": 1809
      },
      {
        "span_text": "Multi-stage or cascade approaches to retrieval have received ample attention in Information Retrieval (IR) research.",
        "gpt_label": "Unsupported Claim",
        "reason": "Broad claim about the extent of prior work without references.",
        "start": 2680,
        "end": 2795
      },
      {
        "span_text": "Pre-trained language models, especially BERT , have shown state-ofthe-art performance when applied to the task of relevance ranking.",
        "gpt_label": "Unsupported Claim",
        "reason": "SOTA performance claim requires supporting citations to specific works.",
        "start": 3139,
        "end": 3270
      },
      {
        "span_text": "[Levy et al., 2017, Elsahar et al., 2018,",
        "gpt_label": "Format",
        "reason": "Missing closing bracket for the citation and multiple works are separated by commas instead of the standard style (e.g., semicolons).",
        "start": 394,
        "end": 433
      },
      {
        "span_text": "[Kwiatkowski et al., 2019, Joshi et al., 2017,",
        "gpt_label": "Format",
        "reason": "Missing closing bracket for the citation and multiple works are separated by commas instead of the standard style (e.g., semicolons).",
        "start": 453,
        "end": 497
      },
      {
        "span_text": "This results in large improvements in retrieval performance and, as a consequence, in the downstream tasks.\n\nMulti-stage or cascade approaches to retrieval have received ample attention in Information Retrieval (IR) research.",
        "gpt_label": "Coherence",
        "reason": "Abrupt shift from specific KGI results to a general discussion of multi-stage IR without a transition or explicit explanation of how the latter relates to the former or to prior KILT baselines; the relationship is implied but not stated.",
        "start": 2572,
        "end": 2795
      },
      {
        "span_text": "RAG [Lewis et al., 2020b], an end-to-end retrieval-based generative model, is the best performing baseline in KILT and it incorporates DPR [Karpukhin et al., 2020] to first retrieve relevant passages for the query, then it uses a model initialized from BART [Lewis et al., 2020a] to perform a sequence-to-sequence generation from each evidence passage concatenated with the query in order to generate the answer. Figure 2 shows the architecture of RAG.",
        "gpt_label": "Lacks synthesis",
        "reason": "Summarizes a prior method without connecting it to the authors’ aims, identifying a gap, or explaining its relevance/limitations for the present work.",
        "start": 1251,
        "end": 1698
      },
      {
        "span_text": "Multi-task DPR  exploits multi-task learning by training both DPR passage and query encoder on all KILT tasks. DensePhrases [Lee et al., 2021] addresses the knowledge intensive tasks with a short answer, such as slot filling. It indexes the phrases in the corpus that can be potential answers. The extracted phrases are represented by their start and end token vectors from the final layer of a transformer initialized from SpanBERT [Joshi et al., 2020].",
        "gpt_label": "Lacks synthesis",
        "reason": "Lists methods and their mechanics without integrating them, articulating limitations, or relating them to the paper’s contribution or research gap.",
        "start": 1700,
        "end": 2148
      },
      {
        "span_text": "Knowledge Graph Induction (KGI) [Glass et al., 2021] combines DPR and RAG models, both trained with task and dataset specific training. KGI employs a two phase training procedure: first training the DPR model, i.e. both the query and context encoder, using the KILT provenance ground truth. Then, KGI trains the sequence-to-sequence generation and further trains the query encoder using only the target output as the objective. This results in large improvements in retrieval performance and, as a consequence, in the downstream tasks.",
        "gpt_label": "Lacks synthesis",
        "reason": "Describes prior work and results but does not discuss how it informs, contrasts with, or motivates the current work, nor what gap remains.",
        "start": 2150,
        "end": 2678
      },
      {
        "span_text": "Multi-stage or cascade approaches to retrieval have received ample attention in Information Retrieval (IR) research. The multi-stage approach begins with the initial retrieval phase, where an initial set of documents or passages form the pool of candidates to be considered for ranking. Then one or more phases of increasingly computationally demanding rerankers are applied. Early approaches in learning to rank [Liu, 2009] used features and linear classifiers. Pre-trained language models, especially BERT , have shown state-ofthe-art performance when applied to the task of relevance ranking. Transformers may be applied as classifiers to each query and passage pair independently [Nogueira and Cho, 2019] or as generators to produce labels for passages in a sequence-tosequence model [Nogueira et al., 2020].",
        "gpt_label": "Lacks synthesis",
        "reason": "Provides general background without tying it to the paper’s objectives, argument, or identifying a specific gap the work addresses.",
        "start": 2680,
        "end": 3485
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "The KILT benchmark and public leaderboard combines eleven datasets across five tasks.",
          "gpt_label": "Unsupported Claim",
          "reason": "First mention of the KILT benchmark/dataset without a citation to the original source.",
          "start": 14,
          "end": 98
        },
        {
          "span_text": "The main advantage of the KILT distribution of these datasets is that the provenance information from each dataset is realigned to reference the same snapshot of Wikipedia.",
          "gpt_label": "Unsupported Claim",
          "reason": "Claims specific features/advantages of KILT without citing the KILT paper.",
          "start": 99,
          "end": 270
        },
        {
          "span_text": "A unified evaluation script and set of metrics is also provided.",
          "gpt_label": "Unsupported Claim",
          "reason": "Asserts provided tooling/metrics of KILT without a supporting citation.",
          "start": 271,
          "end": 334
        },
        {
          "span_text": "A set of baseline methods have been proposed for KILT.",
          "gpt_label": "Unsupported Claim",
          "reason": "Claims prior work (proposed baselines) for KILT without citing the source(s).",
          "start": 583,
          "end": 636
        },
        {
          "span_text": "BLINK",
          "gpt_label": "Unsupported Claim",
          "reason": "First mention of the BLINK dataset/method lacks a citation.",
          "start": 675,
          "end": 680
        },
        {
          "span_text": "This method is a strong baseline to evaluate the retrieval performance, but it does not address the downstream tasks.",
          "gpt_label": "Unsupported Claim",
          "reason": "Evaluative claim about baseline strength and scope without evidence or citation.",
          "start": 827,
          "end": 943
        },
        {
          "span_text": "On the other hand, generative models, such as BART [Lewis et al., 2020a] and T5 [Raffel et al., 2020], show interesting performance when finetuned on the downstream tasks relying only on the implicit knowledge stored in the weights of the neural networks, without the use of any explicit retrieval component.",
          "gpt_label": "Unsupported Claim",
          "reason": "Asserts performance characteristics of generative models for these tasks without citing empirical studies supporting the claim.",
          "start": 944,
          "end": 1249
        },
        {
          "span_text": "is the best performing baseline in KILT",
          "gpt_label": "Unsupported Claim",
          "reason": "Superlative claim about performance on KILT without citing leaderboard or comparative results.",
          "start": 1325,
          "end": 1364
        },
        {
          "span_text": "Multi-task DPR  exploits multi-task learning by training both DPR passage and query encoder on all KILT tasks.",
          "gpt_label": "Unsupported Claim",
          "reason": "Introduces a specific method (Multi-task DPR) without a citation to its source.",
          "start": 1700,
          "end": 1809
        },
        {
          "span_text": "Multi-stage or cascade approaches to retrieval have received ample attention in Information Retrieval (IR) research.",
          "gpt_label": "Unsupported Claim",
          "reason": "Broad claim about the extent of prior work without references.",
          "start": 2680,
          "end": 2795
        },
        {
          "span_text": "Pre-trained language models, especially BERT , have shown state-ofthe-art performance when applied to the task of relevance ranking.",
          "gpt_label": "Unsupported Claim",
          "reason": "SOTA performance claim requires supporting citations to specific works.",
          "start": 3139,
          "end": 3270
        }
      ],
      "Format": [
        {
          "span_text": "[Levy et al., 2017, Elsahar et al., 2018,",
          "gpt_label": "Format",
          "reason": "Missing closing bracket for the citation and multiple works are separated by commas instead of the standard style (e.g., semicolons).",
          "start": 394,
          "end": 433
        },
        {
          "span_text": "[Kwiatkowski et al., 2019, Joshi et al., 2017,",
          "gpt_label": "Format",
          "reason": "Missing closing bracket for the citation and multiple works are separated by commas instead of the standard style (e.g., semicolons).",
          "start": 453,
          "end": 497
        }
      ],
      "Coherence": [
        {
          "span_text": "This results in large improvements in retrieval performance and, as a consequence, in the downstream tasks.\n\nMulti-stage or cascade approaches to retrieval have received ample attention in Information Retrieval (IR) research.",
          "gpt_label": "Coherence",
          "reason": "Abrupt shift from specific KGI results to a general discussion of multi-stage IR without a transition or explicit explanation of how the latter relates to the former or to prior KILT baselines; the relationship is implied but not stated.",
          "start": 2572,
          "end": 2795
        }
      ],
      "Lacks synthesis": [
        {
          "span_text": "RAG [Lewis et al., 2020b], an end-to-end retrieval-based generative model, is the best performing baseline in KILT and it incorporates DPR [Karpukhin et al., 2020] to first retrieve relevant passages for the query, then it uses a model initialized from BART [Lewis et al., 2020a] to perform a sequence-to-sequence generation from each evidence passage concatenated with the query in order to generate the answer. Figure 2 shows the architecture of RAG.",
          "gpt_label": "Lacks synthesis",
          "reason": "Summarizes a prior method without connecting it to the authors’ aims, identifying a gap, or explaining its relevance/limitations for the present work.",
          "start": 1251,
          "end": 1698
        },
        {
          "span_text": "Multi-task DPR  exploits multi-task learning by training both DPR passage and query encoder on all KILT tasks. DensePhrases [Lee et al., 2021] addresses the knowledge intensive tasks with a short answer, such as slot filling. It indexes the phrases in the corpus that can be potential answers. The extracted phrases are represented by their start and end token vectors from the final layer of a transformer initialized from SpanBERT [Joshi et al., 2020].",
          "gpt_label": "Lacks synthesis",
          "reason": "Lists methods and their mechanics without integrating them, articulating limitations, or relating them to the paper’s contribution or research gap.",
          "start": 1700,
          "end": 2148
        },
        {
          "span_text": "Knowledge Graph Induction (KGI) [Glass et al., 2021] combines DPR and RAG models, both trained with task and dataset specific training. KGI employs a two phase training procedure: first training the DPR model, i.e. both the query and context encoder, using the KILT provenance ground truth. Then, KGI trains the sequence-to-sequence generation and further trains the query encoder using only the target output as the objective. This results in large improvements in retrieval performance and, as a consequence, in the downstream tasks.",
          "gpt_label": "Lacks synthesis",
          "reason": "Describes prior work and results but does not discuss how it informs, contrasts with, or motivates the current work, nor what gap remains.",
          "start": 2150,
          "end": 2678
        },
        {
          "span_text": "Multi-stage or cascade approaches to retrieval have received ample attention in Information Retrieval (IR) research. The multi-stage approach begins with the initial retrieval phase, where an initial set of documents or passages form the pool of candidates to be considered for ranking. Then one or more phases of increasingly computationally demanding rerankers are applied. Early approaches in learning to rank [Liu, 2009] used features and linear classifiers. Pre-trained language models, especially BERT , have shown state-ofthe-art performance when applied to the task of relevance ranking. Transformers may be applied as classifiers to each query and passage pair independently [Nogueira and Cho, 2019] or as generators to produce labels for passages in a sequence-tosequence model [Nogueira et al., 2020].",
          "gpt_label": "Lacks synthesis",
          "reason": "Provides general background without tying it to the paper’s objectives, argument, or identifying a specific gap the work addresses.",
          "start": 2680,
          "end": 3485
        }
      ]
    }
  },
  "paper_41.txt": {
    "filename": "paper_41.txt",
    "full_text": "Background and Related Work\n\nWe work with the eight corpora covering six tasks summarized below and exemplified in Table 2. We select two corpora for question answering: CommonsenseQA (Talmor et al., 2019) and COPA (Roemmele et al., 2011). CommonsenseQA consists of multi-choice questions (5 candidate answers) that require some degree of commonsense. COPA presents a premise (e.g., The man broke his toe) and a question (e.g., What was the cause of this?) and the system must choose between two plausible alternatives (e.g. He got a hole in his sock or He dropped a hammer on his foot).\n\nFor textual similarity and paraphrasing, we select QQP 2 and STS-B (Cer et al., 2017). QQP consists of pairs of questions and the task is to determine whether they are paraphrases. STS-B consists of pairs of texts and the task is to determine how semantically similar they are with a score from 0 to 5.\n\nWe select one corpus for the remaining tasks. For inference, we work with QNLI (Rajpurkar et al., 2016), which consists in determining whether a text is a valid answer to a question. We use WiC (Pilehvar and Camacho-Collados, 2019) for word sense disambiguation. WiC consists in determining whether two instances of the same word (in two sentences; italicized in Table 2) are used with the same meaning. For coreference resolution, we choose WSC (Levesque et al., 2012), which consists in determining whether a pronoun and a noun phrase are co-referential (italicized in Table 2). Finally, we work with SST-2 (Socher et al., 2013) for sentiment analysis. The task consists in determining whether a sentence from a collection of movie reviews has positive or negative sentiment.\n\nFor convenience, we work with the formatted versions of these corpora in the GLUE (Wang et al., 2018) and SuperGLUE  benchmarks. The only exception is CommonsenseQA, which is not part of these benchmarks. Related Work Previous work has shown that SNLI (Bowman et al., 2015) and MNLI (Williams et al., 2018) have annotation artifacts (e.g., negation is a strong indicator of contradictions) (Gururangan et al., 2018). The literature has also shown that simple adversarial attacks including negation cues are very effective (Naik et al., 2018;Wallace et al., 2019). Kovatchev et al. (2019) analyze 11 paraphrasing systems and show that they obtain substantially worse results when negation is present.\n\nMore recently, Ribeiro et al. (2020) show that negation is one of the linguistic phenomena commercial sentiment analysis struggle with. Several previous works have investigated the (lack of) ability of transformers to make inferences when negation is present. For example, Ettinger (2020) conclude that BERT is unable to complete sentences when negation is present. BERT also faces challenges solving the task of natural language inference (i.e., identifying entailments and contradictions) with monotonicity and negation (Geiger et al., 2020;Yanaka et al., 2019). Warstadt et al. (2019) show the limitations of BERT making acceptability judgments with sentences that contain negative polarity items. Most related to out work, Hossain et al. ( 2020) analyze the role of negation in three natural language inference corpora: RTE Bar-Haim et al., 2006;Giampiccolo et al., 2007;Bentivogli et al., 2009), SNLI and MNLI. In this paper, we present a similar analysis, but we move beyond natural language inference and work with eight corpora spanning six natural language understanding tasks.\n\n ",
    "all_spans": [
      {
        "span_text": "SuperGLUE  benchmarks.",
        "gpt_label": "Unsupported Claim",
        "reason": "SuperGLUE is a benchmark/dataset and should be cited at first mention, but no citation is provided here.",
        "start": 1751,
        "end": 1772
      },
      {
        "span_text": "Hossain et al. ( 2020)",
        "gpt_label": "Format",
        "reason": "Extraneous space after the opening parenthesis; the year should follow the parenthesis without a leading space.",
        "start": 3049,
        "end": 3070
      },
      {
        "span_text": "The literature has also shown that simple adversarial attacks including negation cues are very effective (Naik et al., 2018;Wallace et al., 2019). Kovatchev et al. (2019) analyze 11 paraphrasing systems and show that they obtain substantially worse results when negation is present.\n\nMore recently, Ribeiro et al. (2020) show that negation is one of the linguistic phenomena commercial sentiment analysis struggle with. Several previous works have investigated the (lack of) ability of transformers to make inferences when negation is present. For example, Ettinger (2020) conclude that BERT is unable to complete sentences when negation is present. BERT also faces challenges solving the task of natural language inference (i.e., identifying entailments and contradictions) with monotonicity and negation (Geiger et al., 2020;Yanaka et al., 2019). Warstadt et al. (2019) show the limitations of BERT making acceptability judgments with sentences that contain negative polarity items.",
        "gpt_label": "Coherence",
        "reason": "The passage jumps across different tasks and findings (adversarial attacks, paraphrasing, sentiment analysis, inference/NLI, acceptability judgments) without explicit transitions or explanation of how each cited work relates to the previous ones. Relationships are implied (all involve negation) but not stated, leading to abrupt shifts between sentences and studies.",
        "start": 2054,
        "end": 3022
      },
      {
        "span_text": "Previous work has shown that SNLI (Bowman et al., 2015) and MNLI (Williams et al., 2018) have annotation artifacts (e.g., negation is a strong indicator of contradictions) (Gururangan et al., 2018). The literature has also shown that simple adversarial attacks including negation cues are very effective (Naik et al., 2018;Wallace et al., 2019). Kovatchev et al. (2019) analyze 11 paraphrasing systems and show that they obtain substantially worse results when negation is present.\n\nMore recently, Ribeiro et al. (2020) show that negation is one of the linguistic phenomena commercial sentiment analysis struggle with. Several previous works have investigated the (lack of) ability of transformers to make inferences when negation is present. For example, Ettinger (2020) conclude that BERT is unable to complete sentences when negation is present. BERT also faces challenges solving the task of natural language inference (i.e., identifying entailments and contradictions) with monotonicity and negation (Geiger et al., 2020;Yanaka et al., 2019). Warstadt et al. (2019) show the limitations of BERT making acceptability judgments with sentences that contain negative polarity items.",
        "gpt_label": "Lacks synthesis",
        "reason": "This passage lists multiple prior studies and findings in a catalog-like manner without explicitly connecting them to the authors’ specific research aims or argument, and without articulating the gap these works leave open. The synthesis and positioning relative to the present work only appear afterward, leaving this segment as summary without integration.",
        "start": 1861,
        "end": 3022
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "SuperGLUE  benchmarks.",
          "gpt_label": "Unsupported Claim",
          "reason": "SuperGLUE is a benchmark/dataset and should be cited at first mention, but no citation is provided here.",
          "start": 1751,
          "end": 1772
        }
      ],
      "Format": [
        {
          "span_text": "Hossain et al. ( 2020)",
          "gpt_label": "Format",
          "reason": "Extraneous space after the opening parenthesis; the year should follow the parenthesis without a leading space.",
          "start": 3049,
          "end": 3070
        }
      ],
      "Coherence": [
        {
          "span_text": "The literature has also shown that simple adversarial attacks including negation cues are very effective (Naik et al., 2018;Wallace et al., 2019). Kovatchev et al. (2019) analyze 11 paraphrasing systems and show that they obtain substantially worse results when negation is present.\n\nMore recently, Ribeiro et al. (2020) show that negation is one of the linguistic phenomena commercial sentiment analysis struggle with. Several previous works have investigated the (lack of) ability of transformers to make inferences when negation is present. For example, Ettinger (2020) conclude that BERT is unable to complete sentences when negation is present. BERT also faces challenges solving the task of natural language inference (i.e., identifying entailments and contradictions) with monotonicity and negation (Geiger et al., 2020;Yanaka et al., 2019). Warstadt et al. (2019) show the limitations of BERT making acceptability judgments with sentences that contain negative polarity items.",
          "gpt_label": "Coherence",
          "reason": "The passage jumps across different tasks and findings (adversarial attacks, paraphrasing, sentiment analysis, inference/NLI, acceptability judgments) without explicit transitions or explanation of how each cited work relates to the previous ones. Relationships are implied (all involve negation) but not stated, leading to abrupt shifts between sentences and studies.",
          "start": 2054,
          "end": 3022
        }
      ],
      "Lacks synthesis": [
        {
          "span_text": "Previous work has shown that SNLI (Bowman et al., 2015) and MNLI (Williams et al., 2018) have annotation artifacts (e.g., negation is a strong indicator of contradictions) (Gururangan et al., 2018). The literature has also shown that simple adversarial attacks including negation cues are very effective (Naik et al., 2018;Wallace et al., 2019). Kovatchev et al. (2019) analyze 11 paraphrasing systems and show that they obtain substantially worse results when negation is present.\n\nMore recently, Ribeiro et al. (2020) show that negation is one of the linguistic phenomena commercial sentiment analysis struggle with. Several previous works have investigated the (lack of) ability of transformers to make inferences when negation is present. For example, Ettinger (2020) conclude that BERT is unable to complete sentences when negation is present. BERT also faces challenges solving the task of natural language inference (i.e., identifying entailments and contradictions) with monotonicity and negation (Geiger et al., 2020;Yanaka et al., 2019). Warstadt et al. (2019) show the limitations of BERT making acceptability judgments with sentences that contain negative polarity items.",
          "gpt_label": "Lacks synthesis",
          "reason": "This passage lists multiple prior studies and findings in a catalog-like manner without explicitly connecting them to the authors’ specific research aims or argument, and without articulating the gap these works leave open. The synthesis and positioning relative to the present work only appear afterward, leaving this segment as summary without integration.",
          "start": 1861,
          "end": 3022
        }
      ]
    }
  },
  "paper_42.txt": {
    "filename": "paper_42.txt",
    "full_text": "Introduction\n\nHuman language technologies can have a direct impact on people's everyday life. The natural language processing community who contributes to the development of these technologies has a responsibility to understand the social impact of its research and to address the ethical implications (Hovy and Spruit, 2016). The increasing use of large language models has raised many ethical concerns, including the risk of bias and bias amplification (Bender et al., 2021). Biases in NLP have received a lot of attention in recent years (Blodgett et al., 2020). However, the bulk of the work has addressed biases linked to the social and cultural experience of English speaking individuals in the United States. In this work, we seek to widen the scope of bias studies by creating material to measure social bias in multiple languages and social contexts. As a case study, we chose to address biases against specific demographic groups in France.\n\nThe CrowS-pairs dataset (Nangia et al., 2020) was recently developed to address nine types of bias. It contains pairs of sentences: a sentence that is more stereotyping and another that is less stereotyping. The goal is to present masked language models with these sentences to assess how the models rank them. If stereotyped sentences are consistently ranked higher than less stereotyped sentences, it characterizes the existence of bias in the model. While CrowS-pairs was designed to measure social bias against protected demographic groups in the US, many of the biases, such as gender or age, can also apply to other social contexts. However, other biases are very specific to the United States, such as those pertaining to African-Americans. This study provides a contribution to assessing the prevalence of US-centric contexts in CrowS-pairs.\n\nA recent study focusing on gender bias in English and German has shown that methods to evidence and mitigate bias in English do not necessarily carry well to other languages (Bartl et al., 2020). This highlights the importance of addressing bias in language models in multiple languages.\n\nWe chose to use the CrowS-pairs dataset as a starting point for our study with the hypothesis that the availability of a multilingual version of the dataset would allow for cross-language comparison of some types of bias. Furthermore, we also hypothesized that the process of enriching the dataset with sentence pairs in French would create an opportunity to characterize biases that are specific to each country and language.\n\nThe main contributions of this work are as follows:\n\n• We extend the CrowS-pairs dataset with 1,679 additional challenge pairs in French and make this new material freely available\n\n• We demonstrate the usability of the new dataset by evaluating bias in three French masked language models, as well as a multilingual model\n\n• We provide insights on biases that are specific to American and French social contexts and suggest guidelines for creating multilingual social bias challenge datasets that allows comparability between languages while also accounting for cultural and language specific biases\n\n ",
    "all_spans": [
      {
        "span_text": "However, the bulk of the work has addressed biases linked to the social and cultural experience of English speaking individuals in the United States.",
        "gpt_label": "Unsupported Claim",
        "reason": "This is a claim about the overall focus of prior research and should be supported with citations to surveys or representative studies; none are provided here.",
        "start": 560,
        "end": 708
      },
      {
        "span_text": "(Hovy and Spruit, 2016)",
        "gpt_label": "Format",
        "reason": "Uses 'and' between two authors inside a parenthetical citation; standard parenthetical styles (e.g., APA) require '&' (Hovy & Spruit, 2016).",
        "start": 301,
        "end": 324
      },
      {
        "span_text": "The increasing use of large language models has raised many ethical concerns, including the risk of bias and bias amplification (Bender et al., 2021). Biases in NLP have received a lot of attention in recent years (Blodgett et al., 2020).",
        "gpt_label": "Coherence",
        "reason": "Two consecutive citations are presented with an abrupt shift from general ethical concerns about large language models to a broad statement about attention to bias in NLP without an explicit connective explanation of how the latter builds on or relates to the former.",
        "start": 325,
        "end": 559
      },
      {
        "span_text": "A recent study focusing on gender bias in English and German has shown that methods to evidence and mitigate bias in English do not necessarily carry well to other languages (Bartl et al., 2020). This highlights the importance of addressing bias in language models in multiple languages.",
        "gpt_label": "Lacks synthesis",
        "reason": "This citation and general statement are not explicitly connected to the authors’ specific approach or contribution; it does not articulate how this finding motivates their chosen method (e.g., adapting CrowS-pairs to French) or the precise gap their work addresses.",
        "start": 1786,
        "end": 2070
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "However, the bulk of the work has addressed biases linked to the social and cultural experience of English speaking individuals in the United States.",
          "gpt_label": "Unsupported Claim",
          "reason": "This is a claim about the overall focus of prior research and should be supported with citations to surveys or representative studies; none are provided here.",
          "start": 560,
          "end": 708
        }
      ],
      "Format": [
        {
          "span_text": "(Hovy and Spruit, 2016)",
          "gpt_label": "Format",
          "reason": "Uses 'and' between two authors inside a parenthetical citation; standard parenthetical styles (e.g., APA) require '&' (Hovy & Spruit, 2016).",
          "start": 301,
          "end": 324
        }
      ],
      "Coherence": [
        {
          "span_text": "The increasing use of large language models has raised many ethical concerns, including the risk of bias and bias amplification (Bender et al., 2021). Biases in NLP have received a lot of attention in recent years (Blodgett et al., 2020).",
          "gpt_label": "Coherence",
          "reason": "Two consecutive citations are presented with an abrupt shift from general ethical concerns about large language models to a broad statement about attention to bias in NLP without an explicit connective explanation of how the latter builds on or relates to the former.",
          "start": 325,
          "end": 559
        }
      ],
      "Lacks synthesis": [
        {
          "span_text": "A recent study focusing on gender bias in English and German has shown that methods to evidence and mitigate bias in English do not necessarily carry well to other languages (Bartl et al., 2020). This highlights the importance of addressing bias in language models in multiple languages.",
          "gpt_label": "Lacks synthesis",
          "reason": "This citation and general statement are not explicitly connected to the authors’ specific approach or contribution; it does not articulate how this finding motivates their chosen method (e.g., adapting CrowS-pairs to French) or the precise gap their work addresses.",
          "start": 1786,
          "end": 2070
        }
      ]
    }
  },
  "paper_43.txt": {
    "filename": "paper_43.txt",
    "full_text": "Introduction\n\nGrammatical Error Correction (GEC) task has a purpose to correct grammatical errors in natural texts. It includes correcting errors in spelling, punctuation, grammar, morphology, word choice, and others. Intelligent GEC system receives text containing mistakes and produces its corrected version. GEC task is complicated and challenging: the accuracy of edits, inference speed, and memory limitations are the topics of intensive research.\n\nCurrently, Machine Translation (MT) is the mainstream approach for GEC. In this setting, errorful sentences correspond to the source language, and error-free sentences correspond to the target language. Early GEC-MT methods leveraged phrase-based statistical machine translation (PBSMT) (Yuan and Felice, 2013). Then they rapidly evolved to sequence-to-sequence Neural Machine Translation (NMT) based on gated recurrent neural networks (Yuan and Briscoe, 2016) and recent powerful Transformer-based Seq2Seq models. They autoregressively capture full dependency among output tokens; however, it might be slow due to sequential decoding. (Grundkiewicz et al., 2019) leveraged Transformer model (Vaswani et al., 2017) which was pre-trained on synthetic GEC data and right-to-left re-ranking for ensemble. (Kaneko et al., 2020) adopted several strategies of BERT (Devlin et al., 2018) usage for GEC. Recently, (Rothe et al., 2021) built their system on top of T5 (Xue et al., 2021), a xxl version of T5 Transformer encoder-decoder model and reached new state-of-the-art results (11B parameters).\n\nThe sequence tagging approach that generates a sequence of text edit operations encoded by tags for errorful input text is becoming more common now. LaserTagger (Malmi et al., 2019) is a sequence tagging model that casts text generation as a text editing task. Corrected texts are reconstructed from the inputs using three main edit operations: keeping a token, deleting it, and adding a phrase before the token. LaserTagger combines a BERT encoder with an autoregressive Transformer decoder, which predicts edit operations. Parallel Iterative Edit (PIE) model  does parallel decoding, achieving quality that is competitive with the Seq2Seq models 3 . It predicts edits instead of tokens and iteratively refines predictions to capture dependencies. A similar approach is presented in (Omelianchuk et al., 2020). GECToR system uses various Transformers as an encoder, linear layers with softmax for tag prediction and error detection instead of a decoder. It also managed to achieve competitive results being potentially several times faster than Seq2Seq because of replacing autoregressive decoder with linear output layers. Also, nowadays generation of synthetic data is becoming significant for most GEC models. Natural languages are rich, and their Grammars contain many rules and exceptions; therefore, professional linguists usually need to annotate highquality corpora for further training of ML-based systems mostly in a supervised manner (Dahlmeier et al., 2013), . At the same time, human annotation is expensive, so researchers are working on methods for augmentation of training data, synthetic data generation, and strategies for its efficient usage (Lichtarge et al., 2019), , (Stahlberg and Kumar, 2021). Most of the latest works use synthetic data to pre-train Transformer-based components of their models.\n\nIn this work, we are focusing on exploring sequence tagging models and their ensembles. Although most of our developments might eventually be applied to other languages, we work with English only in this study. Being a rich-resource language, English provides a highly competitive area for GEC task 3 . We leave dealing with other languages for future work.\n\n ",
    "all_spans": [
      {
        "span_text": "Currently, Machine Translation (MT) is the mainstream approach for GEC.",
        "gpt_label": "Unsupported Claim",
        "reason": "Makes a field-level claim about the dominant approach without citing evidence or surveys.",
        "start": 450,
        "end": 520
      },
      {
        "span_text": "recent powerful Transformer-based Seq2Seq models.",
        "gpt_label": "Unsupported Claim",
        "reason": "References \"recent\" prior work in general terms without citing specific works.",
        "start": 912,
        "end": 960
      },
      {
        "span_text": "The sequence tagging approach that generates a sequence of text edit operations encoded by tags for errorful input text is becoming more common now.",
        "gpt_label": "Unsupported Claim",
        "reason": "Trend claim about increasing adoption lacks supporting citations.",
        "start": 1529,
        "end": 1676
      },
      {
        "span_text": "Parallel Iterative Edit (PIE) model  does parallel decoding, achieving quality that is competitive with the Seq2Seq models 3 .",
        "gpt_label": "Unsupported Claim",
        "reason": "Introduces a specific model and asserts competitive performance without citing the corresponding paper or evidence; the superscript '3' is not a proper citation.",
        "start": 2049,
        "end": 2174
      },
      {
        "span_text": "Also, nowadays generation of synthetic data is becoming significant for most GEC models.",
        "gpt_label": "Unsupported Claim",
        "reason": "Broad trend claim about the field without citations to support it.",
        "start": 2643,
        "end": 2730
      },
      {
        "span_text": "Most of the latest works use synthetic data to pre-train Transformer-based components of their models.",
        "gpt_label": "Unsupported Claim",
        "reason": "Claims that \"most\" recent works follow a practice; should be backed by citations or a survey.",
        "start": 3232,
        "end": 3333
      },
      {
        "span_text": "Being a rich-resource language, English provides a highly competitive area for GEC task 3 .",
        "gpt_label": "Unsupported Claim",
        "reason": "Field-specific evaluative claim without citation; the '3' footnote is not a proper reference.",
        "start": 3544,
        "end": 3634
      },
      {
        "span_text": "3",
        "gpt_label": "Format",
        "reason": "Unbracketed numeric citation/footnote marker inconsistent with the author–year style used elsewhere; it should be formatted as a proper citation (e.g., [3]) or integrated into the author–year system.",
        "start": 756,
        "end": 757
      },
      {
        "span_text": "Also, nowadays generation of synthetic data is becoming significant for most GEC models. Natural languages are rich, and their Grammars contain many rules and exceptions; therefore, professional linguists usually need to annotate highquality corpora for further training of ML-based systems mostly in a supervised manner (Dahlmeier et al., 2013), . At the same time, human annotation is expensive, so researchers are working on methods for augmentation of training data, synthetic data generation, and strategies for its efficient usage (Lichtarge et al., 2019), , (Stahlberg and Kumar, 2021). Most of the latest works use synthetic data to pre-train Transformer-based components of their models.",
        "gpt_label": "Coherence",
        "reason": "Abrupt shift from discussing sequence tagging architectures to synthetic data without an explicit transition or explanation of relevance; the relationship between the cited works on annotation and synthetic data and the preceding model-focused discussion is implied rather than stated, making the multi-sentence segment feel disconnected.",
        "start": 2643,
        "end": 3333
      },
      {
        "span_text": "In this work, we are focusing on exploring sequence tagging models and their ensembles. Although most of our developments might eventually be applied to other languages, we work with English only in this study. Being a rich-resource language, English provides a highly competitive area for GEC task 3 . We leave dealing with other languages for future work.",
        "gpt_label": "Lacks synthesis",
        "reason": "This passage states the authors' focus and scope but does not connect it to the preceding literature, articulate a specific gap in prior work, or provide the authors’ motivation/argument for why exploring sequence tagging ensembles is needed. It follows summaries of related work without explicitly synthesizing them into a clear problem statement or rationale.",
        "start": 3335,
        "end": 3688
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "Currently, Machine Translation (MT) is the mainstream approach for GEC.",
          "gpt_label": "Unsupported Claim",
          "reason": "Makes a field-level claim about the dominant approach without citing evidence or surveys.",
          "start": 450,
          "end": 520
        },
        {
          "span_text": "recent powerful Transformer-based Seq2Seq models.",
          "gpt_label": "Unsupported Claim",
          "reason": "References \"recent\" prior work in general terms without citing specific works.",
          "start": 912,
          "end": 960
        },
        {
          "span_text": "The sequence tagging approach that generates a sequence of text edit operations encoded by tags for errorful input text is becoming more common now.",
          "gpt_label": "Unsupported Claim",
          "reason": "Trend claim about increasing adoption lacks supporting citations.",
          "start": 1529,
          "end": 1676
        },
        {
          "span_text": "Parallel Iterative Edit (PIE) model  does parallel decoding, achieving quality that is competitive with the Seq2Seq models 3 .",
          "gpt_label": "Unsupported Claim",
          "reason": "Introduces a specific model and asserts competitive performance without citing the corresponding paper or evidence; the superscript '3' is not a proper citation.",
          "start": 2049,
          "end": 2174
        },
        {
          "span_text": "Also, nowadays generation of synthetic data is becoming significant for most GEC models.",
          "gpt_label": "Unsupported Claim",
          "reason": "Broad trend claim about the field without citations to support it.",
          "start": 2643,
          "end": 2730
        },
        {
          "span_text": "Most of the latest works use synthetic data to pre-train Transformer-based components of their models.",
          "gpt_label": "Unsupported Claim",
          "reason": "Claims that \"most\" recent works follow a practice; should be backed by citations or a survey.",
          "start": 3232,
          "end": 3333
        },
        {
          "span_text": "Being a rich-resource language, English provides a highly competitive area for GEC task 3 .",
          "gpt_label": "Unsupported Claim",
          "reason": "Field-specific evaluative claim without citation; the '3' footnote is not a proper reference.",
          "start": 3544,
          "end": 3634
        }
      ],
      "Format": [
        {
          "span_text": "3",
          "gpt_label": "Format",
          "reason": "Unbracketed numeric citation/footnote marker inconsistent with the author–year style used elsewhere; it should be formatted as a proper citation (e.g., [3]) or integrated into the author–year system.",
          "start": 756,
          "end": 757
        }
      ],
      "Coherence": [
        {
          "span_text": "Also, nowadays generation of synthetic data is becoming significant for most GEC models. Natural languages are rich, and their Grammars contain many rules and exceptions; therefore, professional linguists usually need to annotate highquality corpora for further training of ML-based systems mostly in a supervised manner (Dahlmeier et al., 2013), . At the same time, human annotation is expensive, so researchers are working on methods for augmentation of training data, synthetic data generation, and strategies for its efficient usage (Lichtarge et al., 2019), , (Stahlberg and Kumar, 2021). Most of the latest works use synthetic data to pre-train Transformer-based components of their models.",
          "gpt_label": "Coherence",
          "reason": "Abrupt shift from discussing sequence tagging architectures to synthetic data without an explicit transition or explanation of relevance; the relationship between the cited works on annotation and synthetic data and the preceding model-focused discussion is implied rather than stated, making the multi-sentence segment feel disconnected.",
          "start": 2643,
          "end": 3333
        }
      ],
      "Lacks synthesis": [
        {
          "span_text": "In this work, we are focusing on exploring sequence tagging models and their ensembles. Although most of our developments might eventually be applied to other languages, we work with English only in this study. Being a rich-resource language, English provides a highly competitive area for GEC task 3 . We leave dealing with other languages for future work.",
          "gpt_label": "Lacks synthesis",
          "reason": "This passage states the authors' focus and scope but does not connect it to the preceding literature, articulate a specific gap in prior work, or provide the authors’ motivation/argument for why exploring sequence tagging ensembles is needed. It follows summaries of related work without explicitly synthesizing them into a clear problem statement or rationale.",
          "start": 3335,
          "end": 3688
        }
      ]
    }
  },
  "paper_44.txt": {
    "filename": "paper_44.txt",
    "full_text": "Introduction\n\nOpen-domain dialogue system often suffers from safe response (Li et al., 2015; problem as they could only refer to the context when generating a response. To alleviate this, Knowledge-grounded conversation (KGC) is proposed to introduce external fact and real-world commonsense as prior knowledge (Zhou et al., 2018a;Dinan et al., 2019;Zhao et al., 2020a), such that a dialogue system is able to ground the conversation with the provided knowledge and therefore generate informative and engaging responses. As external knowledge supplements the background to the inputs and decides what to say, knowledge selection is a key ingredient in KGC.\n\nNumerous methods have been developed to tackle the knowledge selection problem by sequential latent variables (Kim et al., 2020;Meng et al., 2020), reinforcement learning (Zhao et al., 2020b), or expectation maximization algorithm (Li et al., 2020). In spite of the progress in this task, knowledge selection remains an unsolved problem as the precision is still far from satisfactory in Wizard of Wikipedia (Dinan et al., 2019) and other benchmarks in KGC (Gopalakrishnan et al., 2019), which also hinders the optimization of subsequent response generation models. A crucial point is, they often make assumption that the golden knowledge is distinguishable as long as the dialogue context is known, yet this is not always held true because there exists a one-to-many relationship in conversation and the past utterance history in a dialogue session is insufficient to decide the knowledge selection or the future trend of a dialogue.\n\nAs is shown in Figure 1, personalization is a key to success in the task because knowledge selection is a personal or subjective process in nature. When people communicate with each other, their perception of dialogue context will evoke their past memory about relevant life experience, taste and values, which we refer to as personal memory. The aroused fragment of personal memory further guides their interest and preference for different knowledge. In other words, there exists a mapping from one's personal memory to its selection of knowledge.\n\nImporting persona memory into knowledge selection is a non-trivial task. One of the challenge is concretization of personal memory. Personal memory is an abstract concept related to user-specific experience, which is difficult to depict or model. Though it has been discussed in open-domain dialogue (Li et al., 2016;Zhang et al., 2018), no previous research sheds light on the personalization issue in KGC and there exists no dialogue dataset featured with external facts and personal memory at the same time. Besides, there is no annotated label to indicate which knowledge candidate a person will choose based on his or her personal memory. Namely, the mapping between personal memory and knowledge selection is highly unconstrained without golden label.\n\nTo address the above issue, we construct a KGC dataset featured with personalized memory repository, collecting user-specific utterance history under multiple types of context, which is a reflection of one's personal memory. And to discover the underlying relationship between the dialogue context, personal memory and knowledge, we propose a variational method and introduce two latent variables Z p and Z k to indicate the fragment of personal memory to evoke and the knowledge candidate to select respectively. And to model the mapping from Z p to Z k , we introduce an inverse mapping as a dual task and employ dual learning to allow the two mappings to teach each other. The motivation behind this is intuitive: The reconstruction of personal memory from selected knowledge candidate is natural and easy if the mapping from personal memory to knowledge is accurate. Extensive experiment shows that our methods outperform competitive baselines in both automatic evaluation and human evaluation, justifying the importance of introducing personal memory and the effect of the dual learning mechanism empirically.\n\nThe contributions of this work are three-fold:\n\n(1) We explore the personalization issue of the knowledge selection task in KGC and construct a dataset featured with user-specific personal mem-ory to benefit relevant research in the future. We are the first to explore the possibility of introducing personal memory into KGC.\n\n(2) We propose a novel variational method and introduce two latent variables to model the interdependency between the persona and knowledge. Besides, we employ dual learning to optimize the relationship between the dialogue context, personal memory and knowledge in a unified framework.\n\n(3) We conduct extensive experiments and verify the proposed methods empirically. Both the automatic and human evaluation evidence the efficacy of our proposed method.\n\n ",
    "all_spans": [
      {
        "span_text": "In spite of the progress in this task, knowledge selection remains an unsolved problem as the precision is still far from satisfactory in Wizard of Wikipedia (Dinan et al., 2019) and other benchmarks in KGC (Gopalakrishnan et al., 2019), which also hinders the optimization of subsequent response generation models.",
        "gpt_label": "Unsupported Claim",
        "reason": "Claims low precision and negative impact on downstream models without providing empirical evidence or citing studies that report these results; citing datasets alone does not substantiate performance assertions.",
        "start": 896,
        "end": 1208
      },
      {
        "span_text": "they often make assumption that the golden knowledge is distinguishable as long as the dialogue context is known,",
        "gpt_label": "Unsupported Claim",
        "reason": "Generalization about prior work practices lacks citations to specific papers that make this assumption.",
        "start": 1229,
        "end": 1342
      },
      {
        "span_text": "Though it has been discussed in open-domain dialogue (Li et al., 2016;Zhang et al., 2018), no previous research sheds light on the personalization issue in KGC and there exists no dialogue dataset featured with external facts and personal memory at the same time.",
        "gpt_label": "Unsupported Claim",
        "reason": "Strong novelty and absence claim about prior work and datasets requires supporting citations or qualification (e.g., “to the best of our knowledge”).",
        "start": 2369,
        "end": 2629
      },
      {
        "span_text": "Besides, there is no annotated label to indicate which knowledge candidate a person will choose based on his or her personal memory.",
        "gpt_label": "Unsupported Claim",
        "reason": "Asserts a universal property of existing datasets without evidence or references.",
        "start": 2630,
        "end": 2761
      },
      {
        "span_text": "We are the first to explore the possibility of introducing personal memory into KGC.",
        "gpt_label": "Unsupported Claim",
        "reason": "Firstness/novelty claim about prior work needs citation support or a careful qualification.",
        "start": 4227,
        "end": 4310
      },
      {
        "span_text": "(Li et al., 2015;",
        "gpt_label": "Format",
        "reason": "Citation is incomplete with a missing closing parenthesis/bracket.",
        "start": 75,
        "end": 91
      },
      {
        "span_text": "Besides, there is no annotated label to indicate which knowledge candidate a person will choose based on his or her personal memory. Namely, the mapping between personal memory and knowledge selection is highly unconstrained without golden label.\n\nTo address the above issue, we construct a KGC dataset featured with personalized memory repository, collecting user-specific utterance history under multiple types of context, which is a reflection of one's personal memory. And to discover the underlying relationship between the dialogue context, personal memory and knowledge, we propose a variational method and introduce two latent variables Z p and Z k to indicate the fragment of personal memory to evoke and the knowledge candidate to select respectively.",
        "gpt_label": "Coherence",
        "reason": "The transition from the problem of lacking annotated labels to constructing a dataset and proposing a variational method is abrupt. It is not explicitly explained how the new dataset addresses the label scarcity or how the proposed method leverages the absence of labels; the relationship is implied rather than articulated across these sentences.",
        "start": 2630,
        "end": 3387
      },
      {
        "span_text": "Numerous methods have been developed to tackle the knowledge selection problem by sequential latent variables (Kim et al., 2020;Meng et al., 2020), reinforcement learning (Zhao et al., 2020b), or expectation maximization algorithm (Li et al., 2020).",
        "gpt_label": "Lacks synthesis",
        "reason": "This sentence lists prior approaches with citations but does not synthesize them, explain their relationships or limitations, or explicitly connect them to the authors’ specific argument or proposed method within the same span.",
        "start": 651,
        "end": 895
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "In spite of the progress in this task, knowledge selection remains an unsolved problem as the precision is still far from satisfactory in Wizard of Wikipedia (Dinan et al., 2019) and other benchmarks in KGC (Gopalakrishnan et al., 2019), which also hinders the optimization of subsequent response generation models.",
          "gpt_label": "Unsupported Claim",
          "reason": "Claims low precision and negative impact on downstream models without providing empirical evidence or citing studies that report these results; citing datasets alone does not substantiate performance assertions.",
          "start": 896,
          "end": 1208
        },
        {
          "span_text": "they often make assumption that the golden knowledge is distinguishable as long as the dialogue context is known,",
          "gpt_label": "Unsupported Claim",
          "reason": "Generalization about prior work practices lacks citations to specific papers that make this assumption.",
          "start": 1229,
          "end": 1342
        },
        {
          "span_text": "Though it has been discussed in open-domain dialogue (Li et al., 2016;Zhang et al., 2018), no previous research sheds light on the personalization issue in KGC and there exists no dialogue dataset featured with external facts and personal memory at the same time.",
          "gpt_label": "Unsupported Claim",
          "reason": "Strong novelty and absence claim about prior work and datasets requires supporting citations or qualification (e.g., “to the best of our knowledge”).",
          "start": 2369,
          "end": 2629
        },
        {
          "span_text": "Besides, there is no annotated label to indicate which knowledge candidate a person will choose based on his or her personal memory.",
          "gpt_label": "Unsupported Claim",
          "reason": "Asserts a universal property of existing datasets without evidence or references.",
          "start": 2630,
          "end": 2761
        },
        {
          "span_text": "We are the first to explore the possibility of introducing personal memory into KGC.",
          "gpt_label": "Unsupported Claim",
          "reason": "Firstness/novelty claim about prior work needs citation support or a careful qualification.",
          "start": 4227,
          "end": 4310
        }
      ],
      "Format": [
        {
          "span_text": "(Li et al., 2015;",
          "gpt_label": "Format",
          "reason": "Citation is incomplete with a missing closing parenthesis/bracket.",
          "start": 75,
          "end": 91
        }
      ],
      "Coherence": [
        {
          "span_text": "Besides, there is no annotated label to indicate which knowledge candidate a person will choose based on his or her personal memory. Namely, the mapping between personal memory and knowledge selection is highly unconstrained without golden label.\n\nTo address the above issue, we construct a KGC dataset featured with personalized memory repository, collecting user-specific utterance history under multiple types of context, which is a reflection of one's personal memory. And to discover the underlying relationship between the dialogue context, personal memory and knowledge, we propose a variational method and introduce two latent variables Z p and Z k to indicate the fragment of personal memory to evoke and the knowledge candidate to select respectively.",
          "gpt_label": "Coherence",
          "reason": "The transition from the problem of lacking annotated labels to constructing a dataset and proposing a variational method is abrupt. It is not explicitly explained how the new dataset addresses the label scarcity or how the proposed method leverages the absence of labels; the relationship is implied rather than articulated across these sentences.",
          "start": 2630,
          "end": 3387
        }
      ],
      "Lacks synthesis": [
        {
          "span_text": "Numerous methods have been developed to tackle the knowledge selection problem by sequential latent variables (Kim et al., 2020;Meng et al., 2020), reinforcement learning (Zhao et al., 2020b), or expectation maximization algorithm (Li et al., 2020).",
          "gpt_label": "Lacks synthesis",
          "reason": "This sentence lists prior approaches with citations but does not synthesize them, explain their relationships or limitations, or explicitly connect them to the authors’ specific argument or proposed method within the same span.",
          "start": 651,
          "end": 895
        }
      ]
    }
  },
  "paper_45.txt": {
    "filename": "paper_45.txt",
    "full_text": "Related Work\n\nHate speech in user-generated content has been an active research area recently (Fortuna and Nunes, 2018). Researchers have built several datasets for hate speech detection from diverse sources like Twitter (Waseem and Hovy, 2016;Davidson et al., 2017), Yahoo! (Nobata et al., 2016), Fox News (Gao and Huang, 2017), Gab (Mathew et al., 2021) and Reddit (Qian et al., 2019).\n\nCompared to hate speech detection, few studies focus on detecting counter speech (Mathew et al., 2019;Ziems et al., 2020;Garland et al., 2020). Mathew et al. (2019) collect and handcode 6,898 counter hate comments from YouTube videos targeting Jews, Blacks and LGBT communities. Ziems et al. (2020) use a collection of hate and counter hate keywords relevant to COVID-19 and create a dataset containing 359 counter hate tweets targeting Asians. Garland et al. (2020) work with German tweets and define hate and counter speech based on the communities to which the authors belong. Another line of research focuses on curating datasets for counter speech generation using crowdsourcing (Qian et al., 2019) or with the help of trained operators (Chung et al., 2019;Fanton et al., 2021). However, synthetic language is rarely as rich as language in the wild. Even if it were, conclusions and models from synthetic data may not transfer to the real world. In this paper, we work with user-generated content expressing hate and counter-hate rather than synthetic content.\n\nTable 2 summarizes existing datasets for Hate and Counter-hate detection. Most of them do not include context information. In other words, the preceding comments are not provided when annotating Targets. Context does affect human judgments and has been taken into account for Hate detection (Gao and Huang, 2017;Vidgen et al., 2021;Pavlopoulos et al., 2020;Menini et al., 2021). Gao and Huang (2017) annotate hateful comments in the nested structures of 10 Fox News discussion threads. Vidgen et al. (2021)  Utilizing conversational context has also been explored in text classification tasks such as sentiment analysis (Ren et al., 2016), stance (Zubiaga et al., 2018) and sarcasm (Ghosh et al., 2020). To our knowledge, we are the first to investigate the role of context in Hate and Counter-hate detection.\n\n ",
    "all_spans": [
      {
        "span_text": "However, synthetic language is rarely as rich as language in the wild.",
        "gpt_label": "Unsupported Claim",
        "reason": "General assertion about the inferiority of synthetic language lacks a supporting citation or evidence.",
        "start": 1153,
        "end": 1222
      },
      {
        "span_text": "Even if it were, conclusions and models from synthetic data may not transfer to the real world.",
        "gpt_label": "Unsupported Claim",
        "reason": "Claim about domain transferability from synthetic to real-world data is made without citation.",
        "start": 1223,
        "end": 1317
      },
      {
        "span_text": "To our knowledge, we are the first to investigate the role of context in Hate and Counter-hate detection.",
        "gpt_label": "Unsupported Claim",
        "reason": "Novelty claim about prior work lacks supporting evidence or comprehensive citations demonstrating absence of prior studies.",
        "start": 2124,
        "end": 2228
      },
      {
        "span_text": "Context does affect human judgments and has been taken into account for Hate detection (Gao and Huang, 2017;Vidgen et al., 2021;Pavlopoulos et al., 2020;Menini et al., 2021). Gao and Huang (2017) annotate hateful comments in the nested structures of 10 Fox News discussion threads. Vidgen et al. (2021)  Utilizing conversational context has also been explored in text classification tasks such as sentiment analysis (Ren et al., 2016), stance (Zubiaga et al., 2018) and sarcasm (Ghosh et al., 2020).",
        "gpt_label": "Coherence",
        "reason": "The mention of Vidgen et al. (2021) is a fragment with no explanation, and the transition to the general statement about utilizing conversational context in other tasks is abrupt. The relationship between the specific hate-detection works and the broader text-classification context is implied but not explicitly stated, breaking coherence across these sentences.",
        "start": 1634,
        "end": 2123
      },
      {
        "span_text": "Vidgen et al. (2021)",
        "gpt_label": "Lacks synthesis",
        "reason": "This is a standalone, fragmentary citation with no accompanying description or integration into the argument, offering no connection to the authors’ perspective or contribution and thus lacking synthesis.",
        "start": 1911,
        "end": 1930
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "However, synthetic language is rarely as rich as language in the wild.",
          "gpt_label": "Unsupported Claim",
          "reason": "General assertion about the inferiority of synthetic language lacks a supporting citation or evidence.",
          "start": 1153,
          "end": 1222
        },
        {
          "span_text": "Even if it were, conclusions and models from synthetic data may not transfer to the real world.",
          "gpt_label": "Unsupported Claim",
          "reason": "Claim about domain transferability from synthetic to real-world data is made without citation.",
          "start": 1223,
          "end": 1317
        },
        {
          "span_text": "To our knowledge, we are the first to investigate the role of context in Hate and Counter-hate detection.",
          "gpt_label": "Unsupported Claim",
          "reason": "Novelty claim about prior work lacks supporting evidence or comprehensive citations demonstrating absence of prior studies.",
          "start": 2124,
          "end": 2228
        }
      ],
      "Format": [],
      "Coherence": [
        {
          "span_text": "Context does affect human judgments and has been taken into account for Hate detection (Gao and Huang, 2017;Vidgen et al., 2021;Pavlopoulos et al., 2020;Menini et al., 2021). Gao and Huang (2017) annotate hateful comments in the nested structures of 10 Fox News discussion threads. Vidgen et al. (2021)  Utilizing conversational context has also been explored in text classification tasks such as sentiment analysis (Ren et al., 2016), stance (Zubiaga et al., 2018) and sarcasm (Ghosh et al., 2020).",
          "gpt_label": "Coherence",
          "reason": "The mention of Vidgen et al. (2021) is a fragment with no explanation, and the transition to the general statement about utilizing conversational context in other tasks is abrupt. The relationship between the specific hate-detection works and the broader text-classification context is implied but not explicitly stated, breaking coherence across these sentences.",
          "start": 1634,
          "end": 2123
        }
      ],
      "Lacks synthesis": [
        {
          "span_text": "Vidgen et al. (2021)",
          "gpt_label": "Lacks synthesis",
          "reason": "This is a standalone, fragmentary citation with no accompanying description or integration into the argument, offering no connection to the authors’ perspective or contribution and thus lacking synthesis.",
          "start": 1911,
          "end": 1930
        }
      ]
    }
  },
  "paper_46.txt": {
    "filename": "paper_46.txt",
    "full_text": "Related Work\n\nNamed Entity Recognition The mainstream NER systems are designed to recognize flat entities and based on a sequence tagging framework. Collobert et al. (2011) introduced the linear-chain conditional random field (CRF) into neural networkbased sequence tagging models, which can explicitly encode the transition likelihoods between adjacent tags. Many researchers followed this work, and employed LSTM as the encoder. In addition, character-level representations are typically used for English tasks (Huang et al., 2015;Lample et al., 2016;Ma and Hovy, 2016;Chiu and Nichols, 2016), whereas lexicon information is helpful for Chinese NER (Zhang and Yang, 2018;Ma et al., 2020;Li et al., 2020a).\n\nNested NER allows a token to belong to multiple entities, which conflicts with the plain sequence tagging framework. Ju et al. (2018) proposed to use stacked LSTM-CRFs to predict from inner to outer entities. Straková et al. (2019) concatenated the BILOU tags for each token inside the nested entities, which allows the LSTM-CRF to work as for flat entities. Li et al. (2020b) reformulated nested NER as a machine reading comprehension task. Shen et al. (2021) proposed to recognize nested entities by the two-stage object detection method widely used in computer vision.\n\nRecent years, a body of literature emerged on span-based models, which were compatible with both flat and nested entities, and achieved SOTA performance (Eberts and Ulges, 2020;Yu et al., 2020;Li et al., 2021). These models typically enumerate all possible candidate text spans and then classify each span into entity types. In this work, the biaffine model (Yu et al., 2020) is chosen and re-implemented with slight modifications as our baseline, because of its high performance and compatibility with boundary smoothing.\n\nIn addition, pretrained language models, also known as contextualized embeddings, were also widely introduced to NER models, and significantly boosted the model performance (Peters et al., 2018;Devlin et al., 2019). They are used in our baseline by default.\n\nLabel Smoothing Szegedy et al. (2016) proposed the label smoothing as a regularization technique to improve the accuracy of the Inception networks on ImageNet. By explicitly assigning a small probability to non-ground-truth labels, label smoothing can prevent the models from becoming too confident about the predictions, and thus improve generalization. It turned out to be a useful alternative to the standard cross entropy loss, and has been widely adopted to fight against the over-confidence (Zoph et al., 2018;Chorowski and Jaitly, 2017;Vaswani et al., 2017), improve the model calibration (Müller et al., 2019), and denoise incorrect labels (Lukasik et al., 2020).\n\nOur proposed boundary smoothing applies the smoothing technique to entity boundaries, rather than labels. This is driven by the observation that entity boundaries are more ambiguous and inconsistent to annotate in NER engineering. To the best of our knowledge, this study is the first that focuses on the effect of smoothing regularization on NER models.\n\n ",
    "all_spans": [
      {
        "span_text": "The mainstream NER systems are designed to recognize flat entities and based on a sequence tagging framework.",
        "gpt_label": "Unsupported Claim",
        "reason": "Sweeping claim about the dominant design of NER systems is made without citation at first mention; prior work should be cited to support this statement.",
        "start": 39,
        "end": 147
      },
      {
        "span_text": "Many researchers followed this work, and employed LSTM as the encoder.",
        "gpt_label": "Unsupported Claim",
        "reason": "Vague claim about subsequent research trends lacks supporting citations to specific studies.",
        "start": 357,
        "end": 426
      },
      {
        "span_text": "This is driven by the observation that entity boundaries are more ambiguous and inconsistent to annotate in NER engineering.",
        "gpt_label": "Unsupported Claim",
        "reason": "Claims widespread ambiguity/inconsistency in NER boundary annotation without providing empirical evidence or references.",
        "start": 2807,
        "end": 2930
      },
      {
        "span_text": "To the best of our knowledge, this study is the first that focuses on the effect of smoothing regularization on NER models.",
        "gpt_label": "Unsupported Claim",
        "reason": "Novelty claim about being the first in the literature is not substantiated with citations or a survey demonstrating absence of prior work.",
        "start": 2931,
        "end": 3053
      },
      {
        "span_text": "Ju et al. (2018) proposed to use stacked LSTM-CRFs to predict from inner to outer entities. Straková et al. (2019) concatenated the BILOU tags for each token inside the nested entities, which allows the LSTM-CRF to work as for flat entities. Li et al. (2020b) reformulated nested NER as a machine reading comprehension task. Shen et al. (2021) proposed to recognize nested entities by the two-stage object detection method widely used in computer vision.",
        "gpt_label": "Coherence",
        "reason": "These sentences list disparate approaches to nested NER without explicit transitions or relationships (e.g., comparison, contrast, building upon), making the connection between successive cited works abrupt and only implicitly related by the shared topic.",
        "start": 816,
        "end": 1262
      },
      {
        "span_text": "Nested NER allows a token to belong to multiple entities, which conflicts with the plain sequence tagging framework. Ju et al. (2018) proposed to use stacked LSTM-CRFs to predict from inner to outer entities. Straková et al. (2019) concatenated the BILOU tags for each token inside the nested entities, which allows the LSTM-CRF to work as for flat entities. Li et al. (2020b) reformulated nested NER as a machine reading comprehension task. Shen et al. (2021) proposed to recognize nested entities by the two-stage object detection method widely used in computer vision.",
        "gpt_label": "Lacks synthesis",
        "reason": "This paragraph lists prior approaches to nested NER without connecting them to the authors’ own method, identifying a specific gap, or articulating their perspective on how these works motivate or relate to their contribution.",
        "start": 700,
        "end": 1262
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "The mainstream NER systems are designed to recognize flat entities and based on a sequence tagging framework.",
          "gpt_label": "Unsupported Claim",
          "reason": "Sweeping claim about the dominant design of NER systems is made without citation at first mention; prior work should be cited to support this statement.",
          "start": 39,
          "end": 147
        },
        {
          "span_text": "Many researchers followed this work, and employed LSTM as the encoder.",
          "gpt_label": "Unsupported Claim",
          "reason": "Vague claim about subsequent research trends lacks supporting citations to specific studies.",
          "start": 357,
          "end": 426
        },
        {
          "span_text": "This is driven by the observation that entity boundaries are more ambiguous and inconsistent to annotate in NER engineering.",
          "gpt_label": "Unsupported Claim",
          "reason": "Claims widespread ambiguity/inconsistency in NER boundary annotation without providing empirical evidence or references.",
          "start": 2807,
          "end": 2930
        },
        {
          "span_text": "To the best of our knowledge, this study is the first that focuses on the effect of smoothing regularization on NER models.",
          "gpt_label": "Unsupported Claim",
          "reason": "Novelty claim about being the first in the literature is not substantiated with citations or a survey demonstrating absence of prior work.",
          "start": 2931,
          "end": 3053
        }
      ],
      "Format": [],
      "Coherence": [
        {
          "span_text": "Ju et al. (2018) proposed to use stacked LSTM-CRFs to predict from inner to outer entities. Straková et al. (2019) concatenated the BILOU tags for each token inside the nested entities, which allows the LSTM-CRF to work as for flat entities. Li et al. (2020b) reformulated nested NER as a machine reading comprehension task. Shen et al. (2021) proposed to recognize nested entities by the two-stage object detection method widely used in computer vision.",
          "gpt_label": "Coherence",
          "reason": "These sentences list disparate approaches to nested NER without explicit transitions or relationships (e.g., comparison, contrast, building upon), making the connection between successive cited works abrupt and only implicitly related by the shared topic.",
          "start": 816,
          "end": 1262
        }
      ],
      "Lacks synthesis": [
        {
          "span_text": "Nested NER allows a token to belong to multiple entities, which conflicts with the plain sequence tagging framework. Ju et al. (2018) proposed to use stacked LSTM-CRFs to predict from inner to outer entities. Straková et al. (2019) concatenated the BILOU tags for each token inside the nested entities, which allows the LSTM-CRF to work as for flat entities. Li et al. (2020b) reformulated nested NER as a machine reading comprehension task. Shen et al. (2021) proposed to recognize nested entities by the two-stage object detection method widely used in computer vision.",
          "gpt_label": "Lacks synthesis",
          "reason": "This paragraph lists prior approaches to nested NER without connecting them to the authors’ own method, identifying a specific gap, or articulating their perspective on how these works motivate or relate to their contribution.",
          "start": 700,
          "end": 1262
        }
      ]
    }
  },
  "paper_47.txt": {
    "filename": "paper_47.txt",
    "full_text": "Related Work\n\nOpen-Domain Response Generation Recent work of open-domain response generation gener-ally follows the work of Ritter et al. (2011) where the task is treated as a machine translation task, and many of them use a Seq2Seq structure (Sutskever et al., 2014) following previous work (Vinyals and Le, 2015;Shang et al., 2015;Sordoni et al., 2015). In recent years, substantial improvements have been made (Serban et al., 2017;Li et al., 2016;Wolf et al., 2019), and embeddings are used to control response generation on extra information such as persona (Li et al., 2016), profiles (Yang et al., 2017), coherence (Xu et al., 2018, emotions (Huang et al., 2018), and dialogue attributes like response-relatedness (See et al., 2019). However, there is a lack of work that uses embeddings to control response generation over multiple corpora. Our work follows the common models of opendomain conversational systems, while we study the problem of multiple corpora of different domains.\n\n ",
    "all_spans": [
      {
        "span_text": "However, there is a lack of work that uses embeddings to control response generation over multiple corpora.",
        "gpt_label": "Unsupported Claim",
        "reason": "Claims an absence of prior work without providing citations or evidence (e.g., surveys or comparisons to closely related studies) to substantiate the gap.",
        "start": 726,
        "end": 832
      },
      {
        "span_text": "(Xu et al., 2018",
        "gpt_label": "Format",
        "reason": "Missing closing parenthesis in the citation, leading to incorrect punctuation.",
        "start": 611,
        "end": 626
      },
      {
        "span_text": "In recent years, substantial improvements have been made (Serban et al., 2017;Li et al., 2016;Wolf et al., 2019), and embeddings are used to control response generation on extra information such as persona (Li et al., 2016), profiles (Yang et al., 2017), coherence (Xu et al., 2018, emotions (Huang et al., 2018), and dialogue attributes like response-relatedness (See et al., 2019). However, there is a lack of work that uses embeddings to control response generation over multiple corpora.",
        "gpt_label": "Coherence",
        "reason": "The transition from citing general improvements and various embedding-controlled attributes to the claim of a gap on multiple corpora is abrupt. It is not made explicit how the cited works relate to the multi-corpus issue (e.g., that they are single-corpus), and the sentence conflates different citation groups (improvements vs. embedding controls) without clarifying their relationships, leaving the connection between the works and the stated gap implied rather than stated.",
        "start": 351,
        "end": 832
      },
      {
        "span_text": "Our work follows the common models of opendomain conversational systems, while we study the problem of multiple corpora of different domains.",
        "gpt_label": "Lacks synthesis",
        "reason": "The sentence states the authors’ contribution but does not explicitly connect how their approach addresses the identified gap (using embeddings to control generation across multiple corpora) or synthesize its relationship to the cited prior work; it lacks articulation of perspective/motivation and the specific mechanism linking their method to the gap.",
        "start": 833,
        "end": 973
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "However, there is a lack of work that uses embeddings to control response generation over multiple corpora.",
          "gpt_label": "Unsupported Claim",
          "reason": "Claims an absence of prior work without providing citations or evidence (e.g., surveys or comparisons to closely related studies) to substantiate the gap.",
          "start": 726,
          "end": 832
        }
      ],
      "Format": [
        {
          "span_text": "(Xu et al., 2018",
          "gpt_label": "Format",
          "reason": "Missing closing parenthesis in the citation, leading to incorrect punctuation.",
          "start": 611,
          "end": 626
        }
      ],
      "Coherence": [
        {
          "span_text": "In recent years, substantial improvements have been made (Serban et al., 2017;Li et al., 2016;Wolf et al., 2019), and embeddings are used to control response generation on extra information such as persona (Li et al., 2016), profiles (Yang et al., 2017), coherence (Xu et al., 2018, emotions (Huang et al., 2018), and dialogue attributes like response-relatedness (See et al., 2019). However, there is a lack of work that uses embeddings to control response generation over multiple corpora.",
          "gpt_label": "Coherence",
          "reason": "The transition from citing general improvements and various embedding-controlled attributes to the claim of a gap on multiple corpora is abrupt. It is not made explicit how the cited works relate to the multi-corpus issue (e.g., that they are single-corpus), and the sentence conflates different citation groups (improvements vs. embedding controls) without clarifying their relationships, leaving the connection between the works and the stated gap implied rather than stated.",
          "start": 351,
          "end": 832
        }
      ],
      "Lacks synthesis": [
        {
          "span_text": "Our work follows the common models of opendomain conversational systems, while we study the problem of multiple corpora of different domains.",
          "gpt_label": "Lacks synthesis",
          "reason": "The sentence states the authors’ contribution but does not explicitly connect how their approach addresses the identified gap (using embeddings to control generation across multiple corpora) or synthesize its relationship to the cited prior work; it lacks articulation of perspective/motivation and the specific mechanism linking their method to the gap.",
          "start": 833,
          "end": 973
        }
      ]
    }
  },
  "paper_49.txt": {
    "filename": "paper_49.txt",
    "full_text": "Related Work\n\nTraditional sentiment analysis tasks are sentencelevel (Yang and Cardie, 2014;Severyn and Moschitti, 2015) or document-level (Dou, 2017;Lyu et al., 2020) oriented. In contrast, Aspect-based Sentiment Analysis (ABSA) is an aspect or entity oriented fine-grained sentiment analysis task. The most three basic subtasks are Aspect Term Extraction (ATE) (Hu and Liu, 2004;Yin et al., 2016;Li et al., 2018b;Xu et al., 2018;Ma et al., 2019;Chen and Qian, 2020;, Aspect Sentiment Classification (ASC) (Wang et al., 2016b;Tang et al., 2016;Ma et al., 2017;Fan et al., 2018;Li et al., 2018a;Li et al., 2021) and Opinion Term Extraction (OTE) Cardie, 2012, 2013;Fan et al., 2019;Wu et al., 2020b). The studies solve these tasks separately and ignore the dependency between these subtasks. Therefore, some efforts devoted to couple the two subtasks and proposed effective models to jointly extract aspect-based pairs. This kind of work mainly has two tasks: Aspect and Opinion Term Co-Extraction (AOTE) (Wang et al., 2016aDai and Song,  2019; Wang and Pan, 2019;Wu et al., 2020a) and Aspect-Sentiment Pair Extraction (ASPE) (Ma et al., 2018;Li et al., 2019a,b;He et al., 2019).\n\nMost recently, Peng et al. (2020) first proposed the ASTE task and developed a two-stage pipeline framework to couple together aspect extraction, aspect sentiment classification and opinion extraction. To further explore this task, (Mao et al., 2021;Chen et al., 2021a) transformed ASTE to a machine reading comprehension problem and utilized the shared BERT encoder to obatin the triplets after multiple stages decoding. Another line of research focuses on designing a new tagging scheme that makes the model can extract the triplets in an endto-end fashion Wu et al., 2020a;Xu et al., 2021;Yan et al., 2021). For instance,  proposed a positionaware tagging scheme, which solves the limitations related to existing works by enriching the expressiveness of labels. Wu et al. (2020a) proposed a grid tagging scheme, similar to table filling (Miwa and Sasaki, 2014;Gupta et al., 2016), to solve this task in an end-to-end manner. Yan et al. (2021) converted ASTE task into a generative formulation. However, these approaches generally ignore the relations between words and linguistic features which effectively promote the triplet extraction.\n\n ",
    "all_spans": [
      {
        "span_text": "The studies solve these tasks separately and ignore the dependency between these subtasks.",
        "gpt_label": "Unsupported Claim",
        "reason": "General claim about prior work's limitations lacks a supporting citation.",
        "start": 685,
        "end": 774
      },
      {
        "span_text": "proposed effective models",
        "gpt_label": "Unsupported Claim",
        "reason": "Evaluative assertion of effectiveness is made without evidence or citation.",
        "start": 838,
        "end": 863
      },
      {
        "span_text": "For instance,  proposed a positionaware tagging scheme, which solves the limitations related to existing works by enriching the expressiveness of labels.",
        "gpt_label": "Unsupported Claim",
        "reason": "Mentions a specific prior work without citing it and claims it solves limitations without evidence.",
        "start": 1759,
        "end": 1911
      },
      {
        "span_text": "However, these approaches generally ignore the relations between words and linguistic features which effectively promote the triplet extraction.",
        "gpt_label": "Unsupported Claim",
        "reason": "Broad criticism of prior approaches and claim about the benefits of linguistic features are made without citations.",
        "start": 2139,
        "end": 2282
      },
      {
        "span_text": "Another line of research focuses on designing a new tagging scheme that makes the model can extract the triplets in an endto-end fashion Wu et al., 2020a;Xu et al., 2021;Yan et al., 2021). For instance,  proposed a positionaware tagging scheme, which solves the limitations related to existing works by enriching the expressiveness of labels. Wu et al. (2020a) proposed a grid tagging scheme, similar to table filling (Miwa and Sasaki, 2014;Gupta et al., 2016), to solve this task in an end-to-end manner. Yan et al. (2021) converted ASTE task into a generative formulation.",
        "gpt_label": "Coherence",
        "reason": "The transition from tagging-scheme methods to a generative formulation is abrupt and the relationship between these approaches is not made explicit. The sentence beginning with 'For instance,' omits the author(s), leaving unclear which cited work it refers to. The connections among the listed works are implied rather than explicitly articulated, resulting in weak transitions across multiple sentences.",
        "start": 1574,
        "end": 2138
      },
      {
        "span_text": "For instance,  proposed a positionaware tagging scheme, which solves the limitations related to existing works by enriching the expressiveness of labels.",
        "gpt_label": "Lacks synthesis",
        "reason": "Provides an example without attribution and does not connect the cited line of work to the authors’ own approach or clearly articulate the gap/motivation in relation to their contribution.",
        "start": 1759,
        "end": 1911
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "The studies solve these tasks separately and ignore the dependency between these subtasks.",
          "gpt_label": "Unsupported Claim",
          "reason": "General claim about prior work's limitations lacks a supporting citation.",
          "start": 685,
          "end": 774
        },
        {
          "span_text": "proposed effective models",
          "gpt_label": "Unsupported Claim",
          "reason": "Evaluative assertion of effectiveness is made without evidence or citation.",
          "start": 838,
          "end": 863
        },
        {
          "span_text": "For instance,  proposed a positionaware tagging scheme, which solves the limitations related to existing works by enriching the expressiveness of labels.",
          "gpt_label": "Unsupported Claim",
          "reason": "Mentions a specific prior work without citing it and claims it solves limitations without evidence.",
          "start": 1759,
          "end": 1911
        },
        {
          "span_text": "However, these approaches generally ignore the relations between words and linguistic features which effectively promote the triplet extraction.",
          "gpt_label": "Unsupported Claim",
          "reason": "Broad criticism of prior approaches and claim about the benefits of linguistic features are made without citations.",
          "start": 2139,
          "end": 2282
        }
      ],
      "Format": [],
      "Coherence": [
        {
          "span_text": "Another line of research focuses on designing a new tagging scheme that makes the model can extract the triplets in an endto-end fashion Wu et al., 2020a;Xu et al., 2021;Yan et al., 2021). For instance,  proposed a positionaware tagging scheme, which solves the limitations related to existing works by enriching the expressiveness of labels. Wu et al. (2020a) proposed a grid tagging scheme, similar to table filling (Miwa and Sasaki, 2014;Gupta et al., 2016), to solve this task in an end-to-end manner. Yan et al. (2021) converted ASTE task into a generative formulation.",
          "gpt_label": "Coherence",
          "reason": "The transition from tagging-scheme methods to a generative formulation is abrupt and the relationship between these approaches is not made explicit. The sentence beginning with 'For instance,' omits the author(s), leaving unclear which cited work it refers to. The connections among the listed works are implied rather than explicitly articulated, resulting in weak transitions across multiple sentences.",
          "start": 1574,
          "end": 2138
        }
      ],
      "Lacks synthesis": [
        {
          "span_text": "For instance,  proposed a positionaware tagging scheme, which solves the limitations related to existing works by enriching the expressiveness of labels.",
          "gpt_label": "Lacks synthesis",
          "reason": "Provides an example without attribution and does not connect the cited line of work to the authors’ own approach or clearly articulate the gap/motivation in relation to their contribution.",
          "start": 1759,
          "end": 1911
        }
      ]
    }
  },
  "paper_50.txt": {
    "filename": "paper_50.txt",
    "full_text": "Introduction\n\nGrapheme-to-phoneme conversion (G2P) is the task of converting grapheme sequences into corresponding phoneme sequences. Many languages have the difficulty that some grapheme sequences correspond to more than one different phoneme sequence depending on the context.\n\nG2P plays a key role in speech and text processing systems, especially in text-to-speech (TTS) systems. These systems have to produce speech sounds for every word or phrase, even those not contained in a dictionary. In low-resource languages, it is fundamentally difficult to obtain large vocabulary dictionaries with pronunciations. Therefore, pronunciations need to be predicted from character sequences.\n\nIn many languages, each word is composed of syllables and each syllable is composed of characters following the orthography rules of that language. This means that G2P can be formulated as the task of selecting the best path in a lattice generated for a given input word or phrase if we prepare enough orthography rules to make sure that any lattice generated almost certainly includes the path for the correct pronunciation.\n\nAs the result of some effort, we prepared Thai orthography rules. Almost all possible paths in a lattice can be generated from these, and each path needs to be evaluated using a phonological language model to select the best path. With this in mind, we propose a novel G2P method based on a neural regression model that is trained using neural networks to predict how similar a pronunciation candidate is to the correct pronunciation. After generating a set of candidates for an input word or phrase using the orthography rules, this model selects the best-similarity pronunciation from the candidates.\n\nIn the following sections, we describe the proposed method and explain experiments on a dataset of Thai vocabulary entries with pronunciations collected from Wiktionary. After that, we show that the proposed method outperforms encoder-decoder sequence models in terms of the difference between correct and predicted pronunciations, and demonstrate that incorrect, strange output sometimes occurs when using encoder-decoder sequence models while error is within the expected range when using the proposed method. The code is available at https://github.com/T0106661.\n\n ",
    "all_spans": [
      {
        "span_text": "G2P plays a key role in speech and text processing systems, especially in text-to-speech (TTS) systems.",
        "gpt_label": "Unsupported Claim",
        "reason": "General field-wide claim about importance should be supported with citations to foundational TTS/G2P literature.",
        "start": 278,
        "end": 380
      },
      {
        "span_text": "This means that G2P can be formulated as the task of selecting the best path in a lattice generated for a given input word or phrase if we prepare enough orthography rules to make sure that any lattice generated almost certainly includes the path for the correct pronunciation.",
        "gpt_label": "Unsupported Claim",
        "reason": "Presents a specific methodological formulation that is known in prior work without citing any sources establishing this approach.",
        "start": 829,
        "end": 1105
      },
      {
        "span_text": "a dataset of Thai vocabulary entries with pronunciations collected from Wiktionary.",
        "gpt_label": "Unsupported Claim",
        "reason": "First mention of a dataset/resource (Wiktionary) should include a citation or reference.",
        "start": 1793,
        "end": 1875
      },
      {
        "span_text": "encoder-decoder sequence models",
        "gpt_label": "Unsupported Claim",
        "reason": "Refers to a class of prior methods without citing representative or canonical works introducing or applying these models to G2P.",
        "start": 1933,
        "end": 1964
      },
      {
        "span_text": "https://github.com/T0106661.",
        "gpt_label": "Format",
        "reason": "Raw URL presented as a citation without proper academic citation formatting (e.g., bracketed reference or bibliographic entry), and includes a trailing period that can break the link.",
        "start": 2242,
        "end": 2268
      },
      {
        "span_text": "Almost all possible paths in a lattice can be generated from these, and each path needs to be evaluated using a phonological language model to select the best path. With this in mind, we propose a novel G2P method based on a neural regression model that is trained using neural networks to predict how similar a pronunciation candidate is to the correct pronunciation.",
        "gpt_label": "Coherence",
        "reason": "The transition from using a phonological language model for path evaluation to proposing a neural regression model is abrupt. It is unclear whether the neural regression replaces or augments the phonological language model, leaving the relationship between the two approaches implied but not explicitly stated.",
        "start": 1172,
        "end": 1538
      },
      {
        "span_text": "As the result of some effort, we prepared Thai orthography rules. Almost all possible paths in a lattice can be generated from these, and each path needs to be evaluated using a phonological language model to select the best path. With this in mind, we propose a novel G2P method based on a neural regression model that is trained using neural networks to predict how similar a pronunciation candidate is to the correct pronunciation. After generating a set of candidates for an input word or phrase using the orthography rules, this model selects the best-similarity pronunciation from the candidates.",
        "gpt_label": "Lacks synthesis",
        "reason": "This passage introduces the method immediately after setup without connecting it to prior work or explicitly stating the specific gap it addresses. The motivation for why this approach is needed over existing methods is not articulated, resulting in weak synthesis between background and contribution.",
        "start": 1107,
        "end": 1705
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "G2P plays a key role in speech and text processing systems, especially in text-to-speech (TTS) systems.",
          "gpt_label": "Unsupported Claim",
          "reason": "General field-wide claim about importance should be supported with citations to foundational TTS/G2P literature.",
          "start": 278,
          "end": 380
        },
        {
          "span_text": "This means that G2P can be formulated as the task of selecting the best path in a lattice generated for a given input word or phrase if we prepare enough orthography rules to make sure that any lattice generated almost certainly includes the path for the correct pronunciation.",
          "gpt_label": "Unsupported Claim",
          "reason": "Presents a specific methodological formulation that is known in prior work without citing any sources establishing this approach.",
          "start": 829,
          "end": 1105
        },
        {
          "span_text": "a dataset of Thai vocabulary entries with pronunciations collected from Wiktionary.",
          "gpt_label": "Unsupported Claim",
          "reason": "First mention of a dataset/resource (Wiktionary) should include a citation or reference.",
          "start": 1793,
          "end": 1875
        },
        {
          "span_text": "encoder-decoder sequence models",
          "gpt_label": "Unsupported Claim",
          "reason": "Refers to a class of prior methods without citing representative or canonical works introducing or applying these models to G2P.",
          "start": 1933,
          "end": 1964
        }
      ],
      "Format": [
        {
          "span_text": "https://github.com/T0106661.",
          "gpt_label": "Format",
          "reason": "Raw URL presented as a citation without proper academic citation formatting (e.g., bracketed reference or bibliographic entry), and includes a trailing period that can break the link.",
          "start": 2242,
          "end": 2268
        }
      ],
      "Coherence": [
        {
          "span_text": "Almost all possible paths in a lattice can be generated from these, and each path needs to be evaluated using a phonological language model to select the best path. With this in mind, we propose a novel G2P method based on a neural regression model that is trained using neural networks to predict how similar a pronunciation candidate is to the correct pronunciation.",
          "gpt_label": "Coherence",
          "reason": "The transition from using a phonological language model for path evaluation to proposing a neural regression model is abrupt. It is unclear whether the neural regression replaces or augments the phonological language model, leaving the relationship between the two approaches implied but not explicitly stated.",
          "start": 1172,
          "end": 1538
        }
      ],
      "Lacks synthesis": [
        {
          "span_text": "As the result of some effort, we prepared Thai orthography rules. Almost all possible paths in a lattice can be generated from these, and each path needs to be evaluated using a phonological language model to select the best path. With this in mind, we propose a novel G2P method based on a neural regression model that is trained using neural networks to predict how similar a pronunciation candidate is to the correct pronunciation. After generating a set of candidates for an input word or phrase using the orthography rules, this model selects the best-similarity pronunciation from the candidates.",
          "gpt_label": "Lacks synthesis",
          "reason": "This passage introduces the method immediately after setup without connecting it to prior work or explicitly stating the specific gap it addresses. The motivation for why this approach is needed over existing methods is not articulated, resulting in weak synthesis between background and contribution.",
          "start": 1107,
          "end": 1705
        }
      ]
    }
  },
  "paper_51.txt": {
    "filename": "paper_51.txt",
    "full_text": "Introduction\n\nVision and language are two of most important information sources, and the fact that humans can reason jointly with both sources at the same time has motivated artificial intelligence research to consider visually-grounded language understanding. Most work in this area has focused on reasoning with local evidence (Suhr et al., 2018;Hudson and Manning, 2019;Lu et al., 2020;Liu et al., 2021), e.g. asking about factoid questions such as the colors or shapes of objects and numbers of people, yet few of works encourage open-ended reasoning where a model needs to look beyond task inputs. However, humans can relate visual cues to corresponding contextual information that could be multi-modal, and draw on background knowledge when interpreting and grounding images. For example, as Figure 1 shows, people that are familiar with the news can infer that the location is Times Square through the iconic screen panels, and further estimate the period of time by looking a the crowds and the signs. And, this can be done without explicitly including related news pieces as input. In fact, even though some people would not have the prior knowledge to identify the relevant events, it is likely that they would have good estimate of the location and time by interpreting textual evidence in the image, the language, entity names, building styles, and other details in the input image.\n\nIn this work, we identify and formulate this problem, spatio-temporal grounding of images, a task aiming at identifying the time and location the given image was taken. Specifically, we develop a novel dataset TARA, ( Time and pl Ace for Reasoning beyond the im Age), a challenging and important task that tasks models with grounding images to real-world spatial and temporal information. In our collection, we make sure that if models can accurately find images’ creation time and location, they would need to successfully link the visual clues with contexts, which are often only found in texts such as news, stories and encyclopedias. As a result, this task motivates models to consider the association between visual information and language more closely and in a more open-ended setting. Figure 2 shows an example from TARA, and Figure 3 shows a possible way for a model to ground the image to its spatio-temporal information. The system starts with grounding multiple segments from the image, and uses the information to conduct a constrained search in a large news-base, until it locates specific textual information related to the image. This demonstrates the complexity and significance of this task.\n\nTARA is collected via a rigorous process that involves rule-based distant supervision extraction from news-images data which results in 16k image examples. While the training data has high label correctness (around 95%), we further run a crowdsourced validation on 3k examples to form the evaluation dataset. During the validation, annotators are asked to validate that there exists a potential path for humans to derive the correct answer, which encourages proper reasoning in future works. To better support the study of domain transfer and supervision sizes, we collect an additional 61k examples from the Wikipedia domain. We apply the state-of-the-art joint model CLIP (Radford et al., 2021) and show that it only achieves accuracy of 11.11% and 0.46% for time and location, respectively, on our dataset. Additionally, we present a new CLIP-based baseline model that reasons on object and facial segments and achieves 16.46% and 1.07% accuracy for time and location, respectively. We show that there exists a large gap (around 70% in accuracy) between state-of-the-art models and human performance, suggesting that the TARA data will provide a benchmark to motivate reasoning based approaches and support significant future work.\n\n ",
    "all_spans": [
      {
        "span_text": "yet few of works encourage open-ended reasoning where a model needs to look beyond task inputs.",
        "gpt_label": "Unsupported Claim",
        "reason": "Broad claim about the state of prior work without citations to support the assertion that few works encourage open-ended reasoning.",
        "start": 501,
        "end": 595
      },
      {
        "span_text": "While the training data has high label correctness (around 95%),",
        "gpt_label": "Unsupported Claim",
        "reason": "Quantitative claim presented without evidence or a cited methodology showing how label correctness was measured.",
        "start": 2744,
        "end": 2808
      },
      {
        "span_text": "there exists a large gap (around 70% in accuracy) between state-of-the-art models and human performance,",
        "gpt_label": "Unsupported Claim",
        "reason": "Comparative statistic lacks supporting evidence; no human performance figure, measurement procedure, or citation is provided.",
        "start": 3577,
        "end": 3681
      },
      {
        "span_text": "Figure 2 shows an example from TARA, and Figure 3 shows a possible way for a model to ground the image to its spatio-temporal information. The system starts with grounding multiple segments from the image, and uses the information to conduct a constrained search in a large news-base, until it locates specific textual information related to the image.",
        "gpt_label": "Coherence",
        "reason": "The transition from describing figures to \"The system\" is abrupt and the relationship is only implied; it is not explicitly stated that the described system corresponds to the setup in Figure 3, leading to an unclear connection across the sentences.",
        "start": 2174,
        "end": 2524
      },
      {
        "span_text": "To better support the study of domain transfer and supervision sizes, we collect an additional 61k examples from the Wikipedia domain. We apply the state-of-the-art joint model CLIP (Radford et al., 2021) and show that it only achieves accuracy of 11.11% and 0.46% for time and location, respectively, on our dataset.",
        "gpt_label": "Coherence",
        "reason": "The move from collecting additional Wikipedia data to applying CLIP is abrupt; the relationship between the newly collected data and the reported evaluation is not made explicit, leaving the reader to infer how the extra data factors into the experiments.",
        "start": 3078,
        "end": 3390
      },
      {
        "span_text": "Figure 2 shows an example from TARA, and Figure 3 shows a possible way for a model to ground the image to its spatio-temporal information. The system starts with grounding multiple segments from the image, and uses the information to conduct a constrained search in a large news-base, until it locates specific textual information related to the image. This demonstrates the complexity and significance of this task.",
        "gpt_label": "Lacks synthesis",
        "reason": "This passage describes figures and a hypothetical pipeline without connecting it to prior work, the paper’s argument, or how it advances beyond existing methods. It does not articulate the authors’ perspective or explicitly motivate why this approach matters, thus lacking synthesis.",
        "start": 2174,
        "end": 2587
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "yet few of works encourage open-ended reasoning where a model needs to look beyond task inputs.",
          "gpt_label": "Unsupported Claim",
          "reason": "Broad claim about the state of prior work without citations to support the assertion that few works encourage open-ended reasoning.",
          "start": 501,
          "end": 595
        },
        {
          "span_text": "While the training data has high label correctness (around 95%),",
          "gpt_label": "Unsupported Claim",
          "reason": "Quantitative claim presented without evidence or a cited methodology showing how label correctness was measured.",
          "start": 2744,
          "end": 2808
        },
        {
          "span_text": "there exists a large gap (around 70% in accuracy) between state-of-the-art models and human performance,",
          "gpt_label": "Unsupported Claim",
          "reason": "Comparative statistic lacks supporting evidence; no human performance figure, measurement procedure, or citation is provided.",
          "start": 3577,
          "end": 3681
        }
      ],
      "Format": [],
      "Coherence": [
        {
          "span_text": "Figure 2 shows an example from TARA, and Figure 3 shows a possible way for a model to ground the image to its spatio-temporal information. The system starts with grounding multiple segments from the image, and uses the information to conduct a constrained search in a large news-base, until it locates specific textual information related to the image.",
          "gpt_label": "Coherence",
          "reason": "The transition from describing figures to \"The system\" is abrupt and the relationship is only implied; it is not explicitly stated that the described system corresponds to the setup in Figure 3, leading to an unclear connection across the sentences.",
          "start": 2174,
          "end": 2524
        },
        {
          "span_text": "To better support the study of domain transfer and supervision sizes, we collect an additional 61k examples from the Wikipedia domain. We apply the state-of-the-art joint model CLIP (Radford et al., 2021) and show that it only achieves accuracy of 11.11% and 0.46% for time and location, respectively, on our dataset.",
          "gpt_label": "Coherence",
          "reason": "The move from collecting additional Wikipedia data to applying CLIP is abrupt; the relationship between the newly collected data and the reported evaluation is not made explicit, leaving the reader to infer how the extra data factors into the experiments.",
          "start": 3078,
          "end": 3390
        }
      ],
      "Lacks synthesis": [
        {
          "span_text": "Figure 2 shows an example from TARA, and Figure 3 shows a possible way for a model to ground the image to its spatio-temporal information. The system starts with grounding multiple segments from the image, and uses the information to conduct a constrained search in a large news-base, until it locates specific textual information related to the image. This demonstrates the complexity and significance of this task.",
          "gpt_label": "Lacks synthesis",
          "reason": "This passage describes figures and a hypothetical pipeline without connecting it to prior work, the paper’s argument, or how it advances beyond existing methods. It does not articulate the authors’ perspective or explicitly motivate why this approach matters, thus lacking synthesis.",
          "start": 2174,
          "end": 2587
        }
      ]
    }
  },
  "paper_52.txt": {
    "filename": "paper_52.txt",
    "full_text": "Related Works\n\nExisting task weighting strategies can be divided into two categories: weight adaptation methods and Pareto Optimization (PO)-based methods. The weight adaptation methods adaptively adjust the tasks' weights during training based on pre-defined heuristic, such as uncertainty (Kendall et al., 2018), task difficulty prioritization (Guo et al., 2018), gradient normalization (Chen et al., 2018), weight average (Liu et al., 2019) and task variance regularization (Mao et al., 2021). These methods only use training losses or their gradients to compute task weights while ignores the gap between the training loss and generalization loss.\n\nBesides, the PO-based methods formulate MTL as a multi-objective optimization problem and aim to find an arbitrary Pareto stationary solution (Sener and Koltun, 2018;Mahapatra and Rajan, 2020;Lin et al., 2020;Mao et al., 2020). However, in these methods, the learning objectives only involve training losses; thus, they can only achieve Pareto stationary points w.r.t training losses. They also ignore the gap between the training loss and generalization loss. Moreover,  proposes that the PO-based methods can be also regarded as weight adaptation methods for they optimize the weighted sum of training losses as well.\n\nOverlooking the gap between the training loss and generalization loss would degenerate the performance of MTL. This paper proposes a novel task weighting method to solve this issue.\n\n ",
    "all_spans": [
      {
        "span_text": "Existing task weighting strategies can be divided into two categories: weight adaptation methods and Pareto Optimization (PO)-based methods.",
        "gpt_label": "Unsupported Claim",
        "reason": "Taxonomy/classification of prior work is asserted without citing a survey or source establishing these two categories.",
        "start": 15,
        "end": 154
      },
      {
        "span_text": "These methods only use training losses or their gradients to compute task weights while ignores the gap between the training loss and generalization loss.",
        "gpt_label": "Unsupported Claim",
        "reason": "Generalizes about multiple prior methods’ mechanics without citations supporting the claim that they exclusively use training losses/gradients and ignore the generalization gap.",
        "start": 490,
        "end": 643
      },
      {
        "span_text": "However, in these methods, the learning objectives only involve training losses; thus, they can only achieve Pareto stationary points w.r.t training losses.",
        "gpt_label": "Unsupported Claim",
        "reason": "Asserts characteristics and limitations of prior PO-based methods without direct citations; the conclusion depends on the unsupported premise.",
        "start": 870,
        "end": 1023
      },
      {
        "span_text": "They also ignore the gap between the training loss and generalization loss.",
        "gpt_label": "Unsupported Claim",
        "reason": "Claims that prior methods ignore an aspect (generalization gap) without providing evidence or citations.",
        "start": 1024,
        "end": 1098
      },
      {
        "span_text": "Moreover,  proposes that the PO-based methods can be also regarded as weight adaptation methods for they optimize the weighted sum of training losses as well.",
        "gpt_label": "Unsupported Claim",
        "reason": "Refers to a specific proposal without identifying or citing the source.",
        "start": 1099,
        "end": 1256
      },
      {
        "span_text": "Overlooking the gap between the training loss and generalization loss would degenerate the performance of MTL.",
        "gpt_label": "Unsupported Claim",
        "reason": "Causal claim about performance impact lacks supporting evidence or citations.",
        "start": 1258,
        "end": 1367
      },
      {
        "span_text": "They also ignore the gap between the training loss and generalization loss. Moreover,  proposes that the PO-based methods can be also regarded as weight adaptation methods for they optimize the weighted sum of training losses as well.",
        "gpt_label": "Coherence",
        "reason": "The transition is abrupt and the relationship is not explicitly stated: the second sentence references an unspecified source (missing citation after 'Moreover,') and does not clearly connect to the prior discussion of PO-based methods, leaving the link between these sentences and the earlier cited works implicit rather than explicit.",
        "start": 1024,
        "end": 1256
      },
      {
        "span_text": "Moreover,  proposes that the PO-based methods can be also regarded as weight adaptation methods for they optimize the weighted sum of training losses as well.",
        "gpt_label": "Lacks synthesis",
        "reason": "This sentence references prior work without a clear citation and makes a claim about method unification without explaining its relevance to the authors’ argument or contribution, failing to connect the summary to their own perspective or how it motivates their approach.",
        "start": 1099,
        "end": 1256
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "Existing task weighting strategies can be divided into two categories: weight adaptation methods and Pareto Optimization (PO)-based methods.",
          "gpt_label": "Unsupported Claim",
          "reason": "Taxonomy/classification of prior work is asserted without citing a survey or source establishing these two categories.",
          "start": 15,
          "end": 154
        },
        {
          "span_text": "These methods only use training losses or their gradients to compute task weights while ignores the gap between the training loss and generalization loss.",
          "gpt_label": "Unsupported Claim",
          "reason": "Generalizes about multiple prior methods’ mechanics without citations supporting the claim that they exclusively use training losses/gradients and ignore the generalization gap.",
          "start": 490,
          "end": 643
        },
        {
          "span_text": "However, in these methods, the learning objectives only involve training losses; thus, they can only achieve Pareto stationary points w.r.t training losses.",
          "gpt_label": "Unsupported Claim",
          "reason": "Asserts characteristics and limitations of prior PO-based methods without direct citations; the conclusion depends on the unsupported premise.",
          "start": 870,
          "end": 1023
        },
        {
          "span_text": "They also ignore the gap between the training loss and generalization loss.",
          "gpt_label": "Unsupported Claim",
          "reason": "Claims that prior methods ignore an aspect (generalization gap) without providing evidence or citations.",
          "start": 1024,
          "end": 1098
        },
        {
          "span_text": "Moreover,  proposes that the PO-based methods can be also regarded as weight adaptation methods for they optimize the weighted sum of training losses as well.",
          "gpt_label": "Unsupported Claim",
          "reason": "Refers to a specific proposal without identifying or citing the source.",
          "start": 1099,
          "end": 1256
        },
        {
          "span_text": "Overlooking the gap between the training loss and generalization loss would degenerate the performance of MTL.",
          "gpt_label": "Unsupported Claim",
          "reason": "Causal claim about performance impact lacks supporting evidence or citations.",
          "start": 1258,
          "end": 1367
        }
      ],
      "Format": [],
      "Coherence": [
        {
          "span_text": "They also ignore the gap between the training loss and generalization loss. Moreover,  proposes that the PO-based methods can be also regarded as weight adaptation methods for they optimize the weighted sum of training losses as well.",
          "gpt_label": "Coherence",
          "reason": "The transition is abrupt and the relationship is not explicitly stated: the second sentence references an unspecified source (missing citation after 'Moreover,') and does not clearly connect to the prior discussion of PO-based methods, leaving the link between these sentences and the earlier cited works implicit rather than explicit.",
          "start": 1024,
          "end": 1256
        }
      ],
      "Lacks synthesis": [
        {
          "span_text": "Moreover,  proposes that the PO-based methods can be also regarded as weight adaptation methods for they optimize the weighted sum of training losses as well.",
          "gpt_label": "Lacks synthesis",
          "reason": "This sentence references prior work without a clear citation and makes a claim about method unification without explaining its relevance to the authors’ argument or contribution, failing to connect the summary to their own perspective or how it motivates their approach.",
          "start": 1099,
          "end": 1256
        }
      ]
    }
  },
  "paper_53.txt": {
    "filename": "paper_53.txt",
    "full_text": "Related Work\n\nKnowledge can be elicited from pretrained language models. Numerous works have shown that pretrained language models implicitly contain large a amount of knowledge that can be queried via conditional generation (Davison et al., 2019;Petroni et al., 2019;. Consequently, these models can directly perform inference on tasks like commonsense reasoning (Trinh and Le, 2018;), text classification (Shin et al., 2020;Puri and Catanzaro, 2019), and natural language inference (Shin et al., 2020;Schick and Schütze, 2021). Inspired by these observations, we elicit question-related knowledge in an explicit form from language models and use them to guide the inference.\n\nLeveraging external knowledge for commonsense reasoning. Some work uses external commonsense knowledge bases to make improvements on various NLP tasks, including commonsense reasoning. One approach is to inject commonsense knowledge into language models, either by pretraining on knowledge bases (Ma et al., 2021;Chang et al., 2020;Mitra et al., 2019;Zhong et al., 2019) or finetuning the model so that it can reason with additional retrieved knowledge (Chang et al., 2020;Mitra et al., 2019;Bian et al., 2021). Another direction is to ground the question into a knowledge graph and do inference with graph-based reasoning (Lin et al., 2019;Lv et al., 2020;Yasunaga et al., 2021).\n\nA common prerequisite of these methods is a high-quality, high-coverage, in-domain commonsense knowledge base (Ma et al., 2019). Some commonsense reasoning datasets are derived from existing knowledge bases; for example, CommonsenseQA (Talmor et al., 2019) is derived from ConceptNet (Speer et al., 2017), and Social IQA (Sap et al., 2019b) is derived from ATOMIC (Sap et al., 2019a). For such datasets, it is natural to elicit related knowledge from the underlying knowledge base that derived them, and typically this would demonstrate considerable gains (Mitra et al., 2019; Chang et al., 2020). However, if there is a domain mismatch between the dataset and the knowledge base, such gains tend to diminish (Mitra et al., 2019; Ma et al., 2019). This becomes a bottleneck when encountering datasets that have no suitable knowledge base (e.g. NumerSense (Lin et al., 2020) and CommonsenseQA 2.0 (Talmor\net al., 2021)), or when the system needs to handle commonsense queries that do not fit in any of the commonsense domains represented by an existing knowledge base. Our work overcomes this difficulty by leveraging pretrained language models as the source of commonsense knowledge.\n\nAdding generated text during inference. Recently, several works show that model performance on commonsense reasoning can be boosted by augmenting the question with model-generated text, such as clarifications, explanations, and implications. Self-talk (Shwartz et al., 2020) elicits clarifications to concepts in the question and appends them to the inference model input. Contrastive explanations (Paranjape et al., 2021) prompts inference models with generated explanations that contrast between two answer choices. The aforementioned methods depend on task-specific templates to inquire the generator, which means they are only capable of eliciting a limited variety of knowledge and require careful hand-crafting to transfer to new tasks. Other explanation-based methods (Latcinnik and Berant, 2020;Rajani et al., 2019) finetune the generator model so that it produces explanations that are used for question augmentation. DynaGen  uses pretrained commonsense models to generate implications of a question and expands the inference input with these generations. However, its usage of COMeT (Bosselut et al., 2019) as the generator confines its applicability to the social commonsense domain. Our work contributes to this general line of research, yet different from these previous methods that elicit knowledge with task-specific templates or from finetuned knowledge generators, our method requires only a few human-written demonstrations in the style of the task, making it much more flexible, easy-to-transfer, and engineering-efficient.\n\n ",
    "all_spans": [
      {
        "span_text": "Recently, several works show that model performance on commonsense reasoning can be boosted by augmenting the question with model-generated text, such as clarifications, explanations, and implications.",
        "gpt_label": "Unsupported Claim",
        "reason": "Mentions 'recently' and claims multiple prior works without providing citations in the sentence; such claims should be supported with references.",
        "start": 2542,
        "end": 2742
      },
      {
        "span_text": "The aforementioned methods depend on task-specific templates to inquire the generator, which means they are only capable of eliciting a limited variety of knowledge and require careful hand-crafting to transfer to new tasks.",
        "gpt_label": "Unsupported Claim",
        "reason": "Evaluative claim about prior methods’ limitations is not backed by citations or evidence; should reference specific works demonstrating these constraints.",
        "start": 3015,
        "end": 3238
      },
      {
        "span_text": "DynaGen  uses pretrained commonsense models to generate implications of a question and expands the inference input with these generations.",
        "gpt_label": "Unsupported Claim",
        "reason": "Introduces a specific method (DynaGen) without citation at first mention, violating the requirement to cite prior work.",
        "start": 3421,
        "end": 3558
      },
      {
        "span_text": "However, its usage of COMeT (Bosselut et al., 2019) as the generator confines its applicability to the social commonsense domain.",
        "gpt_label": "Unsupported Claim",
        "reason": "Asserts a limitation of the DynaGen method without citing the DynaGen paper or evidence; the COMeT citation does not support the claim about DynaGen’s applicability.",
        "start": 3559,
        "end": 3686
      },
      {
        "span_text": "Other explanation-based methods (Latcinnik and Berant, 2020;Rajani et al., 2019) finetune the generator model so that it produces explanations that are used for question augmentation. DynaGen  uses pretrained commonsense models to generate implications of a question and expands the inference input with these generations.",
        "gpt_label": "Coherence",
        "reason": "The transition between these sentences is abrupt and the relationship between the cited explanation-based methods and DynaGen is not made explicit. It is unclear whether DynaGen is an example of these methods, a contrasting approach, or a separate line of work, and the lack of a citation for DynaGen further obscures the connection.",
        "start": 3239,
        "end": 3558
      },
      {
        "span_text": "Another direction is to ground the question into a knowledge graph and do inference with graph-based reasoning (Lin et al., 2019;Lv et al., 2020;Yasunaga et al., 2021).",
        "gpt_label": "Lacks synthesis",
        "reason": "This sentence lists prior approaches and citations without articulating how they relate to the authors’ perspective, the specific gap they target, or how their method compares, leaving the connection to their argument implicit.",
        "start": 1172,
        "end": 1336
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "Recently, several works show that model performance on commonsense reasoning can be boosted by augmenting the question with model-generated text, such as clarifications, explanations, and implications.",
          "gpt_label": "Unsupported Claim",
          "reason": "Mentions 'recently' and claims multiple prior works without providing citations in the sentence; such claims should be supported with references.",
          "start": 2542,
          "end": 2742
        },
        {
          "span_text": "The aforementioned methods depend on task-specific templates to inquire the generator, which means they are only capable of eliciting a limited variety of knowledge and require careful hand-crafting to transfer to new tasks.",
          "gpt_label": "Unsupported Claim",
          "reason": "Evaluative claim about prior methods’ limitations is not backed by citations or evidence; should reference specific works demonstrating these constraints.",
          "start": 3015,
          "end": 3238
        },
        {
          "span_text": "DynaGen  uses pretrained commonsense models to generate implications of a question and expands the inference input with these generations.",
          "gpt_label": "Unsupported Claim",
          "reason": "Introduces a specific method (DynaGen) without citation at first mention, violating the requirement to cite prior work.",
          "start": 3421,
          "end": 3558
        },
        {
          "span_text": "However, its usage of COMeT (Bosselut et al., 2019) as the generator confines its applicability to the social commonsense domain.",
          "gpt_label": "Unsupported Claim",
          "reason": "Asserts a limitation of the DynaGen method without citing the DynaGen paper or evidence; the COMeT citation does not support the claim about DynaGen’s applicability.",
          "start": 3559,
          "end": 3686
        }
      ],
      "Format": [],
      "Coherence": [
        {
          "span_text": "Other explanation-based methods (Latcinnik and Berant, 2020;Rajani et al., 2019) finetune the generator model so that it produces explanations that are used for question augmentation. DynaGen  uses pretrained commonsense models to generate implications of a question and expands the inference input with these generations.",
          "gpt_label": "Coherence",
          "reason": "The transition between these sentences is abrupt and the relationship between the cited explanation-based methods and DynaGen is not made explicit. It is unclear whether DynaGen is an example of these methods, a contrasting approach, or a separate line of work, and the lack of a citation for DynaGen further obscures the connection.",
          "start": 3239,
          "end": 3558
        }
      ],
      "Lacks synthesis": [
        {
          "span_text": "Another direction is to ground the question into a knowledge graph and do inference with graph-based reasoning (Lin et al., 2019;Lv et al., 2020;Yasunaga et al., 2021).",
          "gpt_label": "Lacks synthesis",
          "reason": "This sentence lists prior approaches and citations without articulating how they relate to the authors’ perspective, the specific gap they target, or how their method compares, leaving the connection to their argument implicit.",
          "start": 1172,
          "end": 1336
        }
      ]
    }
  },
  "paper_54.txt": {
    "filename": "paper_54.txt",
    "full_text": "Introduction\n\nText summarization is an important natural language processing (NLP) task, aiming at generating concise summaries for given texts while preserving the key information. It has extensive real-world applications such as headline generation (Nenkova et al., 2011).\n\nState-of-the-art text summarization models are typically trained in a supervised way with large training corpora, comprising pairs of long texts and their summaries (Zhang et al., 2020;Aghajanyan et al., 2020Aghajanyan et al., , 2021. However, such parallel data are expensive to obtain, preventing the applications to less popular domains and less spoken languages.\n\nUnsupervised text generation has been attracting increasing interest, because it does not require parallel data for training. One widely used approach is to compress a long text into a short one, and to reconstruct it to the long text by a cycle consistency loss (Miao and Blunsom, 2016;Wang and Lee, 2018;Baziotis et al., 2019). Due to the indifferentiability of the compressed sentence space, such an approach requires reinforcement learning (or its variants), which makes the training difficult (Kreutzer et al., 2021).\n\nRecently, Schumann et al. (2020) propose an edit-based approach for unsupervised summarization. Their model maximizes a scoring function that evaluates the quality (fluency and semantics) of the generated summary, achieving higher performance than cycle-consistency methods. However, the search approach is slow in inference because hundreds of search steps are needed for each data sample. Moreover, their approach can only select words from the input sentence with the word order preserved. Thus, it is restricted and may generate noisy summaries due to the local optimality of search algorithms.\n\nTo address the above drawbacks, we propose a Non-Autoregressive approach to Unsupervised Summarization (NAUS). The idea is to perform search as in Schumann et al. (2020) and, inspired by Li et al. (2020), to train a machine learning model to smooth out such noise and to speed up the inference process. Different from Li et al. (2020), we propose to utilize non-autoregressive text generators, which generate all tokens in the output in parallel, based on our following observations:\n\n• Non-autoregressive models are several times faster than autoregressive generation, which is important when the system is deployed.\n\n• The input and output of the summarization task have a strong correspondence. Non-autoregressive generation supports encoder-only architectures, which can better utilize such input-output correspondence and even outperform autoregressive models for summarization.\n\n• For non-autoregressive models, we can design a length-control algorithm based on dynamic programming. This can satisfy the output length constraint, which is typical in summarization but can-not be easily achieved with autoregressive models.\n\nWe conducted experiments on Gigaword headline generation (Graff et al., 2003) and DUC2004 (Over and Yen, 2004) datasets. Experiments show that our NAUS achieves state-of-the-art performance on unsupervised summarization; especially, it outperforms its teacher (i.e., the search approach), confirming that NAUS can indeed smooth out the search noise. Regarding inference efficiency, our NAUS with truncating is 1000 times more efficient than the search approach; even with dynamic programming for length control, NAUS is still 100 times more efficient than search and several times more efficient than autoregressive models. Our NAUS is also able to perform length-transfer summary generation, i.e., generating summaries of different lengths from training.\n\n ",
    "all_spans": [
      {
        "span_text": "Unsupervised text generation has been attracting increasing interest, because it does not require parallel data for training.",
        "gpt_label": "Unsupported Claim",
        "reason": "Trend claim about the field lacks citations to recent works (rule d) and presents a field-level assertion without supporting evidence.",
        "start": 636,
        "end": 760
      },
      {
        "span_text": "However, the search approach is slow in inference because hundreds of search steps are needed for each data sample.",
        "gpt_label": "Unsupported Claim",
        "reason": "Quantified performance claim about a prior method requires a citation or evidence (rule a/b).",
        "start": 1427,
        "end": 1541
      },
      {
        "span_text": "Thus, it is restricted and may generate noisy summaries due to the local optimality of search algorithms.",
        "gpt_label": "Unsupported Claim",
        "reason": "Causal claim about shortcomings of the prior approach and search algorithms lacks supporting citation or evidence (rule b).",
        "start": 1643,
        "end": 1747
      },
      {
        "span_text": "• Non-autoregressive models are several times faster than autoregressive generation, which is important when the system is deployed.",
        "gpt_label": "Unsupported Claim",
        "reason": "Comparative performance/statistical claim without citation or empirical evidence (rule b).",
        "start": 2229,
        "end": 2360
      },
      {
        "span_text": "• Non-autoregressive generation supports encoder-only architectures, which can better utilize such input-output correspondence and even outperform autoregressive models for summarization.",
        "gpt_label": "Unsupported Claim",
        "reason": "Strong claim of outperformance over autoregressive models lacks citations to studies demonstrating this (rule b/d).",
        "start": -1,
        "end": -1
      },
      {
        "span_text": "This can satisfy the output length constraint, which is typical in summarization but can-not be easily achieved with autoregressive models.",
        "gpt_label": "Unsupported Claim",
        "reason": "Claims about typicality of length constraints and the difficulty for autoregressive models are domain-specific assertions without citations (rule b).",
        "start": 2729,
        "end": 2867
      },
      {
        "span_text": "The idea is to perform search as in Schumann et al. (2020) and, inspired by Li et al. (2020), to train a machine learning model to smooth out such noise and to speed up the inference process. Different from Li et al. (2020), we propose to utilize non-autoregressive text generators, which generate all tokens in the output in parallel, based on our following observations:",
        "gpt_label": "Coherence",
        "reason": "Li et al. (2020) is introduced without explaining what their method is or how it relates to Schumann et al.’s search; the subsequent sentence contrasts with Li et al. without stating what is being contrasted. The relationship between the cited works and the proposed approach is implied rather than explicitly articulated across these sentences.",
        "start": 1859,
        "end": 2227
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "Unsupervised text generation has been attracting increasing interest, because it does not require parallel data for training.",
          "gpt_label": "Unsupported Claim",
          "reason": "Trend claim about the field lacks citations to recent works (rule d) and presents a field-level assertion without supporting evidence.",
          "start": 636,
          "end": 760
        },
        {
          "span_text": "However, the search approach is slow in inference because hundreds of search steps are needed for each data sample.",
          "gpt_label": "Unsupported Claim",
          "reason": "Quantified performance claim about a prior method requires a citation or evidence (rule a/b).",
          "start": 1427,
          "end": 1541
        },
        {
          "span_text": "Thus, it is restricted and may generate noisy summaries due to the local optimality of search algorithms.",
          "gpt_label": "Unsupported Claim",
          "reason": "Causal claim about shortcomings of the prior approach and search algorithms lacks supporting citation or evidence (rule b).",
          "start": 1643,
          "end": 1747
        },
        {
          "span_text": "• Non-autoregressive models are several times faster than autoregressive generation, which is important when the system is deployed.",
          "gpt_label": "Unsupported Claim",
          "reason": "Comparative performance/statistical claim without citation or empirical evidence (rule b).",
          "start": 2229,
          "end": 2360
        },
        {
          "span_text": "• Non-autoregressive generation supports encoder-only architectures, which can better utilize such input-output correspondence and even outperform autoregressive models for summarization.",
          "gpt_label": "Unsupported Claim",
          "reason": "Strong claim of outperformance over autoregressive models lacks citations to studies demonstrating this (rule b/d).",
          "start": -1,
          "end": -1
        },
        {
          "span_text": "This can satisfy the output length constraint, which is typical in summarization but can-not be easily achieved with autoregressive models.",
          "gpt_label": "Unsupported Claim",
          "reason": "Claims about typicality of length constraints and the difficulty for autoregressive models are domain-specific assertions without citations (rule b).",
          "start": 2729,
          "end": 2867
        }
      ],
      "Format": [],
      "Coherence": [
        {
          "span_text": "The idea is to perform search as in Schumann et al. (2020) and, inspired by Li et al. (2020), to train a machine learning model to smooth out such noise and to speed up the inference process. Different from Li et al. (2020), we propose to utilize non-autoregressive text generators, which generate all tokens in the output in parallel, based on our following observations:",
          "gpt_label": "Coherence",
          "reason": "Li et al. (2020) is introduced without explaining what their method is or how it relates to Schumann et al.’s search; the subsequent sentence contrasts with Li et al. without stating what is being contrasted. The relationship between the cited works and the proposed approach is implied rather than explicitly articulated across these sentences.",
          "start": 1859,
          "end": 2227
        }
      ]
    }
  },
  "paper_55.txt": {
    "filename": "paper_55.txt",
    "full_text": "Introduction\n\nWhile many information seeking questions can be answered by a short text span, requiring a short span answer significantly limits the types of questions that can be addressed as well as the extent of information that can be conveyed. Recent work (Fan et al., 2019;Krishna et al., 2021) explored long form answers, where answers can be free-form texts consisting of multiple sentences. Their multi-sentence nature leads to interesting and nuanced discourse within the answers, where the answerer can provide information, hedge, explain, provide examples, point to other sources, and more. Answerers can flexibly structure and organize these elements to provide a coherent, concise answer.\n\nThe complexity and flexibility of long form answers pose fresh challenges to the evaluation of long form question answering systems, in stark contrast to short span-based answers where matching spans (Rajpurkar et al., 2016;Joshi et al., 2017) provides a reliable proxy. A recent study (Krishna et al., 2021) demonstrated that automatic metrics like ROUGE (Lin, 2004) are not meaningful for this task and can be easily gamed. Our experiments find that even reliable human preference testing is challenging given the complexity of long form answers, which motivates us to look into the discourse structure of long form answers.\n\nWe take a linguistically informed approach with the dual purpose of (a) to better understand the structure of long form answers, and (b) to assist the evaluation of long-form QA systems. By characterizing the communicative functions of sentences in long form answers (which we call roles), e.g., signaling the organization of the answer, directly answering the question, giving an example, providing background information, etc., we analyze human-written, and machine-generated long form answers. Furthermore, our framework combines functional structures with the notion of information salience by designating a role for sentences that convey the main message of an answer.\n\nWe collect annotations on two datasets, ELI5 (Fan et al., 2019) and Natural Questions (NQ) (Kwiatkowski et al., 2019), which contains long form answers written by search users and from Wikipedia page respectively. In total, we provide fine-grained roles for 3.3K sentences (0.5K examples) and coarse annotation for 6K sentences (1.3K examples). We also annotate a small number (94) of machine-generated answers from a state-of-theart long form question answering system (Krishna et al., 2021) and provide rich analysis about their respective discourse structures. Our analysis demonstrates that studying answer structure can reveal a significant gap between machine-generated answers and human-written answers. We also present a competitive baseline model for automatic role classification, which performs on par with human agreement when trained with our annotated data. Lastly, our dataset yields a novel extractive summarization dataset, providing a benchmark for studying domain transfer in summarization and enabling QA models to provide concise answers to complex queries. We will release all our data and code at http://anonymous.co.\n\n ",
    "all_spans": [
      {
        "span_text": "which performs on par with human agreement",
        "gpt_label": "Unsupported Claim",
        "reason": "This is a comparative performance/statistical claim that requires evidence or citation (e.g., agreement metrics or prior studies) to substantiate, but none is provided here.",
        "start": 2769,
        "end": 2811
      },
      {
        "span_text": "a novel extractive summarization dataset",
        "gpt_label": "Unsupported Claim",
        "reason": "This is a novelty claim about prior work; it should be supported by citations or comparisons to existing summarization datasets to justify novelty, but no supporting references are given.",
        "start": 2876,
        "end": 2916
      },
      {
        "span_text": "The complexity and flexibility of long form answers pose fresh challenges to the evaluation of long form question answering systems, in stark contrast to short span-based answers where matching spans (Rajpurkar et al., 2016;Joshi et al., 2017) provides a reliable proxy. A recent study (Krishna et al., 2021) demonstrated that automatic metrics like ROUGE (Lin, 2004) are not meaningful for this task and can be easily gamed. Our experiments find that even reliable human preference testing is challenging given the complexity of long form answers, which motivates us to look into the discourse structure of long form answers.",
        "gpt_label": "Coherence",
        "reason": "The transition from span-matching for short answers to ROUGE for long-form and then to human preference testing is abrupt. The relationships among the cited works and evaluation approaches are implied rather than explicitly connected, making the multi-sentence flow between these points unclear.",
        "start": 697,
        "end": 1317
      },
      {
        "span_text": "A recent study (Krishna et al., 2021) demonstrated that automatic metrics like ROUGE (Lin, 2004) are not meaningful for this task and can be easily gamed.",
        "gpt_label": "Lacks synthesis",
        "reason": "This sentence cites prior work without explicitly linking the finding to the authors’ own approach within the sentence; the connection to their motivation appears only in the following sentence, leaving this citation momentarily unsynthesized with their argument.",
        "start": 965,
        "end": 1117
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "which performs on par with human agreement",
          "gpt_label": "Unsupported Claim",
          "reason": "This is a comparative performance/statistical claim that requires evidence or citation (e.g., agreement metrics or prior studies) to substantiate, but none is provided here.",
          "start": 2769,
          "end": 2811
        },
        {
          "span_text": "a novel extractive summarization dataset",
          "gpt_label": "Unsupported Claim",
          "reason": "This is a novelty claim about prior work; it should be supported by citations or comparisons to existing summarization datasets to justify novelty, but no supporting references are given.",
          "start": 2876,
          "end": 2916
        }
      ],
      "Format": [],
      "Coherence": [
        {
          "span_text": "The complexity and flexibility of long form answers pose fresh challenges to the evaluation of long form question answering systems, in stark contrast to short span-based answers where matching spans (Rajpurkar et al., 2016;Joshi et al., 2017) provides a reliable proxy. A recent study (Krishna et al., 2021) demonstrated that automatic metrics like ROUGE (Lin, 2004) are not meaningful for this task and can be easily gamed. Our experiments find that even reliable human preference testing is challenging given the complexity of long form answers, which motivates us to look into the discourse structure of long form answers.",
          "gpt_label": "Coherence",
          "reason": "The transition from span-matching for short answers to ROUGE for long-form and then to human preference testing is abrupt. The relationships among the cited works and evaluation approaches are implied rather than explicitly connected, making the multi-sentence flow between these points unclear.",
          "start": 697,
          "end": 1317
        }
      ],
      "Lacks synthesis": [
        {
          "span_text": "A recent study (Krishna et al., 2021) demonstrated that automatic metrics like ROUGE (Lin, 2004) are not meaningful for this task and can be easily gamed.",
          "gpt_label": "Lacks synthesis",
          "reason": "This sentence cites prior work without explicitly linking the finding to the authors’ own approach within the sentence; the connection to their motivation appears only in the following sentence, leaving this citation momentarily unsynthesized with their argument.",
          "start": 965,
          "end": 1117
        }
      ]
    }
  },
  "paper_56.txt": {
    "filename": "paper_56.txt",
    "full_text": "Introduction\n\nKnowledge-grounded conversational models, powered by large pre-trained language models (Radford et al., 2019;Brown et al., 2020;Raffel et al., 2020), are well-known to generate factually incorrect statements, a phenomenon commonly called hallucination (Dziri et al., 2021b;Rashkin et al., 2021b). A large commonality in the majority of prior work seeks to address hallucination by ameliorating the model (Shuster et al., 2021;Mielke et al., 2020;Dziri et al., 2021a;Rashkin et al., 2021b), but no attempt has been made so far to audit the conversational benchmarks to the best of our knowledge.\n\nOn one hand, knowledge-grounded conversational benchmarks may contain hallucinations due to error-prone collection protocols, or due to a design framework that encourages informativeness over faithfulness. Existing dialogue systems are typically trained on corpora crowd-sourced through online platforms (Dinan et al., 2018; Gopalakrishnan et al., 2019; Moon et al., 2019). With loose incentive to come up with faithfully-grounded utterances on the provided knowledge, crowdworkers may ignore knowledge-snippets altogether, use their personal knowledge or sometimes assume a fictional persona, resulting in conversations that are rife with subjective content and unverified factual knowledge. Figure 1 shows a hallucinated conversation from the WoW dataset (Dinan et al., 2018), On the other hand, neural conversational models are not necessarily designed to generate faithful outputs, but to mimic the distributional properties of the data. This kind of optimization will likely push the models to replicate and even amplify the hallucination behaviour at test time (Bender et al., 2021). The presence of even few hallucinated responses may skew the data distribution in a way that curbs the model's ability to generate faithful responses (Kang and Hashimoto, 2020).\n\nIn this work, drawing insights from the linguistic coding system for discourse phenomena (Stiles, 1992) and evaluation frameworks such as BEGIN (Dziri et al., 2021b) and AIS (Rashkin et al., 2021a), we annotate responses from the three widely-used knowledge-grounded conversational benchmarks: Wizard of Wikipedia (Dinan et al., 2018), CMU-DoG (Zhou et al., 2018) and Topi-calChat (Gopalakrishnan et al., 2019). Our analysis reveals surprisingly that more than 60% of the responses are hallucinated in the three datasets, with major hallucination modes that manifest principally through the expression of subjective information (e.g., thoughts, beliefs, feelings, intentions, personal experiences) and the expression of unsupported objective factual information. Further, to understand if neural conversational models make this hallucination more severe, we annotate responses generated by several state-of-the-art models, including ones that are designed to alleviate hallucinations. We find that the generated responses consist of an even larger portion of hallucinations, in comparison with the training data. Our findings question the quality of current conversational datasets, their appropriateness to train knowledgegrounded conversational systems, and the robustness of existing models.\n\n ",
    "all_spans": [
      {
        "span_text": "but no attempt has been made so far to audit the conversational benchmarks to the best of our knowledge.",
        "gpt_label": "Unsupported Claim",
        "reason": "Claims about the absence of prior work should be supported by evidence or citations; statements about prior literature require support at first mention.",
        "start": 494,
        "end": 597
      },
      {
        "span_text": "crowdworkers may ignore knowledge-snippets altogether, use their personal knowledge or sometimes assume a fictional persona, resulting in conversations that are rife with subjective content and unverified factual knowledge.",
        "gpt_label": "Unsupported Claim",
        "reason": "Asserts specific behaviors and prevalence in crowdsourced dialogue data without citing empirical studies or analyses supporting these claims.",
        "start": 1063,
        "end": 1285
      },
      {
        "span_text": "the three widely-used knowledge-grounded conversational benchmarks",
        "gpt_label": "Unsupported Claim",
        "reason": "Describes the datasets as widely used without providing citations or evidence (e.g., usage statistics, surveys) to substantiate the popularity claim.",
        "start": 2081,
        "end": 2147
      },
      {
        "span_text": "including ones that are designed to alleviate hallucinations.",
        "gpt_label": "Unsupported Claim",
        "reason": "Mentions specific model design goals from prior work without citing which models or papers; first mentions of such works should be cited.",
        "start": 2771,
        "end": 2831
      },
      {
        "span_text": "This kind of optimization will likely push the models to replicate and even amplify the hallucination behaviour at test time (Bender et al., 2021). The presence of even few hallucinated responses may skew the data distribution in a way that curbs the model's ability to generate faithful responses (Kang and Hashimoto, 2020).",
        "gpt_label": "Coherence",
        "reason": "The transition between these two cited claims is abrupt and the relationship is implied rather than stated. The first sentence concerns model optimization effects at test time, while the second shifts to data distribution skew from hallucinated responses. It is unclear how the second claim connects causally or evidentially to the first without an explicit link.",
        "start": 1533,
        "end": 1855
      },
      {
        "span_text": "Existing dialogue systems are typically trained on corpora crowd-sourced through online platforms (Dinan et al., 2018; Gopalakrishnan et al., 2019; Moon et al., 2019).",
        "gpt_label": "Lacks synthesis",
        "reason": "This sentence lists prior datasets with citations but, in isolation, does not explicitly connect these works to the authors’ specific research gap or argument; it reports background without articulating the authors’ perspective or how this fact motivates their audit.",
        "start": 804,
        "end": 967
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "but no attempt has been made so far to audit the conversational benchmarks to the best of our knowledge.",
          "gpt_label": "Unsupported Claim",
          "reason": "Claims about the absence of prior work should be supported by evidence or citations; statements about prior literature require support at first mention.",
          "start": 494,
          "end": 597
        },
        {
          "span_text": "crowdworkers may ignore knowledge-snippets altogether, use their personal knowledge or sometimes assume a fictional persona, resulting in conversations that are rife with subjective content and unverified factual knowledge.",
          "gpt_label": "Unsupported Claim",
          "reason": "Asserts specific behaviors and prevalence in crowdsourced dialogue data without citing empirical studies or analyses supporting these claims.",
          "start": 1063,
          "end": 1285
        },
        {
          "span_text": "the three widely-used knowledge-grounded conversational benchmarks",
          "gpt_label": "Unsupported Claim",
          "reason": "Describes the datasets as widely used without providing citations or evidence (e.g., usage statistics, surveys) to substantiate the popularity claim.",
          "start": 2081,
          "end": 2147
        },
        {
          "span_text": "including ones that are designed to alleviate hallucinations.",
          "gpt_label": "Unsupported Claim",
          "reason": "Mentions specific model design goals from prior work without citing which models or papers; first mentions of such works should be cited.",
          "start": 2771,
          "end": 2831
        }
      ],
      "Format": [],
      "Coherence": [
        {
          "span_text": "This kind of optimization will likely push the models to replicate and even amplify the hallucination behaviour at test time (Bender et al., 2021). The presence of even few hallucinated responses may skew the data distribution in a way that curbs the model's ability to generate faithful responses (Kang and Hashimoto, 2020).",
          "gpt_label": "Coherence",
          "reason": "The transition between these two cited claims is abrupt and the relationship is implied rather than stated. The first sentence concerns model optimization effects at test time, while the second shifts to data distribution skew from hallucinated responses. It is unclear how the second claim connects causally or evidentially to the first without an explicit link.",
          "start": 1533,
          "end": 1855
        }
      ],
      "Lacks synthesis": [
        {
          "span_text": "Existing dialogue systems are typically trained on corpora crowd-sourced through online platforms (Dinan et al., 2018; Gopalakrishnan et al., 2019; Moon et al., 2019).",
          "gpt_label": "Lacks synthesis",
          "reason": "This sentence lists prior datasets with citations but, in isolation, does not explicitly connect these works to the authors’ specific research gap or argument; it reports background without articulating the authors’ perspective or how this fact motivates their audit.",
          "start": 804,
          "end": 967
        }
      ]
    }
  },
  "paper_57.txt": {
    "filename": "paper_57.txt",
    "full_text": "Related Work\n\nLong Document Summarization Long document summarization has been studied in multiple domains, such as news (Nallapati et al., 2016), patterns (Trappey et al., 2009, books , scientific publications (Qazvinian and Radev, 2008), and med-ical records (Cohan et al., 2018). Gidiotis and Tsoumakas (2020) proposed a divide-and-conquer method by splitting the input into multiple segments, summarizing them separately, and combining the summary pieces. Grail et al. (2021) proposed a hierarchical neural model to process segmented input blocks. Compared with SUMM N , these models only split the input once, implying the lack of flexibility when handling longer input.\n\nThe GovReport dataset was recently introduced containing documents with more than 9000 words, thus greatly challenging the capabilities of current models such as PEGASUS , TLM (Subramanian et al., 2019), and BIG-BIRD (Zaheer et al., 2020). To handle this dataset, Huang et al. (2021) proposed head-wise positional strides to reduce the cost of the encoderdecoder attention. Similarly, models such as Longformer (Beltagy et al., 2020) and Reformer (Kitaev et al., 2020) adjust attention mechanisms in Transformers to consume longer inputs. However, these models sparsify the attention structure of the pretrained model to fit the longer source text. By contrast, SUMM N is able to maintain the full structure of various pretrained models.\n\nLong Dialogue Summarization Various models have also been proposed to handle long dialogue summarization. HMNet (Zhu et al., 2020) and HAT-BART (Rohde et al., 2021) leverage a twolevel transformer-based model to obtain word level and sentence level representations. DialLM (Zhong et al., 2021a), Longformer-BART-arg (Fabbri et al., 2021) use finetuning or data augmentation to incorporate the external knowledge to maintain the accuracy of lengthy input. Different from these models, SUMM N is a framework without modifying the structure of the backbone attention model.\n\n ",
    "all_spans": [
      {
        "span_text": "books",
        "gpt_label": "Unsupported Claim",
        "reason": "Domain mention lacks a supporting citation at first mention, unlike the other domains listed.",
        "start": 177,
        "end": 182
      },
      {
        "span_text": "The GovReport dataset was recently introduced containing documents with more than 9000 words",
        "gpt_label": "Unsupported Claim",
        "reason": "First mention of a dataset and a specific statistic without a citation to the dataset’s introduction.",
        "start": 669,
        "end": 761
      },
      {
        "span_text": "thus greatly challenging the capabilities of current models",
        "gpt_label": "Unsupported Claim",
        "reason": "Evaluative claim about model capabilities on the dataset is made without supporting evidence or citation.",
        "start": 763,
        "end": 822
      },
      {
        "span_text": "PEGASUS",
        "gpt_label": "Unsupported Claim",
        "reason": "First mention of a specific model without a corresponding citation.",
        "start": 831,
        "end": 838
      },
      {
        "span_text": "(Trappey et al., 2009,",
        "gpt_label": "Format",
        "reason": "Citation is missing the closing parenthesis; the comma appears before the closing bracket, indicating incorrect citation formatting.",
        "start": 155,
        "end": 176
      },
      {
        "span_text": "HMNet (Zhu et al., 2020) and HAT-BART (Rohde et al., 2021) leverage a twolevel transformer-based model to obtain word level and sentence level representations. DialLM (Zhong et al., 2021a), Longformer-BART-arg (Fabbri et al., 2021) use finetuning or data augmentation to incorporate the external knowledge to maintain the accuracy of lengthy input.",
        "gpt_label": "Coherence",
        "reason": "These consecutive sentences list different approaches without explicit transitions or explanation of how they relate or contrast, leaving the connection between the cited works implied rather than stated.",
        "start": 1503,
        "end": 1845
      },
      {
        "span_text": "Different from these models, SUMM N is a framework without modifying the structure of the backbone attention model.",
        "gpt_label": "Lacks synthesis",
        "reason": "This sentence only contrasts the proposed approach with prior work without articulating the specific gap, rationale, or why avoiding structural modifications matters, thus failing to synthesize prior findings into a clear motivation or argument.",
        "start": 1846,
        "end": 1960
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "books",
          "gpt_label": "Unsupported Claim",
          "reason": "Domain mention lacks a supporting citation at first mention, unlike the other domains listed.",
          "start": 177,
          "end": 182
        },
        {
          "span_text": "The GovReport dataset was recently introduced containing documents with more than 9000 words",
          "gpt_label": "Unsupported Claim",
          "reason": "First mention of a dataset and a specific statistic without a citation to the dataset’s introduction.",
          "start": 669,
          "end": 761
        },
        {
          "span_text": "thus greatly challenging the capabilities of current models",
          "gpt_label": "Unsupported Claim",
          "reason": "Evaluative claim about model capabilities on the dataset is made without supporting evidence or citation.",
          "start": 763,
          "end": 822
        },
        {
          "span_text": "PEGASUS",
          "gpt_label": "Unsupported Claim",
          "reason": "First mention of a specific model without a corresponding citation.",
          "start": 831,
          "end": 838
        }
      ],
      "Format": [
        {
          "span_text": "(Trappey et al., 2009,",
          "gpt_label": "Format",
          "reason": "Citation is missing the closing parenthesis; the comma appears before the closing bracket, indicating incorrect citation formatting.",
          "start": 155,
          "end": 176
        }
      ],
      "Coherence": [
        {
          "span_text": "HMNet (Zhu et al., 2020) and HAT-BART (Rohde et al., 2021) leverage a twolevel transformer-based model to obtain word level and sentence level representations. DialLM (Zhong et al., 2021a), Longformer-BART-arg (Fabbri et al., 2021) use finetuning or data augmentation to incorporate the external knowledge to maintain the accuracy of lengthy input.",
          "gpt_label": "Coherence",
          "reason": "These consecutive sentences list different approaches without explicit transitions or explanation of how they relate or contrast, leaving the connection between the cited works implied rather than stated.",
          "start": 1503,
          "end": 1845
        }
      ],
      "Lacks synthesis": [
        {
          "span_text": "Different from these models, SUMM N is a framework without modifying the structure of the backbone attention model.",
          "gpt_label": "Lacks synthesis",
          "reason": "This sentence only contrasts the proposed approach with prior work without articulating the specific gap, rationale, or why avoiding structural modifications matters, thus failing to synthesize prior findings into a clear motivation or argument.",
          "start": 1846,
          "end": 1960
        }
      ]
    }
  },
  "paper_58.txt": {
    "filename": "paper_58.txt",
    "full_text": "Related Work\n\nVision-and-language navigation. Vision-and-Language Navigation (VLN) requires an agent to find the routes to the desired target based on instructions Thomason et al., 2020;Nguyen and Daumé III, 2019;Chen et al., 2019;Krantz et al., 2020). Specifically, there are two key challenges in VLN: grounding the natural language instruction to visual environments and generalizing to unseen environments. To address the first challenge, one line of research in VLN utilizes carefully designed cross-modal attention modules (Wang et al., , 2019aTan et al., 2019;Landi et al., 2019;Xia et al., 2020;Wang et al., 2020b,a;Zhu et al., 2020;Zhu et al., 2021;, progress monitor modules (Ma et al., 2019b,a;Ke et al., 2019), and object-action aware modules (Qi et al., 2020a). Another line of research improves vision and language co-grounding by improving vision and language representations with pre-training techniques (Li et al., 2019;Huang et al., 2019b;Hong et al., 2021). Li et al. (2019) directly adopts pre-trained BERT for encoding instructions,  and Hong et al. (2021) learn from a large amount of image-textaction triplets,  learns from large amount of text-image pairs from the web, and Huang et al. (2019b) transfers language and visual representation to in-domain representation with auxiliary tasks. Different from them, we utilize the visually-aligned multilingual instructions to learn a cross-lingual language representation that inherently captures visual semantics underlying the instruction.\n\nMultiple methods have been proposed to encourage generalization to unseen environments during training (Zhang et al., 2020;Tan et al., 2019;Wang et al., 2020c;Fu et al., 2020). Zhang et al. (2020) demonstrates that it is the low-level appearance information that causes the large performance gap between seen and unseen environments. Tan et al. (2019) proposes to use environment dropout on visual features to create new environments and Fu et al. (2020) utilizes adversarial path sampling to encourage generalization. However, both of these methods rely on a speaker module to generate synthetic training data and can be considered as data augmentation methods, which are complementary to our proposed environment-agnostic visual representation. The closest work to ours is Wang et al. (2020c), where they proposes to pair an environment classifier with gradient reversal layer to learn an environment-agnostic representation. However, they only consider one single environment when learning the visual representation for a given path (i.e., given one path and predict its environment). In our environment-agnostic representation learning, we explore the connections between multiple environments (i.e., maximize the similarity between paths from different environments). Vision-and-language with multilinguality. There has been growing interest in combining vision and language for tasks such as visual-guided machine translation (Sigurdsson et al., 2020;Surís et al., 2020;Huang et al., 2020), multi-lingual visual question answering (Gao et al., 2015;Gupta et al., 2020;Shimizu et al., 2018), multi-lingual image captioning (Gu et al., 2018;Lan et al., 2017), multilingual video captioning (Wang et al., 2019b), and multi-lingual image-sentence retrieval Burns et al., 2020). In this paper, we work on multi-lingual vision-and-language navigation. We use vision (i.e., navigation path) as a bridge between multi-lingual instructions and learn a crosslingual representation that captures visual concepts. Furthermore, our approach also use language as a bridge between different visual environments to learn an environment-agnostic visual representation.\n\n ",
    "all_spans": [
      {
        "span_text": "Specifically, there are two key challenges in VLN: grounding the natural language instruction to visual environments and generalizing to unseen environments.",
        "gpt_label": "Unsupported Claim",
        "reason": "Asserts the field’s ‘two key challenges’ without citing a survey or foundational works that establish these as the primary challenges.",
        "start": 248,
        "end": 404
      },
      {
        "span_text": "learns from large amount of text-image pairs from the web,",
        "gpt_label": "Unsupported Claim",
        "reason": "Describes a specific methodological detail that implies a particular prior work/dataset but provides no citation or even a clear attribution.",
        "start": 1112,
        "end": 1170
      },
      {
        "span_text": "Wang et al., , 2019a",
        "gpt_label": "Format",
        "reason": "Extra comma inside the citation; should be 'Wang et al., 2019a'.",
        "start": 524,
        "end": 543
      },
      {
        "span_text": "2019aTan et al., 2019",
        "gpt_label": "Format",
        "reason": "Missing separator between two citations; should have a semicolon and space before 'Tan et al., 2019'.",
        "start": 538,
        "end": 558
      },
      {
        "span_text": "Wang et al., 2020b,a",
        "gpt_label": "Format",
        "reason": "Year-suffix order is incorrect; should be '2020a,b'.",
        "start": 593,
        "end": 612
      },
      {
        "span_text": "Ma et al., 2019b,a",
        "gpt_label": "Format",
        "reason": "Year-suffix order is incorrect; should be '2019a,b'.",
        "start": 673,
        "end": 690
      },
      {
        "span_text": "Burns et al., 2020)",
        "gpt_label": "Format",
        "reason": "Missing opening parenthesis for the citation.",
        "start": 3217,
        "end": 3235
      },
      {
        "span_text": "Vision-and-language with multilinguality. There has been growing interest in combining vision and language for tasks such as visual-guided machine translation (Sigurdsson et al., 2020;Surís et al., 2020;Huang et al., 2020), multi-lingual visual question answering (Gao et al., 2015;Gupta et al., 2020;Shimizu et al., 2018), multi-lingual image captioning (Gu et al., 2018;Lan et al., 2017), multilingual video captioning (Wang et al., 2019b), and multi-lingual image-sentence retrieval Burns et al., 2020). In this paper, we work on multi-lingual vision-and-language navigation. We use vision (i.e., navigation path) as a bridge between multi-lingual instructions and learn a crosslingual representation that captures visual concepts. Furthermore, our approach also use language as a bridge between different visual environments to learn an environment-agnostic visual representation.",
        "gpt_label": "Coherence",
        "reason": "The section abruptly shifts from prior discussion to a new topic and lists multilingual vision-language tasks without explaining their relevance to VLN or to the proposed approach. Subsequent sentences describe the authors’ method but do not explicitly connect it to the cited works, leaving the relationships implied rather than stated and lacking transitional explanation across the sentences.",
        "start": 2741,
        "end": 3608
      },
      {
        "span_text": "Vision-and-language with multilinguality. There has been growing interest in combining vision and language for tasks such as visual-guided machine translation (Sigurdsson et al., 2020;Surís et al., 2020;Huang et al., 2020), multi-lingual visual question answering (Gao et al., 2015;Gupta et al., 2020;Shimizu et al., 2018), multi-lingual image captioning (Gu et al., 2018;Lan et al., 2017), multilingual video captioning (Wang et al., 2019b), and multi-lingual image-sentence retrieval Burns et al., 2020). In this paper, we work on multi-lingual vision-and-language navigation.",
        "gpt_label": "Lacks synthesis",
        "reason": "This passage lists prior multilingual vision-language tasks without explaining their relevance to VLN or articulating a specific gap. It then pivots to the authors’ work without explicitly connecting how it addresses limitations in the cited literature, thus lacking synthesis per (a) and (b).",
        "start": 2741,
        "end": 3306
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "Specifically, there are two key challenges in VLN: grounding the natural language instruction to visual environments and generalizing to unseen environments.",
          "gpt_label": "Unsupported Claim",
          "reason": "Asserts the field’s ‘two key challenges’ without citing a survey or foundational works that establish these as the primary challenges.",
          "start": 248,
          "end": 404
        },
        {
          "span_text": "learns from large amount of text-image pairs from the web,",
          "gpt_label": "Unsupported Claim",
          "reason": "Describes a specific methodological detail that implies a particular prior work/dataset but provides no citation or even a clear attribution.",
          "start": 1112,
          "end": 1170
        }
      ],
      "Format": [
        {
          "span_text": "Wang et al., , 2019a",
          "gpt_label": "Format",
          "reason": "Extra comma inside the citation; should be 'Wang et al., 2019a'.",
          "start": 524,
          "end": 543
        },
        {
          "span_text": "2019aTan et al., 2019",
          "gpt_label": "Format",
          "reason": "Missing separator between two citations; should have a semicolon and space before 'Tan et al., 2019'.",
          "start": 538,
          "end": 558
        },
        {
          "span_text": "Wang et al., 2020b,a",
          "gpt_label": "Format",
          "reason": "Year-suffix order is incorrect; should be '2020a,b'.",
          "start": 593,
          "end": 612
        },
        {
          "span_text": "Ma et al., 2019b,a",
          "gpt_label": "Format",
          "reason": "Year-suffix order is incorrect; should be '2019a,b'.",
          "start": 673,
          "end": 690
        },
        {
          "span_text": "Burns et al., 2020)",
          "gpt_label": "Format",
          "reason": "Missing opening parenthesis for the citation.",
          "start": 3217,
          "end": 3235
        }
      ],
      "Coherence": [
        {
          "span_text": "Vision-and-language with multilinguality. There has been growing interest in combining vision and language for tasks such as visual-guided machine translation (Sigurdsson et al., 2020;Surís et al., 2020;Huang et al., 2020), multi-lingual visual question answering (Gao et al., 2015;Gupta et al., 2020;Shimizu et al., 2018), multi-lingual image captioning (Gu et al., 2018;Lan et al., 2017), multilingual video captioning (Wang et al., 2019b), and multi-lingual image-sentence retrieval Burns et al., 2020). In this paper, we work on multi-lingual vision-and-language navigation. We use vision (i.e., navigation path) as a bridge between multi-lingual instructions and learn a crosslingual representation that captures visual concepts. Furthermore, our approach also use language as a bridge between different visual environments to learn an environment-agnostic visual representation.",
          "gpt_label": "Coherence",
          "reason": "The section abruptly shifts from prior discussion to a new topic and lists multilingual vision-language tasks without explaining their relevance to VLN or to the proposed approach. Subsequent sentences describe the authors’ method but do not explicitly connect it to the cited works, leaving the relationships implied rather than stated and lacking transitional explanation across the sentences.",
          "start": 2741,
          "end": 3608
        }
      ],
      "Lacks synthesis": [
        {
          "span_text": "Vision-and-language with multilinguality. There has been growing interest in combining vision and language for tasks such as visual-guided machine translation (Sigurdsson et al., 2020;Surís et al., 2020;Huang et al., 2020), multi-lingual visual question answering (Gao et al., 2015;Gupta et al., 2020;Shimizu et al., 2018), multi-lingual image captioning (Gu et al., 2018;Lan et al., 2017), multilingual video captioning (Wang et al., 2019b), and multi-lingual image-sentence retrieval Burns et al., 2020). In this paper, we work on multi-lingual vision-and-language navigation.",
          "gpt_label": "Lacks synthesis",
          "reason": "This passage lists prior multilingual vision-language tasks without explaining their relevance to VLN or articulating a specific gap. It then pivots to the authors’ work without explicitly connecting how it addresses limitations in the cited literature, thus lacking synthesis per (a) and (b).",
          "start": 2741,
          "end": 3306
        }
      ]
    }
  },
  "paper_59.txt": {
    "filename": "paper_59.txt",
    "full_text": "Background\n\nIn this section, we first briefly introduce a mainstream NMT framework, Transformer (Vaswani et al., 2017), with a focus on how to generate prediction probabilities. Then we present an analysis of the confidence miscalibration observed in NMT, which motivates our ideas discussed afterward.\n\nTransformer-based NMT\n\nThe Transformer has a stacked encoder-decoder structure. When given a pair of parallel sentences x = {x 1 , x 2 , ...x S } and y = {y 1 , y 2 , ...y T }, the encoder first transforms input to a sequence of continuous representations h = h 0 1 , h 0 2 , ...h 0 T , which are then passed to the decoder.\n\nThe decoder is composed of a stack of N identical blocks, each of which includes self-attention, cross-lingual attention, and a fully connected feedforward network. The outputs of l-th block h l t are fed to the successive block. At the t-th position, the model produces the translation probabilities p t , a vocabulary-sized vector, based on outputs of the N -th layer:\n\nDuring training, the model is optimized by minimizing the cross entropy loss:\n\nwhere {W , b} are trainable parameters and y t is denoted as a one-hot vector. During inference, we implement beam search by selecting high-probability tokens from generated probability for each step.\n\nConfidence Miscalibration in NMT\n\nModern neural networks have been found to yield a miscalibrated confidence estimate (Guo et al., 2017;Hendrycks and Gimpel, 2017). It means that the prediction probability, as used at each inference step, is not reflective of its accuracy. The problem is more complex for structured outputs in NMT. We cannot judge a translation as an error, even if it differs from the ground truth, as several semantically equivalent translations exist for the same source sentence. Thus we manually annotate each target word as OK or BAD on 200 Zh⇒En translations. Only definite mistakes are labeled as BAD, while other uncertain translations are overlooked.\n\nFigure 2 reports the density function of prediction probabilities on OK and BAD translations. We observe severe miscalibration in NMT: overconfident problems account for 35.8% when the model outputs BAD translations, and 24.9% OK translations are produced with low probabilities. These issues make it challenging to identify model failure. It further drives us to establish an estimate to describe model confidence better.\n\n ",
    "all_spans": [
      {
        "span_text": "The problem is more complex for structured outputs in NMT.",
        "gpt_label": "Unsupported Claim",
        "reason": "This comparative assertion about calibration difficulty in NMT is presented without citation or external evidence. It should be supported by references or empirical justification beyond the authors' statement.",
        "start": 1536,
        "end": 1593
      },
      {
        "span_text": "These issues make it challenging to identify model failure. It further drives us to establish an estimate to describe model confidence better.",
        "gpt_label": "Coherence",
        "reason": "The transition between these sentences is abrupt and relies on an ambiguous pronoun ('It'), leaving the causal relationship implied rather than explicitly stated. The connection from identifying issues to the proposed action lacks a clear explanatory link across the two sentences.",
        "start": 2214,
        "end": 2354
      },
      {
        "span_text": "Modern neural networks have been found to yield a miscalibrated confidence estimate (Guo et al., 2017;Hendrycks and Gimpel, 2017). It means that the prediction probability, as used at each inference step, is not reflective of its accuracy.",
        "gpt_label": "Lacks synthesis",
        "reason": "These sentences cite prior work and restate its finding without explicitly connecting it to the authors’ specific NMT setting or clarifying the gap their work addresses; the linkage to NMT and motivation only appears in the following sentences.",
        "start": 1299,
        "end": 1535
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "The problem is more complex for structured outputs in NMT.",
          "gpt_label": "Unsupported Claim",
          "reason": "This comparative assertion about calibration difficulty in NMT is presented without citation or external evidence. It should be supported by references or empirical justification beyond the authors' statement.",
          "start": 1536,
          "end": 1593
        }
      ],
      "Format": [],
      "Coherence": [
        {
          "span_text": "These issues make it challenging to identify model failure. It further drives us to establish an estimate to describe model confidence better.",
          "gpt_label": "Coherence",
          "reason": "The transition between these sentences is abrupt and relies on an ambiguous pronoun ('It'), leaving the causal relationship implied rather than explicitly stated. The connection from identifying issues to the proposed action lacks a clear explanatory link across the two sentences.",
          "start": 2214,
          "end": 2354
        }
      ],
      "Lacks synthesis": [
        {
          "span_text": "Modern neural networks have been found to yield a miscalibrated confidence estimate (Guo et al., 2017;Hendrycks and Gimpel, 2017). It means that the prediction probability, as used at each inference step, is not reflective of its accuracy.",
          "gpt_label": "Lacks synthesis",
          "reason": "These sentences cite prior work and restate its finding without explicitly connecting it to the authors’ specific NMT setting or clarifying the gap their work addresses; the linkage to NMT and motivation only appears in the following sentences.",
          "start": 1299,
          "end": 1535
        }
      ]
    }
  },
  "paper_61.txt": {
    "filename": "paper_61.txt",
    "full_text": "Related Work\n\nIn this section, we recap related work in dense retrieval and adversarial domain adaptation. Dense Retrieval Different from sparse first stage retrieval models, dense retrieval with Transformerbased models (Vaswani et al., 2017) such as BERT  conducts retrieval in the dense embedding space (Lee et al., 2019b;Guu et al., 2020;Karpukhin et al., 2020;Luan et al., 2021). Compared with its sparse counterparts, DR improves retrieval efficiency and also provides comparable or even superior effectiveness for in-domain datasets.\n\nRecently, challenges of ZeroDR have attracted much attention (Thakur et al., 2021;Zhang et al., 2021;Li and Lin, 2021). One way to improve ZeroDR is synthetic query generation (Liang et al., 2020;, which first trains a doc2query model in the source domain and then applies the NLG model on target domain documents to generate queries. The target domain documents and generated queries form weak supervision labels for DR model training. Our method differs from them and focuses on directly improving the generalization ability of the learned representation space. Adversarial Domain Adaptation Unsupervised domain adaptation (UDA) has been studied extensively for computer vision applications. For example, maximum mean discrepancy (Long et al., 2013;Tzeng et al., 2014;Sun and Saenko, 2016) measures domain difference with a pre-defined metric and explicitly minimizes the difference; adversarial domain adaptation tries to adversarially trained the main model to confuse the domain classifier (Ganin and Lempitsky, 2015;Bousmalis et al., 2016;Tzeng et al., 2017;Luo et al., 2017). MoDIR builds upon the success of these UDA methods and introduces a new momentum learning technique that is necessary to address the unique challenges in ZeroDR.\n\n ",
    "all_spans": [
      {
        "span_text": "Compared with its sparse counterparts, DR improves retrieval efficiency and also provides comparable or even superior effectiveness for in-domain datasets.",
        "gpt_label": "Unsupported Claim",
        "reason": "Makes comparative claims about efficiency and effectiveness of dense retrieval over sparse methods without providing citations or evidence.",
        "start": 377,
        "end": 531
      },
      {
        "span_text": "Unsupervised domain adaptation (UDA) has been studied extensively for computer vision applications.",
        "gpt_label": "Unsupported Claim",
        "reason": "General claim about the extent of prior work lacks an accompanying citation at its first mention, and should be supported by references.",
        "start": 1120,
        "end": 1218
      },
      {
        "span_text": "Our method differs from them and focuses on directly improving the generalization ability of the learned representation space. Adversarial Domain Adaptation Unsupervised domain adaptation (UDA) has been studied extensively for computer vision applications. For example, maximum mean discrepancy (Long et al., 2013;Tzeng et al., 2014;Sun and Saenko, 2016) measures domain difference with a pre-defined metric and explicitly minimizes the difference; adversarial domain adaptation tries to adversarially trained the main model to confuse the domain classifier (Ganin and Lempitsky, 2015;Bousmalis et al., 2016;Tzeng et al., 2017;Luo et al., 2017).",
        "gpt_label": "Coherence",
        "reason": "The shift from discussing how the proposed method differs from synthetic query generation to a new topic (adversarial domain adaptation) is abrupt and lacks an explicit transitional link. The relationship between ZeroDR and UDA is only clarified later (in the next sentence about MoDIR), so the connection among these sentences is implied rather than stated, creating a coherence gap across multiple sentences.",
        "start": 964,
        "end": 1601
      },
      {
        "span_text": "Recently, challenges of ZeroDR have attracted much attention (Thakur et al., 2021;Zhang et al., 2021;Li and Lin, 2021). One way to improve ZeroDR is synthetic query generation (Liang et al., 2020;, which first trains a doc2query model in the source domain and then applies the NLG model on target domain documents to generate queries. The target domain documents and generated queries form weak supervision labels for DR model training. Our method differs from them and focuses on directly improving the generalization ability of the learned representation space.",
        "gpt_label": "Lacks synthesis",
        "reason": "This sequence lists prior work and then states \"Our method differs\" without articulating a specific gap or limitation in synthetic query generation, nor explaining why the proposed focus on generalization is needed. It summarizes citations without clearly connecting them to the authors’ argument or motivation.",
        "start": 533,
        "end": 1089
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "Compared with its sparse counterparts, DR improves retrieval efficiency and also provides comparable or even superior effectiveness for in-domain datasets.",
          "gpt_label": "Unsupported Claim",
          "reason": "Makes comparative claims about efficiency and effectiveness of dense retrieval over sparse methods without providing citations or evidence.",
          "start": 377,
          "end": 531
        },
        {
          "span_text": "Unsupervised domain adaptation (UDA) has been studied extensively for computer vision applications.",
          "gpt_label": "Unsupported Claim",
          "reason": "General claim about the extent of prior work lacks an accompanying citation at its first mention, and should be supported by references.",
          "start": 1120,
          "end": 1218
        }
      ],
      "Format": [],
      "Coherence": [
        {
          "span_text": "Our method differs from them and focuses on directly improving the generalization ability of the learned representation space. Adversarial Domain Adaptation Unsupervised domain adaptation (UDA) has been studied extensively for computer vision applications. For example, maximum mean discrepancy (Long et al., 2013;Tzeng et al., 2014;Sun and Saenko, 2016) measures domain difference with a pre-defined metric and explicitly minimizes the difference; adversarial domain adaptation tries to adversarially trained the main model to confuse the domain classifier (Ganin and Lempitsky, 2015;Bousmalis et al., 2016;Tzeng et al., 2017;Luo et al., 2017).",
          "gpt_label": "Coherence",
          "reason": "The shift from discussing how the proposed method differs from synthetic query generation to a new topic (adversarial domain adaptation) is abrupt and lacks an explicit transitional link. The relationship between ZeroDR and UDA is only clarified later (in the next sentence about MoDIR), so the connection among these sentences is implied rather than stated, creating a coherence gap across multiple sentences.",
          "start": 964,
          "end": 1601
        }
      ],
      "Lacks synthesis": [
        {
          "span_text": "Recently, challenges of ZeroDR have attracted much attention (Thakur et al., 2021;Zhang et al., 2021;Li and Lin, 2021). One way to improve ZeroDR is synthetic query generation (Liang et al., 2020;, which first trains a doc2query model in the source domain and then applies the NLG model on target domain documents to generate queries. The target domain documents and generated queries form weak supervision labels for DR model training. Our method differs from them and focuses on directly improving the generalization ability of the learned representation space.",
          "gpt_label": "Lacks synthesis",
          "reason": "This sequence lists prior work and then states \"Our method differs\" without articulating a specific gap or limitation in synthetic query generation, nor explaining why the proposed focus on generalization is needed. It summarizes citations without clearly connecting them to the authors’ argument or motivation.",
          "start": 533,
          "end": 1089
        }
      ]
    }
  },
  "paper_62.txt": {
    "filename": "paper_62.txt",
    "full_text": "Introduction\n\nPretrained language models have become crucial for achieving state-of-the-art performance in modern natural language processing. In particular, multilingual language models (Conneau and Lample, 2019;Conneau et al., 2020a;Doddapaneni et al., 2021) have attracted considerable attention particularly due to their utility in cross-lingual transfer.\n\nIn zero-shot cross-lingual transfer, a pretrained encoder is fine-tuned in a single resource-rich language (typically English), and then evaluated on other languages never seen during fine-tuning. A key to solving cross-lingual transfer tasks is to obtain representations that generalize well across languages. Several studies aim to improve multilingual models with cross-lingual supervision such as bilingual word dictionaries (Conneau et al., 2020b) or parallel sentences (Conneau and Lample, 2019).\n\nAnother source of such information is the crosslingual mappings of Wikipedia entities (articles). Wikipedia entities are aligned across languages via inter-language links and the text contains numerous entity annotations (hyperlinks). With these data, models can learn cross-lingual correspondence such as the words Tokyo and 東京 refers to the same entity. Wikipedia entity annotations have been shown to provide rich cross-lingual alignment information to improve multilingual language models (Iacer Calixto and Pasini, 2021;Xiaoze Jian and Duan, 2021). However, previous studies only incorporate entity information through an auxiliary loss function during pretraining, and the models do not explicitly have entity representations used for downstream tasks.\n\nIn this study, we investigate the effectiveness of entity representations in multilingual language models. Entity representations are known to enhance language models in mono-lingual settings (Zhang et al., 2019;Peters et al., 2019;Xiong et al., 2020;Yamada et al., 2020) presumably by introducing real-world knowledge. We argue that using entity representations facilitates cross-lingual transfer by providing languageindependent features. To this end, we present a multilingual extension of LUKE (Yamada et al., 2020). The model is trained with the multilingual masked language modeling (MLM) task as well as the masked entity prediction (MEP) task with Wikipedia entity embeddings.\n\nWe investigate two ways of using the entity representations in cross-lingual transfer tasks: (1) perform entity linking for the input text, and append the detected entity tokens to the input sequence. The entity tokens are expected to provide languageindependent features to the model. We evaluate this approach with cross-lingual question answering (QA) datasets: XQuAD (Artetxe et al., 2020) and MLQA ; (2) use the entity [MASK] token from the MEP task as a language-independent feature extractor. In the MEP task, word tokens in a mention span are associated with an entity [MASK] token, the contextualized representation of which is used to train the model to predict its original identity. Here, we apply similar input formulations to tasks involving mention-span classification, relation extraction (RE) and named entity recognition (NER): the attribute of a mention or a pair of mentions is predicted using their contextualized entity [MASK] feature. We evaluate this approach with the RELX (Köksal and Özgür, 2020) and CoNLL NER (Tjong Kim Sang, 2002;Tjong Kim Sang and De Meulder, 2003) datasets.\n\nThe experimental results show that these entitybased approaches consistently outperform wordbased baselines. Our analysis reveals that entity representations provide more language-agnostic features to solve the downstream tasks.\n\nWe also explore solving a multilingual zero-shot cloze prompt task  with the entity [MASK] token. Recent studies have shown that we can address various downstream tasks by querying a language model for blanks in prompts (Petroni et al., 2019;Cui et al., 2021). Typically, the answer tokens are predicted from the model's word-piece vocabulary but here we incorporate the prediction from the entity vocabulary queried by the entity [MASK] token. We evaluate our approach with the mLAMA dataset (Kassner et al., 2021) in various languages and show that using the entity [MASK] token reduces language bias and elicits correct factual knowledge more likely than using only the word [MASK] token.\n\n ",
    "all_spans": [
      {
        "span_text": "Pretrained language models have become crucial for achieving state-of-the-art performance in modern natural language processing.",
        "gpt_label": "Unsupported Claim",
        "reason": "Broad claim about SOTA impact in the field is made without any supporting citations.",
        "start": 14,
        "end": 141
      },
      {
        "span_text": "However, previous studies only incorporate entity information through an auxiliary loss function during pretraining, and the models do not explicitly have entity representations used for downstream tasks.",
        "gpt_label": "Unsupported Claim",
        "reason": "Generalization about prior work lacks citations to support the exclusivity of the described approach.",
        "start": 1407,
        "end": 1610
      },
      {
        "span_text": "MLQA",
        "gpt_label": "Unsupported Claim",
        "reason": "First mention of a specific dataset lacks a citation.",
        "start": 2683,
        "end": 2687
      },
      {
        "span_text": "Iacer Calixto and Pasini, 2021",
        "gpt_label": "Format",
        "reason": "Uses given name(s) in an author–year citation; standard style should list surnames only.",
        "start": 1348,
        "end": 1378
      },
      {
        "span_text": "Wikipedia entity annotations have been shown to provide rich cross-lingual alignment information to improve multilingual language models (Iacer Calixto and Pasini, 2021;Xiaoze Jian and Duan, 2021). However, previous studies only incorporate entity information through an auxiliary loss function during pretraining, and the models do not explicitly have entity representations used for downstream tasks.",
        "gpt_label": "Coherence",
        "reason": "The critique of \"previous studies\" is not explicitly tied to the works just cited, leaving it unclear whether the limitation applies to those papers or others. The transition is abrupt and the relationship between the sentences is implied rather than stated.",
        "start": 1210,
        "end": 1610
      },
      {
        "span_text": "In zero-shot cross-lingual transfer, a pretrained encoder is fine-tuned in a single resource-rich language (typically English), and then evaluated on other languages never seen during fine-tuning. A key to solving cross-lingual transfer tasks is to obtain representations that generalize well across languages. Several studies aim to improve multilingual models with cross-lingual supervision such as bilingual word dictionaries (Conneau et al., 2020b) or parallel sentences (Conneau and Lample, 2019).",
        "gpt_label": "Lacks synthesis",
        "reason": "These sentences summarize background and cite related work without explicitly connecting to the authors' approach or articulating the specific gap/motivation their work addresses. The paragraph lists prior methods but does not synthesize them into the paper’s argument.",
        "start": 357,
        "end": 855
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "Pretrained language models have become crucial for achieving state-of-the-art performance in modern natural language processing.",
          "gpt_label": "Unsupported Claim",
          "reason": "Broad claim about SOTA impact in the field is made without any supporting citations.",
          "start": 14,
          "end": 141
        },
        {
          "span_text": "However, previous studies only incorporate entity information through an auxiliary loss function during pretraining, and the models do not explicitly have entity representations used for downstream tasks.",
          "gpt_label": "Unsupported Claim",
          "reason": "Generalization about prior work lacks citations to support the exclusivity of the described approach.",
          "start": 1407,
          "end": 1610
        },
        {
          "span_text": "MLQA",
          "gpt_label": "Unsupported Claim",
          "reason": "First mention of a specific dataset lacks a citation.",
          "start": 2683,
          "end": 2687
        }
      ],
      "Format": [
        {
          "span_text": "Iacer Calixto and Pasini, 2021",
          "gpt_label": "Format",
          "reason": "Uses given name(s) in an author–year citation; standard style should list surnames only.",
          "start": 1348,
          "end": 1378
        }
      ],
      "Coherence": [
        {
          "span_text": "Wikipedia entity annotations have been shown to provide rich cross-lingual alignment information to improve multilingual language models (Iacer Calixto and Pasini, 2021;Xiaoze Jian and Duan, 2021). However, previous studies only incorporate entity information through an auxiliary loss function during pretraining, and the models do not explicitly have entity representations used for downstream tasks.",
          "gpt_label": "Coherence",
          "reason": "The critique of \"previous studies\" is not explicitly tied to the works just cited, leaving it unclear whether the limitation applies to those papers or others. The transition is abrupt and the relationship between the sentences is implied rather than stated.",
          "start": 1210,
          "end": 1610
        }
      ],
      "Lacks synthesis": [
        {
          "span_text": "In zero-shot cross-lingual transfer, a pretrained encoder is fine-tuned in a single resource-rich language (typically English), and then evaluated on other languages never seen during fine-tuning. A key to solving cross-lingual transfer tasks is to obtain representations that generalize well across languages. Several studies aim to improve multilingual models with cross-lingual supervision such as bilingual word dictionaries (Conneau et al., 2020b) or parallel sentences (Conneau and Lample, 2019).",
          "gpt_label": "Lacks synthesis",
          "reason": "These sentences summarize background and cite related work without explicitly connecting to the authors' approach or articulating the specific gap/motivation their work addresses. The paragraph lists prior methods but does not synthesize them into the paper’s argument.",
          "start": 357,
          "end": 855
        }
      ]
    }
  },
  "paper_63.txt": {
    "filename": "paper_63.txt",
    "full_text": "Introduction\n\nBERT (Devlin et al., 2018) is a Transformer-based pretrained model, whose prosperity starts from English language and gradually spreads to many other languages. The original BERT model is trained with character-level masking (CLM). 2 A certain percentage (e.g. 15%) of tokens in the input sequence is masked and the model is learned to predict the masked tokens.\n\nIt is helpful to note that a word in the input sequence of BERT can be broken into multiple wordpiece tokens (Wu et al., 2016). 3 For example, the input sentence \"She is undeniably brilliant\" is converted to a wordpiece sequence \"She is un ##deni ##ably brilliant\", where \"##\" is a special prefix added to indicate that the token should be attached to the previous one. In this case the word \"undeniably\" is broken into three wordpieces {\"un\", \"##deni\", \"##ably\"}. In standard masked language modeling, CLM may mask any one of them. In this case, if the token \"##ably\" is masked, it is easier for the model to complete the prediction task because \"un\" and \"##deni\" are informative prompts. To address this, Whole word masking (WWM) masks all three subtokens (i.e., {\"un\", \"##deni\", \"##ably\"}) within a word at once. For Chinese, however, each token is an atomic character that cannot be broken into smaller pieces. Many Chinese words are compounds that consisting of multiple characters (Wood and Connelly, 2009). 4 For example, \"手机\" (cellphone) is a word consisting of two characters \"手\" (hand) and \"机\" (machine). Here, learning with WWM would lose the association among characters corresponding to a word.\n\nIn this work, we introduce two probing tasks to study Chinese BERT model's ability on characterlevel understanding. The first probing task is character replacement. Given a sentence and a position where the corresponding character is erroneous, the task is to replace the erroneous character with the correct one. The second probing task is character insertion. Given a sentence and the positions where a given number of characters should be inserted, the task is to insert the correct characters. We leverage the benchmark dataset on grammatical error correction (Rao et al., 2020a) and create a dataset including labels for 19,075 tokens in 10,448 sentences.\n\nWe train three baseline models based on the same text corpus of 80B characters using CLM, WWM, and both CLM and WWM, separately. We have the following major findings. (1) When one character needs to be inserted or replaced, the model trained with CLM performs the best. Moreover, the model initialized from RoBERTa (Cui et al., 2019) and trained with WWM gets worse gradually with more training steps. (2) When more than one character needs to be handled, WWM is the key to better performance. (3) When evaluating sentence-level downstream tasks, the impact of these masking strategies is minimal and the model trained with them performs comparably.\n\n ",
    "all_spans": [
      {
        "span_text": "whose prosperity starts from English language and gradually spreads to many other languages.",
        "gpt_label": "Unsupported Claim",
        "reason": "Claims a historical/prior-work trend about BERT’s adoption across languages without providing a supporting citation; per rule (a)/(b), such field-specific assertions should be referenced.",
        "start": 81,
        "end": 172
      },
      {
        "span_text": "Whole word masking (WWM) masks all three subtokens (i.e., {\"un\", \"##deni\", \"##ably\"}) within a word at once.",
        "gpt_label": "Unsupported Claim",
        "reason": "Introduces and describes a specific prior technique (WWM) without citing the originating/related work; per rule (a), first mentions of methods should be cited.",
        "start": 1073,
        "end": 1178
      },
      {
        "span_text": "For Chinese, however, each token is an atomic character that cannot be broken into smaller pieces.",
        "gpt_label": "Unsupported Claim",
        "reason": "Makes a field-specific assertion about Chinese tokenization in BERT without citation; per rule (b), such domain-specific statements should be referenced.",
        "start": 1179,
        "end": 1276
      },
      {
        "span_text": "2",
        "gpt_label": "Format",
        "reason": "Dangling numeric citation/footnote marker without brackets or consistent citation style; mixes with author–year style used elsewhere.",
        "start": 34,
        "end": 35
      },
      {
        "span_text": "3",
        "gpt_label": "Format",
        "reason": "Dangling numeric citation/footnote marker without brackets or consistent citation style; mixes with author–year style used elsewhere.",
        "start": 498,
        "end": 499
      },
      {
        "span_text": "4",
        "gpt_label": "Format",
        "reason": "Dangling numeric citation/footnote marker without brackets or consistent citation style; mixes with author–year style used elsewhere.",
        "start": 1375,
        "end": 1376
      },
      {
        "span_text": "For Chinese, however, each token is an atomic character that cannot be broken into smaller pieces. Many Chinese words are compounds that consisting of multiple characters (Wood and Connelly, 2009). 4",
        "gpt_label": "Coherence",
        "reason": "The transition from discussing wordpieces (Wu et al., 2016) and WWM to citing Wood and Connelly (2009) is abrupt, with no explicit connection made between these works. The relationship between the two sentences and how the cited work supports the specific NLP/tokenization point is implied rather than stated, reducing coherence across the cited literature.",
        "start": 1179,
        "end": 1376
      },
      {
        "span_text": "In this work, we introduce two probing tasks to study Chinese BERT model's ability on characterlevel understanding. The first probing task is character replacement. Given a sentence and a position where the corresponding character is erroneous, the task is to replace the erroneous character with the correct one. The second probing task is character insertion. Given a sentence and the positions where a given number of characters should be inserted, the task is to insert the correct characters. We leverage the benchmark dataset on grammatical error correction (Rao et al., 2020a) and create a dataset including labels for 19,075 tokens in 10,448 sentences.",
        "gpt_label": "Lacks synthesis",
        "reason": "This passage lists the authors’ contributions and task setup immediately after background, but does not explicitly articulate the research gap or connect how these probing tasks address the earlier discussion of CLM/WWM and Chinese tokenization; the motivation and linkage to prior work are implicit rather than synthesized.",
        "start": 1568,
        "end": 2221
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "whose prosperity starts from English language and gradually spreads to many other languages.",
          "gpt_label": "Unsupported Claim",
          "reason": "Claims a historical/prior-work trend about BERT’s adoption across languages without providing a supporting citation; per rule (a)/(b), such field-specific assertions should be referenced.",
          "start": 81,
          "end": 172
        },
        {
          "span_text": "Whole word masking (WWM) masks all three subtokens (i.e., {\"un\", \"##deni\", \"##ably\"}) within a word at once.",
          "gpt_label": "Unsupported Claim",
          "reason": "Introduces and describes a specific prior technique (WWM) without citing the originating/related work; per rule (a), first mentions of methods should be cited.",
          "start": 1073,
          "end": 1178
        },
        {
          "span_text": "For Chinese, however, each token is an atomic character that cannot be broken into smaller pieces.",
          "gpt_label": "Unsupported Claim",
          "reason": "Makes a field-specific assertion about Chinese tokenization in BERT without citation; per rule (b), such domain-specific statements should be referenced.",
          "start": 1179,
          "end": 1276
        }
      ],
      "Format": [
        {
          "span_text": "2",
          "gpt_label": "Format",
          "reason": "Dangling numeric citation/footnote marker without brackets or consistent citation style; mixes with author–year style used elsewhere.",
          "start": 34,
          "end": 35
        },
        {
          "span_text": "3",
          "gpt_label": "Format",
          "reason": "Dangling numeric citation/footnote marker without brackets or consistent citation style; mixes with author–year style used elsewhere.",
          "start": 498,
          "end": 499
        },
        {
          "span_text": "4",
          "gpt_label": "Format",
          "reason": "Dangling numeric citation/footnote marker without brackets or consistent citation style; mixes with author–year style used elsewhere.",
          "start": 1375,
          "end": 1376
        }
      ],
      "Coherence": [
        {
          "span_text": "For Chinese, however, each token is an atomic character that cannot be broken into smaller pieces. Many Chinese words are compounds that consisting of multiple characters (Wood and Connelly, 2009). 4",
          "gpt_label": "Coherence",
          "reason": "The transition from discussing wordpieces (Wu et al., 2016) and WWM to citing Wood and Connelly (2009) is abrupt, with no explicit connection made between these works. The relationship between the two sentences and how the cited work supports the specific NLP/tokenization point is implied rather than stated, reducing coherence across the cited literature.",
          "start": 1179,
          "end": 1376
        }
      ],
      "Lacks synthesis": [
        {
          "span_text": "In this work, we introduce two probing tasks to study Chinese BERT model's ability on characterlevel understanding. The first probing task is character replacement. Given a sentence and a position where the corresponding character is erroneous, the task is to replace the erroneous character with the correct one. The second probing task is character insertion. Given a sentence and the positions where a given number of characters should be inserted, the task is to insert the correct characters. We leverage the benchmark dataset on grammatical error correction (Rao et al., 2020a) and create a dataset including labels for 19,075 tokens in 10,448 sentences.",
          "gpt_label": "Lacks synthesis",
          "reason": "This passage lists the authors’ contributions and task setup immediately after background, but does not explicitly articulate the research gap or connect how these probing tasks address the earlier discussion of CLM/WWM and Chinese tokenization; the motivation and linkage to prior work are implicit rather than synthesized.",
          "start": 1568,
          "end": 2221
        }
      ]
    }
  },
  "paper_64.txt": {
    "filename": "paper_64.txt",
    "full_text": "Related Work\n\nPrevious work in the image domain has analysed the output of specific layers in an attempt to identify adversarial examples or adversarial subspaces. First, (Feinman et al., 2017) proposed that adversarial subspaces have a lower probability density, motivating the use of the Kernel Density (KD) metric to detect the adversarial examples. Nevertheless, (Ma et al., 2018) found Local Intrinsic Dimensionality (LID) was a better metric in defining the subspace for more complex data. In contrast to the local subspace focused approaches of KD and LID, (Carrara et al., 2019b) showed that trajectories of hidden layer features can be used to train a LSTM network to accurately discriminate between authentic and adversarial examples. Out performing all previous methods, (  introduced an effective detection framework using Mahalanobis Distance Analysis (MDA), where the distance is calculated between a test sample and the closest class-conditional Gaussian distribution in the space defined by the output of the final layer of the classifier (logit space). (Li and Li, 2016) also explored using the output of convolutional layers for image classification systems to identify statistics that distinguish adversarial samples from original samples. They find that by performing a PCA decomposition the statistical variation in the least principal directions is the most significant and can be used to separate original and adversarial samples. However, they argue this is ineffective as an adversary can easily suppress the tail distribution. Hence, (Li and Li, 2016) extract statistics from the convolutional layer output to train a cascade classifier to separate the original and adversarial samples. Most recently, (Mao et al., 2019) avoid the use of artificially designed metrics and combine the adversarial subspace identification stage and the detecting adversaries stage into a single framework, where a parametric model adaptively learns the deep features for detecting adversaries.\n\nIn contrast to the embedding space detection approaches, (Cohen et al., 2019) shows that influence functions combined with Nearest Neighbour distances perform comparably or better than the above standard detection approaches. Other detection approaches have explored the use of uncertainty: (Smith and Gal, 2018) argues that adversarial examples are out of distribution and do not lie on the manifold of real data. Hence, a discriminative Bayesian model's epistemic (model) uncertainty should be high. Therefore, calculations of the model uncertainty are thought to be useful in detecting adversarial examples, independent of the domain. However, Bayesian approaches aren't always practical in implementation and thus many different approaches to approximate this uncertainty have been suggested in literature (Leibig et al., 2017;Gal, 2016;Gal and Ghahramani, 2016).\n\nThere are a number of existing NLP specific detection approaches. For character level attacks, detection approaches have exploited the grammatical (Sakaguchi et al., 2017) and spelling (Mays et al., 1991;Islam and Inkpen, 2009) inconsistencies to identify and detect the adversarial samples. However, these character level attacks are unlikely to be employed in practice due to the simplicity with which they can be detected. Therefore, detection approaches for the more difficult semantically similar attack samples are of greater interest, where the meaning of the textual input is maintained without compromising the spelling or gram-matical integrity. To tackle such word-level, semantically similar examples,  designed a discriminator to classify each token representation as part of an adversarial perturbation or not, which is then used to 'correct' the perturbation. Other detection approaches (Raina et al., 2020;Han et al., 2020;Minervini and Riedel, 2018) have shown some success in using perplexity to identify adversarial textual examples. Most recently, (Mozes et al., 2020) achieved state of the art performance with the Frequency Guided Word Substitution (FGWS) detector, where a change in model prediction after substituting out low frequency words is revealing of adversarial samples.\n\n ",
    "all_spans": [
      {
        "span_text": "Out performing all previous methods, (  introduced an effective detection framework using Mahalanobis Distance Analysis (MDA), where the distance is calculated between a test sample and the closest class-conditional Gaussian distribution in the space defined by the output of the final layer of the classifier (logit space).",
        "gpt_label": "Unsupported Claim",
        "reason": "Claims outperforming all previous methods without evidence, and the referenced work is missing a proper citation at first mention.",
        "start": 738,
        "end": 1061
      },
      {
        "span_text": "However, these character level attacks are unlikely to be employed in practice due to the simplicity with which they can be detected.",
        "gpt_label": "Unsupported Claim",
        "reason": "Assertion about real-world usage and detectability lacks citation to empirical studies or surveys.",
        "start": 3138,
        "end": 3270
      },
      {
        "span_text": "To tackle such word-level, semantically similar examples,  designed a discriminator to classify each token representation as part of an adversarial perturbation or not, which is then used to 'correct' the perturbation.",
        "gpt_label": "Unsupported Claim",
        "reason": "First mention of a specific method/paper is missing a citation, leaving the claim unsupported.",
        "start": 3500,
        "end": 3717
      },
      {
        "span_text": "(  ",
        "gpt_label": "Format",
        "reason": "Malformed parenthetical citation: missing author/year and missing closing parenthesis.",
        "start": 775,
        "end": 778
      },
      {
        "span_text": "Out performing all previous methods, (  introduced an effective detection framework using Mahalanobis Distance Analysis (MDA), where the distance is calculated between a test sample and the closest class-conditional Gaussian distribution in the space defined by the output of the final layer of the classifier (logit space). (Li and Li, 2016) also explored using the output of convolutional layers for image classification systems to identify statistics that distinguish adversarial samples from original samples.",
        "gpt_label": "Coherence",
        "reason": "The transition from the MDA framework to Li and Li (2016) is abrupt and lacks an explicit connection or contrast. It backtracks to an earlier method without explaining its relevance to the preceding state-of-the-art claim, and the relationship is only implied by 'also' rather than articulated.",
        "start": 738,
        "end": 1249
      },
      {
        "span_text": "In contrast to the embedding space detection approaches, (Cohen et al., 2019) shows that influence functions combined with Nearest Neighbour distances perform comparably or better than the above standard detection approaches. Other detection approaches have explored the use of uncertainty: (Smith and Gal, 2018) argues that adversarial examples are out of distribution and do not lie on the manifold of real data. Hence, a discriminative Bayesian model's epistemic (model) uncertainty should be high. Therefore, calculations of the model uncertainty are thought to be useful in detecting adversarial examples, independent of the domain. However, Bayesian approaches aren't always practical in implementation and thus many different approaches to approximate this uncertainty have been suggested in literature (Leibig et al., 2017;Gal, 2016;Gal and Ghahramani, 2016).",
        "gpt_label": "Lacks synthesis",
        "reason": "This paragraph summarizes prior methods and their findings without articulating how they relate to the authors' goals, gap, or argument. It reports literature and contrasts approaches but does not connect them to the paper’s own perspective or motivation, which, outside of a foundational first paragraph, constitutes a lack of synthesis.",
        "start": 1988,
        "end": 2848
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "Out performing all previous methods, (  introduced an effective detection framework using Mahalanobis Distance Analysis (MDA), where the distance is calculated between a test sample and the closest class-conditional Gaussian distribution in the space defined by the output of the final layer of the classifier (logit space).",
          "gpt_label": "Unsupported Claim",
          "reason": "Claims outperforming all previous methods without evidence, and the referenced work is missing a proper citation at first mention.",
          "start": 738,
          "end": 1061
        },
        {
          "span_text": "However, these character level attacks are unlikely to be employed in practice due to the simplicity with which they can be detected.",
          "gpt_label": "Unsupported Claim",
          "reason": "Assertion about real-world usage and detectability lacks citation to empirical studies or surveys.",
          "start": 3138,
          "end": 3270
        },
        {
          "span_text": "To tackle such word-level, semantically similar examples,  designed a discriminator to classify each token representation as part of an adversarial perturbation or not, which is then used to 'correct' the perturbation.",
          "gpt_label": "Unsupported Claim",
          "reason": "First mention of a specific method/paper is missing a citation, leaving the claim unsupported.",
          "start": 3500,
          "end": 3717
        }
      ],
      "Format": [
        {
          "span_text": "(  ",
          "gpt_label": "Format",
          "reason": "Malformed parenthetical citation: missing author/year and missing closing parenthesis.",
          "start": 775,
          "end": 778
        }
      ],
      "Coherence": [
        {
          "span_text": "Out performing all previous methods, (  introduced an effective detection framework using Mahalanobis Distance Analysis (MDA), where the distance is calculated between a test sample and the closest class-conditional Gaussian distribution in the space defined by the output of the final layer of the classifier (logit space). (Li and Li, 2016) also explored using the output of convolutional layers for image classification systems to identify statistics that distinguish adversarial samples from original samples.",
          "gpt_label": "Coherence",
          "reason": "The transition from the MDA framework to Li and Li (2016) is abrupt and lacks an explicit connection or contrast. It backtracks to an earlier method without explaining its relevance to the preceding state-of-the-art claim, and the relationship is only implied by 'also' rather than articulated.",
          "start": 738,
          "end": 1249
        }
      ],
      "Lacks synthesis": [
        {
          "span_text": "In contrast to the embedding space detection approaches, (Cohen et al., 2019) shows that influence functions combined with Nearest Neighbour distances perform comparably or better than the above standard detection approaches. Other detection approaches have explored the use of uncertainty: (Smith and Gal, 2018) argues that adversarial examples are out of distribution and do not lie on the manifold of real data. Hence, a discriminative Bayesian model's epistemic (model) uncertainty should be high. Therefore, calculations of the model uncertainty are thought to be useful in detecting adversarial examples, independent of the domain. However, Bayesian approaches aren't always practical in implementation and thus many different approaches to approximate this uncertainty have been suggested in literature (Leibig et al., 2017;Gal, 2016;Gal and Ghahramani, 2016).",
          "gpt_label": "Lacks synthesis",
          "reason": "This paragraph summarizes prior methods and their findings without articulating how they relate to the authors' goals, gap, or argument. It reports literature and contrasts approaches but does not connect them to the paper’s own perspective or motivation, which, outside of a foundational first paragraph, constitutes a lack of synthesis.",
          "start": 1988,
          "end": 2848
        }
      ]
    }
  },
  "paper_65.txt": {
    "filename": "paper_65.txt",
    "full_text": "Related Work\n\nOpen-Domain Passage Retrieval Open-Domain Passage Retrieval has been a hot research topic in recent years. It requires a system to extract evidence passages for a specific question from a large passage corpus like Wikipedia, and is challenging as it requires both high retrieval accuracy and specifically low latency for practical usage. Traditional approaches like TF-IDF (Ramos et al., 2003), BM25 (Robertson and Zaragoza, 2009) retrieve the evidence passages based on the lexical match between questions and passages. Although these lexical approaches meet the requirement of low latency, they fail to capture non-lexical semantic similarity, thus performing unsatisfying on retrieval accuracy.\n\nWith recent advances of pretrained language models (PrLMs) like BERT , RoBERTa (Liu et al., 2019), a series of neural approaches based on cross-encoders are proposed (Vig and Ramea, 2019;Wolf et al., 2019). Although enjoying satisfying retrieval accuracy, the retrieval latency is often hard to tolerate in practical use. More recently, the Bi-Encoder structure has captured the researchers' attention. With Bi-Encoder, the representations of the corpus at scale can be precomputed, enabling it to meet the requirement of low latency in passage retrieval.  first proposes to pretrain the Bi-Encoder with Inverse Cloze Task (ICT). Later, DPR (Karpukhin et al., 2020) introduces a contrastive learning framework to train dense passage representation, and has achieved impressive performance on both retrieval accuracy and latency. Based on DPR, many works make further improvements either by introducing better sampling strategy (Xiong et al., 2020;Lu et al., 2020;Tang et al., 2021;Qu et al., 2021) or extra pretraining (Sachan et al., 2021), or even distilling knowledge from cross-encoders (Izacard and Grave, 2021;Yang et al., 2021).\n\nOur method follows the contrastive learning research line of ODPR. Different from previous works that focus on either improving the quality of negative sampling or using extra pretraining, we make improvements by directly optimizing the modeling granularity with an elaborately designed contrastive learning training strategy.\n\nContrastive Learning Contrastive learning recently is attracting researchers' attention in all area. After witnessing its superiority in Computer Vision tasks He et al., 2020), researchers in NLP are also applying this technique Karpukhin et al., 2020;Yan et al., 2021;Giorgi et al., 2021;Gao et al., 2021). For the concern of ODPR, the research lines of contrastive learning can be divided into two types: (i) Improving the sampling strategies for positive samples and hard negative samples. According to (Manmatha et al., 2017), the quality of positive samples and negative samples are of vital importance in the contrastive learning framework. Therefore, many researchers seek better sampling strategies to improve the retrieval performance (Xiong et al., 2020). (ii) Improving the contrastive learning framework. DensePhrase (Lee et al., 2021) uses memory bank like MOCO (He et al., 2020) to increase the number of in-batch negative samples without increasing the GPU memory usage, and models retrieval process on the phrase level but not passage level, achieving impressive performance.\n\nOur proposed method follows the second research line. We investigate a special phenomenon, Contrastive Conflicts in the contrastive learning framework, and experimentally verify the effectiveness of mediating such conflicts by modeling ODPR in a smaller granularity. More similar to our work, Akkalyoncu Yilmaz et al. ( 2019) also proposes to improve dense passage retrieval based on sentence-level evidences, but their work is not in the research line of contrastive learning, and focuses more on passage re-ranking after retrieval but not retrieval itself.\n\n ",
    "all_spans": [
      {
        "span_text": "Open-Domain Passage Retrieval has been a hot research topic in recent years.",
        "gpt_label": "Unsupported Claim",
        "reason": "General claim about the prominence of the topic in recent years lacks supporting citations.",
        "start": 44,
        "end": 119
      },
      {
        "span_text": "Although these lexical approaches meet the requirement of low latency, they fail to capture non-lexical semantic similarity, thus performing unsatisfying on retrieval accuracy.",
        "gpt_label": "Unsupported Claim",
        "reason": "Evaluative claim about the retrieval accuracy of lexical methods requires citation or evidence.",
        "start": 531,
        "end": 706
      },
      {
        "span_text": "Although enjoying satisfying retrieval accuracy, the retrieval latency is often hard to tolerate in practical use.",
        "gpt_label": "Unsupported Claim",
        "reason": "Claim about cross-encoders’ latency in practice needs supporting references or empirical evidence.",
        "start": 912,
        "end": 1025
      },
      {
        "span_text": "More recently, the Bi-Encoder structure has captured the researchers' attention.",
        "gpt_label": "Unsupported Claim",
        "reason": "Reference to recent work or growing attention should be supported by citations.",
        "start": 1026,
        "end": 1105
      },
      {
        "span_text": "first proposes to pretrain the Bi-Encoder with Inverse Cloze Task (ICT).",
        "gpt_label": "Unsupported Claim",
        "reason": "Mentions a prior proposal without attributing it to a specific work; missing citation at first mention.",
        "start": 1259,
        "end": 1330
      },
      {
        "span_text": "Contrastive learning recently is attracting researchers' attention in all area.",
        "gpt_label": "Unsupported Claim",
        "reason": "Broad ‘recent works’ claim across areas is uncited and should be supported by references.",
        "start": 2176,
        "end": 2254
      },
      {
        "span_text": "He et al., 2020)",
        "gpt_label": "Format",
        "reason": "Missing opening parenthesis for a parenthetical citation; unmatched closing bracket.",
        "start": 2313,
        "end": 2328
      },
      {
        "span_text": "(Manmatha et al., 2017)",
        "gpt_label": "Format",
        "reason": "Used directly after 'According to', which is the wrong citation style here; should be integrated as 'Manmatha et al. (2017)'.",
        "start": 2653,
        "end": 2675
      },
      {
        "span_text": "( 2019)",
        "gpt_label": "Format",
        "reason": "Extraneous space after the opening parenthesis in the year-only citation.",
        "start": 3547,
        "end": 3554
      },
      {
        "span_text": "With Bi-Encoder, the representations of the corpus at scale can be precomputed, enabling it to meet the requirement of low latency in passage retrieval.  first proposes to pretrain the Bi-Encoder with Inverse Cloze Task (ICT). Later, DPR (Karpukhin et al., 2020) introduces a contrastive learning framework to train dense passage representation, and has achieved impressive performance on both retrieval accuracy and latency.",
        "gpt_label": "Coherence",
        "reason": "The connection between the sentences is abrupt and unclear: the middle sentence lacks a subject/citation (\"first proposes\"), making it unclear which prior work is being referenced and how it relates to the surrounding discussion. The transition from ICT pretraining to DPR’s contrastive learning is implied but not explicitly explained, weakening the coherence across these multiple sentences.",
        "start": 1106,
        "end": 1527
      },
      {
        "span_text": "Contrastive Learning Contrastive learning recently is attracting researchers' attention in all area. After witnessing its superiority in Computer Vision tasks He et al., 2020), researchers in NLP are also applying this technique Karpukhin et al., 2020;Yan et al., 2021;Giorgi et al., 2021;Gao et al., 2021). For the concern of ODPR, the research lines of contrastive learning can be divided into two types: (i) Improving the sampling strategies for positive samples and hard negative samples. According to (Manmatha et al., 2017), the quality of positive samples and negative samples are of vital importance in the contrastive learning framework. Therefore, many researchers seek better sampling strategies to improve the retrieval performance (Xiong et al., 2020). (ii) Improving the contrastive learning framework. DensePhrase (Lee et al., 2021) uses memory bank like MOCO (He et al., 2020) to increase the number of in-batch negative samples without increasing the GPU memory usage, and models retrieval process on the phrase level but not passage level, achieving impressive performance.",
        "gpt_label": "Lacks synthesis",
        "reason": "This paragraph primarily lists prior work and categorizes research lines without articulating the authors' perspective, motivation, or an explicit gap. The connection to their own approach appears only in the following paragraph, leaving this span as descriptive rather than synthesized with the paper’s argument.",
        "start": 2155,
        "end": 3230
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "Open-Domain Passage Retrieval has been a hot research topic in recent years.",
          "gpt_label": "Unsupported Claim",
          "reason": "General claim about the prominence of the topic in recent years lacks supporting citations.",
          "start": 44,
          "end": 119
        },
        {
          "span_text": "Although these lexical approaches meet the requirement of low latency, they fail to capture non-lexical semantic similarity, thus performing unsatisfying on retrieval accuracy.",
          "gpt_label": "Unsupported Claim",
          "reason": "Evaluative claim about the retrieval accuracy of lexical methods requires citation or evidence.",
          "start": 531,
          "end": 706
        },
        {
          "span_text": "Although enjoying satisfying retrieval accuracy, the retrieval latency is often hard to tolerate in practical use.",
          "gpt_label": "Unsupported Claim",
          "reason": "Claim about cross-encoders’ latency in practice needs supporting references or empirical evidence.",
          "start": 912,
          "end": 1025
        },
        {
          "span_text": "More recently, the Bi-Encoder structure has captured the researchers' attention.",
          "gpt_label": "Unsupported Claim",
          "reason": "Reference to recent work or growing attention should be supported by citations.",
          "start": 1026,
          "end": 1105
        },
        {
          "span_text": "first proposes to pretrain the Bi-Encoder with Inverse Cloze Task (ICT).",
          "gpt_label": "Unsupported Claim",
          "reason": "Mentions a prior proposal without attributing it to a specific work; missing citation at first mention.",
          "start": 1259,
          "end": 1330
        },
        {
          "span_text": "Contrastive learning recently is attracting researchers' attention in all area.",
          "gpt_label": "Unsupported Claim",
          "reason": "Broad ‘recent works’ claim across areas is uncited and should be supported by references.",
          "start": 2176,
          "end": 2254
        }
      ],
      "Format": [
        {
          "span_text": "He et al., 2020)",
          "gpt_label": "Format",
          "reason": "Missing opening parenthesis for a parenthetical citation; unmatched closing bracket.",
          "start": 2313,
          "end": 2328
        },
        {
          "span_text": "(Manmatha et al., 2017)",
          "gpt_label": "Format",
          "reason": "Used directly after 'According to', which is the wrong citation style here; should be integrated as 'Manmatha et al. (2017)'.",
          "start": 2653,
          "end": 2675
        },
        {
          "span_text": "( 2019)",
          "gpt_label": "Format",
          "reason": "Extraneous space after the opening parenthesis in the year-only citation.",
          "start": 3547,
          "end": 3554
        }
      ],
      "Coherence": [
        {
          "span_text": "With Bi-Encoder, the representations of the corpus at scale can be precomputed, enabling it to meet the requirement of low latency in passage retrieval.  first proposes to pretrain the Bi-Encoder with Inverse Cloze Task (ICT). Later, DPR (Karpukhin et al., 2020) introduces a contrastive learning framework to train dense passage representation, and has achieved impressive performance on both retrieval accuracy and latency.",
          "gpt_label": "Coherence",
          "reason": "The connection between the sentences is abrupt and unclear: the middle sentence lacks a subject/citation (\"first proposes\"), making it unclear which prior work is being referenced and how it relates to the surrounding discussion. The transition from ICT pretraining to DPR’s contrastive learning is implied but not explicitly explained, weakening the coherence across these multiple sentences.",
          "start": 1106,
          "end": 1527
        }
      ],
      "Lacks synthesis": [
        {
          "span_text": "Contrastive Learning Contrastive learning recently is attracting researchers' attention in all area. After witnessing its superiority in Computer Vision tasks He et al., 2020), researchers in NLP are also applying this technique Karpukhin et al., 2020;Yan et al., 2021;Giorgi et al., 2021;Gao et al., 2021). For the concern of ODPR, the research lines of contrastive learning can be divided into two types: (i) Improving the sampling strategies for positive samples and hard negative samples. According to (Manmatha et al., 2017), the quality of positive samples and negative samples are of vital importance in the contrastive learning framework. Therefore, many researchers seek better sampling strategies to improve the retrieval performance (Xiong et al., 2020). (ii) Improving the contrastive learning framework. DensePhrase (Lee et al., 2021) uses memory bank like MOCO (He et al., 2020) to increase the number of in-batch negative samples without increasing the GPU memory usage, and models retrieval process on the phrase level but not passage level, achieving impressive performance.",
          "gpt_label": "Lacks synthesis",
          "reason": "This paragraph primarily lists prior work and categorizes research lines without articulating the authors' perspective, motivation, or an explicit gap. The connection to their own approach appears only in the following paragraph, leaving this span as descriptive rather than synthesized with the paper’s argument.",
          "start": 2155,
          "end": 3230
        }
      ]
    }
  },
  "paper_66.txt": {
    "filename": "paper_66.txt",
    "full_text": "Introduction\n\nGeneral-purpose pretrained vision and language (V&L) models have gained notable performance on many V&L tasks (Lu et al., 2019;Tan and Bansal, 2019;Li et al., 2019;Li et al., 2020a;Su et al., 2020). As a result, V&L research has changed its focus from task-specific architectures to fine-tuning large V&L models.\n\nCurrent benchmarks give a good perspective on model performance on a wide range of V&L tasks Lourie et al., 2021;Li et al., 2021), but the field is only starting to assess why models perform so well and whether models learn specific capabilities that span multiple V&L tasks. Specifically, we lack detailed understanding of the extent to which such models are able to ground linguistic phenomena-from morphosyntax to semantics-in the visual modality (Bernardi and Pezzelle, 2021). For example, recent evidence suggests that models are insensitive to linguistic distinctions of verb-argument structure (Hendricks and Nematzadeh, 2021) and word order (Cirik et al., 2018;Akula et al., 2020).\n\nOur work addresses this gap with VALSE (Vision And Language Structured Evaluation), a benchmark for V&L model evaluation comprising six tasks, or 'pieces', where each piece has the same structure: given a visual input, a model is asked to distinguish real captions from foils, where a foil is constructed from a caption by altering a word or phrase that realizes a specific linguistic phenomenon, e.g., semantic number of nouns, verb argument structure, or coreference. VALSE uses a resource-lean diagnostic setup that dispenses with large-scale annotation (e.g., of bounding boxes), and builds on existing high-quality image captioning and VQA data. VALSE is designed to leverage the existing prediction heads in pretrained (or finetuned) V&L models; for that reason, our benchmark does not include any re-training and can be interpreted as a zero-shot evaluation. We build test data for each piece so as to safeguard against the possibility of models exploiting artefacts or statistical biases in the data, a well-known issue with highly parameterised neural models pretrained on large amounts of data (Goyal et al., 2017;Madhyastha et al., 2018;Kafle et al., 2019). With this in view, we propose novel methods to guard against the emergence of artefacts during foiling.\n\nOur main contributions are: i) We introduce VALSE, a novel benchmark aimed at gauging the sensitivity of pre-trained V&L models to foiled instances. ii) We cover a wide spectrum of basic linguistic phenomena affecting the linguistic and visual modalities: existence, plurality, counting, spatial relations, actions, and entity coreference. iii) We investigate novel strategies to build valid foils that include automatic and human validation. We balance word frequency distributions between captions and foils, and test against pretrained models solving the benchmark unimodally. We employ masked language modeling (MLM) in foil creation and semantic inference for validating foils, and finally collect human annotations for the entire benchmark. iv) We establish initial experimental results for pretrained V&L models of diverse architectures on VALSE. These models' overall weak performance indicates that the time is ripe for a novel, reliable foiling dataset targeting the visual grounding capabilities of V&L models through the lens of linguistic constructs. 1\n\n2 Background and Related work\n\nPretrained V&L models learn to combine vision and language through self-supervised multitask learning. Tasks include multimodal masked modeling-where words in the text and object labels or regions in the image are masked out, then predictedand image-sentence alignment, whereby a model learns to predict whether an image and a text correspond. Major architectures are single-and dualstream multimodal transformers: single-stream models concatenate word and image features, and encode the resulting sequence with a single transformer stack; dual-stream models use distinct transformer stacks to handle visual and textual inputs, and additional layers (e.g. co-attention) to fuse these into multimodal features.\n\nBenchmarking V&L models V&L models (Li et al., 2019;Lu et al., 2019;Tan and Bansal, 2019;Lu et al., 2020;Li et al., 2020b;Kim et al., 2021) are commonly evaluated on V&L tasks such as VQA (Goyal et al., 2017), visual reasoning (Suhr et al., 2019), or image retrieval (Lin et al., 2014;Plummer et al., 2015). Given how well transformer-based models perform across unimodal and multimodal tasks, research efforts have recently started to address what makes them so effective, and to what extent they learn generalisable representations. Techniques to address these questions in unimodal and multimodal V&L contexts include: adversarial examples (Jia and Liang, 2017;Jia et al., 2019); investigation of the impact of bias, be it linguistic (Gururangan et al., 2018), visual semantic (Agarwal et al., 2020), or socio-economic (Garg et al., 2019); and the use of linguistically-informed counterfactual and minimally-edited examples (Levesque et al., 1 We release our dataset containing all annotators' votes (Prabhakaran et al., 2021) and code upon acceptance. 2012; Gardner et al., 2020). A trend within the latter research line that is specific to V&L models is vision-and-language foiling (Shekhar et al., 2017b;Gokhale et al., 2020;Bitton et al., 2021;Parcalabescu et al., 2021;Rosenberg et al., 2021), where the idea is to create counterfactual (i.e., foiled) and/or minimally edited examples by performing data augmentation on captions (Shekhar et al., 2017b,a) or images (Rosenberg et al., 2021).\n\nSince most V&L models are pretrained on some version of the image-text alignment task, it is possible to test their ability to distinguish correct from foiled captions (in relation to an image) in a zeroshot setting. The construction of foils can serve many investigation purposes. With VALSE, we target the linguistic grounding capabilities of V&L models, focusing on pervasive linguistic phenomena that span multiple tokens, described in §3.1- §3.6. At the same time, we ensure that our data is robust to perturbations and artefacts by i) controlling for word frequency biases between captions and foils, and ii) testing against unimodal collapse, a known issue of V&L models (Goyal et al., 2017;Madhyastha et al., 2018), thereby preventing models from solving the task using a single input modality. The issue of neural models exploiting data artefacts is well-known (Gururangan et al., 2018;Jia et al., 2019;Wang et al., 2020b;He et al., 2021) and methods have been proposed to uncover such effects, including gradient-based, adversarial perturbations or input reduction techniques (cf. Wallace et al., 2020). Yet, these methods are still not fully understood (He et al., 2021) and can be unreliable (Wang et al., 2020b).\n\nOur work is related to Gardner et al. (2020), who construct task-specific contrast sets for NLU. However, our focus is on modelling linguistic phenomena instead of tasks, and we construct carefully curated, balanced, single foils from valid instances that we select from multiple multimodal datasets.\n\n ",
    "all_spans": [
      {
        "span_text": "As a result, V&L research has changed its focus from task-specific architectures to fine-tuning large V&L models.",
        "gpt_label": "Unsupported Claim",
        "reason": "Field-level trend statement about a shift in research focus lacks citations to surveys or bibliometric evidence.",
        "start": 208,
        "end": 320
      },
      {
        "span_text": "but the field is only starting to assess why models perform so well and whether models learn specific capabilities that span multiple V&L tasks.",
        "gpt_label": "Unsupported Claim",
        "reason": "Claim about the current state of the field requires supporting references to recent analyses or surveys.",
        "start": 451,
        "end": 594
      },
      {
        "span_text": "Pretrained V&L models learn to combine vision and language through self-supervised multitask learning.",
        "gpt_label": "Unsupported Claim",
        "reason": "Background claim about typical training paradigm in a niche area should be supported with citations to foundational V&L pretraining works.",
        "start": 3359,
        "end": 3460
      },
      {
        "span_text": "Tasks include multimodal masked modeling-where words in the text and object labels or regions in the image are masked out, then predictedand image-sentence alignment, whereby a model learns to predict whether an image and a text correspond.",
        "gpt_label": "Unsupported Claim",
        "reason": "Specific list of common pretraining tasks in V&L needs citations to the works introducing/using these tasks.",
        "start": 3461,
        "end": 3700
      },
      {
        "span_text": "Major architectures are single-and dualstream multimodal transformers: single-stream models concatenate word and image features, and encode the resulting sequence with a single transformer stack; dual-stream models use distinct transformer stacks to handle visual and textual inputs, and additional layers (e.g. co-attention) to fuse these into multimodal features.",
        "gpt_label": "Unsupported Claim",
        "reason": "Niche, specific description of prevalent architectures should be accompanied by citations to representative single- and dual-stream models.",
        "start": 3701,
        "end": 4063
      },
      {
        "span_text": "Since most V&L models are pretrained on some version of the image-text alignment task,",
        "gpt_label": "Unsupported Claim",
        "reason": "Quantified claim about \"most\" models' pretraining requires evidence or citations to surveys or model papers.",
        "start": 5535,
        "end": 5621
      },
      {
        "span_text": "builds on existing high-quality image captioning and VQA data.",
        "gpt_label": "Unsupported Claim",
        "reason": "First mention of datasets (image captioning and VQA) should be cited; the evaluative term \"high-quality\" also implies a claim needing support.",
        "start": 1589,
        "end": 1650
      },
      {
        "span_text": "Levesque et al.,",
        "gpt_label": "Format",
        "reason": "Citation is broken by an inserted footnote, separating the author from the year; improper citation formatting.",
        "start": 4978,
        "end": 4993
      },
      {
        "span_text": "2012; Gardner et al., 2020)",
        "gpt_label": "Format",
        "reason": "Continuation of a broken citation starting with a year without preceding authors due to misplaced footnote; improper citation formatting.",
        "start": 5103,
        "end": 5129
      },
      {
        "span_text": "Shekhar et al., 2017b,a",
        "gpt_label": "Format",
        "reason": "Incorrect year-suffix ordering/style for multiple same-year works; should be formatted as 2017a,b (or as separate citations).",
        "start": 5476,
        "end": 5498
      },
      {
        "span_text": "Techniques to address these questions in unimodal and multimodal V&L contexts include: adversarial examples (Jia and Liang, 2017;Jia et al., 2019); investigation of the impact of bias, be it linguistic (Gururangan et al., 2018), visual semantic (Agarwal et al., 2020), or socio-economic (Garg et al., 2019); and the use of linguistically-informed counterfactual and minimally-edited examples (Levesque et al., 1 We release our dataset containing all annotators' votes (Prabhakaran et al., 2021) and code upon acceptance. 2012; Gardner et al., 2020). A trend within the latter research line that is specific to V&L models is vision-and-language foiling (Shekhar et al., 2017b;Gokhale et al., 2020;Bitton et al., 2021;Parcalabescu et al., 2021;Rosenberg et al., 2021), where the idea is to create counterfactual (i.e., foiled) and/or minimally edited examples by performing data augmentation on captions (Shekhar et al., 2017b,a) or images (Rosenberg et al., 2021).",
        "gpt_label": "Coherence",
        "reason": "An unrelated footnote sentence (“We release our dataset…”) is inserted between citations within the discussion of techniques, breaking the flow between referenced works and creating an abrupt, unexplained transition to the next sentence about a specific trend. The relationship between the footnote and the surrounding cited literature is not stated, reducing coherence across sentences.",
        "start": 4589,
        "end": 5533
      },
      {
        "span_text": "Benchmarking V&L models V&L models (Li et al., 2019;Lu et al., 2019;Tan and Bansal, 2019;Lu et al., 2020;Li et al., 2020b;Kim et al., 2021) are commonly evaluated on V&L tasks such as VQA (Goyal et al., 2017), visual reasoning (Suhr et al., 2019), or image retrieval (Lin et al., 2014;Plummer et al., 2015). Given how well transformer-based models perform across unimodal and multimodal tasks, research efforts have recently started to address what makes them so effective, and to what extent they learn generalisable representations. Techniques to address these questions in unimodal and multimodal V&L contexts include: adversarial examples (Jia and Liang, 2017;Jia et al., 2019); investigation of the impact of bias, be it linguistic (Gururangan et al., 2018), visual semantic (Agarwal et al., 2020), or socio-economic (Garg et al., 2019); and the use of linguistically-informed counterfactual and minimally-edited examples (Levesque et al., 1 We release our dataset containing all annotators' votes (Prabhakaran et al., 2021) and code upon acceptance. 2012; Gardner et al., 2020). A trend within the latter research line that is specific to V&L models is vision-and-language foiling (Shekhar et al., 2017b;Gokhale et al., 2020;Bitton et al., 2021;Parcalabescu et al., 2021;Rosenberg et al., 2021), where the idea is to create counterfactual (i.e., foiled) and/or minimally edited examples by performing data augmentation on captions (Shekhar et al., 2017b,a) or images (Rosenberg et al., 2021).",
        "gpt_label": "Lacks synthesis",
        "reason": "This paragraph catalogs prior evaluations, techniques, and trends with extensive citations but does not explicitly connect them to the authors’ argument or explain how these works motivate or contrast with their approach; the linkage appears only in the following paragraph.",
        "start": 4065,
        "end": 5533
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "As a result, V&L research has changed its focus from task-specific architectures to fine-tuning large V&L models.",
          "gpt_label": "Unsupported Claim",
          "reason": "Field-level trend statement about a shift in research focus lacks citations to surveys or bibliometric evidence.",
          "start": 208,
          "end": 320
        },
        {
          "span_text": "but the field is only starting to assess why models perform so well and whether models learn specific capabilities that span multiple V&L tasks.",
          "gpt_label": "Unsupported Claim",
          "reason": "Claim about the current state of the field requires supporting references to recent analyses or surveys.",
          "start": 451,
          "end": 594
        },
        {
          "span_text": "Pretrained V&L models learn to combine vision and language through self-supervised multitask learning.",
          "gpt_label": "Unsupported Claim",
          "reason": "Background claim about typical training paradigm in a niche area should be supported with citations to foundational V&L pretraining works.",
          "start": 3359,
          "end": 3460
        },
        {
          "span_text": "Tasks include multimodal masked modeling-where words in the text and object labels or regions in the image are masked out, then predictedand image-sentence alignment, whereby a model learns to predict whether an image and a text correspond.",
          "gpt_label": "Unsupported Claim",
          "reason": "Specific list of common pretraining tasks in V&L needs citations to the works introducing/using these tasks.",
          "start": 3461,
          "end": 3700
        },
        {
          "span_text": "Major architectures are single-and dualstream multimodal transformers: single-stream models concatenate word and image features, and encode the resulting sequence with a single transformer stack; dual-stream models use distinct transformer stacks to handle visual and textual inputs, and additional layers (e.g. co-attention) to fuse these into multimodal features.",
          "gpt_label": "Unsupported Claim",
          "reason": "Niche, specific description of prevalent architectures should be accompanied by citations to representative single- and dual-stream models.",
          "start": 3701,
          "end": 4063
        },
        {
          "span_text": "Since most V&L models are pretrained on some version of the image-text alignment task,",
          "gpt_label": "Unsupported Claim",
          "reason": "Quantified claim about \"most\" models' pretraining requires evidence or citations to surveys or model papers.",
          "start": 5535,
          "end": 5621
        },
        {
          "span_text": "builds on existing high-quality image captioning and VQA data.",
          "gpt_label": "Unsupported Claim",
          "reason": "First mention of datasets (image captioning and VQA) should be cited; the evaluative term \"high-quality\" also implies a claim needing support.",
          "start": 1589,
          "end": 1650
        }
      ],
      "Format": [
        {
          "span_text": "Levesque et al.,",
          "gpt_label": "Format",
          "reason": "Citation is broken by an inserted footnote, separating the author from the year; improper citation formatting.",
          "start": 4978,
          "end": 4993
        },
        {
          "span_text": "2012; Gardner et al., 2020)",
          "gpt_label": "Format",
          "reason": "Continuation of a broken citation starting with a year without preceding authors due to misplaced footnote; improper citation formatting.",
          "start": 5103,
          "end": 5129
        },
        {
          "span_text": "Shekhar et al., 2017b,a",
          "gpt_label": "Format",
          "reason": "Incorrect year-suffix ordering/style for multiple same-year works; should be formatted as 2017a,b (or as separate citations).",
          "start": 5476,
          "end": 5498
        }
      ],
      "Coherence": [
        {
          "span_text": "Techniques to address these questions in unimodal and multimodal V&L contexts include: adversarial examples (Jia and Liang, 2017;Jia et al., 2019); investigation of the impact of bias, be it linguistic (Gururangan et al., 2018), visual semantic (Agarwal et al., 2020), or socio-economic (Garg et al., 2019); and the use of linguistically-informed counterfactual and minimally-edited examples (Levesque et al., 1 We release our dataset containing all annotators' votes (Prabhakaran et al., 2021) and code upon acceptance. 2012; Gardner et al., 2020). A trend within the latter research line that is specific to V&L models is vision-and-language foiling (Shekhar et al., 2017b;Gokhale et al., 2020;Bitton et al., 2021;Parcalabescu et al., 2021;Rosenberg et al., 2021), where the idea is to create counterfactual (i.e., foiled) and/or minimally edited examples by performing data augmentation on captions (Shekhar et al., 2017b,a) or images (Rosenberg et al., 2021).",
          "gpt_label": "Coherence",
          "reason": "An unrelated footnote sentence (“We release our dataset…”) is inserted between citations within the discussion of techniques, breaking the flow between referenced works and creating an abrupt, unexplained transition to the next sentence about a specific trend. The relationship between the footnote and the surrounding cited literature is not stated, reducing coherence across sentences.",
          "start": 4589,
          "end": 5533
        }
      ],
      "Lacks synthesis": [
        {
          "span_text": "Benchmarking V&L models V&L models (Li et al., 2019;Lu et al., 2019;Tan and Bansal, 2019;Lu et al., 2020;Li et al., 2020b;Kim et al., 2021) are commonly evaluated on V&L tasks such as VQA (Goyal et al., 2017), visual reasoning (Suhr et al., 2019), or image retrieval (Lin et al., 2014;Plummer et al., 2015). Given how well transformer-based models perform across unimodal and multimodal tasks, research efforts have recently started to address what makes them so effective, and to what extent they learn generalisable representations. Techniques to address these questions in unimodal and multimodal V&L contexts include: adversarial examples (Jia and Liang, 2017;Jia et al., 2019); investigation of the impact of bias, be it linguistic (Gururangan et al., 2018), visual semantic (Agarwal et al., 2020), or socio-economic (Garg et al., 2019); and the use of linguistically-informed counterfactual and minimally-edited examples (Levesque et al., 1 We release our dataset containing all annotators' votes (Prabhakaran et al., 2021) and code upon acceptance. 2012; Gardner et al., 2020). A trend within the latter research line that is specific to V&L models is vision-and-language foiling (Shekhar et al., 2017b;Gokhale et al., 2020;Bitton et al., 2021;Parcalabescu et al., 2021;Rosenberg et al., 2021), where the idea is to create counterfactual (i.e., foiled) and/or minimally edited examples by performing data augmentation on captions (Shekhar et al., 2017b,a) or images (Rosenberg et al., 2021).",
          "gpt_label": "Lacks synthesis",
          "reason": "This paragraph catalogs prior evaluations, techniques, and trends with extensive citations but does not explicitly connect them to the authors’ argument or explain how these works motivate or contrast with their approach; the linkage appears only in the following paragraph.",
          "start": 4065,
          "end": 5533
        }
      ]
    }
  },
  "paper_67.txt": {
    "filename": "paper_67.txt",
    "full_text": "Related Work\n\nThe standard practice of using BERT is fine-tuning, i.e. the entirety of the model parameters is adjusted on the training corpus of the downstream task, so that the model is adapted to that specific task (Devlin et al., 2019). There is also an alternative feature-based approach, used by ELMo (Peters et al., 2018). In the latter approach, the pre-trained model is regarded as a feature extractor with frozen parameters. During the learning of a downstream task, one feeds a fixed or learnable combination of the model's intermediate representations as input to the task-specific module, and only the parameters of the latter will be updated. It has been shown that the fine-tuning approach is generally superior to the feature-based approach for BERT in terms of task performance (Devlin et al., 2019;Peters et al., 2019).\n\nA natural middle ground between these two approaches is partial fine-tuning, i.e. only fine-tuning some topmost layers of BERT while keeping the remaining bottom layers frozen. This approach has been studied in (Houlsby et al., 2019;Merchant et al., 2020), where the authors observed that finetuning only the top layers can almost achieve the performance of full fine-tuning on several GLUE tasks. The approach of partial fine-tuning essentially regards the bottom layers of BERT as a feature extractor. Freezing weights from bottom layers is a sensible idea as previous studies show that the mid layer representations produced by BERT are most transferrable, whereas the top layers representations are more task-oriented (Wang et al., 2019;Tenney et al., 2019b,a;Merchant et al., 2020).\n\n ",
    "all_spans": [
      {
        "span_text": "several GLUE tasks",
        "gpt_label": "Unsupported Claim",
        "reason": "Mentions the GLUE benchmark without citing it at first mention; datasets/benchmarks should be cited when first introduced (e.g., GLUE should be referenced with its original paper).",
        "start": 1201,
        "end": 1219
      },
      {
        "span_text": "There is also an alternative feature-based approach, used by ELMo (Peters et al., 2018). In the latter approach, the pre-trained model is regarded as a feature extractor with frozen parameters. During the learning of a downstream task, one feeds a fixed or learnable combination of the model's intermediate representations as input to the task-specific module, and only the parameters of the latter will be updated. It has been shown that the fine-tuning approach is generally superior to the feature-based approach for BERT in terms of task performance (Devlin et al., 2019;Peters et al., 2019).",
        "gpt_label": "Coherence",
        "reason": "The passage shifts from describing ELMo’s feature-based approach to a claim about BERT fine-tuning outperforming a feature-based approach without explicitly connecting how feature-based BERT is instantiated. The relationship between the cited works (ELMo vs. BERT feature-based) is implied, not stated, creating an abrupt cross-sentence transition.",
        "start": 237,
        "end": 826
      },
      {
        "span_text": "A natural middle ground between these two approaches is partial fine-tuning, i.e. only fine-tuning some topmost layers of BERT while keeping the remaining bottom layers frozen. This approach has been studied in (Houlsby et al., 2019;Merchant et al., 2020), where the authors observed that finetuning only the top layers can almost achieve the performance of full fine-tuning on several GLUE tasks. The approach of partial fine-tuning essentially regards the bottom layers of BERT as a feature extractor. Freezing weights from bottom layers is a sensible idea as previous studies show that the mid layer representations produced by BERT are most transferrable, whereas the top layers representations are more task-oriented (Wang et al., 2019;Tenney et al., 2019b,a;Merchant et al., 2020).",
        "gpt_label": "Lacks synthesis",
        "reason": "This paragraph compiles prior findings on partial fine-tuning without linking them to the authors’ own research, perspective, or an explicit gap; it summarizes citations but does not articulate how this background motivates or connects to the present work.",
        "start": 828,
        "end": 1604
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "several GLUE tasks",
          "gpt_label": "Unsupported Claim",
          "reason": "Mentions the GLUE benchmark without citing it at first mention; datasets/benchmarks should be cited when first introduced (e.g., GLUE should be referenced with its original paper).",
          "start": 1201,
          "end": 1219
        }
      ],
      "Format": [],
      "Coherence": [
        {
          "span_text": "There is also an alternative feature-based approach, used by ELMo (Peters et al., 2018). In the latter approach, the pre-trained model is regarded as a feature extractor with frozen parameters. During the learning of a downstream task, one feeds a fixed or learnable combination of the model's intermediate representations as input to the task-specific module, and only the parameters of the latter will be updated. It has been shown that the fine-tuning approach is generally superior to the feature-based approach for BERT in terms of task performance (Devlin et al., 2019;Peters et al., 2019).",
          "gpt_label": "Coherence",
          "reason": "The passage shifts from describing ELMo’s feature-based approach to a claim about BERT fine-tuning outperforming a feature-based approach without explicitly connecting how feature-based BERT is instantiated. The relationship between the cited works (ELMo vs. BERT feature-based) is implied, not stated, creating an abrupt cross-sentence transition.",
          "start": 237,
          "end": 826
        }
      ],
      "Lacks synthesis": [
        {
          "span_text": "A natural middle ground between these two approaches is partial fine-tuning, i.e. only fine-tuning some topmost layers of BERT while keeping the remaining bottom layers frozen. This approach has been studied in (Houlsby et al., 2019;Merchant et al., 2020), where the authors observed that finetuning only the top layers can almost achieve the performance of full fine-tuning on several GLUE tasks. The approach of partial fine-tuning essentially regards the bottom layers of BERT as a feature extractor. Freezing weights from bottom layers is a sensible idea as previous studies show that the mid layer representations produced by BERT are most transferrable, whereas the top layers representations are more task-oriented (Wang et al., 2019;Tenney et al., 2019b,a;Merchant et al., 2020).",
          "gpt_label": "Lacks synthesis",
          "reason": "This paragraph compiles prior findings on partial fine-tuning without linking them to the authors’ own research, perspective, or an explicit gap; it summarizes citations but does not articulate how this background motivates or connects to the present work.",
          "start": 828,
          "end": 1604
        }
      ]
    }
  },
  "paper_68.txt": {
    "filename": "paper_68.txt",
    "full_text": "Introduction\n\nLaw is a field of human endeavor dominated by the use of language. As part of their professional training, law students consume large bodies of text as they seek to tune their understanding of the law and its application to help manage human behavior. Virtually every modern legal system produces massive volumes of textual data (Katz et al., 2020). Lawyers, judges, and regulators continuously author legal documents such as briefs, memos, statutes, regulations, contracts, patents and judicial decisions (Coupette et al., 2021). Beyond the consumption and production of language, law and the art of lawyering is also an exercise centered around the analysis and interpretation of text.\n\nNatural language understanding (NLU) technologies can assist legal practitioners in a variety of legal tasks (Chalkidis and Kampas, 2018;Aletras et al., 2019Aletras et al., , 2020Zhong et al., 2020b;   (Aletras et al., 2016;Sim et al., 2016;Katz et al., 2017;Zhong et al., 2018;Chalkidis et al., 2019a;Malik et al., 2021), information extraction from legal documents (Chalkidis et al., , 2019cChen et al., 2020;Hendrycks et al., 2021) and case summarization (Bhattacharya et al., 2019) to legal question answering (Ravichander et al., 2019;Kien et al., 2020;Zhong et al., 2020a,c) and text classification (Nallapati and Manning, 2008;Chalkidis et al., 2019bChalkidis et al., , 2020a. Transformer models (Vaswani et al., 2017) pre-trained on legal, rather than generic, corpora have also been studied (Chalkidis et al., 2020b;Zheng et al., 2021;.\n\nPre-trained Transformers, including BERT (Devlin et al., 2019), GPT-3 (Brown et al., 2020), T5 (Raffel et al., 2020), BART (Lewis et al., 2020), DeBERTa (He et al., 2021) and numerous variants, are currently the state of the art in most natural language processing (NLP) tasks. Rapid performance improvements have been witnessed, to the extent that ambitious multi-task benchmarks (Wang et al., 2018(Wang et al., , 2019b are considered almost 'solved' a few years after their release and need to be made more challenging (Wang et al., 2019a). Recently, Bommasani et al. (2021) named these pre-trained models (e.g., BERT, DALL-E, GPT-3) foundation models. The term may be controversial, but it emphasizes the paradigm shift these models have caused and their interdisciplinary potential. Studying the latter includes the question of how to adapt these models to legal text . As discussed by Zhong et al. (2020b) and Chalkidis et al. (2020b), legal text has distinct characteristics, such as terms that are uncommon in generic corpora (e.g., 'restrictive covenant', 'promissory estoppel', 'tort', 'novation'), terms that have different senses than in everyday language (e.g., an 'executed' contract is signed and effective, a 'party' is a legal entity), older expressions (e.g., pronominal adverbs like 'herein', 'hereto', 'wherefore'), uncommon expressions from other languages (e.g., 'laches', 'voir dire', 'certiorari', 'sub judice'), and long sentences with unusual word order (e.g., \"the provisions for termination hereinafter appearing or will at the cost of the borrower forthwith comply with the same\") to the extent that legal language is often classified as a 'sublanguage' (Tiersma, 1999;Williams, 2007;Haigh, 2018). Furthermore, legal documents are often much longer than the maximum length state-ofthe-art deep learning models can handle, including those designed to handle long text (Beltagy et al., 2020;Zaheer et al., 2020;Yang et al., 2020).\n\nInspired by the recent widespread use of the GLUE multi-task benchmark NLP dataset (Wang et al., 2018(Wang et al., , 2019b, the subsequent more difficult SuperGLUE (Wang et al., 2019a), other previous multi-task NLP benchmarks (Conneau and Kiela, 2018;McCann et al., 2018), and similar initiatives in other domains (Peng et al., 2019), we introduce LexGLUE, a benchmark dataset to evaluate the performance of NLP methods in legal tasks. LexGLUE is based on seven English existing legal NLP datasets, selected using criteria largely from SuperGLUE (discussed in Section 3.1).\n\nWe anticipate that more datasets, tasks, and languages will be added in later versions of LexGLUE. 1 As more legal NLP datasets become available, we also plan to favor datasets checked thoroughly for validity (scores reflecting real-life performance), annotation quality, statistical power, and social bias (Bowman and Dahl, 2021).\n\nAs in GLUE and SuperGLUE (Wang et al., 2019b,a), one of our goals is to push towards generic (or 'foundation') models that can cope with multiple NLP tasks, in our case legal NLP tasks, possibly with limited task-specific fine-tuning. Another goal is to provide a convenient and informative entry point for NLP researchers and practitioners wishing to explore or develop methods for legal NLP. Having these goals in mind, the datasets we include in LexGLUE and the tasks they address have been simplified in several ways, discussed below, to make it easier for newcomers and generic models to address all tasks. We provide Python APIs integrated with Hugging Face (Wolf et al., 2020;Lhoest et al., 2021) to easily import all the datasets we experiment with and evaluate the performance of different models (Section 5.3). By unifying and facilitating the access to a set of law-related datasets and tasks, we hope to attract not only more NLP experts, but also more interdisciplinary researchers (e.g., law doctoral students willing to take NLP courses). More broadly, we hope LexGLUE will speed up the adoption and transparent evaluation of new legal NLP methods and approaches in the commercial sector too. Indeed, there have been many commercial press releases in the legal-tech industry on high-performing systems, but almost no independent evaluation of the performance of machine learning and NLPbased tools. A standard publicly available benchmark would also allay concerns of undue influence in predictive models, including the use of metadata which the relevant law expressly disregards.\n\n ",
    "all_spans": [
      {
        "span_text": "Pre-trained Transformers, including BERT (Devlin et al., 2019), GPT-3 (Brown et al., 2020), T5 (Raffel et al., 2020), BART (Lewis et al., 2020), DeBERTa (He et al., 2021) and numerous variants, are currently the state of the art in most natural language processing (NLP) tasks.",
        "gpt_label": "Unsupported Claim",
        "reason": "This broad SOTA assertion across most NLP tasks lacks supporting citations to evaluations, leaderboards, or survey papers; citing model introductions does not evidence widespread SOTA performance.",
        "start": 1520,
        "end": 1791
      },
      {
        "span_text": "(Wang et al., 2018(Wang et al., , 2019b",
        "gpt_label": "Format",
        "reason": "Nested parenthesis and missing separators within a single citation; also lacks a closing parenthesis.",
        "start": 1895,
        "end": 1932
      },
      {
        "span_text": "Rapid performance improvements have been witnessed, to the extent that ambitious multi-task benchmarks (Wang et al., 2018(Wang et al., , 2019b are considered almost 'solved' a few years after their release and need to be made more challenging (Wang et al., 2019a). Recently, Bommasani et al. (2021) named these pre-trained models (e.g., BERT, DALL-E, GPT-3) foundation models.",
        "gpt_label": "Coherence",
        "reason": "The transition between the sentence about benchmarks being nearly solved and the sentence about naming foundation models is abrupt and lacks an explicit connection. The relationship between the cited works is implied rather than clearly articulated, creating a multi-sentence coherence issue.",
        "start": 1792,
        "end": 2160
      },
      {
        "span_text": "Natural language understanding (NLU) technologies can assist legal practitioners in a variety of legal tasks (Chalkidis and Kampas, 2018;Aletras et al., 2019Aletras et al., , 2020Zhong et al., 2020b;   (Aletras et al., 2016;Sim et al., 2016;Katz et al., 2017;Zhong et al., 2018;Chalkidis et al., 2019a;Malik et al., 2021), information extraction from legal documents (Chalkidis et al., , 2019cChen et al., 2020;Hendrycks et al., 2021) and case summarization (Bhattacharya et al., 2019) to legal question answering (Ravichander et al., 2019;Kien et al., 2020;Zhong et al., 2020a,c) and text classification (Nallapati and Manning, 2008;Chalkidis et al., 2019bChalkidis et al., , 2020a. Transformer models (Vaswani et al., 2017) pre-trained on legal, rather than generic, corpora have also been studied (Chalkidis et al., 2020b;Zheng et al., 2021;.",
        "gpt_label": "Lacks synthesis",
        "reason": "This passage lists tasks and citations without explaining how they inform the paper’s aims or the need for the proposed work, offering no explicit link to the authors’ contribution or a specific gap.",
        "start": 696,
        "end": 1518
      },
      {
        "span_text": "Inspired by the recent widespread use of the GLUE multi-task benchmark NLP dataset (Wang et al., 2018(Wang et al., , 2019b, the subsequent more difficult SuperGLUE (Wang et al., 2019a), other previous multi-task NLP benchmarks (Conneau and Kiela, 2018;McCann et al., 2018), and similar initiatives in other domains (Peng et al., 2019), we introduce LexGLUE, a benchmark dataset to evaluate the performance of NLP methods in legal tasks. LexGLUE is based on seven English existing legal NLP datasets, selected using criteria largely from SuperGLUE (discussed in Section 3.1).",
        "gpt_label": "Lacks synthesis",
        "reason": "The contribution is stated immediately after citing prior benchmarks without explicitly articulating the gap in legal NLP (e.g., lack of a unified benchmark) that motivates LexGLUE.",
        "start": 3445,
        "end": 4011
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "Pre-trained Transformers, including BERT (Devlin et al., 2019), GPT-3 (Brown et al., 2020), T5 (Raffel et al., 2020), BART (Lewis et al., 2020), DeBERTa (He et al., 2021) and numerous variants, are currently the state of the art in most natural language processing (NLP) tasks.",
          "gpt_label": "Unsupported Claim",
          "reason": "This broad SOTA assertion across most NLP tasks lacks supporting citations to evaluations, leaderboards, or survey papers; citing model introductions does not evidence widespread SOTA performance.",
          "start": 1520,
          "end": 1791
        }
      ],
      "Format": [
        {
          "span_text": "(Wang et al., 2018(Wang et al., , 2019b",
          "gpt_label": "Format",
          "reason": "Nested parenthesis and missing separators within a single citation; also lacks a closing parenthesis.",
          "start": 1895,
          "end": 1932
        }
      ],
      "Coherence": [
        {
          "span_text": "Rapid performance improvements have been witnessed, to the extent that ambitious multi-task benchmarks (Wang et al., 2018(Wang et al., , 2019b are considered almost 'solved' a few years after their release and need to be made more challenging (Wang et al., 2019a). Recently, Bommasani et al. (2021) named these pre-trained models (e.g., BERT, DALL-E, GPT-3) foundation models.",
          "gpt_label": "Coherence",
          "reason": "The transition between the sentence about benchmarks being nearly solved and the sentence about naming foundation models is abrupt and lacks an explicit connection. The relationship between the cited works is implied rather than clearly articulated, creating a multi-sentence coherence issue.",
          "start": 1792,
          "end": 2160
        }
      ],
      "Lacks synthesis": [
        {
          "span_text": "Natural language understanding (NLU) technologies can assist legal practitioners in a variety of legal tasks (Chalkidis and Kampas, 2018;Aletras et al., 2019Aletras et al., , 2020Zhong et al., 2020b;   (Aletras et al., 2016;Sim et al., 2016;Katz et al., 2017;Zhong et al., 2018;Chalkidis et al., 2019a;Malik et al., 2021), information extraction from legal documents (Chalkidis et al., , 2019cChen et al., 2020;Hendrycks et al., 2021) and case summarization (Bhattacharya et al., 2019) to legal question answering (Ravichander et al., 2019;Kien et al., 2020;Zhong et al., 2020a,c) and text classification (Nallapati and Manning, 2008;Chalkidis et al., 2019bChalkidis et al., , 2020a. Transformer models (Vaswani et al., 2017) pre-trained on legal, rather than generic, corpora have also been studied (Chalkidis et al., 2020b;Zheng et al., 2021;.",
          "gpt_label": "Lacks synthesis",
          "reason": "This passage lists tasks and citations without explaining how they inform the paper’s aims or the need for the proposed work, offering no explicit link to the authors’ contribution or a specific gap.",
          "start": 696,
          "end": 1518
        },
        {
          "span_text": "Inspired by the recent widespread use of the GLUE multi-task benchmark NLP dataset (Wang et al., 2018(Wang et al., , 2019b, the subsequent more difficult SuperGLUE (Wang et al., 2019a), other previous multi-task NLP benchmarks (Conneau and Kiela, 2018;McCann et al., 2018), and similar initiatives in other domains (Peng et al., 2019), we introduce LexGLUE, a benchmark dataset to evaluate the performance of NLP methods in legal tasks. LexGLUE is based on seven English existing legal NLP datasets, selected using criteria largely from SuperGLUE (discussed in Section 3.1).",
          "gpt_label": "Lacks synthesis",
          "reason": "The contribution is stated immediately after citing prior benchmarks without explicitly articulating the gap in legal NLP (e.g., lack of a unified benchmark) that motivates LexGLUE.",
          "start": 3445,
          "end": 4011
        }
      ]
    }
  },
  "paper_69.txt": {
    "filename": "paper_69.txt",
    "full_text": "Related work\n\nUncertainty estimation in deep learning is a topic that has been studied extensively. Bayesian deep learning includes a family of methods that attempt to capture the notion of uncertainty in deep neural networks. Such methods have gained increased popularity in the deep learning literature and there exist multiple applications in subfields such as Computer Vision (Kendall and Gal, 2017;Litjens et al., 2017; and Natural Language Processing (NLP) (Siddhant and Lipton, 2020;Lyu et al., 2020;.\n\nDespite their obvious advantage of modeling uncertainty, the main problem with Bayesian deep learning methods is the computational cost of full Bayesian inference. To tackle this problem, Gal and Ghahramani (2016) propose using standard dropout (Srivastava et al., 2014) as a practical approximation of Bayesian inference in deep neural networks and call this method Monte Carlo dropout.  use a convolutional neural network with Monte Carlo dropout in order to obtain an uncertainty estimate for active learning in the task of image classification. Houlsby et al. (2011) sample many networks with Monte Carlo simulation and propose an objective function that takes into account the disagreement and confidence of the predictions coming from these networks.\n\nSimilar methods have also been applied to NLP. In machine translation,  extend the Transformer architecture with MC dropout to get a Variational Transformer, and use it to sample multiple translations from the approximate posterior distribution. They also introduce BLEUVar, an uncertainty metric based on the BLEU score (Papineni et al., 2002) between pairs of the generated translations. Lyu et al. (2020) extend the work of  to question answering and propose an active learning approach based on a modified BLEUVar version. Similarly,  use a conditional random field to obtain uncertainty estimates for active learning and apply their method to named entity recognition.\n\nAlthough summarization is a prominent NLP task, summarization uncertainty has not been widely studied.  is the only work that focuses on uncertainty for summarization, but their work does not make use of Bayesian methods. They define a generated summary's uncertainty based on the entropy of each token generated by the model during the decoding phase. Their study includes experiments on CNN/DM and XSum using the PEGASUS and BART summarization models. Their main focus is on understanding different properties of uncertainty during the decoding phase, and their work is not directly comparable to ours.\n\n ",
    "all_spans": [
      {
        "span_text": "Uncertainty estimation in deep learning is a topic that has been studied extensively.",
        "gpt_label": "Unsupported Claim",
        "reason": "Broad claim about the extent of prior work without supporting citations.",
        "start": 14,
        "end": 98
      },
      {
        "span_text": "Despite their obvious advantage of modeling uncertainty, the main problem with Bayesian deep learning methods is the computational cost of full Bayesian inference.",
        "gpt_label": "Unsupported Claim",
        "reason": "Characterizes a primary limitation of a research area without citation.",
        "start": 505,
        "end": 667
      },
      {
        "span_text": " use a convolutional neural network with Monte Carlo dropout in order to obtain an uncertainty estimate for active learning in the task of image classification.",
        "gpt_label": "Unsupported Claim",
        "reason": "Mentions a specific prior study without providing a citation at first mention.",
        "start": 890,
        "end": 1049
      },
      {
        "span_text": "In machine translation,  extend the Transformer architecture with MC dropout to get a Variational Transformer, and use it to sample multiple translations from the approximate posterior distribution.",
        "gpt_label": "Unsupported Claim",
        "reason": "Describes a specific prior work and method but omits the citation to that work.",
        "start": 1303,
        "end": 1500
      },
      {
        "span_text": "They also introduce BLEUVar, an uncertainty metric based on the BLEU score (Papineni et al., 2002) between pairs of the generated translations.",
        "gpt_label": "Unsupported Claim",
        "reason": "Claims introduction of a new metric without citing the paper that introduced it.",
        "start": 1501,
        "end": 1642
      },
      {
        "span_text": "Lyu et al. (2020) extend the work of  to question answering and propose an active learning approach based on a modified BLEUVar version.",
        "gpt_label": "Unsupported Claim",
        "reason": "References prior work being extended but does not cite that work at first mention.",
        "start": 1643,
        "end": 1777
      },
      {
        "span_text": "Similarly,  use a conditional random field to obtain uncertainty estimates for active learning and apply their method to named entity recognition.",
        "gpt_label": "Unsupported Claim",
        "reason": "Mentions a specific prior study and application without citation at first mention.",
        "start": 1778,
        "end": 1923
      },
      {
        "span_text": "Although summarization is a prominent NLP task, summarization uncertainty has not been widely studied.",
        "gpt_label": "Unsupported Claim",
        "reason": "Claim about the state of the literature lacking supporting citations.",
        "start": 1925,
        "end": 2026
      },
      {
        "span_text": " is the only work that focuses on uncertainty for summarization, but their work does not make use of Bayesian methods.",
        "gpt_label": "Unsupported Claim",
        "reason": "Strong exclusivity claim about prior work without a citation.",
        "start": 2027,
        "end": 2144
      },
      {
        "span_text": "Their study includes experiments on CNN/DM and XSum using the PEGASUS and BART summarization models.",
        "gpt_label": "Unsupported Claim",
        "reason": "Mentions datasets and models (CNN/DM, XSum, PEGASUS, BART) without providing citations at first mention.",
        "start": 2275,
        "end": 2374
      },
      {
        "span_text": " use a convolutional neural network with Monte Carlo dropout in order to obtain an uncertainty estimate for active learning in the task of image classification. Houlsby et al. (2011) sample many networks with Monte Carlo simulation and propose an objective function that takes into account the disagreement and confidence of the predictions coming from these networks.",
        "gpt_label": "Coherence",
        "reason": "The transition between these sentences is abrupt and the relationship between the two cited works is only implied, not explicitly stated (a, b). It is unclear how the Houlsby et al. method connects to the prior CNN with MC dropout example. The issue spans multiple sentences (c).",
        "start": 890,
        "end": 1255
      },
      {
        "span_text": "Despite their obvious advantage of modeling uncertainty, the main problem with Bayesian deep learning methods is the computational cost of full Bayesian inference. To tackle this problem, Gal and Ghahramani (2016) propose using standard dropout (Srivastava et al., 2014) as a practical approximation of Bayesian inference in deep neural networks and call this method Monte Carlo dropout.  use a convolutional neural network with Monte Carlo dropout in order to obtain an uncertainty estimate for active learning in the task of image classification. Houlsby et al. (2011) sample many networks with Monte Carlo simulation and propose an objective function that takes into account the disagreement and confidence of the predictions coming from these networks.\n\nSimilar methods have also been applied to NLP. In machine translation,  extend the Transformer architecture with MC dropout to get a Variational Transformer, and use it to sample multiple translations from the approximate posterior distribution. They also introduce BLEUVar, an uncertainty metric based on the BLEU score (Papineni et al., 2002) between pairs of the generated translations. Lyu et al. (2020) extend the work of  to question answering and propose an active learning approach based on a modified BLEUVar version. Similarly,  use a conditional random field to obtain uncertainty estimates for active learning and apply their method to named entity recognition.",
        "gpt_label": "Lacks synthesis",
        "reason": "This section largely catalogs prior methods and applications without connecting them to the authors’ own aims, perspective, or contribution. It does not explicitly state the gap these works leave for the present study or how the current work builds upon, contrasts with, or addresses limitations of the cited approaches.",
        "start": 505,
        "end": 1923
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "Uncertainty estimation in deep learning is a topic that has been studied extensively.",
          "gpt_label": "Unsupported Claim",
          "reason": "Broad claim about the extent of prior work without supporting citations.",
          "start": 14,
          "end": 98
        },
        {
          "span_text": "Despite their obvious advantage of modeling uncertainty, the main problem with Bayesian deep learning methods is the computational cost of full Bayesian inference.",
          "gpt_label": "Unsupported Claim",
          "reason": "Characterizes a primary limitation of a research area without citation.",
          "start": 505,
          "end": 667
        },
        {
          "span_text": " use a convolutional neural network with Monte Carlo dropout in order to obtain an uncertainty estimate for active learning in the task of image classification.",
          "gpt_label": "Unsupported Claim",
          "reason": "Mentions a specific prior study without providing a citation at first mention.",
          "start": 890,
          "end": 1049
        },
        {
          "span_text": "In machine translation,  extend the Transformer architecture with MC dropout to get a Variational Transformer, and use it to sample multiple translations from the approximate posterior distribution.",
          "gpt_label": "Unsupported Claim",
          "reason": "Describes a specific prior work and method but omits the citation to that work.",
          "start": 1303,
          "end": 1500
        },
        {
          "span_text": "They also introduce BLEUVar, an uncertainty metric based on the BLEU score (Papineni et al., 2002) between pairs of the generated translations.",
          "gpt_label": "Unsupported Claim",
          "reason": "Claims introduction of a new metric without citing the paper that introduced it.",
          "start": 1501,
          "end": 1642
        },
        {
          "span_text": "Lyu et al. (2020) extend the work of  to question answering and propose an active learning approach based on a modified BLEUVar version.",
          "gpt_label": "Unsupported Claim",
          "reason": "References prior work being extended but does not cite that work at first mention.",
          "start": 1643,
          "end": 1777
        },
        {
          "span_text": "Similarly,  use a conditional random field to obtain uncertainty estimates for active learning and apply their method to named entity recognition.",
          "gpt_label": "Unsupported Claim",
          "reason": "Mentions a specific prior study and application without citation at first mention.",
          "start": 1778,
          "end": 1923
        },
        {
          "span_text": "Although summarization is a prominent NLP task, summarization uncertainty has not been widely studied.",
          "gpt_label": "Unsupported Claim",
          "reason": "Claim about the state of the literature lacking supporting citations.",
          "start": 1925,
          "end": 2026
        },
        {
          "span_text": " is the only work that focuses on uncertainty for summarization, but their work does not make use of Bayesian methods.",
          "gpt_label": "Unsupported Claim",
          "reason": "Strong exclusivity claim about prior work without a citation.",
          "start": 2027,
          "end": 2144
        },
        {
          "span_text": "Their study includes experiments on CNN/DM and XSum using the PEGASUS and BART summarization models.",
          "gpt_label": "Unsupported Claim",
          "reason": "Mentions datasets and models (CNN/DM, XSum, PEGASUS, BART) without providing citations at first mention.",
          "start": 2275,
          "end": 2374
        }
      ],
      "Format": [],
      "Coherence": [
        {
          "span_text": " use a convolutional neural network with Monte Carlo dropout in order to obtain an uncertainty estimate for active learning in the task of image classification. Houlsby et al. (2011) sample many networks with Monte Carlo simulation and propose an objective function that takes into account the disagreement and confidence of the predictions coming from these networks.",
          "gpt_label": "Coherence",
          "reason": "The transition between these sentences is abrupt and the relationship between the two cited works is only implied, not explicitly stated (a, b). It is unclear how the Houlsby et al. method connects to the prior CNN with MC dropout example. The issue spans multiple sentences (c).",
          "start": 890,
          "end": 1255
        }
      ],
      "Lacks synthesis": [
        {
          "span_text": "Despite their obvious advantage of modeling uncertainty, the main problem with Bayesian deep learning methods is the computational cost of full Bayesian inference. To tackle this problem, Gal and Ghahramani (2016) propose using standard dropout (Srivastava et al., 2014) as a practical approximation of Bayesian inference in deep neural networks and call this method Monte Carlo dropout.  use a convolutional neural network with Monte Carlo dropout in order to obtain an uncertainty estimate for active learning in the task of image classification. Houlsby et al. (2011) sample many networks with Monte Carlo simulation and propose an objective function that takes into account the disagreement and confidence of the predictions coming from these networks.\n\nSimilar methods have also been applied to NLP. In machine translation,  extend the Transformer architecture with MC dropout to get a Variational Transformer, and use it to sample multiple translations from the approximate posterior distribution. They also introduce BLEUVar, an uncertainty metric based on the BLEU score (Papineni et al., 2002) between pairs of the generated translations. Lyu et al. (2020) extend the work of  to question answering and propose an active learning approach based on a modified BLEUVar version. Similarly,  use a conditional random field to obtain uncertainty estimates for active learning and apply their method to named entity recognition.",
          "gpt_label": "Lacks synthesis",
          "reason": "This section largely catalogs prior methods and applications without connecting them to the authors’ own aims, perspective, or contribution. It does not explicitly state the gap these works leave for the present study or how the current work builds upon, contrasts with, or addresses limitations of the cited approaches.",
          "start": 505,
          "end": 1923
        }
      ]
    }
  },
  "paper_70.txt": {
    "filename": "paper_70.txt",
    "full_text": "Introduction\n\nAutomatic Readability Assessment is the task of assigning a reading level for a given text. It is useful in many applications such as selecting age appropriate texts in classrooms (Sheehan et al., 2014), assessment of patient education materials (Sare et al., 2020) and clinical informed consent forms (Perni et al., 2019), measuring the readability of financial disclosures (Loughran and McDonald, 2014), and so on. Contemporary NLP approaches treat it primarily as a classification problem. This approach makes it non-transferable to situations where the reading level scale in the test data doesn't match the one in the training set. Applying learning to rank methods has been seen as a potential solution to this problem in the past. Ranking texts by readability is also useful in a range of application scenarios, from ranking search results based on readability (Kim et al., 2012;Fourney et al., 2018) to controlling the reading level of machine translation output (Agrawal and Carpuat, 2019;Marchisio et al., 2019). However, exploration of ranking methods has not been a prominent direction for ARA research. Further, recent developments in neural ranking approaches haven't been explored for this task yet, to our knowledge.\n\nARA typically relies on the presence of large amounts of data labeled by reading level. Such datasets are not readily available for many languages. Further, although linguistic features are common in ARA research, it is challenging to calculate them for several languages, due to lack of available software support. Though there is a lot of recent interest in neural network based crosslingual transfer learning approaches for various NLP tasks, there hasn't been much research in this direction for ARA yet. In this background, we propose a new neural pairwise ranking model for ARA in this paper, and evaluate its transferability to other datasets and languages.\n\nIn short, we address two research questions:\n\n1. Is neural, pairwise ranking a better approach than classification or regression for ARA, to achieve cross-corpus compatibility?\n\n2. Is zero-shot, cross-lingual transfer possible for ARA models through such a ranking approach?\n\nThe main contributions of this paper are as follows:\n\n1. This paper proposes new neural pairwise ranking model and shows its application to automatic readability assessment.\n\n2. The feasibility of pairwise ranking as a means of achieving cross-corpus compatibility for monolingual (English) ARA is evaluated.\n\n3. Zero shot, neural cross-lingual transfer is assessed for two languages -Spanish and\n\nFrench, based on a model trained on English data. To our knowledge, this is the first such experiment on ARA.\n\n4. We created a new dataset, with parallel, topic controlled texts between English and French.\n\nThe rest of this paper is organized as follows: Section 2 gives an overview of related research. Section 3 describes the proposed neural pairwise ranking model. Section 4 describes our experimental setup and Section 5 discusses the results of our experiments. Section 6 concludes the paper by summarizing our findings and discussing the limitations.\n\n ",
    "all_spans": [
      {
        "span_text": "Contemporary NLP approaches treat it primarily as a classification problem.",
        "gpt_label": "Unsupported Claim",
        "reason": "Claims a general trend in prior work without providing citations.",
        "start": 426,
        "end": 500
      },
      {
        "span_text": "Applying learning to rank methods has been seen as a potential solution to this problem in the past.",
        "gpt_label": "Unsupported Claim",
        "reason": "Refers to prior work/ideas without citing any studies.",
        "start": 644,
        "end": 743
      },
      {
        "span_text": "However, exploration of ranking methods has not been a prominent direction for ARA research.",
        "gpt_label": "Unsupported Claim",
        "reason": "Makes a literature-wide claim about research prominence without evidence or citations.",
        "start": 1025,
        "end": 1116
      },
      {
        "span_text": "Further, recent developments in neural ranking approaches haven't been explored for this task yet, to our knowledge.",
        "gpt_label": "Unsupported Claim",
        "reason": "Asserts a lack of prior work; such novelty/absence claims require supporting citations or systematic evidence.",
        "start": 1117,
        "end": 1232
      },
      {
        "span_text": "ARA typically relies on the presence of large amounts of data labeled by reading level.",
        "gpt_label": "Unsupported Claim",
        "reason": "Generalizes about standard practice in the field without citing supporting sources.",
        "start": 1234,
        "end": 1320
      },
      {
        "span_text": "Such datasets are not readily available for many languages.",
        "gpt_label": "Unsupported Claim",
        "reason": "Asserts dataset scarcity across languages without evidence or references.",
        "start": 1321,
        "end": 1379
      },
      {
        "span_text": "Further, although linguistic features are common in ARA research, it is challenging to calculate them for several languages, due to lack of available software support.",
        "gpt_label": "Unsupported Claim",
        "reason": "Claims both prevalence of linguistic features and tooling limitations without citations.",
        "start": 1380,
        "end": 1546
      },
      {
        "span_text": "Though there is a lot of recent interest in neural network based crosslingual transfer learning approaches for various NLP tasks, there hasn't been much research in this direction for ARA yet.",
        "gpt_label": "Unsupported Claim",
        "reason": "Mentions 'recent interest' and limited ARA research without citing representative works.",
        "start": 1547,
        "end": 1738
      },
      {
        "span_text": "To our knowledge, this is the first such experiment on ARA.",
        "gpt_label": "Unsupported Claim",
        "reason": "Novelty claim about being the first requires substantiation or citations.",
        "start": 2611,
        "end": 2669
      },
      {
        "span_text": "Applying learning to rank methods has been seen as a potential solution to this problem in the past. Ranking texts by readability is also useful in a range of application scenarios, from ranking search results based on readability (Kim et al., 2012;Fourney et al., 2018) to controlling the reading level of machine translation output (Agrawal and Carpuat, 2019;Marchisio et al., 2019). However, exploration of ranking methods has not been a prominent direction for ARA research.",
        "gpt_label": "Coherence",
        "reason": "The transition from proposing learning-to-rank as a solution for cross-corpus incompatibility to listing application scenarios with citations is abrupt and the relationship is only implied. The cited works (search results, MT readability control) are not explicitly connected to the stated ARA problem, creating a loose, unexplained link across sentences.",
        "start": 644,
        "end": 1116
      },
      {
        "span_text": "Ranking texts by readability is also useful in a range of application scenarios, from ranking search results based on readability (Kim et al., 2012;Fourney et al., 2018) to controlling the reading level of machine translation output (Agrawal and Carpuat, 2019;Marchisio et al., 2019).",
        "gpt_label": "Lacks synthesis",
        "reason": "This sentence cites several works as examples but does not connect them to the authors’ specific research questions or proposed method, nor does it articulate how these prior applications reveal a gap that the paper addresses. It functions as a list rather than synthesizing prior work into the paper’s argument.",
        "start": 744,
        "end": 1024
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "Contemporary NLP approaches treat it primarily as a classification problem.",
          "gpt_label": "Unsupported Claim",
          "reason": "Claims a general trend in prior work without providing citations.",
          "start": 426,
          "end": 500
        },
        {
          "span_text": "Applying learning to rank methods has been seen as a potential solution to this problem in the past.",
          "gpt_label": "Unsupported Claim",
          "reason": "Refers to prior work/ideas without citing any studies.",
          "start": 644,
          "end": 743
        },
        {
          "span_text": "However, exploration of ranking methods has not been a prominent direction for ARA research.",
          "gpt_label": "Unsupported Claim",
          "reason": "Makes a literature-wide claim about research prominence without evidence or citations.",
          "start": 1025,
          "end": 1116
        },
        {
          "span_text": "Further, recent developments in neural ranking approaches haven't been explored for this task yet, to our knowledge.",
          "gpt_label": "Unsupported Claim",
          "reason": "Asserts a lack of prior work; such novelty/absence claims require supporting citations or systematic evidence.",
          "start": 1117,
          "end": 1232
        },
        {
          "span_text": "ARA typically relies on the presence of large amounts of data labeled by reading level.",
          "gpt_label": "Unsupported Claim",
          "reason": "Generalizes about standard practice in the field without citing supporting sources.",
          "start": 1234,
          "end": 1320
        },
        {
          "span_text": "Such datasets are not readily available for many languages.",
          "gpt_label": "Unsupported Claim",
          "reason": "Asserts dataset scarcity across languages without evidence or references.",
          "start": 1321,
          "end": 1379
        },
        {
          "span_text": "Further, although linguistic features are common in ARA research, it is challenging to calculate them for several languages, due to lack of available software support.",
          "gpt_label": "Unsupported Claim",
          "reason": "Claims both prevalence of linguistic features and tooling limitations without citations.",
          "start": 1380,
          "end": 1546
        },
        {
          "span_text": "Though there is a lot of recent interest in neural network based crosslingual transfer learning approaches for various NLP tasks, there hasn't been much research in this direction for ARA yet.",
          "gpt_label": "Unsupported Claim",
          "reason": "Mentions 'recent interest' and limited ARA research without citing representative works.",
          "start": 1547,
          "end": 1738
        },
        {
          "span_text": "To our knowledge, this is the first such experiment on ARA.",
          "gpt_label": "Unsupported Claim",
          "reason": "Novelty claim about being the first requires substantiation or citations.",
          "start": 2611,
          "end": 2669
        }
      ],
      "Format": [],
      "Coherence": [
        {
          "span_text": "Applying learning to rank methods has been seen as a potential solution to this problem in the past. Ranking texts by readability is also useful in a range of application scenarios, from ranking search results based on readability (Kim et al., 2012;Fourney et al., 2018) to controlling the reading level of machine translation output (Agrawal and Carpuat, 2019;Marchisio et al., 2019). However, exploration of ranking methods has not been a prominent direction for ARA research.",
          "gpt_label": "Coherence",
          "reason": "The transition from proposing learning-to-rank as a solution for cross-corpus incompatibility to listing application scenarios with citations is abrupt and the relationship is only implied. The cited works (search results, MT readability control) are not explicitly connected to the stated ARA problem, creating a loose, unexplained link across sentences.",
          "start": 644,
          "end": 1116
        }
      ],
      "Lacks synthesis": [
        {
          "span_text": "Ranking texts by readability is also useful in a range of application scenarios, from ranking search results based on readability (Kim et al., 2012;Fourney et al., 2018) to controlling the reading level of machine translation output (Agrawal and Carpuat, 2019;Marchisio et al., 2019).",
          "gpt_label": "Lacks synthesis",
          "reason": "This sentence cites several works as examples but does not connect them to the authors’ specific research questions or proposed method, nor does it articulate how these prior applications reveal a gap that the paper addresses. It functions as a list rather than synthesizing prior work into the paper’s argument.",
          "start": 744,
          "end": 1024
        }
      ]
    }
  },
  "paper_71.txt": {
    "filename": "paper_71.txt",
    "full_text": "Introduction\n\nContextualized embedding algorithms, such as BERT (Devlin et al., 2019), have achieved impressive performance on a wide variety of tasks (Huang et al., 2019;Chan and Fan, 2019;Yoosuf and Yang, 2019). One application of BERT is as a measure of sentence similarity (Zhang et al., 2019;Sellam et al., 2020), based on the assumption that BERT will produce similar representations for the words in two sentences with similar semantics.\n\nWe propose to use paraphrases with alignments between words as a tool for studying how BERT represents words and phrases. Figure 1 shows an example. Critically, when considering an aligned word pair, we can assume the context has a similar impact on both words because we know the phrases are semantically similar. Previously, paraphrases have been used to probe whether compositionality is accurately captured by BERT (Yu and Ettinger, 2020), but we believe they can be used to explore many other questions.\n\nUsing the Paraphrase Database (Pavlick et al., 2015), we explore how consistent contextual representations are when controlling for the semantics of the context. We find that BERT does consistently represent phrases that are paraphrases. Looking at words, BERT effectively handles variation in spelling, but does less well with spelling errors. BERT effectively handles words of varying levels of polysemy, but the representations for synonyms are surprisingly diverse, with a much broader distribution of similarity scores. These findings confirm results from prior work using other methods, while revealing new details.\n\nWe also consider a range of other models' word representations, finding that they have similar patterns to BERT, but with words that are the same and aligned receiving even more consistent representations than from BERT. BERT gives less contextualized representations to paraphrased words than non-paraphrased words, with the exception of punctuation. Finally, we re-evaluate work looking at patterns across BERT's layers and find that when controlling for semantics the later layers actually produce more similar representations (in contrast to previous work).\n\nThese results show that paraphrases are a useful tool for studying representations. By controlling for meaning while presenting interesting surface variations, they provide a unique probe of behavior.\n\n ",
    "all_spans": [
      {
        "span_text": "These findings confirm results from prior work using other methods, while revealing new details.",
        "gpt_label": "Unsupported Claim",
        "reason": "References prior work but provides no citations to support which studies are being confirmed.",
        "start": 1466,
        "end": 1561
      },
      {
        "span_text": "we re-evaluate work looking at patterns across BERT's layers",
        "gpt_label": "Unsupported Claim",
        "reason": "Mentions prior work on patterns across BERT's layers without citing the specific studies.",
        "start": 1922,
        "end": 1982
      },
      {
        "span_text": "(in contrast to previous work)",
        "gpt_label": "Unsupported Claim",
        "reason": "Claims contrast with previous work but does not cite which prior works are being contrasted.",
        "start": 2091,
        "end": 2121
      },
      {
        "span_text": "We also consider a range of other models' word representations, finding that they have similar patterns to BERT, but with words that are the same and aligned receiving even more consistent representations than from BERT. BERT gives less contextualized representations to paraphrased words than non-paraphrased words, with the exception of punctuation.",
        "gpt_label": "Coherence",
        "reason": "The second sentence shifts from comparing other models to BERT to a different comparison within BERT (paraphrased vs non-paraphrased) without an explicit transition or explanation of how it follows from the preceding sentence, making the connection between the statements unclear.",
        "start": 1563,
        "end": 1912
      },
      {
        "span_text": "These findings confirm results from prior work using other methods, while revealing new details.",
        "gpt_label": "Lacks synthesis",
        "reason": "This sentence references prior work in a generic way without specifying which studies or articulating how the current findings relate to them. It lacks explicit connection, comparison, or a clear statement of the gap addressed, resulting in weak synthesis.",
        "start": 1466,
        "end": 1561
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "These findings confirm results from prior work using other methods, while revealing new details.",
          "gpt_label": "Unsupported Claim",
          "reason": "References prior work but provides no citations to support which studies are being confirmed.",
          "start": 1466,
          "end": 1561
        },
        {
          "span_text": "we re-evaluate work looking at patterns across BERT's layers",
          "gpt_label": "Unsupported Claim",
          "reason": "Mentions prior work on patterns across BERT's layers without citing the specific studies.",
          "start": 1922,
          "end": 1982
        },
        {
          "span_text": "(in contrast to previous work)",
          "gpt_label": "Unsupported Claim",
          "reason": "Claims contrast with previous work but does not cite which prior works are being contrasted.",
          "start": 2091,
          "end": 2121
        }
      ],
      "Format": [],
      "Coherence": [
        {
          "span_text": "We also consider a range of other models' word representations, finding that they have similar patterns to BERT, but with words that are the same and aligned receiving even more consistent representations than from BERT. BERT gives less contextualized representations to paraphrased words than non-paraphrased words, with the exception of punctuation.",
          "gpt_label": "Coherence",
          "reason": "The second sentence shifts from comparing other models to BERT to a different comparison within BERT (paraphrased vs non-paraphrased) without an explicit transition or explanation of how it follows from the preceding sentence, making the connection between the statements unclear.",
          "start": 1563,
          "end": 1912
        }
      ],
      "Lacks synthesis": [
        {
          "span_text": "These findings confirm results from prior work using other methods, while revealing new details.",
          "gpt_label": "Lacks synthesis",
          "reason": "This sentence references prior work in a generic way without specifying which studies or articulating how the current findings relate to them. It lacks explicit connection, comparison, or a clear statement of the gap addressed, resulting in weak synthesis.",
          "start": 1466,
          "end": 1561
        }
      ]
    }
  },
  "paper_72.txt": {
    "filename": "paper_72.txt",
    "full_text": "Related Work\n\nSparse attention mechanism The full attention mechanism has a quadratic memory cost. Prior research works have proposed different sparse attention mechanisms to reduce the memory cost. Longformer (Beltagy et al., 2020) uses a dilated sliding window of blocks and global attention patterns. BigBird (Zaheer et al., 2020) employs sliding window and random blocks. Reformer (Kitaev et al., 2020) uses the locality-sensitive hashing. In addition to optimizing the encoder self-attention, Huang et al. (2021) proposes head-wise positional strides to reduce the cost of the encoder-decoder attention. However, sparse attention diminishes the benefits of pretraining and sacrifices parts of the receptive field.\n\nExtract-then-generate method The model first extracts salient text snippets from the input, followed by generating a concise overall summary. Most two-stage summarization approaches (Zhang et al., 2019;Lebanoff et al., 2019;Xu and Durrett, 2019;Bajaj et al., 2021) are trained separately, which suffer from information loss due to the cascaded errors. Some approaches attempt to reduce that loss by bridging the two stages. Chen and Bansal (2018) adopts reinforcement learning with a sentence-level policy gradient method. Bae et al. (2019) proposes summary-level policy gradient. In addition to the drawbacks explained in Section 2.3, our model is different as we jointly train an extractthen-generate model for summarization using latent variables.\n\nDivide-and-conquer approach A common approach in long input summarization is divide-andconquer (Gidiotis and Tsoumakas, 2020;Grail et al., 2021). This approach breaks a long input into multiple parts, which are summarized separately and combined to produce a final complete summary. However, these models do not capture the contextual dependencies across parts and assumes a certain structure of the input (such as paper sections).\n\nHierarchical models Various hierarchical models have been proposed to handle the longer inputs. Cohan et al. (2018) models the document discourse structure with a hierarchical encoder and a discourse-aware decoder to generate the summary. HAT-Bart (Rohde et al., 2021) proposes a new Hierarchical Attention Transformer-based architecture that attempts to capture sentence and paragraphlevel information. HMNet (Zhu et al., 2020) builds a hierarchical structure that includes discourselevel information and speaker roles. However, these models focus mainly on model performance and not on reducing the memory and computational cost.\n\n ",
    "all_spans": [
      {
        "span_text": "The full attention mechanism has a quadratic memory cost.",
        "gpt_label": "Unsupported Claim",
        "reason": "Makes a technical claim about algorithmic complexity without providing a citation or evidence.",
        "start": 41,
        "end": 97
      },
      {
        "span_text": "However, sparse attention diminishes the benefits of pretraining and sacrifices parts of the receptive field.",
        "gpt_label": "Unsupported Claim",
        "reason": "Asserts drawbacks of sparse attention without citing studies or empirical evidence.",
        "start": 599,
        "end": 707
      },
      {
        "span_text": "which suffer from information loss due to the cascaded errors.",
        "gpt_label": "Unsupported Claim",
        "reason": "Claims a specific drawback of two-stage approaches without citation supporting the asserted information loss from cascading.",
        "start": 994,
        "end": 1055
      },
      {
        "span_text": "However, these models do not capture the contextual dependencies across parts and assumes a certain structure of the input (such as paper sections).",
        "gpt_label": "Unsupported Claim",
        "reason": "General claim about limitations of divide-and-conquer models without citations to support the limitation.",
        "start": 1730,
        "end": 1877
      },
      {
        "span_text": "However, these models focus mainly on model performance and not on reducing the memory and computational cost.",
        "gpt_label": "Unsupported Claim",
        "reason": "Broad claim about the focus of prior hierarchical models without providing supporting references.",
        "start": 2393,
        "end": 2502
      },
      {
        "span_text": "BigBird (Zaheer et al., 2020) employs sliding window and random blocks. Reformer (Kitaev et al., 2020) uses the locality-sensitive hashing. In addition to optimizing the encoder self-attention, Huang et al. (2021) proposes head-wise positional strides to reduce the cost of the encoder-decoder attention.",
        "gpt_label": "Coherence",
        "reason": "The transition from Reformer to Huang et al. is abrupt: prior sentences list sparse self-attention patterns, while Huang addresses encoder–decoder attention with positional strides. The relationship between these works is only implied and not explicitly explained, creating unclear linkage across the sentences.",
        "start": 300,
        "end": 598
      },
      {
        "span_text": "Chen and Bansal (2018) adopts reinforcement learning with a sentence-level policy gradient method. Bae et al. (2019) proposes summary-level policy gradient.",
        "gpt_label": "Lacks synthesis",
        "reason": "These sentences list prior approaches without analyzing them, comparing them, or explicitly connecting them to the authors’ motivation or how their method addresses the stated issues.",
        "start": 1127,
        "end": 1280
      },
      {
        "span_text": "Cohan et al. (2018) models the document discourse structure with a hierarchical encoder and a discourse-aware decoder to generate the summary. HAT-Bart (Rohde et al., 2021) proposes a new Hierarchical Attention Transformer-based architecture that attempts to capture sentence and paragraphlevel information. HMNet (Zhu et al., 2020) builds a hierarchical structure that includes discourselevel information and speaker roles.",
        "gpt_label": "Lacks synthesis",
        "reason": "This sequence enumerates individual works with brief descriptions but provides no synthesis or comparison and does not explicitly link these approaches to the authors’ aims or the specific gap their work addresses.",
        "start": 1974,
        "end": 2392
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "The full attention mechanism has a quadratic memory cost.",
          "gpt_label": "Unsupported Claim",
          "reason": "Makes a technical claim about algorithmic complexity without providing a citation or evidence.",
          "start": 41,
          "end": 97
        },
        {
          "span_text": "However, sparse attention diminishes the benefits of pretraining and sacrifices parts of the receptive field.",
          "gpt_label": "Unsupported Claim",
          "reason": "Asserts drawbacks of sparse attention without citing studies or empirical evidence.",
          "start": 599,
          "end": 707
        },
        {
          "span_text": "which suffer from information loss due to the cascaded errors.",
          "gpt_label": "Unsupported Claim",
          "reason": "Claims a specific drawback of two-stage approaches without citation supporting the asserted information loss from cascading.",
          "start": 994,
          "end": 1055
        },
        {
          "span_text": "However, these models do not capture the contextual dependencies across parts and assumes a certain structure of the input (such as paper sections).",
          "gpt_label": "Unsupported Claim",
          "reason": "General claim about limitations of divide-and-conquer models without citations to support the limitation.",
          "start": 1730,
          "end": 1877
        },
        {
          "span_text": "However, these models focus mainly on model performance and not on reducing the memory and computational cost.",
          "gpt_label": "Unsupported Claim",
          "reason": "Broad claim about the focus of prior hierarchical models without providing supporting references.",
          "start": 2393,
          "end": 2502
        }
      ],
      "Format": [],
      "Coherence": [
        {
          "span_text": "BigBird (Zaheer et al., 2020) employs sliding window and random blocks. Reformer (Kitaev et al., 2020) uses the locality-sensitive hashing. In addition to optimizing the encoder self-attention, Huang et al. (2021) proposes head-wise positional strides to reduce the cost of the encoder-decoder attention.",
          "gpt_label": "Coherence",
          "reason": "The transition from Reformer to Huang et al. is abrupt: prior sentences list sparse self-attention patterns, while Huang addresses encoder–decoder attention with positional strides. The relationship between these works is only implied and not explicitly explained, creating unclear linkage across the sentences.",
          "start": 300,
          "end": 598
        }
      ],
      "Lacks synthesis": [
        {
          "span_text": "Chen and Bansal (2018) adopts reinforcement learning with a sentence-level policy gradient method. Bae et al. (2019) proposes summary-level policy gradient.",
          "gpt_label": "Lacks synthesis",
          "reason": "These sentences list prior approaches without analyzing them, comparing them, or explicitly connecting them to the authors’ motivation or how their method addresses the stated issues.",
          "start": 1127,
          "end": 1280
        },
        {
          "span_text": "Cohan et al. (2018) models the document discourse structure with a hierarchical encoder and a discourse-aware decoder to generate the summary. HAT-Bart (Rohde et al., 2021) proposes a new Hierarchical Attention Transformer-based architecture that attempts to capture sentence and paragraphlevel information. HMNet (Zhu et al., 2020) builds a hierarchical structure that includes discourselevel information and speaker roles.",
          "gpt_label": "Lacks synthesis",
          "reason": "This sequence enumerates individual works with brief descriptions but provides no synthesis or comparison and does not explicitly link these approaches to the authors’ aims or the specific gap their work addresses.",
          "start": 1974,
          "end": 2392
        }
      ]
    }
  },
  "paper_73.txt": {
    "filename": "paper_73.txt",
    "full_text": "Introduction\n\nA common research avenue pursued these days is to train monolithic language models with billions of parameters to solve every language understanding and reasoning challenge. In contrast, humans often tackle complex tasks by breaking them down into simpler sub-tasks, and solving these by interacting with other people or automated agents whose skillsets we are familiar with. This approach allows us to learn to solve new complex tasks quickly and effectively, by building upon what's already known. Can AI systems learn to do the same?\n\nTo facilitate research in this direction, we propose a new reasoning challenge and a benchmark called COMMAQA where, in addition to the usual end-task supervision, one has access to a set of predefined AI agents with examples of their natural language inputs. Importantly, the target end-task is designed to be too difficult for current models to learn based only on end-task supervision. The goal is instead to build models that learn to solve the target task by decomposing it into sub-tasks solvable by these agents, and interacting with these agents in natural language to do so.\n\nAs a motivating example, consider the interaction depicted in Figure 1 where a system is asked to buy a book series with a certain property. The system breaks this goal down, using agent-1 (here Google Assistant) to identify the referenced book series as well as the list of books in that series, and then using agent-2 (here Amazon Alexa) to make the purchase. While both of these agents interact with the system in natural language, they have notably different skill sets, rely on privately held knowledge sources, and have been built at an enormous cost. At the same time, neither agent by itself can accomplish the original goal.\n\nAn alternative to building such a system that interacts with existing agents is to teach all requisite sub-tasks and skills to a large black-box system, say via multi-task learning Gupta et al., 2021). This, however, is not only wasteful in terms of time and resources, but often also infeasible. For example, agents such as Google Assistant and OpenAI GPT-3 use private knowledge resources and are computationally expensive to train even once. It would thus be nearly impossible to build a single system with the capabilities of both of these agents.\n\nWe note that agents need not be sophisticated AI assistants. An agent may simply be a previously developed question-answering (QA) model, a math module, a function of textual input, an image captioning system-anything the community already knows how to build. The goal is to learn to leverage existing agents for more complex tasks.\n\nTo enable the development of general systems for this task, we identify the minimal inputs that must be assumed for the task to be learnable-training data for the complex task, existing agents that together can solve the complex task, and examples of valid questions that can be asked of these agents (capturing the agents' capabilities). We build a new synthetic benchmark dataset called COMMAQA (Communicating with agents for QA), containing three complex multihop QA tasks (involving Explicit, Implicit, and Numeric reasoning) and four input QA agents that can solve these tasks.\n\nWe demonstrate that black-box models struggle on COMMAQA even when provided with auxiliary data, such as domain-relevant agent knowledge. On the other hand, a model that leverages the agents (Khot et al., 2021) can achieve very high accuracy but relies on auxiliary supervision (decomposition annotations). While it is possible to identify valid decompositions using just the endtask labels, the search space is extremely large and naïve approaches, as we show, help only with one of the datasets. COMMAQA thus serves as a new challenge for the NLP community.\n\nContributions: We (1) propose a new challenge of learning to solve complex tasks by communicating with agents; (2) develop a synthetic multi-hop QA dataset COMMAQA with three reasoning types;\n\n(3) provide auxiliary training data and a compositional generalization test set; (4) demonstrate the challenging nature of COMMAQA for black-box models; and (5) show the promise of compositional models that learn to communicate with agents.\n\n ",
    "all_spans": [
      {
        "span_text": "A common research avenue pursued these days is to train monolithic language models with billions of parameters to solve every language understanding and reasoning challenge.",
        "gpt_label": "Unsupported Claim",
        "reason": "This makes a broad claim about trends in the field and model scale without citing representative prior work.",
        "start": 14,
        "end": 186
      },
      {
        "span_text": "rely on privately held knowledge sources",
        "gpt_label": "Unsupported Claim",
        "reason": "Asserts a specific property of the referenced agents without providing citations to support it.",
        "start": 1604,
        "end": 1644
      },
      {
        "span_text": "have been built at an enormous cost.",
        "gpt_label": "Unsupported Claim",
        "reason": "Claims substantial development cost for external systems without evidence or citation.",
        "start": 1650,
        "end": 1685
      },
      {
        "span_text": "This, however, is not only wasteful in terms of time and resources, but often also infeasible.",
        "gpt_label": "Unsupported Claim",
        "reason": "Evaluative claim about the feasibility and efficiency of an alternative approach lacks supporting citations or data.",
        "start": 1962,
        "end": 2055
      },
      {
        "span_text": "For example, agents such as Google Assistant and OpenAI GPT-3 use private knowledge resources and are computationally expensive to train even once.",
        "gpt_label": "Unsupported Claim",
        "reason": "Makes specific claims about particular systems' knowledge sources and training cost without citing documentation or prior work.",
        "start": 2056,
        "end": 2202
      },
      {
        "span_text": "It would thus be nearly impossible to build a single system with the capabilities of both of these agents.",
        "gpt_label": "Unsupported Claim",
        "reason": "Strong assertion of impossibility requires evidence or references and is currently unsupported.",
        "start": 2203,
        "end": 2308
      },
      {
        "span_text": "Gupta et al., 2021)",
        "gpt_label": "Format",
        "reason": "Missing opening parenthesis for a parenthetical citation; should be formatted as (Gupta et al., 2021).",
        "start": 1943,
        "end": 1961
      },
      {
        "span_text": "We demonstrate that black-box models struggle on COMMAQA even when provided with auxiliary data, such as domain-relevant agent knowledge. On the other hand, a model that leverages the agents (Khot et al., 2021) can achieve very high accuracy but relies on auxiliary supervision (decomposition annotations).",
        "gpt_label": "Coherence",
        "reason": "The transition from the general claim about black-box models to the citation of Khot et al. (2021) is abrupt. It is not explicitly explained how Khot et al.’s work relates to COMMAQA or to the preceding sentence, leaving the relationship between the cited work and the discussion implied rather than stated.",
        "start": 3223,
        "end": 3526
      },
      {
        "span_text": "An alternative to building such a system that interacts with existing agents is to teach all requisite sub-tasks and skills to a large black-box system, say via multi-task learning Gupta et al., 2021).",
        "gpt_label": "Lacks synthesis",
        "reason": "This sentence drops a citation to prior work without explaining how that work specifically relates to the authors’ claims or contribution. It neither articulates what gap in multi-task learning remains nor connects Gupta et al. (2021) to the paper’s proposed approach, resulting in minimal integration of the literature with the authors’ argument.",
        "start": 1762,
        "end": 1961
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "A common research avenue pursued these days is to train monolithic language models with billions of parameters to solve every language understanding and reasoning challenge.",
          "gpt_label": "Unsupported Claim",
          "reason": "This makes a broad claim about trends in the field and model scale without citing representative prior work.",
          "start": 14,
          "end": 186
        },
        {
          "span_text": "rely on privately held knowledge sources",
          "gpt_label": "Unsupported Claim",
          "reason": "Asserts a specific property of the referenced agents without providing citations to support it.",
          "start": 1604,
          "end": 1644
        },
        {
          "span_text": "have been built at an enormous cost.",
          "gpt_label": "Unsupported Claim",
          "reason": "Claims substantial development cost for external systems without evidence or citation.",
          "start": 1650,
          "end": 1685
        },
        {
          "span_text": "This, however, is not only wasteful in terms of time and resources, but often also infeasible.",
          "gpt_label": "Unsupported Claim",
          "reason": "Evaluative claim about the feasibility and efficiency of an alternative approach lacks supporting citations or data.",
          "start": 1962,
          "end": 2055
        },
        {
          "span_text": "For example, agents such as Google Assistant and OpenAI GPT-3 use private knowledge resources and are computationally expensive to train even once.",
          "gpt_label": "Unsupported Claim",
          "reason": "Makes specific claims about particular systems' knowledge sources and training cost without citing documentation or prior work.",
          "start": 2056,
          "end": 2202
        },
        {
          "span_text": "It would thus be nearly impossible to build a single system with the capabilities of both of these agents.",
          "gpt_label": "Unsupported Claim",
          "reason": "Strong assertion of impossibility requires evidence or references and is currently unsupported.",
          "start": 2203,
          "end": 2308
        }
      ],
      "Format": [
        {
          "span_text": "Gupta et al., 2021)",
          "gpt_label": "Format",
          "reason": "Missing opening parenthesis for a parenthetical citation; should be formatted as (Gupta et al., 2021).",
          "start": 1943,
          "end": 1961
        }
      ],
      "Coherence": [
        {
          "span_text": "We demonstrate that black-box models struggle on COMMAQA even when provided with auxiliary data, such as domain-relevant agent knowledge. On the other hand, a model that leverages the agents (Khot et al., 2021) can achieve very high accuracy but relies on auxiliary supervision (decomposition annotations).",
          "gpt_label": "Coherence",
          "reason": "The transition from the general claim about black-box models to the citation of Khot et al. (2021) is abrupt. It is not explicitly explained how Khot et al.’s work relates to COMMAQA or to the preceding sentence, leaving the relationship between the cited work and the discussion implied rather than stated.",
          "start": 3223,
          "end": 3526
        }
      ],
      "Lacks synthesis": [
        {
          "span_text": "An alternative to building such a system that interacts with existing agents is to teach all requisite sub-tasks and skills to a large black-box system, say via multi-task learning Gupta et al., 2021).",
          "gpt_label": "Lacks synthesis",
          "reason": "This sentence drops a citation to prior work without explaining how that work specifically relates to the authors’ claims or contribution. It neither articulates what gap in multi-task learning remains nor connects Gupta et al. (2021) to the paper’s proposed approach, resulting in minimal integration of the literature with the authors’ argument.",
          "start": 1762,
          "end": 1961
        }
      ]
    }
  },
  "paper_74.txt": {
    "filename": "paper_74.txt",
    "full_text": "Introduction\n\nSouth Asia is home to one-quarter of the world's population and boasts immense linguistic diversity (Saxena and Borin, 2008;Bashir, 2016). With members of at least five major linguistic families and several putative linguistic isolates, this region is a fascinating arena for linguistic research. The languages of South Asia, moreover, have a long recorded history, and have undergone complex change through genetic descent, sociolinguistic interactions, and contact influence.\n\nNevertheless, South Asian languages for the most part remain severely underdocumented (van Driem, 2008), and several languages with even official administrative status (e.g. Sindhi) are low-resourced for the purposes of all natural language processing tasks (Joshi et al., 2020). This data scarcity persists despite long native traditions of linguistic description, continued language vitality with active use on the internet, and vast numbers of speakers (Rahman, 2008;Groff, 2017).\n\nWe argue that the most basic problem in NLP/CL work on South Asian languages is not data scarcity, but data scatteredness. There is much data to be extracted for even the most endangered languages (e.g. Burushaski, a language isolate of the northwest), from annotated corpora and grammatical descriptions compiled by linguists, if only one is willing to wrangle idiosyncratic data formats and digitise existing texts. Thus far, commercial interests and scientific agencies have only intermittently supported the development of language technology for the region-taking a new approach, we propose a research programme from the perspective of computational historical linguistics, outlining current data gathering initiatives in this discipline and potential benefits to other work across NLP.\n\n ",
    "all_spans": [
      {
        "span_text": "With members of at least five major linguistic families and several putative linguistic isolates,",
        "gpt_label": "Unsupported Claim",
        "reason": "This is a specific factual assertion about the number and types of language families in South Asia, but it lacks a direct citation supporting the count and classification.",
        "start": 152,
        "end": 249
      },
      {
        "span_text": "There is much data to be extracted for even the most endangered languages (e.g. Burushaski, a language isolate of the northwest), from annotated corpora and grammatical descriptions compiled by linguists,",
        "gpt_label": "Unsupported Claim",
        "reason": "Claims broad availability of extractable data and annotated corpora for even endangered languages and classifies Burushaski as an isolate without providing citations or evidence.",
        "start": 1092,
        "end": 1294
      },
      {
        "span_text": "Thus far, commercial interests and scientific agencies have only intermittently supported the development of language technology for the region",
        "gpt_label": "Unsupported Claim",
        "reason": "Asserts a historical/quantitative claim about funding and institutional support without citing sources or providing evidence.",
        "start": 1384,
        "end": 1527
      },
      {
        "span_text": "This data scarcity persists despite long native traditions of linguistic description, continued language vitality with active use on the internet, and vast numbers of speakers (Rahman, 2008;Groff, 2017).\n\nWe argue that the most basic problem in NLP/CL work on South Asian languages is not data scarcity, but data scatteredness.",
        "gpt_label": "Coherence",
        "reason": "There is an abrupt shift from asserting persistent data scarcity (supported by citations) to claiming the core problem is not scarcity but scatteredness. The relationship between these claims and the cited works is not explicitly stated, and the paragraph break lacks a transition explaining how the new claim responds to or reframes the prior point.",
        "start": 766,
        "end": 1091
      },
      {
        "span_text": "This data scarcity persists despite long native traditions of linguistic description, continued language vitality with active use on the internet, and vast numbers of speakers (Rahman, 2008;Groff, 2017).",
        "gpt_label": "Lacks synthesis",
        "reason": "The sentence cites prior work but does not connect these cited observations to the authors’ own argument or explicitly articulate how they motivate the proposed research program; it remains background without synthesizing into the paper’s specific gap or perspective.",
        "start": 766,
        "end": 968
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "With members of at least five major linguistic families and several putative linguistic isolates,",
          "gpt_label": "Unsupported Claim",
          "reason": "This is a specific factual assertion about the number and types of language families in South Asia, but it lacks a direct citation supporting the count and classification.",
          "start": 152,
          "end": 249
        },
        {
          "span_text": "There is much data to be extracted for even the most endangered languages (e.g. Burushaski, a language isolate of the northwest), from annotated corpora and grammatical descriptions compiled by linguists,",
          "gpt_label": "Unsupported Claim",
          "reason": "Claims broad availability of extractable data and annotated corpora for even endangered languages and classifies Burushaski as an isolate without providing citations or evidence.",
          "start": 1092,
          "end": 1294
        },
        {
          "span_text": "Thus far, commercial interests and scientific agencies have only intermittently supported the development of language technology for the region",
          "gpt_label": "Unsupported Claim",
          "reason": "Asserts a historical/quantitative claim about funding and institutional support without citing sources or providing evidence.",
          "start": 1384,
          "end": 1527
        }
      ],
      "Format": [],
      "Coherence": [
        {
          "span_text": "This data scarcity persists despite long native traditions of linguistic description, continued language vitality with active use on the internet, and vast numbers of speakers (Rahman, 2008;Groff, 2017).\n\nWe argue that the most basic problem in NLP/CL work on South Asian languages is not data scarcity, but data scatteredness.",
          "gpt_label": "Coherence",
          "reason": "There is an abrupt shift from asserting persistent data scarcity (supported by citations) to claiming the core problem is not scarcity but scatteredness. The relationship between these claims and the cited works is not explicitly stated, and the paragraph break lacks a transition explaining how the new claim responds to or reframes the prior point.",
          "start": 766,
          "end": 1091
        }
      ],
      "Lacks synthesis": [
        {
          "span_text": "This data scarcity persists despite long native traditions of linguistic description, continued language vitality with active use on the internet, and vast numbers of speakers (Rahman, 2008;Groff, 2017).",
          "gpt_label": "Lacks synthesis",
          "reason": "The sentence cites prior work but does not connect these cited observations to the authors’ own argument or explicitly articulate how they motivate the proposed research program; it remains background without synthesizing into the paper’s specific gap or perspective.",
          "start": 766,
          "end": 968
        }
      ]
    }
  },
  "paper_75.txt": {
    "filename": "paper_75.txt",
    "full_text": "Introduction\n\nNatural languages are highly contextual (Fodor, 2001): for a listener, recovering the speaker's intended meaning requires integrating information from different streams, such as grounding in perception (Pecher and Zwaan, 2005), shared world knowledge, and temporal reasoning (Wilson and Sperber, 1998). These processes, more generally, fall under the umbrella term of pragmatics (Grice, 1957). Despite recent progress in multimodal systems, it remains unclear to which extent they can handle settings where context plays a major role, such as in real-world communication.\n\nTo this end, we present a new challenge that requires multimodal models to leverage context to retrieve images from text. In particular, given a contextual description and a set of minimally contrastive candidate images, i.e. differing only in some details, the model has to retrieve the target image. In order to discriminate between similar images, human annotators naturally produce highly nuanced and grammatically complex descriptions. An example of our new challenging dataset, Image Retrieval from Contextual Descriptions (IMAGECODE), is shown in Figure 1.\n\nDuring the data collection process, sets of similar images are selected among static pictures from Open Images (Kuznetsova et al., 2020) and (a larger portion) among video frames from diverse domains. Including both types of images allows for diversifying the dataset while representing different degrees of visual similarity within each set. Next, we crowdsource a contextual description of a target image (presented together with the rest of the set) that contains only differences relevant for retrieval. After a filtering phase involving human retrievers, we obtain a large-scale dataset with 94,020 images and 21,202 descriptions associated with image sets of size 10.\n\nAs a result of this annotation protocol, successfully completing the task requires models to integrate several kinds of context: i) the image set, as the descriptions only make sense in the context of several other images and are not suitable as stand-alone captions. In fact, aspects of the image that are very salient and that therefore would normally be emphasized are not useful in our proposed task. Instead, the focus of our descriptions are finegrained details that help discriminate between images (see Figure 1); ii) the speaker's intention. Due to their high degree of image similarity, contextual descriptions may be literally true for multiple images; however, once the speaker's intention is taken into account, the correct image can be determined by virtue of pragmatics (see Figure 2); iii) temporal sequences: for video frames temporal reasoning is also required to compare different moments of an unfolding event.\n\nOn our new dataset IMAGECODE, we benchmark a series of vision-and-language models that achieve state-of-the-art performance on other multimodal tasks, including both cross-encoders such as ViLBERT (Lu et al., 2019) and bi-encoders such as CLIP (Radford et al., 2021). We report several findings. First, accuracy on static images is vastly superior than on video frames. Therefore, the degree of similarity among the candidate images has an overwhelming impact on retrieval performance. Second, all state-of-the-art models generally struggle with image retrieval from contextual descriptions, whereas humans consistently achieve high accuracy.\n\nHence, we propose model variants capable of better taking context into account: i) once an image description pair is encoded, we refine this representation by attending to the other images in the set; ii) we augment image encodings with special temporal embeddings. Based on our results, models take advantage of this additional information fruitfully but only to a limited degree.\n\nBecause of its challenging nature, due to the minimally contrastive images and complex descriptions, we believe that IMAGECODE will help make visio-linguistic models more context-aware and sensitive to fine-grained details. The dataset and models would be publicly released with the camera-ready version.\n\n ",
    "all_spans": [
      {
        "span_text": "Despite recent progress in multimodal systems,",
        "gpt_label": "Unsupported Claim",
        "reason": "Mentions 'recent progress' without citing specific works; statements about recent advances should be supported with references.",
        "start": 406,
        "end": 452
      },
      {
        "span_text": "it remains unclear to which extent they can handle settings where context plays a major role, such as in real-world communication.",
        "gpt_label": "Unsupported Claim",
        "reason": "Claims a lack of clarity about the state of the field without evidence or citations to surveys or evaluations supporting this assessment.",
        "start": 453,
        "end": 582
      },
      {
        "span_text": "vision-and-language models that achieve state-of-the-art performance on other multimodal tasks",
        "gpt_label": "Unsupported Claim",
        "reason": "SOTA claims should be supported with citations to specific benchmarks or studies demonstrating such performance.",
        "start": 2796,
        "end": 2890
      },
      {
        "span_text": "humans consistently achieve high accuracy.",
        "gpt_label": "Unsupported Claim",
        "reason": "Statistical/performance claim presented without accompanying evidence, data, or citation within the passage.",
        "start": 3335,
        "end": 3376
      },
      {
        "span_text": "Natural languages are highly contextual (Fodor, 2001): for a listener, recovering the speaker's intended meaning requires integrating information from different streams, such as grounding in perception (Pecher and Zwaan, 2005), shared world knowledge, and temporal reasoning (Wilson and Sperber, 1998). These processes, more generally, fall under the umbrella term of pragmatics (Grice, 1957). Despite recent progress in multimodal systems, it remains unclear to which extent they can handle settings where context plays a major role, such as in real-world communication.",
        "gpt_label": "Coherence",
        "reason": "The sequence lists several cited works without explaining their relationships, then abruptly generalizes to pragmatics and jumps to multimodal systems without an explicit link between the theoretical citations and the new claim. The transitions between these sentences are implied rather than stated.",
        "start": 14,
        "end": 582
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "Despite recent progress in multimodal systems,",
          "gpt_label": "Unsupported Claim",
          "reason": "Mentions 'recent progress' without citing specific works; statements about recent advances should be supported with references.",
          "start": 406,
          "end": 452
        },
        {
          "span_text": "it remains unclear to which extent they can handle settings where context plays a major role, such as in real-world communication.",
          "gpt_label": "Unsupported Claim",
          "reason": "Claims a lack of clarity about the state of the field without evidence or citations to surveys or evaluations supporting this assessment.",
          "start": 453,
          "end": 582
        },
        {
          "span_text": "vision-and-language models that achieve state-of-the-art performance on other multimodal tasks",
          "gpt_label": "Unsupported Claim",
          "reason": "SOTA claims should be supported with citations to specific benchmarks or studies demonstrating such performance.",
          "start": 2796,
          "end": 2890
        },
        {
          "span_text": "humans consistently achieve high accuracy.",
          "gpt_label": "Unsupported Claim",
          "reason": "Statistical/performance claim presented without accompanying evidence, data, or citation within the passage.",
          "start": 3335,
          "end": 3376
        }
      ],
      "Coherence": [
        {
          "span_text": "Natural languages are highly contextual (Fodor, 2001): for a listener, recovering the speaker's intended meaning requires integrating information from different streams, such as grounding in perception (Pecher and Zwaan, 2005), shared world knowledge, and temporal reasoning (Wilson and Sperber, 1998). These processes, more generally, fall under the umbrella term of pragmatics (Grice, 1957). Despite recent progress in multimodal systems, it remains unclear to which extent they can handle settings where context plays a major role, such as in real-world communication.",
          "gpt_label": "Coherence",
          "reason": "The sequence lists several cited works without explaining their relationships, then abruptly generalizes to pragmatics and jumps to multimodal systems without an explicit link between the theoretical citations and the new claim. The transitions between these sentences are implied rather than stated.",
          "start": 14,
          "end": 582
        }
      ]
    }
  },
  "paper_76.txt": {
    "filename": "paper_76.txt",
    "full_text": "Related Work\n\nTemplate-based data generation has been previously used for data augmentation, for example to inject numerical skills (Geva et al., 2020), and to improve consistency (Asai and Hajishirzi, 2020), and zero-shot accuracy (Zhao et al., 2019). In addition, templates were used for dataset construction (Talmor and Berant, 2018;Thorne et al., 2021), and to analyse model generalization (Rozen et al., 2019). In this work, we automatically generate examples by instantiating templates using structured data. Since our method relies solely on tables as input, it is highly scalable, has rich lexical diversity, and can be easily extended to new skills and domains.\n\nRecently, Thorne et al. ( 2021) introduced the WIKINLDB dataset, which includes queries that require reasoning over a set of textual facts. Queries are instantiated with values from a knowledge graph (KG), and facts are generated by a LM. Unlike this work, WIKINLDB is focused on evaluating reasoning skills. We, on the other hand, show that generated examples can be used to endow a pretrained LM with new reasoning skills. Moreover, tables are much easier to collect at scale compared to KGs, which tend to have limited coverage. Data augmenatation techniques have been extensively explored in RC, QA, and dialogue (Feng refers to all questions that do not require reasoning over the image modality.     Khashabi et al., 2020;Alberti et al., 2019;Puri et al., 2020;Bartolo et al., 2021). Here, we focus on tables as a valuable source for data generation.\n\nPre-training over tables has focused in the past on reasoning over tables and knowledge-bases Yin et al., 2020;Herzig et al., 2020;Müller et al., 2021;Yu et al., 2021;Neeraja et al., 2021b). Here, we use pre-training over tables to improve reasoning over text. We leave evaluation on tasks beyond RC to future work.\n\nError-driven sampling has been considered in the past in the context of active learning (Sharma et al., 2018), reinforcement learning (Graves et al., 2017;Glover and Hokamp, 2019;Xu et al., 2019), transfer learning Pilault et al., 2021), and distributionally robust optimization (Oren et al., 2019;Sagawa et al., 2020), where the goal is to perform well over a family of distributions. Similar to Gottumukkala et al. (2020), we compute heterogeneous batches based on error rates, and show that this improves efficiency and performance.\n\n ",
    "all_spans": [
      {
        "span_text": "Moreover, tables are much easier to collect at scale compared to KGs, which tend to have limited coverage.",
        "gpt_label": "Unsupported Claim",
        "reason": "Makes a comparative claim about data resource availability and knowledge graph coverage without providing supporting citations.",
        "start": 1084,
        "end": 1189
      },
      {
        "span_text": "Feng refers to all questions that do not require reasoning over the image modality.",
        "gpt_label": "Unsupported Claim",
        "reason": "References an unnamed work by Feng and makes a definitional claim without a proper citation, making the statement unsupported.",
        "start": 1276,
        "end": 1358
      },
      {
        "span_text": "Moreover, tables are much easier to collect at scale compared to KGs, which tend to have limited coverage. Data augmenatation techniques have been extensively explored in RC, QA, and dialogue (Feng refers to all questions that do not require reasoning over the image modality.     Khashabi et al., 2020;Alberti et al., 2019;Puri et al., 2020;Bartolo et al., 2021). Here, we focus on tables as a valuable source for data generation.",
        "gpt_label": "Coherence",
        "reason": "The transition from discussing KGs vs. tables to broadly citing data augmentation in RC/QA/dialogue is abrupt, and the relationship between those cited works and the preceding discussion is not made explicit. The parenthetical citation fragment is also unclear, further weakening the linkage across these sentences.",
        "start": 1084,
        "end": 1507
      },
      {
        "span_text": "In this work, we automatically generate examples by instantiating templates using structured data. Since our method relies solely on tables as input, it is highly scalable, has rich lexical diversity, and can be easily extended to new skills and domains.",
        "gpt_label": "Lacks synthesis",
        "reason": "These sentences follow a list of prior template-based approaches but do not articulate the specific gap in that literature or clearly differentiate how the proposed method advances beyond or addresses shortcomings of the cited works, thus lacking synthesis between prior work and the authors’ contribution.",
        "start": 410,
        "end": 662
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "Moreover, tables are much easier to collect at scale compared to KGs, which tend to have limited coverage.",
          "gpt_label": "Unsupported Claim",
          "reason": "Makes a comparative claim about data resource availability and knowledge graph coverage without providing supporting citations.",
          "start": 1084,
          "end": 1189
        },
        {
          "span_text": "Feng refers to all questions that do not require reasoning over the image modality.",
          "gpt_label": "Unsupported Claim",
          "reason": "References an unnamed work by Feng and makes a definitional claim without a proper citation, making the statement unsupported.",
          "start": 1276,
          "end": 1358
        }
      ],
      "Format": [],
      "Coherence": [
        {
          "span_text": "Moreover, tables are much easier to collect at scale compared to KGs, which tend to have limited coverage. Data augmenatation techniques have been extensively explored in RC, QA, and dialogue (Feng refers to all questions that do not require reasoning over the image modality.     Khashabi et al., 2020;Alberti et al., 2019;Puri et al., 2020;Bartolo et al., 2021). Here, we focus on tables as a valuable source for data generation.",
          "gpt_label": "Coherence",
          "reason": "The transition from discussing KGs vs. tables to broadly citing data augmentation in RC/QA/dialogue is abrupt, and the relationship between those cited works and the preceding discussion is not made explicit. The parenthetical citation fragment is also unclear, further weakening the linkage across these sentences.",
          "start": 1084,
          "end": 1507
        }
      ],
      "Lacks synthesis": [
        {
          "span_text": "In this work, we automatically generate examples by instantiating templates using structured data. Since our method relies solely on tables as input, it is highly scalable, has rich lexical diversity, and can be easily extended to new skills and domains.",
          "gpt_label": "Lacks synthesis",
          "reason": "These sentences follow a list of prior template-based approaches but do not articulate the specific gap in that literature or clearly differentiate how the proposed method advances beyond or addresses shortcomings of the cited works, thus lacking synthesis between prior work and the authors’ contribution.",
          "start": 410,
          "end": 662
        }
      ]
    }
  },
  "paper_77.txt": {
    "filename": "paper_77.txt",
    "full_text": "Introduction\n\nAs neural networks are achieving extraordinary prediction performance in dominating NLP tasks, it becomes increasingly important to explain why a model makes a specific prediction. Recent work starts to extract snippets of input text as the faithful rationale of prediction (Jain et al., 2020;Paranjape et al., 2020), with rationale defined as \"shortest yet sufficient subset of input to predict the same label\" (Lei et al., 2016;Bastings et al., 2019). The underneath assumption is two fold: (1) by retaining the label, we are extracting texts used by predictors (Jain et al., 2020); and (2) short rationales are more readable and intuitive for end users,  (Socher et al., 2013). and therefore are preferred for human understanding (Vafa et al., 2021). Importantly, prior work has knowingly traded off some amount of model performance in order to achieve shortest rationales. For example, when using less than 50% of text as rationales-for-predictions, Paranjape et al. (2020) achieved an accuracy of 84.0% (compared to 91.0% if using the full text). But existing work propose shortest rationales have better human interpretability by intuition rather than from empirical human studies (Vafa et al., 2021). Moreover, when the rationale is too short, the model has a much higher chance of missing the main point in the full text. In Figure 1(A), though the model is able to make the correct positive prediction when using only 20% of the text, it relies on a particular adjective, \"lifeaffirming\", which is seemingly positive but does not reflect the author's sentiment. They may simply be confused when presented to end users.\n\nIn this work, we ask: is shortest rationales really supportive of human understanding? and examine the effects of rationale length on human understanding and performance. Our work includes two steps: First, we design and train a self-explaining model that allows for sparsity control. That is, the model can flexible extract rationales of a targeted length, such that we can compare user perceptions on a set of rationales with varying lengths. As shown in Figure 1, our model design consider three aspects: (A) controllability on rationale length, (B) being context-aware such to priorize certain amount of semantic information in the text, and, (C) extracting continuous text for readability. Through automated valuation on ERASER (DeYoung et al., 2019) datasets, we show that our model outperforms existing self-explaining baselines on both end-task prediction and rationale alignment with human ground annotations.\n\nUsing the rationales with different lengths generated from the model, we conduct human studies to evaluate human accuracy and confidence on predicting the document categories given only rationales. Our results show the best explanations for human understanding are largely not the shortest rationales. Given rationales with short length at 10%, human accuracy on predicting model class is worse than accuracy on the random baseline. Furthermore, while most prior work extracts 10%-30% of text to be rationale (Jain et al., 2020;Paranjape et al., 2020), human accuracy tend to stablize after seeing 40% of the full text. Our result sounds a cautionary note, and we encourage future work to more rigorously define or evaluate the typical assumption of \"shorter rationales are easier to interpret\" before trading off model accuracy for it.\n\n ",
    "all_spans": [
      {
        "span_text": "As neural networks are achieving extraordinary prediction performance in dominating NLP tasks,",
        "gpt_label": "Unsupported Claim",
        "reason": "This is a broad claim about the state of the field and model performance without any citation or empirical evidence; such assertions about prior work should be supported by references.",
        "start": 14,
        "end": 108
      },
      {
        "span_text": "short rationales are more readable and intuitive for end users,  (Socher et al., 2013). and therefore are preferred for human understanding (Vafa et al., 2021).",
        "gpt_label": "Coherence",
        "reason": "Two consecutive sentences cite different works without explicitly stating their relationship. The second is a fragment beginning with 'and,' making the transition abrupt and leaving the connection between Socher et al. (readability) and Vafa et al. (preference for human understanding) implied rather than clearly explained.",
        "start": 600,
        "end": 756
      },
      {
        "span_text": "As shown in Figure 1, our model design consider three aspects: (A) controllability on rationale length, (B) being context-aware such to priorize certain amount of semantic information in the text, and, (C) extracting continuous text for readability. Through automated valuation on ERASER (DeYoung et al., 2019) datasets, we show that our model outperforms existing self-explaining baselines on both end-task prediction and rationale alignment with human ground annotations.",
        "gpt_label": "Lacks synthesis",
        "reason": "This passage lists design choices and an evaluation outcome without explicitly connecting these choices to the previously identified gap (the assumption that shorter rationales aid human understanding) or articulating why each aspect addresses that gap; it also cites ERASER without integrating how this evaluation links back to the paper’s central argument about human interpretability.",
        "start": 2064,
        "end": 2534
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "As neural networks are achieving extraordinary prediction performance in dominating NLP tasks,",
          "gpt_label": "Unsupported Claim",
          "reason": "This is a broad claim about the state of the field and model performance without any citation or empirical evidence; such assertions about prior work should be supported by references.",
          "start": 14,
          "end": 108
        }
      ],
      "Format": [],
      "Coherence": [
        {
          "span_text": "short rationales are more readable and intuitive for end users,  (Socher et al., 2013). and therefore are preferred for human understanding (Vafa et al., 2021).",
          "gpt_label": "Coherence",
          "reason": "Two consecutive sentences cite different works without explicitly stating their relationship. The second is a fragment beginning with 'and,' making the transition abrupt and leaving the connection between Socher et al. (readability) and Vafa et al. (preference for human understanding) implied rather than clearly explained.",
          "start": 600,
          "end": 756
        }
      ],
      "Lacks synthesis": [
        {
          "span_text": "As shown in Figure 1, our model design consider three aspects: (A) controllability on rationale length, (B) being context-aware such to priorize certain amount of semantic information in the text, and, (C) extracting continuous text for readability. Through automated valuation on ERASER (DeYoung et al., 2019) datasets, we show that our model outperforms existing self-explaining baselines on both end-task prediction and rationale alignment with human ground annotations.",
          "gpt_label": "Lacks synthesis",
          "reason": "This passage lists design choices and an evaluation outcome without explicitly connecting these choices to the previously identified gap (the assumption that shorter rationales aid human understanding) or articulating why each aspect addresses that gap; it also cites ERASER without integrating how this evaluation links back to the paper’s central argument about human interpretability.",
          "start": 2064,
          "end": 2534
        }
      ]
    }
  },
  "paper_78.txt": {
    "filename": "paper_78.txt",
    "full_text": "Introduction\n\nRelation extraction is a fundamental problem in natural language processing, which aims to identify the semantic relation between a pair of entities mentioned in the text. Recent progress in supervised relation extraction has achieved great successes (Zeng et al., 2014;Zhou et al., 2016;Soares et al., 2019), but these approaches usually require large-scale labeled data. While in practice, human annotation is time-consuming and labor-intensive. 1 We will release our code after blind review. : The Doctor tries to restore the universe with the help of River and the alternative universe versions of his companions Amy Pond(Karen Gillan) and Rory Williams(Arthur Darvill).  To alleviate the human annotation efforts in relation extraction, some recent studies use distant supervision to generate labeled data for training (Mintz et al., 2009;Lin et al., 2016). However, in the real-world setting, the relations of instances are not always included in the training data, and existing supervised methods cannot well recognize unobserved relations due to weak generalization ability.\n\nTo address the aforementioned limitations, zeroshot relation extraction has been proposed to extract relational facts where the target relations cannot be observed at the training stage. The challenge of zero-shot relation extraction models is how to learn effective representations based on seen relations at the training stage and well generalize to unseen relations at the test stage. Two studies (Levy et al., 2017;Obamuyide and Vlachos, 2018) treat zero-shot relation extraction as a different task (i.e., question answering and textual entailment), but they both need human annotation auxiliary in-formation for input, i.e., pre-defining question templates and relation descriptions. ZS-BERT (Chen and Li, 2021) predicts unseen relations with attribute representation learning. Despite promising improvements on directly predicting unseen relations, ZS-BERT still makes wrong predictions due to similar relations or similar entities. The same problem arises in supervised methods under the zero-shot settings.\n\nAs shown in Figure 1, there are two types of similar errors: Similar Relations and Similar Entities. For similar relations (see Z 1 and Z 2 ), existing methods predict wrongly results because the unseen relations possess similar semantics and data points belong to two relations in the representation space are overlapped. For similar entities (i.e., 2014 contest and 2002 Contest), since entities are the context of relation and relation representations are derived from entities, the relation representations containing similar entities are close (see f (Z 3 ) and f (Z 4 )) and baselines wrongly consider f (Z 4 ) belongs to follows in the representation space, even if two unseen relations are not related. Recently, Instancewise Contrastive Learning (Instance-CL) (He et al., 2020;Yan et al., 2021;Gao et al., 2021; has achieved remarkable success in representation learning. Instance-CL is used to learn an effective representation by pulling together the instances from the same class, while pushing apart instances from different classes. Inspired by Instance-CL, we attempt to use Instance-CL on seen relations to learn the difference between similar relations and the divergence of relation representations derived from similar entities.\n\nIn this paper, we propose a novel Relation Contrastive Learning framework (RCL) to solve the above-mentioned problems. Figure 1 depicts the overview of the proposed model, which consists of four steps: (i) The input for RCL is a batch of sentences containing the pair of target entities and each sentence is sent into input sentence encoder to generate the contextual sentence embeddings 2 . (ii) Taking the sentence embeddings as input, relation augmentation layer is designed to obtain the relation representations f (X i ) and their corresponding augmented views f ( Xi ). (iii) By jointly optimizing a contrastive loss and a relation classification loss on seen relations, RCL can learn subtle difference between instances and achieve better separation between relations in the representation space simultaneously to obtain an effective projection function f . (iv) With the learned f , the whole test set Z can be projected for unseen relation representations in the representation space and zero-shot prediction is performed on unseen relation representations by K-Means.\n\nTo summarize, the major contributions of our work are as follows: (i) We propose a novel framework based on contrastive learning for zero-shot relation extraction. It effectively mitigates two types of similar problems: similar relations and similar entities by learning representations jointly optimized with contrastive loss and classification loss. (ii) We explore various data augmentation strategies in relation augmentation to minimize semantic impact for contrastive instance learning and experimental results show dropout noise as minimal data augmentation can help RCL learn the difference between similar instances better. (iii) We conduct experiments on two well-known datasets. Experimental results show that RCL can advance stateof-the-art performance by a large margin. Besides, even if the number of seen relations is insufficient, RCL can also achieve comparable results with the model trained on the full training set.\n\n ",
    "all_spans": [
      {
        "span_text": "However, in the real-world setting, the relations of instances are not always included in the training data, and existing supervised methods cannot well recognize unobserved relations due to weak generalization ability.",
        "gpt_label": "Unsupported Claim",
        "reason": "Makes a broad claim about limitations of supervised methods without citation or evidence.",
        "start": 866,
        "end": 1084
      },
      {
        "span_text": "Despite promising improvements on directly predicting unseen relations, ZS-BERT still makes wrong predictions due to similar relations or similar entities.",
        "gpt_label": "Unsupported Claim",
        "reason": "Specific critique of a prior method is presented without supporting citation or empirical evidence.",
        "start": 1861,
        "end": 2015
      },
      {
        "span_text": "The same problem arises in supervised methods under the zero-shot settings.",
        "gpt_label": "Unsupported Claim",
        "reason": "General claim about prior methods’ behavior that lacks citations or supporting evidence.",
        "start": 2016,
        "end": 2090
      },
      {
        "span_text": "While in practice, human annotation is time-consuming and labor-intensive. 1 We will release our code after blind review. : The Doctor tries to restore the universe with the help of River and the alternative universe versions of his companions Amy Pond(Karen Gillan) and Rory Williams(Arthur Darvill).  To alleviate the human annotation efforts in relation extraction, some recent studies use distant supervision to generate labeled data for training (Mintz et al., 2009;Lin et al., 2016).",
        "gpt_label": "Coherence",
        "reason": "The inserted sentences about code release and a Doctor Who plot are abrupt and unrelated to the surrounding discussion on annotation and distant supervision, breaking the transition between sentences and obscuring the relationship among them.",
        "start": 382,
        "end": 865
      },
      {
        "span_text": "Two studies (Levy et al., 2017;Obamuyide and Vlachos, 2018) treat zero-shot relation extraction as a different task (i.e., question answering and textual entailment), but they both need human annotation auxiliary in-formation for input, i.e., pre-defining question templates and relation descriptions.",
        "gpt_label": "Lacks synthesis",
        "reason": "Summarizes prior work and a limitation (need for auxiliary human-provided inputs) but does not connect this critique to the authors’ own approach or explain whether/how their method addresses this specific gap, leaving the literature mention unsynthesized with their argument.",
        "start": 1472,
        "end": 1767
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "However, in the real-world setting, the relations of instances are not always included in the training data, and existing supervised methods cannot well recognize unobserved relations due to weak generalization ability.",
          "gpt_label": "Unsupported Claim",
          "reason": "Makes a broad claim about limitations of supervised methods without citation or evidence.",
          "start": 866,
          "end": 1084
        },
        {
          "span_text": "Despite promising improvements on directly predicting unseen relations, ZS-BERT still makes wrong predictions due to similar relations or similar entities.",
          "gpt_label": "Unsupported Claim",
          "reason": "Specific critique of a prior method is presented without supporting citation or empirical evidence.",
          "start": 1861,
          "end": 2015
        },
        {
          "span_text": "The same problem arises in supervised methods under the zero-shot settings.",
          "gpt_label": "Unsupported Claim",
          "reason": "General claim about prior methods’ behavior that lacks citations or supporting evidence.",
          "start": 2016,
          "end": 2090
        }
      ],
      "Format": [],
      "Coherence": [
        {
          "span_text": "While in practice, human annotation is time-consuming and labor-intensive. 1 We will release our code after blind review. : The Doctor tries to restore the universe with the help of River and the alternative universe versions of his companions Amy Pond(Karen Gillan) and Rory Williams(Arthur Darvill).  To alleviate the human annotation efforts in relation extraction, some recent studies use distant supervision to generate labeled data for training (Mintz et al., 2009;Lin et al., 2016).",
          "gpt_label": "Coherence",
          "reason": "The inserted sentences about code release and a Doctor Who plot are abrupt and unrelated to the surrounding discussion on annotation and distant supervision, breaking the transition between sentences and obscuring the relationship among them.",
          "start": 382,
          "end": 865
        }
      ],
      "Lacks synthesis": [
        {
          "span_text": "Two studies (Levy et al., 2017;Obamuyide and Vlachos, 2018) treat zero-shot relation extraction as a different task (i.e., question answering and textual entailment), but they both need human annotation auxiliary in-formation for input, i.e., pre-defining question templates and relation descriptions.",
          "gpt_label": "Lacks synthesis",
          "reason": "Summarizes prior work and a limitation (need for auxiliary human-provided inputs) but does not connect this critique to the authors’ own approach or explain whether/how their method addresses this specific gap, leaving the literature mention unsynthesized with their argument.",
          "start": 1472,
          "end": 1767
        }
      ]
    }
  },
  "paper_79.txt": {
    "filename": "paper_79.txt",
    "full_text": "Related Work\n\nEntity Linking Entity linking has been widely studied (Milne and Witten, 2008;Cucerzan, 2007;Lazic et al., 2015b;Gupta et al., 2017;Raiman and Raiman, 2018;Kolitsas et al., 2018;Cao et al., 2021, inter alia). Dutta and Weikum (2015) combine clustering-based cross-document coreference decisions and linking around sparse bag-of-word representations not well suited for the embedding-   (Bagga and Baldwin, 1998;Gooi and Allan, 2004;Singh et al., 2011;Barhom et al., 2019;Cattan et al., 2020;Caciularu et al., 2021;Ravenscroft et al., 2021;Logan IV et al., inter alia).\n\nAlternatives to Cross-Encoders Our work demonstrates how clustering-based training and prediction improves dual-encoder based models for linking and discovery. If prediction efficiency, and not training efficiency, was the only concern, one could use model distillation (Hinton et al., 2015;Izacard and Grave, 2021, inter alia). We could also consider models such as poly-encoders as an alternative to dual-encoders (Humeau et al., 2020).\n\n ",
    "all_spans": [
      {
        "span_text": "sparse bag-of-word representations not well suited for the embedding-",
        "gpt_label": "Unsupported Claim",
        "reason": "Evaluative claim about the inadequacy of bag-of-word representations for embedding-based methods is asserted without citation or evidence supporting this niche technical judgment.",
        "start": 323,
        "end": 392
      },
      {
        "span_text": "Logan IV et al., inter alia",
        "gpt_label": "Format",
        "reason": "Citation missing year and also lacks a space after the preceding semicolon.",
        "start": 543,
        "end": 569
      },
      {
        "span_text": "Alternatives to Cross-Encoders Our work demonstrates how clustering-based training and prediction improves dual-encoder based models for linking and discovery. If prediction efficiency, and not training efficiency, was the only concern, one could use model distillation (Hinton et al., 2015;Izacard and Grave, 2021, inter alia). We could also consider models such as poly-encoders as an alternative to dual-encoders (Humeau et al., 2020).",
        "gpt_label": "Coherence",
        "reason": "The shift from claiming improvements to dual-encoders, to discussing model distillation for prediction efficiency, to mentioning poly-encoders is abrupt. The relationships among these alternatives and their relevance to each other (and to cross-encoders) are implied rather than explicitly stated, with missing transitions explaining how each cited approach connects to the previous one.",
        "start": 572,
        "end": 1005
      },
      {
        "span_text": "Entity Linking Entity linking has been widely studied (Milne and Witten, 2008;Cucerzan, 2007;Lazic et al., 2015b;Gupta et al., 2017;Raiman and Raiman, 2018;Kolitsas et al., 2018;Cao et al., 2021, inter alia). Dutta and Weikum (2015) combine clustering-based cross-document coreference decisions and linking around sparse bag-of-word representations not well suited for the embedding-   (Bagga and Baldwin, 1998;Gooi and Allan, 2004;Singh et al., 2011;Barhom et al., 2019;Cattan et al., 2020;Caciularu et al., 2021;Ravenscroft et al., 2021;Logan IV et al., inter alia).",
        "gpt_label": "Lacks synthesis",
        "reason": "This paragraph lists prior work and methods without explaining how they relate to the authors’ approach or identifying a specific gap/motivation that their work addresses, offering no explicit connection or perspective.",
        "start": 14,
        "end": 570
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "sparse bag-of-word representations not well suited for the embedding-",
          "gpt_label": "Unsupported Claim",
          "reason": "Evaluative claim about the inadequacy of bag-of-word representations for embedding-based methods is asserted without citation or evidence supporting this niche technical judgment.",
          "start": 323,
          "end": 392
        }
      ],
      "Format": [
        {
          "span_text": "Logan IV et al., inter alia",
          "gpt_label": "Format",
          "reason": "Citation missing year and also lacks a space after the preceding semicolon.",
          "start": 543,
          "end": 569
        }
      ],
      "Coherence": [
        {
          "span_text": "Alternatives to Cross-Encoders Our work demonstrates how clustering-based training and prediction improves dual-encoder based models for linking and discovery. If prediction efficiency, and not training efficiency, was the only concern, one could use model distillation (Hinton et al., 2015;Izacard and Grave, 2021, inter alia). We could also consider models such as poly-encoders as an alternative to dual-encoders (Humeau et al., 2020).",
          "gpt_label": "Coherence",
          "reason": "The shift from claiming improvements to dual-encoders, to discussing model distillation for prediction efficiency, to mentioning poly-encoders is abrupt. The relationships among these alternatives and their relevance to each other (and to cross-encoders) are implied rather than explicitly stated, with missing transitions explaining how each cited approach connects to the previous one.",
          "start": 572,
          "end": 1005
        }
      ],
      "Lacks synthesis": [
        {
          "span_text": "Entity Linking Entity linking has been widely studied (Milne and Witten, 2008;Cucerzan, 2007;Lazic et al., 2015b;Gupta et al., 2017;Raiman and Raiman, 2018;Kolitsas et al., 2018;Cao et al., 2021, inter alia). Dutta and Weikum (2015) combine clustering-based cross-document coreference decisions and linking around sparse bag-of-word representations not well suited for the embedding-   (Bagga and Baldwin, 1998;Gooi and Allan, 2004;Singh et al., 2011;Barhom et al., 2019;Cattan et al., 2020;Caciularu et al., 2021;Ravenscroft et al., 2021;Logan IV et al., inter alia).",
          "gpt_label": "Lacks synthesis",
          "reason": "This paragraph lists prior work and methods without explaining how they relate to the authors’ approach or identifying a specific gap/motivation that their work addresses, offering no explicit connection or perspective.",
          "start": 14,
          "end": 570
        }
      ]
    }
  },
  "paper_80.txt": {
    "filename": "paper_80.txt",
    "full_text": "Introduction\n\nCoherence describes the semantic relation between elements of a text. It recognizes how well a text is organized to convey the information to the reader effectively. Modeling coherence can be beneficial to any system which needs to process a text.\n\nRecent neural coherence models (Mesgar and Strube, 2018;Moon et al., 2019) encode the input document using large-scale pretrained language models (Peters et al., 2018). These neural models compute local coherence, semantic relations between items in adjacent sentences, on the basis of words and even sub-words.\n\nHowever, it has been unclear on which basis these models compute local coherence. Jeon and Strube (2020) present a neural coherence model, which allows to interpret focus information for the first time. Their investigation reveals that neural models, adopting large-scale pretrained language models, frequently compute coherence on the basis of connections between any (sub-)words or function words. In these cases, the model might capture the focus based on spurious information. While such a model might reach or set the state of the art in some end applications, it will do so for the wrong reasons from a linguistic perspective.\n\nThis problem did not appear with pre-neural models of coherence, since they compute coherence on the basis of entities. Early work about pronoun and anaphora resolution by Sidner (1981Sidner ( , 1983 assumes that there is one single salient entity in a sentence, its focus, which serves as a preferred antecedent for anaphoric expressions. Centering theory (Joshi and Weinstein, 1981;Grosz et al., 1995) builds on these insights and introduces an algorithm for tracking changes in focus. Centering theory serves as basis for many researchers to develop systems computing local coherence based on the approximations of entities (Barzilay and Lapata 2008;Feng and Hirst 2012;Guinaudeau and Strube 2013, inter alia).\n\nIn this paper, we propose a neural coherence model which is linguistically more sound than previously proposed neural coherence models. We compute coherence on the basis of entities by constraining our model to capture focus on noun phrases and proper names. This provides us with an explicit representation of the most important items in sentences, leading to the notion of focus. This brings our model linguistically in line with pre-neural models of coherence.\n\nOur approach is not only linguistically more sound but also is in accord with the recent empirical study by O'Connor and Andreas (2021) who investigate what contextual information contributes to accurate predictions in transformer-based language models. Their experiments show that most usable information is captured by nouns and verbs. Their findings suggest that we can design better neural models by focusing on specific context words. Our work follows their findings by modeling entitybased coherence in an end-to-end framework to improve a neural coherence model.\n\nOur model integrates a local coherence module with a component which takes context into account. Our model first encodes a document using a pretrained language model and identifies entities using an linguistic parser. The local coherence module captures the most related representations of entities between adjacent sentences, the local focus. Then it tracks the changes of local foci. The second component captures the context of a text by averaging sentence representations.\n\nWe evaluate our model on three downstream tasks: automated essay scoring (AES), assessing writing quality (AWQ), and assessing discourse coherence (ADC). AES and AWQ determine text quality for a given text, aiming to replicate human scoring results. Since coherence is an essential factor in assessing text quality, many previous coherence models are evaluated on AES and AWQ. ADC evaluates coherence models on informal texts such as emails and online reviews. In our evaluation, our model achieves state-of-the-art performance.\n\nWe also perform a series of analyses to investigate how our model works. Our analyses show that capturing focus on entities gives us better insight into the behaviour of the model, leading to better explainability. Using this information, we examine the statistical differences of texts assigned to different qualities. From the perspective of local coherence, we find that texts of higher quality are neither semantically too consistent nor too variant. Finally, we inspect error cases to investigate how the models achieve their performance differently.\n\n ",
    "all_spans": [
      {
        "span_text": "However, it has been unclear on which basis these models compute local coherence.",
        "gpt_label": "Unsupported Claim",
        "reason": "Field-level claim about a gap in prior work lacks citations to support that this has been unclear; should reference surveys or papers noting this limitation.",
        "start": 569,
        "end": 649
      },
      {
        "span_text": "While such a model might reach or set the state of the art in some end applications, it will do so for the wrong reasons from a linguistic perspective.",
        "gpt_label": "Unsupported Claim",
        "reason": "Claims SOTA performance of unspecified models without citing any evidence or works; SOTA/statistical claims should be supported.",
        "start": 1046,
        "end": 1196
      },
      {
        "span_text": "This problem did not appear with pre-neural models of coherence, since they compute coherence on the basis of entities.",
        "gpt_label": "Unsupported Claim",
        "reason": "Strong comparative claim about earlier models not having the problem is not directly supported by citations; needs evidence or references explicitly demonstrating the absence of the issue.",
        "start": 1198,
        "end": 1316
      },
      {
        "span_text": "We evaluate our model on three downstream tasks: automated essay scoring (AES), assessing writing quality (AWQ), and assessing discourse coherence (ADC).",
        "gpt_label": "Unsupported Claim",
        "reason": "First mention of established tasks/datasets lacks citations to the corresponding benchmarks or canonical works (guideline a).",
        "start": 3409,
        "end": 3561
      },
      {
        "span_text": "Since coherence is an essential factor in assessing text quality, many previous coherence models are evaluated on AES and AWQ.",
        "gpt_label": "Unsupported Claim",
        "reason": "Claim about prior work frequency lacks supporting citations to the studies that evaluate on AES and AWQ.",
        "start": 3657,
        "end": 3782
      },
      {
        "span_text": "ADC evaluates coherence models on informal texts such as emails and online reviews.",
        "gpt_label": "Unsupported Claim",
        "reason": "Description of a specific dataset/task should be accompanied by a citation at first mention (guideline a).",
        "start": 3783,
        "end": 3865
      },
      {
        "span_text": "In our evaluation, our model achieves state-of-the-art performance.",
        "gpt_label": "Unsupported Claim",
        "reason": "SOTA claim is a comparative/statistical statement without citation or evidence presented here; should reference or point to results to substantiate.",
        "start": 3866,
        "end": 3932
      },
      {
        "span_text": "Sidner (1981Sidner ( , 1983",
        "gpt_label": "Format",
        "reason": "Garbled/malformed citation: duplicated author string, misplaced comma, and missing/incorrect parentheses for multiple years (should be something like \"Sidner (1981, 1983)\").",
        "start": 1369,
        "end": 1396
      },
      {
        "span_text": "Our approach is not only linguistically more sound but also is in accord with the recent empirical study by O'Connor and Andreas (2021) who investigate what contextual information contributes to accurate predictions in transformer-based language models. Their experiments show that most usable information is captured by nouns and verbs. Their findings suggest that we can design better neural models by focusing on specific context words. Our work follows their findings by modeling entitybased coherence in an end-to-end framework to improve a neural coherence model.",
        "gpt_label": "Coherence",
        "reason": "The connection between the cited study (which highlights both nouns and verbs) and the authors’ specific choice to focus on entities (primarily nouns) is only implied, not explicitly justified. The transition across these sentences is abrupt, leaving unclear how the findings about nouns and verbs directly motivate an entity-only modeling decision.",
        "start": 2369,
        "end": 2934
      },
      {
        "span_text": "Recent neural coherence models (Mesgar and Strube, 2018;Moon et al., 2019) encode the input document using large-scale pretrained language models (Peters et al., 2018). These neural models compute local coherence, semantic relations between items in adjacent sentences, on the basis of words and even sub-words.",
        "gpt_label": "Lacks synthesis",
        "reason": "This passage summarizes prior work and its characteristics without explicitly connecting these points to the authors’ own perspective or argument within the same span (the gap and motivation are only introduced in the following paragraph).",
        "start": 260,
        "end": 567
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "However, it has been unclear on which basis these models compute local coherence.",
          "gpt_label": "Unsupported Claim",
          "reason": "Field-level claim about a gap in prior work lacks citations to support that this has been unclear; should reference surveys or papers noting this limitation.",
          "start": 569,
          "end": 649
        },
        {
          "span_text": "While such a model might reach or set the state of the art in some end applications, it will do so for the wrong reasons from a linguistic perspective.",
          "gpt_label": "Unsupported Claim",
          "reason": "Claims SOTA performance of unspecified models without citing any evidence or works; SOTA/statistical claims should be supported.",
          "start": 1046,
          "end": 1196
        },
        {
          "span_text": "This problem did not appear with pre-neural models of coherence, since they compute coherence on the basis of entities.",
          "gpt_label": "Unsupported Claim",
          "reason": "Strong comparative claim about earlier models not having the problem is not directly supported by citations; needs evidence or references explicitly demonstrating the absence of the issue.",
          "start": 1198,
          "end": 1316
        },
        {
          "span_text": "We evaluate our model on three downstream tasks: automated essay scoring (AES), assessing writing quality (AWQ), and assessing discourse coherence (ADC).",
          "gpt_label": "Unsupported Claim",
          "reason": "First mention of established tasks/datasets lacks citations to the corresponding benchmarks or canonical works (guideline a).",
          "start": 3409,
          "end": 3561
        },
        {
          "span_text": "Since coherence is an essential factor in assessing text quality, many previous coherence models are evaluated on AES and AWQ.",
          "gpt_label": "Unsupported Claim",
          "reason": "Claim about prior work frequency lacks supporting citations to the studies that evaluate on AES and AWQ.",
          "start": 3657,
          "end": 3782
        },
        {
          "span_text": "ADC evaluates coherence models on informal texts such as emails and online reviews.",
          "gpt_label": "Unsupported Claim",
          "reason": "Description of a specific dataset/task should be accompanied by a citation at first mention (guideline a).",
          "start": 3783,
          "end": 3865
        },
        {
          "span_text": "In our evaluation, our model achieves state-of-the-art performance.",
          "gpt_label": "Unsupported Claim",
          "reason": "SOTA claim is a comparative/statistical statement without citation or evidence presented here; should reference or point to results to substantiate.",
          "start": 3866,
          "end": 3932
        }
      ],
      "Format": [
        {
          "span_text": "Sidner (1981Sidner ( , 1983",
          "gpt_label": "Format",
          "reason": "Garbled/malformed citation: duplicated author string, misplaced comma, and missing/incorrect parentheses for multiple years (should be something like \"Sidner (1981, 1983)\").",
          "start": 1369,
          "end": 1396
        }
      ],
      "Coherence": [
        {
          "span_text": "Our approach is not only linguistically more sound but also is in accord with the recent empirical study by O'Connor and Andreas (2021) who investigate what contextual information contributes to accurate predictions in transformer-based language models. Their experiments show that most usable information is captured by nouns and verbs. Their findings suggest that we can design better neural models by focusing on specific context words. Our work follows their findings by modeling entitybased coherence in an end-to-end framework to improve a neural coherence model.",
          "gpt_label": "Coherence",
          "reason": "The connection between the cited study (which highlights both nouns and verbs) and the authors’ specific choice to focus on entities (primarily nouns) is only implied, not explicitly justified. The transition across these sentences is abrupt, leaving unclear how the findings about nouns and verbs directly motivate an entity-only modeling decision.",
          "start": 2369,
          "end": 2934
        }
      ],
      "Lacks synthesis": [
        {
          "span_text": "Recent neural coherence models (Mesgar and Strube, 2018;Moon et al., 2019) encode the input document using large-scale pretrained language models (Peters et al., 2018). These neural models compute local coherence, semantic relations between items in adjacent sentences, on the basis of words and even sub-words.",
          "gpt_label": "Lacks synthesis",
          "reason": "This passage summarizes prior work and its characteristics without explicitly connecting these points to the authors’ own perspective or argument within the same span (the gap and motivation are only introduced in the following paragraph).",
          "start": 260,
          "end": 567
        }
      ]
    }
  },
  "paper_81.txt": {
    "filename": "paper_81.txt",
    "full_text": "Introduction\n\nThe dissemination of fake news has become an important social issue. For emergent complex events, human readers are usually exposed to multiple news documents, where some are real and others are fake. News documents from different sources naturally form a cluster of topically related documents. We notice that articles about the same topic may contain conflicting or complementary information, which can benefit the task of misinformation detection. An example is shown in Figure 1. As shown in the knowledge graph, the death of Rosanne Boyland in 2021 US Capitol attack is a shared event across all four documents. Each document is internally consistent, which makes it difficult to identify misinformation when judging each news separately. However, the three real news documents complement each other's statements regarding the death of Boyland, while the fake news document contradicts the other stories. Such crossdocument connections can be leveraged to help detect misinformation.\n\nMost existing work in fake news detection is limited to judging each document in isolation. In contrast, we propose a novel task of cross-document misinformation detection that aims to detect fake information from a cluster of topically related news documents. We conduct the task at both document level and event level. Each event describes a specific type of real-world event mentioned in the text (e.g., the death of Boyland in Figure 1), and usually involves certain participants to represent different aspects of the event (e.g., the death cause and the victim of the death event). Document-level detection aims to detect fake news documents. Eventlevel detection is a more fine-grained task that aims to detect fake events, thereby pinpointing specific fake information in news documents.\n\nExisting work on fine-grained misinformation detection detects fake knowledge triplets . However, we focus on identifying false events instead of relations or entities, because events are more important to storytelling, and easier to compare across multiple documents through cross-document coreference resolution.\n\nTo the best of our knowledge, there are no fake news detection datasets with clusters of topically related documents. Therefore, we construct 3 new benchmark datasets based on existing real news corpus with such clusters. Following Fung et al. (2021), we train a generator that generates a document from a knowledge graph (KG), and feed manipulated KGs into the generator to generate fake news documents. By tracking the manipulation operations, we also obtain supervision for event-level detection.\n\nWe further propose a detection system as shown in Figure 2. Given a cluster of documents, we first use an IE system (Lin et al., 2020) to construct a within-document KG for each document. Then, we connect the within-document KGs to form a crossdocument KG using cross-document event coreference resolution (Lai et al., 2021;Wen et al., 2021). Eventually, we use a heterogeneous graph neural network (GNN) to encode the cross-document KG and conduct detection at two levels.\n\nOur contributions are summarized as follows:\n\n1. We propose the novel task of cross-document misinformation detection, and conduct the task at two levels, document level and the more fine-grained event level. \n2. We construct 3 new datasets for our proposed task based on existing document clusters categorized by topics. \n3. We propose a detector that leverages crossdocument information and improve documentlevel detection by utilizing features produced by the event-level detector. Experiments on 3 datasets demonstrate that our method significantly outperforms existing methods.\n\n ",
    "all_spans": [
      {
        "span_text": "Most existing work in fake news detection is limited to judging each document in isolation.",
        "gpt_label": "Unsupported Claim",
        "reason": "This is a claim about the scope of prior work and should be supported with citations to representative studies.",
        "start": 995,
        "end": 1085
      },
      {
        "span_text": "Existing work on fine-grained misinformation detection detects fake knowledge triplets .",
        "gpt_label": "Unsupported Claim",
        "reason": "This references a specific line of prior work but provides no citations to the papers that propose detecting fake knowledge triplets.",
        "start": 1781,
        "end": 1868
      },
      {
        "span_text": "To the best of our knowledge, there are no fake news detection datasets with clusters of topically related documents.",
        "gpt_label": "Unsupported Claim",
        "reason": "This is a claim about the absence of datasets in prior work and should be substantiated with references (e.g., surveys or dataset papers) or a systematic search description.",
        "start": 2095,
        "end": 2211
      },
      {
        "span_text": "To the best of our knowledge, there are no fake news detection datasets with clusters of topically related documents. Therefore, we construct 3 new benchmark datasets based on existing real news corpus with such clusters. Following Fung et al. (2021), we train a generator that generates a document from a knowledge graph (KG), and feed manipulated KGs into the generator to generate fake news documents. By tracking the manipulation operations, we also obtain supervision for event-level detection.",
        "gpt_label": "Coherence",
        "reason": "The transition from constructing datasets from existing real news corpora to adopting a KG-to-text generator (Fung et al., 2021) is abrupt. It is not explicitly explained how KGs are derived from the real corpus, how generated fake documents integrate with the clustered datasets, or how these steps relate; the relationship across these sentences is implied rather than stated.",
        "start": 2095,
        "end": 2589
      },
      {
        "span_text": "Existing work on fine-grained misinformation detection detects fake knowledge triplets . However, we focus on identifying false events instead of relations or entities, because events are more important to storytelling, and easier to compare across multiple documents through cross-document coreference resolution.",
        "gpt_label": "Lacks synthesis",
        "reason": "This passage broadly references prior work without citation and then immediately contrasts with the authors’ approach without articulating a concrete limitation of triplet-based methods or a specific gap in the literature; it lacks integration of related work into a clear argument for why event-level detection is necessary.",
        "start": 1781,
        "end": 2093
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "Most existing work in fake news detection is limited to judging each document in isolation.",
          "gpt_label": "Unsupported Claim",
          "reason": "This is a claim about the scope of prior work and should be supported with citations to representative studies.",
          "start": 995,
          "end": 1085
        },
        {
          "span_text": "Existing work on fine-grained misinformation detection detects fake knowledge triplets .",
          "gpt_label": "Unsupported Claim",
          "reason": "This references a specific line of prior work but provides no citations to the papers that propose detecting fake knowledge triplets.",
          "start": 1781,
          "end": 1868
        },
        {
          "span_text": "To the best of our knowledge, there are no fake news detection datasets with clusters of topically related documents.",
          "gpt_label": "Unsupported Claim",
          "reason": "This is a claim about the absence of datasets in prior work and should be substantiated with references (e.g., surveys or dataset papers) or a systematic search description.",
          "start": 2095,
          "end": 2211
        }
      ],
      "Format": [],
      "Coherence": [
        {
          "span_text": "To the best of our knowledge, there are no fake news detection datasets with clusters of topically related documents. Therefore, we construct 3 new benchmark datasets based on existing real news corpus with such clusters. Following Fung et al. (2021), we train a generator that generates a document from a knowledge graph (KG), and feed manipulated KGs into the generator to generate fake news documents. By tracking the manipulation operations, we also obtain supervision for event-level detection.",
          "gpt_label": "Coherence",
          "reason": "The transition from constructing datasets from existing real news corpora to adopting a KG-to-text generator (Fung et al., 2021) is abrupt. It is not explicitly explained how KGs are derived from the real corpus, how generated fake documents integrate with the clustered datasets, or how these steps relate; the relationship across these sentences is implied rather than stated.",
          "start": 2095,
          "end": 2589
        }
      ],
      "Lacks synthesis": [
        {
          "span_text": "Existing work on fine-grained misinformation detection detects fake knowledge triplets . However, we focus on identifying false events instead of relations or entities, because events are more important to storytelling, and easier to compare across multiple documents through cross-document coreference resolution.",
          "gpt_label": "Lacks synthesis",
          "reason": "This passage broadly references prior work without citation and then immediately contrasts with the authors’ approach without articulating a concrete limitation of triplet-based methods or a specific gap in the literature; it lacks integration of related work into a clear argument for why event-level detection is necessary.",
          "start": 1781,
          "end": 2093
        }
      ]
    }
  },
  "paper_82.txt": {
    "filename": "paper_82.txt",
    "full_text": "Introduction\n\nNeural machine translation (NMT) (Bahdanau et al., 2014;Gehring et al., 2017;Vaswani et al., 2017) has made remarkable achievements in recent years. Generally, NMT models are trained to maximize the likelihood of the next target token given ground-truth tokens as inputs (Johansen and Juselius, 1990;Goodfellow et al., 2016). Due to the token imbalance phenomenon in natural language (Zipf, 1949), for an NMT model, the learning difficulties of different target tokens may be various. However, the vanilla NMT model equally weights the training losses of different target tokens, irrespective of their difficulties.\n\nRecently, various adaptive training approaches (Gu et al., 2020;Xu et al., 2021) have been proposed to alleviate the above problem for NMT. Generally, these approaches re-weight the losses of different target tokens based on specific statistical metrics. For example, Gu et al. (2020) take the token frequency as an indicator and encourage the NMT model to focus more on low-frequency tokens. Xu et al. (2021) further propose the bilingual mutual information (BMI) to measure the word mapping diversity between bilinguals, and down-weight the tokens with relatively lower BMI values.\n\nDespite their achievements, there are still limitations in these adaptive training approaches. Given that the standard translation model autoregressively makes predictions on the condition of previous tar-get contexts, we argue that the statistical metrics used in the above approaches ignore target context information and may assign inaccurate weights for target tokens. Specifically, although existing statistical metrics can reflect complex characteristics of target tokens (e.g., mapping diversity), they fail to model how these properties vary across different target contexts. Secondly, for the identical target tokens in different positions of a target sentence (e.g., two 'traffic' tokens in the Figure 1), they may be mapped from different source-side tokens, but such target-context-free metrics cannot distinguish the above different mappings. In summary, it is necessary to incorporate target context information into the above statistical metrics. One possible solution is to directly take target context information into account and conduct target-context-aware statistical calculations. But in this way, the calculation cost and storage overhead will become huge and unrealistic . Therefore, it is non-trivial to design a suitable target-context-aware statistical metric for adaptive training in the field of NMT.\n\nIn this paper, we aim to address the above issues in adaptive training methods. Firstly, we propose a novel target-context-aware metric, named Conditional Bilingual Mutual Information (CBMI), to measure the importance of different target tokens by their dependence on the source sentence. Specifically, we calculate CBMI by the mutual information between a target token and its source sentence on the condition of its target contexts. With the aid of target-context-aware calculations, CBMI can easily model the various characteristics of target tokens under different target contexts, and of course can distinguish identical target tokens with different source mappings. Regarding the computational efficiency, through decomposing the conditional joint distribution in the aforementioned mutual information, our CBMI can be formalized as the log quotient of the translation model probability and language model probability 3 . Therefore, CBMI can be efficiently calculated during model training without any pre-specific statistical calculations and huge storage overhead, which makes it feasible to supplement target context in-formation for statistical metrics. Subsequently, we design an adaptive training approach based on both the token-and sentence-level CBMI, which dynamically re-weights the training losses of the corresponding target tokens.\n\nWe evaluate our approach on the WMT14 English-German and WMT19 Chinese-English translation tasks. Experimental results on both datasets demonstrate that our approach can significantly outperform the Transformer baseline and other adaptive training methods. Further analyses reveal that CBMI can also reflect the adequacy of translation, and our CBMI-based adaptive training can improve translation adequacy meanwhile maintain fluency. The main contributions of this paper can be summarized as follows:\n\n• We propose a novel target-context-aware metric, named CBMI, which can reflect the importance of target tokens for NMT models. Theoretical analysis and experimental results show that CBMI is computationally efficient, which makes it feasible to complement target context information in statistical metrics.\n\n• We further propose an adaptive training approach based on both the token-and sentencelevel CMBI, which dynamically re-weights the training losses of target tokens.\n\n• Further analyses show that CBMI can also reflect the adequacy of translation, and CBMIbased adaptive training can improve translation adequacy meanwhile maintain fluency.\n\n ",
    "all_spans": [
      {
        "span_text": "But in this way, the calculation cost and storage overhead will become huge and unrealistic .",
        "gpt_label": "Unsupported Claim",
        "reason": "Asserts significant computational and storage burdens without citation or presented evidence/analysis to support the claim.",
        "start": 2293,
        "end": 2385
      },
      {
        "span_text": "WMT14 English-German and WMT19 Chinese-English translation tasks.",
        "gpt_label": "Unsupported Claim",
        "reason": "First mention of shared tasks/datasets lacks citations, which should be provided per academic conventions for datasets.",
        "start": 3897,
        "end": 3961
      },
      {
        "span_text": "3",
        "gpt_label": "Format",
        "reason": "Numeric citation/footnote marker lacks proper formatting (e.g., missing brackets or superscript) and is inconsistent with the author–year citation style used elsewhere.",
        "start": 3439,
        "end": 3440
      },
      {
        "span_text": "Neural machine translation (NMT) (Bahdanau et al., 2014;Gehring et al., 2017;Vaswani et al., 2017) has made remarkable achievements in recent years. Generally, NMT models are trained to maximize the likelihood of the next target token given ground-truth tokens as inputs (Johansen and Juselius, 1990;Goodfellow et al., 2016).",
        "gpt_label": "Coherence",
        "reason": "Two consecutive sentences cite different sets of works without explicitly linking them; the relationship between the foundational NMT works and the training objective citations (especially the unrelated Johansen and Juselius, 1990) is not explained, making the transition abrupt and the connection between cited works unclear.",
        "start": 14,
        "end": 333
      },
      {
        "span_text": "Recently, various adaptive training approaches (Gu et al., 2020;Xu et al., 2021) have been proposed to alleviate the above problem for NMT. Generally, these approaches re-weight the losses of different target tokens based on specific statistical metrics. For example, Gu et al. (2020) take the token frequency as an indicator and encourage the NMT model to focus more on low-frequency tokens. Xu et al. (2021) further propose the bilingual mutual information (BMI) to measure the word mapping diversity between bilinguals, and down-weight the tokens with relatively lower BMI values.",
        "gpt_label": "Lacks synthesis",
        "reason": "This paragraph summarizes prior work without articulating the authors’ perspective or explicitly connecting these methods to the paper’s own approach or identified gap within the same span; it describes contributions of others but does not synthesize them into an argument about what is missing or how the present work addresses it.",
        "start": 623,
        "end": 1198
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "But in this way, the calculation cost and storage overhead will become huge and unrealistic .",
          "gpt_label": "Unsupported Claim",
          "reason": "Asserts significant computational and storage burdens without citation or presented evidence/analysis to support the claim.",
          "start": 2293,
          "end": 2385
        },
        {
          "span_text": "WMT14 English-German and WMT19 Chinese-English translation tasks.",
          "gpt_label": "Unsupported Claim",
          "reason": "First mention of shared tasks/datasets lacks citations, which should be provided per academic conventions for datasets.",
          "start": 3897,
          "end": 3961
        }
      ],
      "Format": [
        {
          "span_text": "3",
          "gpt_label": "Format",
          "reason": "Numeric citation/footnote marker lacks proper formatting (e.g., missing brackets or superscript) and is inconsistent with the author–year citation style used elsewhere.",
          "start": 3439,
          "end": 3440
        }
      ],
      "Coherence": [
        {
          "span_text": "Neural machine translation (NMT) (Bahdanau et al., 2014;Gehring et al., 2017;Vaswani et al., 2017) has made remarkable achievements in recent years. Generally, NMT models are trained to maximize the likelihood of the next target token given ground-truth tokens as inputs (Johansen and Juselius, 1990;Goodfellow et al., 2016).",
          "gpt_label": "Coherence",
          "reason": "Two consecutive sentences cite different sets of works without explicitly linking them; the relationship between the foundational NMT works and the training objective citations (especially the unrelated Johansen and Juselius, 1990) is not explained, making the transition abrupt and the connection between cited works unclear.",
          "start": 14,
          "end": 333
        }
      ],
      "Lacks synthesis": [
        {
          "span_text": "Recently, various adaptive training approaches (Gu et al., 2020;Xu et al., 2021) have been proposed to alleviate the above problem for NMT. Generally, these approaches re-weight the losses of different target tokens based on specific statistical metrics. For example, Gu et al. (2020) take the token frequency as an indicator and encourage the NMT model to focus more on low-frequency tokens. Xu et al. (2021) further propose the bilingual mutual information (BMI) to measure the word mapping diversity between bilinguals, and down-weight the tokens with relatively lower BMI values.",
          "gpt_label": "Lacks synthesis",
          "reason": "This paragraph summarizes prior work without articulating the authors’ perspective or explicitly connecting these methods to the paper’s own approach or identified gap within the same span; it describes contributions of others but does not synthesize them into an argument about what is missing or how the present work addresses it.",
          "start": 623,
          "end": 1198
        }
      ]
    }
  },
  "paper_83.txt": {
    "filename": "paper_83.txt",
    "full_text": "Related Work\n\nThere is an important line of work that focuses on claim verification. This includes techniques that predict the veracity of a claim based on the text of the claim only (Rashkin et al., 2017), linguistic features (Popat et al., 2017), meta information about the claimant (e.g., name, job, party affiliation, veracity history) (Wang, 2017b), review articles (Augenstein et al., 2019;Shu et al., 2018;Nakov et al., 2021), as well as relevant articles returned by a search engine (Popat et al., 2018;Augenstein et al., 2019;Mishra and Setty, 2019). To the best of our knowledge, none of the existing work considers the problem of claim verification based on premise articles. There is an important distinction between articles returned by a search engine in previous work and the premise articles that we consider. The techniques that use a search engine to find articles related to a claim query the search engine after a fact checking website has published a review article and therefore end up retrieving articles that include the review article as well as other articles that summarize and/or discuss the verdict of the fact checking website. Hence they are tackling an entailment problem. In contrast, the premise articles that we consider are the source articles used by a fact checker before publishing a review article. Those articles contain relevant facts, but not a summary or discussion of the review article since they are published before the review article and in fact serve as premises for the review article.\n\nClosely related to claim verification is the problem of fake news detection. In this problem, the credibility of an entire news article is evaluated. The credibility of a news article can be estimated based on linguistic and textual features (Conroy et al., 2015;Reis et al., 2019;Li et al., 2019), discourse level structure (Karimi and Tang, 2019), network analysis (Conroy et al., 2015), knowledge graphs (Cui et al., 2020), inter-user behaviour dynamics (Gangireddy et al., 2020) or a combination of multiple modalities . Some techniques reorder the articles returned by a search engine based on their degree of credibility (Olteanu et al., 2013;Beylunioglu, 2020). An important task that can help the detection of fake news is the task of stance detection (Borges et al., 2019;Jwa et al., 2019), i.e., does the content of an article agree or disagree with the title of the article? The following surveys summarize existing work on fake news detection: (Kumar and Shah, 2018;Bondielli and Marcelloni, 2019).\n\n ",
    "all_spans": [
      {
        "span_text": "To the best of our knowledge, none of the existing work considers the problem of claim verification based on premise articles.",
        "gpt_label": "Unsupported Claim",
        "reason": "Claims novelty/absence of prior work without providing citations or contrasting evidence; assertions about prior literature require support.",
        "start": 549,
        "end": 674
      },
      {
        "span_text": "The techniques that use a search engine to find articles related to a claim query the search engine after a fact checking website has published a review article and therefore end up retrieving articles that include the review article as well as other articles that summarize and/or discuss the verdict of the fact checking website.",
        "gpt_label": "Unsupported Claim",
        "reason": "Makes specific claims about how prior methods operate and what they retrieve without citing supporting studies in this context.",
        "start": 813,
        "end": 1143
      },
      {
        "span_text": "or a combination of multiple modalities .",
        "gpt_label": "Unsupported Claim",
        "reason": "Asserts the existence of multimodal approaches but provides no representative citations.",
        "start": 1996,
        "end": 2036
      },
      {
        "span_text": "Some techniques reorder the articles returned by a search engine based on their degree of credibility (Olteanu et al., 2013;Beylunioglu, 2020). An important task that can help the detection of fake news is the task of stance detection (Borges et al., 2019;Jwa et al., 2019), i.e., does the content of an article agree or disagree with the title of the article?",
        "gpt_label": "Coherence",
        "reason": "The transition from reordering search results to stance detection is abrupt. The relationship between these two cited lines of work is only implied through the general fake news context and not explicitly explained, weakening inter-sentence coherence.",
        "start": 2037,
        "end": 2391
      },
      {
        "span_text": "Closely related to claim verification is the problem of fake news detection. In this problem, the credibility of an entire news article is evaluated. The credibility of a news article can be estimated based on linguistic and textual features (Conroy et al., 2015;Reis et al., 2019;Li et al., 2019), discourse level structure (Karimi and Tang, 2019), network analysis (Conroy et al., 2015), knowledge graphs (Cui et al., 2020), inter-user behaviour dynamics (Gangireddy et al., 2020) or a combination of multiple modalities . Some techniques reorder the articles returned by a search engine based on their degree of credibility (Olteanu et al., 2013;Beylunioglu, 2020). An important task that can help the detection of fake news is the task of stance detection (Borges et al., 2019;Jwa et al., 2019), i.e., does the content of an article agree or disagree with the title of the article? The following surveys summarize existing work on fake news detection: (Kumar and Shah, 2018;Bondielli and Marcelloni, 2019).",
        "gpt_label": "Lacks synthesis",
        "reason": "This paragraph lists related areas, techniques, and surveys for fake news detection without connecting them to the authors' specific problem, explaining their relevance, or articulating a gap that the present work addresses.",
        "start": 1521,
        "end": 2515
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "To the best of our knowledge, none of the existing work considers the problem of claim verification based on premise articles.",
          "gpt_label": "Unsupported Claim",
          "reason": "Claims novelty/absence of prior work without providing citations or contrasting evidence; assertions about prior literature require support.",
          "start": 549,
          "end": 674
        },
        {
          "span_text": "The techniques that use a search engine to find articles related to a claim query the search engine after a fact checking website has published a review article and therefore end up retrieving articles that include the review article as well as other articles that summarize and/or discuss the verdict of the fact checking website.",
          "gpt_label": "Unsupported Claim",
          "reason": "Makes specific claims about how prior methods operate and what they retrieve without citing supporting studies in this context.",
          "start": 813,
          "end": 1143
        },
        {
          "span_text": "or a combination of multiple modalities .",
          "gpt_label": "Unsupported Claim",
          "reason": "Asserts the existence of multimodal approaches but provides no representative citations.",
          "start": 1996,
          "end": 2036
        }
      ],
      "Format": [],
      "Coherence": [
        {
          "span_text": "Some techniques reorder the articles returned by a search engine based on their degree of credibility (Olteanu et al., 2013;Beylunioglu, 2020). An important task that can help the detection of fake news is the task of stance detection (Borges et al., 2019;Jwa et al., 2019), i.e., does the content of an article agree or disagree with the title of the article?",
          "gpt_label": "Coherence",
          "reason": "The transition from reordering search results to stance detection is abrupt. The relationship between these two cited lines of work is only implied through the general fake news context and not explicitly explained, weakening inter-sentence coherence.",
          "start": 2037,
          "end": 2391
        }
      ],
      "Lacks synthesis": [
        {
          "span_text": "Closely related to claim verification is the problem of fake news detection. In this problem, the credibility of an entire news article is evaluated. The credibility of a news article can be estimated based on linguistic and textual features (Conroy et al., 2015;Reis et al., 2019;Li et al., 2019), discourse level structure (Karimi and Tang, 2019), network analysis (Conroy et al., 2015), knowledge graphs (Cui et al., 2020), inter-user behaviour dynamics (Gangireddy et al., 2020) or a combination of multiple modalities . Some techniques reorder the articles returned by a search engine based on their degree of credibility (Olteanu et al., 2013;Beylunioglu, 2020). An important task that can help the detection of fake news is the task of stance detection (Borges et al., 2019;Jwa et al., 2019), i.e., does the content of an article agree or disagree with the title of the article? The following surveys summarize existing work on fake news detection: (Kumar and Shah, 2018;Bondielli and Marcelloni, 2019).",
          "gpt_label": "Lacks synthesis",
          "reason": "This paragraph lists related areas, techniques, and surveys for fake news detection without connecting them to the authors' specific problem, explaining their relevance, or articulating a gap that the present work addresses.",
          "start": 1521,
          "end": 2515
        }
      ]
    }
  },
  "paper_84.txt": {
    "filename": "paper_84.txt",
    "full_text": "Introduction\n\nText-to-SQL parsing is the task of mapping natural language questions to executable SQL queries on relational databases (Zhong et al., 2017). It provides an easy way for common users unfamiliar with query languages to access large databases and has attracted great attention. Recently, lexicological alignments, which align question phrases to their corresponding SQL query fragments, have been proved to be very helpful in improving parsing performance (Shi et al., 2020). As shown in Figure 1, the token \"competitor\" should be aligned to \"c1\" in the SQL query. To capture such alignments, several attention-based models were proposed (Shi et al., 2020;Lei et al., 2020;Liu et al., 2021), which employ the attention weights among tokens to indicate the alignments. Specifically, they use an attention module to perform schema linking at the encoding stage (Lei et al., 2020;Liu et al., 2021), and may use another attention to align each output token to its corresponding input tokens at the decoding stage (Shi et al., 2020).  However, we argue that the attention mechanism is not an appropriate way to capture and leverage lexico-logical alignments. It mainly has the following two problems. First, the standard attention can only model alignments at the token level rather than the phrase level, while there are many multi-granular, non-continuous alignments in the text-to-SQL task. For the example in Figure 1, \"order by . . . limit 1\" is a SQL keyword pattern representing a superlative operation. However, the standard attention module can only align \"order\", \"by\", \"limit\", and \"1\" to \"the longest\" token by token, rather than regarding them as a whole. It may confuse the decoder and lead to the failure to generate this pattern correctly (Herzig and Berant, 2020). Second, traditional attentionbased approaches are prone to overfitting the training data, which is harmful to the model's generalization capability. It is not only the domain generalization (Dong et al., 2019) but also the compositional generalization (Herzig and Berant, 2020).\n\nTo solve the aforementioned problems, we propose a neural parsing framework to leverage explicit lexico-logical alignments. Dong et al. (2019) have pointed out that if we align question tokens to columns or values in databases before parsing, it will help to improve the model's generalization among different domains (databases). Motivated by this, our framework consists of two steps. Specifi-cally, we first implement a simple model to obtain possible lexico-logical alignments before parsing. While in the second step, we inject such alignments into a standard seq2seq parser by treating them as additional contexts, similar to \"prompt information\" or \"evidence\" in machine reading comprehension (Mihaylov and Frank, 2018;Tu et al., 2020;Niu et al., 2020). Moreover, to alleviate the negative effects on the parser caused by noise alignments, we propose a data augmentation method that adds noisy alignments during the training procedure. Experimental results on an open-released dataset, SQUALL (Shi et al., 2020), show that our framework achieves state-of-the-art performance and obtains an absolute improvement of 3.4% compared with existing attention-based models.\n\n ",
    "all_spans": [
      {
        "span_text": "and has attracted great attention.",
        "gpt_label": "Unsupported Claim",
        "reason": "Asserts widespread interest without providing a citation to substantiate the claim.",
        "start": 253,
        "end": 286
      },
      {
        "span_text": "there are many multi-granular, non-continuous alignments in the text-to-SQL task.",
        "gpt_label": "Unsupported Claim",
        "reason": "Claims a specific characteristic of the task without evidence or citation.",
        "start": 1303,
        "end": 1383
      },
      {
        "span_text": "traditional attentionbased approaches are prone to overfitting the training data",
        "gpt_label": "Unsupported Claim",
        "reason": "General claim about a class of methods lacking supporting references.",
        "start": 1774,
        "end": 1854
      },
      {
        "span_text": "achieves state-of-the-art performance and obtains an absolute improvement of 3.4% compared with existing attention-based models.",
        "gpt_label": "Unsupported Claim",
        "reason": "SOTA and improvement claims reference prior work and statistics but provide no citations to specific baselines.",
        "start": 3077,
        "end": 3203
      },
      {
        "span_text": "Specifi-cally, we first implement a simple model to obtain possible lexico-logical alignments before parsing. While in the second step, we inject such alignments into a standard seq2seq parser by treating them as additional contexts, similar to \"prompt information\" or \"evidence\" in machine reading comprehension (Mihaylov and Frank, 2018;Tu et al., 2020;Niu et al., 2020).",
        "gpt_label": "Coherence",
        "reason": "The transition from describing the two-step framework to invoking machine reading comprehension works is abrupt; the text does not explicitly explain how those cited MRC papers relate to or justify the proposed alignment-injection step. The connection is only implied by \"similar to,\" leaving the relationship between the cited works and the current method unclear across these sentences.",
        "start": 2426,
        "end": 2795
      },
      {
        "span_text": "It is not only the domain generalization (Dong et al., 2019) but also the compositional generalization (Herzig and Berant, 2020).",
        "gpt_label": "Lacks synthesis",
        "reason": "This sentence cites prior work on types of generalization without explaining how those works substantiate the claim about attention-based overfitting or how they relate to the paper’s specific gap or approach, thus not integrating the citations into the argument.",
        "start": 1914,
        "end": 2041
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "and has attracted great attention.",
          "gpt_label": "Unsupported Claim",
          "reason": "Asserts widespread interest without providing a citation to substantiate the claim.",
          "start": 253,
          "end": 286
        },
        {
          "span_text": "there are many multi-granular, non-continuous alignments in the text-to-SQL task.",
          "gpt_label": "Unsupported Claim",
          "reason": "Claims a specific characteristic of the task without evidence or citation.",
          "start": 1303,
          "end": 1383
        },
        {
          "span_text": "traditional attentionbased approaches are prone to overfitting the training data",
          "gpt_label": "Unsupported Claim",
          "reason": "General claim about a class of methods lacking supporting references.",
          "start": 1774,
          "end": 1854
        },
        {
          "span_text": "achieves state-of-the-art performance and obtains an absolute improvement of 3.4% compared with existing attention-based models.",
          "gpt_label": "Unsupported Claim",
          "reason": "SOTA and improvement claims reference prior work and statistics but provide no citations to specific baselines.",
          "start": 3077,
          "end": 3203
        }
      ],
      "Format": [],
      "Coherence": [
        {
          "span_text": "Specifi-cally, we first implement a simple model to obtain possible lexico-logical alignments before parsing. While in the second step, we inject such alignments into a standard seq2seq parser by treating them as additional contexts, similar to \"prompt information\" or \"evidence\" in machine reading comprehension (Mihaylov and Frank, 2018;Tu et al., 2020;Niu et al., 2020).",
          "gpt_label": "Coherence",
          "reason": "The transition from describing the two-step framework to invoking machine reading comprehension works is abrupt; the text does not explicitly explain how those cited MRC papers relate to or justify the proposed alignment-injection step. The connection is only implied by \"similar to,\" leaving the relationship between the cited works and the current method unclear across these sentences.",
          "start": 2426,
          "end": 2795
        }
      ],
      "Lacks synthesis": [
        {
          "span_text": "It is not only the domain generalization (Dong et al., 2019) but also the compositional generalization (Herzig and Berant, 2020).",
          "gpt_label": "Lacks synthesis",
          "reason": "This sentence cites prior work on types of generalization without explaining how those works substantiate the claim about attention-based overfitting or how they relate to the paper’s specific gap or approach, thus not integrating the citations into the argument.",
          "start": 1914,
          "end": 2041
        }
      ]
    }
  },
  "paper_85.txt": {
    "filename": "paper_85.txt",
    "full_text": "Related Work\n\nDefending and generating adversarial examples (Jia et al., 2019; have been mostly explored in NLP since the reign of pre-trained language models (LMs) (Devlin et al., 2019). Li et al. (2020); Garg and Ramakrishnan (2020); Morris et al. (2020) show that substituting words in a sentence with masked LMs (Devlin et al., 2019;Liu et al., 2019) can successfully mislead the classification and entailment model predictions to be incorrect. Template-based (McCoy et al., 2019;Glockner et al., 2018) and manually crafted (Gardner et al., 2020) perturbations on evaluation datasets have also been studied for textual entailment.\n\nLanguage-based adversarial examples can be collected to study the robustness of vision-language models as well. Shekhar et al. (2017) introduces FOIL-COCO dataset to evaluate the visionlanguage model's decision when associating images with both correct and \"foil\" captions. Hendricks and Nematzadeh (2021) show that vision-language Transformers are worse at verb understanding than nouns. New versions of the VQA dataset (Antol et al., 2015) are proposed to study robustness of VQA models (Shah et al., 2019;Li et al., 2021). Our work is different in that we use pre-trained LMs to introduce perturbations and evaluate robustness of video-language models.\n\n ",
    "all_spans": [
      {
        "span_text": "have been mostly explored in NLP since the reign of pre-trained language models (LMs) (Devlin et al., 2019).",
        "gpt_label": "Unsupported Claim",
        "reason": "This is a broad, field-level trend claim (“mostly explored in NLP since...”) that requires multiple citations or evidence beyond a single reference to a language model paper; it asserts a temporal and prevalence shift without sufficient supporting sources.",
        "start": 78,
        "end": 184
      },
      {
        "span_text": "(Jia et al., 2019;",
        "gpt_label": "Format",
        "reason": "Malformed parenthetical citation: missing closing parenthesis and stray semicolon.",
        "start": 60,
        "end": 77
      },
      {
        "span_text": "Li et al. (2020);",
        "gpt_label": "Format",
        "reason": "Incorrect citation style: narrative citation followed by a semicolon; semicolons are for parenthetical lists.",
        "start": 185,
        "end": 201
      },
      {
        "span_text": "Garg and Ramakrishnan (2020);",
        "gpt_label": "Format",
        "reason": "Incorrect citation style: narrative citation followed by a semicolon; semicolons are for parenthetical lists.",
        "start": 202,
        "end": 231
      },
      {
        "span_text": "Language-based adversarial examples can be collected to study the robustness of vision-language models as well. Shekhar et al. (2017) introduces FOIL-COCO dataset to evaluate the visionlanguage model's decision when associating images with both correct and \"foil\" captions. Hendricks and Nematzadeh (2021) show that vision-language Transformers are worse at verb understanding than nouns. New versions of the VQA dataset (Antol et al., 2015) are proposed to study robustness of VQA models (Shah et al., 2019;Li et al., 2021).",
        "gpt_label": "Coherence",
        "reason": "These sentences list disparate works without explicit transitions or explanations of how each relates to adversarial examples or to one another. The connections between FOIL-COCO, verb/noun understanding, and VQA robustness are implied rather than stated, creating abrupt shifts and unclear relationships across multiple sentences.",
        "start": 624,
        "end": 1141
      },
      {
        "span_text": "Our work is different in that we use pre-trained LMs to introduce perturbations and evaluate robustness of video-language models.",
        "gpt_label": "Lacks synthesis",
        "reason": "This sentence asserts a difference without explicitly identifying the gap in prior work or synthesizing how the cited studies lead to the authors' approach or motivation; it follows a list of related works with a contribution claim but lacks clear argumentation connecting them.",
        "start": 1142,
        "end": 1270
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "have been mostly explored in NLP since the reign of pre-trained language models (LMs) (Devlin et al., 2019).",
          "gpt_label": "Unsupported Claim",
          "reason": "This is a broad, field-level trend claim (“mostly explored in NLP since...”) that requires multiple citations or evidence beyond a single reference to a language model paper; it asserts a temporal and prevalence shift without sufficient supporting sources.",
          "start": 78,
          "end": 184
        }
      ],
      "Format": [
        {
          "span_text": "(Jia et al., 2019;",
          "gpt_label": "Format",
          "reason": "Malformed parenthetical citation: missing closing parenthesis and stray semicolon.",
          "start": 60,
          "end": 77
        },
        {
          "span_text": "Li et al. (2020);",
          "gpt_label": "Format",
          "reason": "Incorrect citation style: narrative citation followed by a semicolon; semicolons are for parenthetical lists.",
          "start": 185,
          "end": 201
        },
        {
          "span_text": "Garg and Ramakrishnan (2020);",
          "gpt_label": "Format",
          "reason": "Incorrect citation style: narrative citation followed by a semicolon; semicolons are for parenthetical lists.",
          "start": 202,
          "end": 231
        }
      ],
      "Coherence": [
        {
          "span_text": "Language-based adversarial examples can be collected to study the robustness of vision-language models as well. Shekhar et al. (2017) introduces FOIL-COCO dataset to evaluate the visionlanguage model's decision when associating images with both correct and \"foil\" captions. Hendricks and Nematzadeh (2021) show that vision-language Transformers are worse at verb understanding than nouns. New versions of the VQA dataset (Antol et al., 2015) are proposed to study robustness of VQA models (Shah et al., 2019;Li et al., 2021).",
          "gpt_label": "Coherence",
          "reason": "These sentences list disparate works without explicit transitions or explanations of how each relates to adversarial examples or to one another. The connections between FOIL-COCO, verb/noun understanding, and VQA robustness are implied rather than stated, creating abrupt shifts and unclear relationships across multiple sentences.",
          "start": 624,
          "end": 1141
        }
      ],
      "Lacks synthesis": [
        {
          "span_text": "Our work is different in that we use pre-trained LMs to introduce perturbations and evaluate robustness of video-language models.",
          "gpt_label": "Lacks synthesis",
          "reason": "This sentence asserts a difference without explicitly identifying the gap in prior work or synthesizing how the cited studies lead to the authors' approach or motivation; it follows a list of related works with a contribution claim but lacks clear argumentation connecting them.",
          "start": 1142,
          "end": 1270
        }
      ]
    }
  },
  "paper_86.txt": {
    "filename": "paper_86.txt",
    "full_text": "Introduction\n\nInformation extraction (IE) is a task that aims to extract information of interest from text data and represent the extracted information in a structured form. Traditional IE tasks include named entity recognition which recognizes entities and their types (Huang et al., 2015; Ma and Hovy, 2016; Lample et al., 2016; Devlin et al., 2019), relation extraction which identifies the relationships between entities (Zheng et al., 2017; Zeng et al., 2018; Zhong and Chen, 2020), etc. Since the results of IE are structured, they can be easily used by computer systems in different applications such as text mining.\n\nIn this work, we study IE in a new setting, referred to as text-to-table. First, the system receives a training dataset containing text-table pairs. Each text-table pair contains a text and a table (or tables) representing information extracted from the text. The system learns a model for information extraction. Next, the system employs the learned model to conduct information extraction from a new text and outputs the result in a table (or tables). Figure 1 gives an example of text-to-table, where the input (above) is a report of a basketball game, and the output (below) is two tables summarizing the scores of the teams and players from the input.\n\nText-to-table is unique compared to the traditional IE approaches. First, it is mainly designed to extract structured data in a complex form from a long text. As in the example in Figure 1, extraction of information is performed from the entire document. The extracted information contains multiple types of scores of teams and players in a basketball game structured in table format. Second, the schemas for extraction are implicitly included in the training data, and there is no need to explicitly define the schemas. This reduces the need for manual efforts for schema design and annotations.\n\nOur work is inspired by research on the so-called table-to-text (or data-to-text) problem, which is the task of generating a description for a given table . Table -to-text is useful in applications where the content of a table needs to be described in natural language. Thus, text-to-table can be regarded as an inverse problem of table-to-text. However, there are also differences. Most notably, their applications are different. Text-to-table can be applied to document summarization, text mining, etc.\n\nIn this work, we formalize text-to-table as a sequence-to-sequence (seq2seq) task. More specifically, we translate the text into a sequence representation of a table (or tables), where the schema of the table is implicitly contained in the representation. We also build the seq2seq model on top of a pre-trained language model, which is the stateof-the-art approach for seq2seq tasks (Lewis et al., 2019;Raffel et al., 2020). Although the approach is a natural application of existing technologies, as far as we know, there has been no previous study to investigate to what extent the approach works. We also develop a new method for text-to-table within the seq2seq approach with two additional techniques, table constraint and table relation embeddings. Table constraint controls the creation of rows in a table and table relation embeddings affect the alignments between cells and their row headers and column headers. Both are to make the generated table well-formulated.\n\nThe approach to IE based on seq2seq has already been proposed. Methods for conducting individual tasks of relation extraction (Zeng et al., 2018;Nayak and Ng, 2020), named entity recognition (Chen and Moschitti, 2018;Yan et al., 2021), and event extraction (Lu et al., 2021) have been developed. Methods for jointly performing multiple tasks of named entity recognition, relation extraction, and event extraction have also been devised (Paolini et al., 2021). Most of the methods exploit suitable pre-trained models such as BERT. However, all the existing methods rely on pre-defined schemas for extraction. Moreover, their models are designed to extract information from short texts, rather than long texts, and extract information with simple structures (such as an entity and its type), rather than information with complicated structures (such as a table ).\n\nWe conduct extensive experiments on four datasets. Results show that the vanilla seq2seq model fine-tuned from BART (Lewis et al., 2019) can outperform the state-of-the-art IE models finetuned from BERT (Devlin et al., 2019;Zhong and Chen, 2020). Furthermore, results show that our proposed approach to text-to-table with the two techniques can further improve the extraction accuracies. We also summarize the challenging issues with the seq2seq approach to text-to-table for future research.\n\nOur contributions are summarized as follows:\n\n1. We propose the new task of text-to-table for IE. We derive four new datasets for the task from existing datasets. 2. We formalize the task as a seq2seq problem and propose a new method within the seq2seq approach using the techniques of Traditionally, researchers formalize the task as a language understanding problem. The state-ofthe-art methods for NER perform the task on the basis of the pre-trained language model BERT (Devlin et al., 2019). The pipeline approach to RE divides the problem into NER and relation classification, and conducts the two sub-tasks in a sequential manner (Zhong and Chen, 2020), while the end-to-end approach jointly carries out the two sub-tasks (Zheng et al., 2017;Zeng et al., 2018;. The state-of-the-art methods for EE also employ BERT and usually jointly train the models with other tasks such as NER and RE Zhang et al., 2019;Lin et al., 2020). All the methods assume the use of pre-defined schemas (e.g., entity types for NER, entity and relation types for RE, and event templates for EE). Besides, most methods are designed for extraction from short texts. Therefore, existing methods for IE cannot be directly applied to text-to-table.\n\nAnother series of related work is open information extraction (OpenIE), which aims to extract information from texts without relying on explicitly defined schemas (Banko et al., 2007;Wu and Weld, 2010;Mausam et al., 2012;Stanovsky et al., 2018;Zhan and Zhao, 2020). However, OpenIE aims to extract information with simple structures (i.e., relation tuples) from short texts, and the methods in OpenIE cannot be directly applied to text-to-table . IE is also conducted at document level, referred to as doc-level IE. For example, some NER methods directly perform NER on a long document (Strubell et al., 2017;Luo et al., 2018), and others encode each sentence in a document, use attention to fuse document-level information, and perform NER on each sentence (Hu et al., 2020;Xu et al., 2018). There are also RE methods that predict the relationships between entities in a document (Yao et al., 2019;Nan et al., 2020a). However, existing doc-level IE approaches usually do not consider extraction of complex relations between many items.\n\nSequence-to-sequence (seq2seq) is the general problem of transforming one text into another text (Sutskever et al., 2014;Bahdanau et al., 2014), which includes machine translation, text summarization, etc. The use of the pre-trained language models of BART (Lewis et al., 2019) and T5 (Raffel et al., 2020) can significantly boost the performances of seq2seq, such as machine translation (Lewis et al., 2019;Raffel et al., 2020;) and text summarization (Lewis et al., 2019;Raffel et al., 2020;.\n\nRecently, some researchers also formalize the IE problems as seq2seq, that is, transforming the input text into an internal representation. One advantage is that one can employ a single model to extract multiple types of information. Results show that this approach works better than or equally well as the traditional approach of language understanding, in RE (Zeng et al., 2018;Nayak and Ng, 2020), NER (Chen and Moschitti, 2018;Yan et al., 2021) and EE (Lu et al., 2021). Methods for jointly performing multiple tasks including NER, RE and EE have also been devised (Paolini et al., 2021).\n\nData-to-text aims to generate natural language descriptions from the input structured data such as sport commentaries (Wiseman et al., 2017). The structured data is usually represented as tables (Wiseman et al., 2017;Thomson et al., 2020;, sets of table cells (Parikh et al., 2020;Bao et al., 2018), semantic representations (Novikova et al., 2017), or sets of relation triples (Gardent et al., 2017;Nan et al., 2020b). The task requires the model to select the salient information from the data, organize it in a logical order, and generate an accurate and fluent natural language description (Wiseman et al., 2017). Data-to-text models usually adopt the encoder-decoder architecture. The encoders are specifically designed to model the input data, such as multi-layer perceptron (Puduppully et al., 2019a,b), recurrent neural network (Juraska et al., 2018;Shen et al., 2020), graph neural network (Marcheggiani and Perez-Beltrachini, 2018;Koncel-Kedziorski et al., 2019), or Transformer (Gong et al., 2019).\n\n ",
    "all_spans": [
      {
        "span_text": "Our work is inspired by research on the so-called table-to-text (or data-to-text) problem, which is the task of generating a description for a given table .",
        "gpt_label": "Unsupported Claim",
        "reason": "First mention of a research area (table-to-text/data-to-text) lacks citation to representative works.",
        "start": 1861,
        "end": 2016
      },
      {
        "span_text": "Most of the methods exploit suitable pre-trained models such as BERT.",
        "gpt_label": "Unsupported Claim",
        "reason": "Generalization about prior IE-as-seq2seq methods using BERT is made without supporting citations.",
        "start": 3782,
        "end": 3850
      },
      {
        "span_text": "However, all the existing methods rely on pre-defined schemas for extraction.",
        "gpt_label": "Unsupported Claim",
        "reason": "Broad claim about limitations of existing methods is not accompanied by citations.",
        "start": 3851,
        "end": 3927
      },
      {
        "span_text": "Moreover, their models are designed to extract information from short texts, rather than long texts, and extract information with simple structures (such as an entity and its type), rather than information with complicated structures (such as a table ).",
        "gpt_label": "Unsupported Claim",
        "reason": "Sweeping characterization of prior work (short texts/simple structures) lacks citations to substantiate it.",
        "start": 3928,
        "end": 4180
      },
      {
        "span_text": "Traditionally, researchers formalize the task as a language understanding problem.",
        "gpt_label": "Unsupported Claim",
        "reason": "Statement about the conventional formulation in prior work is not supported with citations.",
        "start": 4952,
        "end": 5033
      },
      {
        "span_text": "All the methods assume the use of pre-defined schemas (e.g., entity types for NER, entity and relation types for RE, and event templates for EE).",
        "gpt_label": "Unsupported Claim",
        "reason": "Another broad claim about assumptions in existing methods is presented without citations.",
        "start": 5590,
        "end": 5732
      },
      {
        "span_text": "Besides, most methods are designed for extraction from short texts.",
        "gpt_label": "Unsupported Claim",
        "reason": "Generalization about most prior methods targeting short texts lacks evidence or references.",
        "start": 5733,
        "end": 5799
      },
      {
        "span_text": "However, OpenIE aims to extract information with simple structures (i.e., relation tuples) from short texts, and the methods in OpenIE cannot be directly applied to text-to-table .",
        "gpt_label": "Unsupported Claim",
        "reason": "Claim about OpenIE limitations and inapplicability to the proposed setting is not directly supported by citations.",
        "start": 6142,
        "end": 6319
      },
      {
        "span_text": "However, existing doc-level IE approaches usually do not consider extraction of complex relations between many items.",
        "gpt_label": "Unsupported Claim",
        "reason": "Assertion about limitations of doc-level IE lacks citations to prior analyses or examples.",
        "start": 6783,
        "end": 6899
      },
      {
        "span_text": "2. We formalize the task as a seq2seq problem and propose a new method within the seq2seq approach using the techniques of Traditionally, researchers formalize the task as a language understanding problem. The state-ofthe-art methods for NER perform the task on the basis of the pre-trained language model BERT (Devlin et al., 2019). The pipeline approach to RE divides the problem into NER and relation classification, and conducts the two sub-tasks in a sequential manner (Zhong and Chen, 2020), while the end-to-end approach jointly carries out the two sub-tasks (Zheng et al., 2017;Zeng et al., 2018;. The state-of-the-art methods for EE also employ BERT and usually jointly train the models with other tasks such as NER and RE Zhang et al., 2019;Lin et al., 2020). All the methods assume the use of pre-defined schemas (e.g., entity types for NER, entity and relation types for RE, and event templates for EE). Besides, most methods are designed for extraction from short texts. Therefore, existing methods for IE cannot be directly applied to text-to-table.",
        "gpt_label": "Coherence",
        "reason": "The contribution list abruptly shifts into a literature review without transition or explanation, breaking the logical flow. The phrase \"using the techniques of\" is left incomplete, and subsequent sentences about NER/RE/EE methods are not explicitly tied back to the stated contribution. The relationship between the contribution and the cited works is implied but not stated, causing multi-sentence coherence issues.",
        "start": 4830,
        "end": 5878
      },
      {
        "span_text": "2. We formalize the task as a seq2seq problem and propose a new method within the seq2seq approach using the techniques of Traditionally, researchers formalize the task as a language understanding problem. The state-ofthe-art methods for NER perform the task on the basis of the pre-trained language model BERT (Devlin et al., 2019). The pipeline approach to RE divides the problem into NER and relation classification, and conducts the two sub-tasks in a sequential manner (Zhong and Chen, 2020), while the end-to-end approach jointly carries out the two sub-tasks (Zheng et al., 2017;Zeng et al., 2018;. The state-of-the-art methods for EE also employ BERT and usually jointly train the models with other tasks such as NER and RE Zhang et al., 2019;Lin et al., 2020). All the methods assume the use of pre-defined schemas (e.g., entity types for NER, entity and relation types for RE, and event templates for EE). Besides, most methods are designed for extraction from short texts. Therefore, existing methods for IE cannot be directly applied to text-to-table.",
        "gpt_label": "Lacks synthesis",
        "reason": "This contribution bullet shifts into a list of prior works and their properties without integrating how they motivate or inform the proposed method. It summarizes citations and generic limitations but does not explicitly connect them to the authors’ techniques or clearly articulate the specific gap their approach addresses.",
        "start": 4830,
        "end": 5878
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "Our work is inspired by research on the so-called table-to-text (or data-to-text) problem, which is the task of generating a description for a given table .",
          "gpt_label": "Unsupported Claim",
          "reason": "First mention of a research area (table-to-text/data-to-text) lacks citation to representative works.",
          "start": 1861,
          "end": 2016
        },
        {
          "span_text": "Most of the methods exploit suitable pre-trained models such as BERT.",
          "gpt_label": "Unsupported Claim",
          "reason": "Generalization about prior IE-as-seq2seq methods using BERT is made without supporting citations.",
          "start": 3782,
          "end": 3850
        },
        {
          "span_text": "However, all the existing methods rely on pre-defined schemas for extraction.",
          "gpt_label": "Unsupported Claim",
          "reason": "Broad claim about limitations of existing methods is not accompanied by citations.",
          "start": 3851,
          "end": 3927
        },
        {
          "span_text": "Moreover, their models are designed to extract information from short texts, rather than long texts, and extract information with simple structures (such as an entity and its type), rather than information with complicated structures (such as a table ).",
          "gpt_label": "Unsupported Claim",
          "reason": "Sweeping characterization of prior work (short texts/simple structures) lacks citations to substantiate it.",
          "start": 3928,
          "end": 4180
        },
        {
          "span_text": "Traditionally, researchers formalize the task as a language understanding problem.",
          "gpt_label": "Unsupported Claim",
          "reason": "Statement about the conventional formulation in prior work is not supported with citations.",
          "start": 4952,
          "end": 5033
        },
        {
          "span_text": "All the methods assume the use of pre-defined schemas (e.g., entity types for NER, entity and relation types for RE, and event templates for EE).",
          "gpt_label": "Unsupported Claim",
          "reason": "Another broad claim about assumptions in existing methods is presented without citations.",
          "start": 5590,
          "end": 5732
        },
        {
          "span_text": "Besides, most methods are designed for extraction from short texts.",
          "gpt_label": "Unsupported Claim",
          "reason": "Generalization about most prior methods targeting short texts lacks evidence or references.",
          "start": 5733,
          "end": 5799
        },
        {
          "span_text": "However, OpenIE aims to extract information with simple structures (i.e., relation tuples) from short texts, and the methods in OpenIE cannot be directly applied to text-to-table .",
          "gpt_label": "Unsupported Claim",
          "reason": "Claim about OpenIE limitations and inapplicability to the proposed setting is not directly supported by citations.",
          "start": 6142,
          "end": 6319
        },
        {
          "span_text": "However, existing doc-level IE approaches usually do not consider extraction of complex relations between many items.",
          "gpt_label": "Unsupported Claim",
          "reason": "Assertion about limitations of doc-level IE lacks citations to prior analyses or examples.",
          "start": 6783,
          "end": 6899
        }
      ],
      "Format": [],
      "Coherence": [
        {
          "span_text": "2. We formalize the task as a seq2seq problem and propose a new method within the seq2seq approach using the techniques of Traditionally, researchers formalize the task as a language understanding problem. The state-ofthe-art methods for NER perform the task on the basis of the pre-trained language model BERT (Devlin et al., 2019). The pipeline approach to RE divides the problem into NER and relation classification, and conducts the two sub-tasks in a sequential manner (Zhong and Chen, 2020), while the end-to-end approach jointly carries out the two sub-tasks (Zheng et al., 2017;Zeng et al., 2018;. The state-of-the-art methods for EE also employ BERT and usually jointly train the models with other tasks such as NER and RE Zhang et al., 2019;Lin et al., 2020). All the methods assume the use of pre-defined schemas (e.g., entity types for NER, entity and relation types for RE, and event templates for EE). Besides, most methods are designed for extraction from short texts. Therefore, existing methods for IE cannot be directly applied to text-to-table.",
          "gpt_label": "Coherence",
          "reason": "The contribution list abruptly shifts into a literature review without transition or explanation, breaking the logical flow. The phrase \"using the techniques of\" is left incomplete, and subsequent sentences about NER/RE/EE methods are not explicitly tied back to the stated contribution. The relationship between the contribution and the cited works is implied but not stated, causing multi-sentence coherence issues.",
          "start": 4830,
          "end": 5878
        }
      ],
      "Lacks synthesis": [
        {
          "span_text": "2. We formalize the task as a seq2seq problem and propose a new method within the seq2seq approach using the techniques of Traditionally, researchers formalize the task as a language understanding problem. The state-ofthe-art methods for NER perform the task on the basis of the pre-trained language model BERT (Devlin et al., 2019). The pipeline approach to RE divides the problem into NER and relation classification, and conducts the two sub-tasks in a sequential manner (Zhong and Chen, 2020), while the end-to-end approach jointly carries out the two sub-tasks (Zheng et al., 2017;Zeng et al., 2018;. The state-of-the-art methods for EE also employ BERT and usually jointly train the models with other tasks such as NER and RE Zhang et al., 2019;Lin et al., 2020). All the methods assume the use of pre-defined schemas (e.g., entity types for NER, entity and relation types for RE, and event templates for EE). Besides, most methods are designed for extraction from short texts. Therefore, existing methods for IE cannot be directly applied to text-to-table.",
          "gpt_label": "Lacks synthesis",
          "reason": "This contribution bullet shifts into a list of prior works and their properties without integrating how they motivate or inform the proposed method. It summarizes citations and generic limitations but does not explicitly connect them to the authors’ techniques or clearly articulate the specific gap their approach addresses.",
          "start": 4830,
          "end": 5878
        }
      ]
    }
  },
  "paper_87.txt": {
    "filename": "paper_87.txt",
    "full_text": "Related Work\n\nFrom the period of statistical machine translation (SMT), IMT has been widely exploited to reduce human’s effort by using the human’s feedback to help models to do translation (Foster et al., 1997; Langlais et al., 2000; Simard et al., 2007; Barrachina et al., 2009; González-Rubio et al., 2013; Cheng et al., 2016). Recently, with the development of NMT (Bahdanau et al., 2015; Vaswani et al., 2017), researchers turned to employing IMT on it. A classical type of IMT uses a left-to-right sentence completing framework proposed in Langlais et al. (2000), in which human translators can only do revisions on the translation generated by models from left to right. Generally, the text portion from the beginning to the current modified part is called prefix, and the system will generate a new translation based on the given prefix (SanchisTrilles et al., 2014; Peris et al., 2017a; Knowles and Koehn, 2016).\nCheng et al. (2016) propose a pick-revise framework that enables translators do revisions on arbitrary positions to improve efficiency. Huang et al. (2021) allow users to make any interaction on random position by using LCD (Hokamp and Liu, 2017; Post and Vilar, 2018), algorithms in the decoding stage which can integrate lexical constraints into translation. However, LCD can not achieve a win-win of decoding speed and translation quality. Weng et al. (2019) propose a bidirectional IMT framework also based on LCD, which could fix minor mistakes left to the revisions by doing two constrained decoding processes with opposite directions in tandem. However, it needs to train two \ndecoders, and in each constrained decoding process, the model can only use part of the constraints supplied by translators, making it inefficient both in using human knowledge and decoding speed. But BiTIIMT constructs all constraints into a template as part of the input, which makes it possible for models to use all human knowledge at the same time to fix minor mistakes automatically in the whole sentence. Another series of works (Alkhouli et al., 2019; Song et al., 2020; Chen et al., 2021) apply alignment information to improve the decoding efficiency of LCD. Alkhouli et al. (2019) use alignment extracted by vanilla transformer, which is reported by Garg et al. is poor. Song et al. (2020) need an external aligner to train the alignment module. These works can only do constrained decoding based on a dictionary-style constraint pair, which means a burden for human translators.\n\n\n ",
    "all_spans": [
      {
        "span_text": "Recently, with the development of NMT (Bahdanau et al., 2015; Vaswani et al., 2017), researchers turned to employing IMT on it.",
        "gpt_label": "Unsupported Claim",
        "reason": "Asserts a trend in recent work (IMT applied to NMT) without citing any specific IMT-on-NMT studies; mentions of recent works should be backed by citations.",
        "start": 324,
        "end": 448
      },
      {
        "span_text": "However, LCD can not achieve a win-win of decoding speed and translation quality.",
        "gpt_label": "Unsupported Claim",
        "reason": "Evaluative performance claim about LCD without evidence or citation.",
        "start": 1264,
        "end": 1344
      },
      {
        "span_text": "making it inefficient both in using human knowledge and decoding speed.",
        "gpt_label": "Unsupported Claim",
        "reason": "Judgment about inefficiency is asserted without supporting evidence or citation.",
        "start": 1708,
        "end": 1778
      },
      {
        "span_text": "which is reported by Garg et al. is poor.",
        "gpt_label": "Unsupported Claim",
        "reason": "References a report by prior work without a proper citation (missing year/details) and makes a qualitative claim without evidence.",
        "start": 2216,
        "end": 2255
      },
      {
        "span_text": "which means a burden for human translators.",
        "gpt_label": "Unsupported Claim",
        "reason": "Claims negative impact on translators without supporting evidence or citation.",
        "start": 2419,
        "end": 2461
      },
      {
        "span_text": "Garg et al.",
        "gpt_label": "Format",
        "reason": "Citation is missing the year/parenthetical formatting; it should appear as Garg et al. (YEAR) or (Garg et al., YEAR) rather than just the author string.",
        "start": 2237,
        "end": 2247
      },
      {
        "span_text": "However, LCD can not achieve a win-win of decoding speed and translation quality. Weng et al. (2019) propose a bidirectional IMT framework also based on LCD, which could fix minor mistakes left to the revisions by doing two constrained decoding processes with opposite directions in tandem.",
        "gpt_label": "Coherence",
        "reason": "The transition is abrupt: after stating a general limitation of LCD, it is unclear how Weng et al.'s LCD-based approach addresses that limitation; the relationship is implied but not explicitly stated.",
        "start": 1264,
        "end": 1551
      },
      {
        "span_text": "decoders, and in each constrained decoding process, the model can only use part of the constraints supplied by translators, making it inefficient both in using human knowledge and decoding speed. But BiTIIMT constructs all constraints into a template as part of the input, which makes it possible for models to use all human knowledge at the same time to fix minor mistakes automatically in the whole sentence.",
        "gpt_label": "Coherence",
        "reason": "BiTIIMT is introduced abruptly without context or citation, making the connection to the preceding discussion of Weng et al.'s method unclear.",
        "start": 1584,
        "end": 1992
      },
      {
        "span_text": "Another series of works (Alkhouli et al., 2019; Song et al., 2020; Chen et al., 2021) apply alignment information to improve the decoding efficiency of LCD. Alkhouli et al. (2019) use alignment extracted by vanilla transformer, which is reported by Garg et al. is poor.",
        "gpt_label": "Coherence",
        "reason": "The reference to Garg et al. is introduced without context or clear linkage, leaving the relationship between these works and the reported limitation implicit rather than explicit.",
        "start": 1993,
        "end": 2255
      },
      {
        "span_text": "Cheng et al. (2016) propose a pick-revise framework that enables translators do revisions on arbitrary positions to improve efficiency.",
        "gpt_label": "Lacks synthesis",
        "reason": "This sentence only summarizes prior work without explicitly connecting it to the authors’ argument, identifying a gap, or explaining how it motivates or contrasts with the authors’ approach.",
        "start": 907,
        "end": 1040
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "Recently, with the development of NMT (Bahdanau et al., 2015; Vaswani et al., 2017), researchers turned to employing IMT on it.",
          "gpt_label": "Unsupported Claim",
          "reason": "Asserts a trend in recent work (IMT applied to NMT) without citing any specific IMT-on-NMT studies; mentions of recent works should be backed by citations.",
          "start": 324,
          "end": 448
        },
        {
          "span_text": "However, LCD can not achieve a win-win of decoding speed and translation quality.",
          "gpt_label": "Unsupported Claim",
          "reason": "Evaluative performance claim about LCD without evidence or citation.",
          "start": 1264,
          "end": 1344
        },
        {
          "span_text": "making it inefficient both in using human knowledge and decoding speed.",
          "gpt_label": "Unsupported Claim",
          "reason": "Judgment about inefficiency is asserted without supporting evidence or citation.",
          "start": 1708,
          "end": 1778
        },
        {
          "span_text": "which is reported by Garg et al. is poor.",
          "gpt_label": "Unsupported Claim",
          "reason": "References a report by prior work without a proper citation (missing year/details) and makes a qualitative claim without evidence.",
          "start": 2216,
          "end": 2255
        },
        {
          "span_text": "which means a burden for human translators.",
          "gpt_label": "Unsupported Claim",
          "reason": "Claims negative impact on translators without supporting evidence or citation.",
          "start": 2419,
          "end": 2461
        }
      ],
      "Format": [
        {
          "span_text": "Garg et al.",
          "gpt_label": "Format",
          "reason": "Citation is missing the year/parenthetical formatting; it should appear as Garg et al. (YEAR) or (Garg et al., YEAR) rather than just the author string.",
          "start": 2237,
          "end": 2247
        }
      ],
      "Coherence": [
        {
          "span_text": "However, LCD can not achieve a win-win of decoding speed and translation quality. Weng et al. (2019) propose a bidirectional IMT framework also based on LCD, which could fix minor mistakes left to the revisions by doing two constrained decoding processes with opposite directions in tandem.",
          "gpt_label": "Coherence",
          "reason": "The transition is abrupt: after stating a general limitation of LCD, it is unclear how Weng et al.'s LCD-based approach addresses that limitation; the relationship is implied but not explicitly stated.",
          "start": 1264,
          "end": 1551
        },
        {
          "span_text": "decoders, and in each constrained decoding process, the model can only use part of the constraints supplied by translators, making it inefficient both in using human knowledge and decoding speed. But BiTIIMT constructs all constraints into a template as part of the input, which makes it possible for models to use all human knowledge at the same time to fix minor mistakes automatically in the whole sentence.",
          "gpt_label": "Coherence",
          "reason": "BiTIIMT is introduced abruptly without context or citation, making the connection to the preceding discussion of Weng et al.'s method unclear.",
          "start": 1584,
          "end": 1992
        },
        {
          "span_text": "Another series of works (Alkhouli et al., 2019; Song et al., 2020; Chen et al., 2021) apply alignment information to improve the decoding efficiency of LCD. Alkhouli et al. (2019) use alignment extracted by vanilla transformer, which is reported by Garg et al. is poor.",
          "gpt_label": "Coherence",
          "reason": "The reference to Garg et al. is introduced without context or clear linkage, leaving the relationship between these works and the reported limitation implicit rather than explicit.",
          "start": 1993,
          "end": 2255
        }
      ],
      "Lacks synthesis": [
        {
          "span_text": "Cheng et al. (2016) propose a pick-revise framework that enables translators do revisions on arbitrary positions to improve efficiency.",
          "gpt_label": "Lacks synthesis",
          "reason": "This sentence only summarizes prior work without explicitly connecting it to the authors’ argument, identifying a gap, or explaining how it motivates or contrasts with the authors’ approach.",
          "start": 907,
          "end": 1040
        }
      ]
    }
  },
  "paper_88.txt": {
    "filename": "paper_88.txt",
    "full_text": "Introduction\n\nDistributed representations of events, are a common way to represent events in a machine-readable form and have shown to provide meaningful features for various tasks (Lee and Goldwasser, 2018;Rezaee and Ferraro, 2021;Deng et al., 2021;Martin et al., 2018;. Obtaining effective event representations is challenging, as it requires representations to capture various relations between events. Figure 1 presents four pairs of events with different relations. Two events may share the same event attributes (e.g. event types and sentiments), and there may also be a causal or temporal relation between two events.\n\nEarly works (Weber et al., 2018) exploit easily accessible co-occurrence relation of events to learn event representations. Although the use of cooccurrence relation works well, it is too coarse for deep understanding of events, which requires finegrained knowledge (Lee and Goldwasser, 2019). Recent works focus on fine-grained knowledge, such as discourse relations (Prasad et al., 2006;Lee and Goldwasser, 2019;Zheng et al., 2020) and commonsense knowledge (e.g. sentiments and intents) (Sap et al., 2019;Ding et al., 2019). Concretely, Lee and Goldwasser (2019) and Zheng et al. (2020) leverage 11 discourse relation types to model event script knowledge. Ding et al. (2019) incorporate manually labeled commonsense knowledge (intents and sentiments) into event representation learning. However, the types of fine-grained event knowledge are so diverse that we cannot enumerate all of them and currently adopted finegrained knowledge fall under a small set of event knowledge. In addition, some manually labeled knowledge (Sap et al., 2019;Hwang et al., 2021) is costly and difficult to apply on large datasets.\n\nIn our work, we observe that there is a rich amount of information in co-occurring events, but previous works did not make good use of such information. Based on existing works on event relation extraction (Xue et al., 2016;Lee and Goldwasser, 2019;, we find that the co-occurrence relation, which refers to two events appearing in the same document, can be seen as a superset of current defined explicit discourse relations, as most existing automatic methods extract event relations from documents or sentences. More than that, it also includes other implicit event knowledge, that is, events that occur in the same document may share the same topic and event type. Previous works (Granroth-Wilding and Clark, 2016;Weber et al., 2018) based on cooccurrence information usually exploit instancewise contrastive learning approaches related to the margin loss, which consists of an anchor, positive, and negative sample, where the anchor is more similar to the positive than the negative. However, they share two common limitations: (1) such marginbased approaches struggle to capture the essential differences between events with different semantics, as they only consider one positive and one negative per anchor. (2) Randomly sampled negative samples may contain samples semantically related to the anchor but are undesirably pushed apart in embedding space. This problem arises because these instance-wise contrastive learning approaches treat randomly selected events as negative samples, regardless of their semantic relevance.\n\nWe are motivated to address the above issues with the goal of making better use of cooccurrence information of events. To this end, we present SWCC: a Simultaneous Weakly supervised Contrastive learning and Clustering framework for event representation learning, where we exploit document-level co-occurrence information of events as weak supervision and learn event representations by simultaneously performing weakly supervised contrastive learning and prototype-based clustering. To address the first issue, we build our approach on the contrastive framework with the InfoNCE objective (van den Oord et al., 2019), which is a self-supervised contrastive learning method that uses one positive and multiple negatives. Further, we extend the InfoNCE to a weakly supervised contrastive learning setting, allowing us to consider multiple positives and multiple negatives per anchor (as opposed to the margin loss which uses only one positive and one negative). Co-occurring events are then incorporated as additional positives, weighted by a normalized co-occurrence frequency. To address the second issue, we introduce a prototype-based clustering method to avoid semantically related events being pulled apart. Specifically, we impose a prototype for each cluster, which is a representative embed-ding for a group of semantically related events. Then we cluster the data while enforce consistency between cluster assignments produced for different augmented representations of an event. Unlike the instance-wise contrastive learning, our clustering method focuses on the cluster-level semantic concepts by contrasting between representations of events and clusters. Overall, we make the following contributions:\n\n• We propose a simple and effective framework (SWCC) that learns event representations by making better use of co-occurrence information of events. Experimental results show that our approach outperforms previous approaches on several event related tasks. • We introduce a weakly supervised contrastive learning method that allows us to consider multiple positives and multiple negatives, and a prototype-based clustering method that avoids semantically related events being pulled apart. • We provide a thorough analysis of the prototypebased clustering method to demonstrate that the learned prototype vectors are able to implicitly capture various relations between events. The source code 1 of our SWCC has been uploaded to Anonymous Github for reproducing our results.\n\n ",
    "all_spans": [
      {
        "span_text": "the use of cooccurrence relation works well",
        "gpt_label": "Unsupported Claim",
        "reason": "Evaluative claim about effectiveness of a prior approach is made without a supporting citation or evidence.",
        "start": 749,
        "end": 792
      },
      {
        "span_text": "However, the types of fine-grained event knowledge are so diverse that we cannot enumerate all of them and currently adopted finegrained knowledge fall under a small set of event knowledge.",
        "gpt_label": "Unsupported Claim",
        "reason": "Broad domain-specific assertions about the diversity and coverage of event knowledge are made without citations.",
        "start": 1395,
        "end": 1583
      },
      {
        "span_text": "previous works did not make good use of such information.",
        "gpt_label": "Unsupported Claim",
        "reason": "A claim about limitations of prior work is made without referencing specific studies or evidence.",
        "start": 1812,
        "end": 1868
      },
      {
        "span_text": "the co-occurrence relation, which refers to two events appearing in the same document, can be seen as a superset of current defined explicit discourse relations",
        "gpt_label": "Unsupported Claim",
        "reason": "Strong claim about set inclusion between relation types lacks citation or empirical justification.",
        "start": 1979,
        "end": 2139
      },
      {
        "span_text": "as most existing automatic methods extract event relations from documents or sentences.",
        "gpt_label": "Unsupported Claim",
        "reason": "Generalization about “most existing” methods requires supporting references.",
        "start": 2141,
        "end": 2227
      },
      {
        "span_text": "(1) such marginbased approaches struggle to capture the essential differences between events with different semantics, as they only consider one positive and one negative per anchor.",
        "gpt_label": "Unsupported Claim",
        "reason": "Evaluative claim about the limitations of a class of prior methods is presented without citation or empirical evidence.",
        "start": 2743,
        "end": 2924
      },
      {
        "span_text": "(2) Randomly sampled negative samples may contain samples semantically related to the anchor but are undesirably pushed apart in embedding space.",
        "gpt_label": "Unsupported Claim",
        "reason": "Known issue (“false negatives” in contrastive learning) is asserted without citing supporting literature.",
        "start": 2925,
        "end": 3069
      },
      {
        "span_text": "This problem arises because these instance-wise contrastive learning approaches treat randomly selected events as negative samples, regardless of their semantic relevance.",
        "gpt_label": "Unsupported Claim",
        "reason": "Causal explanation about prior methods’ behavior is given without references.",
        "start": 3070,
        "end": 3240
      },
      {
        "span_text": "1",
        "gpt_label": "Format",
        "reason": "Numeric reference marker appears without proper citation/footnote formatting (e.g., brackets or superscript).",
        "start": 204,
        "end": 205
      },
      {
        "span_text": "Based on existing works on event relation extraction (Xue et al., 2016;Lee and Goldwasser, 2019;, we find that the co-occurrence relation, which refers to two events appearing in the same document, can be seen as a superset of current defined explicit discourse relations, as most existing automatic methods extract event relations from documents or sentences. More than that, it also includes other implicit event knowledge, that is, events that occur in the same document may share the same topic and event type.",
        "gpt_label": "Coherence",
        "reason": "The connection between the cited works on event relation extraction and the claim that co-occurrence is a superset of explicit discourse relations is implied rather than explained. The transition to additional implicit knowledge is abrupt and lacks an explicit link to the referenced literature, making the relationship between the sentences and citations unclear.",
        "start": 1869,
        "end": 2380
      },
      {
        "span_text": "Concretely, Lee and Goldwasser (2019) and Zheng et al. (2020) leverage 11 discourse relation types to model event script knowledge. Ding et al. (2019) incorporate manually labeled commonsense knowledge (intents and sentiments) into event representation learning.",
        "gpt_label": "Lacks synthesis",
        "reason": "These sentences list prior works and their methods without integrating or comparing them, and without explicitly linking them to the authors’ own argument or research gap until the subsequent ‘However’ statement. They summarize but do not synthesize.",
        "start": 1136,
        "end": 1394
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "the use of cooccurrence relation works well",
          "gpt_label": "Unsupported Claim",
          "reason": "Evaluative claim about effectiveness of a prior approach is made without a supporting citation or evidence.",
          "start": 749,
          "end": 792
        },
        {
          "span_text": "However, the types of fine-grained event knowledge are so diverse that we cannot enumerate all of them and currently adopted finegrained knowledge fall under a small set of event knowledge.",
          "gpt_label": "Unsupported Claim",
          "reason": "Broad domain-specific assertions about the diversity and coverage of event knowledge are made without citations.",
          "start": 1395,
          "end": 1583
        },
        {
          "span_text": "previous works did not make good use of such information.",
          "gpt_label": "Unsupported Claim",
          "reason": "A claim about limitations of prior work is made without referencing specific studies or evidence.",
          "start": 1812,
          "end": 1868
        },
        {
          "span_text": "the co-occurrence relation, which refers to two events appearing in the same document, can be seen as a superset of current defined explicit discourse relations",
          "gpt_label": "Unsupported Claim",
          "reason": "Strong claim about set inclusion between relation types lacks citation or empirical justification.",
          "start": 1979,
          "end": 2139
        },
        {
          "span_text": "as most existing automatic methods extract event relations from documents or sentences.",
          "gpt_label": "Unsupported Claim",
          "reason": "Generalization about “most existing” methods requires supporting references.",
          "start": 2141,
          "end": 2227
        },
        {
          "span_text": "(1) such marginbased approaches struggle to capture the essential differences between events with different semantics, as they only consider one positive and one negative per anchor.",
          "gpt_label": "Unsupported Claim",
          "reason": "Evaluative claim about the limitations of a class of prior methods is presented without citation or empirical evidence.",
          "start": 2743,
          "end": 2924
        },
        {
          "span_text": "(2) Randomly sampled negative samples may contain samples semantically related to the anchor but are undesirably pushed apart in embedding space.",
          "gpt_label": "Unsupported Claim",
          "reason": "Known issue (“false negatives” in contrastive learning) is asserted without citing supporting literature.",
          "start": 2925,
          "end": 3069
        },
        {
          "span_text": "This problem arises because these instance-wise contrastive learning approaches treat randomly selected events as negative samples, regardless of their semantic relevance.",
          "gpt_label": "Unsupported Claim",
          "reason": "Causal explanation about prior methods’ behavior is given without references.",
          "start": 3070,
          "end": 3240
        }
      ],
      "Format": [
        {
          "span_text": "1",
          "gpt_label": "Format",
          "reason": "Numeric reference marker appears without proper citation/footnote formatting (e.g., brackets or superscript).",
          "start": 204,
          "end": 205
        }
      ],
      "Coherence": [
        {
          "span_text": "Based on existing works on event relation extraction (Xue et al., 2016;Lee and Goldwasser, 2019;, we find that the co-occurrence relation, which refers to two events appearing in the same document, can be seen as a superset of current defined explicit discourse relations, as most existing automatic methods extract event relations from documents or sentences. More than that, it also includes other implicit event knowledge, that is, events that occur in the same document may share the same topic and event type.",
          "gpt_label": "Coherence",
          "reason": "The connection between the cited works on event relation extraction and the claim that co-occurrence is a superset of explicit discourse relations is implied rather than explained. The transition to additional implicit knowledge is abrupt and lacks an explicit link to the referenced literature, making the relationship between the sentences and citations unclear.",
          "start": 1869,
          "end": 2380
        }
      ],
      "Lacks synthesis": [
        {
          "span_text": "Concretely, Lee and Goldwasser (2019) and Zheng et al. (2020) leverage 11 discourse relation types to model event script knowledge. Ding et al. (2019) incorporate manually labeled commonsense knowledge (intents and sentiments) into event representation learning.",
          "gpt_label": "Lacks synthesis",
          "reason": "These sentences list prior works and their methods without integrating or comparing them, and without explicitly linking them to the authors’ own argument or research gap until the subsequent ‘However’ statement. They summarize but do not synthesize.",
          "start": 1136,
          "end": 1394
        }
      ]
    }
  },
  "paper_89.txt": {
    "filename": "paper_89.txt",
    "full_text": "Introduction\n\nAround 200 languages in the world are signed rather than spoken, featuring their own vocabulary and grammatical structures. For example the American Sign Language (ASL) is not a mere translation of English into signs and is unrelated to the British Sign Language (BSL). This introduces many novel challenges to their automated processing. Research on Sign Language Processing (SLP) encompasses tasks such as sign language detection, i.e. recognising if and which signed language is performed (Moryossef et al., 2020) and sign language recognition (SLR) (Koller, 2020), i.e. the identification of signs either in isolation or in continuous speech. Other tasks concern the translation from signed to spoken (or written) (Camgoz et al.,2018) language or the production of signs from text (Rastgoo et al., 2021). With the recent success of deep learning-based approaches in computer vision (CV), as well as advancements in —from the CV perspective—related tasks of action and gesture recognition (Asadi-Aghbolaghi et al., 2017), SLP is gaining more attention in the CV community (Zheng et al., 2017).\n\nSome recent approaches to various SLP tasks rely on phonological features, perhaps due to the complexity of the tasks (Tornay, 2021; Metaxas et al., 2018; Gebre et al., 2013; avella et al., 2021). Surprisingly, however, little work has been carried out on explicitly modelling the phonology of signed languages. This presents a timely opportunity to investigate signed languages from a linguist’s perspective (Yin et al., 2021). In the context of signed languages, phonology typically distinguishes between manual features, such as usage, position and movement of hands and fingers, and non-manual features, such as facial expression. Sign language phonology is a matured field with well-developed\ntheoretical frameworks (Liddell and Johnson, 1989; Fenlon et al., 2017; Sandler, 2012). These phonological features, or phonemes, are drawn from a fixed inventory of possible configurations which is typically much smaller than the vocabulary of signed languages (Borg and Camilleri, 2020). For example, there is only a limited number of fingers\nthat can be used to perform a sign due to anatomical constraints. Hence, different signs share phonological properties and well performing classifiers can be used to predict those properties for signs unseen during training. This potentially holds even across different languages, because, while different languages may dictate different combinations\nof phonemes, there are also significant overlaps (Tornay et al., 2020).\n\nFinally, these phonological properties have a strong discriminatory power when determining signs. For example, in ASL-Lex (Caselli et al., 2017), a lexicon which also captures phonology information, the authors report that more than 50% of its 994 described signs have a unique combination of only six phonological properties and more than 80% of the signs share their combination with at most two other signs. By relying on additional (i.e., phonological) information from resources such as ASL-Lex, many signs can be determined from (predicted) phonological properties alone, without encountering them in training data. This is a capability that current data-driven approaches to SLR lack by design (Koller, 2020). Thus, in combination, mature approaches to phonology recognition can facilitate the development of sign language resources. This is an important task for both documenting low-resource sign languages as well as rapid developing of large-scale datasets, to fully harness data-driven CV approaches.\n\nTo spur research in this direction, we extend the preliminary work by Tavella et al. (2021) and introduce the task of Phonological Property Recognition (PPR). More specifically, this paper contributes (i) WLASLLex2001, a large-scale, automatically constructed PPR dataset, (ii) an analysis of the dataset quality, and (iii) an empirical study of the performance of different deep-learning based baselines thereon.\n\n ",
    "all_spans": [
      {
        "span_text": "Around 200 languages in the world are signed rather than spoken, featuring their own vocabulary and grammatical structures.",
        "gpt_label": "Unsupported Claim",
        "reason": "Presents a specific statistic and broad linguistic claim about signed languages without any citation.",
        "start": 14,
        "end": 136
      },
      {
        "span_text": "For example the American Sign Language (ASL) is not a mere translation of English into signs and is unrelated to the British Sign Language (BSL).",
        "gpt_label": "Unsupported Claim",
        "reason": "Makes specific claims about relationships between ASL and BSL without providing citations.",
        "start": 137,
        "end": 281
      },
      {
        "span_text": "Surprisingly, however, little work has been carried out on explicitly modelling the phonology of signed languages.",
        "gpt_label": "Unsupported Claim",
        "reason": "Asserts a state-of-the-art literature gap without supporting evidence or references.",
        "start": 1290,
        "end": 1403
      },
      {
        "span_text": "In the context of signed languages, phonology typically distinguishes between manual features, such as usage, position and movement of hands and fingers, and non-manual features, such as facial expression.",
        "gpt_label": "Unsupported Claim",
        "reason": "Defines a standard theoretical distinction in sign language phonology without citing foundational or survey sources.",
        "start": 1519,
        "end": 1723
      },
      {
        "span_text": "avella et al., 2021",
        "gpt_label": "Format",
        "reason": "Author surname is not capitalized; citation uses incorrect capitalization style.",
        "start": 1270,
        "end": 1288
      },
      {
        "span_text": "Surprisingly, however, little work has been carried out on explicitly modelling the phonology of signed languages. This presents a timely opportunity to investigate signed languages from a linguist’s perspective (Yin et al., 2021). In the context of signed languages, phonology typically distinguishes between manual features, such as usage, position and movement of hands and fingers, and non-manual features, such as facial expression. Sign language phonology is a matured field with well-developed\ntheoretical frameworks (Liddell and Johnson, 1989; Fenlon et al., 2017; Sandler, 2012).",
        "gpt_label": "Coherence",
        "reason": "The passage moves from stating a lack of explicit phonology modeling to asserting that sign language phonology is a matured field without making explicit that the former refers to computational modeling while the latter refers to linguistic theory. The transition via a ‘linguist’s perspective’ is not clearly connected to the cited theoretical frameworks, leaving the relationship between the cited works and the research gap implied rather than explicit.",
        "start": 1290,
        "end": 1872
      },
      {
        "span_text": "This presents a timely opportunity to investigate signed languages from a linguist’s perspective (Yin et al., 2021).",
        "gpt_label": "Lacks synthesis",
        "reason": "The sentence cites prior work and makes a generic claim about an opportunity without explicitly connecting how this motivates or shapes the paper’s specific approach (PPR, dataset, baselines) at that point, thus not synthesizing the cited perspective with the authors’ argument.",
        "start": 1404,
        "end": 1518
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "Around 200 languages in the world are signed rather than spoken, featuring their own vocabulary and grammatical structures.",
          "gpt_label": "Unsupported Claim",
          "reason": "Presents a specific statistic and broad linguistic claim about signed languages without any citation.",
          "start": 14,
          "end": 136
        },
        {
          "span_text": "For example the American Sign Language (ASL) is not a mere translation of English into signs and is unrelated to the British Sign Language (BSL).",
          "gpt_label": "Unsupported Claim",
          "reason": "Makes specific claims about relationships between ASL and BSL without providing citations.",
          "start": 137,
          "end": 281
        },
        {
          "span_text": "Surprisingly, however, little work has been carried out on explicitly modelling the phonology of signed languages.",
          "gpt_label": "Unsupported Claim",
          "reason": "Asserts a state-of-the-art literature gap without supporting evidence or references.",
          "start": 1290,
          "end": 1403
        },
        {
          "span_text": "In the context of signed languages, phonology typically distinguishes between manual features, such as usage, position and movement of hands and fingers, and non-manual features, such as facial expression.",
          "gpt_label": "Unsupported Claim",
          "reason": "Defines a standard theoretical distinction in sign language phonology without citing foundational or survey sources.",
          "start": 1519,
          "end": 1723
        }
      ],
      "Format": [
        {
          "span_text": "avella et al., 2021",
          "gpt_label": "Format",
          "reason": "Author surname is not capitalized; citation uses incorrect capitalization style.",
          "start": 1270,
          "end": 1288
        }
      ],
      "Coherence": [
        {
          "span_text": "Surprisingly, however, little work has been carried out on explicitly modelling the phonology of signed languages. This presents a timely opportunity to investigate signed languages from a linguist’s perspective (Yin et al., 2021). In the context of signed languages, phonology typically distinguishes between manual features, such as usage, position and movement of hands and fingers, and non-manual features, such as facial expression. Sign language phonology is a matured field with well-developed\ntheoretical frameworks (Liddell and Johnson, 1989; Fenlon et al., 2017; Sandler, 2012).",
          "gpt_label": "Coherence",
          "reason": "The passage moves from stating a lack of explicit phonology modeling to asserting that sign language phonology is a matured field without making explicit that the former refers to computational modeling while the latter refers to linguistic theory. The transition via a ‘linguist’s perspective’ is not clearly connected to the cited theoretical frameworks, leaving the relationship between the cited works and the research gap implied rather than explicit.",
          "start": 1290,
          "end": 1872
        }
      ],
      "Lacks synthesis": [
        {
          "span_text": "This presents a timely opportunity to investigate signed languages from a linguist’s perspective (Yin et al., 2021).",
          "gpt_label": "Lacks synthesis",
          "reason": "The sentence cites prior work and makes a generic claim about an opportunity without explicitly connecting how this motivates or shapes the paper’s specific approach (PPR, dataset, baselines) at that point, thus not synthesizing the cited perspective with the authors’ argument.",
          "start": 1404,
          "end": 1518
        }
      ]
    }
  },
  "paper_90.txt": {
    "filename": "paper_90.txt",
    "full_text": "Related Work\n\nOther works have observed limitations of the softmax layer when modelling infrequent classes for image classification (Kang et al., 2020) and rare words for MT (Nguyen and Chiang, 2018;Raunak et al., 2020). They show that normalising the magnitude of the softmax weight vectors improves predictions for infrequent classes. However, the motivation for weight normalisation is guided empirically. From the perspective of this work, weight normalisation provably prevents Stolen Probability from arising when a softmax layer has no bias term. For more details, see Section D in the Appendix.\n\n ",
    "all_spans": [
      {
        "span_text": "However, the motivation for weight normalisation is guided empirically.",
        "gpt_label": "Unsupported Claim",
        "reason": "This is a general claim about prior work’s motivation without citing specific studies or evidence to support it.",
        "start": 333,
        "end": 403
      },
      {
        "span_text": "However, the motivation for weight normalisation is guided empirically. From the perspective of this work, weight normalisation provably prevents Stolen Probability from arising when a softmax layer has no bias term.",
        "gpt_label": "Coherence",
        "reason": "The text abruptly shifts from summarizing prior empirical findings to introducing the paper’s theoretical concept (“Stolen Probability”) without explicitly connecting how this theory explains or relates to the cited works’ results. The relationship between the empirical motivation and the new theoretical claim is implied rather than stated, creating a coherence gap across these sentences.",
        "start": 333,
        "end": 547
      },
      {
        "span_text": "",
        "gpt_label": "no_lacks_synthesis",
        "reason": "The paragraph connects prior empirical findings on weight normalization to the authors’ theoretical contribution by articulating the gap (empirically guided motivation) and presenting their perspective (provable prevention of Stolen Probability), thus demonstrating synthesis.",
        "start": 0,
        "end": 0
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "However, the motivation for weight normalisation is guided empirically.",
          "gpt_label": "Unsupported Claim",
          "reason": "This is a general claim about prior work’s motivation without citing specific studies or evidence to support it.",
          "start": 333,
          "end": 403
        }
      ],
      "Format": [],
      "Coherence": [
        {
          "span_text": "However, the motivation for weight normalisation is guided empirically. From the perspective of this work, weight normalisation provably prevents Stolen Probability from arising when a softmax layer has no bias term.",
          "gpt_label": "Coherence",
          "reason": "The text abruptly shifts from summarizing prior empirical findings to introducing the paper’s theoretical concept (“Stolen Probability”) without explicitly connecting how this theory explains or relates to the cited works’ results. The relationship between the empirical motivation and the new theoretical claim is implied rather than stated, creating a coherence gap across these sentences.",
          "start": 333,
          "end": 547
        }
      ],
      "no_lacks_synthesis": [
        {
          "span_text": "",
          "gpt_label": "no_lacks_synthesis",
          "reason": "The paragraph connects prior empirical findings on weight normalization to the authors’ theoretical contribution by articulating the gap (empirically guided motivation) and presenting their perspective (provable prevention of Stolen Probability), thus demonstrating synthesis.",
          "start": 0,
          "end": 0
        }
      ]
    }
  },
  "paper_91.txt": {
    "filename": "paper_91.txt",
    "full_text": "Introduction\n\nThe dominant approach in the design of current NLP solutions consists in (pre-)training a large neural language model, usually applying a Transformer architecture, such as GPT-2, RoBERTa or T5, and fine-tuning the model for specific tasks (Devlin et al., 2018;Raffel et al., 2019). The solutions are evaluated on benchmarks such as GLUE ((Wang et al., 2018)) or SuperGLUE ((Wang et al., 2019)), which allow comparing the performance of various methods designed for the same purpose. A main feature of a good NLP benchmark is the clear separation between train and test sets. This requirement prevents data contamination, when the model (pre-)trained on huge data might have \"seen\" the test set.\n\nThe expansion of digital information is proceeding in two directions on the temporal axis. In the forward direction, new data are made publicly available on the Internet every second. What is less obvious is that, in the backward direction, older and older historical documents are digitized and disseminated publicly.\n\nTo the best of our knowledge, our paper introduces the first benchmark which serves to use and evaluate the \"pre-train and fine-tune scenario\" applied to a massive collection of historical texts.\n\nThe very idea of building language models on historical data is not new. The Google Ngram Viewer (Michel et al., 2011) is based on large amounts of texts from digitized books. The corpus as a whole is not open for the NLP community -only raw n-gram statistics are available. The temporal information is crude (at best, the year of publication is given) and the corpus is heterogeneous (in fact, it is a dump of digitized books of any origin).\n\nIn our research, we use one of the richest sources of homogeneous historical documents, Chronicling America, a collection of digitized newspapers that cover the publication period of over 300 years (with significant coverage of 150 years), and design an NLP benchmark that may open new opportunities for the modeling of the historical language.\n\nRecently, time-aware language models such as Temporal T5 (Dhingra et al., 2021) and Tem-poBERT (Rosin et al., 2021) have been proposed. They focus on modern texts dated yearly, whereas we extend language modeling towards both longer time scales and more fine-grained (daily) resolution, using massive amounts of historical texts.\n\nThe contribution of this paper is as follows:\n\n• We extracted a large corpus of English historical texts that may serve to pre-train historical language models (Section 5).\n\nThese are the main features of the corpus:\n\nthe corpus size is 201 GB, which is comparable with contemporary text data for training massive language models, such as GPT-2, RoBERTa or T5; the corpus is free of spam and noisy data (although the quality of OCR processing varies); texts are dated with a daily resolution, hence a new dimension of time (on a fine-grained level) can be introduced into language modeling; the whole corpus is made publicly available;\n\n• Based on selected excerpts from Chronicling America, we define a suite of challenges (named Challanging America, or ChallAm in short) with three ML tasks combining layout recognition, information extraction and semantic inference (Section 7). We hope that ChallAm will give rise to a historical equivalent of the GLUE (Wang et al., 2018) or Su-perGLUE (Wang et al., 2019) benchmarks.\n\n-In particular, we provide a tool for the intrinsic evaluation of language models based on a word-gap task, which calculates the model perplexity in a comparative scenario (the tool may be used in competitive shared-tasks) (Section 7.3).\n\n• We propose a \"future-proof\" methodology for the creation of NLP challenges: a challenge is automatically updated whenever the underlying corpus is enriched (Section 6.3).\n\n• We introduce a method for data preparation that prevents data contamination (Section 6.3).\n\n• We train base Transformer (RoBERTa) models for historical texts (Section 5). The models are trained on texts spanning 100 years, dated with a daily resolution.\n\n• We provide strong baselines for three ChronAm challenges (Section 8).\n\n• We take under consideration the issue of discrimination and hate speech in the historical American texts. To this end we have applied up-to date methods to filter out the abusive content from the data (Section 9).\n\n ",
    "all_spans": [
      {
        "span_text": "GPT-2, RoBERTa",
        "gpt_label": "Unsupported Claim",
        "reason": "First mention of these specific models lacks citations; works, datasets, or models should be cited at first mention.",
        "start": 186,
        "end": 200
      },
      {
        "span_text": "To the best of our knowledge, our paper introduces the first benchmark which serves to use and evaluate the \"pre-train and fine-tune scenario\" applied to a massive collection of historical texts.",
        "gpt_label": "Unsupported Claim",
        "reason": "Novelty claim about being the first requires evidence or citations to prior work to justify the claim.",
        "start": 1019,
        "end": 1213
      },
      {
        "span_text": "one of the richest sources of homogeneous historical documents",
        "gpt_label": "Unsupported Claim",
        "reason": "Evaluative claim about a dataset’s standing in the field should be supported with citations or evidence.",
        "start": 1678,
        "end": 1740
      },
      {
        "span_text": "Chronicling America",
        "gpt_label": "Unsupported Claim",
        "reason": "First mention of a dataset should include a citation to its source or documentation.",
        "start": 1742,
        "end": 1761
      },
      {
        "span_text": "cover the publication period of over 300 years (with significant coverage of 150 years)",
        "gpt_label": "Unsupported Claim",
        "reason": "Specific statistics about a dataset require a supporting citation.",
        "start": 1805,
        "end": 1892
      },
      {
        "span_text": "which is comparable with contemporary text data for training massive language models, such as GPT-2, RoBERTa or T5",
        "gpt_label": "Unsupported Claim",
        "reason": "Comparative claim referencing prior model training data sizes should be supported with citations to those corpora/papers; GPT-2 and RoBERTa are also mentioned without citation.",
        "start": 2570,
        "end": 2684
      },
      {
        "span_text": "up-to date methods",
        "gpt_label": "Unsupported Claim",
        "reason": "Reference to recent methods should be accompanied by citations to those methods.",
        "start": 4214,
        "end": 4232
      },
      {
        "span_text": "We hope that ChallAm will give rise to a historical equivalent of the GLUE (Wang et al., 2018) or Su-perGLUE (Wang et al., 2019) benchmarks.\n\n-In particular, we provide a tool for the intrinsic evaluation of language models based on a word-gap task, which calculates the model perplexity in a comparative scenario (the tool may be used in competitive shared-tasks) (Section 7.3).",
        "gpt_label": "Coherence",
        "reason": "The transition from comparing ChallAm to GLUE/SuperGLUE to introducing an intrinsic evaluation tool is abrupt. It is not explicitly explained how the tool relates to the proposed benchmark or to the GLUE/SuperGLUE analogy; the relationship is implied rather than stated, creating a multi-sentence coherence gap.",
        "start": 3206,
        "end": 3580
      },
      {
        "span_text": "The expansion of digital information is proceeding in two directions on the temporal axis. In the forward direction, new data are made publicly available on the Internet every second. What is less obvious is that, in the backward direction, older and older historical documents are digitized and disseminated publicly.",
        "gpt_label": "Lacks synthesis",
        "reason": "These sentences provide general observations without explicitly linking them to the paper’s argument, research gap, or motivation for the proposed benchmark; they neither connect to cited work nor articulate how this context informs the authors’ contribution.",
        "start": 702,
        "end": 1017
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "GPT-2, RoBERTa",
          "gpt_label": "Unsupported Claim",
          "reason": "First mention of these specific models lacks citations; works, datasets, or models should be cited at first mention.",
          "start": 186,
          "end": 200
        },
        {
          "span_text": "To the best of our knowledge, our paper introduces the first benchmark which serves to use and evaluate the \"pre-train and fine-tune scenario\" applied to a massive collection of historical texts.",
          "gpt_label": "Unsupported Claim",
          "reason": "Novelty claim about being the first requires evidence or citations to prior work to justify the claim.",
          "start": 1019,
          "end": 1213
        },
        {
          "span_text": "one of the richest sources of homogeneous historical documents",
          "gpt_label": "Unsupported Claim",
          "reason": "Evaluative claim about a dataset’s standing in the field should be supported with citations or evidence.",
          "start": 1678,
          "end": 1740
        },
        {
          "span_text": "Chronicling America",
          "gpt_label": "Unsupported Claim",
          "reason": "First mention of a dataset should include a citation to its source or documentation.",
          "start": 1742,
          "end": 1761
        },
        {
          "span_text": "cover the publication period of over 300 years (with significant coverage of 150 years)",
          "gpt_label": "Unsupported Claim",
          "reason": "Specific statistics about a dataset require a supporting citation.",
          "start": 1805,
          "end": 1892
        },
        {
          "span_text": "which is comparable with contemporary text data for training massive language models, such as GPT-2, RoBERTa or T5",
          "gpt_label": "Unsupported Claim",
          "reason": "Comparative claim referencing prior model training data sizes should be supported with citations to those corpora/papers; GPT-2 and RoBERTa are also mentioned without citation.",
          "start": 2570,
          "end": 2684
        },
        {
          "span_text": "up-to date methods",
          "gpt_label": "Unsupported Claim",
          "reason": "Reference to recent methods should be accompanied by citations to those methods.",
          "start": 4214,
          "end": 4232
        }
      ],
      "Format": [],
      "Coherence": [
        {
          "span_text": "We hope that ChallAm will give rise to a historical equivalent of the GLUE (Wang et al., 2018) or Su-perGLUE (Wang et al., 2019) benchmarks.\n\n-In particular, we provide a tool for the intrinsic evaluation of language models based on a word-gap task, which calculates the model perplexity in a comparative scenario (the tool may be used in competitive shared-tasks) (Section 7.3).",
          "gpt_label": "Coherence",
          "reason": "The transition from comparing ChallAm to GLUE/SuperGLUE to introducing an intrinsic evaluation tool is abrupt. It is not explicitly explained how the tool relates to the proposed benchmark or to the GLUE/SuperGLUE analogy; the relationship is implied rather than stated, creating a multi-sentence coherence gap.",
          "start": 3206,
          "end": 3580
        }
      ],
      "Lacks synthesis": [
        {
          "span_text": "The expansion of digital information is proceeding in two directions on the temporal axis. In the forward direction, new data are made publicly available on the Internet every second. What is less obvious is that, in the backward direction, older and older historical documents are digitized and disseminated publicly.",
          "gpt_label": "Lacks synthesis",
          "reason": "These sentences provide general observations without explicitly linking them to the paper’s argument, research gap, or motivation for the proposed benchmark; they neither connect to cited work nor articulate how this context informs the authors’ contribution.",
          "start": 702,
          "end": 1017
        }
      ]
    }
  },
  "paper_92.txt": {
    "filename": "paper_92.txt",
    "full_text": "Related Work\n\nSparse seq2seq models. Our proposed α-ReLU transformation is based on the α-entmax transformation of Peters et al. (2019), which in turn is a generalization of the sparsemax transformation (Martins and Astudillo, 2016). In our work, we study sparseness at the output of a neural network. Nevertheless, there are a number of works aimed at sparsification within a neural network. For example, Malaviya et al. (2018); Peters et al. (2019);Correia et al. (2019) show that sparsemax and αentmax can replace softmax in the attention mechanism with some success. A recent work of Zhang et al. (2021) attempted to replace softmax with a component-wise ReLU in the attention mechanism. Unfortunately, in its pure form, this replacement leads to the inability of the model to learn at all, since its loss function does not decrease during optimization. The authors solve this problem by adding a normalizing layer on top of the attention layer.\n\nThese and other works (Zhang et al., 2019) state that sparsity in the weights of attention produces more interpretable patterns. However, Meister et al. (2021) questioned this claim and were unable to find clear evidence to support it. Therefore, in this work, we focused on the application of α-ReLU to the output of the transformer model, and not to the mechanism of attention, but at the same time we do not deny the possibility of studying the latter.\n\nSelf-normalization. Self-normalizing training aims to bypass the need of normalization during inference time. This is done by tweaking the learning mechanism so that the sum of all predictions sums (approximately) to a constant value. Theoretical work on why this works is poorly understood (Andreas et al., 2015) but early work in neural machine translation has shown its empirical value. Vaswani et al. (2013) achieves that by using noisecontrastive estimation (the neural model is used to re-rank the output of a hierarchical phrase-based machine translation system). Noise-contrastive estimation is also the standard training mechanism for word2vec (more popular than the alternative hierarchical softmax), which also eschews any expensive normalization. Differently, Devlin et al. (2014) changes the training loss to include a factor that encourages the normalizing factor to be 1. At inference time, this is just assumed and decoding time is reported to achieve a 15x speed-up.\n\n ",
    "all_spans": [
      {
        "span_text": "Noise-contrastive estimation is also the standard training mechanism for word2vec (more popular than the alternative hierarchical softmax), which also eschews any expensive normalization.",
        "gpt_label": "Unsupported Claim",
        "reason": "Makes specific and comparative claims about word2vec training (being the standard and more popular than hierarchical softmax) without providing citations; such niche assertions about prior work require evidence.",
        "start": 1954,
        "end": 2140
      },
      {
        "span_text": "Malaviya et al. (2018)",
        "gpt_label": "Format",
        "reason": "Wrong citation style: narrative citations are improperly separated by semicolons; multiple references should be grouped in a single parenthetical citation.",
        "start": 401,
        "end": 422
      },
      {
        "span_text": "Peters et al. (2019)",
        "gpt_label": "Format",
        "reason": "Wrong citation style: used as a narrative citation in a semicolon-separated list instead of being part of a single parenthetical group.",
        "start": 114,
        "end": 133
      },
      {
        "span_text": "Correia et al. (2019)",
        "gpt_label": "Format",
        "reason": "Wrong citation style and spacing: appears in a semicolon-separated narrative list and is missing a space after the preceding semicolon; should be in a grouped parenthetical citation.",
        "start": 444,
        "end": 464
      },
      {
        "span_text": "Theoretical work on why this works is poorly understood (Andreas et al., 2015) but early work in neural machine translation has shown its empirical value. Vaswani et al. (2013) achieves that by using noisecontrastive estimation (the neural model is used to re-rank the output of a hierarchical phrase-based machine translation system). Noise-contrastive estimation is also the standard training mechanism for word2vec (more popular than the alternative hierarchical softmax), which also eschews any expensive normalization.",
        "gpt_label": "Coherence",
        "reason": "The connection between these cited works is implied but not explicitly stated. It is unclear how Andreas et al. (2015) relates to Vaswani et al. (2013) beyond a vague 'achieves that,' and how noise-contrastive estimation specifically yields self-normalization. The transition to word2vec further shifts topics without clarifying the relevance to the prior claims, creating an abrupt, under-explained linkage across multiple sentences.",
        "start": 1622,
        "end": 2140
      },
      {
        "span_text": "Self-normalization. Self-normalizing training aims to bypass the need of normalization during inference time. This is done by tweaking the learning mechanism so that the sum of all predictions sums (approximately) to a constant value. Theoretical work on why this works is poorly understood (Andreas et al., 2015) but early work in neural machine translation has shown its empirical value. Vaswani et al. (2013) achieves that by using noisecontrastive estimation (the neural model is used to re-rank the output of a hierarchical phrase-based machine translation system). Noise-contrastive estimation is also the standard training mechanism for word2vec (more popular than the alternative hierarchical softmax), which also eschews any expensive normalization. Differently, Devlin et al. (2014) changes the training loss to include a factor that encourages the normalizing factor to be 1. At inference time, this is just assumed and decoding time is reported to achieve a 15x speed-up.",
        "gpt_label": "Lacks synthesis",
        "reason": "This paragraph summarizes prior work on self-normalization without connecting it to the authors’ α-ReLU contribution, articulating a gap, or explaining its relevance to their argument or motivation.",
        "start": 1390,
        "end": 2362
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "Noise-contrastive estimation is also the standard training mechanism for word2vec (more popular than the alternative hierarchical softmax), which also eschews any expensive normalization.",
          "gpt_label": "Unsupported Claim",
          "reason": "Makes specific and comparative claims about word2vec training (being the standard and more popular than hierarchical softmax) without providing citations; such niche assertions about prior work require evidence.",
          "start": 1954,
          "end": 2140
        }
      ],
      "Format": [
        {
          "span_text": "Malaviya et al. (2018)",
          "gpt_label": "Format",
          "reason": "Wrong citation style: narrative citations are improperly separated by semicolons; multiple references should be grouped in a single parenthetical citation.",
          "start": 401,
          "end": 422
        },
        {
          "span_text": "Peters et al. (2019)",
          "gpt_label": "Format",
          "reason": "Wrong citation style: used as a narrative citation in a semicolon-separated list instead of being part of a single parenthetical group.",
          "start": 114,
          "end": 133
        },
        {
          "span_text": "Correia et al. (2019)",
          "gpt_label": "Format",
          "reason": "Wrong citation style and spacing: appears in a semicolon-separated narrative list and is missing a space after the preceding semicolon; should be in a grouped parenthetical citation.",
          "start": 444,
          "end": 464
        }
      ],
      "Coherence": [
        {
          "span_text": "Theoretical work on why this works is poorly understood (Andreas et al., 2015) but early work in neural machine translation has shown its empirical value. Vaswani et al. (2013) achieves that by using noisecontrastive estimation (the neural model is used to re-rank the output of a hierarchical phrase-based machine translation system). Noise-contrastive estimation is also the standard training mechanism for word2vec (more popular than the alternative hierarchical softmax), which also eschews any expensive normalization.",
          "gpt_label": "Coherence",
          "reason": "The connection between these cited works is implied but not explicitly stated. It is unclear how Andreas et al. (2015) relates to Vaswani et al. (2013) beyond a vague 'achieves that,' and how noise-contrastive estimation specifically yields self-normalization. The transition to word2vec further shifts topics without clarifying the relevance to the prior claims, creating an abrupt, under-explained linkage across multiple sentences.",
          "start": 1622,
          "end": 2140
        }
      ],
      "Lacks synthesis": [
        {
          "span_text": "Self-normalization. Self-normalizing training aims to bypass the need of normalization during inference time. This is done by tweaking the learning mechanism so that the sum of all predictions sums (approximately) to a constant value. Theoretical work on why this works is poorly understood (Andreas et al., 2015) but early work in neural machine translation has shown its empirical value. Vaswani et al. (2013) achieves that by using noisecontrastive estimation (the neural model is used to re-rank the output of a hierarchical phrase-based machine translation system). Noise-contrastive estimation is also the standard training mechanism for word2vec (more popular than the alternative hierarchical softmax), which also eschews any expensive normalization. Differently, Devlin et al. (2014) changes the training loss to include a factor that encourages the normalizing factor to be 1. At inference time, this is just assumed and decoding time is reported to achieve a 15x speed-up.",
          "gpt_label": "Lacks synthesis",
          "reason": "This paragraph summarizes prior work on self-normalization without connecting it to the authors’ α-ReLU contribution, articulating a gap, or explaining its relevance to their argument or motivation.",
          "start": 1390,
          "end": 2362
        }
      ]
    }
  },
  "paper_93.txt": {
    "filename": "paper_93.txt",
    "full_text": "Introduction\n\nAs a fundamental task in the natural language processing (NLP) field, unsupervised sentence representation learning (Kiros et al., 2015;Hill et al., 2016) aims to derive high-quality sentence representations that can benefit various downstream tasks, especially for low-resourced domains or computationally expensive tasks, e.g., zero-shot text semantic match (Qiao et al., 2016), large-scale semantic similarity comparison (Agirre et al., 2015), and document retrieval (Le and Mikolov, 2014).\n\nAs a widely used semantic representation approach, pre-trained language models (PLMs) (Devlin et al., 2019) have achieved remarkable performance on various NLP tasks. However, several studies have found that the original sentence representations derived by PLMs are not uniformly distributed with respect to directions, but instead occupy a narrow cone in the vector space (Ethayarajh, 2019), which largely limits their expressiveness. To address this issue, contrastive learning (Chen et al., 2020) has been adopted to refine PLM-derived sentence representations. It pulls semantically close neighbors together to improve the alignment, while pushing apart non-neighbors for the uniformity of the whole representation space. In the learning process, both positive and negative examples are involved in contrast with the original sentence. For positive examples, previous works apply data augmentation strategies (Yan et al., 2021) on the original sentence to generate highly similar variations. While, negative examples are commonly randomly sampled from the batch or training data (e.g., inbatch negatives (Gao et al., 2021)), due to the lack of ground-truth negatives.\n\nAlthough such a negative sampling way is simple and convenient, it may cause sampling bias and affects the sentence representation learning. First, the sampled negatives are likely to be false negatives that are indeed semantically close to the original sentence. As shown in Figure 1, given a random input sentence, about half of in-batch negatives have a cosine similarity above 0.7 with the original sentence based on the SimCSE model (Gao et al., 2021). It may hurt the semantics of the sentence representations by simply pushing apart sampled negatives. Second, due to the anisotropy problem (Ethayarajh, 2019), the sampled negatives are from the narrow representation cone spanned by PLMs, which cannot fully reflect the overall semantics of the representation space. Hence, it is sub-optimal for learning the uniformity objective of sentence representations.\n\nTo address the above issues, we propose a debiased contrastive learning framework for unsupervised sentence representation learning. The core idea is to improve the random negative sampling strategy for alleviating the sampling bias problem. First, in our framework, we design an instance weighting method to punish the sampled false negatives during training. We incorporate a complementary model to evaluate the similarity score between each negative and the original sentence, and assign lower weight for negatives with a higher similarity score. In this way, we can detect semantically-close false negatives and further reduce their influence. Second, we randomly initialize new negatives based on random Gaussian noise to simulate sampling within the whole semantic space, and devise a gradient-based algorithm to optimize the noise-based negatives towards the most nonuniform points. By learning to contrast with the nonuniform noise-based negatives, we can extend the occupied space of sentence representations and improve the uniformity of the representation space.\n\nTo this end, we propose DCLR, a general framework towards Debiased Contrastive Learning of unsupervised sentence Representations. In our approach, we first initialize the noise-based negatives from a Gaussian distribution, and leverage a gradient-based algorithm to update the new negatives by considering the uniformity of the representation space. Then, we adopt the complementary model to produce the weights for the new negatives and randomly sampled negatives, where the false negatives will be punished. Finally, we augment the positive examples via dropout (Gao et al., 2021) and combine it with the negatives for contrastive learning. We demonstrate that our DCLR outperforms competitive baselines on semantic textual similarity (STS) tasks using BERT (Devlin et al., 2019) and RoBERTa (Liu et al., 2019).\n\nOur contributions are summarized as follows:\n(1) To our knowledge, our approach is the first attempt to reduce the sampling bias in contrastive learning of unsupervised sentence representations.\n(2) We propose DCLR, a debiased contrastive learning framework that utilizes an instance weighting method to punish false negatives and generates noise-based negatives to guarantee the uniformity of the whole representation space.\n(3) Experimental results on seven semantic textual similarity tasks show the effectiveness of our framework.\n\n ",
    "all_spans": [
      {
        "span_text": "several studies have found that the original sentence representations derived by PLMs are not uniformly distributed with respect to directions, but instead occupy a narrow cone in the vector space",
        "gpt_label": "Unsupported Claim",
        "reason": "Claims multiple prior studies but cites only one (Ethayarajh, 2019); additional supporting citations are needed.",
        "start": 676,
        "end": 872
      },
      {
        "span_text": "To address this issue, contrastive learning (Chen et al., 2020) has been adopted to refine PLM-derived sentence representations.",
        "gpt_label": "Unsupported Claim",
        "reason": "Asserts adoption of contrastive learning for refining PLM-based sentence representations but does not cite the specific NLP/sentence-representation works that did so (e.g., SimCSE); the provided citation (Chen et al., 2020) is a general contrastive learning paper in vision.",
        "start": 935,
        "end": 1061
      },
      {
        "span_text": "(1) To our knowledge, our approach is the first attempt to reduce the sampling bias in contrastive learning of unsupervised sentence representations.",
        "gpt_label": "Unsupported Claim",
        "reason": "Novelty claim about prior work lacks evidence or supporting citations demonstrating no previous attempt addressed this.",
        "start": 4441,
        "end": 4589
      },
      {
        "span_text": "To address this issue, contrastive learning (Chen et al., 2020) has been adopted to refine PLM-derived sentence representations. It pulls semantically close neighbors together to improve the alignment, while pushing apart non-neighbors for the uniformity of the whole representation space. In the learning process, both positive and negative examples are involved in contrast with the original sentence. For positive examples, previous works apply data augmentation strategies (Yan et al., 2021) on the original sentence to generate highly similar variations. While, negative examples are commonly randomly sampled from the batch or training data (e.g., inbatch negatives (Gao et al., 2021)), due to the lack of ground-truth negatives.",
        "gpt_label": "Coherence",
        "reason": "The sequence introduces contrastive learning with a general citation (Chen et al., 2020) and then abruptly shifts to separate works on positives (Yan et al., 2021) and negatives (Gao et al., 2021) without explicitly linking how these specific methods relate to Chen’s framework or to each other. The relationships among the cited works are implied rather than clearly stated, creating an abrupt flow across multiple sentences.",
        "start": 935,
        "end": 1660
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "several studies have found that the original sentence representations derived by PLMs are not uniformly distributed with respect to directions, but instead occupy a narrow cone in the vector space",
          "gpt_label": "Unsupported Claim",
          "reason": "Claims multiple prior studies but cites only one (Ethayarajh, 2019); additional supporting citations are needed.",
          "start": 676,
          "end": 872
        },
        {
          "span_text": "To address this issue, contrastive learning (Chen et al., 2020) has been adopted to refine PLM-derived sentence representations.",
          "gpt_label": "Unsupported Claim",
          "reason": "Asserts adoption of contrastive learning for refining PLM-based sentence representations but does not cite the specific NLP/sentence-representation works that did so (e.g., SimCSE); the provided citation (Chen et al., 2020) is a general contrastive learning paper in vision.",
          "start": 935,
          "end": 1061
        },
        {
          "span_text": "(1) To our knowledge, our approach is the first attempt to reduce the sampling bias in contrastive learning of unsupervised sentence representations.",
          "gpt_label": "Unsupported Claim",
          "reason": "Novelty claim about prior work lacks evidence or supporting citations demonstrating no previous attempt addressed this.",
          "start": 4441,
          "end": 4589
        }
      ],
      "Format": [],
      "Coherence": [
        {
          "span_text": "To address this issue, contrastive learning (Chen et al., 2020) has been adopted to refine PLM-derived sentence representations. It pulls semantically close neighbors together to improve the alignment, while pushing apart non-neighbors for the uniformity of the whole representation space. In the learning process, both positive and negative examples are involved in contrast with the original sentence. For positive examples, previous works apply data augmentation strategies (Yan et al., 2021) on the original sentence to generate highly similar variations. While, negative examples are commonly randomly sampled from the batch or training data (e.g., inbatch negatives (Gao et al., 2021)), due to the lack of ground-truth negatives.",
          "gpt_label": "Coherence",
          "reason": "The sequence introduces contrastive learning with a general citation (Chen et al., 2020) and then abruptly shifts to separate works on positives (Yan et al., 2021) and negatives (Gao et al., 2021) without explicitly linking how these specific methods relate to Chen’s framework or to each other. The relationships among the cited works are implied rather than clearly stated, creating an abrupt flow across multiple sentences.",
          "start": 935,
          "end": 1660
        }
      ]
    }
  },
  "paper_94.txt": {
    "filename": "paper_94.txt",
    "full_text": "Related Work\n\nTask-Oriented Dialogue. Task-oriented dialogue aims at accomplishing user's goal. Traditional systems (Williams and Young, 2007;Young et al., 2013) adopt a pipelined approach that requires dialogue state tracking for understanding user's goal, dialogue policy learning for deciding which system action to take, and natural language generation for generating dialogue responses.\n\nRecently, to simplify the modelling effort, researchers have shifted their attention to building neural network models that address the TOD subtasks Eric et al., 2017;Lei et al., 2018;Liang et al., 2020). With the advances in pretrained language models (PLMs), Budzianowski and Vulić (2019) first applied the GPT-2 model for the NLG task. Lin et al. (2020) and  moved one step forward and utilized pretrained language models to solve all TOD sub-tasks conditioned on the history of oracle belief states. Based on the GPT-2 model, Hosseini-Asl et al. (2020) proposed a cascaded model, SimpleTOD, that addresses all TOD sub-tasks without using the oracle information. To improve the system performance, Peng et al. (2021) and Liu et al. (2021) applied dialogue pre-training over external dialogue corpora. However, both methods require the pretraining data to be fully annotated for all TOD sub-tasks (i.e., DST, POL, and NLG) which greatly limits the amount of data they can use. Additionally, Liu et al. (2021) achieved better results with noisy chanel model that requires two additional language models for outputs re-scoring. Unlike their approach, we address the task of task-oriented dialogue with a single unified model.\n\nLanguage Model Pre-training. The research community has witnessed remarkable progress of pre-training methods in a wide range of NLP tasks, including language understanding (Peters et al., 2018;Devlin et al., 2019;Yang et al., 2019) and text generation (Radford et al., 2019;Lewis et al., 2020;Raffel et al., 2020).\n\nIn the dialogue domain, many models are pretrained on open-domain conversational data like Reddit. Based on GPT-2, Transfertransfo (Wolf et al., 2019b) achieves good results on ConvAI-2 competition. As another extension of GPT-2, Di-aloGPT (Zhang et al., 2020c) performs well in generating open-domain dialogue response. ConveRT ) is a language model with dual-encoder built for the task of response selection. PLATO (Bao et al., 2020) pre-trains a model with discrete latent variable structure for the response generation task.  adapts BERT with TOD pre-training and achieves strong performances on four dialogue understanding tasks.\n\nPre-training on Supplementary Data. Recent work (Phang et al., 2018;Aghajanyan et al., 2021) found that supplementary training on the tasks with intermediate-labelled data improves the performance of the fine-tuned models on GLUE natural language understanding benchmark (Wang et al., 2018). Our work studies a similar supplementary training setup with intermediate-labelled data for task-oriented dialogue systems. Unlike previous work, we use a single multi-task model for all relevant sub-tasks in task-oriented dialogue systems.\n\n ",
    "all_spans": [
      {
        "span_text": "In the dialogue domain, many models are pretrained on open-domain conversational data like Reddit.",
        "gpt_label": "Unsupported Claim",
        "reason": "Claims a trend and mentions a dataset (Reddit) without citing specific works or the dataset source at first mention.",
        "start": 1907,
        "end": 2004
      },
      {
        "span_text": "ConvAI-2 competition.",
        "gpt_label": "Unsupported Claim",
        "reason": "First mention of a shared task/competition should include a citation to the competition/dataset.",
        "start": 2082,
        "end": 2102
      },
      {
        "span_text": "ConveRT ) is a language model with dual-encoder built for the task of response selection.",
        "gpt_label": "Unsupported Claim",
        "reason": "Introduces a specific model (ConveRT) without providing a citation at first mention.",
        "start": 2223,
        "end": 2311
      },
      {
        "span_text": " adapts BERT with TOD pre-training and achieves strong performances on four dialogue understanding tasks.",
        "gpt_label": "Unsupported Claim",
        "reason": "Refers to an unnamed prior work and performance claim without any accompanying citation.",
        "start": 2428,
        "end": 2532
      },
      {
        "span_text": "ConveRT ) is a language model with dual-encoder built for the task of response selection. PLATO (Bao et al., 2020) pre-trains a model with discrete latent variable structure for the response generation task.  adapts BERT with TOD pre-training and achieves strong performances on four dialogue understanding tasks.",
        "gpt_label": "Coherence",
        "reason": "These sentences list disparate works (response selection, response generation, dialogue understanding) with no explicit transitions or explanation of their relationships. The final sentence omits the cited work’s name, making its connection to the prior works unclear. The coherence issue arises across multiple sentences.",
        "start": 2223,
        "end": 2532
      },
      {
        "span_text": "Recently, to simplify the modelling effort, researchers have shifted their attention to building neural network models that address the TOD subtasks Eric et al., 2017;Lei et al., 2018;Liang et al., 2020).",
        "gpt_label": "Lacks synthesis",
        "reason": "Lists prior work without explaining its relevance or connection to the authors’ argument or contribution.",
        "start": 389,
        "end": 589
      },
      {
        "span_text": "With the advances in pretrained language models (PLMs), Budzianowski and Vulić (2019) first applied the GPT-2 model for the NLG task. Lin et al. (2020) and  moved one step forward and utilized pretrained language models to solve all TOD sub-tasks conditioned on the history of oracle belief states. Based on the GPT-2 model, Hosseini-Asl et al. (2020) proposed a cascaded model, SimpleTOD, that addresses all TOD sub-tasks without using the oracle information.",
        "gpt_label": "Lacks synthesis",
        "reason": "Summarizes several prior systems in sequence without articulating a clear gap or explicitly tying these summaries to the authors’ perspective within the span.",
        "start": 590,
        "end": 1045
      },
      {
        "span_text": "In the dialogue domain, many models are pretrained on open-domain conversational data like Reddit. Based on GPT-2, Transfertransfo (Wolf et al., 2019b) achieves good results on ConvAI-2 competition. As another extension of GPT-2, Di-aloGPT (Zhang et al., 2020c) performs well in generating open-domain dialogue response. ConveRT ) is a language model with dual-encoder built for the task of response selection. PLATO (Bao et al., 2020) pre-trains a model with discrete latent variable structure for the response generation task.  adapts BERT with TOD pre-training and achieves strong performances on four dialogue understanding tasks.",
        "gpt_label": "Lacks synthesis",
        "reason": "Enumerates models and results without explaining their relevance to the paper’s goals or identifying a specific gap; presents disconnected summaries.",
        "start": 1907,
        "end": 2532
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "In the dialogue domain, many models are pretrained on open-domain conversational data like Reddit.",
          "gpt_label": "Unsupported Claim",
          "reason": "Claims a trend and mentions a dataset (Reddit) without citing specific works or the dataset source at first mention.",
          "start": 1907,
          "end": 2004
        },
        {
          "span_text": "ConvAI-2 competition.",
          "gpt_label": "Unsupported Claim",
          "reason": "First mention of a shared task/competition should include a citation to the competition/dataset.",
          "start": 2082,
          "end": 2102
        },
        {
          "span_text": "ConveRT ) is a language model with dual-encoder built for the task of response selection.",
          "gpt_label": "Unsupported Claim",
          "reason": "Introduces a specific model (ConveRT) without providing a citation at first mention.",
          "start": 2223,
          "end": 2311
        },
        {
          "span_text": " adapts BERT with TOD pre-training and achieves strong performances on four dialogue understanding tasks.",
          "gpt_label": "Unsupported Claim",
          "reason": "Refers to an unnamed prior work and performance claim without any accompanying citation.",
          "start": 2428,
          "end": 2532
        }
      ],
      "Format": [],
      "Coherence": [
        {
          "span_text": "ConveRT ) is a language model with dual-encoder built for the task of response selection. PLATO (Bao et al., 2020) pre-trains a model with discrete latent variable structure for the response generation task.  adapts BERT with TOD pre-training and achieves strong performances on four dialogue understanding tasks.",
          "gpt_label": "Coherence",
          "reason": "These sentences list disparate works (response selection, response generation, dialogue understanding) with no explicit transitions or explanation of their relationships. The final sentence omits the cited work’s name, making its connection to the prior works unclear. The coherence issue arises across multiple sentences.",
          "start": 2223,
          "end": 2532
        }
      ],
      "Lacks synthesis": [
        {
          "span_text": "Recently, to simplify the modelling effort, researchers have shifted their attention to building neural network models that address the TOD subtasks Eric et al., 2017;Lei et al., 2018;Liang et al., 2020).",
          "gpt_label": "Lacks synthesis",
          "reason": "Lists prior work without explaining its relevance or connection to the authors’ argument or contribution.",
          "start": 389,
          "end": 589
        },
        {
          "span_text": "With the advances in pretrained language models (PLMs), Budzianowski and Vulić (2019) first applied the GPT-2 model for the NLG task. Lin et al. (2020) and  moved one step forward and utilized pretrained language models to solve all TOD sub-tasks conditioned on the history of oracle belief states. Based on the GPT-2 model, Hosseini-Asl et al. (2020) proposed a cascaded model, SimpleTOD, that addresses all TOD sub-tasks without using the oracle information.",
          "gpt_label": "Lacks synthesis",
          "reason": "Summarizes several prior systems in sequence without articulating a clear gap or explicitly tying these summaries to the authors’ perspective within the span.",
          "start": 590,
          "end": 1045
        },
        {
          "span_text": "In the dialogue domain, many models are pretrained on open-domain conversational data like Reddit. Based on GPT-2, Transfertransfo (Wolf et al., 2019b) achieves good results on ConvAI-2 competition. As another extension of GPT-2, Di-aloGPT (Zhang et al., 2020c) performs well in generating open-domain dialogue response. ConveRT ) is a language model with dual-encoder built for the task of response selection. PLATO (Bao et al., 2020) pre-trains a model with discrete latent variable structure for the response generation task.  adapts BERT with TOD pre-training and achieves strong performances on four dialogue understanding tasks.",
          "gpt_label": "Lacks synthesis",
          "reason": "Enumerates models and results without explaining their relevance to the paper’s goals or identifying a specific gap; presents disconnected summaries.",
          "start": 1907,
          "end": 2532
        }
      ]
    }
  },
  "paper_95.txt": {
    "filename": "paper_95.txt",
    "full_text": "Related work\n\nThe application of NLP methods to automatic LSC detection is already a rather well-developed subfield of NLP research (Tahmasebi et al., 2018;Kutuzov et al., 2018). In particular, the emergence of word embeddings as a viable way to model the distributional hypothesis in semantics (Firth, 1957) has paved the way for an application of word embeddings to LSC modeling (Kim et al., 2014;Hamilton et al., 2016b;Eger and Mehler, 2016;Yao et al., 2018). Synchronically, the meaning of a word is characterized by word embeddings in terms of the contexts it appears in. LSC is captured by training word embeddings at different time points and comparing these distributions typically using cosine distance.\n\nThe main issues in this comparison is the alignment of temporal embeddings spaces, especially for neural embeddings as these are initialized and trained stochastically, which means that separate runs -on even the same data -will yield different embeddings spaces. Thus, work has focused on the development of methods to perform alignments to make embedding spaces comparable across time (see Kutuzov et al. (2018) for an overview). As an alternative to neural embeddings, scholars have also used purely count-based measures, which are naturally aligned across dimensions. Normalisation techniques are also applied, e.g. based on positive pointwise mutual information (PPMI) (Hamilton et al., 2016b;Yao et al., 2018).\n\nMost studies of LSC do not rely on a control dataset against which to validate their conclusions. In Dubossarsky et al. (2017), on the contrary, it is argued that any claims about putative laws of semantic change in diachronic corpora must be evaluated against a relevant control condition. The authors propose a methodology in which a control condition is created artificially from the original diachronic text collection by reshuffling the data.\n\nNo systematic LSC is expected in the artificially developed control dataset.\n\nThe distributional hypothesis has also been proposed as an explanatory model within the domain of phonology suggesting that phonological classes are acquired through distributional information (Chomsky and Halle, 1968;Mielke, 2008). Driven by this hypothesis, recent work has focused on testing how distributional properties can be learned by phoneme embeddings (see Mayer 2020 for an overview). Silfverberg et al. (2018) investigated to what extent learned vector representations of phonemes align with their respective representations in a feature space in which dimensions are articulatory descriptors (e.g., ±plosive). Recently, Mayer (2020) has shown that phonological classes, such as long and short vowels, can be deduced from phoneme embeddings normalised using PPMI by iteratively performing PCA on candidate classes.\n\nThus, while the distributional hypothesis for phonology is well-established, one notable issue is the fact that the empirical evidence to study sound change is relatively inaccessible since it requires recorded speech or phonologically transcribed data. Simulation is therefore used as a tool for studying the underlying mechanisms of sound change by creating computational models based on linguistic theory (Wedel, 2015). Through simulation, questions pertaining to e.g., what factors influence the (in)stability of vowel systems across generations (de Boer, 2003) can be modeled by controlling the assumptions made by the model. Work on simulation ranges from implementing theoretical approaches using mathematical models (Pierrehumbert, 2001;Blythe and Croft, 2012) to iterated learning and neural networks (Hare and Elman, 1995;Beguš, 2021).\n\nWhile the output of such models can be tested empirically on what we observe at a synchronic level, they are primarily theoretically driven. In this paper, we wish to take a data-driven approach and utilize some of the methods reviewed above to track historical sound change in writing. Rather than using word embeddings as done to model lexical change, we will use character embeddings, that are better suited to the task of sound change modeling.\n\n ",
    "all_spans": [
      {
        "span_text": "Most studies of LSC do not rely on a control dataset against which to validate their conclusions.",
        "gpt_label": "Unsupported Claim",
        "reason": "This is a broad claim about the existing literature that cites no evidence or survey to substantiate it.",
        "start": 1414,
        "end": 1510
      },
      {
        "span_text": "As an alternative to neural embeddings, scholars have also used purely count-based measures, which are naturally aligned across dimensions.",
        "gpt_label": "Unsupported Claim",
        "reason": "This statement references prior work in general terms but does not provide citations to studies that used count-based measures for LSC.",
        "start": 1134,
        "end": 1272
      },
      {
        "span_text": "the empirical evidence to study sound change is relatively inaccessible since it requires recorded speech or phonologically transcribed data.",
        "gpt_label": "Unsupported Claim",
        "reason": "This is a specific claim about data availability/practical constraints in a niche subfield and should be supported with citations.",
        "start": 2869,
        "end": 3009
      },
      {
        "span_text": "Kutuzov et al. (2018)",
        "gpt_label": "Format",
        "reason": "Narrative-style citation used inside parentheses; should be parenthetical style (e.g., Kutuzov et al., 2018) to avoid nested parentheses.",
        "start": 1096,
        "end": 1116
      },
      {
        "span_text": "Mayer 2020",
        "gpt_label": "Format",
        "reason": "Missing comma between author and year; should be Mayer, 2020 (or Mayer (2020) in narrative form).",
        "start": 2302,
        "end": 2312
      },
      {
        "span_text": "The authors propose a methodology in which a control condition is created artificially from the original diachronic text collection by reshuffling the data.\n\nNo systematic LSC is expected in the artificially developed control dataset.\n\nThe distributional hypothesis has also been proposed as an explanatory model within the domain of phonology suggesting that phonological classes are acquired through distributional information (Chomsky and Halle, 1968;Mielke, 2008).",
        "gpt_label": "Coherence",
        "reason": "Abrupt shift from discussing control datasets for lexical semantic change to phonology without an explicit transition or explanation of relevance; the relationship between the preceding discussion and the new topic is implied but not stated.",
        "start": 1702,
        "end": 2167
      },
      {
        "span_text": "The main issues in this comparison is the alignment of temporal embeddings spaces, especially for neural embeddings as these are initialized and trained stochastically, which means that separate runs -on even the same data -will yield different embeddings spaces. Thus, work has focused on the development of methods to perform alignments to make embedding spaces comparable across time (see Kutuzov et al. (2018) for an overview). As an alternative to neural embeddings, scholars have also used purely count-based measures, which are naturally aligned across dimensions. Normalisation techniques are also applied, e.g. based on positive pointwise mutual information (PPMI) (Hamilton et al., 2016b;Yao et al., 2018).",
        "gpt_label": "Lacks synthesis",
        "reason": "Summarizes prior methods and issues (alignment, count-based measures, normalization) without articulating the authors’ perspective, research gap, or how these points relate to their approach.",
        "start": 705,
        "end": 1412
      },
      {
        "span_text": "Most studies of LSC do not rely on a control dataset against which to validate their conclusions. In Dubossarsky et al. (2017), on the contrary, it is argued that any claims about putative laws of semantic change in diachronic corpora must be evaluated against a relevant control condition. The authors propose a methodology in which a control condition is created artificially from the original diachronic text collection by reshuffling the data.\n\nNo systematic LSC is expected in the artificially developed control dataset.",
        "gpt_label": "Lacks synthesis",
        "reason": "Describes a control-condition methodology and its expected outcome without connecting it to the authors’ own study (e.g., whether or how they adopt, adapt, or contrast with this approach).",
        "start": 1414,
        "end": 1934
      },
      {
        "span_text": "The distributional hypothesis has also been proposed as an explanatory model within the domain of phonology suggesting that phonological classes are acquired through distributional information (Chomsky and Halle, 1968;Mielke, 2008). Driven by this hypothesis, recent work has focused on testing how distributional properties can be learned by phoneme embeddings (see Mayer 2020 for an overview). Silfverberg et al. (2018) investigated to what extent learned vector representations of phonemes align with their respective representations in a feature space in which dimensions are articulatory descriptors (e.g., ±plosive). Recently, Mayer (2020) has shown that phonological classes, such as long and short vowels, can be deduced from phoneme embeddings normalised using PPMI by iteratively performing PCA on candidate classes.",
        "gpt_label": "Lacks synthesis",
        "reason": "Lists prior work on phoneme embeddings and phonological classes without explicitly stating how these findings motivate, inform, or contrast with the authors’ character-embedding approach.",
        "start": 1936,
        "end": 2755
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "Most studies of LSC do not rely on a control dataset against which to validate their conclusions.",
          "gpt_label": "Unsupported Claim",
          "reason": "This is a broad claim about the existing literature that cites no evidence or survey to substantiate it.",
          "start": 1414,
          "end": 1510
        },
        {
          "span_text": "As an alternative to neural embeddings, scholars have also used purely count-based measures, which are naturally aligned across dimensions.",
          "gpt_label": "Unsupported Claim",
          "reason": "This statement references prior work in general terms but does not provide citations to studies that used count-based measures for LSC.",
          "start": 1134,
          "end": 1272
        },
        {
          "span_text": "the empirical evidence to study sound change is relatively inaccessible since it requires recorded speech or phonologically transcribed data.",
          "gpt_label": "Unsupported Claim",
          "reason": "This is a specific claim about data availability/practical constraints in a niche subfield and should be supported with citations.",
          "start": 2869,
          "end": 3009
        }
      ],
      "Format": [
        {
          "span_text": "Kutuzov et al. (2018)",
          "gpt_label": "Format",
          "reason": "Narrative-style citation used inside parentheses; should be parenthetical style (e.g., Kutuzov et al., 2018) to avoid nested parentheses.",
          "start": 1096,
          "end": 1116
        },
        {
          "span_text": "Mayer 2020",
          "gpt_label": "Format",
          "reason": "Missing comma between author and year; should be Mayer, 2020 (or Mayer (2020) in narrative form).",
          "start": 2302,
          "end": 2312
        }
      ],
      "Coherence": [
        {
          "span_text": "The authors propose a methodology in which a control condition is created artificially from the original diachronic text collection by reshuffling the data.\n\nNo systematic LSC is expected in the artificially developed control dataset.\n\nThe distributional hypothesis has also been proposed as an explanatory model within the domain of phonology suggesting that phonological classes are acquired through distributional information (Chomsky and Halle, 1968;Mielke, 2008).",
          "gpt_label": "Coherence",
          "reason": "Abrupt shift from discussing control datasets for lexical semantic change to phonology without an explicit transition or explanation of relevance; the relationship between the preceding discussion and the new topic is implied but not stated.",
          "start": 1702,
          "end": 2167
        }
      ],
      "Lacks synthesis": [
        {
          "span_text": "The main issues in this comparison is the alignment of temporal embeddings spaces, especially for neural embeddings as these are initialized and trained stochastically, which means that separate runs -on even the same data -will yield different embeddings spaces. Thus, work has focused on the development of methods to perform alignments to make embedding spaces comparable across time (see Kutuzov et al. (2018) for an overview). As an alternative to neural embeddings, scholars have also used purely count-based measures, which are naturally aligned across dimensions. Normalisation techniques are also applied, e.g. based on positive pointwise mutual information (PPMI) (Hamilton et al., 2016b;Yao et al., 2018).",
          "gpt_label": "Lacks synthesis",
          "reason": "Summarizes prior methods and issues (alignment, count-based measures, normalization) without articulating the authors’ perspective, research gap, or how these points relate to their approach.",
          "start": 705,
          "end": 1412
        },
        {
          "span_text": "Most studies of LSC do not rely on a control dataset against which to validate their conclusions. In Dubossarsky et al. (2017), on the contrary, it is argued that any claims about putative laws of semantic change in diachronic corpora must be evaluated against a relevant control condition. The authors propose a methodology in which a control condition is created artificially from the original diachronic text collection by reshuffling the data.\n\nNo systematic LSC is expected in the artificially developed control dataset.",
          "gpt_label": "Lacks synthesis",
          "reason": "Describes a control-condition methodology and its expected outcome without connecting it to the authors’ own study (e.g., whether or how they adopt, adapt, or contrast with this approach).",
          "start": 1414,
          "end": 1934
        },
        {
          "span_text": "The distributional hypothesis has also been proposed as an explanatory model within the domain of phonology suggesting that phonological classes are acquired through distributional information (Chomsky and Halle, 1968;Mielke, 2008). Driven by this hypothesis, recent work has focused on testing how distributional properties can be learned by phoneme embeddings (see Mayer 2020 for an overview). Silfverberg et al. (2018) investigated to what extent learned vector representations of phonemes align with their respective representations in a feature space in which dimensions are articulatory descriptors (e.g., ±plosive). Recently, Mayer (2020) has shown that phonological classes, such as long and short vowels, can be deduced from phoneme embeddings normalised using PPMI by iteratively performing PCA on candidate classes.",
          "gpt_label": "Lacks synthesis",
          "reason": "Lists prior work on phoneme embeddings and phonological classes without explicitly stating how these findings motivate, inform, or contrast with the authors’ character-embedding approach.",
          "start": 1936,
          "end": 2755
        }
      ]
    }
  },
  "paper_96.txt": {
    "filename": "paper_96.txt",
    "full_text": "Related Work\n\nPre-processing steps can substantially alter the results of the LDA models even in languages with good tokenization heuristics such as English (Schofield and Mimno, 2016;May et al., 2016). We believe that languages that do not have clear tokenization standards deserve investigation into what kind of processing is appropriate. Many works recognize that LDA results can be improved when input are including phrases (Lindsey et al., 2012;Lau et al., 2013;Yu et al., 2013;El-Kishky et al., 2014;Wang et al., 2016;Bin et al., 2018;Li et al., 2018). We consider it valuable to specifically assess approaches to determining these phrases. Despite their popularity in analyzing large amounts of text data, LDA models are notoriously complex to evaluate. One must evaluate both the statistical fit of a model and the human-registered thematic coherence of the words found to arise in the high-probability words, or keys, of a topic, which may not correlate (Chang et al., 2009). Analyses often combine evaluations of fit (Wallach et al., 2009) and automated approximations of human judgments of coherence (Bouma, 2009;Mimno et al., 2011) based on mutual information, even with the expectation these may only somewhat correlate with true human judgments (Lau et al., 2014). A limitation of these existing approaches, however, is that they expect the vocabulary and tokenization to remain constant between two models. For our evaluation, we use a normalized log likelihood approach to capture fit while accounting for changes in vocabulary (Schofield and Mimno, 2016).\n\n ",
    "all_spans": [
      {
        "span_text": "Despite their popularity in analyzing large amounts of text data, LDA models are notoriously complex to evaluate.",
        "gpt_label": "Unsupported Claim",
        "reason": "Makes claims about LDA popularity and the difficulty of evaluating LDA without a supporting citation at first mention.",
        "start": 636,
        "end": 748
      },
      {
        "span_text": "A limitation of these existing approaches, however, is that they expect the vocabulary and tokenization to remain constant between two models.",
        "gpt_label": "Unsupported Claim",
        "reason": "Asserts a specific limitation of prior approaches without citing evidence or representative works to support the claim.",
        "start": 1261,
        "end": 1402
      },
      {
        "span_text": "We consider it valuable to specifically assess approaches to determining these phrases. Despite their popularity in analyzing large amounts of text data, LDA models are notoriously complex to evaluate.",
        "gpt_label": "Coherence",
        "reason": "Abrupt shift from discussing phrase-determination methods to evaluation of LDA without an explicit transitional link explaining how the evaluation discussion relates to the preceding focus on phrases.",
        "start": 549,
        "end": 748
      },
      {
        "span_text": "Many works recognize that LDA results can be improved when input are including phrases (Lindsey et al., 2012;Lau et al., 2013;Yu et al., 2013;El-Kishky et al., 2014;Wang et al., 2016;Bin et al., 2018;Li et al., 2018). We consider it valuable to specifically assess approaches to determining these phrases.",
        "gpt_label": "Lacks synthesis",
        "reason": "This summarizes prior work on using phrases but follows only with a vague statement of intent; it does not explicitly articulate the specific gap in the literature or how the proposed assessment advances beyond existing approaches.",
        "start": 339,
        "end": 635
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "Despite their popularity in analyzing large amounts of text data, LDA models are notoriously complex to evaluate.",
          "gpt_label": "Unsupported Claim",
          "reason": "Makes claims about LDA popularity and the difficulty of evaluating LDA without a supporting citation at first mention.",
          "start": 636,
          "end": 748
        },
        {
          "span_text": "A limitation of these existing approaches, however, is that they expect the vocabulary and tokenization to remain constant between two models.",
          "gpt_label": "Unsupported Claim",
          "reason": "Asserts a specific limitation of prior approaches without citing evidence or representative works to support the claim.",
          "start": 1261,
          "end": 1402
        }
      ],
      "Format": [],
      "Coherence": [
        {
          "span_text": "We consider it valuable to specifically assess approaches to determining these phrases. Despite their popularity in analyzing large amounts of text data, LDA models are notoriously complex to evaluate.",
          "gpt_label": "Coherence",
          "reason": "Abrupt shift from discussing phrase-determination methods to evaluation of LDA without an explicit transitional link explaining how the evaluation discussion relates to the preceding focus on phrases.",
          "start": 549,
          "end": 748
        }
      ],
      "Lacks synthesis": [
        {
          "span_text": "Many works recognize that LDA results can be improved when input are including phrases (Lindsey et al., 2012;Lau et al., 2013;Yu et al., 2013;El-Kishky et al., 2014;Wang et al., 2016;Bin et al., 2018;Li et al., 2018). We consider it valuable to specifically assess approaches to determining these phrases.",
          "gpt_label": "Lacks synthesis",
          "reason": "This summarizes prior work on using phrases but follows only with a vague statement of intent; it does not explicitly articulate the specific gap in the literature or how the proposed assessment advances beyond existing approaches.",
          "start": 339,
          "end": 635
        }
      ]
    }
  },
  "paper_97.txt": {
    "filename": "paper_97.txt",
    "full_text": "Introduction\n\nAlthough masked language models build contextualized word representations, they are pre-trained with losses that minimize distance to uncontextualized word embeddings (Peters et al., 2018;Devlin et al., 2019;Liu et al., 2019). In this paper, we introduce Question Answering Infused Pre-training (QUIP), a new pre-training loss based on question answering (QA) that depends much more directly on context, and learns improved token-level representations for a range of zero-and few-shot tasks.\n\nOur intuition for QUIP is that the contextualized representation for a phrase in a passage should contain enough information to identify all the questions that the phrase could answer in context. For example, in Figure 1, the representation for Johannes Brahms should be similar to the representation of all questions it can answer, such as \"Who wrote the violin concerto?\" We anticipate that optimizing passage representations for QA should benefit many downstream tasks, as question-answer pairs have been used as broad-coverage meaning representations (He et al., 2015; Michael et al., 2018), and a wide range of NLP tasks can be cast as QA problems (Levy et al., 2017; McCann et al., 2018; Gardner et al., 2019), For instance, our learned representations should encode whether a phrase answers a question like “Why was the movie considered good?”, which corresponds to identifying rationales for sentiment analysis.\n\nWe train QUIP with a bi-encoder extractive QA objective. The bi-encoder model independently encodes passages and questions such that the representation of each phrase in a passage is similar to the representation of reading comprehension questions answered by that phrase. To train this model, we use a question generation model to synthesize 80 million QA examples, then train the bi-encoder to match the predictions of a cross-encoder QA\nmodel, which processes the passage and question together, on these examples. Bi-encoder QA has been used before for efficient open-domain QA via phrase retrieval (Seo et al., 2018, 2019; Lee et al., 2020, 2021), but its lower accuracy compared to cross-encoder QA has previously been viewed as a drawback. We instead view the relative weakness of bi-encoder QA as an opportunity to improve contextual representations via knowledge distillation, as self-training can be effective when the student model must solve a harder problem than the teacher (Xie et al., 2020). In particular, since the bi-encoder does not know the question when encoding the passage, it must produce a single passage representation that simultaneously encodes the answers to all possible questions. In contrast, while\ncross-encoder QA models are more accurate, they depend on a specific question when encoding a passage; thus, they are less suited to downstream use cases that require contextualized representations of passages in isolation.\n\nWe show that QUIP token-level representations are useful in a variety of zero-shot and few-shot learning settings, both because the representations directly encode useful contextual information, and because we can often reduce downstream tasks to QA. For few-shot paraphrase detection, QUIP with BERTScore-based features (Zhang et al., 2020)\noutperforms prior work by 9 F1 points across four datasets. For few-shot named entity recognition (NER), QUIP combined with an initialization scheme that uses question embeddings improves over RoBERTa-large by 14 F1 across two\ndatasets. Finally, for zero-shot sentiment analysis, QUIP with question prompts improves over RoBERTa-large with MLM-style prompts by 5 accuracy points across three datasets, and extracts interpretable rationales as a side effect. Through ablations, we show that using real questions, a strong teacher model, and the bi-encoder architecture are all crucial to the success of QUIP. We will release code to reproduce all results upon publication.\n\n ",
    "all_spans": [
      {
        "span_text": "its lower accuracy compared to cross-encoder QA has previously been viewed as a drawback.",
        "gpt_label": "Unsupported Claim",
        "reason": "Makes a claim about prior comparative performance and how it was viewed in previous work without citing any supporting studies.",
        "start": 2067,
        "end": 2155
      },
      {
        "span_text": "cross-encoder QA models are more accurate",
        "gpt_label": "Unsupported Claim",
        "reason": "Asserts a comparative accuracy claim about model classes without providing citations.",
        "start": 2638,
        "end": 2679
      },
      {
        "span_text": "outperforms prior work by 9 F1 points across four datasets.",
        "gpt_label": "Unsupported Claim",
        "reason": "Claims improvement over prior work without citing which prior systems or papers; first mention of prior work should be accompanied by references.",
        "start": 3202,
        "end": 3260
      },
      {
        "span_text": "Bi-encoder QA has been used before for efficient open-domain QA via phrase retrieval (Seo et al., 2018, 2019; Lee et al., 2020, 2021), but its lower accuracy compared to cross-encoder QA has previously been viewed as a drawback. We instead view the relative weakness of bi-encoder QA as an opportunity to improve contextual representations via knowledge distillation, as self-training can be effective when the student model must solve a harder problem than the teacher (Xie et al., 2020).",
        "gpt_label": "Coherence",
        "reason": "The transition from prior work on bi-encoder QA for phrase retrieval to a claim about knowledge distillation justified by self-training is abrupt. The relationship between these cited lines of work is implied rather than explicitly explained, leaving unclear how the retrieval-focused prior work connects to the self-training principle supporting the proposed approach.",
        "start": 1930,
        "end": 2414
      },
      {
        "span_text": "question-answer pairs have been used as broad-coverage meaning representations (He et al., 2015; Michael et al., 2018), and a wide range of NLP tasks can be cast as QA problems (Levy et al., 2017; McCann et al., 2018; Gardner et al., 2019),",
        "gpt_label": "Lacks synthesis",
        "reason": "This segment stacks citations to assert broad claims about QA without integrating what specific insights or limitations from these works motivate QUIP, nor does it explicitly articulate the precise gap that these prior approaches leave for the proposed method to address.",
        "start": 977,
        "end": 1212
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "its lower accuracy compared to cross-encoder QA has previously been viewed as a drawback.",
          "gpt_label": "Unsupported Claim",
          "reason": "Makes a claim about prior comparative performance and how it was viewed in previous work without citing any supporting studies.",
          "start": 2067,
          "end": 2155
        },
        {
          "span_text": "cross-encoder QA models are more accurate",
          "gpt_label": "Unsupported Claim",
          "reason": "Asserts a comparative accuracy claim about model classes without providing citations.",
          "start": 2638,
          "end": 2679
        },
        {
          "span_text": "outperforms prior work by 9 F1 points across four datasets.",
          "gpt_label": "Unsupported Claim",
          "reason": "Claims improvement over prior work without citing which prior systems or papers; first mention of prior work should be accompanied by references.",
          "start": 3202,
          "end": 3260
        }
      ],
      "Format": [],
      "Coherence": [
        {
          "span_text": "Bi-encoder QA has been used before for efficient open-domain QA via phrase retrieval (Seo et al., 2018, 2019; Lee et al., 2020, 2021), but its lower accuracy compared to cross-encoder QA has previously been viewed as a drawback. We instead view the relative weakness of bi-encoder QA as an opportunity to improve contextual representations via knowledge distillation, as self-training can be effective when the student model must solve a harder problem than the teacher (Xie et al., 2020).",
          "gpt_label": "Coherence",
          "reason": "The transition from prior work on bi-encoder QA for phrase retrieval to a claim about knowledge distillation justified by self-training is abrupt. The relationship between these cited lines of work is implied rather than explicitly explained, leaving unclear how the retrieval-focused prior work connects to the self-training principle supporting the proposed approach.",
          "start": 1930,
          "end": 2414
        }
      ],
      "Lacks synthesis": [
        {
          "span_text": "question-answer pairs have been used as broad-coverage meaning representations (He et al., 2015; Michael et al., 2018), and a wide range of NLP tasks can be cast as QA problems (Levy et al., 2017; McCann et al., 2018; Gardner et al., 2019),",
          "gpt_label": "Lacks synthesis",
          "reason": "This segment stacks citations to assert broad claims about QA without integrating what specific insights or limitations from these works motivate QUIP, nor does it explicitly articulate the precise gap that these prior approaches leave for the proposed method to address.",
          "start": 977,
          "end": 1212
        }
      ]
    }
  },
  "paper_98.txt": {
    "filename": "paper_98.txt",
    "full_text": "Introduction\n\nRetrieval systems aim at retrieving the documents most relevant to the input queries, and have received substantial spotlight since they work as core elements in diverse applications, especially for open-domain question answering (QA) (Voorhees, 1999). Open-domain QA is a task of answering the question from a massive amount of documents, often requiring two components, a retriever and a reader (Chen et al., 2017;Karpukhin et al., 2020). Specifically, a retriever ranks the most questionrelated documents, and a reader answers the question using the retrieved documents.\n\nTraditional sparse retrieval approaches such as BM25 (Robertson et al., 1994) and TF-IDF rely on term-based matching, hence suffering from the vocabulary mismatch problem: the failure of retrieving relevant documents due to the lexical difference from queries. To tackle such a problem, recent research focuses on dense retrieval models to generate learnable dense representations for queries and documents with a dual encoder structure (Karpukhin et al., 2020;. Despite their recent successes, some challenges still remain in the dense retrieval scheme for a couple of reasons. First, dense retrieval models need a large amount of labeled training data for a decent performance. However, as Figure 1 shows, the proportion of labeled query-document pairs is extremely small since it is almost impossible to rely on humans for the annotations of a large document corpus. Second, in order to adapt a retrieval model to the real world, where documents constantly emerge, handling unlabeled documents that are not seen during training should obviously be considered, but remains challenging.\n\nTo automatically expand the query-document pairs, recent work generates queries from generative models (Liang et al., 2020;Ma et al., 2021) or incorporates queries from other datasets , and then generates extra pairs of augmented queries and documents. However, these query augmentation schemes have serious obvious drawbacks. First, it is infeasible to augment queries for every document in the dataset (see the number of unlabeled documents in Figure 1), since generating and pairing queries are quite costly. Second, even after obtaining new pairs, we need extra training steps to reflect the generated pairs on the retrieval model. Third, this query augmentation method does not add variations to the documents but only to the queries, thus it may be suboptimal to handle enormous unlabeled documents. Since augmenting additional queries is costly, the question is then if it is feasible to only manipulate the given query-document pairing to handle numerous unlabeled documents. To answer this question, we first visualize the embeddings of labeled and unlabeled documents. Figure 1 shows that there is no distinct distributional shift between labeled and unlabeled documents. Thus it could be effective to manipulate only the labeled documents to handle the nearby unlabeled documents as well as the labeled documents. Using this observation, we propose a novel document augmentation method for a dense retriever, which not only interpolates two different document representations associated with the labeled query (Figure 2, center), but also stochastically perturbs the representations of labeled documents with a dropout mask (Figure 2,right). One notable advantage of our scheme is that, since it manipulates only the representations of documents, our model does not require explicit annotation steps of query-document pairs, which is efficient. We refer to our overall method as Document Augmentation for dense Retrieval (DAR).\n\nWe experimentally validate our method on standard open-domain QA datasets, namely Natural Question (NQ) (Kwiatkowski et al., 2019) and Triv-iaQA (Joshi et al., 2017) (TQA), against various evaluation metrics for retrieval models. The experimental results show that our method significantly improves the retrieval performances on both the unlabeled and labeled documents. Furthermore, a detailed analysis of the proposed model shows that interpolation and stochastic perturbation positively contribute to the overall performance.\n\nOur contributions in this work are threefold: • We propose to augment documents for dense retrieval models to tackle the problem of insufficient labels of query-document pairs. • We present two novel document augmentation schemes for dense retrievers: interpolation and perturbation of document representations. • We show that our method achieves outstanding retrieval performances on both labeled and unlabeled documents on open-domain QA tasks.\n\n ",
    "all_spans": [
      {
        "span_text": "hence suffering from the vocabulary mismatch problem: the failure of retrieving relevant documents due to the lexical difference from queries.",
        "gpt_label": "Unsupported Claim",
        "reason": "Asserts a well-known IR issue without providing a citation to support the claim or define the term.",
        "start": 701,
        "end": 842
      },
      {
        "span_text": "First, dense retrieval models need a large amount of labeled training data for a decent performance.",
        "gpt_label": "Unsupported Claim",
        "reason": "Claims a data requirement about dense retrieval without citing supporting studies or benchmarks.",
        "start": 1158,
        "end": 1257
      },
      {
        "span_text": "Second, in order to adapt a retrieval model to the real world, where documents constantly emerge, handling unlabeled documents that are not seen during training should obviously be considered, but remains challenging.",
        "gpt_label": "Unsupported Claim",
        "reason": "States that handling unseen unlabeled documents remains challenging without citing prior work demonstrating this difficulty.",
        "start": 1447,
        "end": 1663
      },
      {
        "span_text": "or incorporates queries from other datasets",
        "gpt_label": "Unsupported Claim",
        "reason": "Mentions a prior-work strategy but provides no citation to specific works that use this approach.",
        "start": 1803,
        "end": 1846
      },
      {
        "span_text": "To tackle such a problem, recent research focuses on dense retrieval models to generate learnable dense representations for queries and documents with a dual encoder structure (Karpukhin et al., 2020;. Despite their recent successes, some challenges still remain in the dense retrieval scheme for a couple of reasons.",
        "gpt_label": "Coherence",
        "reason": "The transition from citing dense retrieval work to discussing “their recent successes” is abrupt and does not explicitly connect which works are being referenced. The incomplete citation punctuation suggests multiple works but lists only one, leaving the relationship between the cited work(s) and the ensuing general claim unclear across these two sentences.",
        "start": 843,
        "end": 1157
      },
      {
        "span_text": "To tackle such a problem, recent research focuses on dense retrieval models to generate learnable dense representations for queries and documents with a dual encoder structure (Karpukhin et al., 2020;.",
        "gpt_label": "Lacks synthesis",
        "reason": "This sentence cites prior work and describes a general approach without explicitly linking it to the authors' own argument or clarifying the specific gap their method addresses; it is purely descriptive rather than integrative.",
        "start": 843,
        "end": 1042
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "hence suffering from the vocabulary mismatch problem: the failure of retrieving relevant documents due to the lexical difference from queries.",
          "gpt_label": "Unsupported Claim",
          "reason": "Asserts a well-known IR issue without providing a citation to support the claim or define the term.",
          "start": 701,
          "end": 842
        },
        {
          "span_text": "First, dense retrieval models need a large amount of labeled training data for a decent performance.",
          "gpt_label": "Unsupported Claim",
          "reason": "Claims a data requirement about dense retrieval without citing supporting studies or benchmarks.",
          "start": 1158,
          "end": 1257
        },
        {
          "span_text": "Second, in order to adapt a retrieval model to the real world, where documents constantly emerge, handling unlabeled documents that are not seen during training should obviously be considered, but remains challenging.",
          "gpt_label": "Unsupported Claim",
          "reason": "States that handling unseen unlabeled documents remains challenging without citing prior work demonstrating this difficulty.",
          "start": 1447,
          "end": 1663
        },
        {
          "span_text": "or incorporates queries from other datasets",
          "gpt_label": "Unsupported Claim",
          "reason": "Mentions a prior-work strategy but provides no citation to specific works that use this approach.",
          "start": 1803,
          "end": 1846
        }
      ],
      "Format": [],
      "Coherence": [
        {
          "span_text": "To tackle such a problem, recent research focuses on dense retrieval models to generate learnable dense representations for queries and documents with a dual encoder structure (Karpukhin et al., 2020;. Despite their recent successes, some challenges still remain in the dense retrieval scheme for a couple of reasons.",
          "gpt_label": "Coherence",
          "reason": "The transition from citing dense retrieval work to discussing “their recent successes” is abrupt and does not explicitly connect which works are being referenced. The incomplete citation punctuation suggests multiple works but lists only one, leaving the relationship between the cited work(s) and the ensuing general claim unclear across these two sentences.",
          "start": 843,
          "end": 1157
        }
      ],
      "Lacks synthesis": [
        {
          "span_text": "To tackle such a problem, recent research focuses on dense retrieval models to generate learnable dense representations for queries and documents with a dual encoder structure (Karpukhin et al., 2020;.",
          "gpt_label": "Lacks synthesis",
          "reason": "This sentence cites prior work and describes a general approach without explicitly linking it to the authors' own argument or clarifying the specific gap their method addresses; it is purely descriptive rather than integrative.",
          "start": 843,
          "end": 1042
        }
      ]
    }
  },
  "paper_99.txt": {
    "filename": "paper_99.txt",
    "full_text": "Related Work\n\nFor NLP tasks, adapters are introduced for the transformer architecture. A set of adapter parameters was added at each transformer layer, which is mostly bottleneck architectures Houlsby et al. (2019). By keeping the output dimension identical, they cause no change to the structure or parameters of the original model.\n\nAdapters quickly gained popularity in NLP with various applications. For multi-task learning (Caruana, 1997;Zhang and Yang, 2017;Liu et al., 2019b), a projected self-attention layer is proposed by Stickland and Murray (2019), while Bapna et al. (2019) proposed an additional layer norm suitable for machine translation.\n\nBesides the applications of adapters, researchers are also dedicated to improving their performance. Based on the architecture introduced by Houlsby et al. (2019), AdapterFusion (Pfeiffer et al., 2020a) leveraged knowledge from multiple tasks with a new two-stage learning algorithm. Despite the recent popularity of these methods, they still train a relatively large number of training parameters.\n\nRecently, studies start to focus on improving the parameter-efficiency of adapters. Diff-pruning (Guo et al., 2020) achieves parameter efficiency by adding a sparse, task-specific difference-vector to the fixed original parameters. The vector is adaptively pruned during training with a differentiable approximation to the L 0 -norm penalty to encourage sparsity. Rücklé et al. (2020) introduced Adap-terDrop, which has been recently integrated into AdapterHub (Pfeiffer et al., 2020b) by removing adapters from lower transformer layers during training and inference, which can dynamically reduce the computational cost. Mahabadi et al. (2021) proposed Compacter, which improved the trade-off between performance and trainable parameters per task with low-rank optimization.\n\nOn the other hand, without modifying the architecture of the PLM, BitFit (Ben Zaken et al., 2021) shows that fine-tuning only the bias terms of a large PLM is also competitive with fine-tuning the entire model. Fine-tuning only the bias terms can be considered as adding a task-specific shift to the token representation. BitFit is most similar to our work. While in BitFit, the shifts added to all the representations are exactly the same for all input tokens, in our work, the shifts are token-dependent.\n\n ",
    "all_spans": [
      {
        "span_text": "For NLP tasks, adapters are introduced for the transformer architecture.",
        "gpt_label": "Unsupported Claim",
        "reason": "First mention of the introduction of adapters for transformers lacks a citation to the originating or key papers and thus needs support.",
        "start": 14,
        "end": 85
      },
      {
        "span_text": "Adapters quickly gained popularity in NLP with various applications.",
        "gpt_label": "Unsupported Claim",
        "reason": "Claims about popularity and breadth of applications require citations to representative works or evidence.",
        "start": 331,
        "end": 398
      },
      {
        "span_text": "Despite the recent popularity of these methods, they still train a relatively large number of training parameters.",
        "gpt_label": "Unsupported Claim",
        "reason": "Evaluative claim about parameter counts lacks supporting citations or quantitative evidence.",
        "start": 928,
        "end": 1041
      },
      {
        "span_text": "Recently, studies start to focus on improving the parameter-efficiency of adapters.",
        "gpt_label": "Unsupported Claim",
        "reason": "Trend claim about recent studies should be accompanied by citations to the specific works.",
        "start": 1043,
        "end": 1125
      },
      {
        "span_text": "Houlsby et al. (2019)",
        "gpt_label": "Format",
        "reason": "Uses narrative citation style in a context that requires a parenthetical citation (should be formatted like “(Houlsby et al., 2019)”).",
        "start": 192,
        "end": 212
      },
      {
        "span_text": "Adapters quickly gained popularity in NLP with various applications. For multi-task learning (Caruana, 1997;Zhang and Yang, 2017;Liu et al., 2019b), a projected self-attention layer is proposed by Stickland and Murray (2019), while Bapna et al. (2019) proposed an additional layer norm suitable for machine translation.",
        "gpt_label": "Coherence",
        "reason": "The connection between the general claim about adapters' applications and the specific cited works is implied but not explicitly stated. It is unclear how the cited methods (projected self-attention, additional layer norm) relate to adapters, and the juxtaposition of multi-task learning and machine translation lacks a clear transition explaining their relevance to the prior sentence.",
        "start": 331,
        "end": 646
      },
      {
        "span_text": "Based on the architecture introduced by Houlsby et al. (2019), AdapterFusion (Pfeiffer et al., 2020a) leveraged knowledge from multiple tasks with a new two-stage learning algorithm. Despite the recent popularity of these methods, they still train a relatively large number of training parameters.",
        "gpt_label": "Coherence",
        "reason": "The relationship between the two sentences is underspecified: the referent of \"these methods\" is ambiguous (AdapterFusion specifically or adapter techniques generally), and the link between the prior description and the subsequent claim about trainable parameters is not made explicit.",
        "start": 748,
        "end": 1041
      },
      {
        "span_text": "Diff-pruning (Guo et al., 2020) achieves parameter efficiency by adding a sparse, task-specific difference-vector to the fixed original parameters. The vector is adaptively pruned during training with a differentiable approximation to the L 0 -norm penalty to encourage sparsity. Rücklé et al. (2020) introduced Adap-terDrop, which has been recently integrated into AdapterHub (Pfeiffer et al., 2020b) by removing adapters from lower transformer layers during training and inference, which can dynamically reduce the computational cost. Mahabadi et al. (2021) proposed Compacter, which improved the trade-off between performance and trainable parameters per task with low-rank optimization.",
        "gpt_label": "Coherence",
        "reason": "These consecutive sentences list disparate methods with abrupt shifts and no explicit transitions explaining how they relate or differ. In particular, the move from diff-pruning (not adapter-specific) to adapter-focused techniques is not discussed, leaving the relationship between the cited works implied rather than stated.",
        "start": 1126,
        "end": 1808
      },
      {
        "span_text": "Adapters quickly gained popularity in NLP with various applications. For multi-task learning (Caruana, 1997;Zhang and Yang, 2017;Liu et al., 2019b), a projected self-attention layer is proposed by Stickland and Murray (2019), while Bapna et al. (2019) proposed an additional layer norm suitable for machine translation.\n\nBesides the applications of adapters, researchers are also dedicated to improving their performance. Based on the architecture introduced by Houlsby et al. (2019), AdapterFusion (Pfeiffer et al., 2020a) leveraged knowledge from multiple tasks with a new two-stage learning algorithm. Despite the recent popularity of these methods, they still train a relatively large number of training parameters.\n\nRecently, studies start to focus on improving the parameter-efficiency of adapters. Diff-pruning (Guo et al., 2020) achieves parameter efficiency by adding a sparse, task-specific difference-vector to the fixed original parameters. The vector is adaptively pruned during training with a differentiable approximation to the L 0 -norm penalty to encourage sparsity. Rücklé et al. (2020) introduced Adap-terDrop, which has been recently integrated into AdapterHub (Pfeiffer et al., 2020b) by removing adapters from lower transformer layers during training and inference, which can dynamically reduce the computational cost. Mahabadi et al. (2021) proposed Compacter, which improved the trade-off between performance and trainable parameters per task with low-rank optimization.",
        "gpt_label": "Lacks synthesis",
        "reason": "These paragraphs largely list prior works and their features without integrating them into an argument or explicitly connecting them to the authors’ approach or motivation. The gap is only vaguely implied and not tied to the authors’ contribution here.",
        "start": 331,
        "end": 1808
      }
    ],
    "spans_by_label": {
      "Unsupported Claim": [
        {
          "span_text": "For NLP tasks, adapters are introduced for the transformer architecture.",
          "gpt_label": "Unsupported Claim",
          "reason": "First mention of the introduction of adapters for transformers lacks a citation to the originating or key papers and thus needs support.",
          "start": 14,
          "end": 85
        },
        {
          "span_text": "Adapters quickly gained popularity in NLP with various applications.",
          "gpt_label": "Unsupported Claim",
          "reason": "Claims about popularity and breadth of applications require citations to representative works or evidence.",
          "start": 331,
          "end": 398
        },
        {
          "span_text": "Despite the recent popularity of these methods, they still train a relatively large number of training parameters.",
          "gpt_label": "Unsupported Claim",
          "reason": "Evaluative claim about parameter counts lacks supporting citations or quantitative evidence.",
          "start": 928,
          "end": 1041
        },
        {
          "span_text": "Recently, studies start to focus on improving the parameter-efficiency of adapters.",
          "gpt_label": "Unsupported Claim",
          "reason": "Trend claim about recent studies should be accompanied by citations to the specific works.",
          "start": 1043,
          "end": 1125
        }
      ],
      "Format": [
        {
          "span_text": "Houlsby et al. (2019)",
          "gpt_label": "Format",
          "reason": "Uses narrative citation style in a context that requires a parenthetical citation (should be formatted like “(Houlsby et al., 2019)”).",
          "start": 192,
          "end": 212
        }
      ],
      "Coherence": [
        {
          "span_text": "Adapters quickly gained popularity in NLP with various applications. For multi-task learning (Caruana, 1997;Zhang and Yang, 2017;Liu et al., 2019b), a projected self-attention layer is proposed by Stickland and Murray (2019), while Bapna et al. (2019) proposed an additional layer norm suitable for machine translation.",
          "gpt_label": "Coherence",
          "reason": "The connection between the general claim about adapters' applications and the specific cited works is implied but not explicitly stated. It is unclear how the cited methods (projected self-attention, additional layer norm) relate to adapters, and the juxtaposition of multi-task learning and machine translation lacks a clear transition explaining their relevance to the prior sentence.",
          "start": 331,
          "end": 646
        },
        {
          "span_text": "Based on the architecture introduced by Houlsby et al. (2019), AdapterFusion (Pfeiffer et al., 2020a) leveraged knowledge from multiple tasks with a new two-stage learning algorithm. Despite the recent popularity of these methods, they still train a relatively large number of training parameters.",
          "gpt_label": "Coherence",
          "reason": "The relationship between the two sentences is underspecified: the referent of \"these methods\" is ambiguous (AdapterFusion specifically or adapter techniques generally), and the link between the prior description and the subsequent claim about trainable parameters is not made explicit.",
          "start": 748,
          "end": 1041
        },
        {
          "span_text": "Diff-pruning (Guo et al., 2020) achieves parameter efficiency by adding a sparse, task-specific difference-vector to the fixed original parameters. The vector is adaptively pruned during training with a differentiable approximation to the L 0 -norm penalty to encourage sparsity. Rücklé et al. (2020) introduced Adap-terDrop, which has been recently integrated into AdapterHub (Pfeiffer et al., 2020b) by removing adapters from lower transformer layers during training and inference, which can dynamically reduce the computational cost. Mahabadi et al. (2021) proposed Compacter, which improved the trade-off between performance and trainable parameters per task with low-rank optimization.",
          "gpt_label": "Coherence",
          "reason": "These consecutive sentences list disparate methods with abrupt shifts and no explicit transitions explaining how they relate or differ. In particular, the move from diff-pruning (not adapter-specific) to adapter-focused techniques is not discussed, leaving the relationship between the cited works implied rather than stated.",
          "start": 1126,
          "end": 1808
        }
      ],
      "Lacks synthesis": [
        {
          "span_text": "Adapters quickly gained popularity in NLP with various applications. For multi-task learning (Caruana, 1997;Zhang and Yang, 2017;Liu et al., 2019b), a projected self-attention layer is proposed by Stickland and Murray (2019), while Bapna et al. (2019) proposed an additional layer norm suitable for machine translation.\n\nBesides the applications of adapters, researchers are also dedicated to improving their performance. Based on the architecture introduced by Houlsby et al. (2019), AdapterFusion (Pfeiffer et al., 2020a) leveraged knowledge from multiple tasks with a new two-stage learning algorithm. Despite the recent popularity of these methods, they still train a relatively large number of training parameters.\n\nRecently, studies start to focus on improving the parameter-efficiency of adapters. Diff-pruning (Guo et al., 2020) achieves parameter efficiency by adding a sparse, task-specific difference-vector to the fixed original parameters. The vector is adaptively pruned during training with a differentiable approximation to the L 0 -norm penalty to encourage sparsity. Rücklé et al. (2020) introduced Adap-terDrop, which has been recently integrated into AdapterHub (Pfeiffer et al., 2020b) by removing adapters from lower transformer layers during training and inference, which can dynamically reduce the computational cost. Mahabadi et al. (2021) proposed Compacter, which improved the trade-off between performance and trainable parameters per task with low-rank optimization.",
          "gpt_label": "Lacks synthesis",
          "reason": "These paragraphs largely list prior works and their features without integrating them into an argument or explicitly connecting them to the authors’ approach or motivation. The gap is only vaguely implied and not tied to the authors’ contribution here.",
          "start": 331,
          "end": 1808
        }
      ]
    }
  }
}