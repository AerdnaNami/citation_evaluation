[
    {
        "filename": "paper_2.txt",
        "label": "Format",
        "text": "Ajjour et al. 1",
        "start": 4881,
        "end": 4894,
        "spans_a": [
            {
                "filename": "paper_2.txt",
                "start": 4881,
                "end": 4896,
                "label": "Format",
                "text": "Ajjour et al. 1",
                "full_text": "Background\n\nHuman values are of concern to most if not to all social sciences (Rokeach, 1973) and have also been integrated into computational frameworks of argumentation (Bench-Capon, 2003). In NLP, values have been analyzed for personality profiling (Maheshwari et al., 2017), but not yet for argument mining, as considered here.\n\nValues in Social Science\n\nRokeach (1973) already described the two concepts of (1) a value as a belief pertaining to desirable end states or modes of conduct and (2) a value system as prioritization of values based on cultural, social, and personal factors. These definitions attribute values to persons rather than to objects, facilitating a systematic analysis (Rokeach, 1973). The paper at hand targets the personal values behind arguments, meaning the values in the former sense that the arguments, mostly implicitly, resort to.\n\nSeveral of the value schemes proposed in the literature pertain to specific purposes. England (1967) suggested 66 values related to management decisions, such as high productivity and prestige, and categorized them by relevant entity, for example business organizations and individuals. Brown and Crace (2002) looked at 14 values for counseling and therapy, such as responsibility and spirituality, and Kahle et al. (1988) at nine for consumer research, such as warm relationships and excitement.\n\nOther proposed value schemes are more generic. Combining research from anthropology, sociology, philosophy, and psychology, Rokeach (1973) estimates the total number of human values to be fewer than hundreds, and develops a practical survey of 36 values that distinguishes between values pertaining to desirable end states and desirable behavior. Specifically for cross-cultural analyses, Schwartz et al. ( 2012) derived 48 value questions from the universal needs of individuals and societies, including obeying all the laws and to be humble. Moreover, Schwartz (1994) proposes a relatedness of values by their tendency to be compatible in their pursuit (see Figure 1). This relatedness reflects two \"higher order\" conflicts: (1) openness to change/own thoughts vs. conservation/submission, and (2) self-transcension (directed towards others/the environment) vs. self-enhancing (directed towards one's self), allowing to analyse values at several levels. Cheng and Fleischmann (2010) consolidates 12 schemes into a \"meta-inventory\" with 16 values, such as honesty and justice, revealing a large overlap in schemes across fields of research. However, as the meta-inventory is strictly more coarse-grained than Schwartz et al.'s theory we do not investigate it further for this paper.\n\nValues in Argumentation Research\n\nFormal argumentation employs value systems to model audience-specific preferences, that is, an argument's strength depends on the degree to which the audience reveres the values the argument resorts to. Examples include value-based argumentation schemes (van der Weide et al., 2009), defeasible logic programming (Teze et al., 2019), and the value-based argumentation framework of Bench-Capon (2003). The latter is an extension of the abstract argumentation framework of Dung (1995) that has already been applied manually to analyze interactions with reasoning and persuasion subject to a specific value system (Atkinson and Bench-Capon, 2021). This paper present a first step towards the large-scale automatic application of these works as it takes values to argument mining. Feldman (2021) recently showed the strong connection between values and the moral foundation theory (Haidt, 2012). Like personal values, this theory analyzes ethical reasoning behind human choices, but considers five rather abstract \"foundations:\" care, fairness, loyalty, authority, and purity. Alshomary and Wachsmuth (2021) hypothesized that the foundations could be used for audiencespecific argument generation. Kobbe et al. (2020) tried to classify arguments by foundations, but noted a low human agreement due to the vagueness of the foundations. We assume values can here contribute to the classification by foundations.\n\nPartly, values overlap with ideas of framing in communication, that is, the selection and emphasis of specific aspects of (perceived) reality to promote a particular problem definition, causal interpretation, ethical evaluation, and/or recommendation (Entman, 1993). In frames, values can define the costs and benefits of options (Entman, 1993) whereas common value systems are used for evaluation. Frames have been studied computationally for news (Naderi and Hirst, 2015), political speech (De Vreese, 2005), and argumentation (Ajjour et al., 2019). In argumentation, some values are so prevalent that they constitute frames of their own, indicating a potential use of values in frame identification. For example, 14 of the 54 values we use in this work are also frames in the dataset of Ajjour et al. 1 Values may be considered as aspects under which to group arguments. Some researchers have mined aspects from text (Trautmann, 2020) or used them to control argument generation (Schiller et al., 2021). Others have studied the task of opinion summarization in arguments (Egan et al., 2016;Misra et al., 2016;Chen et al., 2019), aiming at the most important aspects discussed in a debate. Related, the task of key point analysis (Bar-Haim et al., 2020;Friedman et al., 2021) is to generate a small set of concise statements that each represent a different aspect. We argue that analyzing the values found in a collection of arguments provides a new perspective to aspects in argumentation, focusing on the \"why\" behind an argument's reasoning.\n\n References: \nAjjour, Y., Alshomary, M., Wachsmuth, H., and Stein, B. 2019. Modeling Frames in Argumentation. In 2019 Conference on Empirical Methods in Natural Language Processing and 9th International Joint Conference on Natural Language Processing (EMNLP 2019). pp. 2922--2932\nAlshomary, M. and Wachsmuth, H. 2021. Toward audience-aware argument generation. In Patterns. pp. 100253 10.1016/j.patter.2021.100253\nKatie Atkinson and Trevor Bench-Capon. 2021. Valuebased argumentation. In Journal of Applied Logics. pp. 1543--1588\nBabbar, R., Partalas, I., Gaussier, E., and Amini, M. 2013. On flat versus hierarchical classification in large-scale taxonomies. In 27th Annual Conference on Neural Information Processing Systems (NIPS 2013). pp. 1824--1832\nBar-Haim, R., Eden, L., Friedman, R., Kantor, Y., Lahav, D., and Slonim, N. 2020. From arguments to key points: Towards automatic argument summarization. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. pp. 4029--4039 10.18653/v1/2020.acl-main.371\nTrevor, J. M. 2003. Persuasion in practical argument using value-based argumentation frameworks. In J. Log. Comput. pp. 429--448 10.1093/logcom/13.3.429\nTrevor, J. M. 2021. Bench-Capon. 2021. Audiences and argument strength. In 3rd Workshop on Argument Strength.\nBrown, D. and Kelly Crace, R. 2002. Life values inventory facilitator's guide. In Life values inventory facilitator's guide.\nChen, S., Khashabi, D., Yin, W., Callison-Burch, C., and Roth, D. 2019. Seeing things from a different angle:discovering diverse perspectives about claims. In Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT 2019). pp. 542--557 10.18653/v1/N19-1053\nCheng, A. and Fleischmann, K. R. 2010. Developing a meta-inventory of human values. In 73rd ASIS&T Annual Meeting (ASIST 2010). pp. 1--10 10.1002/meet.14504701232\nVreese, C.H.D. 2005. News framing: Theory and typology. Information design journal & document design. In News framing: Theory and typology. Information design journal & document design. pp. 13\nPhan Minh, D. 1995. On the acceptability of arguments and its fundamental role in nonmonotonic reasoning, logic programming and n-person games. In Artificial Intelligence. pp. 321--357 10.1016/0004-3702(94)00041-X\nEgan, C., Siddharthan, A., and Wyner, A. Z. 2016. Summarising the points made in online political debates. In Proceedings of the Third Workshop on Argument Mining, hosted by the 54th Annual Meeting of the Association for Computational Linguistics, ArgMining@ACL 2016. 10.18653/v1/w16-2816\nEngland, G. W. 1967. Personal value systems of american managers. In Academy of Management journal. pp. 53--68\nRobert M Entman 1993. Framing: Towards clarification of a fractured paradigm. McQuail's reader in mass communication theory. In Framing: Towards clarification of a fractured paradigm. McQuail's reader in mass communication theory. pp. 390--397\nFeldman, G. 2021. Personal values and moral foundations: Examining relations and joint prediction of moral variables. Social Psychological and Personality. In Science. pp. 676--686\nFriedman, R., Dankin, L., Katz, Y., Hou, Y., and Slonim, N. 2021. Overview of KPA-2021 shared task: Key point based quantitative summarization. In Proceedings of the 8th Workshop on Argumentation Mining.\nGretz, S., Friedman, R., Cohen-Karlik, E., Toledo, A., Lahav, D., Aharonov, R., and Slonim, N. 2020. A large-scale dataset for argument quality ranking: Construction and analysis. In 34th AAAI Conference on Artificial Intelligence (AAAI 2020). pp. 7805--7813 10.1609/aaai.v34i05.6285\nHaerpfer, C., Inglehart, R., Moreno, A., Welzel, C., Kizilova, K., Diez-Medrano, J., Lagos, M., Norris, P., Ponarin, E., and Puranen, B. 2020. World values survey. In World values survey. 10.14281/18241.13\nHaidt, J. 2012. The righteous mind: Why good people are divided by politics and religion. In The righteous mind: Why good people are divided by politics and religion.\nHovy, D., Berg-Kirkpatrick, T., Vaswani, A., and Hovy, E. 2013. Learning whom to trust with mace. In Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT 2013). pp. 1120--1130\nLynn R Kahle, B., Poulos, A., and Sukhdial 1988. Changes in social values in the united states during the past decade. In Journal of Advertising Research. pp. 35--41\nKobbe, J., Rehbein, I., Hulpus, I., and Stuckenschmidt, H. 2020. Exploring morality in argumentation. In Proceedings of the 7th Workshop on Argument Mining. pp. 30--40\nKrippendorff, K. 2004. Measuring the reliability of qualitative text analysis data. In Quality & quantity. pp. 787--800 10.1007/s11135-004-8107-7\nLoza Menc\u00eda, E. and Jannsen, F. 2016. Learning rules for multi-label classification: a stacking and a separate-and-conquer approach. In Machine Learning. pp. 77--126 10.1007/s10994-016-5552-1\nMaheshwari, T., Reganti, A. N., Gupta, S., Jamatia, A., Kumar, U., Gamb\u00e4ck, B., and Das, A. 2017. A societal sentiment analysis: Predicting the values and ethics of individuals by analysing social media content. In 15th Conference of the European Chapter of the Association for Computational Linguistics. pp. 731--741 10.18653/v1/e17-1069\nMisra, A., Ecker, B., and Walker, M. 2016. Measuring the similarity of sentential arguments in dialogue. In Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue. pp. 276--287 10.18653/v1/W16-3636\nNaderi, N. and Hirst, G. 2015. Argumentation mining in parliamentary discourse. In Principles and practice of multi-agent systems. pp. 16--25\nRokeach, M. 1973. The nature of human values. In The nature of human values.\nSchiller, B., Daxenberger, J., and Gurevych, I. 2021. Aspect-controlled neural argument generation. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. pp. 380--396 10.18653/v1/2021.naacl-main.34\nShalom, H. and Schwartz 1994. Are there universal aspects in the structure and contents of human values?. In Journal of Social Issues. pp. 19--45 10.1111/j.1540-4560.1994.tb01196.x\nShalom, H., Schwartz, J., Cieciuch, M., Vecchione, E., Davidov, R., Fischer, C., Beierlein, A., Ramos, M., Verkasalo, J., L\u00f6nnqvist, K., and Demirutku 2012. Refining the theory of basic individual values. In Journal of personality and social psychology. pp. 103 10.1037/a0029393\nJohn R Searle 2003. Rationality in action. In Rationality in action.\nCarlos Teze, J., Perello-Moragues, A., Godo, L., and Noriega, P. 2019. Practical reasoning using values: an argumentative approach based on a hierarchy of values. In Annals of Mathematics and Artificial Intelligence. pp. 293--319 10.1007/s10472-019-09660-8\nTrautmann, D. 2020. Aspect-based argument mining. In Proceedings of the 7th Workshop on Argument Mining. pp. 41--52\nThomas, L., Van Der Weide, F., Dignum, J., Ch, Meyer, H., Prakken, G., and Vreeswijk 2009. Practical reasoning using values. In Argumentation in Multi-Agent Systems. pp. 79--93 10.1007/978-3-642-12805-9_5\nWilcox, R. R. 1996. Statistics for the Social Sciences. In Statistics for the Social Sciences."
            }
        ],
        "spans_b": [
            {
                "filename": "paper_2.txt",
                "start": 4881,
                "end": 4894,
                "label": "Format",
                "text": "Ajjour et al.",
                "full_text": "Background\n\nHuman values are of concern to most if not to all social sciences (Rokeach, 1973) and have also been integrated into computational frameworks of argumentation (Bench-Capon, 2003). In NLP, values have been analyzed for personality profiling (Maheshwari et al., 2017), but not yet for argument mining, as considered here.\n\nValues in Social Science\n\nRokeach (1973) already described the two concepts of (1) a value as a belief pertaining to desirable end states or modes of conduct and (2) a value system as prioritization of values based on cultural, social, and personal factors. These definitions attribute values to persons rather than to objects, facilitating a systematic analysis (Rokeach, 1973). The paper at hand targets the personal values behind arguments, meaning the values in the former sense that the arguments, mostly implicitly, resort to.\n\nSeveral of the value schemes proposed in the literature pertain to specific purposes. England (1967) suggested 66 values related to management decisions, such as high productivity and prestige, and categorized them by relevant entity, for example business organizations and individuals. Brown and Crace (2002) looked at 14 values for counseling and therapy, such as responsibility and spirituality, and Kahle et al. (1988) at nine for consumer research, such as warm relationships and excitement.\n\nOther proposed value schemes are more generic. Combining research from anthropology, sociology, philosophy, and psychology, Rokeach (1973) estimates the total number of human values to be fewer than hundreds, and develops a practical survey of 36 values that distinguishes between values pertaining to desirable end states and desirable behavior. Specifically for cross-cultural analyses, Schwartz et al. ( 2012) derived 48 value questions from the universal needs of individuals and societies, including obeying all the laws and to be humble. Moreover, Schwartz (1994) proposes a relatedness of values by their tendency to be compatible in their pursuit (see Figure 1). This relatedness reflects two \"higher order\" conflicts: (1) openness to change/own thoughts vs. conservation/submission, and (2) self-transcension (directed towards others/the environment) vs. self-enhancing (directed towards one's self), allowing to analyse values at several levels. Cheng and Fleischmann (2010) consolidates 12 schemes into a \"meta-inventory\" with 16 values, such as honesty and justice, revealing a large overlap in schemes across fields of research. However, as the meta-inventory is strictly more coarse-grained than Schwartz et al.'s theory we do not investigate it further for this paper.\n\nValues in Argumentation Research\n\nFormal argumentation employs value systems to model audience-specific preferences, that is, an argument's strength depends on the degree to which the audience reveres the values the argument resorts to. Examples include value-based argumentation schemes (van der Weide et al., 2009), defeasible logic programming (Teze et al., 2019), and the value-based argumentation framework of Bench-Capon (2003). The latter is an extension of the abstract argumentation framework of Dung (1995) that has already been applied manually to analyze interactions with reasoning and persuasion subject to a specific value system (Atkinson and Bench-Capon, 2021). This paper present a first step towards the large-scale automatic application of these works as it takes values to argument mining. Feldman (2021) recently showed the strong connection between values and the moral foundation theory (Haidt, 2012). Like personal values, this theory analyzes ethical reasoning behind human choices, but considers five rather abstract \"foundations:\" care, fairness, loyalty, authority, and purity. Alshomary and Wachsmuth (2021) hypothesized that the foundations could be used for audiencespecific argument generation. Kobbe et al. (2020) tried to classify arguments by foundations, but noted a low human agreement due to the vagueness of the foundations. We assume values can here contribute to the classification by foundations.\n\nPartly, values overlap with ideas of framing in communication, that is, the selection and emphasis of specific aspects of (perceived) reality to promote a particular problem definition, causal interpretation, ethical evaluation, and/or recommendation (Entman, 1993). In frames, values can define the costs and benefits of options (Entman, 1993) whereas common value systems are used for evaluation. Frames have been studied computationally for news (Naderi and Hirst, 2015), political speech (De Vreese, 2005), and argumentation (Ajjour et al., 2019). In argumentation, some values are so prevalent that they constitute frames of their own, indicating a potential use of values in frame identification. For example, 14 of the 54 values we use in this work are also frames in the dataset of Ajjour et al. 1 Values may be considered as aspects under which to group arguments. Some researchers have mined aspects from text (Trautmann, 2020) or used them to control argument generation (Schiller et al., 2021). Others have studied the task of opinion summarization in arguments (Egan et al., 2016;Misra et al., 2016;Chen et al., 2019), aiming at the most important aspects discussed in a debate. Related, the task of key point analysis (Bar-Haim et al., 2020;Friedman et al., 2021) is to generate a small set of concise statements that each represent a different aspect. We argue that analyzing the values found in a collection of arguments provides a new perspective to aspects in argumentation, focusing on the \"why\" behind an argument's reasoning.\n\n References: \nAjjour, Y., Alshomary, M., Wachsmuth, H., and Stein, B. 2019. Modeling Frames in Argumentation. In 2019 Conference on Empirical Methods in Natural Language Processing and 9th International Joint Conference on Natural Language Processing (EMNLP 2019). pp. 2922--2932\nAlshomary, M. and Wachsmuth, H. 2021. Toward audience-aware argument generation. In Patterns. pp. 100253 10.1016/j.patter.2021.100253\nKatie Atkinson and Trevor Bench-Capon. 2021. Valuebased argumentation. In Journal of Applied Logics. pp. 1543--1588\nBabbar, R., Partalas, I., Gaussier, E., and Amini, M. 2013. On flat versus hierarchical classification in large-scale taxonomies. In 27th Annual Conference on Neural Information Processing Systems (NIPS 2013). pp. 1824--1832\nBar-Haim, R., Eden, L., Friedman, R., Kantor, Y., Lahav, D., and Slonim, N. 2020. From arguments to key points: Towards automatic argument summarization. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. pp. 4029--4039 10.18653/v1/2020.acl-main.371\nTrevor, J. M. 2003. Persuasion in practical argument using value-based argumentation frameworks. In J. Log. Comput. pp. 429--448 10.1093/logcom/13.3.429\nTrevor, J. M. 2021. Bench-Capon. 2021. Audiences and argument strength. In 3rd Workshop on Argument Strength.\nBrown, D. and Kelly Crace, R. 2002. Life values inventory facilitator's guide. In Life values inventory facilitator's guide.\nChen, S., Khashabi, D., Yin, W., Callison-Burch, C., and Roth, D. 2019. Seeing things from a different angle:discovering diverse perspectives about claims. In Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT 2019). pp. 542--557 10.18653/v1/N19-1053\nCheng, A. and Fleischmann, K. R. 2010. Developing a meta-inventory of human values. In 73rd ASIS&T Annual Meeting (ASIST 2010). pp. 1--10 10.1002/meet.14504701232\nVreese, C.H.D. 2005. News framing: Theory and typology. Information design journal & document design. In News framing: Theory and typology. Information design journal & document design. pp. 13\nPhan Minh, D. 1995. On the acceptability of arguments and its fundamental role in nonmonotonic reasoning, logic programming and n-person games. In Artificial Intelligence. pp. 321--357 10.1016/0004-3702(94)00041-X\nEgan, C., Siddharthan, A., and Wyner, A. Z. 2016. Summarising the points made in online political debates. In Proceedings of the Third Workshop on Argument Mining, hosted by the 54th Annual Meeting of the Association for Computational Linguistics, ArgMining@ACL 2016. 10.18653/v1/w16-2816\nEngland, G. W. 1967. Personal value systems of american managers. In Academy of Management journal. pp. 53--68\nRobert M Entman 1993. Framing: Towards clarification of a fractured paradigm. McQuail's reader in mass communication theory. In Framing: Towards clarification of a fractured paradigm. McQuail's reader in mass communication theory. pp. 390--397\nFeldman, G. 2021. Personal values and moral foundations: Examining relations and joint prediction of moral variables. Social Psychological and Personality. In Science. pp. 676--686\nFriedman, R., Dankin, L., Katz, Y., Hou, Y., and Slonim, N. 2021. Overview of KPA-2021 shared task: Key point based quantitative summarization. In Proceedings of the 8th Workshop on Argumentation Mining.\nGretz, S., Friedman, R., Cohen-Karlik, E., Toledo, A., Lahav, D., Aharonov, R., and Slonim, N. 2020. A large-scale dataset for argument quality ranking: Construction and analysis. In 34th AAAI Conference on Artificial Intelligence (AAAI 2020). pp. 7805--7813 10.1609/aaai.v34i05.6285\nHaerpfer, C., Inglehart, R., Moreno, A., Welzel, C., Kizilova, K., Diez-Medrano, J., Lagos, M., Norris, P., Ponarin, E., and Puranen, B. 2020. World values survey. In World values survey. 10.14281/18241.13\nHaidt, J. 2012. The righteous mind: Why good people are divided by politics and religion. In The righteous mind: Why good people are divided by politics and religion.\nHovy, D., Berg-Kirkpatrick, T., Vaswani, A., and Hovy, E. 2013. Learning whom to trust with mace. In Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT 2013). pp. 1120--1130\nLynn R Kahle, B., Poulos, A., and Sukhdial 1988. Changes in social values in the united states during the past decade. In Journal of Advertising Research. pp. 35--41\nKobbe, J., Rehbein, I., Hulpus, I., and Stuckenschmidt, H. 2020. Exploring morality in argumentation. In Proceedings of the 7th Workshop on Argument Mining. pp. 30--40\nKrippendorff, K. 2004. Measuring the reliability of qualitative text analysis data. In Quality & quantity. pp. 787--800 10.1007/s11135-004-8107-7\nLoza Menc\u00eda, E. and Jannsen, F. 2016. Learning rules for multi-label classification: a stacking and a separate-and-conquer approach. In Machine Learning. pp. 77--126 10.1007/s10994-016-5552-1\nMaheshwari, T., Reganti, A. N., Gupta, S., Jamatia, A., Kumar, U., Gamb\u00e4ck, B., and Das, A. 2017. A societal sentiment analysis: Predicting the values and ethics of individuals by analysing social media content. In 15th Conference of the European Chapter of the Association for Computational Linguistics. pp. 731--741 10.18653/v1/e17-1069\nMisra, A., Ecker, B., and Walker, M. 2016. Measuring the similarity of sentential arguments in dialogue. In Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue. pp. 276--287 10.18653/v1/W16-3636\nNaderi, N. and Hirst, G. 2015. Argumentation mining in parliamentary discourse. In Principles and practice of multi-agent systems. pp. 16--25\nRokeach, M. 1973. The nature of human values. In The nature of human values.\nSchiller, B., Daxenberger, J., and Gurevych, I. 2021. Aspect-controlled neural argument generation. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. pp. 380--396 10.18653/v1/2021.naacl-main.34\nShalom, H. and Schwartz 1994. Are there universal aspects in the structure and contents of human values?. In Journal of Social Issues. pp. 19--45 10.1111/j.1540-4560.1994.tb01196.x\nShalom, H., Schwartz, J., Cieciuch, M., Vecchione, E., Davidov, R., Fischer, C., Beierlein, A., Ramos, M., Verkasalo, J., L\u00f6nnqvist, K., and Demirutku 2012. Refining the theory of basic individual values. In Journal of personality and social psychology. pp. 103 10.1037/a0029393\nJohn R Searle 2003. Rationality in action. In Rationality in action.\nCarlos Teze, J., Perello-Moragues, A., Godo, L., and Noriega, P. 2019. Practical reasoning using values: an argumentative approach based on a hierarchy of values. In Annals of Mathematics and Artificial Intelligence. pp. 293--319 10.1007/s10472-019-09660-8\nTrautmann, D. 2020. Aspect-based argument mining. In Proceedings of the 7th Workshop on Argument Mining. pp. 41--52\nThomas, L., Van Der Weide, F., Dignum, J., Ch, Meyer, H., Prakken, G., and Vreeswijk 2009. Practical reasoning using values. In Argumentation in Multi-Agent Systems. pp. 79--93 10.1007/978-3-642-12805-9_5\nWilcox, R. R. 1996. Statistics for the Social Sciences. In Statistics for the Social Sciences."
            }
        ]
    },
    {
        "filename": "paper_6.txt",
        "label": "Format",
        "text": "in (Liu et al., 2021)",
        "start": 2053,
        "end": 2071,
        "spans_a": [
            {
                "filename": "paper_6.txt",
                "start": 2050,
                "end": 2071,
                "label": "Format",
                "text": "in (Liu et al., 2021)",
                "full_text": "Related Work\n\nZero-shot cross-lingual structured prediction. Zero-shot cross-lingual learning becomes an emerging research topic as it eliminates the requirement of labeled data for training models in low-resource languages. Various structured prediction tasks have be studied, including named entity recognition (Pan et al., 2017;Hu et al., 2020), dependency parsing (Ahmad et al., 2019, relation extraction (Zou et al., 2018;Ni and Florian, 2019), and event argument extraction (Subburathinam et al., 2019;Ahmad et al., 2021;Nguyen and Nguyen, 2021). Most of them are classification-based models that build classifiers on top of a multilingual pre-trained masked language models. To further deal with the discrepancy between languages, some of them require additional information, such as bilingual dictionaries (Liu et al., 2019; Ni and Florian, 2019), translation pairs (Zou et al., 2018), and dependency parse trees (Subburathinam et al., 2019;Ahmad et al., 2021;Nguyen and Nguyen, 2021). However, as pointed out by previous literature (Li et al., 2021;Hsu et al., 2021), classification-based models are less powerful to model dependencies between entities compared to generation-based models.\n\nGeneration-based structured prediction. Several works have demonstrated the great success of generation-based models on monolingual structured prediction tasks, including named entity recognition (Yan et al., 2021), relation extraction (Huang et al., 2021;Paolini et al., 2021), and event extraction (Du et al., 2021;Hsu et al., 2021;Lu et al., 2021). Yet, as mentioned in Section 1, their designed generating targets are language-dependent. Accordingly, directly applying their methods to the zero-shot cross-lingual setting would result in less-preferred performance.\n\nPrompting methods. There are growing interests recently to incorporate prompts on pre-trained language models in order to guide the models' behavior or elicit knowledge (Shin et al., 2020;Schick and Sch\u00fctze, 2021;Qin and Eisner, 2021;Scao and Rush, 2021). Following the taxonomy in (Liu et al., 2021), these methods can be classified depending on whether the language models' parameters are tuned and on whether trainable prompts are introduced. Our method belongs to the category that fixes the prompts and tune the language models' parameters. Despite the flourish of the research in prompting methods, there is only limited attention being put on multilingual tasks (Winata et al., 2021).\n\n References: \nWasi Uddin Ahmad, N., Peng, K., and Chang 2021. GATE: graph attention transformer encoder for cross-lingual relation and event extraction. In Thirty-Fifth AAAI Conference on Artificial Intelligence (AAAI).\nWasi Uddin Ahmad, Z., Zhang, X., Ma, E. H., Hovy, K., Chang, N., and Peng 2019. On difficulties of cross-lingual transfer with order differences: A case study on dependency parsing. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT).\nDe Cao, N., Wu, L., Popat, K., Artetxe, M., Goyal, N., Plekhanov, M., Zettlemoyer, L., Cancedda, N., Riedel, S., and Petroni, F. 2021. Multilingual autoregressive entity linking. In Multilingual autoregressive entity linking. arXiv:2103.12528\nConneau, A., Khandelwal, K., Goyal, N., Chaudhary, V., Wenzek, G., Guzm\u00e1n, F., Grave, E., Ott, M., Zettlemoyer, L., and Stoyanov, V. 2020. Unsupervised cross-lingual representation learning at scale. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics (ACL).\nDoddington, G. R., Mitchell, A., Przybocki, M. A., Ramshaw, L. A., Strassel, S. M., and Weischedel, R. M. 2004. The automatic content extraction (ACE) program -tasks, data, and evaluation. In Proceedings of the Fourth International Conference on Language Resources and Evaluation (LREC).\nDu, X., Rush, A. M., and Cardie, C. 2021. GRIT: generative role-filler transformers for document-level event entity extraction. In Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics (EACL).\nHsu, I., Huang, K., Boschee, E., Miller, S., Natarajan, P., Chang, K., and Peng, N. 2021. Degree: A data-efficient generative event extraction model. In Degree: A data-efficient generative event extraction model. arXiv:2108.12724\nHu, J., Ruder, S., Siddhant, A., Neubig, G., Firat, O., and Johnson, M. 2020. XTREME: A massively multilingual multitask benchmark for evaluating cross-lingual generalisation. In Proceedings of the 37th International Conference on Machine Learning (ICML).\nHuang, K., Tang, S., and Peng, N. 2021. Document-level entity-based extraction as template generation. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing.\nThomas, N., Kipf, M., and Welling 2017. Semisupervised classification with graph convolutional networks. In 5th International Conference on Learning Representations (ICLR).\nLewis, M., Liu, Y., Goyal ; Abdelrahman Mohamed, N., Levy, O., Stoyanov, V., and Zettlemoyer, L. 2020. BART: denoising sequence-to-sequence pretraining for natural language generation, translation, and comprehension. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics.\nLi, S., Heng, J., and Han, J. 2021. Documentlevel event argument extraction by conditional generation. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT).\nLin, Y., Ji, H., Huang, F., and Wu, L. 2020. A joint neural model for information extraction with global features. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics (ACL).\nLiu, J., Chen, Y., and Liu, K. 2019. Neural cross-lingual event detection with minimal parallel resources. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP).\nLiu, P., Yuan, W., Fu, J., Jiang, Z., Hayashi, H., and Neubig, G. 2021. Pretrain, prompt, and predict: A systematic survey of prompting methods in natural language processing. In Pretrain, prompt, and predict: A systematic survey of prompting methods in natural language processing. arXiv:2107.13586\nLiu, Y., Gu, J., Goyal, N., Li, X., Edunov, S., Ghazvininejad, M., Lewis, M., and Zettlemoyer, L. 2020. Multilingual denoising pre-training for neural machine translation. In Trans. Assoc. Comput. Linguistics. pp. 726--742\nLu, Y., Lin, H., Xu, J., Han, X., Tang, J., Li, A., Sun, L., Liao, M., and Chen, S. 2021. Text2event: Controllable sequence-tostructure generation for end-to-end event extraction. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (ACL/IJCNLP).\nVan Nguyen, M. and Huu Nguyen, T. 2021. Improving cross-lingual transfer for event argument extraction with language-universal sentence structures. In Proceedings of the Sixth Arabic Natural Language Processing Workshop.\nNi, J. and Florian, R. 2019. Neural cross-lingual relation extraction based on bilingual word embedding mapping. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP).\nPan, X., Zhang, B., May, J., Nothman, J., Knight, K., and Ji, H. 2017. Crosslingual name tagging and linking for 282 languages. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (ACL).\nPaolini, G., Athiwaratkun, B., Krone, J., Ma, J., Achille, A., Anubhai, R., Nogueira, C., Santos, B., Xiang, S., and Soatto 2021. Structured prediction as translation between augmented natural languages. In 9th International Conference on Learning Representations.\nPeng, H., Parikh, A. P., Faruqui, M., Dhingra, B., and Das, D. 2019. Text generation with exemplar-based adaptive decoding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT).\nQi, P., Zhang, Y., Zhang, Y., Bolton, J., and Manning, C. D. 2020. Stanza: A python natural language processing toolkit for many human languages. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations (ACL).\nQin, G. and Eisner, J. 2021. Learning how to ask: Querying lms with mixtures of soft prompts. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT).\nRaffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M., Zhou, Y., Li, W., and Liu, P. J. 2020. Exploring the limits of transfer learning with a unified text-to-text transformer. In J. Mach. Learn. Res.\nTeven, L., Scao, A. M., and Rush 2021. How many data points is a prompt worth. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT).\nSchick, T. and Sch\u00fctze, H. 2021. Exploiting cloze-questions for few-shot text classification and natural language inference. In Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics (EACL).\nSee, A., Peter, J., Liu, C. D., and Manning 2017. Get to the point: Summarization with pointergenerator networks. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics.\nShin, T., Razeghi, Y., Logan, R. L., IV, Wallace, E., and Singh, S. 2020. Autoprompt: Eliciting knowledge from language models with automatically generated prompts. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing.\nSong, Z., Bies, A., Strassel, S. M., Riese, T., Mott, J., Ellis, J., Wright, J., Kulick, S., Ryant, N., and Ma, X. 2015. From light to rich ERE: annotation of entities, relations, and events. In Proceedings of the The 3rd Workshop on EVENTS: Definition, Detection, Coreference, and Representation, (EVENTS@HLP-NAACL).\nSubburathinam, A., Lu, D., Ji, H., May, J., Chang, S., Sil, A., and ClareR\nVoss 2019. Cross-lingual structure transfer for relation and event extraction. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP).\nTang, Y., Tran, C., Li, X., Chen, P., Goyal, N., Chaudhary, V., Gu, J., and Fan, A. 2020. Multilingual translation with extensible multilingual pretraining and finetuning. In Multilingual translation with extensible multilingual pretraining and finetuning. arXiv:2008.00401\nVaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, L., and Polosukhin, I. 2017. Attention is all you need. In Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017 (NeurIPS).\nWadden, D., Wennberg, U., Luan, Y., and Hajishirzi, H. 2019. Entity, relation, and event extraction with contextualized span representations. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing.\nWang, X., Wang, Z., Han, X., Liu, Z., Li, J., Li, P., Sun, M., Zhou, J., and Ren, X. 2019. HMEAE: hierarchical modular event argument extraction. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing.\nGenta Indra Winata, A., Madotto, Z., Lin, R., Liu, J., Yosinski, P., and Fung 2021. Language models are few-shot multilingual learners. In Language models are few-shot multilingual learners. arXiv:2109.07684\nXu, H., Ebner, S., Yarmohammadi, M., White, A. S., Van Durme, B., and Murray, K. W. 2021. Gradual fine-tuning for low-resource domain adaptation. In Gradual fine-tuning for low-resource domain adaptation. arXiv:2103.02205\nXue, L., Constant, N., Roberts, A., Kale, M., Al-Rfou, R., and Siddhant, A. Aditya Barua, and Colin Raffel. 2021. mt5: A massively multilingual pre-trained text-to-text transformer. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT).\nYan, H., Gui, T., Dai, J., Guo, Q., Zhang, Z., and Qiu, X. 2021. A unified generative framework for various NER subtasks. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (ACL/IJCNLP).\nZou, B., Xu, Z., Hong, Y., and Zhou, G. 2018. Adversarial feature adaptation for cross-lingual relation classification. In Proceedings of the 27th International Conference on Computational Linguistics (COLING)."
            }
        ],
        "spans_b": [
            {
                "filename": "paper_6.txt",
                "start": 2053,
                "end": 2071,
                "label": "Format",
                "text": "(Liu et al., 2021)",
                "full_text": "Related Work\n\nZero-shot cross-lingual structured prediction. Zero-shot cross-lingual learning becomes an emerging research topic as it eliminates the requirement of labeled data for training models in low-resource languages. Various structured prediction tasks have be studied, including named entity recognition (Pan et al., 2017;Hu et al., 2020), dependency parsing (Ahmad et al., 2019, relation extraction (Zou et al., 2018;Ni and Florian, 2019), and event argument extraction (Subburathinam et al., 2019;Ahmad et al., 2021;Nguyen and Nguyen, 2021). Most of them are classification-based models that build classifiers on top of a multilingual pre-trained masked language models. To further deal with the discrepancy between languages, some of them require additional information, such as bilingual dictionaries (Liu et al., 2019; Ni and Florian, 2019), translation pairs (Zou et al., 2018), and dependency parse trees (Subburathinam et al., 2019;Ahmad et al., 2021;Nguyen and Nguyen, 2021). However, as pointed out by previous literature (Li et al., 2021;Hsu et al., 2021), classification-based models are less powerful to model dependencies between entities compared to generation-based models.\n\nGeneration-based structured prediction. Several works have demonstrated the great success of generation-based models on monolingual structured prediction tasks, including named entity recognition (Yan et al., 2021), relation extraction (Huang et al., 2021;Paolini et al., 2021), and event extraction (Du et al., 2021;Hsu et al., 2021;Lu et al., 2021). Yet, as mentioned in Section 1, their designed generating targets are language-dependent. Accordingly, directly applying their methods to the zero-shot cross-lingual setting would result in less-preferred performance.\n\nPrompting methods. There are growing interests recently to incorporate prompts on pre-trained language models in order to guide the models' behavior or elicit knowledge (Shin et al., 2020;Schick and Sch\u00fctze, 2021;Qin and Eisner, 2021;Scao and Rush, 2021). Following the taxonomy in (Liu et al., 2021), these methods can be classified depending on whether the language models' parameters are tuned and on whether trainable prompts are introduced. Our method belongs to the category that fixes the prompts and tune the language models' parameters. Despite the flourish of the research in prompting methods, there is only limited attention being put on multilingual tasks (Winata et al., 2021).\n\n References: \nWasi Uddin Ahmad, N., Peng, K., and Chang 2021. GATE: graph attention transformer encoder for cross-lingual relation and event extraction. In Thirty-Fifth AAAI Conference on Artificial Intelligence (AAAI).\nWasi Uddin Ahmad, Z., Zhang, X., Ma, E. H., Hovy, K., Chang, N., and Peng 2019. On difficulties of cross-lingual transfer with order differences: A case study on dependency parsing. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT).\nDe Cao, N., Wu, L., Popat, K., Artetxe, M., Goyal, N., Plekhanov, M., Zettlemoyer, L., Cancedda, N., Riedel, S., and Petroni, F. 2021. Multilingual autoregressive entity linking. In Multilingual autoregressive entity linking. arXiv:2103.12528\nConneau, A., Khandelwal, K., Goyal, N., Chaudhary, V., Wenzek, G., Guzm\u00e1n, F., Grave, E., Ott, M., Zettlemoyer, L., and Stoyanov, V. 2020. Unsupervised cross-lingual representation learning at scale. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics (ACL).\nDoddington, G. R., Mitchell, A., Przybocki, M. A., Ramshaw, L. A., Strassel, S. M., and Weischedel, R. M. 2004. The automatic content extraction (ACE) program -tasks, data, and evaluation. In Proceedings of the Fourth International Conference on Language Resources and Evaluation (LREC).\nDu, X., Rush, A. M., and Cardie, C. 2021. GRIT: generative role-filler transformers for document-level event entity extraction. In Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics (EACL).\nHsu, I., Huang, K., Boschee, E., Miller, S., Natarajan, P., Chang, K., and Peng, N. 2021. Degree: A data-efficient generative event extraction model. In Degree: A data-efficient generative event extraction model. arXiv:2108.12724\nHu, J., Ruder, S., Siddhant, A., Neubig, G., Firat, O., and Johnson, M. 2020. XTREME: A massively multilingual multitask benchmark for evaluating cross-lingual generalisation. In Proceedings of the 37th International Conference on Machine Learning (ICML).\nHuang, K., Tang, S., and Peng, N. 2021. Document-level entity-based extraction as template generation. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing.\nThomas, N., Kipf, M., and Welling 2017. Semisupervised classification with graph convolutional networks. In 5th International Conference on Learning Representations (ICLR).\nLewis, M., Liu, Y., Goyal ; Abdelrahman Mohamed, N., Levy, O., Stoyanov, V., and Zettlemoyer, L. 2020. BART: denoising sequence-to-sequence pretraining for natural language generation, translation, and comprehension. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics.\nLi, S., Heng, J., and Han, J. 2021. Documentlevel event argument extraction by conditional generation. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT).\nLin, Y., Ji, H., Huang, F., and Wu, L. 2020. A joint neural model for information extraction with global features. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics (ACL).\nLiu, J., Chen, Y., and Liu, K. 2019. Neural cross-lingual event detection with minimal parallel resources. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP).\nLiu, P., Yuan, W., Fu, J., Jiang, Z., Hayashi, H., and Neubig, G. 2021. Pretrain, prompt, and predict: A systematic survey of prompting methods in natural language processing. In Pretrain, prompt, and predict: A systematic survey of prompting methods in natural language processing. arXiv:2107.13586\nLiu, Y., Gu, J., Goyal, N., Li, X., Edunov, S., Ghazvininejad, M., Lewis, M., and Zettlemoyer, L. 2020. Multilingual denoising pre-training for neural machine translation. In Trans. Assoc. Comput. Linguistics. pp. 726--742\nLu, Y., Lin, H., Xu, J., Han, X., Tang, J., Li, A., Sun, L., Liao, M., and Chen, S. 2021. Text2event: Controllable sequence-tostructure generation for end-to-end event extraction. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (ACL/IJCNLP).\nVan Nguyen, M. and Huu Nguyen, T. 2021. Improving cross-lingual transfer for event argument extraction with language-universal sentence structures. In Proceedings of the Sixth Arabic Natural Language Processing Workshop.\nNi, J. and Florian, R. 2019. Neural cross-lingual relation extraction based on bilingual word embedding mapping. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP).\nPan, X., Zhang, B., May, J., Nothman, J., Knight, K., and Ji, H. 2017. Crosslingual name tagging and linking for 282 languages. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (ACL).\nPaolini, G., Athiwaratkun, B., Krone, J., Ma, J., Achille, A., Anubhai, R., Nogueira, C., Santos, B., Xiang, S., and Soatto 2021. Structured prediction as translation between augmented natural languages. In 9th International Conference on Learning Representations.\nPeng, H., Parikh, A. P., Faruqui, M., Dhingra, B., and Das, D. 2019. Text generation with exemplar-based adaptive decoding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT).\nQi, P., Zhang, Y., Zhang, Y., Bolton, J., and Manning, C. D. 2020. Stanza: A python natural language processing toolkit for many human languages. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations (ACL).\nQin, G. and Eisner, J. 2021. Learning how to ask: Querying lms with mixtures of soft prompts. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT).\nRaffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M., Zhou, Y., Li, W., and Liu, P. J. 2020. Exploring the limits of transfer learning with a unified text-to-text transformer. In J. Mach. Learn. Res.\nTeven, L., Scao, A. M., and Rush 2021. How many data points is a prompt worth. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT).\nSchick, T. and Sch\u00fctze, H. 2021. Exploiting cloze-questions for few-shot text classification and natural language inference. In Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics (EACL).\nSee, A., Peter, J., Liu, C. D., and Manning 2017. Get to the point: Summarization with pointergenerator networks. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics.\nShin, T., Razeghi, Y., Logan, R. L., IV, Wallace, E., and Singh, S. 2020. Autoprompt: Eliciting knowledge from language models with automatically generated prompts. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing.\nSong, Z., Bies, A., Strassel, S. M., Riese, T., Mott, J., Ellis, J., Wright, J., Kulick, S., Ryant, N., and Ma, X. 2015. From light to rich ERE: annotation of entities, relations, and events. In Proceedings of the The 3rd Workshop on EVENTS: Definition, Detection, Coreference, and Representation, (EVENTS@HLP-NAACL).\nSubburathinam, A., Lu, D., Ji, H., May, J., Chang, S., Sil, A., and ClareR\nVoss 2019. Cross-lingual structure transfer for relation and event extraction. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP).\nTang, Y., Tran, C., Li, X., Chen, P., Goyal, N., Chaudhary, V., Gu, J., and Fan, A. 2020. Multilingual translation with extensible multilingual pretraining and finetuning. In Multilingual translation with extensible multilingual pretraining and finetuning. arXiv:2008.00401\nVaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, L., and Polosukhin, I. 2017. Attention is all you need. In Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017 (NeurIPS).\nWadden, D., Wennberg, U., Luan, Y., and Hajishirzi, H. 2019. Entity, relation, and event extraction with contextualized span representations. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing.\nWang, X., Wang, Z., Han, X., Liu, Z., Li, J., Li, P., Sun, M., Zhou, J., and Ren, X. 2019. HMEAE: hierarchical modular event argument extraction. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing.\nGenta Indra Winata, A., Madotto, Z., Lin, R., Liu, J., Yosinski, P., and Fung 2021. Language models are few-shot multilingual learners. In Language models are few-shot multilingual learners. arXiv:2109.07684\nXu, H., Ebner, S., Yarmohammadi, M., White, A. S., Van Durme, B., and Murray, K. W. 2021. Gradual fine-tuning for low-resource domain adaptation. In Gradual fine-tuning for low-resource domain adaptation. arXiv:2103.02205\nXue, L., Constant, N., Roberts, A., Kale, M., Al-Rfou, R., and Siddhant, A. Aditya Barua, and Colin Raffel. 2021. mt5: A massively multilingual pre-trained text-to-text transformer. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT).\nYan, H., Gui, T., Dai, J., Guo, Q., Zhang, Z., and Qiu, X. 2021. A unified generative framework for various NER subtasks. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (ACL/IJCNLP).\nZou, B., Xu, Z., Hong, Y., and Zhou, G. 2018. Adversarial feature adaptation for cross-lingual relation classification. In Proceedings of the 27th International Conference on Computational Linguistics (COLING)."
            }
        ]
    }
]