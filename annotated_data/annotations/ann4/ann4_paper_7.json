[
    {
        "filename": "paper_7.txt",
        "start": 262,
        "end": 588,
        "label": "Coherence",
        "text": "Following the work of DrQA (Chen et al., 2017), most recent works build a two-stage retriever-reader system to tackle the problem. The retriever aims at retrieving supportive passages to the given question from a large document corpus. The reader intends to find answer of the question from the first stage retrieved passages.",
        "full_text": "Related Work\n\nOpen-Domain Question Answering\n\nIn this era of data explosion, ODQA offers a way to rapidly and accurately fulfill user's information needs, and hence has recently received significant attention from both industry and academia (Min et al., 2021a). Following the work of DrQA (Chen et al., 2017), most recent works build a two-stage retriever-reader system to tackle the problem. The retriever aims at retrieving supportive passages to the given question from a large document corpus. The reader intends to find answer of the question from the first stage retrieved passages. Early work of Chen et al. (2017) adapts a BiLSTM architecture with various lexical and semantic features from the question and passages as inputs. Later, with the emergence of large-scale pre-trained language models, readers based on pre-trained models such as BERT and T5 Raffel et al., 2019) have become a common approach (Yang et al., 2019;Karpukhin et al., 2020;Izacard and Grave, 2020b).\n\nGenerative Readers\n\nCompared to extractive models which extract existing words from the retrieved passages, generative models are able to produce new words out of the retrieved passages, and thus provide a more flexible modeling framework.  and Lewis et al. (2020a) concatenate the given question with top retrieved passages and feed the concatenation to the BART model (Lewis et al., 2019). Izacard and Grave (2020b) separately encodes the question with each top retrieved passage, then takes the concatenation of the encoder outputs as input to the decoder. Their method provide a way to better aggregate evidence from multiple passages and improve the performance significantly. FiD-KD (Izacard and Grave, 2020a) is an extension of FiD model that increases the accuracy of passage retrieval by training the dense retriever with the guidance of the FiD reader iteratively.\n\nPointer-Generator Network\n\nPointer-Generator Network (See et al., 2017) is an extension of the sequence-to-sequence model by integrating a copy mechanism (Vinyals et al., 2017) into the generator. At each decoding stage, the model is able to either directly copy a word from the input or generate one with certain probability, and thus can be viewed as a combination of extractive and generative approaches. It has been frequently used in natural language tasks like summarization (Gu et al., 2016;See et al.,  Gehrmann et al., 2018) and neural machine translation (Luong et al., 2014;Gu et al., 2017), but its application to ODQA has been less explored.\n\n References: \nAsai, A., Hashimoto, K., Hajishirzi, H., Socher, R., and Xiong, C. 1911. Learning to retrieve reasoning paths over wikipedia graph for question answering. In Learning to retrieve reasoning paths over wikipedia graph for question answering.\nChen, D., Fisch, A., Weston, J., and Bordes, A. 2017. Reading wikipedia to answer opendomain questions. In Reading wikipedia to answer opendomain questions. abs/1704.00051\nDevlin, J., Chang, M., Lee, K., and Toutanova, K. 2019. BERT: pre-training of deep bidirectional transformers for language understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019. pp. 4171--4186 10.18653/v1/n19-1423\nGehrmann, S., Deng, Y., and Rush, A. M. 2018. Bottom-up abstractive summarization. In Bottom-up abstractive summarization. abs/1808.10792\nGu, J., Bradbury, J., Xiong, C., Victor, O. K., Li, R., and Socher 2017. Non-autoregressive neural machine translation. In Non-autoregressive neural machine translation. abs/1711.02281\nGu, J., Lu, Z., Li, H., Victor, O. K., and Li 2016. Incorporating copying mechanism in sequenceto-sequence learning. In Incorporating copying mechanism in sequenceto-sequence learning. abs/1603.06393\nIzacard, G. and Grave, E. 2020. Distilling knowledge from reader to retriever for question answering. In Distilling knowledge from reader to retriever for question answering. abs/2012.04584\nIzacard, G. and Grave, E. 1282. Leveraging passage retrieval with generative models for open domain question answering. CoRR, abs. In Leveraging passage retrieval with generative models for open domain question answering. CoRR, abs.\nJoshi, M., Choi, E., Weld, D. S., and Zettlemoyer, L. 2017. Triviaqa: A large scale distantly supervised challenge dataset for reading comprehension. In Triviaqa: A large scale distantly supervised challenge dataset for reading comprehension. abs/1705.03551\nKarpukhin, V., Oguz, B., Min, S., Lewis, P., Wu, L., Edunov, S., Chen, D., and Yih, W. 2020. Dense passage retrieval for open-domain question answering. In Dense passage retrieval for open-domain question answering. arXiv:2004.04906\nKwiatkowski, T., Palomaki, J., Redfield, O., Collins, M., Parikh, A., Alberti, C., Epstein, D., Polosukhin, I., Devlin, J., Lee, K., Toutanova, K., Jones, L., Kelcey, M., Chang, M., Dai, A., Uszkoreit, J., Le, Q., and Petrov, S. 2019. Natural questions: a benchmark for question answering research. In Transactions of the Association for Computational Linguistics. pp. 452--466\nLewis, M., Liu, Y., Goyal, N., Ghazvininejad, M., Mohamed, A., Levy, O., Stoyanov, V., and Zettlemoyer, L. 2019.\n1910. BART: denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension. CoRR, abs. In BART: denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension. CoRR, abs.\nPatrick, S. H., Lewis, E., Perez, A., Piktus, F., Petroni, V., Karpukhin, N., Goyal, H., K\u00fcttler, M., Lewis, W., Yih, T., Rockt\u00e4schel, S., Riedel, D., and Kiela 2005. Retrieval-augmented generation for knowledge-intensive NLP tasks. In Retrieval-augmented generation for knowledge-intensive NLP tasks.\nPatrick, S. H., Lewis, P., Stenetorp, S., and Riedel 2008. Question and answer test-train overlap in open-domain question answering datasets. CoRR, abs. In Question and answer test-train overlap in open-domain question answering datasets. CoRR, abs.\nLoshchilov, I. and Hutter, F. 2017. Fixing weight decay regularization in adam. In Fixing weight decay regularization in adam. abs/1711.05101\nLuong, T., Sutskever, I., Le, Q. V., Vinyals, O., and Zaremba, W. 2014. Addressing the rare word problem in neural machine translation. In Addressing the rare word problem in neural machine translation.\nMaynez, J., Narayan, S., Bohnet, B., and Mcdonald, R. T. 0661. On faithfulness and factuality in abstractive summarization. CoRR, abs. In On faithfulness and factuality in abstractive summarization. CoRR, abs.\nMin, S., Boyd-Graber, J. L., Alberti, C., Chen, D., Choi, E., Collins, M., Guu, K., Hajishirzi, H., Lee, K., Palomaki, J., Raffel, C., Roberts, A., Kwiatkowski, T., Patrick, S. H., Lewis, Y., Wu, H., K\u00fcttler, L., Liu, P., Minervini, P., Stenetorp, S., Riedel, S., Yang, M., Seo, G., Izacard, F., Petroni, L., Hosseini, N. D., Cao, E., Grave, I., Yamada, S., Shimaoka, M., Suzuki, S., Miyawaki, S., Sato, R., Takahashi, J., Suzuki, M., Fajcik, M., and Docekal\nMin, S., Lee, K., Chang, M., Toutanova, K., and Hajishirzi, H. 2021. Joint passage ranking for diverse multi-answer retrieval. In Joint passage ranking for diverse multi-answer retrieval. abs/2104.08445\nMin, S., Michael, J., Hajishirzi, H., and Zettlemoyer, L. 2004. Ambigqa: Answering ambiguous open-domain questions. CoRR, abs. In Ambigqa: Answering ambiguous open-domain questions. CoRR, abs.\nRaffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M., Zhou, Y., Li, W., and Liu, P. J. 1910. Exploring the limits of transfer learning with a unified text-to-text transformer. In Exploring the limits of transfer learning with a unified text-to-text transformer.\nRajpurkar, P., Zhang, J., Lopyrev, K., and Liang, P. 2016. Squad: 100, 000+ questions for machine comprehension of text. In Squad: 100, 000+ questions for machine comprehension of text. abs/1606.05250\nRogers, A., Gardner, M., and Augenstein, I. 2021. QA dataset explosion: A taxonomy of NLP resources for question answering and reading comprehension. In QA dataset explosion: A taxonomy of NLP resources for question answering and reading comprehension. abs/2107.12708\nSee, A., Peter, J., Liu, C.D., and Manning 2017. Get to the point: Summarization with pointer-generator networks. In Get to the point: Summarization with pointer-generator networks. arXiv:1704.04368\nVinyals, O., Fortunato, M., and Jaitly, N. 2017.\nVoorhees, E. M. 1999. The TREC-8 question answering track report. In Proceedings of The Eighth Text REtrieval Conference. TREC 1999\nWu, Y., Minervini, P., Stenetorp, P., and Riedel, S. 2021. Training adaptive computation for open-domain question answering with computational constraints. In Training adaptive computation for open-domain question answering with computational constraints. abs/2107.02102\nYamada, I., Asai, A., and Hajishirzi, H. 2021. Efficient passage retrieval with hashing for open-domain question answering. In Efficient passage retrieval with hashing for open-domain question answering. abs/2106.00882\nYang, W., Xie, Y., Lin, A., Li, X., Tan, L., Xiong, K., Li, M., and Lin, J. 1718. End-to-end open-domain question answering with bertserini. CoRR, abs. In End-to-end open-domain question answering with bertserini. CoRR, abs.\nZhou, C., Neubig, G., Gu, J., Diab, M., Guzm\u00e1n, F., Zettlemoyer, L., and Ghazvininejad, M. 2021. Detecting hallucinated content in conditional neural sequence generation. In Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021. pp. 1393--1404 10.18653/v1/2021.findings-acl.120"
    },
    {
        "filename": "paper_7.txt",
        "start": 588,
        "end": 981,
        "label": "Coherence",
        "text": "Early work of Chen et al. (2017) adapts a BiLSTM architecture with various lexical and semantic features from the question and passages as inputs. Later, with the emergence of large-scale pre-trained language models, readers based on pre-trained models such as BERT and T5 Raffel et al., 2019) have become a common approach (Yang et al., 2019;Karpukhin et al., 2020;Izacard and Grave, 2020b).",
        "full_text": "Related Work\n\nOpen-Domain Question Answering\n\nIn this era of data explosion, ODQA offers a way to rapidly and accurately fulfill user's information needs, and hence has recently received significant attention from both industry and academia (Min et al., 2021a). Following the work of DrQA (Chen et al., 2017), most recent works build a two-stage retriever-reader system to tackle the problem. The retriever aims at retrieving supportive passages to the given question from a large document corpus. The reader intends to find answer of the question from the first stage retrieved passages. Early work of Chen et al. (2017) adapts a BiLSTM architecture with various lexical and semantic features from the question and passages as inputs. Later, with the emergence of large-scale pre-trained language models, readers based on pre-trained models such as BERT and T5 Raffel et al., 2019) have become a common approach (Yang et al., 2019;Karpukhin et al., 2020;Izacard and Grave, 2020b).\n\nGenerative Readers\n\nCompared to extractive models which extract existing words from the retrieved passages, generative models are able to produce new words out of the retrieved passages, and thus provide a more flexible modeling framework.  and Lewis et al. (2020a) concatenate the given question with top retrieved passages and feed the concatenation to the BART model (Lewis et al., 2019). Izacard and Grave (2020b) separately encodes the question with each top retrieved passage, then takes the concatenation of the encoder outputs as input to the decoder. Their method provide a way to better aggregate evidence from multiple passages and improve the performance significantly. FiD-KD (Izacard and Grave, 2020a) is an extension of FiD model that increases the accuracy of passage retrieval by training the dense retriever with the guidance of the FiD reader iteratively.\n\nPointer-Generator Network\n\nPointer-Generator Network (See et al., 2017) is an extension of the sequence-to-sequence model by integrating a copy mechanism (Vinyals et al., 2017) into the generator. At each decoding stage, the model is able to either directly copy a word from the input or generate one with certain probability, and thus can be viewed as a combination of extractive and generative approaches. It has been frequently used in natural language tasks like summarization (Gu et al., 2016;See et al.,  Gehrmann et al., 2018) and neural machine translation (Luong et al., 2014;Gu et al., 2017), but its application to ODQA has been less explored.\n\n References: \nAsai, A., Hashimoto, K., Hajishirzi, H., Socher, R., and Xiong, C. 1911. Learning to retrieve reasoning paths over wikipedia graph for question answering. In Learning to retrieve reasoning paths over wikipedia graph for question answering.\nChen, D., Fisch, A., Weston, J., and Bordes, A. 2017. Reading wikipedia to answer opendomain questions. In Reading wikipedia to answer opendomain questions. abs/1704.00051\nDevlin, J., Chang, M., Lee, K., and Toutanova, K. 2019. BERT: pre-training of deep bidirectional transformers for language understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019. pp. 4171--4186 10.18653/v1/n19-1423\nGehrmann, S., Deng, Y., and Rush, A. M. 2018. Bottom-up abstractive summarization. In Bottom-up abstractive summarization. abs/1808.10792\nGu, J., Bradbury, J., Xiong, C., Victor, O. K., Li, R., and Socher 2017. Non-autoregressive neural machine translation. In Non-autoregressive neural machine translation. abs/1711.02281\nGu, J., Lu, Z., Li, H., Victor, O. K., and Li 2016. Incorporating copying mechanism in sequenceto-sequence learning. In Incorporating copying mechanism in sequenceto-sequence learning. abs/1603.06393\nIzacard, G. and Grave, E. 2020. Distilling knowledge from reader to retriever for question answering. In Distilling knowledge from reader to retriever for question answering. abs/2012.04584\nIzacard, G. and Grave, E. 1282. Leveraging passage retrieval with generative models for open domain question answering. CoRR, abs. In Leveraging passage retrieval with generative models for open domain question answering. CoRR, abs.\nJoshi, M., Choi, E., Weld, D. S., and Zettlemoyer, L. 2017. Triviaqa: A large scale distantly supervised challenge dataset for reading comprehension. In Triviaqa: A large scale distantly supervised challenge dataset for reading comprehension. abs/1705.03551\nKarpukhin, V., Oguz, B., Min, S., Lewis, P., Wu, L., Edunov, S., Chen, D., and Yih, W. 2020. Dense passage retrieval for open-domain question answering. In Dense passage retrieval for open-domain question answering. arXiv:2004.04906\nKwiatkowski, T., Palomaki, J., Redfield, O., Collins, M., Parikh, A., Alberti, C., Epstein, D., Polosukhin, I., Devlin, J., Lee, K., Toutanova, K., Jones, L., Kelcey, M., Chang, M., Dai, A., Uszkoreit, J., Le, Q., and Petrov, S. 2019. Natural questions: a benchmark for question answering research. In Transactions of the Association for Computational Linguistics. pp. 452--466\nLewis, M., Liu, Y., Goyal, N., Ghazvininejad, M., Mohamed, A., Levy, O., Stoyanov, V., and Zettlemoyer, L. 2019.\n1910. BART: denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension. CoRR, abs. In BART: denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension. CoRR, abs.\nPatrick, S. H., Lewis, E., Perez, A., Piktus, F., Petroni, V., Karpukhin, N., Goyal, H., K\u00fcttler, M., Lewis, W., Yih, T., Rockt\u00e4schel, S., Riedel, D., and Kiela 2005. Retrieval-augmented generation for knowledge-intensive NLP tasks. In Retrieval-augmented generation for knowledge-intensive NLP tasks.\nPatrick, S. H., Lewis, P., Stenetorp, S., and Riedel 2008. Question and answer test-train overlap in open-domain question answering datasets. CoRR, abs. In Question and answer test-train overlap in open-domain question answering datasets. CoRR, abs.\nLoshchilov, I. and Hutter, F. 2017. Fixing weight decay regularization in adam. In Fixing weight decay regularization in adam. abs/1711.05101\nLuong, T., Sutskever, I., Le, Q. V., Vinyals, O., and Zaremba, W. 2014. Addressing the rare word problem in neural machine translation. In Addressing the rare word problem in neural machine translation.\nMaynez, J., Narayan, S., Bohnet, B., and Mcdonald, R. T. 0661. On faithfulness and factuality in abstractive summarization. CoRR, abs. In On faithfulness and factuality in abstractive summarization. CoRR, abs.\nMin, S., Boyd-Graber, J. L., Alberti, C., Chen, D., Choi, E., Collins, M., Guu, K., Hajishirzi, H., Lee, K., Palomaki, J., Raffel, C., Roberts, A., Kwiatkowski, T., Patrick, S. H., Lewis, Y., Wu, H., K\u00fcttler, L., Liu, P., Minervini, P., Stenetorp, S., Riedel, S., Yang, M., Seo, G., Izacard, F., Petroni, L., Hosseini, N. D., Cao, E., Grave, I., Yamada, S., Shimaoka, M., Suzuki, S., Miyawaki, S., Sato, R., Takahashi, J., Suzuki, M., Fajcik, M., and Docekal\nMin, S., Lee, K., Chang, M., Toutanova, K., and Hajishirzi, H. 2021. Joint passage ranking for diverse multi-answer retrieval. In Joint passage ranking for diverse multi-answer retrieval. abs/2104.08445\nMin, S., Michael, J., Hajishirzi, H., and Zettlemoyer, L. 2004. Ambigqa: Answering ambiguous open-domain questions. CoRR, abs. In Ambigqa: Answering ambiguous open-domain questions. CoRR, abs.\nRaffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M., Zhou, Y., Li, W., and Liu, P. J. 1910. Exploring the limits of transfer learning with a unified text-to-text transformer. In Exploring the limits of transfer learning with a unified text-to-text transformer.\nRajpurkar, P., Zhang, J., Lopyrev, K., and Liang, P. 2016. Squad: 100, 000+ questions for machine comprehension of text. In Squad: 100, 000+ questions for machine comprehension of text. abs/1606.05250\nRogers, A., Gardner, M., and Augenstein, I. 2021. QA dataset explosion: A taxonomy of NLP resources for question answering and reading comprehension. In QA dataset explosion: A taxonomy of NLP resources for question answering and reading comprehension. abs/2107.12708\nSee, A., Peter, J., Liu, C.D., and Manning 2017. Get to the point: Summarization with pointer-generator networks. In Get to the point: Summarization with pointer-generator networks. arXiv:1704.04368\nVinyals, O., Fortunato, M., and Jaitly, N. 2017.\nVoorhees, E. M. 1999. The TREC-8 question answering track report. In Proceedings of The Eighth Text REtrieval Conference. TREC 1999\nWu, Y., Minervini, P., Stenetorp, P., and Riedel, S. 2021. Training adaptive computation for open-domain question answering with computational constraints. In Training adaptive computation for open-domain question answering with computational constraints. abs/2107.02102\nYamada, I., Asai, A., and Hajishirzi, H. 2021. Efficient passage retrieval with hashing for open-domain question answering. In Efficient passage retrieval with hashing for open-domain question answering. abs/2106.00882\nYang, W., Xie, Y., Lin, A., Li, X., Tan, L., Xiong, K., Li, M., and Lin, J. 1718. End-to-end open-domain question answering with bertserini. CoRR, abs. In End-to-end open-domain question answering with bertserini. CoRR, abs.\nZhou, C., Neubig, G., Gu, J., Diab, M., Guzm\u00e1n, F., Zettlemoyer, L., and Ghazvininejad, M. 2021. Detecting hallucinated content in conditional neural sequence generation. In Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021. pp. 1393--1404 10.18653/v1/2021.findings-acl.120"
    },
    {
        "filename": "paper_7.txt",
        "start": 1223,
        "end": 1374,
        "label": "Coherence",
        "text": "and Lewis et al. (2020a) concatenate the given question with top retrieved passages and feed the concatenation to the BART model (Lewis et al., 2019).",
        "full_text": "Related Work\n\nOpen-Domain Question Answering\n\nIn this era of data explosion, ODQA offers a way to rapidly and accurately fulfill user's information needs, and hence has recently received significant attention from both industry and academia (Min et al., 2021a). Following the work of DrQA (Chen et al., 2017), most recent works build a two-stage retriever-reader system to tackle the problem. The retriever aims at retrieving supportive passages to the given question from a large document corpus. The reader intends to find answer of the question from the first stage retrieved passages. Early work of Chen et al. (2017) adapts a BiLSTM architecture with various lexical and semantic features from the question and passages as inputs. Later, with the emergence of large-scale pre-trained language models, readers based on pre-trained models such as BERT and T5 Raffel et al., 2019) have become a common approach (Yang et al., 2019;Karpukhin et al., 2020;Izacard and Grave, 2020b).\n\nGenerative Readers\n\nCompared to extractive models which extract existing words from the retrieved passages, generative models are able to produce new words out of the retrieved passages, and thus provide a more flexible modeling framework.  and Lewis et al. (2020a) concatenate the given question with top retrieved passages and feed the concatenation to the BART model (Lewis et al., 2019). Izacard and Grave (2020b) separately encodes the question with each top retrieved passage, then takes the concatenation of the encoder outputs as input to the decoder. Their method provide a way to better aggregate evidence from multiple passages and improve the performance significantly. FiD-KD (Izacard and Grave, 2020a) is an extension of FiD model that increases the accuracy of passage retrieval by training the dense retriever with the guidance of the FiD reader iteratively.\n\nPointer-Generator Network\n\nPointer-Generator Network (See et al., 2017) is an extension of the sequence-to-sequence model by integrating a copy mechanism (Vinyals et al., 2017) into the generator. At each decoding stage, the model is able to either directly copy a word from the input or generate one with certain probability, and thus can be viewed as a combination of extractive and generative approaches. It has been frequently used in natural language tasks like summarization (Gu et al., 2016;See et al.,  Gehrmann et al., 2018) and neural machine translation (Luong et al., 2014;Gu et al., 2017), but its application to ODQA has been less explored.\n\n References: \nAsai, A., Hashimoto, K., Hajishirzi, H., Socher, R., and Xiong, C. 1911. Learning to retrieve reasoning paths over wikipedia graph for question answering. In Learning to retrieve reasoning paths over wikipedia graph for question answering.\nChen, D., Fisch, A., Weston, J., and Bordes, A. 2017. Reading wikipedia to answer opendomain questions. In Reading wikipedia to answer opendomain questions. abs/1704.00051\nDevlin, J., Chang, M., Lee, K., and Toutanova, K. 2019. BERT: pre-training of deep bidirectional transformers for language understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019. pp. 4171--4186 10.18653/v1/n19-1423\nGehrmann, S., Deng, Y., and Rush, A. M. 2018. Bottom-up abstractive summarization. In Bottom-up abstractive summarization. abs/1808.10792\nGu, J., Bradbury, J., Xiong, C., Victor, O. K., Li, R., and Socher 2017. Non-autoregressive neural machine translation. In Non-autoregressive neural machine translation. abs/1711.02281\nGu, J., Lu, Z., Li, H., Victor, O. K., and Li 2016. Incorporating copying mechanism in sequenceto-sequence learning. In Incorporating copying mechanism in sequenceto-sequence learning. abs/1603.06393\nIzacard, G. and Grave, E. 2020. Distilling knowledge from reader to retriever for question answering. In Distilling knowledge from reader to retriever for question answering. abs/2012.04584\nIzacard, G. and Grave, E. 1282. Leveraging passage retrieval with generative models for open domain question answering. CoRR, abs. In Leveraging passage retrieval with generative models for open domain question answering. CoRR, abs.\nJoshi, M., Choi, E., Weld, D. S., and Zettlemoyer, L. 2017. Triviaqa: A large scale distantly supervised challenge dataset for reading comprehension. In Triviaqa: A large scale distantly supervised challenge dataset for reading comprehension. abs/1705.03551\nKarpukhin, V., Oguz, B., Min, S., Lewis, P., Wu, L., Edunov, S., Chen, D., and Yih, W. 2020. Dense passage retrieval for open-domain question answering. In Dense passage retrieval for open-domain question answering. arXiv:2004.04906\nKwiatkowski, T., Palomaki, J., Redfield, O., Collins, M., Parikh, A., Alberti, C., Epstein, D., Polosukhin, I., Devlin, J., Lee, K., Toutanova, K., Jones, L., Kelcey, M., Chang, M., Dai, A., Uszkoreit, J., Le, Q., and Petrov, S. 2019. Natural questions: a benchmark for question answering research. In Transactions of the Association for Computational Linguistics. pp. 452--466\nLewis, M., Liu, Y., Goyal, N., Ghazvininejad, M., Mohamed, A., Levy, O., Stoyanov, V., and Zettlemoyer, L. 2019.\n1910. BART: denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension. CoRR, abs. In BART: denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension. CoRR, abs.\nPatrick, S. H., Lewis, E., Perez, A., Piktus, F., Petroni, V., Karpukhin, N., Goyal, H., K\u00fcttler, M., Lewis, W., Yih, T., Rockt\u00e4schel, S., Riedel, D., and Kiela 2005. Retrieval-augmented generation for knowledge-intensive NLP tasks. In Retrieval-augmented generation for knowledge-intensive NLP tasks.\nPatrick, S. H., Lewis, P., Stenetorp, S., and Riedel 2008. Question and answer test-train overlap in open-domain question answering datasets. CoRR, abs. In Question and answer test-train overlap in open-domain question answering datasets. CoRR, abs.\nLoshchilov, I. and Hutter, F. 2017. Fixing weight decay regularization in adam. In Fixing weight decay regularization in adam. abs/1711.05101\nLuong, T., Sutskever, I., Le, Q. V., Vinyals, O., and Zaremba, W. 2014. Addressing the rare word problem in neural machine translation. In Addressing the rare word problem in neural machine translation.\nMaynez, J., Narayan, S., Bohnet, B., and Mcdonald, R. T. 0661. On faithfulness and factuality in abstractive summarization. CoRR, abs. In On faithfulness and factuality in abstractive summarization. CoRR, abs.\nMin, S., Boyd-Graber, J. L., Alberti, C., Chen, D., Choi, E., Collins, M., Guu, K., Hajishirzi, H., Lee, K., Palomaki, J., Raffel, C., Roberts, A., Kwiatkowski, T., Patrick, S. H., Lewis, Y., Wu, H., K\u00fcttler, L., Liu, P., Minervini, P., Stenetorp, S., Riedel, S., Yang, M., Seo, G., Izacard, F., Petroni, L., Hosseini, N. D., Cao, E., Grave, I., Yamada, S., Shimaoka, M., Suzuki, S., Miyawaki, S., Sato, R., Takahashi, J., Suzuki, M., Fajcik, M., and Docekal\nMin, S., Lee, K., Chang, M., Toutanova, K., and Hajishirzi, H. 2021. Joint passage ranking for diverse multi-answer retrieval. In Joint passage ranking for diverse multi-answer retrieval. abs/2104.08445\nMin, S., Michael, J., Hajishirzi, H., and Zettlemoyer, L. 2004. Ambigqa: Answering ambiguous open-domain questions. CoRR, abs. In Ambigqa: Answering ambiguous open-domain questions. CoRR, abs.\nRaffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M., Zhou, Y., Li, W., and Liu, P. J. 1910. Exploring the limits of transfer learning with a unified text-to-text transformer. In Exploring the limits of transfer learning with a unified text-to-text transformer.\nRajpurkar, P., Zhang, J., Lopyrev, K., and Liang, P. 2016. Squad: 100, 000+ questions for machine comprehension of text. In Squad: 100, 000+ questions for machine comprehension of text. abs/1606.05250\nRogers, A., Gardner, M., and Augenstein, I. 2021. QA dataset explosion: A taxonomy of NLP resources for question answering and reading comprehension. In QA dataset explosion: A taxonomy of NLP resources for question answering and reading comprehension. abs/2107.12708\nSee, A., Peter, J., Liu, C.D., and Manning 2017. Get to the point: Summarization with pointer-generator networks. In Get to the point: Summarization with pointer-generator networks. arXiv:1704.04368\nVinyals, O., Fortunato, M., and Jaitly, N. 2017.\nVoorhees, E. M. 1999. The TREC-8 question answering track report. In Proceedings of The Eighth Text REtrieval Conference. TREC 1999\nWu, Y., Minervini, P., Stenetorp, P., and Riedel, S. 2021. Training adaptive computation for open-domain question answering with computational constraints. In Training adaptive computation for open-domain question answering with computational constraints. abs/2107.02102\nYamada, I., Asai, A., and Hajishirzi, H. 2021. Efficient passage retrieval with hashing for open-domain question answering. In Efficient passage retrieval with hashing for open-domain question answering. abs/2106.00882\nYang, W., Xie, Y., Lin, A., Li, X., Tan, L., Xiong, K., Li, M., and Lin, J. 1718. End-to-end open-domain question answering with bertserini. CoRR, abs. In End-to-end open-domain question answering with bertserini. CoRR, abs.\nZhou, C., Neubig, G., Gu, J., Diab, M., Guzm\u00e1n, F., Zettlemoyer, L., and Ghazvininejad, M. 2021. Detecting hallucinated content in conditional neural sequence generation. In Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021. pp. 1393--1404 10.18653/v1/2021.findings-acl.120"
    },
    {
        "filename": "paper_7.txt",
        "start": 46,
        "end": 981,
        "label": "Lacks Synthesis",
        "text": "In this era of data explosion, ODQA offers a way to rapidly and accurately fulfill user's information needs, and hence has recently received significant attention from both industry and academia (Min et al., 2021a). Following the work of DrQA (Chen et al., 2017), most recent works build a two-stage retriever-reader system to tackle the problem. The retriever aims at retrieving supportive passages to the given question from a large document corpus. The reader intends to find answer of the question from the first stage retrieved passages. Early work of Chen et al. (2017) adapts a BiLSTM architecture with various lexical and semantic features from the question and passages as inputs. Later, with the emergence of large-scale pre-trained language models, readers based on pre-trained models such as BERT and T5 Raffel et al., 2019) have become a common approach (Yang et al., 2019;Karpukhin et al., 2020;Izacard and Grave, 2020b).",
        "full_text": "Related Work\n\nOpen-Domain Question Answering\n\nIn this era of data explosion, ODQA offers a way to rapidly and accurately fulfill user's information needs, and hence has recently received significant attention from both industry and academia (Min et al., 2021a). Following the work of DrQA (Chen et al., 2017), most recent works build a two-stage retriever-reader system to tackle the problem. The retriever aims at retrieving supportive passages to the given question from a large document corpus. The reader intends to find answer of the question from the first stage retrieved passages. Early work of Chen et al. (2017) adapts a BiLSTM architecture with various lexical and semantic features from the question and passages as inputs. Later, with the emergence of large-scale pre-trained language models, readers based on pre-trained models such as BERT and T5 Raffel et al., 2019) have become a common approach (Yang et al., 2019;Karpukhin et al., 2020;Izacard and Grave, 2020b).\n\nGenerative Readers\n\nCompared to extractive models which extract existing words from the retrieved passages, generative models are able to produce new words out of the retrieved passages, and thus provide a more flexible modeling framework.  and Lewis et al. (2020a) concatenate the given question with top retrieved passages and feed the concatenation to the BART model (Lewis et al., 2019). Izacard and Grave (2020b) separately encodes the question with each top retrieved passage, then takes the concatenation of the encoder outputs as input to the decoder. Their method provide a way to better aggregate evidence from multiple passages and improve the performance significantly. FiD-KD (Izacard and Grave, 2020a) is an extension of FiD model that increases the accuracy of passage retrieval by training the dense retriever with the guidance of the FiD reader iteratively.\n\nPointer-Generator Network\n\nPointer-Generator Network (See et al., 2017) is an extension of the sequence-to-sequence model by integrating a copy mechanism (Vinyals et al., 2017) into the generator. At each decoding stage, the model is able to either directly copy a word from the input or generate one with certain probability, and thus can be viewed as a combination of extractive and generative approaches. It has been frequently used in natural language tasks like summarization (Gu et al., 2016;See et al.,  Gehrmann et al., 2018) and neural machine translation (Luong et al., 2014;Gu et al., 2017), but its application to ODQA has been less explored.\n\n References: \nAsai, A., Hashimoto, K., Hajishirzi, H., Socher, R., and Xiong, C. 1911. Learning to retrieve reasoning paths over wikipedia graph for question answering. In Learning to retrieve reasoning paths over wikipedia graph for question answering.\nChen, D., Fisch, A., Weston, J., and Bordes, A. 2017. Reading wikipedia to answer opendomain questions. In Reading wikipedia to answer opendomain questions. abs/1704.00051\nDevlin, J., Chang, M., Lee, K., and Toutanova, K. 2019. BERT: pre-training of deep bidirectional transformers for language understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019. pp. 4171--4186 10.18653/v1/n19-1423\nGehrmann, S., Deng, Y., and Rush, A. M. 2018. Bottom-up abstractive summarization. In Bottom-up abstractive summarization. abs/1808.10792\nGu, J., Bradbury, J., Xiong, C., Victor, O. K., Li, R., and Socher 2017. Non-autoregressive neural machine translation. In Non-autoregressive neural machine translation. abs/1711.02281\nGu, J., Lu, Z., Li, H., Victor, O. K., and Li 2016. Incorporating copying mechanism in sequenceto-sequence learning. In Incorporating copying mechanism in sequenceto-sequence learning. abs/1603.06393\nIzacard, G. and Grave, E. 2020. Distilling knowledge from reader to retriever for question answering. In Distilling knowledge from reader to retriever for question answering. abs/2012.04584\nIzacard, G. and Grave, E. 1282. Leveraging passage retrieval with generative models for open domain question answering. CoRR, abs. In Leveraging passage retrieval with generative models for open domain question answering. CoRR, abs.\nJoshi, M., Choi, E., Weld, D. S., and Zettlemoyer, L. 2017. Triviaqa: A large scale distantly supervised challenge dataset for reading comprehension. In Triviaqa: A large scale distantly supervised challenge dataset for reading comprehension. abs/1705.03551\nKarpukhin, V., Oguz, B., Min, S., Lewis, P., Wu, L., Edunov, S., Chen, D., and Yih, W. 2020. Dense passage retrieval for open-domain question answering. In Dense passage retrieval for open-domain question answering. arXiv:2004.04906\nKwiatkowski, T., Palomaki, J., Redfield, O., Collins, M., Parikh, A., Alberti, C., Epstein, D., Polosukhin, I., Devlin, J., Lee, K., Toutanova, K., Jones, L., Kelcey, M., Chang, M., Dai, A., Uszkoreit, J., Le, Q., and Petrov, S. 2019. Natural questions: a benchmark for question answering research. In Transactions of the Association for Computational Linguistics. pp. 452--466\nLewis, M., Liu, Y., Goyal, N., Ghazvininejad, M., Mohamed, A., Levy, O., Stoyanov, V., and Zettlemoyer, L. 2019.\n1910. BART: denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension. CoRR, abs. In BART: denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension. CoRR, abs.\nPatrick, S. H., Lewis, E., Perez, A., Piktus, F., Petroni, V., Karpukhin, N., Goyal, H., K\u00fcttler, M., Lewis, W., Yih, T., Rockt\u00e4schel, S., Riedel, D., and Kiela 2005. Retrieval-augmented generation for knowledge-intensive NLP tasks. In Retrieval-augmented generation for knowledge-intensive NLP tasks.\nPatrick, S. H., Lewis, P., Stenetorp, S., and Riedel 2008. Question and answer test-train overlap in open-domain question answering datasets. CoRR, abs. In Question and answer test-train overlap in open-domain question answering datasets. CoRR, abs.\nLoshchilov, I. and Hutter, F. 2017. Fixing weight decay regularization in adam. In Fixing weight decay regularization in adam. abs/1711.05101\nLuong, T., Sutskever, I., Le, Q. V., Vinyals, O., and Zaremba, W. 2014. Addressing the rare word problem in neural machine translation. In Addressing the rare word problem in neural machine translation.\nMaynez, J., Narayan, S., Bohnet, B., and Mcdonald, R. T. 0661. On faithfulness and factuality in abstractive summarization. CoRR, abs. In On faithfulness and factuality in abstractive summarization. CoRR, abs.\nMin, S., Boyd-Graber, J. L., Alberti, C., Chen, D., Choi, E., Collins, M., Guu, K., Hajishirzi, H., Lee, K., Palomaki, J., Raffel, C., Roberts, A., Kwiatkowski, T., Patrick, S. H., Lewis, Y., Wu, H., K\u00fcttler, L., Liu, P., Minervini, P., Stenetorp, S., Riedel, S., Yang, M., Seo, G., Izacard, F., Petroni, L., Hosseini, N. D., Cao, E., Grave, I., Yamada, S., Shimaoka, M., Suzuki, S., Miyawaki, S., Sato, R., Takahashi, J., Suzuki, M., Fajcik, M., and Docekal\nMin, S., Lee, K., Chang, M., Toutanova, K., and Hajishirzi, H. 2021. Joint passage ranking for diverse multi-answer retrieval. In Joint passage ranking for diverse multi-answer retrieval. abs/2104.08445\nMin, S., Michael, J., Hajishirzi, H., and Zettlemoyer, L. 2004. Ambigqa: Answering ambiguous open-domain questions. CoRR, abs. In Ambigqa: Answering ambiguous open-domain questions. CoRR, abs.\nRaffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M., Zhou, Y., Li, W., and Liu, P. J. 1910. Exploring the limits of transfer learning with a unified text-to-text transformer. In Exploring the limits of transfer learning with a unified text-to-text transformer.\nRajpurkar, P., Zhang, J., Lopyrev, K., and Liang, P. 2016. Squad: 100, 000+ questions for machine comprehension of text. In Squad: 100, 000+ questions for machine comprehension of text. abs/1606.05250\nRogers, A., Gardner, M., and Augenstein, I. 2021. QA dataset explosion: A taxonomy of NLP resources for question answering and reading comprehension. In QA dataset explosion: A taxonomy of NLP resources for question answering and reading comprehension. abs/2107.12708\nSee, A., Peter, J., Liu, C.D., and Manning 2017. Get to the point: Summarization with pointer-generator networks. In Get to the point: Summarization with pointer-generator networks. arXiv:1704.04368\nVinyals, O., Fortunato, M., and Jaitly, N. 2017.\nVoorhees, E. M. 1999. The TREC-8 question answering track report. In Proceedings of The Eighth Text REtrieval Conference. TREC 1999\nWu, Y., Minervini, P., Stenetorp, P., and Riedel, S. 2021. Training adaptive computation for open-domain question answering with computational constraints. In Training adaptive computation for open-domain question answering with computational constraints. abs/2107.02102\nYamada, I., Asai, A., and Hajishirzi, H. 2021. Efficient passage retrieval with hashing for open-domain question answering. In Efficient passage retrieval with hashing for open-domain question answering. abs/2106.00882\nYang, W., Xie, Y., Lin, A., Li, X., Tan, L., Xiong, K., Li, M., and Lin, J. 1718. End-to-end open-domain question answering with bertserini. CoRR, abs. In End-to-end open-domain question answering with bertserini. CoRR, abs.\nZhou, C., Neubig, G., Gu, J., Diab, M., Guzm\u00e1n, F., Zettlemoyer, L., and Ghazvininejad, M. 2021. Detecting hallucinated content in conditional neural sequence generation. In Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021. pp. 1393--1404 10.18653/v1/2021.findings-acl.120"
    },
    {
        "filename": "paper_7.txt",
        "start": 1003,
        "end": 1857,
        "label": "Lacks Synthesis",
        "text": "Compared to extractive models which extract existing words from the retrieved passages, generative models are able to produce new words out of the retrieved passages, and thus provide a more flexible modeling framework.  and Lewis et al. (2020a) concatenate the given question with top retrieved passages and feed the concatenation to the BART model (Lewis et al., 2019). Izacard and Grave (2020b) separately encodes the question with each top retrieved passage, then takes the concatenation of the encoder outputs as input to the decoder. Their method provide a way to better aggregate evidence from multiple passages and improve the performance significantly. FiD-KD (Izacard and Grave, 2020a) is an extension of FiD model that increases the accuracy of passage retrieval by training the dense retriever with the guidance of the FiD reader iteratively.",
        "full_text": "Related Work\n\nOpen-Domain Question Answering\n\nIn this era of data explosion, ODQA offers a way to rapidly and accurately fulfill user's information needs, and hence has recently received significant attention from both industry and academia (Min et al., 2021a). Following the work of DrQA (Chen et al., 2017), most recent works build a two-stage retriever-reader system to tackle the problem. The retriever aims at retrieving supportive passages to the given question from a large document corpus. The reader intends to find answer of the question from the first stage retrieved passages. Early work of Chen et al. (2017) adapts a BiLSTM architecture with various lexical and semantic features from the question and passages as inputs. Later, with the emergence of large-scale pre-trained language models, readers based on pre-trained models such as BERT and T5 Raffel et al., 2019) have become a common approach (Yang et al., 2019;Karpukhin et al., 2020;Izacard and Grave, 2020b).\n\nGenerative Readers\n\nCompared to extractive models which extract existing words from the retrieved passages, generative models are able to produce new words out of the retrieved passages, and thus provide a more flexible modeling framework.  and Lewis et al. (2020a) concatenate the given question with top retrieved passages and feed the concatenation to the BART model (Lewis et al., 2019). Izacard and Grave (2020b) separately encodes the question with each top retrieved passage, then takes the concatenation of the encoder outputs as input to the decoder. Their method provide a way to better aggregate evidence from multiple passages and improve the performance significantly. FiD-KD (Izacard and Grave, 2020a) is an extension of FiD model that increases the accuracy of passage retrieval by training the dense retriever with the guidance of the FiD reader iteratively.\n\nPointer-Generator Network\n\nPointer-Generator Network (See et al., 2017) is an extension of the sequence-to-sequence model by integrating a copy mechanism (Vinyals et al., 2017) into the generator. At each decoding stage, the model is able to either directly copy a word from the input or generate one with certain probability, and thus can be viewed as a combination of extractive and generative approaches. It has been frequently used in natural language tasks like summarization (Gu et al., 2016;See et al.,  Gehrmann et al., 2018) and neural machine translation (Luong et al., 2014;Gu et al., 2017), but its application to ODQA has been less explored.\n\n References: \nAsai, A., Hashimoto, K., Hajishirzi, H., Socher, R., and Xiong, C. 1911. Learning to retrieve reasoning paths over wikipedia graph for question answering. In Learning to retrieve reasoning paths over wikipedia graph for question answering.\nChen, D., Fisch, A., Weston, J., and Bordes, A. 2017. Reading wikipedia to answer opendomain questions. In Reading wikipedia to answer opendomain questions. abs/1704.00051\nDevlin, J., Chang, M., Lee, K., and Toutanova, K. 2019. BERT: pre-training of deep bidirectional transformers for language understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019. pp. 4171--4186 10.18653/v1/n19-1423\nGehrmann, S., Deng, Y., and Rush, A. M. 2018. Bottom-up abstractive summarization. In Bottom-up abstractive summarization. abs/1808.10792\nGu, J., Bradbury, J., Xiong, C., Victor, O. K., Li, R., and Socher 2017. Non-autoregressive neural machine translation. In Non-autoregressive neural machine translation. abs/1711.02281\nGu, J., Lu, Z., Li, H., Victor, O. K., and Li 2016. Incorporating copying mechanism in sequenceto-sequence learning. In Incorporating copying mechanism in sequenceto-sequence learning. abs/1603.06393\nIzacard, G. and Grave, E. 2020. Distilling knowledge from reader to retriever for question answering. In Distilling knowledge from reader to retriever for question answering. abs/2012.04584\nIzacard, G. and Grave, E. 1282. Leveraging passage retrieval with generative models for open domain question answering. CoRR, abs. In Leveraging passage retrieval with generative models for open domain question answering. CoRR, abs.\nJoshi, M., Choi, E., Weld, D. S., and Zettlemoyer, L. 2017. Triviaqa: A large scale distantly supervised challenge dataset for reading comprehension. In Triviaqa: A large scale distantly supervised challenge dataset for reading comprehension. abs/1705.03551\nKarpukhin, V., Oguz, B., Min, S., Lewis, P., Wu, L., Edunov, S., Chen, D., and Yih, W. 2020. Dense passage retrieval for open-domain question answering. In Dense passage retrieval for open-domain question answering. arXiv:2004.04906\nKwiatkowski, T., Palomaki, J., Redfield, O., Collins, M., Parikh, A., Alberti, C., Epstein, D., Polosukhin, I., Devlin, J., Lee, K., Toutanova, K., Jones, L., Kelcey, M., Chang, M., Dai, A., Uszkoreit, J., Le, Q., and Petrov, S. 2019. Natural questions: a benchmark for question answering research. In Transactions of the Association for Computational Linguistics. pp. 452--466\nLewis, M., Liu, Y., Goyal, N., Ghazvininejad, M., Mohamed, A., Levy, O., Stoyanov, V., and Zettlemoyer, L. 2019.\n1910. BART: denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension. CoRR, abs. In BART: denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension. CoRR, abs.\nPatrick, S. H., Lewis, E., Perez, A., Piktus, F., Petroni, V., Karpukhin, N., Goyal, H., K\u00fcttler, M., Lewis, W., Yih, T., Rockt\u00e4schel, S., Riedel, D., and Kiela 2005. Retrieval-augmented generation for knowledge-intensive NLP tasks. In Retrieval-augmented generation for knowledge-intensive NLP tasks.\nPatrick, S. H., Lewis, P., Stenetorp, S., and Riedel 2008. Question and answer test-train overlap in open-domain question answering datasets. CoRR, abs. In Question and answer test-train overlap in open-domain question answering datasets. CoRR, abs.\nLoshchilov, I. and Hutter, F. 2017. Fixing weight decay regularization in adam. In Fixing weight decay regularization in adam. abs/1711.05101\nLuong, T., Sutskever, I., Le, Q. V., Vinyals, O., and Zaremba, W. 2014. Addressing the rare word problem in neural machine translation. In Addressing the rare word problem in neural machine translation.\nMaynez, J., Narayan, S., Bohnet, B., and Mcdonald, R. T. 0661. On faithfulness and factuality in abstractive summarization. CoRR, abs. In On faithfulness and factuality in abstractive summarization. CoRR, abs.\nMin, S., Boyd-Graber, J. L., Alberti, C., Chen, D., Choi, E., Collins, M., Guu, K., Hajishirzi, H., Lee, K., Palomaki, J., Raffel, C., Roberts, A., Kwiatkowski, T., Patrick, S. H., Lewis, Y., Wu, H., K\u00fcttler, L., Liu, P., Minervini, P., Stenetorp, S., Riedel, S., Yang, M., Seo, G., Izacard, F., Petroni, L., Hosseini, N. D., Cao, E., Grave, I., Yamada, S., Shimaoka, M., Suzuki, S., Miyawaki, S., Sato, R., Takahashi, J., Suzuki, M., Fajcik, M., and Docekal\nMin, S., Lee, K., Chang, M., Toutanova, K., and Hajishirzi, H. 2021. Joint passage ranking for diverse multi-answer retrieval. In Joint passage ranking for diverse multi-answer retrieval. abs/2104.08445\nMin, S., Michael, J., Hajishirzi, H., and Zettlemoyer, L. 2004. Ambigqa: Answering ambiguous open-domain questions. CoRR, abs. In Ambigqa: Answering ambiguous open-domain questions. CoRR, abs.\nRaffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M., Zhou, Y., Li, W., and Liu, P. J. 1910. Exploring the limits of transfer learning with a unified text-to-text transformer. In Exploring the limits of transfer learning with a unified text-to-text transformer.\nRajpurkar, P., Zhang, J., Lopyrev, K., and Liang, P. 2016. Squad: 100, 000+ questions for machine comprehension of text. In Squad: 100, 000+ questions for machine comprehension of text. abs/1606.05250\nRogers, A., Gardner, M., and Augenstein, I. 2021. QA dataset explosion: A taxonomy of NLP resources for question answering and reading comprehension. In QA dataset explosion: A taxonomy of NLP resources for question answering and reading comprehension. abs/2107.12708\nSee, A., Peter, J., Liu, C.D., and Manning 2017. Get to the point: Summarization with pointer-generator networks. In Get to the point: Summarization with pointer-generator networks. arXiv:1704.04368\nVinyals, O., Fortunato, M., and Jaitly, N. 2017.\nVoorhees, E. M. 1999. The TREC-8 question answering track report. In Proceedings of The Eighth Text REtrieval Conference. TREC 1999\nWu, Y., Minervini, P., Stenetorp, P., and Riedel, S. 2021. Training adaptive computation for open-domain question answering with computational constraints. In Training adaptive computation for open-domain question answering with computational constraints. abs/2107.02102\nYamada, I., Asai, A., and Hajishirzi, H. 2021. Efficient passage retrieval with hashing for open-domain question answering. In Efficient passage retrieval with hashing for open-domain question answering. abs/2106.00882\nYang, W., Xie, Y., Lin, A., Li, X., Tan, L., Xiong, K., Li, M., and Lin, J. 1718. End-to-end open-domain question answering with bertserini. CoRR, abs. In End-to-end open-domain question answering with bertserini. CoRR, abs.\nZhou, C., Neubig, G., Gu, J., Diab, M., Guzm\u00e1n, F., Zettlemoyer, L., and Ghazvininejad, M. 2021. Detecting hallucinated content in conditional neural sequence generation. In Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021. pp. 1393--1404 10.18653/v1/2021.findings-acl.120"
    },
    {
        "filename": "paper_7.txt",
        "start": 1886,
        "end": 2513,
        "label": "Lacks Synthesis",
        "text": "Pointer-Generator Network (See et al., 2017) is an extension of the sequence-to-sequence model by integrating a copy mechanism (Vinyals et al., 2017) into the generator. At each decoding stage, the model is able to either directly copy a word from the input or generate one with certain probability, and thus can be viewed as a combination of extractive and generative approaches. It has been frequently used in natural language tasks like summarization (Gu et al., 2016;See et al.,  Gehrmann et al., 2018) and neural machine translation (Luong et al., 2014;Gu et al., 2017), but its application to ODQA has been less explored.",
        "full_text": "Related Work\n\nOpen-Domain Question Answering\n\nIn this era of data explosion, ODQA offers a way to rapidly and accurately fulfill user's information needs, and hence has recently received significant attention from both industry and academia (Min et al., 2021a). Following the work of DrQA (Chen et al., 2017), most recent works build a two-stage retriever-reader system to tackle the problem. The retriever aims at retrieving supportive passages to the given question from a large document corpus. The reader intends to find answer of the question from the first stage retrieved passages. Early work of Chen et al. (2017) adapts a BiLSTM architecture with various lexical and semantic features from the question and passages as inputs. Later, with the emergence of large-scale pre-trained language models, readers based on pre-trained models such as BERT and T5 Raffel et al., 2019) have become a common approach (Yang et al., 2019;Karpukhin et al., 2020;Izacard and Grave, 2020b).\n\nGenerative Readers\n\nCompared to extractive models which extract existing words from the retrieved passages, generative models are able to produce new words out of the retrieved passages, and thus provide a more flexible modeling framework.  and Lewis et al. (2020a) concatenate the given question with top retrieved passages and feed the concatenation to the BART model (Lewis et al., 2019). Izacard and Grave (2020b) separately encodes the question with each top retrieved passage, then takes the concatenation of the encoder outputs as input to the decoder. Their method provide a way to better aggregate evidence from multiple passages and improve the performance significantly. FiD-KD (Izacard and Grave, 2020a) is an extension of FiD model that increases the accuracy of passage retrieval by training the dense retriever with the guidance of the FiD reader iteratively.\n\nPointer-Generator Network\n\nPointer-Generator Network (See et al., 2017) is an extension of the sequence-to-sequence model by integrating a copy mechanism (Vinyals et al., 2017) into the generator. At each decoding stage, the model is able to either directly copy a word from the input or generate one with certain probability, and thus can be viewed as a combination of extractive and generative approaches. It has been frequently used in natural language tasks like summarization (Gu et al., 2016;See et al.,  Gehrmann et al., 2018) and neural machine translation (Luong et al., 2014;Gu et al., 2017), but its application to ODQA has been less explored.\n\n References: \nAsai, A., Hashimoto, K., Hajishirzi, H., Socher, R., and Xiong, C. 1911. Learning to retrieve reasoning paths over wikipedia graph for question answering. In Learning to retrieve reasoning paths over wikipedia graph for question answering.\nChen, D., Fisch, A., Weston, J., and Bordes, A. 2017. Reading wikipedia to answer opendomain questions. In Reading wikipedia to answer opendomain questions. abs/1704.00051\nDevlin, J., Chang, M., Lee, K., and Toutanova, K. 2019. BERT: pre-training of deep bidirectional transformers for language understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019. pp. 4171--4186 10.18653/v1/n19-1423\nGehrmann, S., Deng, Y., and Rush, A. M. 2018. Bottom-up abstractive summarization. In Bottom-up abstractive summarization. abs/1808.10792\nGu, J., Bradbury, J., Xiong, C., Victor, O. K., Li, R., and Socher 2017. Non-autoregressive neural machine translation. In Non-autoregressive neural machine translation. abs/1711.02281\nGu, J., Lu, Z., Li, H., Victor, O. K., and Li 2016. Incorporating copying mechanism in sequenceto-sequence learning. In Incorporating copying mechanism in sequenceto-sequence learning. abs/1603.06393\nIzacard, G. and Grave, E. 2020. Distilling knowledge from reader to retriever for question answering. In Distilling knowledge from reader to retriever for question answering. abs/2012.04584\nIzacard, G. and Grave, E. 1282. Leveraging passage retrieval with generative models for open domain question answering. CoRR, abs. In Leveraging passage retrieval with generative models for open domain question answering. CoRR, abs.\nJoshi, M., Choi, E., Weld, D. S., and Zettlemoyer, L. 2017. Triviaqa: A large scale distantly supervised challenge dataset for reading comprehension. In Triviaqa: A large scale distantly supervised challenge dataset for reading comprehension. abs/1705.03551\nKarpukhin, V., Oguz, B., Min, S., Lewis, P., Wu, L., Edunov, S., Chen, D., and Yih, W. 2020. Dense passage retrieval for open-domain question answering. In Dense passage retrieval for open-domain question answering. arXiv:2004.04906\nKwiatkowski, T., Palomaki, J., Redfield, O., Collins, M., Parikh, A., Alberti, C., Epstein, D., Polosukhin, I., Devlin, J., Lee, K., Toutanova, K., Jones, L., Kelcey, M., Chang, M., Dai, A., Uszkoreit, J., Le, Q., and Petrov, S. 2019. Natural questions: a benchmark for question answering research. In Transactions of the Association for Computational Linguistics. pp. 452--466\nLewis, M., Liu, Y., Goyal, N., Ghazvininejad, M., Mohamed, A., Levy, O., Stoyanov, V., and Zettlemoyer, L. 2019.\n1910. BART: denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension. CoRR, abs. In BART: denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension. CoRR, abs.\nPatrick, S. H., Lewis, E., Perez, A., Piktus, F., Petroni, V., Karpukhin, N., Goyal, H., K\u00fcttler, M., Lewis, W., Yih, T., Rockt\u00e4schel, S., Riedel, D., and Kiela 2005. Retrieval-augmented generation for knowledge-intensive NLP tasks. In Retrieval-augmented generation for knowledge-intensive NLP tasks.\nPatrick, S. H., Lewis, P., Stenetorp, S., and Riedel 2008. Question and answer test-train overlap in open-domain question answering datasets. CoRR, abs. In Question and answer test-train overlap in open-domain question answering datasets. CoRR, abs.\nLoshchilov, I. and Hutter, F. 2017. Fixing weight decay regularization in adam. In Fixing weight decay regularization in adam. abs/1711.05101\nLuong, T., Sutskever, I., Le, Q. V., Vinyals, O., and Zaremba, W. 2014. Addressing the rare word problem in neural machine translation. In Addressing the rare word problem in neural machine translation.\nMaynez, J., Narayan, S., Bohnet, B., and Mcdonald, R. T. 0661. On faithfulness and factuality in abstractive summarization. CoRR, abs. In On faithfulness and factuality in abstractive summarization. CoRR, abs.\nMin, S., Boyd-Graber, J. L., Alberti, C., Chen, D., Choi, E., Collins, M., Guu, K., Hajishirzi, H., Lee, K., Palomaki, J., Raffel, C., Roberts, A., Kwiatkowski, T., Patrick, S. H., Lewis, Y., Wu, H., K\u00fcttler, L., Liu, P., Minervini, P., Stenetorp, S., Riedel, S., Yang, M., Seo, G., Izacard, F., Petroni, L., Hosseini, N. D., Cao, E., Grave, I., Yamada, S., Shimaoka, M., Suzuki, S., Miyawaki, S., Sato, R., Takahashi, J., Suzuki, M., Fajcik, M., and Docekal\nMin, S., Lee, K., Chang, M., Toutanova, K., and Hajishirzi, H. 2021. Joint passage ranking for diverse multi-answer retrieval. In Joint passage ranking for diverse multi-answer retrieval. abs/2104.08445\nMin, S., Michael, J., Hajishirzi, H., and Zettlemoyer, L. 2004. Ambigqa: Answering ambiguous open-domain questions. CoRR, abs. In Ambigqa: Answering ambiguous open-domain questions. CoRR, abs.\nRaffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M., Zhou, Y., Li, W., and Liu, P. J. 1910. Exploring the limits of transfer learning with a unified text-to-text transformer. In Exploring the limits of transfer learning with a unified text-to-text transformer.\nRajpurkar, P., Zhang, J., Lopyrev, K., and Liang, P. 2016. Squad: 100, 000+ questions for machine comprehension of text. In Squad: 100, 000+ questions for machine comprehension of text. abs/1606.05250\nRogers, A., Gardner, M., and Augenstein, I. 2021. QA dataset explosion: A taxonomy of NLP resources for question answering and reading comprehension. In QA dataset explosion: A taxonomy of NLP resources for question answering and reading comprehension. abs/2107.12708\nSee, A., Peter, J., Liu, C.D., and Manning 2017. Get to the point: Summarization with pointer-generator networks. In Get to the point: Summarization with pointer-generator networks. arXiv:1704.04368\nVinyals, O., Fortunato, M., and Jaitly, N. 2017.\nVoorhees, E. M. 1999. The TREC-8 question answering track report. In Proceedings of The Eighth Text REtrieval Conference. TREC 1999\nWu, Y., Minervini, P., Stenetorp, P., and Riedel, S. 2021. Training adaptive computation for open-domain question answering with computational constraints. In Training adaptive computation for open-domain question answering with computational constraints. abs/2107.02102\nYamada, I., Asai, A., and Hajishirzi, H. 2021. Efficient passage retrieval with hashing for open-domain question answering. In Efficient passage retrieval with hashing for open-domain question answering. abs/2106.00882\nYang, W., Xie, Y., Lin, A., Li, X., Tan, L., Xiong, K., Li, M., and Lin, J. 1718. End-to-end open-domain question answering with bertserini. CoRR, abs. In End-to-end open-domain question answering with bertserini. CoRR, abs.\nZhou, C., Neubig, G., Gu, J., Diab, M., Guzm\u00e1n, F., Zettlemoyer, L., and Ghazvininejad, M. 2021. Detecting hallucinated content in conditional neural sequence generation. In Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021. pp. 1393--1404 10.18653/v1/2021.findings-acl.120"
    },
    {
        "filename": "paper_7.txt",
        "start": 310,
        "end": 327,
        "label": "Unsupported Claim",
        "text": "most recent works",
        "full_text": "Related Work\n\nOpen-Domain Question Answering\n\nIn this era of data explosion, ODQA offers a way to rapidly and accurately fulfill user's information needs, and hence has recently received significant attention from both industry and academia (Min et al., 2021a). Following the work of DrQA (Chen et al., 2017), most recent works build a two-stage retriever-reader system to tackle the problem. The retriever aims at retrieving supportive passages to the given question from a large document corpus. The reader intends to find answer of the question from the first stage retrieved passages. Early work of Chen et al. (2017) adapts a BiLSTM architecture with various lexical and semantic features from the question and passages as inputs. Later, with the emergence of large-scale pre-trained language models, readers based on pre-trained models such as BERT and T5 Raffel et al., 2019) have become a common approach (Yang et al., 2019;Karpukhin et al., 2020;Izacard and Grave, 2020b).\n\nGenerative Readers\n\nCompared to extractive models which extract existing words from the retrieved passages, generative models are able to produce new words out of the retrieved passages, and thus provide a more flexible modeling framework.  and Lewis et al. (2020a) concatenate the given question with top retrieved passages and feed the concatenation to the BART model (Lewis et al., 2019). Izacard and Grave (2020b) separately encodes the question with each top retrieved passage, then takes the concatenation of the encoder outputs as input to the decoder. Their method provide a way to better aggregate evidence from multiple passages and improve the performance significantly. FiD-KD (Izacard and Grave, 2020a) is an extension of FiD model that increases the accuracy of passage retrieval by training the dense retriever with the guidance of the FiD reader iteratively.\n\nPointer-Generator Network\n\nPointer-Generator Network (See et al., 2017) is an extension of the sequence-to-sequence model by integrating a copy mechanism (Vinyals et al., 2017) into the generator. At each decoding stage, the model is able to either directly copy a word from the input or generate one with certain probability, and thus can be viewed as a combination of extractive and generative approaches. It has been frequently used in natural language tasks like summarization (Gu et al., 2016;See et al.,  Gehrmann et al., 2018) and neural machine translation (Luong et al., 2014;Gu et al., 2017), but its application to ODQA has been less explored.\n\n References: \nAsai, A., Hashimoto, K., Hajishirzi, H., Socher, R., and Xiong, C. 1911. Learning to retrieve reasoning paths over wikipedia graph for question answering. In Learning to retrieve reasoning paths over wikipedia graph for question answering.\nChen, D., Fisch, A., Weston, J., and Bordes, A. 2017. Reading wikipedia to answer opendomain questions. In Reading wikipedia to answer opendomain questions. abs/1704.00051\nDevlin, J., Chang, M., Lee, K., and Toutanova, K. 2019. BERT: pre-training of deep bidirectional transformers for language understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019. pp. 4171--4186 10.18653/v1/n19-1423\nGehrmann, S., Deng, Y., and Rush, A. M. 2018. Bottom-up abstractive summarization. In Bottom-up abstractive summarization. abs/1808.10792\nGu, J., Bradbury, J., Xiong, C., Victor, O. K., Li, R., and Socher 2017. Non-autoregressive neural machine translation. In Non-autoregressive neural machine translation. abs/1711.02281\nGu, J., Lu, Z., Li, H., Victor, O. K., and Li 2016. Incorporating copying mechanism in sequenceto-sequence learning. In Incorporating copying mechanism in sequenceto-sequence learning. abs/1603.06393\nIzacard, G. and Grave, E. 2020. Distilling knowledge from reader to retriever for question answering. In Distilling knowledge from reader to retriever for question answering. abs/2012.04584\nIzacard, G. and Grave, E. 1282. Leveraging passage retrieval with generative models for open domain question answering. CoRR, abs. In Leveraging passage retrieval with generative models for open domain question answering. CoRR, abs.\nJoshi, M., Choi, E., Weld, D. S., and Zettlemoyer, L. 2017. Triviaqa: A large scale distantly supervised challenge dataset for reading comprehension. In Triviaqa: A large scale distantly supervised challenge dataset for reading comprehension. abs/1705.03551\nKarpukhin, V., Oguz, B., Min, S., Lewis, P., Wu, L., Edunov, S., Chen, D., and Yih, W. 2020. Dense passage retrieval for open-domain question answering. In Dense passage retrieval for open-domain question answering. arXiv:2004.04906\nKwiatkowski, T., Palomaki, J., Redfield, O., Collins, M., Parikh, A., Alberti, C., Epstein, D., Polosukhin, I., Devlin, J., Lee, K., Toutanova, K., Jones, L., Kelcey, M., Chang, M., Dai, A., Uszkoreit, J., Le, Q., and Petrov, S. 2019. Natural questions: a benchmark for question answering research. In Transactions of the Association for Computational Linguistics. pp. 452--466\nLewis, M., Liu, Y., Goyal, N., Ghazvininejad, M., Mohamed, A., Levy, O., Stoyanov, V., and Zettlemoyer, L. 2019.\n1910. BART: denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension. CoRR, abs. In BART: denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension. CoRR, abs.\nPatrick, S. H., Lewis, E., Perez, A., Piktus, F., Petroni, V., Karpukhin, N., Goyal, H., K\u00fcttler, M., Lewis, W., Yih, T., Rockt\u00e4schel, S., Riedel, D., and Kiela 2005. Retrieval-augmented generation for knowledge-intensive NLP tasks. In Retrieval-augmented generation for knowledge-intensive NLP tasks.\nPatrick, S. H., Lewis, P., Stenetorp, S., and Riedel 2008. Question and answer test-train overlap in open-domain question answering datasets. CoRR, abs. In Question and answer test-train overlap in open-domain question answering datasets. CoRR, abs.\nLoshchilov, I. and Hutter, F. 2017. Fixing weight decay regularization in adam. In Fixing weight decay regularization in adam. abs/1711.05101\nLuong, T., Sutskever, I., Le, Q. V., Vinyals, O., and Zaremba, W. 2014. Addressing the rare word problem in neural machine translation. In Addressing the rare word problem in neural machine translation.\nMaynez, J., Narayan, S., Bohnet, B., and Mcdonald, R. T. 0661. On faithfulness and factuality in abstractive summarization. CoRR, abs. In On faithfulness and factuality in abstractive summarization. CoRR, abs.\nMin, S., Boyd-Graber, J. L., Alberti, C., Chen, D., Choi, E., Collins, M., Guu, K., Hajishirzi, H., Lee, K., Palomaki, J., Raffel, C., Roberts, A., Kwiatkowski, T., Patrick, S. H., Lewis, Y., Wu, H., K\u00fcttler, L., Liu, P., Minervini, P., Stenetorp, S., Riedel, S., Yang, M., Seo, G., Izacard, F., Petroni, L., Hosseini, N. D., Cao, E., Grave, I., Yamada, S., Shimaoka, M., Suzuki, S., Miyawaki, S., Sato, R., Takahashi, J., Suzuki, M., Fajcik, M., and Docekal\nMin, S., Lee, K., Chang, M., Toutanova, K., and Hajishirzi, H. 2021. Joint passage ranking for diverse multi-answer retrieval. In Joint passage ranking for diverse multi-answer retrieval. abs/2104.08445\nMin, S., Michael, J., Hajishirzi, H., and Zettlemoyer, L. 2004. Ambigqa: Answering ambiguous open-domain questions. CoRR, abs. In Ambigqa: Answering ambiguous open-domain questions. CoRR, abs.\nRaffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M., Zhou, Y., Li, W., and Liu, P. J. 1910. Exploring the limits of transfer learning with a unified text-to-text transformer. In Exploring the limits of transfer learning with a unified text-to-text transformer.\nRajpurkar, P., Zhang, J., Lopyrev, K., and Liang, P. 2016. Squad: 100, 000+ questions for machine comprehension of text. In Squad: 100, 000+ questions for machine comprehension of text. abs/1606.05250\nRogers, A., Gardner, M., and Augenstein, I. 2021. QA dataset explosion: A taxonomy of NLP resources for question answering and reading comprehension. In QA dataset explosion: A taxonomy of NLP resources for question answering and reading comprehension. abs/2107.12708\nSee, A., Peter, J., Liu, C.D., and Manning 2017. Get to the point: Summarization with pointer-generator networks. In Get to the point: Summarization with pointer-generator networks. arXiv:1704.04368\nVinyals, O., Fortunato, M., and Jaitly, N. 2017.\nVoorhees, E. M. 1999. The TREC-8 question answering track report. In Proceedings of The Eighth Text REtrieval Conference. TREC 1999\nWu, Y., Minervini, P., Stenetorp, P., and Riedel, S. 2021. Training adaptive computation for open-domain question answering with computational constraints. In Training adaptive computation for open-domain question answering with computational constraints. abs/2107.02102\nYamada, I., Asai, A., and Hajishirzi, H. 2021. Efficient passage retrieval with hashing for open-domain question answering. In Efficient passage retrieval with hashing for open-domain question answering. abs/2106.00882\nYang, W., Xie, Y., Lin, A., Li, X., Tan, L., Xiong, K., Li, M., and Lin, J. 1718. End-to-end open-domain question answering with bertserini. CoRR, abs. In End-to-end open-domain question answering with bertserini. CoRR, abs.\nZhou, C., Neubig, G., Gu, J., Diab, M., Guzm\u00e1n, F., Zettlemoyer, L., and Ghazvininejad, M. 2021. Detecting hallucinated content in conditional neural sequence generation. In Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021. pp. 1393--1404 10.18653/v1/2021.findings-acl.120"
    },
    {
        "filename": "paper_7.txt",
        "start": 1090,
        "end": 1108,
        "label": "Unsupported Claim",
        "text": "generative models",
        "full_text": "Related Work\n\nOpen-Domain Question Answering\n\nIn this era of data explosion, ODQA offers a way to rapidly and accurately fulfill user's information needs, and hence has recently received significant attention from both industry and academia (Min et al., 2021a). Following the work of DrQA (Chen et al., 2017), most recent works build a two-stage retriever-reader system to tackle the problem. The retriever aims at retrieving supportive passages to the given question from a large document corpus. The reader intends to find answer of the question from the first stage retrieved passages. Early work of Chen et al. (2017) adapts a BiLSTM architecture with various lexical and semantic features from the question and passages as inputs. Later, with the emergence of large-scale pre-trained language models, readers based on pre-trained models such as BERT and T5 Raffel et al., 2019) have become a common approach (Yang et al., 2019;Karpukhin et al., 2020;Izacard and Grave, 2020b).\n\nGenerative Readers\n\nCompared to extractive models which extract existing words from the retrieved passages, generative models are able to produce new words out of the retrieved passages, and thus provide a more flexible modeling framework.  and Lewis et al. (2020a) concatenate the given question with top retrieved passages and feed the concatenation to the BART model (Lewis et al., 2019). Izacard and Grave (2020b) separately encodes the question with each top retrieved passage, then takes the concatenation of the encoder outputs as input to the decoder. Their method provide a way to better aggregate evidence from multiple passages and improve the performance significantly. FiD-KD (Izacard and Grave, 2020a) is an extension of FiD model that increases the accuracy of passage retrieval by training the dense retriever with the guidance of the FiD reader iteratively.\n\nPointer-Generator Network\n\nPointer-Generator Network (See et al., 2017) is an extension of the sequence-to-sequence model by integrating a copy mechanism (Vinyals et al., 2017) into the generator. At each decoding stage, the model is able to either directly copy a word from the input or generate one with certain probability, and thus can be viewed as a combination of extractive and generative approaches. It has been frequently used in natural language tasks like summarization (Gu et al., 2016;See et al.,  Gehrmann et al., 2018) and neural machine translation (Luong et al., 2014;Gu et al., 2017), but its application to ODQA has been less explored.\n\n References: \nAsai, A., Hashimoto, K., Hajishirzi, H., Socher, R., and Xiong, C. 1911. Learning to retrieve reasoning paths over wikipedia graph for question answering. In Learning to retrieve reasoning paths over wikipedia graph for question answering.\nChen, D., Fisch, A., Weston, J., and Bordes, A. 2017. Reading wikipedia to answer opendomain questions. In Reading wikipedia to answer opendomain questions. abs/1704.00051\nDevlin, J., Chang, M., Lee, K., and Toutanova, K. 2019. BERT: pre-training of deep bidirectional transformers for language understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019. pp. 4171--4186 10.18653/v1/n19-1423\nGehrmann, S., Deng, Y., and Rush, A. M. 2018. Bottom-up abstractive summarization. In Bottom-up abstractive summarization. abs/1808.10792\nGu, J., Bradbury, J., Xiong, C., Victor, O. K., Li, R., and Socher 2017. Non-autoregressive neural machine translation. In Non-autoregressive neural machine translation. abs/1711.02281\nGu, J., Lu, Z., Li, H., Victor, O. K., and Li 2016. Incorporating copying mechanism in sequenceto-sequence learning. In Incorporating copying mechanism in sequenceto-sequence learning. abs/1603.06393\nIzacard, G. and Grave, E. 2020. Distilling knowledge from reader to retriever for question answering. In Distilling knowledge from reader to retriever for question answering. abs/2012.04584\nIzacard, G. and Grave, E. 1282. Leveraging passage retrieval with generative models for open domain question answering. CoRR, abs. In Leveraging passage retrieval with generative models for open domain question answering. CoRR, abs.\nJoshi, M., Choi, E., Weld, D. S., and Zettlemoyer, L. 2017. Triviaqa: A large scale distantly supervised challenge dataset for reading comprehension. In Triviaqa: A large scale distantly supervised challenge dataset for reading comprehension. abs/1705.03551\nKarpukhin, V., Oguz, B., Min, S., Lewis, P., Wu, L., Edunov, S., Chen, D., and Yih, W. 2020. Dense passage retrieval for open-domain question answering. In Dense passage retrieval for open-domain question answering. arXiv:2004.04906\nKwiatkowski, T., Palomaki, J., Redfield, O., Collins, M., Parikh, A., Alberti, C., Epstein, D., Polosukhin, I., Devlin, J., Lee, K., Toutanova, K., Jones, L., Kelcey, M., Chang, M., Dai, A., Uszkoreit, J., Le, Q., and Petrov, S. 2019. Natural questions: a benchmark for question answering research. In Transactions of the Association for Computational Linguistics. pp. 452--466\nLewis, M., Liu, Y., Goyal, N., Ghazvininejad, M., Mohamed, A., Levy, O., Stoyanov, V., and Zettlemoyer, L. 2019.\n1910. BART: denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension. CoRR, abs. In BART: denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension. CoRR, abs.\nPatrick, S. H., Lewis, E., Perez, A., Piktus, F., Petroni, V., Karpukhin, N., Goyal, H., K\u00fcttler, M., Lewis, W., Yih, T., Rockt\u00e4schel, S., Riedel, D., and Kiela 2005. Retrieval-augmented generation for knowledge-intensive NLP tasks. In Retrieval-augmented generation for knowledge-intensive NLP tasks.\nPatrick, S. H., Lewis, P., Stenetorp, S., and Riedel 2008. Question and answer test-train overlap in open-domain question answering datasets. CoRR, abs. In Question and answer test-train overlap in open-domain question answering datasets. CoRR, abs.\nLoshchilov, I. and Hutter, F. 2017. Fixing weight decay regularization in adam. In Fixing weight decay regularization in adam. abs/1711.05101\nLuong, T., Sutskever, I., Le, Q. V., Vinyals, O., and Zaremba, W. 2014. Addressing the rare word problem in neural machine translation. In Addressing the rare word problem in neural machine translation.\nMaynez, J., Narayan, S., Bohnet, B., and Mcdonald, R. T. 0661. On faithfulness and factuality in abstractive summarization. CoRR, abs. In On faithfulness and factuality in abstractive summarization. CoRR, abs.\nMin, S., Boyd-Graber, J. L., Alberti, C., Chen, D., Choi, E., Collins, M., Guu, K., Hajishirzi, H., Lee, K., Palomaki, J., Raffel, C., Roberts, A., Kwiatkowski, T., Patrick, S. H., Lewis, Y., Wu, H., K\u00fcttler, L., Liu, P., Minervini, P., Stenetorp, S., Riedel, S., Yang, M., Seo, G., Izacard, F., Petroni, L., Hosseini, N. D., Cao, E., Grave, I., Yamada, S., Shimaoka, M., Suzuki, S., Miyawaki, S., Sato, R., Takahashi, J., Suzuki, M., Fajcik, M., and Docekal\nMin, S., Lee, K., Chang, M., Toutanova, K., and Hajishirzi, H. 2021. Joint passage ranking for diverse multi-answer retrieval. In Joint passage ranking for diverse multi-answer retrieval. abs/2104.08445\nMin, S., Michael, J., Hajishirzi, H., and Zettlemoyer, L. 2004. Ambigqa: Answering ambiguous open-domain questions. CoRR, abs. In Ambigqa: Answering ambiguous open-domain questions. CoRR, abs.\nRaffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M., Zhou, Y., Li, W., and Liu, P. J. 1910. Exploring the limits of transfer learning with a unified text-to-text transformer. In Exploring the limits of transfer learning with a unified text-to-text transformer.\nRajpurkar, P., Zhang, J., Lopyrev, K., and Liang, P. 2016. Squad: 100, 000+ questions for machine comprehension of text. In Squad: 100, 000+ questions for machine comprehension of text. abs/1606.05250\nRogers, A., Gardner, M., and Augenstein, I. 2021. QA dataset explosion: A taxonomy of NLP resources for question answering and reading comprehension. In QA dataset explosion: A taxonomy of NLP resources for question answering and reading comprehension. abs/2107.12708\nSee, A., Peter, J., Liu, C.D., and Manning 2017. Get to the point: Summarization with pointer-generator networks. In Get to the point: Summarization with pointer-generator networks. arXiv:1704.04368\nVinyals, O., Fortunato, M., and Jaitly, N. 2017.\nVoorhees, E. M. 1999. The TREC-8 question answering track report. In Proceedings of The Eighth Text REtrieval Conference. TREC 1999\nWu, Y., Minervini, P., Stenetorp, P., and Riedel, S. 2021. Training adaptive computation for open-domain question answering with computational constraints. In Training adaptive computation for open-domain question answering with computational constraints. abs/2107.02102\nYamada, I., Asai, A., and Hajishirzi, H. 2021. Efficient passage retrieval with hashing for open-domain question answering. In Efficient passage retrieval with hashing for open-domain question answering. abs/2106.00882\nYang, W., Xie, Y., Lin, A., Li, X., Tan, L., Xiong, K., Li, M., and Lin, J. 1718. End-to-end open-domain question answering with bertserini. CoRR, abs. In End-to-end open-domain question answering with bertserini. CoRR, abs.\nZhou, C., Neubig, G., Gu, J., Diab, M., Guzm\u00e1n, F., Zettlemoyer, L., and Ghazvininejad, M. 2021. Detecting hallucinated content in conditional neural sequence generation. In Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021. pp. 1393--1404 10.18653/v1/2021.findings-acl.120"
    },
    {
        "filename": "paper_7.txt",
        "start": 2462,
        "end": 2513,
        "label": "Unsupported Claim",
        "text": "but its application to ODQA has been less explored.",
        "full_text": "Related Work\n\nOpen-Domain Question Answering\n\nIn this era of data explosion, ODQA offers a way to rapidly and accurately fulfill user's information needs, and hence has recently received significant attention from both industry and academia (Min et al., 2021a). Following the work of DrQA (Chen et al., 2017), most recent works build a two-stage retriever-reader system to tackle the problem. The retriever aims at retrieving supportive passages to the given question from a large document corpus. The reader intends to find answer of the question from the first stage retrieved passages. Early work of Chen et al. (2017) adapts a BiLSTM architecture with various lexical and semantic features from the question and passages as inputs. Later, with the emergence of large-scale pre-trained language models, readers based on pre-trained models such as BERT and T5 Raffel et al., 2019) have become a common approach (Yang et al., 2019;Karpukhin et al., 2020;Izacard and Grave, 2020b).\n\nGenerative Readers\n\nCompared to extractive models which extract existing words from the retrieved passages, generative models are able to produce new words out of the retrieved passages, and thus provide a more flexible modeling framework.  and Lewis et al. (2020a) concatenate the given question with top retrieved passages and feed the concatenation to the BART model (Lewis et al., 2019). Izacard and Grave (2020b) separately encodes the question with each top retrieved passage, then takes the concatenation of the encoder outputs as input to the decoder. Their method provide a way to better aggregate evidence from multiple passages and improve the performance significantly. FiD-KD (Izacard and Grave, 2020a) is an extension of FiD model that increases the accuracy of passage retrieval by training the dense retriever with the guidance of the FiD reader iteratively.\n\nPointer-Generator Network\n\nPointer-Generator Network (See et al., 2017) is an extension of the sequence-to-sequence model by integrating a copy mechanism (Vinyals et al., 2017) into the generator. At each decoding stage, the model is able to either directly copy a word from the input or generate one with certain probability, and thus can be viewed as a combination of extractive and generative approaches. It has been frequently used in natural language tasks like summarization (Gu et al., 2016;See et al.,  Gehrmann et al., 2018) and neural machine translation (Luong et al., 2014;Gu et al., 2017), but its application to ODQA has been less explored.\n\n References: \nAsai, A., Hashimoto, K., Hajishirzi, H., Socher, R., and Xiong, C. 1911. Learning to retrieve reasoning paths over wikipedia graph for question answering. In Learning to retrieve reasoning paths over wikipedia graph for question answering.\nChen, D., Fisch, A., Weston, J., and Bordes, A. 2017. Reading wikipedia to answer opendomain questions. In Reading wikipedia to answer opendomain questions. abs/1704.00051\nDevlin, J., Chang, M., Lee, K., and Toutanova, K. 2019. BERT: pre-training of deep bidirectional transformers for language understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019. pp. 4171--4186 10.18653/v1/n19-1423\nGehrmann, S., Deng, Y., and Rush, A. M. 2018. Bottom-up abstractive summarization. In Bottom-up abstractive summarization. abs/1808.10792\nGu, J., Bradbury, J., Xiong, C., Victor, O. K., Li, R., and Socher 2017. Non-autoregressive neural machine translation. In Non-autoregressive neural machine translation. abs/1711.02281\nGu, J., Lu, Z., Li, H., Victor, O. K., and Li 2016. Incorporating copying mechanism in sequenceto-sequence learning. In Incorporating copying mechanism in sequenceto-sequence learning. abs/1603.06393\nIzacard, G. and Grave, E. 2020. Distilling knowledge from reader to retriever for question answering. In Distilling knowledge from reader to retriever for question answering. abs/2012.04584\nIzacard, G. and Grave, E. 1282. Leveraging passage retrieval with generative models for open domain question answering. CoRR, abs. In Leveraging passage retrieval with generative models for open domain question answering. CoRR, abs.\nJoshi, M., Choi, E., Weld, D. S., and Zettlemoyer, L. 2017. Triviaqa: A large scale distantly supervised challenge dataset for reading comprehension. In Triviaqa: A large scale distantly supervised challenge dataset for reading comprehension. abs/1705.03551\nKarpukhin, V., Oguz, B., Min, S., Lewis, P., Wu, L., Edunov, S., Chen, D., and Yih, W. 2020. Dense passage retrieval for open-domain question answering. In Dense passage retrieval for open-domain question answering. arXiv:2004.04906\nKwiatkowski, T., Palomaki, J., Redfield, O., Collins, M., Parikh, A., Alberti, C., Epstein, D., Polosukhin, I., Devlin, J., Lee, K., Toutanova, K., Jones, L., Kelcey, M., Chang, M., Dai, A., Uszkoreit, J., Le, Q., and Petrov, S. 2019. Natural questions: a benchmark for question answering research. In Transactions of the Association for Computational Linguistics. pp. 452--466\nLewis, M., Liu, Y., Goyal, N., Ghazvininejad, M., Mohamed, A., Levy, O., Stoyanov, V., and Zettlemoyer, L. 2019.\n1910. BART: denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension. CoRR, abs. In BART: denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension. CoRR, abs.\nPatrick, S. H., Lewis, E., Perez, A., Piktus, F., Petroni, V., Karpukhin, N., Goyal, H., K\u00fcttler, M., Lewis, W., Yih, T., Rockt\u00e4schel, S., Riedel, D., and Kiela 2005. Retrieval-augmented generation for knowledge-intensive NLP tasks. In Retrieval-augmented generation for knowledge-intensive NLP tasks.\nPatrick, S. H., Lewis, P., Stenetorp, S., and Riedel 2008. Question and answer test-train overlap in open-domain question answering datasets. CoRR, abs. In Question and answer test-train overlap in open-domain question answering datasets. CoRR, abs.\nLoshchilov, I. and Hutter, F. 2017. Fixing weight decay regularization in adam. In Fixing weight decay regularization in adam. abs/1711.05101\nLuong, T., Sutskever, I., Le, Q. V., Vinyals, O., and Zaremba, W. 2014. Addressing the rare word problem in neural machine translation. In Addressing the rare word problem in neural machine translation.\nMaynez, J., Narayan, S., Bohnet, B., and Mcdonald, R. T. 0661. On faithfulness and factuality in abstractive summarization. CoRR, abs. In On faithfulness and factuality in abstractive summarization. CoRR, abs.\nMin, S., Boyd-Graber, J. L., Alberti, C., Chen, D., Choi, E., Collins, M., Guu, K., Hajishirzi, H., Lee, K., Palomaki, J., Raffel, C., Roberts, A., Kwiatkowski, T., Patrick, S. H., Lewis, Y., Wu, H., K\u00fcttler, L., Liu, P., Minervini, P., Stenetorp, S., Riedel, S., Yang, M., Seo, G., Izacard, F., Petroni, L., Hosseini, N. D., Cao, E., Grave, I., Yamada, S., Shimaoka, M., Suzuki, S., Miyawaki, S., Sato, R., Takahashi, J., Suzuki, M., Fajcik, M., and Docekal\nMin, S., Lee, K., Chang, M., Toutanova, K., and Hajishirzi, H. 2021. Joint passage ranking for diverse multi-answer retrieval. In Joint passage ranking for diverse multi-answer retrieval. abs/2104.08445\nMin, S., Michael, J., Hajishirzi, H., and Zettlemoyer, L. 2004. Ambigqa: Answering ambiguous open-domain questions. CoRR, abs. In Ambigqa: Answering ambiguous open-domain questions. CoRR, abs.\nRaffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M., Zhou, Y., Li, W., and Liu, P. J. 1910. Exploring the limits of transfer learning with a unified text-to-text transformer. In Exploring the limits of transfer learning with a unified text-to-text transformer.\nRajpurkar, P., Zhang, J., Lopyrev, K., and Liang, P. 2016. Squad: 100, 000+ questions for machine comprehension of text. In Squad: 100, 000+ questions for machine comprehension of text. abs/1606.05250\nRogers, A., Gardner, M., and Augenstein, I. 2021. QA dataset explosion: A taxonomy of NLP resources for question answering and reading comprehension. In QA dataset explosion: A taxonomy of NLP resources for question answering and reading comprehension. abs/2107.12708\nSee, A., Peter, J., Liu, C.D., and Manning 2017. Get to the point: Summarization with pointer-generator networks. In Get to the point: Summarization with pointer-generator networks. arXiv:1704.04368\nVinyals, O., Fortunato, M., and Jaitly, N. 2017.\nVoorhees, E. M. 1999. The TREC-8 question answering track report. In Proceedings of The Eighth Text REtrieval Conference. TREC 1999\nWu, Y., Minervini, P., Stenetorp, P., and Riedel, S. 2021. Training adaptive computation for open-domain question answering with computational constraints. In Training adaptive computation for open-domain question answering with computational constraints. abs/2107.02102\nYamada, I., Asai, A., and Hajishirzi, H. 2021. Efficient passage retrieval with hashing for open-domain question answering. In Efficient passage retrieval with hashing for open-domain question answering. abs/2106.00882\nYang, W., Xie, Y., Lin, A., Li, X., Tan, L., Xiong, K., Li, M., and Lin, J. 1718. End-to-end open-domain question answering with bertserini. CoRR, abs. In End-to-end open-domain question answering with bertserini. CoRR, abs.\nZhou, C., Neubig, G., Gu, J., Diab, M., Guzm\u00e1n, F., Zettlemoyer, L., and Ghazvininejad, M. 2021. Detecting hallucinated content in conditional neural sequence generation. In Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021. pp. 1393--1404 10.18653/v1/2021.findings-acl.120"
    }
]