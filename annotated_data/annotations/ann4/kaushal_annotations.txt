Search parameters
==========
Coding by: All coders
Codes: 
Format. Coherence. Lacks Synthesis. Unsupported Claim. Codes: 4 / 4
Files:
paper_1.txt, paper_10.txt, paper_2.txt, paper_3.txt, paper_4.txt, paper_5.txt, paper_6.txt, paper_7.txt, paper_8.txt, paper_9.txt,  Files:  10 / 96

==========

Code count totals: 66
============
Coherence : 11
Format : 7
Lacks Synthesis : 12
Unsupported Claim : 36
============
Text code statistics:
Coherence | paper_1.txt | Count: 2 | Percent of file: 1.75%
Coherence | paper_2.txt | Count: 2 | Percent of file: 5.02%
Coherence | paper_7.txt | Count: 3 | Percent of file: 9.09%
Coherence | paper_8.txt | Count: 1 | Percent of file: 1.39%
Coherence | paper_9.txt | Count: 3 | Percent of file: 17.52%
Format | paper_1.txt | Count: 3 | Percent of file: 0.83%
Format | paper_2.txt | Count: 2 | Percent of file: 0.33%
Format | paper_4.txt | Count: 1 | Percent of file: 0.33%
Format | paper_6.txt | Count: 1 | Percent of file: 0.14%
Lacks Synthesis | paper_1.txt | Count: 2 | Percent of file: 11.93%
Lacks Synthesis | paper_2.txt | Count: 1 | Percent of file: 13.84%
Lacks Synthesis | paper_4.txt | Count: 1 | Percent of file: 10.29%
Lacks Synthesis | paper_6.txt | Count: 3 | Percent of file: 18.83%
Lacks Synthesis | paper_7.txt | Count: 3 | Percent of file: 25.25%
Lacks Synthesis | paper_9.txt | Count: 2 | Percent of file: 18.6%
Unsupported Claim | paper_1.txt | Count: 1 | Percent of file: 0.13%
Unsupported Claim | paper_2.txt | Count: 3 | Percent of file: 1.74%
Unsupported Claim | paper_3.txt | Count: 3 | Percent of file: 0.26%
Unsupported Claim | paper_4.txt | Count: 6 | Percent of file: 1.13%
Unsupported Claim | paper_5.txt | Count: 3 | Percent of file: 0.2%
Unsupported Claim | paper_6.txt | Count: 3 | Percent of file: 0.87%
Unsupported Claim | paper_7.txt | Count: 3 | Percent of file: 0.9%
Unsupported Claim | paper_8.txt | Count: 5 | Percent of file: 0.68%
Unsupported Claim | paper_9.txt | Count: 6 | Percent of file: 2.41%
Unsupported Claim | paper_10.txt | Count: 3 | Percent of file: 0.68%
========

[741-843] Coherence, File: paper_1.txt,  Coder: default
For instance, Mao et al. (2019) generates story with multitasking learning on commonsense QA datasets.


[1022-1101] Coherence, File: paper_1.txt,  Coder: default
Ji et al. (2020) do multi-hop with a graph convolutional network on ConceptNet.


[867-1363] Coherence, File: paper_2.txt,  Coder: default
Several of the value schemes proposed in the literature pertain to specific purposes. England (1967) suggested 66 values related to management decisions, such as high productivity and prestige, and categorized them by relevant entity, for example business organizations and individuals. Brown and Crace (2002) looked at 14 values for counseling and therapy, such as responsibility and spirituality, and Kahle et al. (1988) at nine for consumer research, such as warm relationships and excitement.


[4643-4793] Coherence, File: paper_2.txt,  Coder: default
In argumentation, some values are so prevalent that they constitute frames of their own, indicating a potential use of values in frame identification.


[262-588] Coherence, File: paper_7.txt,  Coder: default
Following the work of DrQA (Chen et al., 2017), most recent works build a two-stage retriever-reader system to tackle the problem. The retriever aims at retrieving supportive passages to the given question from a large document corpus. The reader intends to find answer of the question from the first stage retrieved passages.


[588-981] Coherence, File: paper_7.txt,  Coder: default
 Early work of Chen et al. (2017) adapts a BiLSTM architecture with various lexical and semantic features from the question and passages as inputs. Later, with the emergence of large-scale pre-trained language models, readers based on pre-trained models such as BERT and T5 Raffel et al., 2019) have become a common approach (Yang et al., 2019;Karpukhin et al., 2020;Izacard and Grave, 2020b).


[1223-1374] Coherence, File: paper_7.txt,  Coder: default
 and Lewis et al. (2020a) concatenate the given question with top retrieved passages and feed the concatenation to the BART model (Lewis et al., 2019).


[814-1063] Coherence, File: paper_8.txt,  Coder: default
On the one hand, these metrics are not accessible on some tasks such as regression. On the other hand, In order for these methods to perform well, one usually needs to fine-tune the threshold, which varies widely across different tasks and datasets.


[262-1625] Coherence, File: paper_9.txt,  Coder: default
Data-based Transfer Translating utterances for the intent classification task is relatively straightforward so previous works focused on projecting and/or aligning the entity labels between translated utterances (Dou and Neubig, 2021). This technique is followed by standard supervised training with those pseudo-labels and is commonly known as a translate-train method. One of the earliest works still being used for this purpose is fastalign (Dyer et al., 2013). It's an unsupervised word aligner trained on a parallel corpus to map each word (thus its entity label) in the source utterance to the word(s) in the target user utterance. Projecting the entity labels can also be done with word-by-word translation and source label copying (Yi and Cheng, 2021). A teacher model then weakly labels the target data, which is used to train the final student model. Sometimes, this type of label projection is complemented with an additional entity alignment step (Li et al., 2021a). Better performance can be achieved by using machine translation with entity matching and distributional statistics (Jain et al., 2019) though this can be a costly process for each language. A category of 'word substitution' methods such as code-switching (Qin et al., 2020;Kuwanto et al., 2021) or dictionary-enhanced pretraining  have also been shown to improve cross-lingual transfe


[1629-2216] Coherence, File: paper_9.txt,  Coder: default
Model-based Transfer Prior to the adoption of multilingual transformers (Lample and Conneau, 2019), task-oriented XNLU methods employed a BiLSTM encoder combined with different multilingual embeddings (Schuster et al., 2019). Newer approaches usually involve a pretrained XLM and the addition of some new training component with the inference routine remaining mostly unchanged. Xu et al. (2020) learn to jointly align and predict entity labels by fusing the source and target language embeddings with attention and using the resulting cross-lingual representation for entity prediction.


[3288-3609] Coherence, File: paper_9.txt,  Coder: default
XeroAlign works by generating a sentence embedding of the user utterance for each language, e.g. English (source) and Thai (target) using the CLS token of the XLM. A Mean Squared Error loss function minimises the difference between the multilingual sentence embeddings and is backpropagated along with the main task loss.


[1259-1295] Format, File: paper_1.txt,  Coder: default
various types of knowledge resources


[1384-1432] Format, File: paper_1.txt,  Coder: default
 large-scale commonsense knowledge graphs (CSKG)


[1583-1585] Format, File: paper_1.txt,  Coder: default
, 


[2938-2967] Format, File: paper_2.txt,  Coder: default
(van der Weide et al., 2009),


[4881-4894] Format, File: paper_2.txt,  Coder: default
Ajjour et al.


[1551-1589] Format, File: paper_4.txt,  Coder: default
Amazon Alexa Socialbot Grand Challenge


[2053-2071] Format, File: paper_6.txt,  Coder: default
(Liu et al., 2021)


[14-557] Lacks Synthesis, File: paper_1.txt,  Coder: default
Large-scale pretrained language models have been shown to encode some knowledge implicitly through their pretraining objectives (Petroni et al., 2019a), including both commonsense (Shwartz et al., 2020) and factual knowledge (Petroni et al., 2019b). However, pretrained language models still struggle with some downstream applications, especially when the model needs to make inference based on context (Do and Pavlick, 2021;Kassner and Schütze, 2020). Thus, recent works have also explored enhancing pretrained models with external knowledge.


[559-1247] Lacks Synthesis, File: paper_1.txt,  Coder: default
Introducing knowledge into language models has been shown to be successful on various downstream tasks and model architecture (Ren et al., 2020;Zhao et al., 2020;Song et al., 2019). For instance, Mao et al. (2019) generates story with multitasking learning on commonsense QA datasets. Zhao et al. (2020) used BERT as a knowledge selection module for dialogue generation. Chakrabarty et al. (2020) ranked knowledge generated from the COMET for sarcasm generation. Ji et al. (2020) do multi-hop with a graph convolutional network on ConceptNet. Similarly, our work uses external knowledge sources, but with several different settings to enhance text generation for counseling conversations.


[867-2648] Lacks Synthesis, File: paper_2.txt,  Coder: default
Several of the value schemes proposed in the literature pertain to specific purposes. England (1967) suggested 66 values related to management decisions, such as high productivity and prestige, and categorized them by relevant entity, for example business organizations and individuals. Brown and Crace (2002) looked at 14 values for counseling and therapy, such as responsibility and spirituality, and Kahle et al. (1988) at nine for consumer research, such as warm relationships and excitement.

Other proposed value schemes are more generic. Combining research from anthropology, sociology, philosophy, and psychology, Rokeach (1973) estimates the total number of human values to be fewer than hundreds, and develops a practical survey of 36 values that distinguishes between values pertaining to desirable end states and desirable behavior. Specifically for cross-cultural analyses, Schwartz et al. ( 2012) derived 48 value questions from the universal needs of individuals and societies, including obeying all the laws and to be humble. Moreover, Schwartz (1994) proposes a relatedness of values by their tendency to be compatible in their pursuit (see Figure 1). This relatedness reflects two "higher order" conflicts: (1) openness to change/own thoughts vs. conservation/submission, and (2) self-transcension (directed towards others/the environment) vs. self-enhancing (directed towards one's self), allowing to analyse values at several levels. Cheng and Fleischmann (2010) consolidates 12 schemes into a "meta-inventory" with 16 values, such as honesty and justice, revealing a large overlap in schemes across fields of research. However, as the meta-inventory is strictly more coarse-grained than Schwartz et al.'s theory we do not investigate it further for this paper.


[30-1200] Lacks Synthesis, File: paper_4.txt,  Coder: default
A common issue occurs that can potentially impact the validity of results is filtering the set of systems to be evaluated via automatic metric scores. Since metric scores are known to be a poor substitute for human assessment, this only results in the pos-sibility that the best system according to human judges is inadvertently filtered out at this stage. For example, ConvAI2 (Dinan et al., 2019) ranked models firstly using automatic metrics before top models according to metric scores were assessed by crowd-sourced workers on Mechanical Turk, while similarly in the sixth Dialog System Technology Challenge (DSTC6) systems were filtered according to metric scores prior to human evaluation.

In terms of the live evaluation, competitions such as Convai2 report such evaluations as highly challenging, with many of the resulting dialogues reported to be senseless, offensive, or simply not in line with instructions and ultimately live evaluation results have been discarded.

Despite challenges, competitions that operate in the public domain, making data and evaluation techniques available to researchers (such as ourselves) should be applauded for such efforts.


[14-1198] Lacks Synthesis, File: paper_6.txt,  Coder: default
Zero-shot cross-lingual structured prediction. Zero-shot cross-lingual learning becomes an emerging research topic as it eliminates the requirement of labeled data for training models in low-resource languages. Various structured prediction tasks have be studied, including named entity recognition (Pan et al., 2017;Hu et al., 2020), dependency parsing (Ahmad et al., 2019, relation extraction (Zou et al., 2018;Ni and Florian, 2019), and event argument extraction (Subburathinam et al., 2019;Ahmad et al., 2021;Nguyen and Nguyen, 2021). Most of them are classification-based models that build classifiers on top of a multilingual pre-trained masked language models. To further deal with the discrepancy between languages, some of them require additional information, such as bilingual dictionaries (Liu et al., 2019; Ni and Florian, 2019), translation pairs (Zou et al., 2018), and dependency parse trees (Subburathinam et al., 2019;Ahmad et al., 2021;Nguyen and Nguyen, 2021). However, as pointed out by previous literature (Li et al., 2021;Hsu et al., 2021), classification-based models are less powerful to model dependencies between entities compared to generation-based models.


[1200-1769] Lacks Synthesis, File: paper_6.txt,  Coder: default
Generation-based structured prediction. Several works have demonstrated the great success of generation-based models on monolingual structured prediction tasks, including named entity recognition (Yan et al., 2021), relation extraction (Huang et al., 2021;Paolini et al., 2021), and event extraction (Du et al., 2021;Hsu et al., 2021;Lu et al., 2021). Yet, as mentioned in Section 1, their designed generating targets are language-dependent. Accordingly, directly applying their methods to the zero-shot cross-lingual setting would result in less-preferred performance.


[1771-2462] Lacks Synthesis, File: paper_6.txt,  Coder: default
Prompting methods. There are growing interests recently to incorporate prompts on pre-trained language models in order to guide the models' behavior or elicit knowledge (Shin et al., 2020;Schick and Schütze, 2021;Qin and Eisner, 2021;Scao and Rush, 2021). Following the taxonomy in (Liu et al., 2021), these methods can be classified depending on whether the language models' parameters are tuned and on whether trainable prompts are introduced. Our method belongs to the category that fixes the prompts and tune the language models' parameters. Despite the flourish of the research in prompting methods, there is only limited attention being put on multilingual tasks (Winata et al., 2021).


[46-981] Lacks Synthesis, File: paper_7.txt,  Coder: default
In this era of data explosion, ODQA offers a way to rapidly and accurately fulfill user's information needs, and hence has recently received significant attention from both industry and academia (Min et al., 2021a). Following the work of DrQA (Chen et al., 2017), most recent works build a two-stage retriever-reader system to tackle the problem. The retriever aims at retrieving supportive passages to the given question from a large document corpus. The reader intends to find answer of the question from the first stage retrieved passages. Early work of Chen et al. (2017) adapts a BiLSTM architecture with various lexical and semantic features from the question and passages as inputs. Later, with the emergence of large-scale pre-trained language models, readers based on pre-trained models such as BERT and T5 Raffel et al., 2019) have become a common approach (Yang et al., 2019;Karpukhin et al., 2020;Izacard and Grave, 2020b).


[1003-1857] Lacks Synthesis, File: paper_7.txt,  Coder: default
Compared to extractive models which extract existing words from the retrieved passages, generative models are able to produce new words out of the retrieved passages, and thus provide a more flexible modeling framework.  and Lewis et al. (2020a) concatenate the given question with top retrieved passages and feed the concatenation to the BART model (Lewis et al., 2019). Izacard and Grave (2020b) separately encodes the question with each top retrieved passage, then takes the concatenation of the encoder outputs as input to the decoder. Their method provide a way to better aggregate evidence from multiple passages and improve the performance significantly. FiD-KD (Izacard and Grave, 2020a) is an extension of FiD model that increases the accuracy of passage retrieval by training the dense retriever with the guidance of the FiD reader iteratively.


[1886-2513] Lacks Synthesis, File: paper_7.txt,  Coder: default
Pointer-Generator Network (See et al., 2017) is an extension of the sequence-to-sequence model by integrating a copy mechanism (Vinyals et al., 2017) into the generator. At each decoding stage, the model is able to either directly copy a word from the input or generate one with certain probability, and thus can be viewed as a combination of extractive and generative approaches. It has been frequently used in natural language tasks like summarization (Gu et al., 2016;See et al.,  Gehrmann et al., 2018) and neural machine translation (Luong et al., 2014;Gu et al., 2017), but its application to ODQA has been less explored.


[262-1625] Lacks Synthesis, File: paper_9.txt,  Coder: default
Data-based Transfer Translating utterances for the intent classification task is relatively straightforward so previous works focused on projecting and/or aligning the entity labels between translated utterances (Dou and Neubig, 2021). This technique is followed by standard supervised training with those pseudo-labels and is commonly known as a translate-train method. One of the earliest works still being used for this purpose is fastalign (Dyer et al., 2013). It's an unsupervised word aligner trained on a parallel corpus to map each word (thus its entity label) in the source utterance to the word(s) in the target user utterance. Projecting the entity labels can also be done with word-by-word translation and source label copying (Yi and Cheng, 2021). A teacher model then weakly labels the target data, which is used to train the final student model. Sometimes, this type of label projection is complemented with an additional entity alignment step (Li et al., 2021a). Better performance can be achieved by using machine translation with entity matching and distributional statistics (Jain et al., 2019) though this can be a costly process for each language. A category of 'word substitution' methods such as code-switching (Qin et al., 2020;Kuwanto et al., 2021) or dictionary-enhanced pretraining  have also been shown to improve cross-lingual transfe


[2902-3951] Lacks Synthesis, File: paper_9.txt,  Coder: default
The most related prior works are Arivazhagan et al. (2019) for machine translation and  for task-oriented XNLU. Both of these are cross-lingual alignment methods that use translated training data to zero-shot transfer the source language model to the target language. We focus on the latter work, called XeroAlign, which reported the most recent SOTA scores on our evaluation datasets. XeroAlign works by generating a sentence embedding of the user utterance for each language, e.g. English (source) and Thai (target) using the CLS token of the XLM. A Mean Squared Error loss function minimises the difference between the multilingual sentence embeddings and is backpropagated along with the main task loss. XeroAlign aims to bring sentence embeddings in different languages closer together with a bias towards intent classification due to the CLS embedding, which is the standard input to the intent classifier. We reproduce this method for analysis and comparisons but add a small post-processing step that distinctly improves the reported scores.


[473-486] Unsupported Claim, File: paper_1.txt,  Coder: default
recent works 


[153-172] Unsupported Claim, File: paper_10.txt,  Coder: default
humans’ development


[273-294] Unsupported Claim, File: paper_10.txt,  Coder: default
facilitate learning. 


[2596-2641] Unsupported Claim, File: paper_10.txt,  Coder: default
 validated narrative comprehension frameworks


[1365-1411] Unsupported Claim, File: paper_2.txt,  Coder: default
Other proposed value schemes are more generic.


[2684-2712] Unsupported Claim, File: paper_2.txt,  Coder: default
Formal argumentation employs


[4643-4793] Unsupported Claim, File: paper_2.txt,  Coder: default
In argumentation, some values are so prevalent that they constitute frames of their own, indicating a potential use of values in frame identification.


[789-801] Unsupported Claim, File: paper_3.txt,  Coder: default
most of them


[1017-1037] Unsupported Claim, File: paper_3.txt,  Coder: default
most of these models


[1359-1377] Unsupported Claim, File: paper_3.txt,  Coder: default
not well explored.


[30-51] Unsupported Claim, File: paper_4.txt,  Coder: default
A common issue occurs


[205-210] Unsupported Claim, File: paper_4.txt,  Coder: default
known


[608-650] Unsupported Claim, File: paper_4.txt,  Coder: default
Dialog System Technology Challenge (DSTC6)


[1221-1234] Unsupported Claim, File: paper_4.txt,  Coder: default
competitions 


[4155-4186] Unsupported Claim, File: paper_4.txt,  Coder: default
Contrary to common expectations


[4575-4591] Unsupported Claim, File: paper_4.txt,  Coder: default
account the fact


[1333-1351] Unsupported Claim, File: paper_5.txt,  Coder: default
frequency baseline


[2052-2066] Unsupported Claim, File: paper_5.txt,  Coder: default
tail phenomena


[2365-2376] Unsupported Claim, File: paper_5.txt,  Coder: default
ZuCo corpus


[105-128] Unsupported Claim, File: paper_6.txt,  Coder: default
emerging research topic


[633-681] Unsupported Claim, File: paper_6.txt,  Coder: default
multilingual pre-trained masked language models.


[1726-1768] Unsupported Claim, File: paper_6.txt,  Coder: default
would result in less-preferred performance


[310-327] Unsupported Claim, File: paper_7.txt,  Coder: default
most recent works


[1090-1108] Unsupported Claim, File: paper_7.txt,  Coder: default
 generative models


[2462-2513] Unsupported Claim, File: paper_7.txt,  Coder: default
but its application to ODQA has been less explored.


[33-54] Unsupported Claim, File: paper_8.txt,  Coder: default
widely used technique


[401-411] Unsupported Claim, File: paper_8.txt,  Coder: default
 exit late


[751-812] Unsupported Claim, File: paper_8.txt,  Coder: default
However, these methods can not easily generalize to new tasks


[3565-3582] Unsupported Claim, File: paper_8.txt,  Coder: default
previous methods 


[3773-3786] Unsupported Claim, File: paper_8.txt,  Coder: default
previous work


[14-75] Unsupported Claim, File: paper_9.txt,  Coder: default
Several approaches to zero-shot cross-lingual transfer exist 


[110-176] Unsupported Claim, File: paper_9.txt,  Coder: default
 Databased Transfer, which focuses on training data transformation


[184-260] Unsupported Claim, File: paper_9.txt,  Coder: default
Model-based Transfer that centres around modifying models' training routine.


[262-339] Unsupported Claim, File: paper_9.txt,  Coder: default
Data-based Transfer Translating utterances for the intent classification task


[589-607] Unsupported Claim, File: paper_9.txt,  Coder: default
commonly known as 


[1855-1870] Unsupported Claim, File: paper_9.txt,  Coder: default
Newer approache
