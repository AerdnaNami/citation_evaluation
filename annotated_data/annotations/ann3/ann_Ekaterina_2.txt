Search parameters
==========
Coding by: All coders
Codes: 
Coherence. Format. Lacks synthesis. Unsupported claim. Codes: 4 / 4
Files:
paper_1.txt, paper_10.txt, paper_100.txt, paper_11.txt, paper_13.txt, paper_14.txt, paper_15.txt, paper_16.txt, paper_17.txt, paper_18.txt, paper_19.txt, paper_2.txt, paper_20.txt, paper_21.txt, paper_22.txt, paper_23.txt, paper_24.txt, paper_25.txt, paper_26.txt, paper_27.txt, paper_28.txt, paper_3.txt, paper_30.txt, paper_31.txt, paper_32.txt, paper_33.txt, paper_34.txt, paper_35.txt, paper_36.txt, paper_37.txt, paper_38.txt, paper_39.txt, paper_4.txt, paper_40.txt, paper_41.txt, paper_42.txt, paper_43.txt, paper_44.txt, paper_45.txt, paper_46.txt, paper_47.txt, paper_49.txt, paper_5.txt, paper_50.txt, paper_51.txt, paper_52.txt, paper_53.txt, paper_54.txt, paper_55.txt, paper_56.txt, paper_57.txt, paper_58.txt, paper_59.txt, paper_6.txt, paper_61.txt, paper_62.txt, paper_63.txt, paper_64.txt, paper_65.txt, paper_66.txt, paper_67.txt, paper_68.txt, paper_69.txt, paper_7.txt, paper_70.txt, paper_71.txt, paper_72.txt, paper_73.txt, paper_74.txt, paper_75.txt, paper_76.txt, paper_77.txt, paper_78.txt, paper_79.txt, paper_8.txt, paper_80.txt, paper_81.txt, paper_82.txt, paper_83.txt, paper_84.txt, paper_85.txt, paper_86.txt, paper_87.txt, paper_88.txt, paper_89.txt, paper_9.txt, paper_90.txt, paper_91.txt, paper_92.txt, paper_93.txt, paper_94.txt, paper_95.txt, paper_96.txt, paper_97.txt, paper_98.txt, paper_99.txt,  Files:  96 / 96

==========

Code count totals: 50
============
Coherence : 7
Format : 9
Lacks synthesis : 7
Unsupported claim : 27
============
Text code statistics:
Coherence | paper_1.txt | Count: 3 | Percent of file: 7.24%
Coherence | paper_2.txt | Count: 2 | Percent of file: 5.75%
Coherence | paper_6.txt | Count: 1 | Percent of file: 1.12%
Coherence | paper_7.txt | Count: 1 | Percent of file: 2.01%
Format | paper_1.txt | Count: 1 | Percent of file: 0.05%
Format | paper_2.txt | Count: 1 | Percent of file: 0.1%
Format | paper_6.txt | Count: 4 | Percent of file: 0.28%
Format | paper_8.txt | Count: 2 | Percent of file: 0.13%
Format | paper_9.txt | Count: 1 | Percent of file: 0.02%
Lacks synthesis | paper_6.txt | Count: 2 | Percent of file: 13.13%
Lacks synthesis | paper_7.txt | Count: 3 | Percent of file: 26.07%
Lacks synthesis | paper_9.txt | Count: 1 | Percent of file: 10.53%
Lacks synthesis | paper_10.txt | Count: 1 | Percent of file: 1.4%
Unsupported claim | paper_1.txt | Count: 1 | Percent of file: 1.3%
Unsupported claim | paper_3.txt | Count: 6 | Percent of file: 2.94%
Unsupported claim | paper_4.txt | Count: 6 | Percent of file: 9.84%
Unsupported claim | paper_5.txt | Count: 3 | Percent of file: 0.38%
Unsupported claim | paper_6.txt | Count: 1 | Percent of file: 1.26%
Unsupported claim | paper_7.txt | Count: 1 | Percent of file: 0.09%
Unsupported claim | paper_8.txt | Count: 6 | Percent of file: 2.85%
Unsupported claim | paper_9.txt | Count: 1 | Percent of file: 1.9%
Unsupported claim | paper_10.txt | Count: 2 | Percent of file: 3.23%
========

[559-1101] Coherence, File: paper_1.txt,  Coder: default
Introducing knowledge into language models has been shown to be successful on various downstream tasks and model architecture (Ren et al., 2020;Zhao et al., 2020;Song et al., 2019). For instance, Mao et al. (2019) generates story with multitasking learning on commonsense QA datasets. Zhao et al. (2020) used BERT as a knowledge selection module for dialogue generation. Chakrabarty et al. (2020) ranked knowledge generated from the COMET for sarcasm generation. Ji et al. (2020) do multi-hop with a graph convolutional network on ConceptNet.


[1507-1623] Coherence, File: paper_1.txt,  Coder: default
The most widely used CSKG resources include Concept-Net (Speer et al., 2017), ATOMIC TransOMCS (Zhang et al., 2020).


[1624-1713] Coherence, File: paper_1.txt,  Coder: default
There are also medical related knowledge base such UMLS (Bodenreider, 2004) and OHAMA 1 .


[2321-2507] Coherence, File: paper_2.txt,  Coder: default
Cheng and Fleischmann (2010) consolidates 12 schemes into a "meta-inventory" with 16 values, such as honesty and justice, revealing a large overlap in schemes across fields of research. 


[3461-4015] Coherence, File: paper_2.txt,  Coder: default
Feldman (2021) recently showed the strong connection between values and the moral foundation theory (Haidt, 2012). Like personal values, this theory analyzes ethical reasoning behind human choices, but considers five rather abstract "foundations:" care, fairness, loyalty, authority, and purity. Alshomary and Wachsmuth (2021) hypothesized that the foundations could be used for audiencespecific argument generation. Kobbe et al. (2020) tried to classify arguments by foundations, but noted a low human agreement due to the vagueness of the foundations. 


[2261-2406] Coherence, File: paper_6.txt,  Coder: default
Despite the flourish of the research in prompting methods, there is only limited attention being put on multilingual tasks (Winata et al., 2021).


[1665-1857] Coherence, File: paper_7.txt,  Coder: default
FiD-KD (Izacard and Grave, 2020a) is an extension of FiD model that increases the accuracy of passage retrieval by training the dense retriever with the guidance of the FiD reader iteratively.


[1709-1714] Format, File: paper_1.txt,  Coder: default
 1 . 


[4881-4894] Format, File: paper_2.txt,  Coder: default
Ajjour et al.


[813-816] Format, File: paper_6.txt,  Coder: default
 Ni


[1021-1025] Format, File: paper_6.txt,  Coder: default
 Hsu


[1399-1407] Format, File: paper_6.txt,  Coder: default
 Paolini


[1994-2015] Format, File: paper_6.txt,  Coder: default
in (Liu et al., 2021)


[610-614] Format, File: paper_8.txt,  Coder: default
 Liu


[4135-4154] Format, File: paper_8.txt,  Coder: default
 Liu et al., 2020a;


[2988-2990] Format, File: paper_9.txt,  Coder: default
  


[1993-2167] Lacks synthesis, File: paper_10.txt,  Coder: default
To bridge the gap, we constructed FairytaleQA, an open-source dataset focusing on comprehension of narratives, targeting students from kindergarten to eighth grade (Table 1).


[14-1162] Lacks synthesis, File: paper_6.txt,  Coder: default
Zero-shot cross-lingual structured prediction. Zero-shot cross-lingual learning becomes an emerging research topic as it eliminates the requirement of labeled data for training models in low-resource languages. Various structured prediction tasks have be studied, including named entity recognition (Pan et al., 2017;Hu et al., 2020), dependency parsing (Ahmad et al., 2019, relation extraction (Zou et al., 2018;Ni and Florian, 2019), and event argument extraction (Subburathinam et al., 2019;Ahmad et al., 2021;Nguyen and Nguyen, 2021). Most of them are classification-based models that build classifiers on top of a multilingual pre-trained masked language models. To further deal with the discrepancy between languages, some of them require additional information, such as bilingual dictionaries Ni and Florian, 2019), translation pairs (Zou et al., 2018), and dependency parse trees (Subburathinam et al., 2019;Ahmad et al., 2021;Nguyen and Nguyen, 2021). However, as pointed out by previous literature Hsu et al., 2021), classification-based models are less powerful to model dependencies between entities compared to generation-based models.


[1164-1713] Lacks synthesis, File: paper_6.txt,  Coder: default
Generation-based structured prediction. Several works have demonstrated the great success of generation-based models on monolingual structured prediction tasks, including named entity recognition (Yan et al., 2021), relation extraction Paolini et al., 2021), and event extraction (Du et al., 2021;Hsu et al., 2021;Lu et al., 2021). Yet, as mentioned in Section 1, their designed generating targets are language-dependent. Accordingly, directly applying their methods to the zero-shot cross-lingual setting would result in less-preferred performance.


[14-981] Lacks synthesis, File: paper_7.txt,  Coder: default
Open-Domain Question Answering

In this era of data explosion, ODQA offers a way to rapidly and accurately fulfill user's information needs, and hence has recently received significant attention from both industry and academia (Min et al., 2021a). Following the work of DrQA (Chen et al., 2017), most recent works build a two-stage retriever-reader system to tackle the problem. The retriever aims at retrieving supportive passages to the given question from a large document corpus. The reader intends to find answer of the question from the first stage retrieved passages. Early work of Chen et al. (2017) adapts a BiLSTM architecture with various lexical and semantic features from the question and passages as inputs. Later, with the emergence of large-scale pre-trained language models, readers based on pre-trained models such as BERT and T5 Raffel et al., 2019) have become a common approach (Yang et al., 2019;Karpukhin et al., 2020;Izacard and Grave, 2020b).


[983-1857] Lacks synthesis, File: paper_7.txt,  Coder: default
Generative Readers

Compared to extractive models which extract existing words from the retrieved passages, generative models are able to produce new words out of the retrieved passages, and thus provide a more flexible modeling framework.  and Lewis et al. (2020a) concatenate the given question with top retrieved passages and feed the concatenation to the BART model (Lewis et al., 2019). Izacard and Grave (2020b) separately encodes the question with each top retrieved passage, then takes the concatenation of the encoder outputs as input to the decoder. Their method provide a way to better aggregate evidence from multiple passages and improve the performance significantly. FiD-KD (Izacard and Grave, 2020a) is an extension of FiD model that increases the accuracy of passage retrieval by training the dense retriever with the guidance of the FiD reader iteratively.


[1859-2513] Lacks synthesis, File: paper_7.txt,  Coder: default
Pointer-Generator Network

Pointer-Generator Network (See et al., 2017) is an extension of the sequence-to-sequence model by integrating a copy mechanism (Vinyals et al., 2017) into the generator. At each decoding stage, the model is able to either directly copy a word from the input or generate one with certain probability, and thus can be viewed as a combination of extractive and generative approaches. It has been frequently used in natural language tasks like summarization (Gu et al., 2016;See et al.,  Gehrmann et al., 2018) and neural machine translation (Luong et al., 2014;Gu et al., 2017), but its application to ODQA has been less explored.


[262-1627] Lacks synthesis, File: paper_9.txt,  Coder: default
Data-based Transfer Translating utterances for the intent classification task is relatively straightforward so previous works focused on projecting and/or aligning the entity labels between translated utterances (Dou and Neubig, 2021). This technique is followed by standard supervised training with those pseudo-labels and is commonly known as a translate-train method. One of the earliest works still being used for this purpose is fastalign (Dyer et al., 2013). It's an unsupervised word aligner trained on a parallel corpus to map each word (thus its entity label) in the source utterance to the word(s) in the target user utterance. Projecting the entity labels can also be done with word-by-word translation and source label copying (Yi and Cheng, 2021). A teacher model then weakly labels the target data, which is used to train the final student model. Sometimes, this type of label projection is complemented with an additional entity alignment step (Li et al., 2021a). Better performance can be achieved by using machine translation with entity matching and distributional statistics (Jain et al., 2019) though this can be a costly process for each language. A category of 'word substitution' methods such as code-switching (Qin et al., 2020;Kuwanto et al., 2021) or dictionary-enhanced pretraining  have also been shown to improve cross-lingual transfer.


[1372-1506] Unsupported claim, File: paper_1.txt,  Coder: default
For example, large-scale commonsense knowledge graphs (CSKG) store structured commonsense knowledge in the form of knowledge triplets.


[98-293] Unsupported claim, File: paper_10.txt,  Coder: default
Question answering (QA) are fundamental for supporting humans’ development of reading comprehension skills, as questions serve as both instruments for evaluation and tools to facilitate learning.


[1785-1992] Unsupported claim, File: paper_10.txt,  Coder: default
This issue is compounded by the fact that many benchmarks rely on crowd-sourced workers who may not have sufficient training or education domain knowledge needed to create valid questions in a onsistent way.


[715-1194] Unsupported claim, File: paper_3.txt,  Coder: default
However, previous speech pre-training work suffers from two problems: (1) most of them learn the speech representation with only unlabeled speech data but ignore the importance of textual data to spoken language tasks (e.g., automatic speech recognition) which require the modality transformation; (2) most of these models solely rely on a pre-trained speech encoder for various downstream tasks, leaving the decoder not pre-trained for the sequence-to-sequence generation tasks.


[3125-3139] Unsupported claim, File: paper_3.txt,  Coder: default
the BASE model


[3143-3155] Unsupported claim, File: paper_3.txt,  Coder: default
the ASR task


[3186-3232] Unsupported claim, File: paper_3.txt,  Coder: default
the state-of-the-art voice Transformer network


[3237-3248] Unsupported claim, File: paper_3.txt,  Coder: default
the VC task


[3446-3458] Unsupported claim, File: paper_3.txt,  Coder: default
the SID task


[181-387] Unsupported claim, File: paper_4.txt,  Coder: default
Since metric scores are known to be a poor substitute for human assessment, this only results in the pos-sibility that the best system according to human judges is inadvertently filtered out at this stage. 


[595-726] Unsupported claim, File: paper_4.txt,  Coder: default
in the sixth Dialog System Technology Challenge (DSTC6) systems were filtered according to metric scores prior to human evaluation.


[728-1010] Unsupported claim, File: paper_4.txt,  Coder: default
In terms of the live evaluation, competitions such as Convai2 report such evaluations as highly challenging, with many of the resulting dialogues reported to be senseless, offensive, or simply not in line with instructions and ultimately live evaluation results have been discarded.


[1202-1396] Unsupported claim, File: paper_4.txt,  Coder: default
On the other hand, competitions that (for one reason or another) do not release data and evaluation techniques into the public domain have reported relative success in terms of human evaluation.


[1397-1540] Unsupported claim, File: paper_4.txt,  Coder: default
However until such methods can be accessed and independently verified through replication studies, they will unfortunately have little impact .


[4488-4651] Unsupported claim, File: paper_4.txt,  Coder: default
In addition to the above issues, human evaluation of dialogue systems rarely take into account the fact that differences in performance can occur simply by chance.


[759-797] Unsupported claim, File: paper_5.txt,  Coder: default
sentiment analysis (SST movie reviews)


[802-833] Unsupported claim, File: paper_5.txt,  Coder: default
relation extraction (Wikipedia)


[2361-2376] Unsupported claim, File: paper_5.txt,  Coder: default
the ZuCo corpus


[61-224] Unsupported claim, File: paper_6.txt,  Coder: default
Zero-shot cross-lingual learning becomes an emerging research topic as it eliminates the requirement of labeled data for training models in low-resource languages.


[1718-1727] Unsupported claim, File: paper_7.txt,  Coder: default
FiD model


[14-103] Unsupported claim, File: paper_8.txt,  Coder: default
Early exiting is a widely used technique to accelerate inference of deep neural networks.


[732-794] Unsupported claim, File: paper_8.txt,  Coder: default
However, these methods can not easily generalize to new tasks.


[1409-1478] Unsupported claim, File: paper_8.txt,  Coder: default
Compared with previous heuristically designed metrics for difficulty,


[3669-3768] Unsupported claim, File: paper_8.txt,  Coder: default
HASHEE requires no internal classifiers nor extra parameters, which are necessary in previous work.


[4299-4454] Unsupported claim, File: paper_8.txt,  Coder: default
HASHEE, despite its simplicity, can achieve higher performance with fewer FLOPs and inference time than previous state-of-the-art methods on various tasks.


[4483-4518] Unsupported claim, File: paper_8.txt,  Coder: default
several text summarization datasets


[14-260] Unsupported claim, File: paper_9.txt,  Coder: default
Several approaches to zero-shot cross-lingual transfer exist and can broadly be divided into: a) Databased Transfer, which focuses on training data transformation and b) Model-based Transfer that centres around modifying models' training routine.
